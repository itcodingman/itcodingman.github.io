[{"categories":["Spring"],"contents":"1. 概述 在本文中，我们将描述观察者模式并查看一些 Java 实现替代方案。 2.什么是观察者模式？ 观察者是一种行为设计模式。它指定对象之间的通信：observable和observers。observable对象是通知observers其状态变化的对象。 例如，新闻机构可以在收到新闻时通知频道。接收新闻会改变通讯社的状态，并导致频道得到通知。 让我们看看我们如何自己实现它。 首先，让我们定义NewsAgency类： public class NewsAgency { private String news; private List\u0026lt;Channel\u0026gt; channels = new ArrayList\u0026lt;\u0026gt;(); public void addObserver(Channel channel) { this.channels.add(channel); } public void removeObserver(Channel channel) { this.channels.remove(channel); } public void setNews(String news) { this.news = news; for (Channel channel : this.channels) { channel.update(this.news); } } } NewsAgency是可观察的，当新闻更新时，NewsAgency的状态会发生变化。当发生变化时，*NewsAgency通过调用他们的**update()*方法来通知观察者这一事实。 为了能够做到这一点，可观察对象需要保留对观察者的引用，在我们的例子中，它是通道变量。 现在让我们看看观察者（Channel类）的样子。它应该具有update()方法，当NewsAgency的状态发生变化时会调用该方法： public class NewsChannel implements Channel { private String news; @Override public void update(Object news) { this.setNews((String) news); } } Channel接口只有一种方法： public interface Channel { public void update(Object o); } 现在，如果我们将NewsChannel的实例添加到观察者列表中，并更改NewsAgency的状态，则NewsChannel的实例将被更新： NewsAgency observable = new NewsAgency(); NewsChannel observer = new NewsChannel(); observable.addObserver(observer); observable.setNews(\u0026#34;news\u0026#34;); assertEquals(observer.getNews(), \u0026#34;news\u0026#34;); Java 核心库中有一个预定义的Observer接口，这使得观察者模式的实现更加简单。让我们看看它。 3. 使用Observer实现 java.util.Observer接口定义了*update()*方法，所以我们不需要像上一节那样自己定义它。 让我们看看如何在我们的实现中使用它： public class ONewsChannel implements Observer { private String news; @Override public void update(Observable o, Object news) { this.setNews((String) news); } } 在这里，第二个参数来自Observable，我们将在下面看到。 要定义observable，我们需要扩展 Java 的Observable类： public class ONewsAgency extends Observable { private String news; public void setNews(String news) { this.news = news; setChanged(); notifyObservers(news); } } 请注意，我们不需要直接调用观察者的update()方法。我们只需调用setChanged()和notifyObservers()，Observable类会为我们完成剩下的工作。 此外，它包含一个观察者列表并公开了维护该列表的方法*——addObserver()和deleteObserver()*。 要测试结果，我们只需将观察者添加到此列表并设置新闻： ONewsAgency observable = new ONewsAgency(); ONewsChannel observer = new ONewsChannel(); observable.addObserver(observer); observable.setNews(\u0026#34;news\u0026#34;); assertEquals(observer.getNews(), \u0026#34;news\u0026#34;); Observer接口并不完美，自 Java 9 以来已被弃用。它的一个缺点是Observable不是接口而是类，这就是为什么子类不能用作可观察对象的原因。 此外，开发人员可以覆盖某些Observable的同步方法并破坏它们的线程安全。 让我们看一下ProperyChangeListener接口，建议不要使用Observer。 4. 使用PropertyChangeListener实现 **在此实现中，可观察对象必须保留对PropertyChangeSupport实例的引用。**当类的属性发生更改时，它有助于将通知发送给观察者。 让我们定义可观察对象： public class PCLNewsAgency { private String news; private PropertyChangeSupport support; public PCLNewsAgency() { support = new PropertyChangeSupport(this); } public void addPropertyChangeListener(PropertyChangeListener pcl) { support.addPropertyChangeListener(pcl); } public void removePropertyChangeListener(PropertyChangeListener pcl) { support.removePropertyChangeListener(pcl); } public void setNews(String value) { support.firePropertyChange(\u0026#34;news\u0026#34;, this.news, value); this.news = value; } } 使用这种支持，我们可以添加和删除观察者，并在可观察对象的状态发生变化时通知他们： support.firePropertyChange(\u0026#34;news\u0026#34;, this.news, value); 这里，第一个参数是观察到的属性的名称。第二个和第三个参数相应地是它的旧值和新值。 观察者应该实现*PropertyChangeListener*： public class PCLNewsChannel implements PropertyChangeListener { private String news; public void propertyChange(PropertyChangeEvent evt) { this.setNews((String) evt.getNewValue()); } } 由于PropertyChangeSupport类正在为我们接线，我们可以从事件中恢复新的属性值。 让我们测试实现以确保它也可以工作： PCLNewsAgency observable = new PCLNewsAgency(); PCLNewsChannel observer = new PCLNewsChannel(); observable.addPropertyChangeListener(observer); observable.setNews(\u0026#34;news\u0026#34;); assertEquals(observer.getNews(), \u0026#34;news\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/java_observer_pattern/","tags":["Pattern"],"title":"Java中的观察者模式"},{"categories":["Java"],"contents":"1. 概述 有时我们需要确定一个对象是否是原始类型，特别是对于包装原始类型。但是，标准 JDK 中没有内置方法来实现这一点。 在本快速教程中，我们将了解如何使用核心 Java 实现解决方案。然后我们将看看如何使用几个常用的库来实现这一点。 2. 原始类型和包装类 在 Java 中有九个预定义的对象来表示八个原语和一个*void类型。*每个原始类型都有一个对应的Wrapper Class。 要了解有关Primitives和Object的更多信息，请参阅这篇文章。 ** java.lang.Class.isPrimitive()方法可以判断指定的对象是否代表原始类型。但是，它不适用于原语的包装器。 例如，以下语句返回false： Integer.class.isPrimitive(); 现在让我们来看看实现这一目标的不同方法。 3. 使用核心 Java 首先，让我们定义一个存储包装器和原始类型类的HashMap变量： private static final Map\u0026lt;Class\u0026lt;?\u0026gt;, Class\u0026lt;?\u0026gt;\u0026gt; WRAPPER_TYPE_MAP; static { WRAPPER_TYPE_MAP = new HashMap\u0026lt;Class\u0026lt;?\u0026gt;, Class\u0026lt;?\u0026gt;\u0026gt;(16); WRAPPER_TYPE_MAP.put(Integer.class, int.class); WRAPPER_TYPE_MAP.put(Byte.class, byte.class); WRAPPER_TYPE_MAP.put(Character.class, char.class); WRAPPER_TYPE_MAP.put(Boolean.class, boolean.class); WRAPPER_TYPE_MAP.put(Double.class, double.class); WRAPPER_TYPE_MAP.put(Float.class, float.class); WRAPPER_TYPE_MAP.put(Long.class, long.class); WRAPPER_TYPE_MAP.put(Short.class, short.class); WRAPPER_TYPE_MAP.put(Void.class, void.class); } 如果对象是原始包装类，我们可以使用java.utils.Map.ContainsKey()方法从预定义的HashMap变量中查找它。 现在我们可以创建一个简单的实用方法来确定对象源是否为原始类型： public static boolean isPrimitiveType(Object source) { return WRAPPER_TYPE_MAP.containsKey(source.getClass()); } 让我们验证这是否按预期工作： assertTrue(PrimitiveTypeUtil.isPrimitiveType(false)); assertTrue(PrimitiveTypeUtil.isPrimitiveType(1L)); assertFalse(PrimitiveTypeUtil.isPrimitiveType(StringUtils.EMPTY)); 4. 使用 Apache Commons – ClassUtils.isPrimitiveOrWrapper() Apache Commons Lang有一个ClassUtils.isPrimitiveOrWrapper方法，可用于确定一个类是原始类还是原始类的包装器。 首先，让我们将Maven Central的commons-lang3依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;version\u0026gt; \u0026lt;dependency\u0026gt; 然后让我们测试一下： assertTrue(ClassUtils.isPrimitiveOrWrapper(Boolean.False.getClass())); assertTrue(ClassUtils.isPrimitiveOrWrapper(boolean.class)); assertFalse(ClassUtils.isPrimitiveOrWrapper(StringUtils.EMPTY.getClass())); 5. 使用Guava——Primitives.isWrapperType() Guava通过Primitives.isWrapperType方法提供了类似的实现。 同样，让我们​​首先添加来自Maven Central的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;artifactId\u0026gt; \u0026lt;version\u0026gt;31.0.1-jre\u0026lt;version\u0026gt; \u0026lt;dependency\u0026gt; 同样，我们可以使用以下方法对其进行测试： assertTrue(Primitives.isWrapperType(Boolean.FALSE.getClass())); assertFalse(Primitives.isWrapperType(StringUtils.EMPTY.getClass())); 但是，Primitives.isWrapperType方法不适用于原始类，以下代码将返回 false： assertFalse(Primitives.isWrapperType(boolean.class)); \u0026quot; ","permalink":"http://itcodingman.github.io/java_object_primitive_type/","tags":["Core Java"],"title":"确定对象是否为原始类型"},{"categories":["Java"],"contents":"1. 简介 在这个快速教程中，我们将探索在 Java中获取整数位数的不同方法。 我们还将分析不同的方法，以确定哪种算法最适合每种情况。 2.整数位数 对于这里讨论的方法，我们只考虑正整数。如果我们期望任何负输入，那么我们可以在使用任何这些方法之前先使用Math.abs(number) 。 2.1 基于字符串的解决方案 获取Integer中位数的最简单方法可能是将其转换为String，然后调用*length()*方法。这将返回我们数字的字符串表示的长度： int length = String.valueOf(number).length(); **但是，这可能是一种次优方法，因为该语句涉及为每个评估分配一个*字符串的内存。**JVM 必须解析我们的数字并将其数字复制到单独的字符串中，*并执行许多其他不同的操作（如保留临时副本、处理 Unicode 转换等）。 如果我们只有几个数字要评估，那么我们可以使用这个解决方案，因为这种方法与任何其他方法之间的差异可以忽略不计，即使对于大量数字也是如此。 2.2. 对数法 对于以十进制形式表示的数字，如果我们以 10 为底数取其对数并将其四舍五入，我们将得到该数字的位数： int length = (int) (Math.log10(number) + 1); 请注意，未定义任何数字的log 10 0 ，因此如果我们期望任何值为**0的输入，那么我们也可以对其进行检查。 **对数方法比基于字符串的方法快得多，因为它不需要经过任何数据转换的过程。**它只涉及一个简单、直接的计算，没有任何额外的对象初始化或循环。 2.3. 重复乘法 在这个方法中，我们将取一个临时变量（初始化为 1）并不断地将它乘以 10，直到它变得大于我们的数字。在此过程中，我们还将使用一个长度变量，它将跟踪数字的长度： int length = 0; long temp = 1; while (temp \u0026lt;= number) { length++; temp *= 10; } return length; 在此代码中，temp *= 10与编写*temp = (temp \u0026laquo; 3) + (temp \u0026laquo; 1)*相同。由于与移位运算符相比，在某些处理器上乘法通常是一种更昂贵的运算，因此后者可能更有效一些。 2.4. 以二的幂除 如果我们知道我们的数字的范围，那么我们可以使用一个可以进一步减少我们比较的变体。此方法将数字除以 2 的幂（例如 1、2、4、8 等）： int length = 1; if (number \u0026gt;= 100000000) { length += 8; number /= 100000000; } if (number \u0026gt;= 10000) { length += 4; number /= 10000; } if (number \u0026gt;= 100) { length += 2; number /= 100; } if (number \u0026gt;= 10) { length += 1; } return length; 它利用了任何数字都可以用 2 的幂表示的事实。例如，15 可以表示为 8+4+2+1，它们都是 2 的幂。 对于 15 位数字，我们将在之前的方法中进行 15 次比较，而在此方法中只有 4 次。 2.5. 分而治之 与此处描述的所有其他方法相比，这可能是最笨重的方法；但是，它也是最快的，因为我们不执行任何类型的转换、乘法、加法或对象初始化。 我们只需三到四个简单的if语句就可以得到答案： if (number \u0026lt; 100000) { if (number \u0026lt; 100) { if (number \u0026lt; 10) { return 1; } else { return 2; } } else { if (number \u0026lt; 1000) { return 3; } else { if (number \u0026lt; 10000) { return 4; } else { return 5; } } } } else { if (number \u0026lt; 10000000) { if (number \u0026lt; 1000000) { return 6; } else { return 7; } } else { if (number \u0026lt; 100000000) { return 8; } else { if (number \u0026lt; 1000000000) { return 9; } else { return 10; } } } } 与前面的方法类似，我们只有知道我们的数字的范围才能使用这种方法。 3. 基准测试 现在我们对潜在的解决方案有了很好的理解，让我们使用Java Microbenchmark Harness (JMH)对我们的方法进行一些简单的基准测试。 下表显示了每个操作的平均处理时间（以纳秒为单位）： Benchmark Mode Cnt Score Error Units Benchmarking.stringBasedSolution avgt 200 32.736 ± 0.589 ns/op Benchmarking.logarithmicApproach avgt 200 26.123 ± 0.064 ns/op Benchmarking.repeatedMultiplication avgt 200 7.494 ± 0.207 ns/op Benchmarking.dividingWithPowersOf2 avgt 200 1.264 ± 0.030 ns/op Benchmarking.divideAndConquer avgt 200 0.956 ± 0.011 ns/op 基于String的方案是最简单的，也是最昂贵的操作，因为它是唯一需要数据转换和新对象初始化的方案。 对数方法比以前的解决方案效率更高，因为它不涉及任何数据转换。此外，作为单行解决方案，它可以很好地替代基于字符串的方法。 重复乘法涉及与数字长度成比例的简单乘法；例如，如果一个数字是 15 位长，那么这个方法将涉及 15 次乘法。 然而，下一个方法利用了每个数字都可以用 2 的幂表示的事实（类似于 BCD 的方法）。它将相同的方程简化为四个除法运算，因此它比前者更有效。 最后，正如我们可以推断的那样，**最有效的算法是冗长的分而治之的实现，**它只需三到四个简单的if语句即可提供答案。如果我们有大量需要分析的数字数据集，我们可以使用它。 4。结论 在这篇简短的文章中，我们概述了一些在整数中查找位数的方法，并比较了每种方法的效率。 Java底层 通用页脚横幅 \u0026quot; ","permalink":"http://itcodingman.github.io/java_number_of_digits_in_int/","tags":[],"title":"Java中整数中的位数"},{"categories":["Java"],"contents":"1. 简介 当Java无法将String转换为数字类型时，它会抛出NumberFormatException—— 一个未经检查的异常。 由于它是unchecked，Java 不会强迫我们去处理或声明它。 在这个快速教程中，我们将描述和演示Java 中导致NumberFormatException的原因以及如何避免或处理它。 2. NumberFormatException的原因 有多种问题会导致NumberFormatException。例如，Java 中的一些构造函数和方法会抛出此异常。 我们将在下面的部分中讨论其中的大部分。 2.1 传递给构造函数的非数字数据 让我们看一下使用非数字数据构造Integer或Double对象的尝试。 这两个语句都会抛出NumberFormatException： Integer aIntegerObj = new Integer(\u0026#34;one\u0026#34;); Double doubleDecimalObj = new Double(\u0026#34;two.2\u0026#34;); 让我们看看当我们在第 1 行将无效输入“one”传递给Integer构造函数时得到的堆栈跟踪： Exception in thread \u0026#34;main\u0026#34; java.lang.NumberFormatException: For input string: \u0026#34;one\u0026#34; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:580) at java.lang.Integer.\u0026lt;init\u0026gt;(Integer.java:867) at MainClass.main(MainClass.java:11) 它抛出NumberFormatException。Integer构造函数在尝试在内部使用 parseInt() 理解输入时失败。 Java Number API 不会将单词解析为数字，因此我们可以通过将代码更改为预期值来更正代码： Integer aIntegerObj = new Integer(\u0026#34;1\u0026#34;); Double doubleDecimalObj = new Double(\u0026#34;2.2\u0026#34;); 2.2. 解析包含非数字数据的字符串 类似于 Java 在构造函数中对解析的支持，我们有专门的解析方法，如par *seInt()、parseDouble()、*valueOf()和decode() 。 如果我们尝试对这些进行相同类型的转换： int aIntPrim = Integer.parseInt(\u0026#34;two\u0026#34;); double aDoublePrim = Double.parseDouble(\u0026#34;two.two\u0026#34;); Integer aIntObj = Integer.valueOf(\u0026#34;three\u0026#34;); Long decodedLong = Long.decode(\u0026#34;64403L\u0026#34;); 然后我们会看到同样的错误行为。 而且，我们可以用类似的方式修复它们： int aIntPrim = Integer.parseInt(\u0026#34;2\u0026#34;); double aDoublePrim = Double.parseDouble(\u0026#34;2.2\u0026#34;); Integer aIntObj = Integer.valueOf(\u0026#34;3\u0026#34;); Long decodedLong = Long.decode(\u0026#34;64403\u0026#34;); 2.3. 传递带有无关字符的字符串 或者，如果我们尝试将字符串转换为输入中包含无关数据的数字，例如空格或特殊字符： Short shortInt = new Short(\u0026#34;2 \u0026#34;); int bIntPrim = Integer.parseInt(\u0026#34;_6000\u0026#34;); 然后，我们将遇到与以前相同的问题。 我们可以通过一些字符串操作来纠正这些问题： Short shortInt = new Short(\u0026#34;2 \u0026#34;.trim()); int bIntPrim = Integer.parseInt(\u0026#34;_6000\u0026#34;.replaceAll(\u0026#34;_\u0026#34;, \u0026#34;\u0026#34;)); int bIntPrim = Integer.parseInt(\u0026#34;-6000\u0026#34;); 请注意，在第 3 行中，允许使用负数，使用连字符作为减号。 2.4. 特定于区域设置的数字格式 让我们看一下特定于语言环境的数字的特殊情况。在欧洲地区，逗号可能代表小数位。例如，“4000,1”可以表示十进制数“4000.1”。 默认情况下，我们将通过尝试解析包含逗号的值来获得NumberFormatException ： double aDoublePrim = Double.parseDouble(\u0026#34;4000,1\u0026#34;); 在这种情况下，我们需要允许逗号并避免异常。为了使这成为可能，Java 需要将这里的逗号理解为小数。 我们可以允许欧洲地区使用逗号，并通过使用NumberFormat来避免异常。 让我们以Locale for France 为例来看看它的实际效果： NumberFormat numberFormat = NumberFormat.getInstance(Locale.FRANCE); Number parsedNumber = numberFormat.parse(\u0026#34;4000,1\u0026#34;); assertEquals(4000.1, parsedNumber.doubleValue()); assertEquals(4000, parsedNumber.intValue()); 3. 最佳实践 让我们谈谈一些可以帮助我们处理NumberFormatException的良好做法：  不要尝试将字母或特殊字符转换为数字——Java Number API 无法做到这一点。 我们可能希望**使用正则表达式****验证输入字符串**并为无效字符抛出异常。 *我们可以使用trim()*和 *replaceAll()*等方法针对可预见的已知问题清理输入。 在某些情况下，输入中的特殊字符可能是有效的。因此，我们对此进行了特殊处理，例如使用支持多种格式的NumberFormat。 \u0026quot;  ","permalink":"http://itcodingman.github.io/java_number_format_exception/","tags":[],"title":"了解 Java 中的 NumberFormatException"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将讨论 Java 的*Number类*。首先，我们将了解 Number类的作用以及它包含的方法。然后，我们将深入研究这个抽象类的各种实现。 2. Number类 Number是java.lang包中的一个抽象类。各种子类扩展了Number类。最常用的是：  byte short int long double float  此类的主要目的是提供将相关数值转换为各种原始类型（如byte、short、int、long、double和float ）的方法。 有四种抽象方法可用于帮助完成任务：  intValue() longValue() doubleValue() floatValue()  ** Number还有两个具体方法byteValue()和shortValue() **，它们将分别返回指定数字的byte值和short值。要了解有关Number类的不同实现的更多信息，请参阅我们关于Wrapper Classes的文章。 在接下来的部分中，我们将详细了解这些方法及其用法。 3. 具体方法 让我们一一讨论具体方法。 3.1 shortValue() 顾名思义，此方法将指定的Number对象转换为原始的short值。 默认实现将int值转换为short并返回它。但是，子类有自己的实现，它们将各自的值转换为short然后返回。 下面是如何将Double值转换为短原始类型： @Test public void givenDoubleValue_whenShortValueUsed_thenShortValueReturned() { Double doubleValue = Double.valueOf(9999.999); assertEquals(9999, doubleValue.shortValue()); } 3.2. byteValue() 此方法将指定Number对象的值作为byte值返回。然而，Number类的子类有自己的实现。 以下是如何将float值转换为byte值： @Test public void givenFloatValue_whenByteValueUsed_thenByteValueReturned() { Float floatValue = Float.valueOf(101.99F); assertEquals(101, floatValue.byteValue()); } 4. 抽象方法 此外，Number类还有一些抽象方法和几个实现它们的子类。 在本节中，让我们快速了解如何使用这些方法。 4.1 intValue() 此方法在上下文中返回*Number的int*表示形式。** 让我们看看如何将Long值更改为int： @Test public void givenLongValue_whenInitValueUsed_thenInitValueReturned() { Long longValue = Long.valueOf(1000L); assertEquals(1000, longValue.intValue()); } 当然，编译器在这里通过将long值转换为int来执行缩小操作。 4.2. longValue() 此方法将返回指定为long的数字的值。 在这个例子中，我们看到一个Integer值是如何通过Integer类转换为long的： @Test public void givenIntegerValue_whenLongValueUsed_thenLongValueReturned() { Integer integerValue = Integer.valueOf(100); assertEquals(100, integerValue.longValue()); } 与intValue()方法相比，longValue()在扩展基元转换后返回long值。 4.3. floatValue() **我们可以使用此方法将指定 N 数字的值作为浮点数返回。让我们看一下如何将Short值转换为浮点值： @Test public void givenShortValue_whenFloatValueUsed_thenFloatValueReturned() { Short shortValue = Short.valueOf(127); assertEquals(127.0F, shortValue.floatValue(), 0); } **同样，longValue()和floatValue()也执行扩展原语转换。 4.4. doubleValue() 最后，此方法将给定Number类的值转换为double原始数据类型并返回它。 这是使用此方法将Byte转换为double的示例： @Test public void givenByteValue_whenDoubleValueUsed_thenDoubleValueReturned() { Byte byteValue = Byte.valueOf(120); assertEquals(120.0, byteValue.doubleValue(), 0); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_number_class/","tags":["Core Java"],"title":"Java中的数字类指南"},{"categories":["Java"],"contents":"1. 概述 多年来，我们一直在采取多种策略，从 Elvis 运算符到*Optional，以帮助从我们的应用程序中删除NullPointerException 。*在本教程中，我们将了解 Uber 对对话NullAway的贡献以及如何使用它。 NullAway 是一个构建工具，可帮助我们消除Java 代码中的NullPointerException (NPE)。 此工具执行一系列基于类型的本地检查，以确保在您的代码中被取消引用的任何指针都不能为null。它具有低构建时间开销，并且可以配置为在您的代码的每个构建中运行。 2. 安装 下面我们来看看如何安装 NullAway 及其依赖项。在此示例中，我们将使用 Gradle 配置 NullAway。 NullAway 依赖于 Error Prone。因此，我们将添加容易出错的插件： plugins { id \u0026#34;net.ltgt.errorprone\u0026#34; version \u0026#34;1.1.1\u0026#34; } 我们还将在不同的范围内添加四个依赖项：annotationProcessor、compileOnly、errorprone和errorproneJavac： dependencies { annotationProcessor \u0026#34;com.uber.nullaway:nullaway:0.7.9\u0026#34; compileOnly \u0026#34;com.google.code.findbugs:jsr305:3.0.2\u0026#34; errorprone \u0026#34;com.google.errorprone:error_prone_core:2.3.4\u0026#34; errorproneJavac \u0026#34;com.google.errorprone:javac:9+181-r4173-1\u0026#34; } 最后，我们将添加配置 NullAway 在编译期间如何工作的 Gradle 任务： import net.ltgt.gradle.errorprone.CheckSeverity tasks.withType(JavaCompile) { options.errorprone { check(\u0026#34;NullAway\u0026#34;, CheckSeverity.ERROR) option(\u0026#34;NullAway:AnnotatedPackages\u0026#34;, \u0026#34;com.codingman\u0026#34;) } } 上述任务将 NullAway 严重性设置为错误级别，这意味着我们可以配置 NullAway 以停止生成错误。默认情况下，NullAway 只会在编译时警告用户。 此外，该任务设置要检查空取消引用的包。 就是这样，我们现在可以在我们的 Java 代码中使用该工具了。 同样，我们可以使用其他构建系统Maven 或 Bazel来集成该工具。 3. 用法 假设我们有一个Person类，其中包含一个age属性。此外，我们还有一个getAge方法，它接受一个Person实例作为参数： Integer getAge(Person person) { return person.getAge(); } 此时，我们可以看到如果person为null ， getAge将抛出NullPointerException。 NullAway 假定每个方法参数、返回值和字段都是非空的。因此，它将期望person实例为非null。 我们还假设在我们的代码中确实有一个地方将空引用传递给getAge： Integer yearsToRetirement() { Person p = null; // ... p never gets set correctly...  return 65 - getAge(p); } 然后，运行构建将产生以下错误： error: [NullAway] passing @Nullable parameter \u0026#39;null\u0026#39; where @NonNull is required getAge(p); 我们可以通过向参数添加*@Nullable*注释来修复此错误： Integer getAge(@Nullable Person person) { // ... same as earlier } 现在，当我们运行构建时，我们会看到一个新错误： error: [NullAway] dereferenced expression person is @Nullable return person.getAge(); ^ 这告诉我们person实例有可能为null。我们可以通过添加一个标准的空检查来解决这个问题： Integer getAge(@Nullable Person person) { if (person != null) { return person.getAge(); } else { return 0; } } \u0026quot; ","permalink":"http://itcodingman.github.io/java_nullaway/","tags":["Exception","Java Null"],"title":"使用 NullAway 避免 NullPointerExceptions"},{"categories":["Java","Java Collections"],"contents":"1. 概述 在本教程中，我们将看到如何从 Java 集合创建空安全流。 首先，需要对 Java 8 的方法参考、Lambda 表达式、可选 和流 API 有一定的了解才能完全理解本材料。 如果您不熟悉这些主题中的任何一个，请先查看我们之前的文章：Java 8 中的新特性、 Java 8 可选指南和Java 8 流简介。 2. Maven依赖 在我们开始之前，我们需要在某些场景下需要一个 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; *commons-collections4*库可以从 Maven Central 下载。 3. 从集合创建流 从任何类型的Collection创建Stream的基本方法是根据所需的流类型在集合上调用*stream()或parallelStream()*方法： Collection\u0026lt;String\u0026gt; collection = Arrays.asList(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;); Stream\u0026lt;String\u0026gt; streamOfCollection = collection.stream(); 我们的集合很可能在某个时候有一个外部源，当从集合创建流时，我们可能最终会使用类似于下面的方法： public Stream\u0026lt;String\u0026gt; collectionAsStream(Collection\u0026lt;String\u0026gt; collection) { return collection.stream(); } 这可能会导致一些问题。当提供的集合指向空引用时，代码将在运行时抛出 NullPointerException。 以下部分介绍了我们如何防止这种情况。 4. 使创建的集合流为空安全 4.1 添加检查以防止空引用 为了防止意外的空指针异常，我们可以选择在从集合创建流时添加检查以防止空 引用： Stream\u0026lt;String\u0026gt; collectionAsStream(Collection\u0026lt;String\u0026gt; collection) { return collection == null ? Stream.empty() : collection.stream(); } 然而，这种方法有几个问题。 首先，空值检查妨碍了业务逻辑，降低了程序的整体可读性。 其次，在 Java SE 8 之后，使用null表示值的缺失被认为是错误的方法：有更好的方法来模拟值的缺失和存在。 请务必记住，空Collection与 null Collection不同。虽然第一个表示我们的查询没有要显示的结果或元素，但第二个表示在此过程中刚刚发生了一种错误。 4.2. 使用CollectionUtils库中的emptyIfNull方法 我们可以选择使用 Apache Commons 的CollectionUtils库来确保我们的流是空安全的。这个库提供了一个emptyIfNull方法，它返回一个不可变的空集合，给定一个空集合作为参数，否则返回集合本身： public Stream\u0026lt;String\u0026gt; collectionAsStream(Collection\u0026lt;String\u0026gt; collection) { return emptyIfNull(collection).stream(); } 这是一个非常简单的策略。但是，它依赖于外部库。如果软件开发策略限制使用此类库，则此解决方案无效。 4.3. 使用 Java 8 的可选 Java SE 8 的Optional是一个单值容器，它要么包含值，要么不包含值。如果缺少值，则称Optional容器为空。 使用Optional可以说是从流中创建空安全集合的最佳整体策略。 让我们看看如何使用它，然后在下面进行快速讨论： public Stream\u0026lt;String\u0026gt; collectionToStream(Collection\u0026lt;String\u0026gt; collection) { return Optional.ofNullable(collection) .map(Collection::stream) .orElseGet(Stream::empty); }  **Optional.ofNullable(collection)从传入的集合中创建一个Optional对象。如果集合为空，则创建一个空的Optional对象。 **map(Collection::stream)提取Optional对象中包含的值作为map方法 ( Collection.stream() ) ***orElseGet(Stream::empty)*在Optional对象为空的情况下返回回退值，即传入的集合为null。  因此，我们主动保护我们的代码免受意外空指针异常的影响。 4.4. 使用 Java 9 的Stream OfNullable 在 4.1 节中检查我们之前的三元示例。并且考虑到某些元素可能是null而不是Collection，我们可以使用Stream 类中的ofNullable方法 。 我们可以将上面的示例转换为： Stream\u0026lt;String\u0026gt; collectionAsStream(Collection\u0026lt;String\u0026gt; collection) { return collection.stream().flatMap(s -\u0026gt; Stream.ofNullable(s)); } 5. 结论 在本文中，我们简要回顾了如何从给定集合创建流。然后，我们继续探索三个关键策略，以确保在从集合创建时创建的流是空安全的。 最后，我们指出了在相关时使用每种策略的弱点。 Java底层 通用页脚横幅 \u0026quot; ","permalink":"http://itcodingman.github.io/java_null_safe_streams_from_collections/","tags":["Java Null","Java Streams"],"title":"来自集合的 Java 空安全流"},{"categories":["Java"],"contents":"1. 概述 在某些情况下，尝试使用*pow()*在 Java 中查找第 n 个根是不准确的。原因是双精度数可能会在途中丢失精度。因此，我们可能需要对结果进行润色以处理这些情况。 2.问题 假设我们要计算第 N 个根为： base = 125, exponent = 3 换句话说，125 的 3 次方是哪个数？ 假设**数字 x 的 n 次根等于数字 x 的1/n 次方 **。因此，我们将等式转换为： N-th root = Math.pow(125, 1/3) 结果是 4.999999999999999。而 4.999999999999999 的 3 次方不是 125。那么我们该如何解决呢？ 3. 正确计算第N个根 上述问题的解决方案主要是一种数学解决方法，而且很简单。众所周知，数字 x 的 n 次根等于数字 x 的1/n 次方。 有几种方法可以利用上面的等式。首先，我们可以使用 BigDecimal并实现我们的Newton-Raphson方法版本。其次，我们可以将结果四舍五入到最接近的数字，最后，我们可以定义结果可接受的误差范围。我们将专注于最后两种方法。 3.1 圆形的 我们现在将使用舍入来解决我们的问题。让我们重用之前的示例，看看我们如何获得正确的结果： public void whenBaseIs125AndNIs3_thenNthIs5() { double nth = Math.round(Math.pow(125, 1.0 / 3.0)); assertEquals(5, nth, 0); } 3.2. 误差范围 这种方法与上面非常相似。我们只需要定义一个可接受的误差范围，假设为 0.00001： public void whenBaseIs625AndNIs4_thenNthIs5() { double nth = Math.pow(625, 1.0 / 4.0); assertEquals(5, nth, 0.00001); } 测试证明我们的方法正确计算了第 n 个根。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_nth_root/","tags":["Core Java"],"title":"在 Java 中计算第 n 个根"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将探索 Java NIO.2 文件系统 API 的WatchService接口。这是 Java 7 中与FileVisitor接口一起引入的较新 IO API 的鲜为人知的特性之一。 要在应用程序中使用WatchService接口，您需要导入适当的类： import java.nio.file.*; 2. 为什么要使用WatchService 了解服务功能的一个常见示例实际上是 IDE。 您可能已经注意到 IDE 总是会检测到发生在其外部的源代码文件的更改。一些 IDE 使用对话框通知您，以便您可以选择是否从文件系统重新加载文件，其他 IDE 只是在后台更新文件。 同样，Play 等较新的框架也默认热重新加载应用程序代码——无论何时您从任何编辑器执行编辑。 这些应用程序采用了一种称为文件更改通知的功能，该功能在所有文件系统中都可用。 基本上，我们可以编写代码来轮询文件系统以查找特定文件和目录的更改。但是，此解决方案不可扩展，尤其是在文件和目录达到成百上千的情况下。 在 Java 7 NIO.2 中，WatchService API 提供了一个可扩展的解决方案来监控目录的变化。它有一个干净的 API 并且针对性能进行了很好的优化，我们不需要实现我们自己的解决方案。 3. Watchservice 是如何工作的？ 要使用WatchService功能，第一步是使用java.nio.file.FileSystems类创建一个**WatchService实例： WatchService watchService = FileSystems.getDefault().newWatchService(); 接下来，我们必须创建要监视的目录的路径： Path path = Paths.get(\u0026#34;pathToDir\u0026#34;); 在这一步之后，我们必须向 watch 服务注册路径。在这个阶段有两个重要的概念需要理解。StandardWatchEventKinds类和WatchKey类。看看下面的注册码只是为了了解每个秋天的地方。我们将对此进行解释： WatchKey watchKey = path.register( watchService, StandardWatchEventKinds...); 这里只注意两件重要的事情：首先，路径注册 API 调用将监视服务实例作为第一个参数，然后是StandardWatchEventKinds的可变参数。其次，注册过程的返回类型是一个WatchKey实例。 **3.1 StandardWatchEventKinds ** 这是一个类，其实例告诉监视服务要在注册目录上监视的事件类型。目前有四种可能的事件值得关注：  StandardWatchEventKinds.ENTRY_CREATE – 在监视目录中创建新条目时触发。这可能是由于创建了新文件或重命名了现有文件。 StandardWatchEventKinds.ENTRY_MODIFY – 当监视目录中的现有条目被修改时触发。所有文件编辑都会触发此事件。在某些平台上，即使更改文件属性也会触发它。 StandardWatchEventKinds.ENTRY_DELETE – 在监视目录中删除、移动或重命名条目时触发。 StandardWatchEventKinds.OVERFLOW – 触发以指示丢失或丢弃的事件。我们不会过多关注它  **3.2. WatchKey ** 此类表示向监视服务注册目录。当我们注册一个目录时，当我们向观察服务询问我们注册的任何事件是否发生时，它的实例由观察服务返回给我们。 Watch 服务没有为我们提供任何事件发生时都会调用的回调方法。我们只能通过多种方式对其进行轮询以找到此信息。 我们可以使用poll API： WatchKey watchKey = watchService.poll(); 此 API 调用立即返回。它返回下一个已发生事件的排队监视键，如果未发生已注册事件，则返回 null。 我们还可以使用带有超时参数的重载版本： WatchKey watchKey = watchService.poll(long timeout, TimeUnit units); 此 API 调用在返回值上与上一个类似。但是，它会阻塞超时时间单位，以提供更多时间来发生事件，而不是立即返回 null。 最后，我们可以使用take API： WatchKey watchKey = watchService.take(); 最后一种方法只是阻塞，直到事件发生。 这里我们必须注意一些非常重要的事情：当WatchKey实例由poll或take API 返回时，如果不调用它的 reset API，它将不会捕获更多事件： watchKey.reset(); 这意味着每次轮询操作返回时，监视键实例都会从监视服务队列中删除。重置API 调用将其放回队列中以等待更多事件。 观察者服务最实际的应用需要一个循环，在这个循环中我们不断检查被观察目录中的变化并进行相应的处理。我们可以使用以下成语来实现这一点： WatchKey key; while ((key = watchService.take()) != null) { for (WatchEvent\u0026lt;?\u0026gt; event : key.pollEvents()) { //process  } key.reset(); } 我们创建一个监视键来存储轮询操作的返回值。while 循环将阻塞，直到条件语句以监视键或 null 返回。 当我们得到一个 watch 键时，while 循环就会执行其中的代码。我们使用WatchKey.pollEvents API 返回已发生事件的列表。然后我们使用for each循环一个一个地处理它们。 处理完所有事件后，我们必须调用reset API 再次将 watch key 入队。 4. 目录监视示例 由于我们在上一小节中介绍了WatchService API 及其内部工作原理以及我们如何使用它，现在我们可以继续看一个完整且实用的示例。 出于可移植性的原因，我们将观察用户主目录中的活动，该目录应该在所有现代操作系统上都可用。 该代码仅包含几行代码，因此我们将其保留在 main 方法中： public class DirectoryWatcherExample { public static void main(String[] args) { WatchService watchService = FileSystems.getDefault().newWatchService(); Path path = Paths.get(System.getProperty(\u0026#34;user.home\u0026#34;)); path.register( watchService, StandardWatchEventKinds.ENTRY_CREATE, StandardWatchEventKinds.ENTRY_DELETE, StandardWatchEventKinds.ENTRY_MODIFY); WatchKey key; while ((key = watchService.take()) != null) { for (WatchEvent\u0026lt;?\u0026gt; event : key.pollEvents()) { System.out.println( \u0026#34;Event kind:\u0026#34; + event.kind() + \u0026#34;. File affected: \u0026#34; + event.context() + \u0026#34;.\u0026#34;); } key.reset(); } } } 这就是我们真正需要做的。现在您可以运行该类以开始查看目录。 当您导航到用户主目录并执行任何文件操作活动（例如创建文件或目录、更改文件内容甚至删除文件）时，所有这些都将记录在控制台中。 例如，假设您进入用户主页，在空间中单击鼠标右键，选择 *new -\u0026gt; file创建一个新文件，然后将其命名为testFile*。然后你添加一些内容并保存。控制台的输出将如下所示： Event kind:ENTRY_CREATE. File affected: New Text Document.txt. Event kind:ENTRY_DELETE. File affected: New Text Document.txt. Event kind:ENTRY_CREATE. File affected: testFile.txt. Event kind:ENTRY_MODIFY. File affected: testFile.txt. Event kind:ENTRY_MODIFY. File affected: testFile.txt. 随意编辑路径以指向您要观看的任何目录。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_watchservice/","tags":["Java IO","Java NIO"],"title":"Java NIO2 中的 WatchService 指南"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将探讨 NIO2 的一个有趣特性*——FileVisitor*接口。 所有操作系统和一些第三方应用程序都具有文件搜索功能，用户可以在其中定义搜索条件。 这个接口是我们在 Java 应用程序中实现这样的功能所需要的。如果您需要搜索所有*.mp3文件，查找并删除.class*文件或查找所有上个月没有访问过的文件，那么这个界面就是您所需要的。 我们实现此功能所需的所有类都捆绑在一个包中： import java.nio.file.*; 2. FileVisitor 的工作原理 使用FileVisitor接口，您可以将文件树遍历到任何深度，并对在任何分支上找到的文件或目录执行任何操作。 FileVisitor接口的典型实现如下所示： public class FileVisitorImpl implements FileVisitor\u0026lt;Path\u0026gt; { @Override public FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs) { return null; } @Override public FileVisitResult visitFile( Path file, BasicFileAttributes attrs) { return null; } @Override public FileVisitResult visitFileFailed( Path file, IOException exc) { return null; } @Override public FileVisitResult postVisitDirectory( Path dir, IOException exc) { return null; } } 这四种接口方法允许我们在遍历过程中的关键点指定所需的行为：分别是访问目录之前、访问文件时、发生故障时和访问目录之后。 每个阶段的返回值都是FileVisitResult类型并控制遍历的流程。也许您想遍历文件树以查找特定目录并在找到时终止进程，或者您想跳过特定目录或文件。 FileVisitResult是**FileVisitor接口方法的四个可能返回值的枚举：  FileVisitResult.CONTINUE - 表示文件树遍历应该在返回它的方法退出后继续 FileVisitResult.TERMINATE – 停止文件树遍历并且不再访问目录或文件 FileVisitResult.SKIP_SUBTREE – 此结果仅在从preVisitDirectory API返回时才有意义，在其他地方，它的工作方式类似于CONTINUE。它表示应跳过当前目录及其所有子目录 FileVisitResult.SKIP_SIBLINGS – 表示应该继续遍历而不访问当前文件或目录的同级。如果在preVisitDirectory阶段调用，那么即使是当前目录也会被跳过并且不会调用postVisitDirectory  最后，必须有一种方法来触发遍历过程，可能是当用户在定义搜索条件后从图形用户界面单击*搜索按钮时。*这是最简单的部分。 我们只需要调用Files类的静态**walkFileTree API并将Path类的实例传递给它，该实例表示遍历的起点，然后是FileVisitor的实例： Path startingDir = Paths.get(\u0026#34;pathToDir\u0026#34;); FileVisitorImpl visitor = new FileVisitorImpl(); Files.walkFileTree(startingDir, visitor); 3. 文件搜索示例 在本节中，我们将使用FileVisitor接口实现一个文件搜索应用程序。我们希望用户可以指定完整的文件名以及扩展名和要查看的起始目录。 当我们找到文件时，我们会在屏幕上打印一条成功消息，当搜索整个文件树但没有找到该文件时，我们还会打印一条相应的失败消息。 3.1 类 我们将调用这个类FileSearchExample.java： public class FileSearchExample implements FileVisitor\u0026lt;Path\u0026gt; { private String fileName; private Path startDir; // standard constructors } 我们还没有实现接口方法。请注意，我们创建了一个构造函数，它获取要搜索的文件的名称和开始搜索的路径。我们将仅使用起始路径作为基本情况来得出未找到该文件的结论。 在下面的小节中，我们将实现每个接口方法并讨论它在这个特定示例应用程序中的作用。 3.2. preVisitDirectory API 让我们从实现preVisitDirectory API 开始： @Override public FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs) { return CONTINUE; } 正如我们之前所说，每次进程在树中遇到新目录时都会调用此 API。它的返回值根据我们的决定决定接下来会发生什么。这是我们将跳过特定目录并将它们从搜索样本空间中删除的点。 让我们选择不区分任何目录，只搜索所有目录。 3.3. visitFile API 接下来，我们将实现visitFile API。这是主要动作发生的地方。每次遇到文件时都会调用此 API。我们利用这一点来检查文件属性并与我们的标准进行比较并返回适当的结果： @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) { String fileName = file.getFileName().toString(); if (FILE_NAME.equals(fileName)) { System.out.println(\u0026#34;File found: \u0026#34; + file.toString()); return TERMINATE; } return CONTINUE; } 在我们的例子中，我们只检查正在访问的文件的名称，以了解它是否是用户正在搜索的文件。如果名称匹配，我们会打印一条成功消息并终止该过程。 但是，在这里可以做很多事情，尤其是在阅读了文件属性部分之后。您可以检查创建时间、上次修改时间或上次访问时间或attrs参数中可用的几个属性并做出相应决定。 3.4. visitFileFailed API _ 接下来，我们将实现visitFileFailed API。当 JVM 无法访问特定文件时调用此 API。也许它已被另一个应用程序锁定，或者它可能只是一个权限问题： @Override public FileVisitResult visitFileFailed(Path file, IOException exc) { System.out.println(\u0026#34;Failed to access file: \u0026#34; + file.toString()); return CONTINUE; } 我们只需记录一条失败消息并继续遍历目录树的其余部分。在图形应用程序中，您可以选择询问用户是否继续使用对话框，或者只是在某处记录消息并编译报告以供以后使用。 3.5. postVisitDirectory API 最后，我们将实现postVisitDirectory API。每次完全遍历目录时都会调用此 API： @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc){ boolean finishedSearch = Files.isSameFile(dir, START_DIR); if (finishedSearch) { System.out.println(\u0026#34;File:\u0026#34; + FILE_NAME + \u0026#34; not found\u0026#34;); return TERMINATE; } return CONTINUE; } 我们使用Files.isSameFile API 来检查刚刚遍历的目录是否是我们开始遍历的目录。如果返回值为true，则表示搜索已完成，尚未找到该文件。所以我们用失败消息终止进程。 但是，如果返回值为false，则意味着我们刚刚完成了对子目录的遍历，并且仍有可能在其他子目录中找到该文件。所以我们继续遍历。 我们现在可以添加我们的 main 方法来执行FileSearchExample应用程序： public static void main(String[] args) { Path startingDir = Paths.get(\u0026#34;C:/Users/user/Desktop\u0026#34;); String fileToSearch = \u0026#34;hibernate-guide.txt\u0026#34; FileSearchExample crawler = new FileSearchExample( fileToSearch, startingDir); Files.walkFileTree(startingDir, crawler); } 您可以通过更改startingDir和fileToSearch变量的值来玩转这个示例。当fileToSearch存在于startingDir或其任何子目录中时，您将收到一条成功消息，否则将收到一条失败消息。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_file_visitor/","tags":["Java IO","Java NIO"],"title":"NIO2 FileVisitor 指南"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将探讨 Java 7 NIO.2 文件系统 API 的高级特性之一——特别是文件属性 API。 如果您想先深入了解这些基础部分，我们之前已经介绍了文件和路径API 。 处理文件系统操作所需的所有文件都捆绑在java.nio.file 包中： import java.nio.file.*; 2. 基本文件属性 让我们从所有文件系统共有的基本属性的高级视图开始——由BasicFileAttributeView提供——它存储所有必需的和可选的可见文件属性。 我们可以通过创建 HOME 路径并获取它的基本属性视图来探索当前机器上用户 home 位置的基本属性： String HOME = System.getProperty(\u0026#34;user.home\u0026#34;); Path home = Paths.get(HOME); BasicFileAttributeView basicView = Files.getFileAttributeView(home, BasicFileAttributeView.class); 经过上述步骤，我们现在可以读取一次批量操作中指向的路径的所有属性： BasicFileAttributes basicAttribs = basicView.readAttributes(); 我们现在可以探索我们可以在应用程序中实际使用的不同常见属性，尤其是在条件语句中。 我们可以从它的基本属性容器中查询文件的大小： @Test public void givenPath_whenGetsFileSize_thenCorrect() { long size = basicAttribs.size(); assertTrue(size \u0026gt; 0); } 我们还可以检查它是否是一个目录： @Test public void givenPath_whenChecksIfDirectory_thenCorrect() { boolean isDir = basicAttribs.isDirectory(); assertTrue(isDir); } 或常规文件： @Test public void givenPath_whenChecksIfFile_thenCorrect() { boolean isFile = basicAttribs.isRegularFile(); assertFalse(isFile); } 使用 Java NIO.2，我们现在能够处理文件系统中的符号链接或软链接。这些是我们通常称为快捷方式的文件或目录。 检查文件是否为符号链接： @Test public void givenPath_whenChecksIfSymLink_thenCorrect() { boolean isSymLink = basicAttribs.isSymbolicLink(); assertFalse(isSymLink); } 在极少数情况下，我们可以调用isOther API 来检查文件是否不属于常规文件、目录或符号链接的常见类别： @Test public void givenPath_whenChecksIfOther_thenCorrect() { boolean isOther = basicAttribs.isOther(); assertFalse(isOther); } 要获取文件的创建时间： FileTime created = basicAttribs.creationTime(); 获取最后修改时间： FileTime modified = basicAttribs.lastModifiedTime(); 并获得最后一次访问时间： FileTime accessed = basicAttribs.lastAccessTime(); 以上所有示例都返回一个FileTime对象。这是一个比单纯的时间戳更有用的抽象。 例如，我们可以轻松地比较两个文件时间，以了解哪个事件发生在另一个之前或之后： @Test public void givenFileTimes_whenComparesThem_ThenCorrect() { FileTime created = basicAttribs.creationTime(); FileTime modified = basicAttribs.lastModifiedTime(); FileTime accessed = basicAttribs.lastAccessTime(); assertTrue(0 \u0026gt;= created.compareTo(accessed)); assertTrue(0 \u0026lt;= modified.compareTo(created)); assertTrue(0 == created.compareTo(created)); } compareTo API的工作方式与 Java 中的其他可比较项相同。如果它被调用的对象小于参数，它会返回一个负值；在我们的例子中，创建时间肯定比第一个断言中的访问时间早。 在第二个断言中，我们得到一个正整数值，因为修改只能在创建事件之后进行。最后，当被比较的时间相等时，它返回 0。 当我们有一个 FileTime 对象时，我们可以根据需要将其转换为大多数其他单位；天、小时、分钟、秒、毫秒等。我们通过调用适当的 API 来做到这一点： accessed.to(TimeUnit.SECONDS); accessed.to(TimeUnit.HOURS); accessed.toMillis(); 我们也可以通过调用其toString API来打印人类可读的文件时间形式： accessed.toString(); 以 ISO 时间格式打印一些有用的东西： 2016-11-24T07:52:53.376Z 我们还可以通过调用setTimes(modified, access, created) API 来更改视图的时间属性。我们在我们想要更改的地方传入新的FileTime对象，或者在我们不想更改的地方传入 null。 要将上次访问时间更改为未来一分钟，我们将按照以下步骤操作： FileTime newAccessTime = FileTime.fromMillis( basicAttribs.lastAccessTime().toMillis() + 60000); basicView.setTimes(null, newAccessTime , null); 从机器上运行并使用文件系统的任何其他应用程序可以看出，此更改将持续存在于实际文件中。 3. 文件空间属性 当您在 Windows、Linux 或 Mac 上打开我的计算机时，通常可以看到有关您的存储驱动器的空间信息的图形分析。 Java NIO.2 使这种高级功能变得非常容易。它与底层文件系统交互以检索此信息，而我们只需调用简单的 API。 我们可以使用FileStore类来检查存储驱动器并获取重要信息，例如它的大小、已使用的空间量以及未使用的空间量。 要获取文件系统中任意文件位置的FileStore实例，我们使用**Files类的getFileStore API ： Path file = Paths.get(\u0026#34;file\u0026#34;); FileStore store = Files.getFileStore(file); 这个FileStore实例专门表示指定文件所在的文件存储，而不是文件本身。要获得总空间： long total = store.getTotalSpace(); 要获得已用空间： long used = store.getTotalSpace() - store.getUnallocatedSpace(); 我们不太可能采用这种方法而不是下一种方法。 更常见的是，我们可能会获得有关所有文件存储的存储信息。为了在程序中模拟我的计算机的图形驱动器空间信息，我们可以使用FileSystem类来枚举文件存储： Iterable\u0026lt;FileStore\u0026gt; fileStores = FileSystems.getDefault().getFileStores(); 然后，我们可以遍历返回的值并对信息做任何我们需要做的事情，例如更新图形用户界面： for (FileStore fileStore : fileStores) { long totalSpace = fileStore.getTotalSpace(); long unAllocated = fileStore.getUnallocatedSpace(); long usable = fileStore.getUsableSpace(); } 请注意，所有返回值都以字节为单位。我们可以转换为合适的单位以及使用基本算术计算其他信息，例如已用空间。 未分配空间和可用空间之间的区别在于JVM 的可访问性。 可用空间是 JVM 可用的空间，而未分配空间是底层文件系统看到的可用空间。因此，可用空间有时可能小于未分配空间。 4. 文件所有者属性 要检查文件所有权信息，我们使用FileOwnerAttributeView接口。它为我们提供了所有权信息的高级视图。 我们可以像这样创建一个FileOwnerAttributeView对象： Path path = Paths.get(HOME); FileOwnerAttributeView ownerView = Files.getFileAttributeView( attribPath, FileOwnerAttributeView.class); 从上面的视图中获取文件的所有者： UserPrincipal owner = ownerView.getOwner(); 除了为其他任意目的获取所有者的名称之外，我们实际上无法以编程方式对上述对象做任何事情： String ownerName = owner.toString(); 5. 用户定义的文件属性 在某些情况下，文件系统中定义的文件属性不足以满足您的需求。如果您遇到这种情况并需要在文件上设置自己的属性，那么UserDefinedFileAttributeView接口将派上用场： Path path = Paths.get(\u0026#34;somefile\u0026#34;); UserDefinedFileAttributeView userDefView = Files.getFileAttributeView( attribPath, UserDefinedFileAttributeView.class); 要检索已为上述视图表示的文件定义的用户定义属性列表： List\u0026lt;String\u0026gt; attribList = userDefView.list(); 要在文件上设置用户定义的属性，我们使用以下成语： String name = \u0026#34;attrName\u0026#34;; String value = \u0026#34;attrValue\u0026#34;; userDefView.write(name, Charset.defaultCharset().encode(value)); 当您需要访问用户定义的属性时，您可以遍历视图返回的属性列表并使用以下习惯用法检查它们： ByteBuffer attrValue = ByteBuffer.allocate(userView.size(attrName)); userDefView.read(attribName, attribValue); attrValue.flip(); String attrValue = Charset.defaultCharset().decode(attrValue).toString(); 要从文件中删除用户定义的属性，我们只需调用视图的删除 API： userDefView.delete(attrName); \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_file_attribute/","tags":["Java IO","Java NIO"],"title":"NIO2 文件属性 API 指南"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将演示如何使用 Java 7 NIO.2 通道 API 构建简单的服务器及其客户端。 我们将看看AsynchronousServerSocketChannel和AsynchronousSocketChannel类，它们是分别用于实现服务器和客户端的关键类。 如果您是 NIO.2 通道 API 的新手，我们在此站点上有一篇介绍性文章。您可以通过以下链接阅读它。 使用 NIO.2 通道 API 所需的所有类都捆绑在java.nio.channels包中： import java.nio.channels.*; 2. 有Future的服务器 AsynchronousServerSocketChannel的实例是通过调用其类的静态开放 API 来创建的： AsynchronousServerSocketChannel server = AsynchronousServerSocketChannel.open(); 一个新创建的异步服务器套接字通道已打开但尚未绑定，因此我们必须将其绑定到本地地址并可选地选择一个端口： server.bind(new InetSocketAddress(\u0026#34;127.0.0.1\u0026#34;, 4555)); 我们也可以传入 null 以便它使用本地地址并绑定到任意端口： server.bind(null); 绑定后，accept API 用于启动对通道套接字的连接的接受： Future\u0026lt;AsynchronousSocketChannel\u0026gt; acceptFuture = server.accept(); 与异步通道操作一样，上述调用立即返回并继续执行。 接下来，我们可以使用get API 来查询来自Future对象的响应： AsynchronousSocketChannel worker = future.get(); 如有必要，此调用将阻塞以等待来自客户端的连接请求。或者，如果我们不想永远等待，我们可以指定超时： AsynchronousSocketChannel worker = acceptFuture.get(10, TimeUnit.SECONDS); 在上述调用返回并且操作成功后，我们可以创建一个循环，在其中我们侦听传入的消息并将它们回显给客户端。 让我们创建一个名为runServer的方法，在该方法中我们将等待并处理任何传入的消息： public void runServer() { clientChannel = acceptResult.get(); if ((clientChannel != null) \u0026amp;\u0026amp; (clientChannel.isOpen())) { while (true) { ByteBuffer buffer = ByteBuffer.allocate(32); Future\u0026lt;Integer\u0026gt; readResult = clientChannel.read(buffer); // perform other computations  readResult.get(); buffer.flip(); Future\u0026lt;Integer\u0026gt; writeResult = clientChannel.write(buffer); // perform other computations  writeResult.get(); buffer.clear(); } clientChannel.close(); serverChannel.close(); } } 在循环内部，我们所做的只是根据操作创建一个用于读取和写入的缓冲区。 然后，每次我们进行读取或写入时，我们都可以继续执行任何其他代码，当我们准备好处理结果时，我们调用Future对象的get() API 。 要启动服务器，我们调用它的构造函数，然后调用main中的**runServer方法： public static void main(String[] args) { AsyncEchoServer server = new AsyncEchoServer(); server.runServer(); } 3. 带有CompletionHandler的服务器 在本节中，我们将看到如何使用CompletionHandler方法而不是Future方法来实现相同的服务器。 在构造函数中，我们创建了一个AsynchronousServerSocketChannel并将其绑定到本地地址，就像我们之前所做的那样： serverChannel = AsynchronousServerSocketChannel.open(); InetSocketAddress hostAddress = new InetSocketAddress(\u0026#34;localhost\u0026#34;, 4999); serverChannel.bind(hostAddress); 接下来，仍然在构造函数内部，我们创建一个 while 循环，在该循环中我们接受来自客户端的任何传入连接。此 while 循环严格用于防止服务器在与客户端建立连接之前退出。 为了防止循环无休止地运行，我们在其末尾调用*System.in.read()*来阻止执行，直到从标准输入流中读取传入连接： while (true) { serverChannel.accept( null, new CompletionHandler\u0026lt;AsynchronousSocketChannel,Object\u0026gt;() { @Override public void completed( AsynchronousSocketChannel result, Object attachment) { if (serverChannel.isOpen()){ serverChannel.accept(null, this); } clientChannel = result; if ((clientChannel != null) \u0026amp;\u0026amp; (clientChannel.isOpen())) { ReadWriteHandler handler = new ReadWriteHandler(); ByteBuffer buffer = ByteBuffer.allocate(32); Map\u0026lt;String, Object\u0026gt; readInfo = new HashMap\u0026lt;\u0026gt;(); readInfo.put(\u0026#34;action\u0026#34;, \u0026#34;read\u0026#34;); readInfo.put(\u0026#34;buffer\u0026#34;, buffer); clientChannel.read(buffer, readInfo, handler); } } @Override public void failed(Throwable exc, Object attachment) { // process error  } }); System.in.read(); } 当建立连接时，调用accept操作的CompletionHandler中的**完成回调方法。 它的返回类型是AsynchronousSocketChannel的一个实例。如果服务器套接字通道仍然打开，我们再次调用接受API 以准备另一个传入连接，同时重用相同的处理程序。 接下来，我们将返回的套接字通道分配给一个全局实例。然后我们检查它是否不为空，并且在对其执行操作之前它是打开的。 我们可以开始读取和写入操作的点是在接受操作的处理程序的完成回调 API 中。此步骤取代了之前我们使用get API 轮询通道的方法。 请注意，除非我们明确关闭它，否则在建立连接后服务器将不再退出。 还要注意，我们创建了一个单独的内部类来处理读写操作；读写处理程序。此时，我们将看到附件对象如何派上用场。 首先，让我们看一下ReadWriteHandler类： class ReadWriteHandler implements CompletionHandler\u0026lt;Integer, Map\u0026lt;String, Object\u0026gt;\u0026gt; { @Override public void completed( Integer result, Map\u0026lt;String, Object\u0026gt; attachment) { Map\u0026lt;String, Object\u0026gt; actionInfo = attachment; String action = (String) actionInfo.get(\u0026#34;action\u0026#34;); if (\u0026#34;read\u0026#34;.equals(action)) { ByteBuffer buffer = (ByteBuffer) actionInfo.get(\u0026#34;buffer\u0026#34;); buffer.flip(); actionInfo.put(\u0026#34;action\u0026#34;, \u0026#34;write\u0026#34;); clientChannel.write(buffer, actionInfo, this); buffer.clear(); } else if (\u0026#34;write\u0026#34;.equals(action)) { ByteBuffer buffer = ByteBuffer.allocate(32); actionInfo.put(\u0026#34;action\u0026#34;, \u0026#34;read\u0026#34;); actionInfo.put(\u0026#34;buffer\u0026#34;, buffer); clientChannel.read(buffer, actionInfo, this); } } @Override public void failed(Throwable exc, Map\u0026lt;String, Object\u0026gt; attachment) { //  } } ReadWriteHandler类中附件的通用类型是映射。我们特别需要通过它传递两个重要参数——操作（动作）的类型和缓冲区。 接下来，我们将看到如何使用这些参数。 我们执行的第一个操作是读取，因为这是一个仅响应客户端消息的回显服务器。在ReadWriteHandler的完成回调方法中，我们检索附加的数据并决定相应地做什么。 如果是读操作已经完成，我们检索缓冲区，更改附件的动作参数并立即执行写操作以将消息回显给客户端。 如果是刚刚完成的写入操作，我们再次调用**读取API 以准备服务器接收另一条传入消息。 4. 客户 设置服务器后，我们现在可以通过调用AsyncronousSocketChannel类上的开放API 来设置客户端。此调用创建客户端套接字通道的新实例，然后我们使用它来建立与服务器的连接： AsynchronousSocketChannel client = AsynchronousSocketChannel.open(); InetSocketAddress hostAddress = new InetSocketAddress(\u0026#34;localhost\u0026#34;, 4999) Future\u0026lt;Void\u0026gt; future = client.connect(hostAddress); 连接操作成功时不返回任何内容。但是，我们仍然可以使用Future对象来监控异步操作的状态。 让我们调用get API 来等待连接： future.get() 在这一步之后，我们可以开始向服务器发送消息并接收相同的回声。sendMessage方法如下所示： public String sendMessage(String message) { byte[] byteMsg = new String(message).getBytes(); ByteBuffer buffer = ByteBuffer.wrap(byteMsg); Future\u0026lt;Integer\u0026gt; writeResult = client.write(buffer); // do some computation  writeResult.get(); buffer.flip(); Future\u0026lt;Integer\u0026gt; readResult = client.read(buffer); // do some computation  readResult.get(); String echo = new String(buffer.array()).trim(); buffer.clear(); return echo; } 5. 测试 为了确认我们的服务器和客户端应用程序按预期执行，我们可以使用测试： @Test public void givenServerClient_whenServerEchosMessage_thenCorrect() { String resp1 = client.sendMessage(\u0026#34;hello\u0026#34;); String resp2 = client.sendMessage(\u0026#34;world\u0026#34;); assertEquals(\u0026#34;hello\u0026#34;, resp1); assertEquals(\u0026#34;world\u0026#34;, resp2); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_async_socket_channel/","tags":["Java IO","Java NIO"],"title":"NIO2 异步套接字通道指南"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将探讨 Java 7 中新 I/O (NIO2) 的关键附加 API 之一，即异步文件通道 API。 如果您是一般异步通道 API 的新手，我们在此站点上有一篇介绍性文章，您可以在继续之前点击此链接阅读该文章。 您还可以阅读更多关于 NIO2文件操作和路径操作的信息——理解这些将使本文更容易理解。 要在我们的项目中使用 NIO2 异步文件通道，我们必须导入java.nio.channels包，因为它捆绑了所有必需的类： import java.nio.channels.*; 2. AsynchronousFileChannel 在本节中，我们将探讨如何使用使我们能够对文件执行异步操作的主类AsynchronousFileChannel类。要创建它的实例，我们调用静态open方法： Path filePath = Paths.get(\u0026#34;/path/to/file\u0026#34;); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( filePath, READ, WRITE, CREATE, DELETE_ON_CLOSE); 所有枚举值都来自StandardOpenOption。 open API 的第一个参数是表示文件位置的Path对象。要了解有关 NIO2 中路径操作的更多信息，请点击此链接。其他参数组成了一组指定选项，这些选项应该可用于返回的文件通道。 我们创建的异步文件通道可用于对文件执行所有已知操作。要仅执行操作的子集，我们将仅指定这些操作的选项。例如，只阅读： Path filePath = Paths.get(\u0026#34;/path/to/file\u0026#34;); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( filePath, StandardOpenOption.READ); 3. 从文件中读取 就像 NIO2 中的所有异步操作一样，读取文件内容可以通过两种方式完成。使用Future和使用CompletionHandler。在每种情况下，我们都使用返回通道的readAPI。 在 maven 的测试资源文件夹中或在源目录中，如果不使用 maven，让我们创建一个名为file.txt的文件，其开头只有文本abcdefghijk 。我们现在将演示如何阅读此内容。 3.1 Future的方法 首先，我们将看到如何使用Future类异步读取文件： @Test public void givenFilePath_whenReadsContentWithFuture_thenCorrect() { Path path = Paths.get( URI.create( this.getClass().getResource(\u0026#34;/file.txt\u0026#34;).toString())); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( path, StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(1024); Future\u0026lt;Integer\u0026gt; operation = fileChannel.read(buffer, 0); // run other code as operation continues in background  operation.get(); String fileContent = new String(buffer.array()).trim(); buffer.clear(); assertEquals(fileContent, \u0026#34;abcdefghijk\u0026#34;); } 在上面的代码中，在创建了一个文件通道之后，我们使用了read API——它接受一个ByteBuffer来存储从通道中读取的内容作为它的第一个参数。 第二个参数是一个 long 指示文件中开始读取的位置。 无论文件是否已被读取，该方法都会立即返回。 接下来，我们可以在后台继续操作时执行任何其他代码。当我们执行完其他代码时，我们可以调用get() API，如果我们正在执行其他代码时操作已经完成，它会立即返回，否则它会阻塞直到操作完成。 我们的断言确实证明文件中的内容已被读取。 如果我们将readAPI 调用中的位置参数从零更改为其他值，我们也会看到效果。例如，字符串abcdefghijk中的第七个字符是g。因此，将 position 参数更改为 7 会导致缓冲区包含字符串ghijk。 3.2. CompletionHandler方法 接下来，我们将看到如何使用CompletionHandler实例读取文件的内容： @Test public void givenPath_whenReadsContentWithCompletionHandler_thenCorrect() { Path path = Paths.get( URI.create( this.getClass().getResource(\u0026#34;/file.txt\u0026#34;).toString())); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(1024); fileChannel.read( buffer, 0, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override public void completed(Integer result, ByteBuffer attachment) { // result is number of bytes read  // attachment is the buffer containing content  } @Override public void failed(Throwable exc, ByteBuffer attachment) { } }); } 在上面的代码中，我们使用了读取API 的第二个变体。它仍然将ByteBuffer和读取操作的开始位置分别作为第一个和第二个参数。第三个参数是CompletionHandler实例。 完成处理程序的第一个通用类型是操作的返回类型，在这种情况下，一个表示读取的字节数的整数。 第二个是附件的类型。我们选择附加缓冲区，这样当读取完成时，我们可以在完成的回调 API 中使用文件的内容。 从语义上讲，这不是一个真正有效的单元测试，因为我们不能在完成的回调方法中进行断言。然而，我们这样做是为了保持一致性，并且因为我们希望我们的代码尽可能地复制粘贴运行。 4. 写入文件 Java NIO2 还允许我们对文件执行写操作。正如我们对其他操作所做的那样，我们可以通过两种方式写入文件。使用Future和使用CompletionHandler。在每种情况下，我们都使用返回通道的写入API。 可以像这样创建用于写入文件的AsynchronousFileChannel ： AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE); 4.1 特别注意事项 注意传递给openAPI 的选项。如果我们希望创建由路径表示的文件以防它尚不存在，我们还可以添加另一个选项StandardOpenOption.CREATE 。另一个常见选项是StandardOpenOption.APPEND，它不会覆盖文件中的现有内容。 我们将使用以下行来创建我们的文件通道用于测试目的： AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( path, WRITE, CREATE, DELETE_ON_CLOSE); 这样，我们将提供任意路径并确保创建文件。测试退出后，创建的文件将被删除。为确保创建的文件在测试退出后不被删除，您可以删除最后一个选项。 要运行断言，我们需要在写入文件后尽可能读取文件内容。让我们将读取的逻辑隐藏在一个单独的方法中以避免冗余： public static String readContent(Path file) { AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( file, StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(1024); Future\u0026lt;Integer\u0026gt; operation = fileChannel.read(buffer, 0); // run other code as operation continues in background  operation.get(); String fileContent = new String(buffer.array()).trim(); buffer.clear(); return fileContent; } 4.2. Future的方法 使用Future类异步写入文件： @Test public void givenPathAndContent_whenWritesToFileWithFuture_thenCorrect() { String fileName = UUID.randomUUID().toString(); Path path = Paths.get(fileName); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( path, WRITE, CREATE, DELETE_ON_CLOSE); ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put(\u0026#34;hello world\u0026#34;.getBytes()); buffer.flip(); Future\u0026lt;Integer\u0026gt; operation = fileChannel.write(buffer, 0); buffer.clear(); //run other code as operation continues in background  operation.get(); String content = readContent(path); assertEquals(\u0026#34;hello world\u0026#34;, content); } 让我们检查一下上面代码中发生了什么。我们创建一个随机文件名并使用它来获取一个Path对象。我们使用此路径打开带有前面提到的选项的异步文件通道。 然后，我们将要写入文件的内容放入缓冲区并执行write。我们使用我们的辅助方法来读取文件的内容，并确实确认它是我们所期望的。 4.3. CompletionHandler方法 我们还可以使用完成处理程序，这样我们就不必在 while 循环中等待操作完成： @Test public void givenPathAndContent_whenWritesToFileWithHandler_thenCorrect() { String fileName = UUID.randomUUID().toString(); Path path = Paths.get(fileName); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( path, WRITE, CREATE, DELETE_ON_CLOSE); ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put(\u0026#34;hello world\u0026#34;.getBytes()); buffer.flip(); fileChannel.write( buffer, 0, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override public void completed(Integer result, ByteBuffer attachment) { // result is number of bytes written  // attachment is the buffer  } @Override public void failed(Throwable exc, ByteBuffer attachment) { } }); } 这次我们调用 write API 时，唯一的新东西是第三个参数，我们在其中传递了CompletionHandler类型的匿名内部类。 当操作完成时，类调用它的完成方法，我们可以在其中定义应该发生的事情。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_async_file_channel/","tags":["Java IO","Java NIO"],"title":"NIO2 异步文件通道指南"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将探讨 Java NIO 的Selector组件的介绍部分。 选择器提供了一种机制，用于监视一个或多个 NIO 通道并识别一个或多个何时可用于数据传输。 这样，单个线程可用于管理多个通道，从而管理多个网络连接。 2. 为什么使用选择器？ 使用选择器，我们可以使用一个线程而不是多个线程来管理多个通道。线程之间的上下文切换对于操作系统来说代价高昂，此外，每个线程都会占用内存。 因此，我们使用的线程越少越好。但是，重要的是要记住，现代操作系统和 CPU 在多任务处理方面不断进步，因此多线程的开销会随着时间的推移而不断减少。 在这里，我们将讨论如何使用选择器在单个线程中处理多个通道。 另请注意，选择器不仅可以帮助您读取数据；还可以帮助您读取数据。他们还可以侦听传入的网络连接并通过慢速通道写入数据。 3. 设置 要使用选择器，我们不需要任何特殊设置。我们需要的所有类都在核心java.nio包中，我们只需要导入我们需要的。 之后，我们可以使用选择器对象注册多个通道。当任何通道上发生 I/O 活动时，选择器会通知我们。这就是我们可以在单个线程上从大量数据源中读取数据的方式。 我们向选择器注册的任何通道都必须是SelectableChannel的子类。这些是一种特殊类型的通道，可以置于非阻塞模式。 4. 创建Selector 可以通过调用Selector类的静态open方法来创建选择器，该方法将使用系统的默认选择器提供程序来创建新的选择器： Selector selector = Selector.open(); 5. 注册可选频道 为了让选择器监控任何通道，我们必须向选择器注册这些通道。我们通过调用可选通道的注册方法来做到这一点。 但是在使用选择器注册通道之前，它必须处于非阻塞模式： channel.configureBlocking(false); SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 这意味着我们不能将FileChannel与选择器一起使用，因为它们不能像我们使用套接字通道那样切换到非阻塞模式。 第一个参数是我们之前创建的Selector对象，第二个参数定义了一个兴趣集**，**这意味着我们有兴趣通过选择器在受监控的通道中监听哪些事件。 我们可以监听四种不同的事件，每一种都由SelectionKey类中的一个常量表示：  连接-当客户端尝试连接到服务器时。由SelectionKey.OP_CONNECT表示 接受-当服务器接受来自客户端的连接时。由SelectionKey.OP_ACCEPT表示 读取-当服务器准备好从通道读取时。由SelectionKey.OP_READ表示 写入-当服务器准备好写入通道时。由SelectionKey.OP_WRITE表示  返回的对象SelectionKey表示可选通道向选择器的注册。我们将在下一节中进一步研究它。 6. SelectionKey对象 正如我们在上一节中看到的，当我们使用选择器注册通道时，我们会得到一个SelectionKey对象。该对象保存表示通道注册的数据。 它包含一些重要的属性，我们必须很好地理解这些属性才能在通道上使用选择器。我们将在以下小节中介绍这些属性。 6.1 interestSet interestSet定义了我们希望选择器在此通道上注意的事件集。它是一个整数值；我们可以通过以下方式获取这些信息。 首先，我们有由SelectionKey的interestOps方法返回的interestSet。然后我们在前面看到的SelectionKey中有事件常量。 当我们 AND 这两个值时，我们得到一个布尔值，它告诉我们是否正在监视事件： int interestSet = selectionKey.interestOps(); boolean isInterestedInAccept = interestSet \u0026amp; SelectionKey.OP_ACCEPT; boolean isInterestedInConnect = interestSet \u0026amp; SelectionKey.OP_CONNECT; boolean isInterestedInRead = interestSet \u0026amp; SelectionKey.OP_READ; boolean isInterestedInWrite = interestSet \u0026amp; SelectionKey.OP_WRITE; 6.2. selectionKey 就绪集定义了通道准备就绪的事件集。它也是一个整数值；我们可以通过以下方式获取这些信息。 我们已经得到了SelectionKey的readyOps方法返回的就绪集。当我们像在兴趣集的情况下那样将此值与事件常量进行 AND 运算时，我们会得到一个布尔值，表示通道是否为特定值做好准备。 另一种更短的替代方法是使用SelectionKey的便捷方法来实现同样的目的： selectionKey.isAcceptable(); selectionKey.isConnectable(); selectionKey.isReadable(); selectionKey.isWriteable(); 6.3. Channel 从SelectionKey对象访问正在观看的频道非常简单。我们只是调用通道方法： Channel channel = key.channel(); 6.4. Selector 就像获取频道一样，从SelectionKey对象中获取**Selector对象非常容易： Selector selector = key.selector(); 6.5 附加对象 我们可以将对象附加到*SelectionKey。*有时我们可能想要给一个频道一个自定义 ID 或附加我们可能想要跟踪的任何类型的 Java 对象。 附加对象是一种方便的方法。以下是从SelectionKey附加和获取对象的方法： key.attach(Object); Object object = key.attachment(); 或者，我们可以选择在频道注册期间附加一个对象。我们将它作为第三个参数添加到通道的register方法中，如下所示： SelectionKey key = channel.register( selector, SelectionKey.OP_ACCEPT, object); 7. 频道键选择 到目前为止，我们已经了解了如何创建选择器、向其注册通道并检查表示通道注册到选择器的SelectionKey对象的属性。 这只是过程的一半，现在我们必须执行一个连续的过程来选择我们之前看到的就绪集。我们使用选择器的select方法进行选择，如下所示： int channels = selector.select(); 此方法会阻塞，直到至少一个通道准备好进行操作。返回的整数表示其通道已准备好进行操作的键的数量。 接下来，我们通常检索一组选定的键进行处理： Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); 我们得到的集合是SelectionKey对象，每个键代表一个已注册的通道，准备好进行操作。 在此之后，我们通常会遍历这个集合，并且对于每个键，我们获取通道并执行我们感兴趣的集合中出现的任何操作。 在通道的生命周期中，可能会多次选择它，因为它的键出现在不同事件的就绪集中。这就是为什么我们必须有一个连续的循环来在通道事件发生时捕获和处理它们。 8. 完整示例 为了巩固我们在前几节中获得的知识，我们将构建一个完整的客户端-服务器示例。 为了便于测试我们的代码，我们将构建一个回显服务器和一个回显客户端。在这种设置中，客户端连接到服务器并开始向它发送消息。服务器回显每个客户端发送的消息。 当服务器遇到特定消息时，例如end，它会将其解释为通信结束并关闭与客户端的连接。 8.1 服务器 这是我们的EchoServer.java代码： public class EchoServer { private static final String POISON_PILL = \u0026#34;POISON_PILL\u0026#34;; public static void main(String[] args) throws IOException { Selector selector = Selector.open(); ServerSocketChannel serverSocket = ServerSocketChannel.open(); serverSocket.bind(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 5454)); serverSocket.configureBlocking(false); serverSocket.register(selector, SelectionKey.OP_ACCEPT); ByteBuffer buffer = ByteBuffer.allocate(256); while (true) { selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iter = selectedKeys.iterator(); while (iter.hasNext()) { SelectionKey key = iter.next(); if (key.isAcceptable()) { register(selector, serverSocket); } if (key.isReadable()) { answerWithEcho(buffer, key); } iter.remove(); } } } private static void answerWithEcho(ByteBuffer buffer, SelectionKey key) throws IOException { SocketChannel client = (SocketChannel) key.channel(); client.read(buffer); if (new String(buffer.array()).trim().equals(POISON_PILL)) { client.close(); System.out.println(\u0026#34;Not accepting client messages anymore\u0026#34;); } else { buffer.flip(); client.write(buffer); buffer.clear(); } } private static void register(Selector selector, ServerSocketChannel serverSocket) throws IOException { SocketChannel client = serverSocket.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); } public static Process start() throws IOException, InterruptedException { String javaHome = System.getProperty(\u0026#34;java.home\u0026#34;); String javaBin = javaHome + File.separator + \u0026#34;bin\u0026#34; + File.separator + \u0026#34;java\u0026#34;; String classpath = System.getProperty(\u0026#34;java.class.path\u0026#34;); String className = EchoServer.class.getCanonicalName(); ProcessBuilder builder = new ProcessBuilder(javaBin, \u0026#34;-cp\u0026#34;, classpath, className); return builder.start(); } } 这就是正在发生的事情；我们通过调用静态open方法创建一个Selector对象。然后我们也通过调用它的静态open方法来创建一个通道，特别是一个ServerSocketChannel实例。 这是因为** ServerSocketChannel是可选择的并且适用于面向流的侦听套接字**。 然后我们将它绑定到我们选择的端口。还记得我们之前说过，在将可选通道注册到选择器之前，我们必须先将其设置为非阻塞模式。所以接下来我们这样做，然后将通道注册到选择器。 在这个阶段我们不需要这个通道的SelectionKey实例，所以我们不会记住它。 Java NIO 使用面向缓冲区的模型而不是面向流的模型。因此套接字通信通常通过写入和读取缓冲区来进行。 因此，我们创建了一个新的ByteBuffer，服务器将对其进行写入和读取。我们将其初始化为 256 字节，它只是一个任意值，取决于我们计划来回传输的数据量。 最后，我们执行选择过程。我们选择准备好的通道，检索它们的选择键，遍历键，并执行每个通道准备好的操作。 我们在无限循环中执行此操作，因为无论是否有活动，服务器通常都需要继续运行。 ServerSocketChannel可以处理的唯一操作是ACCEPT操作。当我们接受来自客户端的连接时，我们会获得一个SocketChannel对象，我们可以在该对象上进行读写。我们将其设置为非阻塞模式并将其注册为对选择器的 READ 操作。 在随后的选择之一期间，该新通道将变为就绪状态。我们检索它并将其内容读入缓冲区。作为一个回显服务器，我们必须将此内容写回客户端。 *当我们想要写入我们一直在读取的缓冲区时，我们必须调用*flip()方法。 我们最终通过调用翻转方法将缓冲区设置为写入模式并简单地对其进行写入。 定义了*start()*方法，以便在单元测试期间可以将 echo 服务器作为单独的进程启动。 8.2. 客户端 这是我们的EchoClient.java代码： public class EchoClient { private static SocketChannel client; private static ByteBuffer buffer; private static EchoClient instance; public static EchoClient start() { if (instance == null) instance = new EchoClient(); return instance; } public static void stop() throws IOException { client.close(); buffer = null; } private EchoClient() { try { client = SocketChannel.open(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 5454)); buffer = ByteBuffer.allocate(256); } catch (IOException e) { e.printStackTrace(); } } public String sendMessage(String msg) { buffer = ByteBuffer.wrap(msg.getBytes()); String response = null; try { client.write(buffer); buffer.clear(); client.read(buffer); response = new String(buffer.array()).trim(); System.out.println(\u0026#34;response=\u0026#34; + response); buffer.clear(); } catch (IOException e) { e.printStackTrace(); } return response; } } 客户端比服务器简单。 我们使用单例模式在start静态方法中实例化它。我们从此方法调用私有构造函数。 在私有构造函数中，我们在绑定服务器通道的同一端口上打开一个连接，并且仍然在同一主机上。 然后我们创建一个可以写入和读取的缓冲区。 最后，我们有一个sendMessage方法，它读取将我们传递给它的任何字符串包装到一个字节缓冲区中，该缓冲区通过通道传输到服务器。 然后我们从客户端通道中读取以获取服务器发送的消息。我们将其作为我们信息的回声返回。 8.3. 测试 在一个名为EchoTest.java的类中，我们将创建一个测试用例，它启动服务器，向服务器发送消息，并且只有在从服务器接收到相同的消息时才通过。作为最后一步，测试用例在完成之前停止服务器。 我们现在可以运行测试： public class EchoTest { Process server; EchoClient client; @Before public void setup() throws IOException, InterruptedException { server = EchoServer.start(); client = EchoClient.start(); } @Test public void givenServerClient_whenServerEchosMessage_thenCorrect() { String resp1 = client.sendMessage(\u0026#34;hello\u0026#34;); String resp2 = client.sendMessage(\u0026#34;world\u0026#34;); assertEquals(\u0026#34;hello\u0026#34;, resp1); assertEquals(\u0026#34;world\u0026#34;, resp2); } @After public void teardown() throws IOException { server.destroy(); EchoClient.stop(); } } 9. selector.wakeup() 正如我们之前看到的，调用*selector.select()会阻塞当前线程，直到其中一个被监视的通道准备好运行。我们可以通过从另一个线程调用selector.wakeup()*来覆盖它。 结果是阻塞线程立即返回而不是继续等待，无论通道是否已就绪。 我们可以使用*CountDownLatch*来演示这一点并跟踪代码执行步骤： @Test public void whenWakeUpCalledOnSelector_thenBlockedThreadReturns() { Pipe pipe = Pipe.open(); Selector selector = Selector.open(); SelectableChannel channel = pipe.source(); channel.configureBlocking(false); channel.register(selector, OP_READ); List\u0026lt;String\u0026gt; invocationStepsTracker = Collections.synchronizedList(new ArrayList\u0026lt;\u0026gt;()); CountDownLatch latch = new CountDownLatch(1); new Thread(() -\u0026gt; { invocationStepsTracker.add(\u0026#34;\u0026gt;\u0026gt; Count down\u0026#34;); latch.countDown(); try { invocationStepsTracker.add(\u0026#34;\u0026gt;\u0026gt; Start select\u0026#34;); selector.select(); invocationStepsTracker.add(\u0026#34;\u0026gt;\u0026gt; End select\u0026#34;); } catch (IOException e) { e.printStackTrace(); } }).start(); invocationStepsTracker.add(\u0026#34;\u0026gt;\u0026gt; Start await\u0026#34;); latch.await(); invocationStepsTracker.add(\u0026#34;\u0026gt;\u0026gt; End await\u0026#34;); invocationStepsTracker.add(\u0026#34;\u0026gt;\u0026gt; Wakeup thread\u0026#34;); selector.wakeup(); //clean up  channel.close(); assertThat(invocationStepsTracker) .containsExactly( \u0026#34;\u0026gt;\u0026gt; Start await\u0026#34;, \u0026#34;\u0026gt;\u0026gt; Count down\u0026#34;, \u0026#34;\u0026gt;\u0026gt; Start select\u0026#34;, \u0026#34;\u0026gt;\u0026gt; End await\u0026#34;, \u0026#34;\u0026gt;\u0026gt; Wakeup thread\u0026#34;, \u0026#34;\u0026gt;\u0026gt; End select\u0026#34; ); } 在这个例子中，我们使用 Java NIO 的Pipe类来打开一个通道进行测试。我们在线程安全列表中跟踪代码执行步骤。通过分析这些步骤，我们可以看到*selector.wakeup()是如何释放被selector.select()*阻塞的线程的。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio_selector/","tags":["Java IO","Java NIO"],"title":"Java NIO 选择器简介"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将学习如何在 Java中使用新的 I/O (NIO2) Path API。 NIO2 中的Path API 构成了 Java 7 附带的主要新功能区域之一，特别是新文件系统 API 与文件 API 的子集。 2. 设置 NIO2 支持捆绑在java.nio.file包中。因此，设置您的项目以使用Path API 只需导入此包中的所有内容： import java.nio.file.*; 由于本文中的代码示例可能会在不同的环境中运行，我们先来了解一下用户的主目录： private static String HOME = System.getProperty(\u0026#34;user.home\u0026#34;); 此变量将指向任何环境中的有效位置。 Paths类是涉及文件系统路径的所有操作的主要入口点。它允许我们创建和操作文件和目录的路径。 值得注意的是，路径操作本质上主要是句法操作；它们对底层文件系统没有影响，文件系统对它们是成功还是失败也没有任何影响。这意味着将不存在的路径作为路径操作的参数传递与它是成功还是失败无关。 3. 路径操作 在本节中，我们将介绍路径操作中使用的主要语法。顾名思义，Path类是文件系统中路径的编程表示。 Path对象包含用于构造路径的文件名和目录列表，用于检查、定位和操作文件。 辅助类java.nio.file.Paths（复数形式）是创建Path对象的正式方式。它有两种从路径字符串创建路径的静态方法： Path path = Paths.get(\u0026#34;path string\u0026#34;); 无论我们在路径String中使用正斜杠还是反斜杠，都没有关系，API会根据底层文件系统的要求来解析这个参数。 从java.net.URI对象： Path path = Paths.get(URI object); 我们现在可以继续看看这些在行动。 4. 创建路径 从路径字符串创建Path对象： @Test public void givenPathString_whenCreatesPathObject_thenCorrect() { Path p = Paths.get(\u0026#34;/articles/demo\u0026#34;); assertEquals(\u0026#34;\\\\articles\\\\demo\u0026#34;, p.toString()); } 除了第一部分（在本例中为articles）之外， get API 还可以采用路径字符串部分（在本例中为articles和demo ）的可变参数参数。 如果我们提供这些部分而不是完整的路径字符串，它们将用于构造 Path 对象，我们不需要在变量参数部分中包含名称分隔符（斜杠）： @Test public void givenPathParts_whenCreatesPathObject_thenCorrect() { Path p = Paths.get(\u0026#34;/articles\u0026#34;, \u0026#34;demo\u0026#34;); assertEquals(\u0026#34;\\\\articles\\\\demo\u0026#34;, p.toString()); } 5. 检索路径信息 您可以将 Path 对象视为序列的名称元素。诸如E:\\demo\\articles\\java这样的路径字符串由三个名称元素组成，即demo、articles和java。目录结构中的最高元素将位于索引 0，在本例中为demo。 目录结构中的最低元素将位于索引*[n-1]处，其中n*是路径中名称元素的数量。这个最低的元素称为文件名，无论它是否是实际文件： @Test public void givenPath_whenRetrievesFileName_thenCorrect() { Path p = Paths.get(\u0026#34;/articles/demo/logs\u0026#34;); Path fileName = p.getFileName(); assertEquals(\u0026#34;logs\u0026#34;, fileName.toString()); } 方法可用于按索引检索单个元素： @Test public void givenPath_whenRetrievesNameByIndex_thenCorrect() { Path p = Paths.get(\u0026#34;/articles/demo/logs\u0026#34;); Path name0 = getName(0); Path name1 = getName(1); Path name2 = getName(2); assertEquals(\u0026#34;articles\u0026#34;, name0.toString()); assertEquals(\u0026#34;demo\u0026#34;, name1.toString()); assertEquals(\u0026#34;logs\u0026#34;, name2.toString()); } 或使用这些索引范围的路径的子序列： @Test public void givenPath_whenCanRetrieveSubsequenceByIndex_thenCorrect() { Path p = Paths.get(\u0026#34;/articles/demo/logs\u0026#34;); Path subPath1 = p.subpath(0,1); Path subPath2 = p.subpath(0,2); assertEquals(\u0026#34;articles\u0026#34;, subPath1.toString()); assertEquals(\u0026#34;articles\\\\demo\u0026#34;, subPath2.toString()); assertEquals(\u0026#34;articles\\\\demo\\\\logs\u0026#34;, p.subpath(0, 3).toString()); assertEquals(\u0026#34;demo\u0026#34;, p.subpath(1, 2).toString()); assertEquals(\u0026#34;demo\\\\logs\u0026#34;, p.subpath(1, 3).toString()); assertEquals(\u0026#34;logs\u0026#34;, p.subpath(2, 3).toString()); } 每个路径都与父路径相关联，如果该路径没有父路径，则为null 。路径对象的父级由路径的根组件（如果有）和路径中除文件名之外的每个元素组成。例如，/a/b/c 的父路径为 /a/b，/ a的父路径为 null： @Test public void givenPath_whenRetrievesParent_thenCorrect() { Path p1 = Paths.get(\u0026#34;/articles/demo/logs\u0026#34;); Path p2 = Paths.get(\u0026#34;/articles/demo\u0026#34;); Path p3 = Paths.get(\u0026#34;/articles\u0026#34;); Path p4 = Paths.get(\u0026#34;/\u0026#34;); Path parent1 = p1.getParent(); Path parent2 = p2.getParent(); Path parent3 = p3.getParent(); Path parent4 = p4.getParenth(); assertEquals(\u0026#34;\\\\articles\\\\demo\u0026#34;, parent1.toString()); assertEquals(\u0026#34;\\\\articles\u0026#34;, parent2.toString()); assertEquals(\u0026#34;\\\\\u0026#34;, parent3.toString()); assertEquals(null, parent4); } 我们还可以获取路径的根元素： @Test public void givenPath_whenRetrievesRoot_thenCorrect() { Path p1 = Paths.get(\u0026#34;/articles/demo/logs\u0026#34;); Path p2 = Paths.get(\u0026#34;c:/articles/demo/logs\u0026#34;); Path root1 = p1.getRoot(); Path root2 = p2.getRoot(); assertEquals(\u0026#34;\\\\\u0026#34;, root1.toString()); assertEquals(\u0026#34;c:\\\\\u0026#34;, root2.toString()); } 6. 规范化路径 许多文件系统使用*“.”* 符号表示当前目录，*“..”*表示父目录。您可能会遇到路径包含冗余目录信息的情况。 例如，考虑以下路径字符串： /demo/./articles /demo/authors/../articles /demo/articles 它们都解析到相同的位置*/demo/articles*。前两个有冗余，而最后一个没有。 规范化路径涉及删除其中的冗余。为此目的提供了Path.normalize ()操作。 这个例子现在应该是不言自明的： @Test public void givenPath_whenRemovesRedundancies_thenCorrect1() { Path p = Paths.get(\u0026#34;/home/./demo/articles\u0026#34;); Path cleanPath = p.normalize(); assertEquals(\u0026#34;\\\\home\\\\demo\\\\articles\u0026#34;, cleanPath.toString()); } 这个也是： @Test public void givenPath_whenRemovesRedundancies_thenCorrect2() { Path p = Paths.get(\u0026#34;/home/demo/../articles\u0026#34;); Path cleanPath = p.normalize(); assertEquals(\u0026#34;\\\\home\\\\articles\u0026#34;, cleanPath.toString()); } 7. 路径转换 有一些操作可以将路径转换为选定的演示格式。要将任何路径转换为可以从浏览器打开的字符串，我们使用toUri方法： @Test public void givenPath_whenConvertsToBrowseablePath_thenCorrect() { Path p = Paths.get(\u0026#34;/home/demo/articles.html\u0026#34;); URI uri = p.toUri(); assertEquals( \u0026#34;file:///E:/home/demo/articles.html\u0026#34;, uri.toString()); } 我们还可以将路径转换为其绝对表示。toAbsolutePath方法根据文件系统默认目录解析路径： @Test public void givenPath_whenConvertsToAbsolutePath_thenCorrect() { Path p = Paths.get(\u0026#34;/home/demo/articles.html\u0026#34;); Path absPath = p.toAbsolutePath(); assertEquals( \u0026#34;E:\\\\home\\\\demo\\\\articles.html\u0026#34;, absPath.toString()); } 但是，当检测到要解析的路径已经是绝对路径时，该方法按原样返回： @Test public void givenAbsolutePath_whenRetainsAsAbsolute_thenCorrect() { Path p = Paths.get(\u0026#34;E:\\\\home\\\\demo\\\\articles.html\u0026#34;); Path absPath = p.toAbsolutePath(); assertEquals( \u0026#34;E:\\\\home\\\\demo\\\\articles.html\u0026#34;, absPath.toString()); } 我们还可以通过调用toRealPath方法将任何路径转换为其实际等效路径。此方法尝试通过将其元素映射到文件系统中的实际目录和文件来解析路径。 是时候使用我们在设置部分创建的变量了，该变量指向登录用户在文件系统中的主位置： @Test public void givenExistingPath_whenGetsRealPathToFile_thenCorrect() { Path p = Paths.get(HOME); Path realPath = p.toRealPath(); assertEquals(HOME, realPath.toString()); } 上面的测试并没有真正告诉我们这个操作的行为。最明显的结果是，如果文件系统中不存在该路径，那么该操作将抛出一个IOException，继续阅读。 由于缺乏更好的方法来驱动这一点，请看下一个测试，它试图将不存在的路径转换为真实路径： @Test(expected = NoSuchFileException.class) public void givenInExistentPath_whenFailsToConvert_thenCorrect() { Path p = Paths.get(\u0026#34;E:\\\\home\\\\demo\\\\articles.html\u0026#34;); p.toRealPath(); } 当我们捕获到IOException时，测试成功。此操作引发的IOException的实际子类是NoSuchFileException。 8. 加入路径 可以使用resolve方法连接任意两条路径。 简单地说，我们可以在任何Path上调用**resolve方法，并传入部分路径作为参数。该部分路径附加到原始路径： @Test public void givenTwoPaths_whenJoinsAndResolves_thenCorrect() { Path p = Paths.get(\u0026#34;/demo/articles\u0026#34;); Path p2 = p.resolve(\u0026#34;java\u0026#34;); assertEquals(\u0026#34;\\\\demo\\\\articles\\\\java\u0026#34;, p2.toString()); } 但是，当传递给resolve方法的路径字符串不是*部分路径时；*最值得注意的是绝对路径，然后返回传入的路径： @Test public void givenAbsolutePath_whenResolutionRetainsIt_thenCorrect() { Path p = Paths.get(\u0026#34;/demo/articles\u0026#34;); Path p2 = p.resolve(\u0026#34;C:\\\\demo\\\\articles\\java\u0026#34;); assertEquals(\u0026#34;C:\\\\demo\\\\articles\\\\java\u0026#34;, p2.toString()); } 任何具有根元素的路径都会发生同样的事情。路径字符串*“java”没有根元素，而路径字符串“/java”*有根元素。因此，当您传入带有根元素的路径时，它会按原样返回： @Test public void givenPathWithRoot_whenResolutionRetainsIt_thenCorrect2() { Path p = Paths.get(\u0026#34;/demo/articles\u0026#34;); Path p2 = p.resolve(\u0026#34;/java\u0026#34;); assertEquals(\u0026#34;\\\\java\u0026#34;, p2.toString()); } 9. 相对化路径 相对化一词仅意味着在两条已知路径之间创建直接路径。例如，如果我们有一个目录*/demo并且在其中，我们还有另外两个目录，例如/demo/authors和/demo/articles*是有效路径。 相对于作者的**文章路径将被描述为*“在目录层次结构中向上移动一级，然后进入文章目录”或..\\articles：* @Test public void givenSiblingPaths_whenCreatesPathToOther_thenCorrect() { Path p1 = Paths.get(\u0026#34;articles\u0026#34;); Path p2 = Paths.get(\u0026#34;authors\u0026#34;); Path p1_rel_p2 = p1.relativize(p2); Path p2_rel_p1 = p2.relativize(p1); assertEquals(\u0026#34;..\\\\authors\u0026#34;, p1_rel_p2.toString()); assertEquals(\u0026#34;..\\\\articles\u0026#34;, p2_rel_p1.toString()); } 假设我们将文章目录移动到作者文件夹，这样它们就不再是兄弟了。以下相对化操作涉及在demo和文章之间创建路径，反之亦然： @Test public void givenNonSiblingPaths_whenCreatesPathToOther_thenCorrect() { Path p1 = Paths.get(\u0026#34;/demo\u0026#34;); Path p2 = Paths.get(\u0026#34;/demo/authors/articles\u0026#34;); Path p1_rel_p2 = p1.relativize(p2); Path p2_rel_p1 = p2.relativize(p1); assertEquals(\u0026#34;authors\\\\articles\u0026#34;, p1_rel_p2.toString()); assertEquals(\u0026#34;..\\\\..\u0026#34;, p2_rel_p1.toString()); } 10. 比较路径 Path类有一个直观的 equals 方法实现，它使我们能够比较两条路径是否相等： @Test public void givenTwoPaths_whenTestsEquality_thenCorrect() { Path p1 = Paths.get(\u0026#34;/demo/articles\u0026#34;); Path p2 = Paths.get(\u0026#34;/demo/articles\u0026#34;); Path p3 = Paths.get(\u0026#34;/demo/authors\u0026#34;); assertTrue(p1.equals(p2)); assertFalse(p1.equals(p3)); } 您还可以检查路径是否以给定字符串开头： @Test public void givenPath_whenInspectsStart_thenCorrect() { Path p1 = Paths.get(\u0026#34;/demo/articles\u0026#34;); assertTrue(p1.startsWith(\u0026#34;/demo\u0026#34;)); } 或以其他字符串结尾： @Test public void givenPath_whenInspectsEnd_thenCorrect() { Path p1 = Paths.get(\u0026#34;/demo/articles\u0026#34;); assertTrue(p1.endsWith(\u0026#34;articles\u0026#34;)); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_path/","tags":["Java IO","Java NIO"],"title":"Java NIO2 路径 API"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将重点关注 Java 平台中的新 I/O API — NIO2 — 来执行基本的文件操作。 NIO2 中的文件 API 构成了 Java 7 附带的 Java 平台的主要新功能领域之一，特别是新文件系统 API 和路径 API 的子集。 2. 设置 设置您的项目以使用文件 API 只是进行此导入的问题： import java.nio.file.*; 由于本文中的代码示例可能会在不同的环境中运行，让我们获取用户主目录的句柄，该句柄在所有操作系统中都有效： private static String HOME = System.getProperty(\u0026#34;user.home\u0026#34;); Files类是java.nio.file包的主要入口点之一。此类提供了一组丰富的 API，用于读取、写入和操作文件和目录。Files类方法适用于Path对象的实例。 3. 检查文件或目录 我们可以有一个Path实例来表示文件系统上的文件或目录。它指向的文件或目录是否存在，是否可访问，可以通过文件操作来确认。 为简单起见，每当我们使用术语文件时，除非另有明确说明，否则我们将同时指代文件和目录。 要检查文件是否存在，我们使用exists API： @Test public void givenExistentPath_whenConfirmsFileExists_thenCorrect() { Path p = Paths.get(HOME); assertTrue(Files.exists(p)); } 要检查文件是否不存在，我们使用notExists API： @Test public void givenNonexistentPath_whenConfirmsFileNotExists_thenCorrect() { Path p = Paths.get(HOME + \u0026#34;/inexistent_file.txt\u0026#34;); assertTrue(Files.notExists(p)); } 我们还可以检查文件是像myfile.txt这样的常规文件还是只是一个目录，我们使用isRegularFile API： @Test public void givenDirPath_whenConfirmsNotRegularFile_thenCorrect() { Path p = Paths.get(HOME); assertFalse(Files.isRegularFile(p)); } 还有一些静态方法可以检查文件权限。要检查文件是否可读，我们使用isReadable API： @Test public void givenExistentDirPath_whenConfirmsReadable_thenCorrect() { Path p = Paths.get(HOME); assertTrue(Files.isReadable(p)); } 要检查它是否可写，我们使用isWritable API： @Test public void givenExistentDirPath_whenConfirmsWritable_thenCorrect() { Path p = Paths.get(HOME); assertTrue(Files.isWritable(p)); } 同样，要检查它是否可执行： @Test public void givenExistentDirPath_whenConfirmsExecutable_thenCorrect() { Path p = Paths.get(HOME); assertTrue(Files.isExecutable(p)); } 当我们有两个路径时​​，我们可以检查它们是否都指向底层文件系统上的同一个文件： @Test public void givenSameFilePaths_whenConfirmsIsSame_thenCorrect() { Path p1 = Paths.get(HOME); Path p2 = Paths.get(HOME); assertTrue(Files.isSameFile(p1, p2)); } 4. 创建文件 文件系统 API 提供用于创建文件的单行操作。要创建常规文件，我们使用createFile API 并向其传递一个表示我们要创建的文件的Path对象。 路径中的所有名称元素都必须存在，除了文件名，否则，我们会得到一个IOException： @Test public void givenFilePath_whenCreatesNewFile_thenCorrect() { String fileName = \u0026#34;myfile_\u0026#34; + UUID.randomUUID().toString() + \u0026#34;.txt\u0026#34;; Path p = Paths.get(HOME + \u0026#34;/\u0026#34; + fileName); assertFalse(Files.exists(p)); Files.createFile(p); assertTrue(Files.exists(p)); } 在上面的测试中，我们首先查看路径的时候是不存在的，然后经过createFile操作后发现是存在的。 要创建目录，我们使用createDirectory API： @Test public void givenDirPath_whenCreatesNewDir_thenCorrect() { String dirName = \u0026#34;myDir_\u0026#34; + UUID.randomUUID().toString(); Path p = Paths.get(HOME + \u0026#34;/\u0026#34; + dirName); assertFalse(Files.exists(p)); Files.createDirectory(p); assertTrue(Files.exists(p)); assertFalse(Files.isRegularFile(p)); assertTrue(Files.isDirectory(p)); } 此操作要求路径中的所有名称元素都存在，如果不存在，我们也会得到一个IOException： @Test(expected = NoSuchFileException.class) public void givenDirPath_whenFailsToCreateRecursively_thenCorrect() { String dirName = \u0026#34;myDir_\u0026#34; + UUID.randomUUID().toString() + \u0026#34;/subdir\u0026#34;; Path p = Paths.get(HOME + \u0026#34;/\u0026#34; + dirName); assertFalse(Files.exists(p)); Files.createDirectory(p); } 但是，如果我们希望通过一次调用创建目录层次结构，我们使用createDirectories方法。与前面的操作不同，当它在路径中遇到任何缺少的名称元素时，它不会抛出IOException，它会递归地创建它们直到最后一个元素： @Test public void givenDirPath_whenCreatesRecursively_thenCorrect() { Path dir = Paths.get( HOME + \u0026#34;/myDir_\u0026#34; + UUID.randomUUID().toString()); Path subdir = dir.resolve(\u0026#34;subdir\u0026#34;); assertFalse(Files.exists(dir)); assertFalse(Files.exists(subdir)); Files.createDirectories(subdir); assertTrue(Files.exists(dir)); assertTrue(Files.exists(subdir)); } 5. 创建临时文件 许多应用程序在运行时会在文件系统中创建一系列临时文件。因此，大多数文件系统都有一个专用目录来存储此类应用程序生成的临时文件。 新的文件系统 API 为此提供了特定的操作。createTempFile API 执行此操作。它需要一个路径对象、一个文件前缀和一个文件后缀： @Test public void givenFilePath_whenCreatesTempFile_thenCorrect() { String prefix = \u0026#34;log_\u0026#34;; String suffix = \u0026#34;.txt\u0026#34;; Path p = Paths.get(HOME + \u0026#34;/\u0026#34;); Files.createTempFile(p, prefix, suffix); assertTrue(Files.exists(p)); } 这些参数足以满足需要此操作的要求。但是，如果需要指定文件的特定属性，还有第四个可变参数参数。 上面的测试在HOME目录中创建了一个临时文件，分别预置和附加提供的前缀和后缀字符串。我们最终会得到一个类似log_8821081429012075286.txt的文件名。长数字字符串是系统生成的。 但是，如果我们不提供前缀和后缀，则文件名将仅包含长数字字符串和默认的*.tmp*扩展名： @Test public void givenPath_whenCreatesTempFileWithDefaults_thenCorrect() { Path p = Paths.get(HOME + \u0026#34;/\u0026#34;); Files.createTempFile(p, null, null); assertTrue(Files.exists(p)); } 上面的操作创建了一个名称类似于8600179353689423985.tmp的文件。 最后，如果我们既不提供路径、前缀也不提供后缀，那么操作将始终使用默认值。创建文件的默认位置将是文件系统提供的临时文件目录： @Test public void givenNoFilePath_whenCreatesTempFileInTempDir_thenCorrect() { Path p = Files.createTempFile(null, null); assertTrue(Files.exists(p)); } 在 Windows 上，这将默认为C:\\Users\\user\\AppData\\Local\\Temp\\6100927974988978748.tmp 之类的内容。 上述所有操作都可以通过使用createTempDirectory而不是createTempFile来适应创建目录而不是常规文件。 6. 删除文件 要删除文件，我们使用删除API。为了清楚起见，以下测试首先确保文件不存在，然后创建它并确认它现在存在，最后删除它并确认它不再存在： @Test public void givenPath_whenDeletes_thenCorrect() { Path p = Paths.get(HOME + \u0026#34;/fileToDelete.txt\u0026#34;); assertFalse(Files.exists(p)); Files.createFile(p); assertTrue(Files.exists(p)); Files.delete(p); assertFalse(Files.exists(p)); } 但是，如果文件系统中不存在文件，则删除操作将失败并出现IOException： @Test(expected = NoSuchFileException.class) public void givenInexistentFile_whenDeleteFails_thenCorrect() { Path p = Paths.get(HOME + \u0026#34;/inexistentFile.txt\u0026#34;); assertFalse(Files.exists(p)); Files.delete(p); } 我们可以通过使用deleteIfExists来避免这种情况，如果文件不存在，它会静默失败。当多个线程正在执行此操作时，这一点很重要，并且我们不希望仅仅因为一个线程比当前失败的线程更早地执行该操作而发出失败消息： @Test public void givenInexistentFile_whenDeleteIfExistsWorks_thenCorrect() { Path p = Paths.get(HOME + \u0026#34;/inexistentFile.txt\u0026#34;); assertFalse(Files.exists(p)); Files.deleteIfExists(p); } 当处理目录而不是常规文件时，我们应该记住删除操作默认情况下不会递归工作。因此，如果目录不为空，它将失败并出现IOException： @Test(expected = DirectoryNotEmptyException.class) public void givenPath_whenFailsToDeleteNonEmptyDir_thenCorrect() { Path dir = Paths.get( HOME + \u0026#34;/emptyDir\u0026#34; + UUID.randomUUID().toString()); Files.createDirectory(dir); assertTrue(Files.exists(dir)); Path file = dir.resolve(\u0026#34;file.txt\u0026#34;); Files.createFile(file); Files.delete(dir); assertTrue(Files.exists(dir)); } 7. 复制文件 您可以使用复制API 复制文件或目录： @Test public void givenFilePath_whenCopiesToNewLocation_thenCorrect() { Path dir1 = Paths.get( HOME + \u0026#34;/firstdir_\u0026#34; + UUID.randomUUID().toString()); Path dir2 = Paths.get( HOME + \u0026#34;/otherdir_\u0026#34; + UUID.randomUUID().toString()); Files.createDirectory(dir1); Files.createDirectory(dir2); Path file1 = dir1.resolve(\u0026#34;filetocopy.txt\u0026#34;); Path file2 = dir2.resolve(\u0026#34;filetocopy.txt\u0026#34;); Files.createFile(file1); assertTrue(Files.exists(file1)); assertFalse(Files.exists(file2)); Files.copy(file1, file2); assertTrue(Files.exists(file2)); } 如果目标文件存在，则复制失败，除非指定了REPLACE_EXISTING选项： @Test(expected = FileAlreadyExistsException.class) public void givenPath_whenCopyFailsDueToExistingFile_thenCorrect() { Path dir1 = Paths.get( HOME + \u0026#34;/firstdir_\u0026#34; + UUID.randomUUID().toString()); Path dir2 = Paths.get( HOME + \u0026#34;/otherdir_\u0026#34; + UUID.randomUUID().toString()); Files.createDirectory(dir1); Files.createDirectory(dir2); Path file1 = dir1.resolve(\u0026#34;filetocopy.txt\u0026#34;); Path file2 = dir2.resolve(\u0026#34;filetocopy.txt\u0026#34;); Files.createFile(file1); Files.createFile(file2); assertTrue(Files.exists(file1)); assertTrue(Files.exists(file2)); Files.copy(file1, file2); Files.copy(file1, file2, StandardCopyOption.REPLACE_EXISTING); } 但是，在复制目录时，不会递归地复制内容。这意味着如果*/demo包含/articles.db和/authors.db文件，则将 /demo 复制到*新位置将创建一个空目录。 8. 移动文件 您可以使用移动API 移动文件或目录。它在大多数方面类似于复制操作。如果复制操作类似于基于 GUI 的系统中的复制和粘贴操作，那么**移动类似于剪切和粘贴操作： @Test public void givenFilePath_whenMovesToNewLocation_thenCorrect() { Path dir1 = Paths.get( HOME + \u0026#34;/firstdir_\u0026#34; + UUID.randomUUID().toString()); Path dir2 = Paths.get( HOME + \u0026#34;/otherdir_\u0026#34; + UUID.randomUUID().toString()); Files.createDirectory(dir1); Files.createDirectory(dir2); Path file1 = dir1.resolve(\u0026#34;filetocopy.txt\u0026#34;); Path file2 = dir2.resolve(\u0026#34;filetocopy.txt\u0026#34;); Files.createFile(file1); assertTrue(Files.exists(file1)); assertFalse(Files.exists(file2)); Files.move(file1, file2); assertTrue(Files.exists(file2)); assertFalse(Files.exists(file1)); } 如果目标文件存在，则移动操作将失败，除非像我们对复制操作所做的那样指定了REPLACE_EXISTING选项： @Test(expected = FileAlreadyExistsException.class) public void givenFilePath_whenMoveFailsDueToExistingFile_thenCorrect() { Path dir1 = Paths.get( HOME + \u0026#34;/firstdir_\u0026#34; + UUID.randomUUID().toString()); Path dir2 = Paths.get( HOME + \u0026#34;/otherdir_\u0026#34; + UUID.randomUUID().toString()); Files.createDirectory(dir1); Files.createDirectory(dir2); Path file1 = dir1.resolve(\u0026#34;filetocopy.txt\u0026#34;); Path file2 = dir2.resolve(\u0026#34;filetocopy.txt\u0026#34;); Files.createFile(file1); Files.createFile(file2); assertTrue(Files.exists(file1)); assertTrue(Files.exists(file2)); Files.move(file1, file2); Files.move(file1, file2, StandardCopyOption.REPLACE_EXISTING); assertTrue(Files.exists(file2)); assertFalse(Files.exists(file1)); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_file_api/","tags":["Java IO","Java NIO"],"title":"Java NIO2 文件 API 简介"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将探讨 Java 7异步通道 API中新 I/O (NIO2) 的关键附加 API 之一的基础。 这是涵盖该特定主题的系列文章中的第一篇。 异步通道 API 是对 Java 1.4 附带的早期新 I/O (NIO) API 的增强。要了解 NIO 选择器，请点击此链接。 NIO API 的另一个增强是新的文件系统 API。您也可以在此站点上阅读有关其文件操作和路径操作的更多信息。 要在我们的项目中使用 NIO2 异步通道，我们必须导入java.nio.channels包，因为其中捆绑了所需的类： import java.nio.channels.*; 2. 异步通道 API 的工作原理 异步通道 API 被引入到现有的java.nio.channels包中，简单地说——通过在类名前面加上Asynchronous一词。 一些核心类包括：AsynchronousSocketChannel、AsynchronousServerSocketChannel和AsynchronousFileChannel。 您可能已经注意到，这些类在风格上与标准 NIO 通道 API 相似。 而且，NIO 通道类可用的大多数 API 操作在新的异步版本中也可用。主要区别在于新通道允许异步执行某些操作。 启动操作时，异步通道 API 为我们提供了两种用于监视和控制挂起操作的替代方案。该操作可以返回java.util.concurrent.Future对象，或者我们可以将**java.nio.channels.CompletionHandler传递给它。 3. Future的方法 ** Future对象表示异步计算的结果。**假设我们要创建一个服务器来监听客户端连接，我们在AsynchronousServerSocketChannel上调用静态开放API，并可选择将返回的套接字通道绑定到一个地址： AsynchronousServerSocketChannel server = AsynchronousServerSocketChannel.open().bind(null); 我们传入了null以便系统可以自动分配地址。然后，我们在返回的服务器SocketChannel上调用accept方法： Future\u0026lt;AsynchronousSocketChannel\u0026gt; future = server.accept(); 当我们在旧 IO 中调用ServerSocketChannel的accept方法时，它会阻塞，直到收到来自客户端的传入连接。但是AsynchronousServerSocketChannel的accept方法会立即返回一个Future对象。 Future对象的泛型类型是操作的返回类型。在我们上面的例子中，它是AsynchronousSocketChannel但它也可以是Integer或String，这取决于操作的最终返回类型。 我们可以使用Future对象来查询操作的状态： future.isDone(); 如果底层操作已经完成，此 API 返回*true 。*请注意，在这种情况下，完成可能意味着正常终止、异常或取消。 我们还可以显式检查操作是否已取消： future.isCancelled(); 如果操作在正常完成之前被取消，它只返回true，否则返回false。取消是通过cancel方法执行的： future.cancel(true); 该调用取消了由Future对象表示的操作。该参数表示即使操作已经开始，也可以中断。操作一旦完成，就无法取消 为了检索计算结果，我们使用get方法： AsynchronousSocketChannel client= future.get(); 如果我们在操作完成之前调用这个API，它会阻塞直到完成，然后返回操作的结果。 4. CompletionHandler方法 使用 Future 处理操作的替代方法是使用CompletionHandler类的回调机制。异步通道允许指定完成处理程序来使用操作的结果： AsynchronousServerSocketChannel listener = AsynchronousServerSocketChannel.open().bind(null); listener.accept( attachment, new CompletionHandler\u0026lt;AsynchronousSocketChannel, Object\u0026gt;() { public void completed( AsynchronousSocketChannel client, Object attachment) { // do whatever with client  } public void failed(Throwable exc, Object attachment) { // handle failure  } }); 当I/O 操作成功完成时调用完成的回调 API。如果操作失败，则调用失败的回调。 这些回调方法接受其他参数——允许我们传递我们认为可能适合与操作一起标记的任何数据。第一个参数可用作回调方法的第二个参数。 最后，一个清晰的场景是——对不同的异步操作使用相同的CompletionHandler。在这种情况下，我们将受益于标记每个操作以在处理结果时提供上下文，我们将在下一节中看到这一点。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_nio2_async_channels/","tags":["Java IO","Java NIO"],"title":"Java NIO2 异步通道 API 指南"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将介绍如何在 Java 中创建自定义异常。 我们将展示如何实现用户定义的异常并将其用于已检查和未检查的异常。 2. 自定义例外的需要 Java 异常几乎涵盖了编程中必然会发生的所有一般异常。 然而，我们有时需要用我们自己的来补充这些标准例外。 这些是引入自定义异常的主要原因：  业务逻辑异常——特定于业务逻辑和工作流的异常。这些帮助应用程序用户或开发人员了解确切的问题是什么。 捕获现有 Java 异常的子集并提供特定处理  Java 异常可以检查和取消检查。在接下来的部分中，我们将介绍这两种情况。 3. 自定义检查异常 已检查异常是需要显式处理的异常。 让我们考虑一段返回文件第一行的代码： try (Scanner file = new Scanner(new File(fileName))) { if (file.hasNextLine()) return file.nextLine(); } catch(FileNotFoundException e) { // Logging, etc } 上面的代码是处理 Java 检查异常的经典方法。虽然代码抛出FileNotFoundException，但不清楚确切的原因是什么——文件不存在还是文件名无效。 要创建自定义异常，我们必须扩展java.lang.Exception类。 让我们通过创建一个名为IncorrectFileNameException的自定义检查异常来查看一个示例： public class IncorrectFileNameException extends Exception { public IncorrectFileNameException(String errorMessage) { super(errorMessage); } } 请注意，我们还必须提供一个构造函数，该构造函数将String作为错误消息并调用父类构造函数。 这就是我们定义自定义异常所需要做的一切。 接下来，让我们看看如何在示例中使用自定义异常： try (Scanner file = new Scanner(new File(fileName))) { if (file.hasNextLine()) return file.nextLine(); } catch (FileNotFoundException e) { if (!isCorrectFileName(fileName)) { throw new IncorrectFileNameException(\u0026#34;Incorrect filename : \u0026#34; + fileName ); } //... } 我们已经创建并使用了自定义异常，因此用户现在可以知道确切的异常是什么。 这够了吗？因此，我们失去了异常的根本原因。 为了解决这个问题，我们还可以在构造函数中添加一个 java.lang.Throwable 参数。这样，我们可以将根异常传递给方法调用： public IncorrectFileNameException(String errorMessage, Throwable err) { super(errorMessage, err); } 现在IncorrectFileNameException与异常的根本原因一起使用： try (Scanner file = new Scanner(new File(fileName))) { if (file.hasNextLine()) { return file.nextLine(); } } catch (FileNotFoundException err) { if (!isCorrectFileName(fileName)) { throw new IncorrectFileNameException( \u0026#34;Incorrect filename : \u0026#34; + fileName , err); } // ... } 这就是我们可以使用自定义异常 而不丢失它们发生的根本原因的方式。 4. 自定义未检查异常 在我们的同一个示例中，假设如果文件名不包含任何扩展名，我们需要一个自定义异常。 在这种情况下，我们需要一个类似于前一个的自定义未经检查的异常，因为这个错误只会在运行时检测到。 要创建自定义的未经检查的异常，我们需要扩展java.lang.RuntimeException类： public class IncorrectFileExtensionException extends RuntimeException { public IncorrectFileExtensionException(String errorMessage, Throwable err) { super(errorMessage, err); } } 这样，我们可以在示例中使用这个自定义的未检查异常： try (Scanner file = new Scanner(new File(fileName))) { if (file.hasNextLine()) { return file.nextLine(); } else { throw new IllegalArgumentException(\u0026#34;Non readable file\u0026#34;); } } catch (FileNotFoundException err) { if (!isCorrectFileName(fileName)) { throw new IncorrectFileNameException( \u0026#34;Incorrect filename : \u0026#34; + fileName , err); } //... } catch(IllegalArgumentException err) { if(!containsExtension(fileName)) { throw new IncorrectFileExtensionException( \u0026#34;Filename does not contain extension : \u0026#34; + fileName, err); } //... } \u0026#34; ","permalink":"http://itcodingman.github.io/java_new_custom_exception/","tags":["Core Java","Exception"],"title":"在 Java 中创建自定义异常"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将重点关注网络接口以及如何在 Java 中以编程方式访问它们。 简单地说，网络接口是设备与其任何网络连接之间的互连点。 在日常语言中，我们用术语网络接口卡 (NIC) 来指代它们——但它们不一定都是硬件形式。 例如，流行的 localhost IP 127.0.0.1是我们在测试 Web 和网络应用程序时经常使用的环回接口，它不是直接的硬件接口。 当然，系统通常有多个活动的网络连接，例如有线以太网、WIFI、蓝牙等。 在 Java 中，我们可以用来直接与它们交互的主要 API 是java.net.NetworkInterface类。因此，为了快速开始，让我们导入完整的包： import java.net.*; 2. 为什么要访问网络接口？ 大多数 Java 程序可能不会直接与它们交互。然而，当我们确实需要这种低级访问时，有些特殊情况。 其中最突出的是系统有多个卡，并且您希望可以自由选择特定接口来使用带有. 在这种情况下，我们通常知道名称，但不一定知道 IP 地址。 通常，当我们想要与特定服务器地址建立套接字连接时： Socket socket = new Socket(); socket.connect(new InetSocketAddress(address, port)); 这样，系统将选择一个合适的本地地址，绑定到它并通过其网络接口与服务器通信。但是，这种方法不允许我们选择自己的方法。 我们将在这里做一个假设；我们不知道地址，但我们知道名字。仅出于演示目的，假设我们希望通过环回接口进行连接，按照惯例，它的名称是lo，至少在 Linux 和 Windows 系统上，在 OSX 上它是lo0： NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); Enumeration\u0026lt;InetAddress\u0026gt; nifAddresses = nif.getInetAddresses(); Socket socket = new Socket(); socket.bind(new InetSocketAddress(nifAddresses.nextElement(), 0)); socket.connect(new InetSocketAddress(address, port)); 所以我们首先检索附加到lo的网络接口，检索附加到它的地址，创建一个套接字，将它绑定到我们在编译时甚至不知道的任何枚举地址，然后连接。 NetworkInterface对象包含一个名称和一组分配给它的 IP 地址。因此绑定到这些地址中的任何一个都将保证通过此接口进行通信。 这并没有真正说明 API 有什么特别之处。我们知道，如果我们希望我们的本地地址是 localhost，那么只要我们添加绑定代码，第一个片段就足够了。 此外，由于 localhost 有一个众所周知的地址127.0.0.1 ，我们将永远不需要完成所有这些步骤，我们可以轻松地将套接字绑定到它。 但是，在您的情况下，lo可能代表其他接口，例如蓝牙 - net1、无线网络 - net0或以太网 - eth0。在这种情况下，您在编译时不会知道 IP 地址。 3. 检索网络接口 在本节中，我们将探索用于检索可用接口的其他可用 API。在上一节中，我们只看到了其中一种方法；*getByName()*静态方法。 值得注意的是，NetworkInterface类没有任何公共构造函数，因此我们当然无法创建新实例。相反，我们将使用可用的 API 来检索一个。 到目前为止，我们看到的 API 用于按指定名称搜索网络接口： @Test public void givenName_whenReturnsNetworkInterface_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); assertNotNull(nif); } 如果没有名称，则返回null ： @Test public void givenInExistentName_whenReturnsNull_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;inexistent_name\u0026#34;); assertNull(nif); } 第二个 API 是getByInetAddress()，它也要求我们提供一个已知参数，这次我们可以提供 IP 地址： @Test public void givenIP_whenReturnsNetworkInterface_thenCorrect() { byte[] ip = new byte[] { 127, 0, 0, 1 }; NetworkInterface nif = NetworkInterface.getByInetAddress( InetAddress.getByAddress(ip)); assertNotNull(nif); } 或主机名： @Test public void givenHostName_whenReturnsNetworkInterface_thenCorrect() { NetworkInterface nif = NetworkInterface.getByInetAddress( InetAddress.getByName(\u0026#34;localhost\u0026#34;)); assertNotNull(nif); } 或者，如果您具体了解 localhost： @Test public void givenLocalHost_whenReturnsNetworkInterface_thenCorrect() { NetworkInterface nif = NetworkInterface.getByInetAddress( InetAddress.getLocalHost()); assertNotNull(nif); } 另一种选择也是显式使用环回接口： @Test public void givenLoopBack_whenReturnsNetworkInterface_thenCorrect() { NetworkInterface nif = NetworkInterface.getByInetAddress( InetAddress.getLoopbackAddress()); assertNotNull(nif); } 仅在 Java 7 之后才可用的第三种方法是通过其索引获取网络接口： NetworkInterface nif = NetworkInterface.getByIndex(int index); 最后一种方法涉及使用getNetworkInterfaces API。它返回系统中所有可用网络接口的枚举。在循环中检索返回的对象是我们的责任，标准的习惯用法使用List： Enumeration\u0026lt;NetworkInterface\u0026gt; nets = NetworkInterface.getNetworkInterfaces(); for (NetworkInterface nif: Collections.list(nets)) { //do something with the network interface } 4. 网络接口参数 在检索对象后，我们可以从其中获得很多有价值的信息。其中最有用的是分配给它的 IP 地址列表。 我们可以使用两个 API 获取 IP 地址。第一个 API 是getInetAddresses()。它返回一个InetAddress实例的**枚举，我们可以按照我们认为合适的方式对其进行处理： @Test public void givenInterface_whenReturnsInetAddresses_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); Enumeration\u0026lt;InetAddress\u0026gt; addressEnum = nif.getInetAddresses(); InetAddress address = addressEnum.nextElement(); assertEquals(\u0026#34;127.0.0.1\u0026#34;, address.getHostAddress()); } 第二个 API 是getInterfaceAddresses()。它返回一个比InetAddress实例更强大的InterfaceAddress实例**列表。例如，除了 IP 地址，您可能对广播地址感兴趣： @Test public void givenInterface_whenReturnsInterfaceAddresses_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); List\u0026lt;InterfaceAddress\u0026gt; addressEnum = nif.getInterfaceAddresses(); InterfaceAddress address = addressEnum.get(0); InetAddress localAddress=address.getAddress(); InetAddress broadCastAddress = address.getBroadcast(); assertEquals(\u0026#34;127.0.0.1\u0026#34;, localAddress.getHostAddress()); assertEquals(\u0026#34;127.255.255.255\u0026#34;,broadCastAddress.getHostAddress()); } 除了分配给它的名称和 IP 地址之外，我们还可以访问有关接口的网络参数。要检查它是否已启动并运行： @Test public void givenInterface_whenChecksIfUp_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); assertTrue(nif.isUp()); } 要检查它是否是环回接口： @Test public void givenInterface_whenChecksIfLoopback_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); assertTrue(nif.isLoopback()); } 要检查它是否代表点对点网络连接： @Test public void givenInterface_whenChecksIfPointToPoint_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); assertFalse(nif.isPointToPoint()); } 或者如果它是一个虚拟接口： @Test public void givenInterface_whenChecksIfVirtual_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); assertFalse(nif.isVirtual()); } 检查是否支持多播： @Test public void givenInterface_whenChecksMulticastSupport_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); assertTrue(nif.supportsMulticast()); } 或者检索其物理地址，通常称为 MAC 地址： @Test public void givenInterface_whenGetsMacAddress_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;lo\u0026#34;); byte[] bytes = nif.getHardwareAddress(); assertNotNull(bytes); } 另一个参数是最大传输单元，它定义了可以通过此接口传输的最大数据包大小： @Test public void givenInterface_whenGetsMTU_thenCorrect() { NetworkInterface nif = NetworkInterface.getByName(\u0026#34;net0\u0026#34;); int mtu = nif.getMTU(); assertEquals(1500, mtu); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_network_interfaces/","tags":[],"title":"在 Java 中使用网络接口"},{"categories":["Data"],"contents":"1. 概述 **Spectator是一个用于检测代码和为维度时间序列后端系统收集数据的库。**Spectator 起源于 Netflix，用于各种指标收集，与之配套使用的后端系统主要是Atlas。 在本教程中，我们将了解 Spectator 提供的内容以及我们如何使用它来收集指标。 2. Maven依赖 在我们深入实际实现之前，让我们将Spectator依赖添加到 pom.xml 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.netflix.spectator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spectator-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spectator-api是核心的观众库。 3. Registry、Meter和 Metrics的基础知识 在我们开始深入研究这个库之前，我们应该首先了解Registry、Meter和 Metrics的基础知识*。*  Registry是我们维护一组仪表的地方 Meter用于收集有关我们应用程序的一组测量值，例如Counter、Timer、Gauge等。 指标是我们在仪表上显示的单个测量值，例如计数、持续时间、最大值、平均值等。  让我们进一步探索这些并了解它们在 Spectator 库中的使用方式。 4. Registry Spectator 库带有Registry作为接口，并带有一些内置实现，例如DefaultRegistry 和 NoopRegistry。我们还可以根据我们的要求创建自定义注册表实现。 注册表实现可以如下使用： Registry registry = new DefaultRegistry(); 5. Meters ** 仪表主要有两种类型，即主动式和被动式。** 5.1 Active Meters 这些仪表用于测量某些事件的发生。我们有三种类型的仪表：  Counter 计时器 DistributionSummary  5.2. Passive Meters 这些计量器用于在需要时获取指标的值。例如，运行线程的数量可能是我们想要衡量的指标。我们只有一种此类仪表，即Gauge。 接下来，让我们详细探索这些不同类型的仪表。 6. Counter 这些仪表测量事件发生的速率。例如，假设我们想要测量从列表中插入或删除元素的速率。 让我们首先在初始化时向Registry对象注册一个计数器： insertCounter = registry.counter(\u0026#34;list.insert.count\u0026#34;); removeCounter = registry.counter(\u0026#34;list.remove.count\u0026#34;); 在这里，我们可以允许用户使用依赖注入的任何注册表实现。 现在，我们可以分别递增或递减计数器计量器以添加到列表或从列表中删除： requestList.add(element); insertCounter.increment(); requestList.remove(0); removeCounter.increment(); 这样，我们就可以生成两个meter，然后，我们可以将metrics推送到Atlas进行可视化。 7. 计时器 这些仪表测量在某些事件上花费的时间。Spectator 支持两种类型的计时器：  定时器 长任务定时器  7.1 Timer 这些定时器主要用于测量短期事件。因此，他们通常衡量事件完成后所花费的时间。 首先，我们需要在Registry中注册这个仪表： requestLatency = registry.timer(\u0026#34;app.request.latency\u0026#34;); 接下来，我们可以调用*Timer的**record()*方法来测量处理请求所花费的时间： requestLatency.record(() -\u0026gt; handleRequest(input)); 7.2. LongTaskTimer 这些计时器主要用于测量长时间运行的任务的持续时间。因此，即使事件正在进行中，我们也可以查询这些计时器。这也是量规的一种。 当事件正在进行时，我们可以看到 持续时间 和activeTasks等指标。 同样，作为第一步，我们需要注册这个仪表： refreshDuration = LongTaskTimer.get(registry, registry.createId(\u0026#34;metadata.refreshDuration\u0026#34;)); 接下来，我们可以使用LongTaskTimer来启动和停止长时间运行任务的测量： long taskId = refreshDuration.start(); try { Thread.sleep(input); return \u0026#34;Done\u0026#34;; } catch (InterruptedException e) { e.printStackTrace(); throw e; } finally { refreshDuration.stop(taskId); } 8. Gauges 正如我们之前讨论的，仪表是无源仪表。因此，这些给出了一个在任何时间点为正在运行的任务采样的值。因此，例如，如果我们想知道 JVM 中正在运行的线程数或任何时间点的堆内存使用情况，我们会使用它。 我们有两种类型的仪表：  Polled Gauges Active Gauges  8.1 Polled Gauges 这种类型的仪表在后台轮询正在运行的任务的值。它在它监视的任务上创建一个钩子。因此，无需更新此仪表中的值。 现在，让我们看看如何使用这个量规来监控List的大小： PolledMeter.using(registry) .withName(\u0026#34;list.size\u0026#34;) .monitorValue(listSize); 在这里， PolledMeter是允许 使用*monitorValue()方法对listSize进行后台轮询的类。*此外，listSize 是跟踪样本列表大小的变量。 8.2. Active Gauges 这种类型的仪表需要定期手动更新与监控任务更新相关的值。这是使用主动仪表的示例*：* gauge = registry.gauge(\u0026#34;list.size\u0026#34;); 我们首先在Registry中注册这个仪表。然后，我们在列表中添加或删除元素时手动更新它： list.add(element); gauge.set(listSize); list.remove(0); gauge.set(listSize); 9. DistributionSummary 现在，我们将研究另一个称为DistributionSummary 的仪表。它跟踪事件的分布。该仪表可以测量请求有效负载的大小。例如，我们将使用DistributionSummary来衡量请求的大小。 首先，和往常一样，我们在Registry中注册这个仪表： distributionSummary = registry.distributionSummary(\u0026#34;app.request.size\u0026#34;); 现在，我们可以使用类似于Timer的仪表来记录请求的大小： distributionSummary.record((long) input.length()); handleRequest(); 10. Spectator vs. Servo vs. Micrometer Servo也是一个衡量不同代码指标的库。Spectator 是 Netflix 打造的 Servo 的继任者。Spectator 最初是为 Java 8 推出的，从未来支持的角度来看，它是一个更好的选择。 这些 Netflix 库是市场上用于衡量不同指标的各种选项之一。我们总是可以单独使用它们，或者我们可以使用像Micrometer这样的外观。Micrometer 让用户可以轻松地在不同的度量标准测量库之间切换。因此，它还允许选择不同的后端监控系统。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_netflix_spectator/","tags":["Metrics"],"title":"Netflix 观众指南"},{"categories":["Data"],"contents":"1. 概述 在本文中，我们将了解 Netflix 开发的 Mantis 平台。 我们将通过创建、运行和调查流处理作业来探索主要的 Mantis 概念。 2. 什么是Mantis？ Mantis 是一个用于构建流处理应用程序（作业）的平台。它提供了一种简单的方法来管理作业的部署和生命周期。此外，它促进了这些作业之间的资源分配、发现和通信。 因此，开发人员可以专注于实际的业务逻辑，同时拥有强大且可扩展的平台支持来运行他们的高容量、低延迟、非阻塞应用程序。 Mantis 作业由三个不同的部分组成：  源，负责从外部源检索数据 一个或多个阶段，负责处理传入的事件流 和一个收集处理数据的接收器  现在让我们探索它们中的每一个。 3. 设置和依赖 让我们从添加*mantis-runtime和jackson-databind*依赖项开始： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.mantisrx\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mantis-runtime\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 现在，为了设置我们作业的数据源，让我们实现 Mantis Source接口： public class RandomLogSource implements Source\u0026lt;String\u0026gt; { @Override public Observable\u0026lt;Observable\u0026lt;String\u0026gt;\u0026gt; call(Context context, Index index) { return Observable.just( Observable .interval(250, TimeUnit.MILLISECONDS) .map(this::createRandomLogEvent)); } private String createRandomLogEvent(Long tick) { // generate a random log entry string  ... } } 正如我们所看到的，它只是每秒多次生成随机日志条目。 4. 我们的第一份作业 现在让我们创建一个简单地从RandomLogSource收集日志事件的 Mantis 作业。稍后，我们将添加组和聚合转换以获得更复杂和有趣的结果。 首先，让我们创建一个LogEvent实体： public class LogEvent implements JsonType { private Long index; private String level; private String message; // ... } 然后，让我们添加我们的TransformLogStage。 这是一个实现 ScalarComputation 接口并拆分日志条目以构建LogEvent的简单阶段。此外，它会过滤掉任何格式错误的字符串： public class TransformLogStage implements ScalarComputation\u0026lt;String, LogEvent\u0026gt; { @Override public Observable\u0026lt;LogEvent\u0026gt; call(Context context, Observable\u0026lt;String\u0026gt; logEntry) { return logEntry .map(log -\u0026gt; log.split(\u0026#34;#\u0026#34;)) .filter(parts -\u0026gt; parts.length == 3) .map(LogEvent::new); } } 4.1 运行作业 在这一点上，我们有足够的构建块来组合我们的 Mantis 工作： public class LogCollectingJob extends MantisJobProvider\u0026lt;LogEvent\u0026gt; { @Override public Job\u0026lt;LogEvent\u0026gt; getJobInstance() { return MantisJob .source(new RandomLogSource()) .stage(new TransformLogStage(), new ScalarToScalar.Config\u0026lt;\u0026gt;()) .sink(Sinks.eagerSubscribe(Sinks.sse(LogEvent::toJsonString))) .metadata(new Metadata.Builder().build()) .create(); } } 让我们仔细看看我们的工作。 正如我们所见，它扩展了 MantisJobProvider。首先，它从我们的RandomLogSource获取数据并将TransformLogStage应用于获取的数据。最后，它将处理后的数据发送到内置接收器，该接收器通过SSE急切地订阅和传递数据。 现在，让我们将我们的作业配置为在启动时在本地执行： @SpringBootApplication public class MantisApplication implements CommandLineRunner { // ...  @Override public void run(String... args) { LocalJobExecutorNetworked.execute(new LogCollectingJob().getJobInstance()); } } 让我们运行应用程序。我们将看到如下日志消息： ... Serving modern HTTP SSE server sink on port: 86XX 现在让我们使用curl连接到接收器： $ curl localhost:86XX data: {\u0026#34;index\u0026#34;:86,\u0026#34;level\u0026#34;:\u0026#34;WARN\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;login attempt\u0026#34;} data: {\u0026#34;index\u0026#34;:87,\u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;user created\u0026#34;} data: {\u0026#34;index\u0026#34;:88,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;user created\u0026#34;} data: {\u0026#34;index\u0026#34;:89,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;login attempt\u0026#34;} data: {\u0026#34;index\u0026#34;:90,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;user created\u0026#34;} data: {\u0026#34;index\u0026#34;:91,\u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;user created\u0026#34;} data: {\u0026#34;index\u0026#34;:92,\u0026#34;level\u0026#34;:\u0026#34;WARN\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;login attempt\u0026#34;} data: {\u0026#34;index\u0026#34;:93,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;user created\u0026#34;} ... 4.2. 配置接收器 到目前为止，我们已经使用内置接收器来收集我们处理过的数据。让我们看看我们是否可以通过提供自定义接收器来为我们的场景增加更多的灵活性。 例如，如果我们想按消息过滤日志怎么办？ 让我们创建一个实现Sink接口的LogSink ： public class LogSink implements Sink\u0026lt;LogEvent\u0026gt; { @Override public void call(Context context, PortRequest portRequest, Observable\u0026lt;LogEvent\u0026gt; logEventObservable) { SelfDocumentingSink\u0026lt;LogEvent\u0026gt; sink = new ServerSentEventsSink.Builder\u0026lt;LogEvent\u0026gt;() .withEncoder(LogEvent::toJsonString) .withPredicate(filterByLogMessage()) .build(); logEventObservable.subscribe(); sink.call(context, portRequest, logEventObservable); } private Predicate\u0026lt;LogEvent\u0026gt; filterByLogMessage() { return new Predicate\u0026lt;\u0026gt;(\u0026#34;filter by message\u0026#34;, parameters -\u0026gt; { if (parameters != null \u0026amp;\u0026amp; parameters.containsKey(\u0026#34;filter\u0026#34;)) { return logEvent -\u0026gt; logEvent.getMessage().contains(parameters.get(\u0026#34;filter\u0026#34;).get(0)); } return logEvent -\u0026gt; true; }); } } 在这个 sink 实现中，我们配置了一个使用filter参数的谓词来仅检索包含filter参数中设置的文本的日志： $ curl localhost:8874?filter=login data: {\u0026#34;index\u0026#34;:93,\u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;login attempt\u0026#34;} data: {\u0026#34;index\u0026#34;:95,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;login attempt\u0026#34;} data: {\u0026#34;index\u0026#34;:97,\u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;login attempt\u0026#34;} ... 注意 Mantis 还提供了一种强大的查询语言MQL，可用于以 SQL 方式查询、转换和分析流数据。 5. 阶段链接 现在假设我们想知道在给定时间间隔内有多少ERROR、WARN或INFO日志条目。为此，我们将在我们的工作中再添加两个阶段并将它们链接在一起。 5.1 分组 首先，让我们创建一个GroupLogStage。 此阶段是一个ToGroupComputation实现，它从现有的TransformLogStage接收**LogEvent流数据。之后，它按日志记录级别对条目进行分组并将它们发送到下一个阶段： public class GroupLogStage implements ToGroupComputation\u0026lt;LogEvent, String, LogEvent\u0026gt; { @Override public Observable\u0026lt;MantisGroup\u0026lt;String, LogEvent\u0026gt;\u0026gt; call(Context context, Observable\u0026lt;LogEvent\u0026gt; logEvent) { return logEvent.map(log -\u0026gt; new MantisGroup\u0026lt;\u0026gt;(log.getLevel(), log)); } public static ScalarToGroup.Config\u0026lt;LogEvent, String, LogEvent\u0026gt; config(){ return new ScalarToGroup.Config\u0026lt;LogEvent, String, LogEvent\u0026gt;() .description(\u0026#34;Group event data by level\u0026#34;) .codec(JacksonCodecs.pojo(LogEvent.class)) .concurrentInput(); } } 我们还通过提供描述创建了一个自定义阶段配置，用于序列化输出的编解码器，并允许该阶段的调用方法通过使用concurrentInput() 并发运行。 **需要注意的一点是，这个阶段是水平可扩展的。这意味着我们可以根据需要运行此阶段的尽可能多的实例。**另外值得一提的是，当部署在 Mantis 集群中时，这个阶段会将数据发送到下一个阶段，以便属于特定组的所有事件都将落在下一个阶段的同一个工作人员上。 5.2. 聚合 在我们继续创建下一个阶段之前，让我们首先添加一个LogAggregate实体： public class LogAggregate implements JsonType { private final Integer count; private final String level; } 现在，让我们创建链中的最后一个阶段。 此阶段实现GroupToScalarComputation并将日志组流转换为标量LogAggregate。它通过计算每种类型的日志在流中出现的次数来做到这一点。此外，它还有一个LogAggregationDuration参数，可以用来控制聚合窗口的大小： public class CountLogStage implements GroupToScalarComputation\u0026lt;String, LogEvent, LogAggregate\u0026gt; { private int duration; @Override public void init(Context context) { duration = (int)context.getParameters().get(\u0026#34;LogAggregationDuration\u0026#34;, 1000); } @Override public Observable\u0026lt;LogAggregate\u0026gt; call(Context context, Observable\u0026lt;MantisGroup\u0026lt;String, LogEvent\u0026gt;\u0026gt; mantisGroup) { return mantisGroup .window(duration, TimeUnit.MILLISECONDS) .flatMap(o -\u0026gt; o.groupBy(MantisGroup::getKeyValue) .flatMap(group -\u0026gt; group.reduce(0, (count, value) -\u0026gt; count = count + 1) .map((count) -\u0026gt; new LogAggregate(count, group.getKey())) )); } public static GroupToScalar.Config\u0026lt;String, LogEvent, LogAggregate\u0026gt; config(){ return new GroupToScalar.Config\u0026lt;String, LogEvent, LogAggregate\u0026gt;() .description(\u0026#34;sum events for a log level\u0026#34;) .codec(JacksonCodecs.pojo(LogAggregate.class)) .withParameters(getParameters()); } public static List\u0026lt;ParameterDefinition\u0026lt;?\u0026gt;\u0026gt; getParameters() { List\u0026lt;ParameterDefinition\u0026lt;?\u0026gt;\u0026gt; params = new ArrayList\u0026lt;\u0026gt;(); params.add(new IntParameter() .name(\u0026#34;LogAggregationDuration\u0026#34;) .description(\u0026#34;window size for aggregation in milliseconds\u0026#34;) .validator(Validators.range(100, 10000)) .defaultValue(5000) .build()); return params; } } 5.3. 配置和运行作业 现在唯一要做的就是配置我们的工作： public class LogAggregationJob extends MantisJobProvider\u0026lt;LogAggregate\u0026gt; { @Override public Job\u0026lt;LogAggregate\u0026gt; getJobInstance() { return MantisJob .source(new RandomLogSource()) .stage(new TransformLogStage(), TransformLogStage.stageConfig()) .stage(new GroupLogStage(), GroupLogStage.config()) .stage(new CountLogStage(), CountLogStage.config()) .sink(Sinks.eagerSubscribe(Sinks.sse(LogAggregate::toJsonString))) .metadata(new Metadata.Builder().build()) .create(); } } 一旦我们运行应用程序并执行我们的新作业，我们可以看到每隔几秒检索一次日志计数： $ curl localhost:8133 data: {\u0026#34;count\u0026#34;:3,\u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;} data: {\u0026#34;count\u0026#34;:13,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;} data: {\u0026#34;count\u0026#34;:4,\u0026#34;level\u0026#34;:\u0026#34;WARN\u0026#34;} data: {\u0026#34;count\u0026#34;:8,\u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;} data: {\u0026#34;count\u0026#34;:5,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;} data: {\u0026#34;count\u0026#34;:7,\u0026#34;level\u0026#34;:\u0026#34;WARN\u0026#34;} ... \u0026quot; ","permalink":"http://itcodingman.github.io/java_netflix_mantis/","tags":["Netflix"],"title":"Netflix 螳螂简介"},{"categories":["Java"],"contents":"1. 简介 本教程对 Java 语言中的嵌套类进行了快速而中肯的介绍。 简而言之，Java 允许我们在其他类中定义类。嵌套类使我们能够对仅在一个地方使用的类进行逻辑分组，编写更具可读性和可维护性的代码并增加封装性。 在开始之前，让我们看一下该语言中可用的几种嵌套类：  静态嵌套类 非静态嵌套类 本地课程 匿名课程  在接下来的部分中，我们将详细讨论其中的每一个。 2. 静态嵌套类 关于静态嵌套类，需要记住以下几点：  与静态成员一样，它们属于它们的封闭类，而不是类的实例 它们的声明中可以包含所有类型的访问修饰符 他们只能访问封闭类中的静态成员 他们可以定义静态和非静态成员  让我们看看如何声明一个静态嵌套类： public class Enclosing { private static int x = 1; public static class StaticNested { private void run() { // method implementation  } } @Test public void test() { Enclosing.StaticNested nested = new Enclosing.StaticNested(); nested.run(); } } 3. 非静态嵌套类 接下来，这里有一些关于非静态嵌套类的快速要点：  它们也被称为内部类 它们的声明中可以包含所有类型的访问修饰符 就像实例变量和方法一样，内部类与封闭类的实例相关联 它们可以访问封闭类的所有成员，无论它们是静态的还是非静态的 他们只能定义非静态成员  下面是我们如何声明一个内部类： public class Outer { public class Inner { // ...  } } 如果我们声明一个带有修饰符static的嵌套类，那么它就是一个静态成员。否则，它是一个内部类。尽管语法上的区别只是一个关键字（即static），但在语义上，这些嵌套类之间存在巨大差异。内部类实例绑定到封闭类实例，因此它们可以访问其成员。在选择是否将嵌套类设为内部类时，我们应该注意这个问题。 要实例化一个内部类，我们必须首先实例化它的封闭类。 让我们看看如何做到这一点： Outer outer = new Outer(); Outer.Inner inner = outer.new Inner(); 在接下来的小节中，我们将展示一些特殊类型的内部类。 3.1 本地class 局部类是一种特殊类型的内部类——其中类定义在方法或范围块内。 让我们看看关于这种类型的类要记住的几点：  他们的声明中不能有访问修饰符 他们可以访问封闭上下文中的静态和非静态成员 他们只能定义实例成员  这是一个简单的例子： public class NewEnclosing { void run() { class Local { void run() { // method implementation  } } Local local = new Local(); local.run(); } @Test public void test() { NewEnclosing newEnclosing = new NewEnclosing(); newEnclosing.run(); } } 3.2. 匿名类 匿名类可用于定义接口或抽象类的实现，而无需创建可重用的实现。 让我们列出一些关于匿名类的要点：  他们的声明中不能有访问修饰符 他们可以访问封闭上下文中的静态和非静态成员 他们只能定义实例成员 它们是唯一不能定义构造函数或扩展/实现其他类或接口的嵌套类类型  要定义一个匿名类，我们首先定义一个简单的抽象类： abstract class SimpleAbstractClass { abstract void run(); } 现在让我们看看如何定义一个匿名类： public class AnonymousInnerUnitTest { @Test public void whenRunAnonymousClass_thenCorrect() { SimpleAbstractClass simpleAbstractClass = new SimpleAbstractClass() { void run() { // method implementation  } }; simpleAbstractClass.run(); } } 有关更多详细信息，我们可能会在 Java 中的匿名类教程中找到有用的。 4. 阴影 如果内部类的成员具有相同的名称**，则内部类成员的声明会影响封闭类的成员声明。** 在这种情况下，this关键字指的是嵌套类的实例，并且可以使用外部类的名称来引用外部类的成员。 让我们看一个简单的例子： public class NewOuter { int a = 1; static int b = 2; public class InnerClass { int a = 3; static final int b = 4; public void run() { System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); System.out.println(\u0026#34;NewOuterTest.this.a = \u0026#34; + NewOuter.this.a); System.out.println(\u0026#34;NewOuterTest.b = \u0026#34; + NewOuter.b); System.out.println(\u0026#34;NewOuterTest.this.b = \u0026#34; + NewOuter.this.b); } } @Test public void test() { NewOuter outer = new NewOuter(); NewOuter.InnerClass inner = outer.new InnerClass(); inner.run(); } } 5. 序列化 为了避免在尝试序列化嵌套类时出现java.io.NotSerializableException ，我们应该：  将嵌套类声明为static 使嵌套类和封闭类都实现Serializable \u0026quot;  ","permalink":"http://itcodingman.github.io/java_nested_classes/","tags":["Core Java"],"title":"Java中的嵌套类"},{"categories":["Java"],"contents":"1. 简介 在本教程中，我们将探索嵌套，即 Java 11 中引入的新访问控制上下文。 2. Java 11 之前 2.1 嵌套类型 Java 允许类和接口相互嵌套。这些嵌套类型可以不受限制地相互访问，包括私有字段、方法和构造函数。 考虑以下嵌套类示例： public class Outer { public void outerPublic() { } private void outerPrivate() { } class Inner { public void innerPublic() { outerPrivate(); } } } 在这里，虽然方法outerPrivate()是private，但可以从方法*innerPublic()*访问它。 我们可以将顶级类型以及嵌套在其中的所有类型描述为形成一个嵌套。巢中的两个成员被描述为巢友。 因此，在上面的示例中，Outer和Inner一起形成一个巢，并且是彼此的巢穴。 2.2. 桥接法 JVM 访问规则不允许巢友之间的私有访问。理想情况下，我们应该得到上述示例的编译错误。但是，Java 源代码编译器通过引入间接级别来允许访问。 例如，对私有成员的调用被编译为对目标类中编译器生成的、包私有的桥接方法的调用，进而调用预期的私有方法。 这发生在幕后。这种桥接方法略微增加了已部署应用程序的大小，并且可能会混淆用户和工具。 2.3. 使用反射 这样做的另一个后果是核心反射也拒绝访问。这是令人惊讶的，因为反射调用的行为应该与源级调用相同。 例如，如果我们尝试从Inner类反射 地调用outerPrivate() ： public void innerPublicReflection(Outer ob) throws Exception { Method method = ob.getClass().getDeclaredMethod(\u0026#34;outerPrivate\u0026#34;); method.invoke(ob); } 我们会得到一个例外： java.lang.IllegalAccessException: Class com.codingman.Outer$Inner can not access a member of class com.codingman.Outer with modifiers \u0026#34;private\u0026#34; Java 11 试图解决这些问题。 3. 基于嵌套的访问控制 Java 11 在 JVM 中引入了嵌套的概念和相关的访问规则。这简化了 Java 源代码编译器的工作。 为了实现这一点，类文件格式现在包含两个新属性：  一个嵌套成员（通常是顶级类）被指定为嵌套宿主。它包含一个属性 (NestMembers) 来标识其他静态已知的嵌套成员。 每个其他嵌套成员都有一个属性 (NestHost) 来标识其嵌套宿主。  因此，类型C和D要成为巢友，它们必须具有相同的巢宿主。如果类型C在其 NestHost 属性中列出 D ，则它声称是**D托管的巢的成员。如果D还在其 NestMembers 属性中列出C ，则验证成员资格。此外，类型D隐含地是它所托管的嵌套的成员。 现在编译器不需要生成桥接方法。 最后，基于嵌套的访问控制从核心反射中移除了令人惊讶的行为。因此，上一节中显示的方法*innerPublicReflection()*将毫无例外地执行。 4. Nestmate 反射 API Java 11 提供了使用核心反射查询新类文件属性的方法。java.lang.Class类包含以下三个新方法。 4.1 getNestHost() 这将返回该Class对象所属的嵌套的嵌套主机： @Test public void whenGetNestHostFromOuter_thenGetNestHost() { is(Outer.class.getNestHost().getName()).equals(\u0026#34;com.codingman.Outer\u0026#34;); } @Test public void whenGetNestHostFromInner_thenGetNestHost() { is(Outer.Inner.class.getNestHost().getName()).equals(\u0026#34;com.codingman.Outer\u0026#34;); } Outer和Inner类都属于嵌套主机com.codingman.Outer。 4.2. isNestmateOf() 这确定给定的Class是否是这个Class对象的嵌套： @Test public void whenCheckNestmatesForNestedClasses_thenGetTrue() { is(Outer.Inner.class.isNestmateOf(Outer.class)).equals(true); } 4.3. getNestMembers() 这将返回一个包含Class对象的数组，这些对象表示该Class对象所属的嵌套的所有成员： @Test public void whenGetNestMembersForNestedClasses_thenGetAllNestedClasses() { Set\u0026lt;String\u0026gt; nestMembers = Arrays.stream(Outer.Inner.class.getNestMembers()) .map(Class::getName) .collect(Collectors.toSet()); is(nestMembers.size()).equals(2); assertTrue(nestMembers.contains(\u0026#34;com.codingman.Outer\u0026#34;)); assertTrue(nestMembers.contains(\u0026#34;com.codingman.Outer$Inner\u0026#34;)); } 5. 编译细节 5.1 Java 11 之前的桥接方法 让我们深入了解编译器生成的桥接方法的细节。我们可以通过反汇编生成的类文件来看到这一点： $ javap -c Outer Compiled from \u0026#34;Outer.java\u0026#34; public class com.codingman.Outer { public com.codingman.Outer(); Code: 0: aload_0 1: invokespecial #2 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V  4: return public void outerPublic(); Code: 0: return static void access$000(com.codingman.Outer); Code: 0: aload_0 1: invokespecial #1 // Method outerPrivate:()V  4: return } 在这里，除了默认构造函数和公共方法outerPublic() 之外，请注意方法access$000()。编译器将此作为桥接方法生成。 innerPublic()通过这个方法调用outerPrivate()： $ javap -c Outer\\$Inner Compiled from \u0026#34;Outer.java\u0026#34; class com.codingman.Outer$Inner { final com.codingman.Outer this$0; com.codingman.Outer$Inner(com.codingman.Outer); Code: 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Lcom/codingman/Outer;  5: aload_0 6: invokespecial #2 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V  9: return public void innerPublic(); Code: 0: aload_0 1: getfield #1 // Field this$0:Lcom/codingman/Outer;  4: invokestatic #3 // Method com/codingman/Outer.access$000:(Lcom/codingman/Outer;)V  7: return } 注意第 19 行的注释。这里，innerPublic()调用桥接方法access$000()。 5.2. 使用 Java 11 Java 11 编译器将生成以下反汇编的Outer类文件： $ javap -c Outer Compiled from \u0026#34;Outer.java\u0026#34; public class com.codingman.Outer { public com.codingman.Outer(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V  4: return public void outerPublic(); Code: 0: return } 请注意，没有编译器生成的桥接方法。此外， Inner类现在可以直接调用*outerPrivate()*方法： $ javap -c Outer\\$Inner.class Compiled from \u0026#34;Outer.java\u0026#34; class com.codingman.Outer$Inner { final com.codingman.Outer this$0; com.codingman.Outer$Inner(com.codingman.Outer); Code: 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Lcom/codingman/Outer;  5: aload_0 6: invokespecial #2 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V  9: return public void innerPublic(); Code: 0: aload_0 1: getfield #1 // Field this$0:Lcom/codingman/Outer;  4: invokevirtual #3 // Method com/codingman/Outer.outerPrivate:()V  7: return } \u0026quot; ","permalink":"http://itcodingman.github.io/java_nest_based_access_control/","tags":["Java 11"],"title":"Java 11 基于嵌套的访问控制"},{"categories":["Persistence"],"contents":"1. 简介 这篇文章是关于Neo4j——当今市场上最成熟、功能最齐全的图形数据库之一。图数据库处理数据建模任务的观点是，生活中的许多事物都可以表示为节点（V）的集合，它们之间的连接称为边（E）。 2. 嵌入式 Neo4j 开始使用Neo4j的最简单方法是使用**Neo4j在与您的应用程序相同的 JVM 中运行的嵌入式版本。 首先，我们需要添加一个 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.neo4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;neo4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以查看此链接以下载最新版本。 接下来，让我们创建一个工厂： GraphDatabaseFactory graphDbFactory = new GraphDatabaseFactory(); 最后，我们创建一个嵌入式数据库： GraphDatabaseService graphDb = graphDbFactory.newEmbeddedDatabase( new File(\u0026#34;data/cars\u0026#34;)); 现在可以开始真正的行动了！首先，我们需要在我们的图中创建一些节点，为此，我们需要启动一个事务，因为Neo4j将拒绝任何破坏性操作，除非一个事务已经启动： graphDb.beginTx(); 一旦我们有一个正在进行的事务，我们就可以开始添加节点： Node car = graphDb.createNode(Label.label(\u0026#34;Car\u0026#34;)); car.setProperty(\u0026#34;make\u0026#34;, \u0026#34;tesla\u0026#34;); car.setProperty(\u0026#34;model\u0026#34;, \u0026#34;model3\u0026#34;); Node owner = graphDb.createNode(Label.label(\u0026#34;Person\u0026#34;)); owner.setProperty(\u0026#34;firstName\u0026#34;, \u0026#34;ann\u0026#34;); owner.setProperty(\u0026#34;lastName\u0026#34;, \u0026#34;bob\u0026#34;); 在这里，我们添加了具有属性make和model的节点Car以及具有属性firstName和lastName的节点Person 现在我们可以添加一个关系： owner.createRelationshipTo(car, RelationshipType.withName(\u0026#34;owner\u0026#34;)); 上面的语句添加了一条连接两个节点的边，带有所有者标签。我们可以通过运行一个用Neo4j强大的Cypher语言编写的查询来验证这种关系： Result result = graphDb.execute( \u0026#34;MATCH (c:Car) \u0026lt;-[owner]- (p:Person) \u0026#34; + \u0026#34;WHERE c.make = \u0026#39;tesla\u0026#39;\u0026#34; + \u0026#34;RETURN p.firstName, p.lastName\u0026#34;); 在这里，我们要求为任何品牌为特斯拉的汽车寻找车主，并将他/她的名字和姓氏返回给我们。不出所料，这会返回：{p.firstName=ann, p.lastName=bob} 3. Cypher 查询语言 Neo4j提供了一种非常强大且非常直观的查询语言，它支持人们期望从数据库中获得的全部功能。让我们检查一下如何完成标准的创建、检索、更新和删除任务。 3.1 创建节点 Create 关键字可用于创建节点和关系。 CREATE (self:Company {name:\u0026#34;Toyota\u0026#34;}) RETURN self 在这里，我们创建了一个具有单一属性name的公司。节点定义用圆括号标记，其属性用大括号括起来。在这种情况下，self是节点的别名，Company是节点标签。 3.2. 创建关系 可以在单个查询中创建一个节点和与该节点的关系： Result result = graphDb.execute( \u0026#34;CREATE (tt:Company {name:\\\u0026#34;Toyota\\\u0026#34;}) \u0026#34; + \u0026#34;-[:owns]-\u0026gt; (tesla:Car {make: \u0026#39;tesla\u0026#39;, model: \u0026#39;modelX\u0026#39;})\u0026#34; + \u0026#34;RETURN tt, tesla\u0026#34;); 在这里，我们创建了节点tt和tesla，并在它们之间建立了所有权关系。当然，与预先存在的节点建立关系也是可能的。 3.3. 检索数据 MATCH关键字用于查找数据，结合RETURN来控制返回哪些数据点。WHERE子句可用于仅过滤掉那些具有我们想要的属性的节点。 让我们弄清楚拥有特斯拉modelX的公司的名称： Result result = graphDb.execute( \u0026#34;MATCH (company:Company)-[:owns]-\u0026gt; (car:Car)\u0026#34; + \u0026#34;WHERE car.make=\u0026#39;tesla\u0026#39; and car.model=\u0026#39;modelX\u0026#39;\u0026#34; + \u0026#34;RETURN company.name\u0026#34;); 3.4. 更新节点 SET关键字可用于更新节点属性或标签。让我们为我们的特斯拉增加里程： Result result = graphDb.execute(\u0026#34;MATCH (car:Car)\u0026#34; + \u0026#34;WHERE car.make=\u0026#39;tesla\u0026#39;\u0026#34; + \u0026#34; SET car.milage=120\u0026#34; + \u0026#34; SET car :Car:Electro\u0026#34; + \u0026#34; SET car.model=NULL\u0026#34; + \u0026#34; RETURN car\u0026#34;); 在这里，我们添加了一个名为milage的新属性，将标签修改为Car和Electro，最后，我们完全删除了模型属性。 3.5. 删除节点 DELETE 关键字可用于从图中永久删除节点或关系： graphDb.execute(\u0026#34;MATCH (company:Company)\u0026#34; + \u0026#34; WHERE company.name=\u0026#39;Toyota\u0026#39;\u0026#34; + \u0026#34; DELETE company\u0026#34;); 在这里，我们删除了一家名为 Toyota 的公司。 3.6. 参数绑定 在上面的示例中，我们有硬编码的参数值，这不是最佳实践。幸运的是，Neo4j提供了将变量绑定到查询的工具： Map\u0026lt;String, Object\u0026gt; params = new HashMap\u0026lt;\u0026gt;(); params.put(\u0026#34;name\u0026#34;, \u0026#34;tt\u0026#34;); params.put(\u0026#34;make\u0026#34;, \u0026#34;tesla\u0026#34;); params.put(\u0026#34;model\u0026#34;, \u0026#34;modelS\u0026#34;); Result result = graphDb.execute(\u0026#34;CREATE (tt:Company {name:$name}) \u0026#34; + \u0026#34;-[:owns]-\u0026gt; (tesla:Car {make: $make, model: $model})\u0026#34; + \u0026#34;RETURN tt, tesla\u0026#34;, params); 4. Java驱动 到目前为止，我们一直在研究与嵌入式Neo4j实例的交互，但是，在生产环境中，我们很可能希望运行一个独立的服务器并通过提供的驱动程序连接到它。首先，我们需要在 maven pom.xml中添加另一个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.neo4j.driver\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;neo4j-java-driver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以点击此链接检查此驱动程序的最新版本。 现在我们可以建立连接了： Driver driver = GraphDatabase.driver( \u0026#34;bolt://localhost:7687\u0026#34;, AuthTokens.basic(\u0026#34;neo4j\u0026#34;, \u0026#34;12345\u0026#34;)); 然后，创建一个会话： Session session = driver.session(); 最后，我们可以运行一些查询： session.run(\u0026#34;CREATE (tt:Company {name:\\\u0026#34;Toyota\\\u0026#34;}) \u0026#34; + \u0026#34;-[:owns]-\u0026gt; (tesla:Car {make: \u0026#39;tesla\u0026#39;, model: \u0026#39;modelX\u0026#39;})\u0026#34; + \u0026#34;RETURN tt, tesla\u0026#34;); 完成所有工作后，我们需要关闭会话和驱动程序： session.close(); driver.close(); 5. JDBC驱动 也可以通过 JDBC 驱动程序与Neo4j交互。**我们的pom.xml的另一个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.neo4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;neo4j-jdbc-driver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以点击此链接下载此驱动程序的最新版本。 接下来，让我们建立一个 JDBC 连接： Connection con = DriverManager.getConnection( \u0026#34;jdbc:neo4j:bolt://localhost/?user=neo4j,password=12345,scheme=basic\u0026#34;); 这里的con是一个常规的 JDBC 连接，可用于创建和执行语句或准备好的语句： try (Statement stmt = con. stmt.execute(\u0026#34;CREATE (tt:Company {name:\\\u0026#34;Toyota\\\u0026#34;}) \u0026#34; + \u0026#34;-[:owns]-\u0026gt; (tesla:Car {make: \u0026#39;tesla\u0026#39;, model: \u0026#39;modelX\u0026#39;})\u0026#34; + \u0026#34;RETURN tt, tesla\u0026#34;) ResultSet rs = stmt.executeQuery( \u0026#34;MATCH (company:Company)-[:owns]-\u0026gt; (car:Car)\u0026#34; + \u0026#34;WHERE car.make=\u0026#39;tesla\u0026#39; and car.model=\u0026#39;modelX\u0026#39;\u0026#34; + \u0026#34;RETURN company.name\u0026#34;); while (rs.next()) { rs.getString(\u0026#34;company.name\u0026#34;); } } 6. 对象-图-映射 Object-Graph-Mapping 或 OGM 是一种使我们能够将域 POJO 用作Neo4j数据库中的实体的技术。让我们来看看这是如何工作的。第一步，像往常一样，我们向pom.xml添加新的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.neo4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;neo4j-ogm-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.neo4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;neo4j-ogm-embedded-driver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以检查OGM Core Link和OGM Embedded Driver Link以检查这些库的最新版本。 其次，我们用 OGM 注释来注释我们的 POJO： @NodeEntity public class Company { private Long id; private String name; @Relationship(type=\u0026#34;owns\u0026#34;) private Car car; } @NodeEntity public class Car { private Long id; private String make; @Relationship(direction = \u0026#34;INCOMING\u0026#34;) private Company company; } @NodeEntity通知Neo4j这个对象需要由结果图中的一个节点来表示。@Relationship传达了与表示相关类型的节点创建关系的需要。在这种情况下，一家公司拥有一辆汽车。 请注意，Neo4j要求每个实体都有一个主键，默认选择一个名为id的字段。可以通过使用@Id @GeneratedValue 对其进行注释来使用替代命名的字段。 然后，我们需要创建一个用于引导Neo4j的 OGM 的配置。为简单起见，让我们使用嵌入式内存数据库： Configuration conf = new Configuration.Builder().build(); 之后，我们使用我们创建的配置和我们注释的 POJO 所在的包名称初始化SessionFactory ： SessionFactory factory = new SessionFactory(conf, \u0026#34;com.codingman.graph\u0026#34;); 最后，我们可以创建一个Session并开始使用它： Session session = factory.openSession(); Car tesla = new Car(\u0026#34;tesla\u0026#34;, \u0026#34;modelS\u0026#34;); Company company = new Company(\u0026#34;Toyota\u0026#34;); company.setCar(tesla); session.save(company); 在这里，我们启动了一个会话，创建了我们的 POJO，并要求 OGM 会话将它们持久化。Neo4j OGM 运行时透明地将对象转换为一组Cypher查询，这些查询在数据库中创建了适当的节点和边。 如果这个过程看起来很熟悉，那是因为它是！这正是 JPA 的工作方式，唯一的区别是对象是被转换为持久化到 RDBMS 的行，还是被持久化到图形数据库的一系列节点和边。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_neo4j/","tags":[],"title":"使用 Java 的 Neo4J 指南"},{"categories":["Java"],"contents":"1. 概述 在这个快速教程中，我们将讨论 Java 中 native关键字的概念，我们还将展示如何将本地方法集成到 Java 代码中。 2. Java中的 native关键字 首先，让我们讨论一下Java中的native关键字是什么。 简而言之，这是一个非访问修饰符，用于访问以 Java 以外的语言（如 C/C++）实现的方法。 它表示方法或代码的平台相关实现，还充当JNI和其他编程语言之间的接口。 3. native方法 本机方法是一种 Java 方法（实例方法或类方法），其实现也是用另一种编程语言（如 C/C++）编写的。 此外，标记为 native的方法 不能有主体，并且应该以分号结尾： [ public | protected | private] native [return_type] method (); 我们可以使用它们：  用其他编程语言编写的系统调用或库实现接口 访问只能通过其他语言访问的系统或硬件资源 将现有的用 C/C++ 编写的遗留代码集成到 Java 应用程序中 使用 Java 中的任意代码调用已编译的动态加载库  4. 例子 现在让我们演示如何将这些方法集成到我们的 Java 代码中。 4.1 在 Java 中访问本机代码 首先，让我们创建一个DateTimeUtils类 ，它需要访问一个名为 getSystemTime的依赖于平台的**本机方法： public class DateTimeUtils { public native String getSystemTime(); // ... } 要加载它，我们将使用 System.loadLibrary。 让我们将加载这个库的调用放在一个 static块中，以便它在我们的类中可用： public class DateTimeUtils { public native String getSystemTime(); static { System.loadLibrary(\u0026#34;nativedatetimeutils\u0026#34;); } } 我们创建了一个动态链接库 *nativedatetimeutils ，它使用我们的 *JNI 指南文章 中的详细说明在 C++中实现 getSystemTime。 4.2. 测试native方法 最后，让我们看看如何测试DateTimeUtils 类中定义的本地方法： public class DateTimeUtilsManualTest { @BeforeClass public static void setUpClass() { // .. load other dependent libraries  System.loadLibrary(\u0026#34;nativedatetimeutils\u0026#34;); } @Test public void givenNativeLibsLoaded_thenNativeMethodIsAccessible() { DateTimeUtils dateTimeUtils = new DateTimeUtils(); LOG.info(\u0026#34;System time is : \u0026#34; + dateTimeUtils.getSystemTime()); assertNotNull(dateTimeUtils.getSystemTime()); } } 以下是记录器的输出： [main] INFO c.b.n.DateTimeUtilsManualTest - System time is : Wed Dec 19 11:34:02 2018 正如我们所见，在 native关键字的帮助下，我们成功地访问了用另一种语言（在我们的例子中是 C++）编写的依赖于平台的实现。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_native/","tags":[],"title":"Java Native 关键字和方法"},{"categories":["Java"],"contents":"1. 简介 本文重点介绍*Nashorn——*从 Java 8 开始为 JVM 提供的新的默认 JavaScript 引擎。 许多复杂的技术已被用于使Nashorn的性能比其前身*Rhino 的性能高出几个数量级，*因此这是一个值得的改变。 让我们看一下可以使用它的一些方法。 2.命令行 JDK 1.8 包含一个名为jjs的命令行解释器，它可用于运行 JavaScript 文件，或者，如果以不带参数的方式启动，则作为 REPL（交互式 shell）： $ $JAVA_HOME/bin/jjs hello.js Hello World 这里的hello.js文件包含一条指令：print(“Hello World”); 相同的代码可以交互方式运行： $ $JAVA_HOME/bin/jjs jjs\u0026gt; print(\u0026#34;Hello World\u0026#34;) Hello World 您还可以通过添加*#!$JAVA_HOME/bin/jjs作为第一行来指示 *nix 运行时使用jjs*运行目标脚本： #!$JAVA_HOME/bin/jjs var greeting = \u0026#34;Hello World\u0026#34;; print(greeting); 然后文件就可以正常运行了： $ ./hello.js Hello World 3. 嵌入式脚本引擎 在 JVM 中运行 JavaScript 的第二种可能更常见的方法是通过*ScriptEngine。*JSR-223 定义了一组脚本 API，允许可用于任何动态语言的可插入脚本引擎架构（当然，前提是它具有 JVM 实现）。 让我们创建一个 JavaScript 引擎： ScriptEngine engine = new ScriptEngineManager().getEngineByName(\u0026#34;nashorn\u0026#34;); Object result = engine.eval( \u0026#34;var greeting=\u0026#39;hello world\u0026#39;;\u0026#34; + \u0026#34;print(greeting);\u0026#34; + \u0026#34;greeting\u0026#34;); 在这里，我们创建了一个新的ScriptEngineManager并立即要求它给我们一个名为nashorn的ScriptEngine。然后，我们传递一些指令并获得可以预见的结果，结果是一个字符串“ hello world ”。 4. 将数据传递给脚本 通过定义一个Bindings对象并将其作为第二个参数传递给eval函数，可以将数据传递到引擎中： Bindings bindings = engine.createBindings(); bindings.put(\u0026#34;count\u0026#34;, 3); bindings.put(\u0026#34;name\u0026#34;, \u0026#34;demo\u0026#34;); String script = \u0026#34;var greeting=\u0026#39;Hello \u0026#39;;\u0026#34; + \u0026#34;for(var i=count;i\u0026gt;0;i--) { \u0026#34; + \u0026#34;greeting+=name + \u0026#39; \u0026#39;\u0026#34; + \u0026#34;}\u0026#34; + \u0026#34;greeting\u0026#34;; Object bindingsResult = engine.eval(script, bindings); 运行此代码段会生成：“ Hello demo demo demo ”。 5. 调用 JavaScript 函数 当然，也可以从您的 Java 代码中调用 JavaScript 函数： engine.eval(\u0026#34;function composeGreeting(name) {\u0026#34; + \u0026#34;return \u0026#39;Hello \u0026#39; + name\u0026#34; + \u0026#34;}\u0026#34;); Invocable invocable = (Invocable) engine; Object funcResult = invocable.invokeFunction(\u0026#34;composeGreeting\u0026#34;, \u0026#34;demo\u0026#34;); 这将返回“ Hello demo ”。 6. 使用 Java 对象 由于我们在 JVM 中运行，因此可以在 JavaScript 代码中使用本机 Java 对象。 这是通过使用Java对象来完成的： Object map = engine.eval(\u0026#34;var HashMap = Java.type(\u0026#39;java.util.HashMap\u0026#39;);\u0026#34; + \u0026#34;var map = new HashMap();\u0026#34; + \u0026#34;map.put(\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;);\u0026#34; + \u0026#34;map\u0026#34;); 7. 语言扩展 Nashorn的目标是 ECMAScript 5.1，但它确实提供了扩展以使 JavaScript 的使用更好一点。 7.1 使用 For-Each 迭代集合 For-each是一个方便的扩展，可以更轻松地对各种集合进行迭代： String script = \u0026#34;var list = [1, 2, 3, 4, 5];\u0026#34; + \u0026#34;var result = \u0026#39;\u0026#39;;\u0026#34; + \u0026#34;for each (var i in list) {\u0026#34; + \u0026#34;result+=i+\u0026#39;-\u0026#39;;\u0026#34; + \u0026#34;};\u0026#34; + \u0026#34;print(result);\u0026#34;; engine.eval(script); 在这里，我们使用for-each迭代构造连接数组的元素。 结果输出将是1-2-3-4-5-。 7.2. 函数字面量 在简单的函数声明中，您可以省略花括号： function increment(in) ++in 显然，这只能用于简单的单行函数。 7.3. 条件捕获子句 可以添加仅在指定条件为真时才执行的受保护的 catch 子句： try { throw \u0026#34;BOOM\u0026#34;; } catch(e if typeof e === \u0026#39;string\u0026#39;) { print(\u0026#34;String thrown: \u0026#34; + e); } catch(e) { print(\u0026#34;this shouldn\u0026#39;t happen!\u0026#34;); } 这将打印“抛出的字符串：BOOM ”。 7.4. 类型化数组和类型转换 可以使用 Java 类型数组并与 JavaScript 数组相互转换： function arrays(arr) { var javaIntArray = Java.to(arr, \u0026#34;int[]\u0026#34;); print(javaIntArray[0]); print(javaIntArray[1]); print(javaIntArray[2]); } Nashorn在此处执行一些类型转换，以确保来自动态类型 JavaScript 数组的所有值都可以放入纯整数 Java 数组中。 *使用参数[100, “1654”, true]*调用上述函数的结果是输出 100、1654 和 1（所有数字）。 字符串和布尔值被隐式转换为它们的逻辑整数对应物。 7.5。使用Object.setPrototypeOf设置对象的原型 Nashorn定义了一个 API 扩展，使我们能够更改对象的原型： Object.setPrototypeOf(obj, newProto) 此函数通常被认为是*Object.prototype.__proto__*的更好替代方法，因此它应该是在所有新代码中设置对象原型的首选方法。 7.6. 神奇的__noSuchProperty__和__noSuchMethod__ ** 可以在对象上定义方法，只要访问未定义的属性或调用未定义的方法，就会调用这些方法： var demo = { __noSuchProperty__: function (propName) { print(\u0026#34;Accessed non-existing property: \u0026#34; + propName); }, __noSuchMethod__: function (methodName) { print(\u0026#34;Invoked non-existing method: \u0026#34; + methodName); } }; demo.doesNotExist; demo.callNonExistingMethod() 这将打印： Accessed non-existing property: doesNotExist Invoked non-existing method: callNonExistingMethod 7.7. 使用Object.bindProperties绑定对象属性 Object.bindProperties可用于将属性从一个对象绑定到另一个对象： var first = { name: \u0026#34;Whiskey\u0026#34;, age: 5 }; var second = { volume: 100 }; Object.bindProperties(first, second); print(first.volume); second.volume = 1000; print(first.volume); 请注意，这创建的是一个“实时”绑定，并且对源对象的任何更新也通过绑定目标可见。 7.8. 地点 当前文件名、目录和行可以从全局变量*__FILE__、__DIR__、__LINE__中获取：* print(__FILE__, __LINE__, __DIR__) 7.9 String.prototype 的扩展 Nashorn在String原型上提供了两个简单但非常有用的扩展。这些是trimRight和trimLeft函数，不出所料，它们返回删除空格的String的副本： print(\u0026#34; hello world\u0026#34;.trimLeft()); print(\u0026#34;hello world \u0026#34;.trimRight()); 将打印两次“hello world”，没有前导或尾随空格。 7.10 Java.asJSON兼容函数 使用这个函数，我们可以获得一个与 Java JSON 库期望兼容的对象。 也就是说，如果它本身，或任何通过它可传递到达的对象是一个 JavaScript 数组，那么这些对象将作为JSObject公开，该 JSObject 也实现了用于公开数组元素的List接口。 Object obj = engine.eval(\u0026#34;Java.asJSONCompatible( { number: 42, greet: \u0026#39;hello\u0026#39;, primes: [2,3,5,7,11,13] })\u0026#34;); Map\u0026lt;String, Object\u0026gt; map = (Map\u0026lt;String, Object\u0026gt;)obj; System.out.println(map.get(\u0026#34;greet\u0026#34;)); System.out.println(map.get(\u0026#34;primes\u0026#34;)); System.out.println(List.class.isAssignableFrom(map.get(\u0026#34;primes\u0026#34;).getClass())); 这将打印“ hello ”，然后是*[2, 3, 5, 7, 11, 13]，然后是true。* 8. 加载脚本 也可以从ScriptEngine加载另一个 JavaScript 文件： load(\u0026#39;classpath:script.js\u0026#39;) 也可以从 URL 加载脚本： load(\u0026#39;/script.js\u0026#39;) 请记住，JavaScript 没有命名空间的概念，因此所有内容都堆积在全局范围内。这使得加载的脚本可能与您的代码或彼此之间产生命名冲突。这可以通过使用loadWithNewGlobal函数来缓解： var math = loadWithNewGlobal(\u0026#39;classpath:math_module.js\u0026#39;) math.increment(5); 使用以下math_module.js： var math = { increment: function(num) { return ++num; } }; math;bai 在这里，我们定义了一个名为math的对象，它有一个名为*increment 的函数。*使用这种范式，我们甚至可以模拟基本的模块化！ \u0026quot; ","permalink":"http://itcodingman.github.io/java_nashorn/","tags":[],"title":"Nashorn 简介"},{"categories":["Java"],"contents":"1. 概述 有时我们需要知道当前正在执行的 Java 方法的名称。 这篇快速文章介绍了几种在当前执行堆栈中获取方法名称的简单方法。 2. Java 9：堆栈行走 API **Java 9 引入了Stack-Walking API以一种惰性且高效的方式遍历 JVM 堆栈帧。**为了使用这个 API 找到当前正在执行的方法，我们可以编写一个简单的测试： public void givenJava9_whenWalkingTheStack_thenFindMethod() { StackWalker walker = StackWalker.getInstance(); Optional\u0026lt;String\u0026gt; methodName = walker.walk(frames -\u0026gt; frames .findFirst() .map(StackWalker.StackFrame::getMethodName)); assertTrue(methodName.isPresent()); assertEquals(\u0026#34;givenJava9_whenWalkingTheStack_thenFindMethod\u0026#34;, methodName.get()); } 首先，我们 使用*getInstance()工厂方法获得一个StackWalker实例 。然后我们使用walk()*方法从上到下遍历栈帧：  *walk()*方法可以将 堆栈帧流 - *Stream\u0026lt; StackFrame \u0026gt; -*转换为任何东西 给定流中的第一个元素是栈顶帧 栈顶帧总是代表当前正在执行的方法  因此，如果我们从流中获取第一个元素，我们就会知道当前正在执行的方法的详细信息。更具体地说，我们可以使用StackFrame.getMethodName()来查找方法名称。 2.1 优点 与其他方法相比（稍后会详细介绍），Stack-Walking API 有几个优点：  无需创建虚拟匿名内部类实例 — new Object().getClass() {} 无需创建虚拟异常 — new Throwable() 无需急切地捕获整个堆栈跟踪，这可能会很昂贵  相反， StackWalker只是以一种懒惰的方式逐个遍历堆栈。在这种情况下，它只获取顶部帧，而不是堆栈跟踪方法，它急切地捕获所有帧。 最重要的是，如果您使用的是 Java 9+，请使用 Stack-Walking API。 3.使用getEnclosureMethod 我们可以使用getEnclosureMethod() API找到正在执行的方法的名称： public void givenObject_whenGetEnclosingMethod_thenFindMethod() { String methodName = new Object() {} .getClass() .getEnclosingMethod() .getName(); assertEquals(\u0026#34;givenObject_whenGetEnclosingMethod_thenFindMethod\u0026#34;, methodName); } 4. 使用Throwable Stack Trace 使用Throwable堆栈跟踪为我们提供了当前正在执行的方法的堆栈跟踪： public void givenThrowable_whenGetStacktrace_thenFindMethod() { StackTraceElement[] stackTrace = new Throwable().getStackTrace(); assertEquals( \u0026#34;givenThrowable_whenGetStacktrace_thenFindMethod\u0026#34;, stackTrace[0].getMethodName()); } 5. 使用线程堆栈跟踪 此外，当前线程（从 JDK 1.5 开始）的堆栈跟踪通常包括正在执行的方法的名称： public void givenCurrentThread_whenGetStackTrace_thenFindMethod() { StackTraceElement[] stackTrace = Thread.currentThread() .getStackTrace(); assertEquals( \u0026#34;givenCurrentThread_whenGetStackTrace_thenFindMethod\u0026#34;, stackTrace[1].getMethodName()); } 但是，我们需要记住，这种解决方案有一个明显的缺点。一些虚拟机可能会跳过一个或多个堆栈帧。虽然这并不常见，但我们应该意识到这可能会发生。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_name_of_executing_method/","tags":["Core Java"],"title":"如何获取正在执行的方法的名称？"},{"categories":["Java","Youtube"],"contents":"20分钟学习Tomcat   ","permalink":"http://itcodingman.github.io/20_mins_tomcat/","tags":[],"title":"20分钟学习Tomcat"},{"categories":["Java Concurrency"],"contents":"1. 概述 在本教程中，我们将看到**在Java中实现互斥锁**的不同方法。 2. 互斥体 在多线程应用程序中，两个或多个线程可能需要同时访问共享资源，从而导致意外行为。这种共享资源的例子是数据结构、输入输出设备、文件和网络连接。 我们称这种情况为竞争条件。并且，访问共享资源的程序部分称为临界区。因此，为了避免竞争条件，我们需要同步对临界区的访问。 互斥锁（或互斥锁）是最简单的同步器类型——它确保一次只有一个线程可以执行计算机程序的关键部分。 要访问临界区，线程先获取互斥锁，然后访问临界区，最后释放互斥锁。与此同时，**所有其他线程都会阻塞，直到互斥锁释放。**只要一个线程退出临界区，另一个线程就可以进入临界区。 3. 为什么是互斥锁？ 首先，我们举一个SequenceGeneror类的例子，它通过每次将currentValue加一来生成下一个序列： public class SequenceGenerator { private int currentValue = 0; public int getNextSequence() { currentValue = currentValue + 1; return currentValue; } } 现在，让我们创建一个测试用例，看看当多个线程尝试同时访问该方法时该方法的行为： @Test public void givenUnsafeSequenceGenerator_whenRaceCondition_thenUnexpectedBehavior() throws Exception { int count = 1000; Set\u0026lt;Integer\u0026gt; uniqueSequences = getUniqueSequences(new SequenceGenerator(), count); Assert.assertEquals(count, uniqueSequences.size()); } private Set\u0026lt;Integer\u0026gt; getUniqueSequences(SequenceGenerator generator, int count) throws Exception { ExecutorService executor = Executors.newFixedThreadPool(3); Set\u0026lt;Integer\u0026gt; uniqueSequences = new LinkedHashSet\u0026lt;\u0026gt;(); List\u0026lt;Future\u0026lt;Integer\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; count; i++) { futures.add(executor.submit(generator::getNextSequence)); } for (Future\u0026lt;Integer\u0026gt; future : futures) { uniqueSequences.add(future.get()); } executor.awaitTermination(1, TimeUnit.SECONDS); executor.shutdown(); return uniqueSequences; } 一旦我们执行了这个测试用例，我们可以看到它大部分时间都失败了，原因类似于： java.lang.AssertionError: expected:\u0026lt;1000\u0026gt; but was:\u0026lt;989\u0026gt; at org.junit.Assert.fail(Assert.java:88) at org.junit.Assert.failNotEquals(Assert.java:834) at org.junit.Assert.assertEquals(Assert.java:645) uniqueSequences的大小应该等于我们在测试用例中执行*getNextSequence方法的次数。*但是，由于竞争条件，情况并非如此。显然，我们不希望这种行为。 因此，为了避免这种竞争条件，我们需要确保一次只有一个线程可以执行getNextSequence方法。在这种情况下，我们可以使用互斥锁来同步线程。 有多种方法，我们可以在 Java 中实现互斥锁。所以，接下来，我们将看到为我们的SequenceGenerator类实现互斥锁的不同方法。 4. 使用synchronized关键字 首先，我们将讨论synchronized关键字，这是在 Java 中实现互斥锁的最简单方法。 Java 中的每个对象都有一个与之关联的内在锁。synchronized方法和synchronized块使用这种内在锁来限制对临界区的访问一次只能访问一个线程。 因此，当线程调用synchronized方法或进入synchronized块时，它会自动获取锁。当方法或块完成或从它们抛出异常时，锁会释放。 让我们将 getNextSequence更改为具有互斥锁，只需添加synchronized关键字： public class SequenceGeneratorUsingSynchronizedMethod extends SequenceGenerator { @Override public synchronized int getNextSequence() { return super.getNextSequence(); } } synchronized块类似于synchronized方法，对临界区和我们可以用于锁定的对象有更多的控制。 那么，现在让我们看看如何使用synchronized块在自定义互斥对象上进行同步： public class SequenceGeneratorUsingSynchronizedBlock extends SequenceGenerator { private Object mutex = new Object(); @Override public int getNextSequence() { synchronized (mutex) { return super.getNextSequence(); } } } 5. 使用ReentrantLock ReentrantLock 类是在 Java 1.5 中引入的。与同步关键字方法相比，它提供了更多的灵活性和控制力。 让我们看看如何使用ReentrantLock来实现互斥： public class SequenceGeneratorUsingReentrantLock extends SequenceGenerator { private ReentrantLock mutex = new ReentrantLock(); @Override public int getNextSequence() { try { mutex.lock(); return super.getNextSequence(); } finally { mutex.unlock(); } } } 6. 使用Semaphore 与ReentrantLock一样，Semaphore 类也在 Java 1.5 中引入。 在互斥锁的情况下，只有一个线程可以访问临界区，而信号量允许固定数量的线程访问临界区。因此，我们还可以通过将Semaphore中允许的线程数设置为1来实现互斥锁。 现在让我们使用Semaphore创建另一个线程安全的SequenceGenerator版本： public class SequenceGeneratorUsingSemaphore extends SequenceGenerator { private Semaphore mutex = new Semaphore(1); @Override public int getNextSequence() { try { mutex.acquire(); return super.getNextSequence(); } catch (InterruptedException e) { // exception handling code  } finally { mutex.release(); } } } 7. 使用 Guava 的Monitor类 到目前为止，我们已经看到了使用 Java 提供的特性来实现互斥锁的选项。 但是，Google 的 Guava 库的Monitor类是ReentrantLock类的更好替代品。根据其文档，使用Monitor的代码比使用ReentrantLock的代码更具可读性且不易出错。 首先，我们将为Guava添加 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;31.0.1-jre\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在，我们将使用Monitor类编写SequenceGenerator的另一个子类： public class SequenceGeneratorUsingMonitor extends SequenceGenerator { private Monitor mutex = new Monitor(); @Override public int getNextSequence() { mutex.enter(); try { return super.getNextSequence(); } finally { mutex.leave(); } } } \u0026quot; ","permalink":"http://itcodingman.github.io/java_mutex/","tags":[],"title":"在 Java 中使用互斥对象"},{"categories":["Testing"],"contents":"1. 概述 软件测试是指用于评估软件应用程序功能的技术。在本文中，我们将讨论软件测试行业中使用的一些指标，例如代码覆盖率和变异测试，并对如何使用PITest 库执行变异测试特别感兴趣。 为了简单起见，我们将这个演示基于一个基本的回文函数——请注意，回文是一个向后和向前读取相同的字符串。 2. Maven依赖 正如您在 Maven 依赖项配置中所见，我们将使用 JUnit 来运行我们的测试，并使用PITest库将突变体引入我们的代码中——别担心，我们马上就会看到突变体是什么。您始终可以通过以下链接查找针对 maven 中央存储库的最新依赖项版本。 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.pitest\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pitest-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.10\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt; 为了让 PITest 库启动并运行，我们还需要在pom.xml配置文件中包含Pitest-maven插件： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.pitest\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pitest-maven\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.10\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;targetClasses\u0026gt; \u0026lt;param\u0026gt;com.codingman.testing.mutation.*\u0026lt;/param\u0026gt; \u0026lt;/targetClasses\u0026gt; \u0026lt;targetTests\u0026gt; \u0026lt;param\u0026gt;com.codingman.mutation.test.*\u0026lt;/param\u0026gt; \u0026lt;/targetTests\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 3. 项目设置 现在我们已经配置了 Maven 依赖项，让我们看看这个不言自明的回文函数： public boolean isPalindrome(String inputString) { if (inputString.length() == 0) { return true; } else { char firstChar = inputString.charAt(0); char lastChar = inputString.charAt(inputString.length() - 1); String mid = inputString.substring(1, inputString.length() - 1); return (firstChar == lastChar) \u0026amp;\u0026amp; isPalindrome(mid); } } 我们现在需要的是一个简单的 JUnit 测试，以确保我们的实现以所需的方式工作： @Test public void whenPalindrom_thenAccept() { Palindrome palindromeTester = new Palindrome(); assertTrue(palindromeTester.isPalindrome(\u0026#34;noon\u0026#34;)); } 到目前为止一切顺利，我们已准备好将测试用例作为 JUnit 测试成功运行。 接下来，在本文中，我们将重点关注使用 PITest 库的代码和变异覆盖率。 4. 代码覆盖率 代码覆盖率已在软件行业广泛使用，以衡量在自动化测试期间执行路径的百分比。 我们可以使用Eclipse IDE 上提供的Eclemma 等工具，根据执行路径测量有效的代码覆盖率。 在运行具有代码覆盖率的TestPalindrome之后，我们可以轻松地获得 100% 的覆盖率分数——注意isPalindrome是递归的，因此很明显空输入长度检查无论如何都会被覆盖。 不幸的是，代码覆盖率指标有时可能非常无效，因为 100% 的代码覆盖率分数仅意味着所有行都至少执行了一次，但它没有说明测试准确性或用例完整性，这就是突变测试真正重要的原因。 5. 突变覆盖率 突变测试是一种用于提高测试充分性和识别代码缺陷的测试技术。这个想法是动态更改生产代码并导致测试失败。  好的测试会失败  代码中的每次更改都称为突变，它会导致程序的更改版本，称为突变。 我们说如果突变会导致测试失败，则该突变被杀死。我们还说，如果突变体不能影响测试的行为，那么突变体就会存活下来。 现在让我们使用 Maven 运行测试，目标选项设置为：org.pitest:pitest-maven:mutationCoverage。 我们可以在target/pit-test/YYYYMMDDHHMI目录下查看 HTML 格式的报告：  100% 线路覆盖率：7/7 63% 突变覆盖率：5/8  显然，我们的测试扫描了所有的执行路径，因此，线路覆盖率是 100%。另一方面，PITest 库引入了8 个突变体，其中 5 个被杀死——导致失败——但 3 个幸存下来。 我们可以查看com.codingman.testing.mutation/Palindrome.java.html报告以获取有关创建的突变体的更多详细信息： 这些是运行变异覆盖测试时默认激活的变异器：  INCREMENTS_MUTATOR VOID_METHOD_CALL_MUTATOR RETURN_VALS_MUTATOR MATH_MUTATOR NEGATE_CONDITIONALS_MUTATOR INVERT_NEGS_MUTATOR CONDITIONALS_BOUNDARY_MUTATOR  有关 PITest 突变器的更多详细信息，您可以查看官方**文档页面**链接。 我们的变异覆盖率分数反映了测试用例的缺乏，因为我们无法确保我们的回文函数拒绝非回文和近回文字符串输入。 6. 提高突变分数 现在我们知道什么是突变，我们需要通过杀死幸存的突变体来提高我们的突变分数。 让我们以第 6 行的第一个突变 - 否定条件 - 为例。突变体幸存下来，因为即使我们更改代码片段： if (inputString.length() == 0) { return true; } 至： if (inputString.length() != 0) { return true; } 测试会通过，这就是突变存活的原因。这个想法是实施一个新的测试，如果引入了突变体，它将失败。对剩余的突变体也可以这样做。 @Test public void whenNotPalindrom_thanReject() { Palindrome palindromeTester = new Palindrome(); assertFalse(palindromeTester.isPalindrome(\u0026#34;box\u0026#34;)); } @Test public void whenNearPalindrom_thanReject() { Palindrome palindromeTester = new Palindrome(); assertFalse(palindromeTester.isPalindrome(\u0026#34;neon\u0026#34;)); } 现在我们可以使用突变覆盖插件运行我们的测试，以确保所有突变都被杀死，正如我们在目标目录中生成的 PITest 报告中看到的那样。  100% 线路覆盖率：7/7 100% 突变覆盖率：8/8  7. PITest 测试配置 突变测试有时可能会占用大量资源，因此我们需要进行适当的配置以提高测试效率。我们可以使用targetClasses标签来定义要变异的类列表。变异测试不能应用于现实世界项目中的所有类，因为它既费时又对资源至关重要。 定义您计划在变异测试期间使用的变异器也很重要，以最大限度地减少执行测试所需的计算资源： \u0026lt;configuration\u0026gt; \u0026lt;targetClasses\u0026gt; \u0026lt;param\u0026gt;com.codingman.testing.mutation.*\u0026lt;/param\u0026gt; \u0026lt;/targetClasses\u0026gt; \u0026lt;targetTests\u0026gt; \u0026lt;param\u0026gt;com.codingman.mutation.test.*\u0026lt;/param\u0026gt; \u0026lt;/targetTests\u0026gt; \u0026lt;mutators\u0026gt; \u0026lt;mutator\u0026gt;CONSTRUCTOR_CALLS\u0026lt;/mutator\u0026gt; \u0026lt;mutator\u0026gt;VOID_METHOD_CALLS\u0026lt;/mutator\u0026gt; \u0026lt;mutator\u0026gt;RETURN_VALS\u0026lt;/mutator\u0026gt; \u0026lt;mutator\u0026gt;NON_VOID_METHOD_CALLS\u0026lt;/mutator\u0026gt; \u0026lt;/mutators\u0026gt; \u0026lt;/configuration\u0026gt; 此外，PITest 库提供了多种可用于自定义测试策略的选项，例如，您可以使用maxMutationsPerClass选项指定类引入的最大突变数。有关 PITest 选项的更多详细信息，请参阅官方**Maven 快速入门指南**。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mutation_testing_with_pitest/","tags":[],"title":"使用 PITest 进行突变测试"},{"categories":["Data","Java"],"contents":"1. 概述 在本文中，我们将研究*Multiverse* 库——它帮助我们在 Java中实现软件事务内存的概念。 使用这个库中的构造，我们可以创建一个共享状态的同步机制——这比使用 Java 核心库的标准实现更优雅、更易读。 2. Maven依赖 首先，我们需要将multiverse-core库添加到我们的 pom 中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.multiverse\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;multiverse-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.7.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Multiverse API 让我们从一些基础知识开始。 软件事务内存 (STM) 是从 SQL 数据库世界移植的概念——每个操作都在满足*ACID（原子性、一致性、隔离性、持久性）*属性的事务中执行。这里只满足原子性、一致性和隔离性，因为该机制在内存中运行。 **Multiverse 库中的主要接口是TxnObject——**每个事务对象都需要实现它，并且该库为我们提供了许多可以使用的特定子类。 每个需要放在关键部分中的操作，只能由一个线程访问并使用任何事务对象 - 需要包装在*StmUtils.atomic()*方法中。临界区是程序中不能由多个线程同时执行的地方，因此对它的访问应该受到某种同步机制的保护。 如果一个事务中的一个动作成功了，这个事务将被提交，并且新的状态将可以被其他线程访问。如果发生一些错误，事务将不会被提交，因此状态不会改变。 最后，如果两个线程想要修改事务中的相同状态，则只有一个线程会成功并提交其更改。下一个线程将能够在其事务中执行其操作。 4. 使用STM实现账户逻辑 现在让我们看一个例子。 假设我们要使用Multiverse库提供的 STM 创建银行账户逻辑。我们的Account对象将具有 TxnLong 类型的lastUpadate时间戳，以及存储给定帐户当前余额的balance字段，并且是TxnInteger类型。 TxnLong和TxnInteger是来自Multiverse的类。它们必须在事务中执行。否则会抛出异常。我们需要使用StmUtils来创建事务对象的新实例： public class Account { private TxnLong lastUpdate; private TxnInteger balance; public Account(int balance) { this.lastUpdate = StmUtils.newTxnLong(System.currentTimeMillis()); this.balance = StmUtils.newTxnInteger(balance); } } 接下来，我们将创建*adjustBy()*方法——它将余额增加给定的数量。该操作需要在事务中执行。 如果在其中抛出任何异常，事务将结束而不提交任何更改： public void adjustBy(int amount) { adjustBy(amount, System.currentTimeMillis()); } public void adjustBy(int amount, long date) { StmUtils.atomic(() -\u0026gt; { balance.increment(amount); lastUpdate.set(date); if (balance.get() \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Not enough money\u0026#34;); } }); } 如果我们想获取给定账户的当前余额，我们需要从 balance 字段中获取值，但也需要使用原子语义来调用它： public Integer getBalance() { return balance.atomicGet(); } 5. 测试账户 让我们测试一下我们的Account逻辑。首先，我们想简单地从账户中减去给定的余额： @Test public void givenAccount_whenDecrement_thenShouldReturnProperValue() { Account a = new Account(10); a.adjustBy(-5); assertThat(a.getBalance()).isEqualTo(5); } 接下来，假设我们从账户中提款，余额为负数。该操作应引发异常，并保持帐户完好无损，因为该操作是在事务中执行且未提交： @Test(expected = IllegalArgumentException.class) public void givenAccount_whenDecrementTooMuch_thenShouldThrow() { // given  Account a = new Account(10); // when  a.adjustBy(-11); } 现在让我们测试两个线程同时减少余额时可能出现的并发问题。 如果一个线程想要将其减少 5，而第二个线程想要减少 6，那么这两个操作之一应该会失败，因为给定帐户的当前余额等于 10。 我们将向ExecutorService提交两个线程，并使用CountDownLatch同时启动它们： ExecutorService ex = Executors.newFixedThreadPool(2); Account a = new Account(10); CountDownLatch countDownLatch = new CountDownLatch(1); AtomicBoolean exceptionThrown = new AtomicBoolean(false); ex.submit(() -\u0026gt; { try { countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } try { a.adjustBy(-6); } catch (IllegalArgumentException e) { exceptionThrown.set(true); } }); ex.submit(() -\u0026gt; { try { countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } try { a.adjustBy(-5); } catch (IllegalArgumentException e) { exceptionThrown.set(true); } }); 同时盯着两个动作后，其中一个会抛出异常： countDownLatch.countDown(); ex.awaitTermination(1, TimeUnit.SECONDS); ex.shutdown(); assertTrue(exceptionThrown.get()); 6. 从一个帐户转移到另一个帐户 假设我们想将钱从一个帐户转移到另一个帐户。我们可以在Account类上实现**transferTo()方法，方法是传递我们要向其转账给定金额的另一个Account ： public void transferTo(Account other, int amount) { StmUtils.atomic(() -\u0026gt; { long date = System.currentTimeMillis(); adjustBy(-amount, date); other.adjustBy(amount, date); }); } 所有逻辑都在事务中执行。这将保证当我们想要转移高于给定账户余额的金额时，两个账户都将完好无损，因为交易不会提交。 让我们测试传输逻辑： Account a = new Account(10); Account b = new Account(10); a.transferTo(b, 5); assertThat(a.getBalance()).isEqualTo(5); assertThat(b.getBalance()).isEqualTo(15); 我们只需创建两个帐户，将资金从一个帐户转移到另一个帐户，一切都按预期进行。接下来，假设我们要转帐比帐户上可用的更多的钱。*transferTo()*调用将抛出IllegalArgumentException *，*并且不会提交更改： try { a.transferTo(b, 20); } catch (IllegalArgumentException e) { System.out.println(\u0026#34;failed to transfer money\u0026#34;); } assertThat(a.getBalance()).isEqualTo(5); assertThat(b.getBalance()).isEqualTo(15); 请注意，a和b帐户的余额与调用*transferTo()*方法之前的余额相同。 7. STM 是死锁安全的 当我们使用标准的 Java 同步机制时，我们的逻辑很容易出现死锁，无法从中恢复。 当我们想将钱从账户a转移到账户b时，就会发生死锁。在标准 Java 实现中，一个线程需要锁定帐户a，然后锁定帐户b。假设同时，另一个线程想要将钱从账户b转移到账户a。另一个线程锁定帐户b等待帐户a被解锁。 不幸的是，账户a的锁由第一个线程持有，而账户b的锁由第二个线程持有。这种情况会导致我们的程序无限期阻塞。 幸运的是，当使用 STM 实现*transferTo()逻辑时，我们不需要担心死锁，因为 STM 是死锁安全的。让我们使用我们的transferTo()*方法进行测试。 假设我们有两个线程。第一个线程想从账户a向账户b转移一些钱，第二个线程想从账户b向账户a转移一些钱。我们需要创建两个帐户并启动两个线程，它们将同时执行*transferTo()*方法： ExecutorService ex = Executors.newFixedThreadPool(2); Account a = new Account(10); Account b = new Account(10); CountDownLatch countDownLatch = new CountDownLatch(1); ex.submit(() -\u0026gt; { try { countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } a.transferTo(b, 10); }); ex.submit(() -\u0026gt; { try { countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } b.transferTo(a, 1); }); 开始处理后，两个帐户都将具有正确的余额字段： countDownLatch.countDown(); ex.awaitTermination(1, TimeUnit.SECONDS); ex.shutdown(); assertThat(a.getBalance()).isEqualTo(1); assertThat(b.getBalance()).isEqualTo(19); \u0026quot; ","permalink":"http://itcodingman.github.io/java_multiverse_stm/","tags":[],"title":"使用 Multiverse 的 Java 软件事务内存"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将学习如何在 Java 中声明多行字符串。 现在 Java 15 已经发布，我们可以使用称为文本块的新本机功能。 如果我们不能使用此功能，我们还将审查其他方法。 2. 文本块 我们可以通过使用**\u0026quot;\u0026quot;\u0026quot;（三个双引号）**声明字符串来使用文本块： public String textBlocks() { return \u0026#34;\u0026#34;\u0026#34; Get busy living or get busy dying. --Stephen King\u0026#34;\u0026#34;\u0026#34;; } 到目前为止，这是声明多行字符串的最方便的方法。实际上，我们不必处理行分隔符或缩进空格，正如我们在专门文章中所读到的那样。 此功能在 Java 15 中可用，如果我们启用预览功能，则在 Java 13 和 14 中也可用。 在接下来的章节中，如果我们使用 Java 的早期版本或Text 块不适用，我们将回顾其他合适的方法。 3. 获取线分隔符 每个操作系统都可以有自己的方式来定义和识别新行。在 Java 中，很容易获得操作系统的行分隔符： String newLine = System.getProperty(\u0026#34;line.separator\u0026#34;); 我们将在以下部分中使用这个newLine来创建多行字符串。 4. 字符串连接 字符串连接是一种简单的本地方法，可用于创建多行字符串： public String stringConcatenation() { return \u0026#34;Get busy living\u0026#34; .concat(newLine) .concat(\u0026#34;or\u0026#34;) .concat(newLine) .concat(\u0026#34;get busy dying.\u0026#34;) .concat(newLine) .concat(\u0026#34;--Stephen King\u0026#34;); } 使用 + 运算符是实现相同目的的另一种方法。Java 编译器以相同的方式翻译*concat()*和 + 运算符： public String stringConcatenation() { return \u0026#34;Get busy living\u0026#34; + newLine + \u0026#34;or\u0026#34; + newLine + \u0026#34;get busy dying.\u0026#34; + newLine + \u0026#34;--Stephen King\u0026#34;; } 5. 字符串连接 Java 8 引入了String#join，它采用分隔符和一些字符串作为参数。它返回一个最终字符串，其中所有输入字符串与分隔符连接在一起： public String stringJoin() { return String.join(newLine, \u0026#34;Get busy living\u0026#34;, \u0026#34;or\u0026#34;, \u0026#34;get busy dying.\u0026#34;, \u0026#34;--Stephen King\u0026#34;); } 6. StringBuilder StringBuilder是构建String的辅助类。StringBuilder是在 Java 1.5 中引入的，作为StringBuffer的替代品。在循环中构建巨大的字符串是一个不错的选择： public String stringBuilder() { return new StringBuilder() .append(\u0026#34;Get busy living\u0026#34;) .append(newLine) .append(\u0026#34;or\u0026#34;) .append(newLine) .append(\u0026#34;get busy dying.\u0026#34;) .append(newLine) .append(\u0026#34;--Stephen King\u0026#34;) .toString(); } 7. StringWriter StringWriter是我们可以用来创建多行字符串的另一种方法。我们在这里不需要newLine，因为我们使用PrintWriter。println函数自动添加新行： public String stringWriter() { StringWriter stringWriter = new StringWriter(); PrintWriter printWriter = new PrintWriter(stringWriter); printWriter.println(\u0026#34;Get busy living\u0026#34;); printWriter.println(\u0026#34;or\u0026#34;); printWriter.println(\u0026#34;get busy dying.\u0026#34;); printWriter.println(\u0026#34;--Stephen King\u0026#34;); return stringWriter.toString(); } 8. Guava Joiner 仅将外部库用于这样的简单任务没有多大意义，但是，如果项目已经将该库用于其他目的，我们可以使用它。例如，Google 的 Guava 库非常受欢迎。Guava 有一个Joiner类，它能够构建多行字符串： public String guavaJoiner() { return Joiner.on(newLine).join(ImmutableList.of(\u0026#34;Get busy living\u0026#34;, \u0026#34;or\u0026#34;, \u0026#34;get busy dying.\u0026#34;, \u0026#34;--Stephen King\u0026#34;)); } 9. 从文件加载 Java 完全按原样读取文件。这意味着，如果我们在文本文件中有一个多行字符串，那么在读取文件时我们将拥有相同的字符串。在 Java中有很多方法可以从文件中读取。 实际上，将长字符串与代码分开是一种很好的做法： public String loadFromFile() throws IOException { return new String(Files.readAllBytes(Paths.get(\u0026#34;src/main/resources/stephenking.txt\u0026#34;))); } 10. 使用 IDE 功能 许多现代 IDE 支持多行复制/粘贴。Eclipse 和 IntelliJ IDEA 就是此类 IDE 的示例。我们可以简单地复制我们的多行字符串并粘贴到这些 IDE 中的两个双引号内。 显然，此方法不适用于运行时创建字符串，但它是获取多行字符串的一种快速简便的方法。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_multiline_string/","tags":["Java String"],"title":"Java 多行字符串"},{"categories":["Algorithms"],"contents":"1. 简介 在本文中，我们将了解多群优化算法。与同一类的其他算法一样，其目的是通过最大化或最小化特定函数（称为适应度函数）来找到问题的最佳解决方案。 让我们从一些理论开始。 2. 多群优化的工作原理 Multi-swarm 是Swarm算法的一种变体。顾名思义，**Swarm 算法通过模拟一组对象在可能解空间中的运动来解决问题。**在多群版本中，有多个群而不是只有一个群。 群体的基本组成部分称为粒子。粒子由它的实际位置和它的速度来定义，这也是我们问题的一种可能的解决方案，它用于计算下一个位置。 粒子的速度不断变化，以一定的随机性向所有粒子群中所有粒子中找到的最佳位置倾斜，以增加覆盖的空间量。 这最终会导致大多数粒子到达有限的一组点，这些点是适应度函数中的局部最小值或最大值，这取决于我们是试图最小化还是最大化它。 尽管找到的点始终是函数的局部最小值或最大值，但它不一定是全局点，因为不能保证算法已经完全探索了解的空间。 出于这个原因，多群体被称为元启发式——它找到的解决方案是最好的，但它们可能不是绝对最好的。 3. 实施 现在我们知道了多群是什么以及它是如何工作的，让我们来看看如何实现它。 对于我们的示例，我们将尝试解决StackExchange 上发布的这个现实优化问题：  在英雄联盟中，玩家在防御物理伤害时的有效生命值由E=H(100+A)/100给出，其中H是生命值，A是护甲。 健康每单位花费 2.5 金币，护甲每单位花费 18 金币。你有3600金币，你需要优化你的生命值和护甲的效率E，以尽可能长时间地抵抗敌方队伍的攻击。你应该买多少？  3.1 粒子 我们首先对我们的基本构造（粒子）进行建模。粒子的状态包括其当前位置，即解决问题的一对生命值和护甲值、粒子在两个轴上的速度和粒子适应度得分。 我们还将存储我们找到的最佳位置和适应度分数，因为我们需要它们来更新粒子速度： public class Particle { private long[] position; private long[] speed; private double fitness; private long[] bestPosition;\tprivate double bestFitness = Double.NEGATIVE_INFINITY; // constructors and other methods } 我们选择使用长数组来表示速度和位置，因为我们可以从问题陈述中推断出我们不能购买部分盔甲或健康，因此解决方案必须在整数域中。 我们不想使用int，因为这会导致计算过程中出现溢出问题。 3.2. 一群 接下来，让我们将群体定义为粒子的集合。再一次，我们还将存储历史最佳位置和得分以供以后计算。 群体还需要通过为每个粒子分配一个随机的初始位置和速度来处理其粒子的初始化。 我们可以粗略估计解决方案的边界，因此我们将这个限制添加到随机数生成器中。 这将减少运行算法所需的计算能力和时间： public class Swarm { private Particle[] particles; private long[] bestPosition; private double bestFitness = Double.NEGATIVE_INFINITY; public Swarm(int numParticles) { particles = new Particle[numParticles]; for (int i = 0; i \u0026lt; numParticles; i++) { long[] initialParticlePosition = { random.nextInt(Constants.PARTICLE_UPPER_BOUND), random.nextInt(Constants.PARTICLE_UPPER_BOUND) }; long[] initialParticleSpeed = { random.nextInt(Constants.PARTICLE_UPPER_BOUND), random.nextInt(Constants.PARTICLE_UPPER_BOUND) }; particles[i] = new Particle( initialParticlePosition, initialParticleSpeed); } } // methods omitted } 3.3. 多群 最后，让我们通过创建一个 Multiswarm 类来结束我们的模型。 与群类似，我们将跟踪群的集合以及在所有群中找到的最佳粒子位置和适应度。 我们还将存储对适应度函数的引用以供以后使用： public class Multiswarm { private Swarm[] swarms; private long[] bestPosition; private double bestFitness = Double.NEGATIVE_INFINITY; private FitnessFunction fitnessFunction; public Multiswarm( int numSwarms, int particlesPerSwarm, FitnessFunction fitnessFunction) { this.fitnessFunction = fitnessFunction; this.swarms = new Swarm[numSwarms]; for (int i = 0; i \u0026lt; numSwarms; i++) { swarms[i] = new Swarm(particlesPerSwarm); } } // methods omitted } 3.4. 适应度函数 现在让我们实现适应度函数。 为了将算法逻辑与这个特定问题解耦，我们将引入一个具有单一方法的接口。 此方法将粒子位置作为参数，并返回一个表明它有多好的值： public interface FitnessFunction { public double getFitness(long[] particlePosition); } 假设根据问题约束找到的结果是有效的，测量适应度只是返回我们想要最大化的计算的有效健康度的问题。 对于我们的问题，我们有以下特定的验证约束：  解决方案只能是正整数 在提供的黄金数量下，解决方案必须是可行的  当违反这些约束之一时，我们返回一个负数，表明我们离有效性边界有多远。 这是在前一种情况下找到的数字或在后一种情况下不可用的黄金数量： public class LolFitnessFunction implements FitnessFunction { @Override public double getFitness(long[] particlePosition) { long health = particlePosition[0]; long armor = particlePosition[1]; if (health \u0026lt; 0 \u0026amp;\u0026amp; armor \u0026lt; 0) { return -(health * armor); } else if (health \u0026lt; 0) { return health; } else if (armor \u0026lt; 0) { return armor; } double cost = (health * 2.5) + (armor * 18); if (cost \u0026gt; 3600) { return 3600 - cost; } else { long fitness = (health * (100 + armor)) / 100; return fitness; } } } 3.5. 主循环 主程序将在所有 swarm 中的所有粒子之间进行迭代，并执行以下操作：  计算粒子适应度 如果找到了新的最佳位置，则更新粒子、群和多群历史 通过将当前速度添加到每个维度来计算新的粒子位置 计算新的粒子速度  目前，我们将通过创建一个专用方法将速度更新留到下一节： public void mainLoop() { for (Swarm swarm : swarms) { for (Particle particle : swarm.getParticles()) { long[] particleOldPosition = particle.getPosition().clone(); particle.setFitness(fitnessFunction.getFitness(particleOldPosition)); if (particle.getFitness() \u0026gt; particle.getBestFitness()) { particle.setBestFitness(particle.getFitness());\tparticle.setBestPosition(particleOldPosition); if (particle.getFitness() \u0026gt; swarm.getBestFitness()) {\tswarm.setBestFitness(particle.getFitness()); swarm.setBestPosition(particleOldPosition); if (swarm.getBestFitness() \u0026gt; bestFitness) { bestFitness = swarm.getBestFitness(); bestPosition = swarm.getBestPosition().clone(); } } } long[] position = particle.getPosition(); long[] speed = particle.getSpeed(); position[0] += speed[0]; position[1] += speed[1]; speed[0] = getNewParticleSpeedForIndex(particle, swarm, 0); speed[1] = getNewParticleSpeedForIndex(particle, swarm, 1); } } } 3.6. 速度更新 粒子必须改变它的速度，因为这就是它设法探索不同可能解决方案的方式。 粒子的速度将需要使粒子向其自身、其群体和所有群体找到的最佳位置移动，并为每个群体分配一定的权重。我们将这些权重分别称为认知权重、社会权重和全局权重。 为了增加一些变化，我们将这些权重中的每一个与一个介于 0 和 1 之间的随机数相乘。我们还将在公式中添加一个惯性因子，以激励粒子不要减速太多： private int getNewParticleSpeedForIndex( Particle particle, Swarm swarm, int index) { return (int) ((Constants.INERTIA_FACTOR * particle.getSpeed()[index]) + (randomizePercentage(Constants.COGNITIVE_WEIGHT) * (particle.getBestPosition()[index] - particle.getPosition()[index])) + (randomizePercentage(Constants.SOCIAL_WEIGHT) * (swarm.getBestPosition()[index] - particle.getPosition()[index])) + (randomizePercentage(Constants.GLOBAL_WEIGHT) * (bestPosition[index] - particle.getPosition()[index]))); } 惯性、认知、社会和全局权重的可接受值分别为 0.729、1.49445、1.49445 和 0.3645。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_multi_swarm_algorithm/","tags":[],"title":"Java中的多群优化算法"},{"categories":["Java"],"contents":"1. 概述 Java 不断发展并向 JDK 添加新功能。而且，如果我们想在我们的 API 中使用这些功能，那么这可能会迫使下游依赖项升级其 JDK 版本。 有时，我们被迫等待使用新的语言功能以保持兼容。 不过，在本教程中，我们将了解 Multi-Release JAR (MRJAR) 以及它们如何同时包含与不同 JDK 版本兼容的实现。 2. 简单示例 让我们看一下一个名为 DateHelper的实用程序类 ，它有一个检查闰年的方法。让我们假设它是使用 JDK 7 编写并构建为在 JRE 7+ 上运行的： public class DateHelper { public static boolean checkIfLeapYear(String dateStr) throws Exception { logger.info(\u0026#34;Checking for leap year using Java 1 calendar API \u0026#34;); Calendar cal = Calendar.getInstance(); cal.setTime(new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;).parse(dateStr)); int year = cal.get(Calendar.YEAR); return (new GregorianCalendar()).isLeapYear(year); } } checkIfLeapYear方法将从我们的测试应用程序的 main 方法中调用*：* public class App { public static void main(String[] args) throws Exception { String dateToCheck = args[0]; boolean isLeapYear = DateHelper.checkIfLeapYear(dateToCheck); logger.info(\u0026#34;Date given \u0026#34; + dateToCheck + \u0026#34; is leap year: \u0026#34; + isLeapYear); } } 让我们快进到今天。 我们知道 Java 8 有一种更简洁的方式来解析日期。所以，我们想利用这一点并重写我们的逻辑。为此，我们需要切换到 JDK 8+。但是，这意味着我们的模块将停止在最初为其编写的 JRE 7 上工作。 我们不希望这种情况发生，除非绝对必要。 3. 多版本 Jar 文件 Java 9 中的解决方案是保持原始类不变，而是使用新的 JDK 创建一个新版本并将它们打包在一起。在运行时，JVM（版本 9 或更高版本）将调用这两个版本中的任何一个，并优先选择 JVM 支持的最高版本。 例如，如果 MRJAR 包含同一类的 Java 版本 7（默认）、9 和 10，则 JVM 10+ 将执行版本 10，而 JVM 9 将执行版本 9。在这两种情况下，默认版本都不会执行为该 JVM 存在更合适的版本。 请注意，新版本类的公共定义应与原始版本完全匹配。换句话说，我们不允许添加任何新版本专有的新公共 API。 4. 文件夹结构 由于 Java 中的类通过名称直接映射到文件，因此不可能在同一位置创建新版本的*DateHelper 。*因此，我们需要在单独的文件夹中创建它们。 让我们首先创建一个与java处于同一级别的文件夹java9。之后，让我们克隆保留其包文件夹结构的DateHelper.java文件并将其放在java9 中： src/ main/ java/ com/ codingman/ multireleaseapp/ App.java DateHelper.java java9/ com/ codingman/ multireleaseapp/ DateHelper.java 一些还不支持 MRJAR 的 IDE可能会为重复的DateHelper.java类抛出错误。 我们将在另一个教程中讨论如何将它与 Maven 等构建工具集成。现在，让我们只关注基本面。 5. 代码更改 让我们重写java9克隆类的逻辑： public class DateHelper { public static boolean checkIfLeapYear(String dateStr) throws Exception { logger.info(\u0026#34;Checking for leap year using Java 9 Date Api\u0026#34;); return LocalDate.parse(dateStr).isLeapYear(); } } 请注意，我们没有对克隆类的公共方法签名进行任何更改，而只是更改了内部逻辑。同时，我们没有添加任何新的公共方法。 这非常重要，因为如果不遵循这两个规则，jar 创建将失败。 6. Java中的交叉编译 交叉编译是 Java 中可以编译文件以在早期版本上运行的功能。这意味着我们不需要安装单独的 JDK 版本。 让我们使用 JDK 9 或更高版本编译我们的类。 首先，为 Java 7 平台编译旧代码： javac --release 7 -d classes src\\main\\java\\com\\codingman\\multireleaseapp\\*.java 其次，为 Java 9 平台编译新代码： javac --release 9 -d classes-9 src\\main\\java9\\com\\codingman\\multireleaseapp\\*.java release选项用于指示 Java 编译器和目标 JRE 的版本。 7. 创建 MRJAR 最后，使用 9+ 版本创建 MRJAR 文件： jar --create --file target/mrjar.jar --main-class com.codingman.multireleaseapp.App -C classes . --release 9 -C classes-9 . 后跟文件夹名称的release选项使该文件夹的内容打包在版本号值下的 jar 文件中： com/ codingman/ multireleaseapp/ App.class DateHelper.class META-INF/ versions/ 9/ com/ codingman/ multireleaseapp/ DateHelper.class MANIFEST.MF MANIFEST.MF文件具有让 JVM 知道这是一个 MRJAR 文件的属性集： Multi-Release: true 因此，JVM 在运行时加载适当的类。 较旧的 JVM 会忽略指示这是 MRJAR 文件的新属性，并将其视为普通 JAR 文件。 8. 测试 最后，让我们针对 Java 7 或 8 测试我们的 jar： \u0026gt; java -jar target/mrjar.jar \u0026#34;2012-09-22\u0026#34; Checking for leap year using Java 1 calendar API Date given 2012-09-22 is leap year: true 然后，让我们针对 Java 9 或更高版本再次测试 jar： \u0026gt; java -jar target/mrjar.jar \u0026#34;2012-09-22\u0026#34; Checking for leap year using Java 9 Date Api Date given 2012-09-22 is leap year: true \u0026quot; ","permalink":"http://itcodingman.github.io/java_multi_release_jar/","tags":["Java 9"],"title":"多版本 Jar 文件"},{"categories":["Java Collections"],"contents":"1. 概述 创建多维ArrayList经常出现在编程过程中。在许多情况下，需要创建二维ArrayList或三维ArrayList。 在本教程中，我们将讨论如何在 Java中创建多维ArrayList 。 2. 二维ArrayList 假设我们要表示一个有 3 个顶点的图，编号为 0 到 2。此外，我们假设图中有 3 条边 (0, 1)、(1, 2) 和 (2, 0)，其中一对of vertices 代表一条边。 我们可以通过创建和填充 ArrayList 的ArrayList来表示二维ArrayList中的边。 首先，让我们创建一个新的 2-D ArrayList： int vertexCount = 3; ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; graph = new ArrayList\u0026lt;\u0026gt;(vertexCount); 接下来，我们将使用另一个ArrayList初始化**ArrayList的每个元素： for(int i=0; i \u0026lt; vertexCount; i++) { graph.add(new ArrayList()); } 最后，我们可以将所有边 (0, 1)、(1, 2) 和 (2, 0) 添加到我们的二维ArrayList中： graph.get(0).add(1); graph.get(1).add(2); graph.get(2).add(0); 让我们还假设我们的图不是有向图。因此，我们还需要将边 (1, 0)、(2, 1) 和 (0, 2) 添加到二维ArrayList中： graph.get(1).add(0); graph.get(2).add(1); graph.get(0).add(2); 然后，要遍历整个图，我们可以使用双 for 循环： int vertexCount = graph.size(); for (int i = 0; i \u0026lt; vertexCount; i++) { int edgeCount = graph.get(i).size(); for (int j = 0; j \u0026lt; edgeCount; j++) { Integer startVertex = i; Integer endVertex = graph.get(i).get(j); System.out.printf(\u0026#34;Vertex %d is connected to vertex %d%n\u0026#34;, startVertex, endVertex); } } 3. 三维ArrayList 在上一节中，我们创建了一个二维ArrayList。按照相同的逻辑，让我们创建一个三维ArrayList： 假设我们想要表示一个 3-D 空间。因此，这个 3-D 空间中的每个点都将由三个坐标表示，例如 X、Y 和 Z。 除此之外，让我们假设每个点都有一种颜色，红色、绿色、蓝色或黄色。现在，每个点 (X, Y, Z) 及其颜色都可以用一个三维ArrayList 表示。 为简单起见，假设我们正在创建一个 (2 x 2 x 2) 3-D 空间。它将有八个点：(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0 , 1), (1, 1, 0) 和 (1, 1, 1)。 让我们首先初始化变量和 3-D ArrayList： int x_axis_length = 2; int y_axis_length = 2; int z_axis_length = 2; ArrayList\u0026lt;ArrayList\u0026lt;ArrayList\u0026lt;String\u0026gt;\u0026gt;\u0026gt; space = new ArrayList\u0026lt;\u0026gt;(x_axis_length); 然后，让我们用ArrayList\u0026lt;ArrayList\u0026gt;初始化ArrayList的每个元素： for (int i = 0; i \u0026lt; x_axis_length; i++) { space.add(new ArrayList\u0026lt;ArrayList\u0026lt;String\u0026gt;\u0026gt;(y_axis_length)); for (int j = 0; j \u0026lt; y_axis_length; j++) { space.get(i).add(new ArrayList\u0026lt;String\u0026gt;(z_axis_length)); } } 现在，我们可以为空间中的点添加颜色。让我们为点 (0, 0, 0) 和 (0, 0, 1) 添加红色： space.get(0).get(0).add(0,\u0026#34;Red\u0026#34;); space.get(0).get(0).add(1,\u0026#34;Red\u0026#34;); 然后，让我们为点 (0, 1, 0) 和 (0, 1, 1) 设置蓝色： space.get(0).get(1).add(0,\u0026#34;Blue\u0026#34;); space.get(0).get(1).add(1,\u0026#34;Blue\u0026#34;); 同样，我们可以继续在空间中填充其他颜色的点。 请注意，坐标为 (i, j, k) 的点的颜色信息存储在以下 3-D ArrayList元素中： space.get(i).get(j).get(k) 正如我们在这个例子中看到的， 空间变量是一个ArrayList。此外，这个ArrayList的每个元素都是一个 2-D ArrayList（类似于我们在第 2 节中看到的）。 请注意，我们 空间 ArrayList中元素的索引表示 X 坐标，而该索引处的每个 2-D ArrayList表示 (Y, Z) 坐标。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_multi_dimensional_arraylist/","tags":["Java List"],"title":"Java中的多维数组列表"},{"categories":["Java","Spring","BiliBili"],"contents":"Visual Studio Code Spring Boot 的安装及使用 Visual Studio Code和Spring Boot的安装及使用 \r","permalink":"http://itcodingman.github.io/vscode_spring_boot_install_introduce/","tags":[],"title":"Visual Studio Code Spring Boot 的安装及使用"},{"categories":["Java"],"contents":"1. 概述 持续时间是用小时、分钟、秒、毫秒等表示的时间量。我们可能希望将持续时间格式化为某个特定的时间模式。 我们可以通过在一些 JDK 库的帮助下编写自定义代码或利用第三方库来实现这一点。 在这个快速教程中，我们将了解如何编写简单的代码来将给定的持续时间格式化为 HH:MM:SS 格式。 2. Java 解决方案 有多种方式可以表示持续时间——例如，以分钟、秒和毫秒为单位，或者作为具有自己特定格式的 Java Duration 。 本节和后续部分将重点介绍使用某些 JDK 库将间隔（以毫秒指定）格式化为 HH:MM:SS。为了我们的示例，我们将 38114000ms 格式化为 10:35:14 (HH:MM:SS)。 2.1 Duration 从 Java 8 开始，引入了Duration类来处理各种单位的时间间隔。Duration类附带了许多帮助方法来从持续时间中获取小时、分钟和秒。 要使用Duration类将区间格式化为 HH:MM:SS ，我们需要使用Duration类中的Millis工厂方法从区间初始化Duration对象。这会将间隔转换为我们可以使用的Duration对象： Duration duration = Duration.ofMillis(38114000); 为了便于从秒计算到我们想要的单位，我们需要获取持续时间或间隔内的总秒数： long seconds = duration.getSeconds(); 然后，一旦我们有了秒数，我们就会为我们想要的格式生成相应的小时、分钟和秒： long HH = seconds / 3600; long MM = (seconds % 3600) / 60; long SS = seconds % 60; 最后，我们格式化生成的值： String timeInHHMMSS = String.format(\u0026#34;%02d:%02d:%02d\u0026#34;, HH, MM, SS); 让我们试试这个解决方案： assertThat(timeInHHMMSS).isEqualTo(\u0026#34;10:35:14\u0026#34;); 如果我们使用 Java 9 或更高版本，我们可以使用一些辅助方法直接获取单位，而无需执行任何计算： long HH = duration.toHours(); long MM = duration.toMinutesPart(); long SS = duration.toSecondsPart(); String timeInHHMMSS = String.format(\u0026#34;%02d:%02d:%02d\u0026#34;, HH, MM, SS); 上面的代码片段将给我们与上面测试相同的结果： assertThat(timeInHHMMSS).isEqualTo(\u0026#34;10:35:14\u0026#34;); 2.2. TimeUnit 就像上一节讨论的Duration 类一样， TimeUnit表示给定粒度的时间。它提供了一些帮助方法来转换单位——在我们的例子中是小时、分钟和秒——并在这些单位中执行计时和延迟操作。 要将持续时间（以毫秒为单位）格式化为 HH:MM:SS 格式，我们需要做的就是使用TimeUnit中相应的辅助方法： long HH = TimeUnit.MILLISECONDS.toHours(38114000); long MM = TimeUnit.MILLISECONDS.toMinutes(38114000) % 60; long SS = TimeUnit.MILLISECONDS.toSeconds(38114000) % 60; 然后，根据上面生成的单位格式化持续时间： String timeInHHMMSS = String.format(\u0026#34;%02d:%02d:%02d\u0026#34;, HH, MM, SS); assertThat(timeInHHMMSS).isEqualTo(\u0026#34;10:35:14\u0026#34;); 3. 使用第三方库 我们可能会选择通过使用第三方库方法而不是自己编写来尝试不同的路线。 3.1 Apache Commons 要使用Apache Commons，我们需要将commons-lang3添加到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 正如预期的那样，这个库在其DurationFormatUtils类中具有formatDuration以及其他单位格式化方法： String timeInHHMMSS = DurationFormatUtils.formatDuration(38114000, \u0026#34;HH:MM:SS\u0026#34;, true); assertThat(timeInHHMMSS).isEqualTo(\u0026#34;10:35:14\u0026#34;); 3.2. Joda Time **当我们使用 Java 8 之前的 Java 版本时， Joda Time**库会派上用场，因为它可以方便地表示和格式化时间单位。要使用 Joda Time，让我们将joda-time 依赖项添加到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;joda-time\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;joda-time\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.10\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Joda Time 有一个Duration类来表示时间。首先，我们将间隔以毫秒为单位转换为 Joda Time Duration对象的实例： Duration duration = new Duration(38114000); 然后，我们使用Duration中的toPeriod方法从上述持续时间中获取周期，该方法将其转换或初始化为 Joda Time 中的Period类的实例： Period period = duration.toPeriod(); 我们使用对应的辅助方法从Period获取单位（小时、分钟和秒） ： long HH = period.getHours(); long MM = period.getMinutes(); long SS = period.getSeconds(); 最后，我们可以格式化持续时间并测试结果： String timeInHHMMSS = String.format(\u0026#34;%02d:%02d:%02d\u0026#34;, HH, MM, SS); assertThat(timeInHHMMSS).isEqualTo(\u0026#34;10:35:14\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/java_ms_to_hhmmss/","tags":["Java Dates"],"title":"将毫秒持续时间格式化为 HH:MM:SS"},{"categories":["Python","Youtube"],"contents":"推箱子——pygame项目实战   ","permalink":"http://itcodingman.github.io/pygame_sokoban/","tags":[],"title":"推箱子——pygame项目实战"},{"categories":["Data"],"contents":"1. 概述 在本教程中，我们将了解如何使用Eclipse Paho 项目提供的库在 Java 项目中添加 MQTT 消息传递。 2. MQTT 入门 MQTT（MQ 遥测传输）是一种消息传递协议，旨在满足对一种简单且轻量级的方法将数据传输到/从低功率设备（例如工业应用中使用的设备）传输数据的需求。 随着 IoT（物联网）设备的日益普及，MQTT 的使用越来越多，导致 OASIS 和 ISO 对其进行了标准化。 该协议支持单一的消息传递模式，即发布-订阅模式：客户端发送的每条消息都包含一个关联的“主题”，代理使用该主题将其路由到订阅的客户端。主题名称可以是简单的字符串，如“ oiltemp ”或类似路径的字符串“ motor/1/rpm ”。 为了接收消息，客户端使用其确切名称或包含支持的通配符之一的字符串订阅一个或多个主题（“#”表示多级主题，“+”表示单级”）。 3. 项目设置 为了在 Maven 项目中包含 Paho 库，我们必须添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.eclipse.paho\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;org.eclipse.paho.client.mqttv3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  可以从 Maven Central 下载最新版本的Eclipse Paho Java 库模块。 4. 客户端设置 使用 Paho 库时，为了从 MQTT 代理发送和/或接收消息，我们需要做的第一件事是获取IMqttClient接口的实现*。*该接口包含应用程序建立与服务器的连接、发送和接收消息所需的所有方法。 Paho 开箱即用，提供了该接口的两种实现，一种是异步的（MqttAsyncClient），一种是同步的（MqttClient）。在我们的例子中，我们将关注语义更简单的同步版本。 设置本身是一个两步过程：我们首先创建 MqttClient类的实例，然后将其连接到我们的服务器。以下小节详细介绍了这些步骤。 4.1 创建一个新的IMqttClient实例 下面的代码片段展示了如何创建一个新的 IMqttClient同步实例： String publisherId = UUID.randomUUID().toString(); IMqttClient publisher = new MqttClient(\u0026#34;tcp://iot.eclipse.org:1883\u0026#34;,publisherId); 在这种情况下，我们使用最简单的可用构造函数，它采用 MQTT 代理的端点地址和唯一标识我们的客户端的客户端标识符。 在我们的例子中，我们使用了一个随机的 UUID，因此每次运行都会生成一个新的客户端标识符。 Paho 还提供了额外的构造函数，我们可以使用这些构造函数来自定义用于存储未确认消息的持久性机制和/或 用于运行协议引擎实现所需的后台任务的ScheduledExecutorService 。 我们使用的服务器端点是由 Paho 项目托管的公共 MQTT 代理，它允许任何具有 Internet 连接的人在无需任何身份验证的情况下测试客户端。 4.2. 连接到服务器 我们新创建的MqttClient实例没有连接到服务器。我们通过调用它的 *connect()*方法来做到这一点，可选地传递一个 MqttConnectOptions实例，该实例允许我们自定义协议的某些方面。 特别是，我们可以使用这些选项来传递附加信息，例如安全凭证、会话恢复模式、重新连接模式等。 MqttConnectionOptions 类将这些选项公开为简单的属性，我们可以使用普通的 setter 方法进行设置。我们只需要设置场景所需的属性——其余的将采用默认值。 用于建立与服务器的连接的代码通常如下所示： MqttConnectOptions options = new MqttConnectOptions(); options.setAutomaticReconnect(true); options.setCleanSession(true); options.setConnectionTimeout(10); publisher.connect(options); 在这里，我们定义我们的连接选项，以便：  如果发生网络故障，库将自动尝试重新连接到服务器 它将丢弃以前运行的未发送消息 连接超时设置为 10 秒  5. 发送消息 使用已连接的 MqttClient发送消息非常简单。我们使用其中一种*publish()*方法变体，使用以下服务质量选项之一将有效负载（始终为字节数组）发送到给定主题：  0 - “最多一次”语义，也称为“即发即弃”。当可以接受消息丢失时使用此选项，因为它不需要任何类型的确认或持久性 1 - “至少一次”语义。当消息丢失是不可接受 的并且您的订阅者可以处理重复时使用此选项 2 – “恰好一次”语义。当消息丢失是不可接受 的并且您的订阅者无法处理重复时使用此选项  在我们的示例项目中， EngineTemperatureSensor类扮演一个模拟传感器的角色，每次我们调用它的 call() 方法时都会产生一个新的温度读数。 此类实现 Callable 接口，因此我们可以轻松地将其与java.util.concurrent包中可用的ExecutorService实现 之一一起使用： public class EngineTemperatureSensor implements Callable\u0026lt;Void\u0026gt; { // ... private members omitted  public EngineTemperatureSensor(IMqttClient client) { this.client = client; } @Override public Void call() throws Exception { if ( !client.isConnected()) { return null; } MqttMessage msg = readEngineTemp(); msg.setQos(0); msg.setRetained(true); client.publish(TOPIC,msg); return null; } private MqttMessage readEngineTemp() { double temp = 80 + rnd.nextDouble() * 20.0; byte[] payload = String.format(\u0026#34;T:%04.2f\u0026#34;,temp) .getBytes(); return new MqttMessage(payload); } } **MqttMessage 封装了负载本身、请求的服务质量以及消息的保留标志。**此标志向代理指示它应该保留此消息直到被订阅者使用。 我们可以使用这个特性来实现“最后一次正确”的行为，这样当一个新的订阅者连接到服务器时，它会立即收到保留的消息。 6. 接收消息 为了从 MQTT 代理接收消息，我们需要使用*subscribe()*方法变体之一，它允许我们指定：  我们希望接收的消息的一个或多个主题过滤器 相关的 QoS 处理接收到的消息的回调处理程序  在以下示例中，我们展示了如何将消息侦听器添加到现有 IMqttClient实例以接收来自给定主题的消息。我们使用 CountDownLatch 作为回调和主执行线程之间的同步机制，每次有新消息到达时将其递减。 在示例代码中，我们使用了不同的IMqttClient实例来接收消息。我们这样做只是为了更清楚哪个客户端做什么，但这不是 Paho 限制——如果你愿意，你可以使用同一个客户端来发布和接收消息： CountDownLatch receivedSignal = new CountDownLatch(10); subscriber.subscribe(EngineTemperatureSensor.TOPIC, (topic, msg) -\u0026gt; { byte[] payload = msg.getPayload(); // ... payload handling omitted  receivedSignal.countDown(); }); receivedSignal.await(1, TimeUnit.MINUTES); 上面使用的subscribe()变体将IMqttMessageListener实例作为其第二个参数。 在我们的例子中，我们使用一个简单的 lambda 函数来处理有效负载并递减一个计数器。如果在指定的时间窗口（1 分钟）内没有足够的消息到达， *await()*方法将抛出异常。 使用 Paho 时，我们不需要显式确认消息接收。如果回调正常返回，Paho 假定它成功消费并向服务器发送确认。 如果回调抛出异常，客户端将被关闭。 请注意，这将导致任何以 QoS 级别 0 发送的消息丢失。 一旦客户端重新连接并再次订阅主题，服务器将重新发送以 QoS 级别 1 或 2 发送的消息。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mqtt_client/","tags":[],"title":"Java 中的 MQTT 客户端"},{"categories":["Algorithms"],"contents":"1. 概述 在本文中，我们将探索蒙特卡洛树搜索 (MCTS) 算法及其应用。 我们将通过在 Java 中实现井字游戏来详细了解它的各个阶段。我们将设计一个通用的解决方案，它可以在许多其他实际应用中使用，而且改动很小。 2. 简介 简单地说，蒙特卡洛树搜索是一种概率搜索算法。它是一种独特的决策算法，因为它在具有大量可能性的开放式环境中效率很高。 如果您已经熟悉Minimax等博弈论算法，它需要一个函数来评估当前状态，并且它必须计算博弈树中的许多层级才能找到最佳移动。 不幸的是，在像围棋这样具有高分支因子的游戏中这样做是不可行的（随着树的高度增加会产生数百万种可能性），并且很难编写一个好的评估函数来计算目前的状态是。 蒙特卡洛树搜索将蒙特卡洛方法应用于博弈树搜索。由于它是基于游戏状态的随机抽样，它不需要暴力破解每种可能性。此外，它不一定要求我们编写评估或良好的启发式函数。 而且，一个快速的旁注——它彻底改变了计算机围棋的世界。自 2016 年 3 月以来，随着谷歌的AlphaGo（由 MCTS 和神经网络构建）击败李世石（围棋世界冠军），它已成为一个流行的研究课题。 3. 蒙特卡洛树搜索算法 现在，让我们探索一下算法是如何工作的。最初，我们将构建一个带有根节点的前瞻树（游戏树），然后我们将通过随机展开继续扩展它。在此过程中，我们将维护每个节点的访问次数和获胜次数。 最后，我们将选择统计数据最有希望的节点。 该算法由四个阶段组成；让我们详细探讨所有这些。 3.1 选择 在这个初始阶段，算法从一个根节点开始并选择一个子节点，以便它选择具有最大获胜率的节点。我们还想确保每个节点都有公平的机会。 **这个想法是继续选择最佳子节点，直到我们到达树的叶节点。**选择此类子节点的一个好方法是使用 UCT（应用于树的上置信边界）公式： 其中  w i = 第i步后的获胜次数 n i = 第i次移动后的模拟次数 c = 勘探参数（理论上等于 √2） t = 父节点的模拟总数  该公式确保没有一个州会成为饥饿的受害者，而且它也比其他州更频繁地扮演有前途的分支。 3.2. 扩张 当它不能再应用 UCT 来查找后继节点时，它通过附加来自叶节点的所有可能状态来扩展博弈树。 3.3. 模拟 展开后，算法任意选取一个子节点，并从选定节点模拟随机游戏，直到达到游戏的结果状态。如果在播放过程中随机或半随机选择节点，则称为轻播放。您还可以通过编写质量启发式或评估函数来选择重演。 3.4. 反向传播 这也称为更新阶段。一旦算法到达游戏结束，它就会评估状态以确定哪个玩家获胜。它向上遍历到根并增加所有访问节点的访问分数。如果该位置的玩家赢得了比赛，它还会更新每个节点的获胜分数。 MCTS 不断重复这四个阶段，直到某个固定的迭代次数或某个固定的时间。 在这种方法中，我们根据随机移动估计每个节点的获胜分数。因此，迭代次数越多，估计就越可靠。算法估计在搜索开始时会不太准确，并在足够的时间后不断改进。同样，它完全取决于问题的类型。 4. 试运行 在这里，节点包含作为总访问/获胜分数的统计数据。 5. 实施 现在，让我们使用蒙特卡洛树搜索算法来实现一个井字游戏。 我们将为 MCTS 设计一个通用解决方案，该解决方案也可用于许多其他棋盘游戏。我们将查看文章本身中的大部分代码。 首先，我们需要Tree和Node类的基本实现以具有树搜索功能： public class Node { State state; Node parent; List\u0026lt;Node\u0026gt; childArray; // setters and getters } public class Tree { Node root; } 由于每个节点都会有一个特定的问题状态，让我们也实现一个State类： public class State { Board board; int playerNo; int visitCount; double winScore; // copy constructor, getters, and setters  public List\u0026lt;State\u0026gt; getAllPossibleStates() { // constructs a list of all possible states from current state  } public void randomPlay() { /* get a list of all possible positions on the board and play a random move */ } } 现在，让我们实现MonteCarloTreeSearch类，它将负责从给定的游戏位置找到下一个最佳移动： public class MonteCarloTreeSearch { static final int WIN_SCORE = 10; int level; int opponent; public Board findNextMove(Board board, int playerNo) { // define an end time which will act as a terminating condition  opponent = 3 - playerNo; Tree tree = new Tree(); Node rootNode = tree.getRoot(); rootNode.getState().setBoard(board); rootNode.getState().setPlayerNo(opponent); while (System.currentTimeMillis() \u0026lt; end) { Node promisingNode = selectPromisingNode(rootNode); if (promisingNode.getState().getBoard().checkStatus() == Board.IN_PROGRESS) { expandNode(promisingNode); } Node nodeToExplore = promisingNode; if (promisingNode.getChildArray().size() \u0026gt; 0) { nodeToExplore = promisingNode.getRandomChildNode(); } int playoutResult = simulateRandomPlayout(nodeToExplore); backPropogation(nodeToExplore, playoutResult); } Node winnerNode = rootNode.getChildWithMaxScore(); tree.setRoot(winnerNode); return winnerNode.getState().getBoard(); } } 在这里，我们不断迭代所有四个阶段，直到预定义的时间，最后，我们得到一棵具有可靠统计数据的树，以做出明智的决定。 现在，让我们为所有阶段实现方法。 我们将从需要 UCT 实施的选择阶段开始： private Node selectPromisingNode(Node rootNode) { Node node = rootNode; while (node.getChildArray().size() != 0) { node = UCT.findBestNodeWithUCT(node); } return node; } public class UCT { public static double uctValue( int totalVisit, double nodeWinScore, int nodeVisit) { if (nodeVisit == 0) { return Integer.MAX_VALUE; } return ((double) nodeWinScore / (double) nodeVisit) + 1.41 * Math.sqrt(Math.log(totalVisit) / (double) nodeVisit); } public static Node findBestNodeWithUCT(Node node) { int parentVisit = node.getState().getVisitCount(); return Collections.max( node.getChildArray(), Comparator.comparing(c -\u0026gt; uctValue(parentVisit, c.getState().getWinScore(), c.getState().getVisitCount()))); } } 这个阶段推荐一个叶子节点，应该在扩展阶段进一步扩展： private void expandNode(Node node) { List\u0026lt;State\u0026gt; possibleStates = node.getState().getAllPossibleStates(); possibleStates.forEach(state -\u0026gt; { Node newNode = new Node(state); newNode.setParent(node); newNode.getState().setPlayerNo(node.getState().getOpponent()); node.getChildArray().add(newNode); }); } **接下来，我们编写代码来选择一个随机节点并从中模拟随机播放。**此外，我们将有一个更新函数来传播从叶到根的分数和访问计数： private void backPropogation(Node nodeToExplore, int playerNo) { Node tempNode = nodeToExplore; while (tempNode != null) { tempNode.getState().incrementVisit(); if (tempNode.getState().getPlayerNo() == playerNo) { tempNode.getState().addScore(WIN_SCORE); } tempNode = tempNode.getParent(); } } private int simulateRandomPlayout(Node node) { Node tempNode = new Node(node); State tempState = tempNode.getState(); int boardStatus = tempState.getBoard().checkStatus(); if (boardStatus == opponent) { tempNode.getParent().getState().setWinScore(Integer.MIN_VALUE); return boardStatus; } while (boardStatus == Board.IN_PROGRESS) { tempState.togglePlayer(); tempState.randomPlay(); boardStatus = tempState.getBoard().checkStatus(); } return boardStatus; } 现在我们完成了 MCTS 的实现。我们所需要的只是一个井字游戏特定的Board类实现。请注意，使用我们的实现玩其他游戏；我们只需要更改Board类。 public class Board { int[][] boardValues; public static final int DEFAULT_BOARD_SIZE = 3; public static final int IN_PROGRESS = -1; public static final int DRAW = 0; public static final int P1 = 1; public static final int P2 = 2; // getters and setters  public void performMove(int player, Position p) { this.totalMoves++; boardValues[p.getX()][p.getY()] = player; } public int checkStatus() { /* Evaluate whether the game is won and return winner. If it is draw return 0 else return -1 */ } public List\u0026lt;Position\u0026gt; getEmptyPositions() { int size = this.boardValues.length; List\u0026lt;Position\u0026gt; emptyPositions = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; size; i++) { for (int j = 0; j \u0026lt; size; j++) { if (boardValues[i][j] == 0) emptyPositions.add(new Position(i, j)); } } return emptyPositions; } } 我们刚刚实现了一个在井字游戏中无法击败的 AI。让我们编写一个单元案例来证明 AI 与 AI 总是会打成平手： @Test public void givenEmptyBoard_whenSimulateInterAIPlay_thenGameDraw() { Board board = new Board(); int player = Board.P1; int totalMoves = Board.DEFAULT_BOARD_SIZE * Board.DEFAULT_BOARD_SIZE; for (int i = 0; i \u0026lt; totalMoves; i++) { board = mcts.findNextMove(board, player); if (board.checkStatus() != -1) { break; } player = 3 - player; } int winStatus = board.checkStatus(); assertEquals(winStatus, Board.DRAW); } 6. 优势  它不一定需要有关游戏的任何战术知识 一个通用的 MCTS 实现可以重用于任意数量的游戏，几乎不需要修改 专注于赢得比赛的机会较高的节点 适用于具有高分支因子的问题，因为它不会在所有可能的分支上浪费计算 算法实现起来非常简单 可以在任何给定时间停止执行，它仍然会建议目前计算的下一个最佳状态  7. 缺点 如果 MCTS 以其基本形式使用而没有任何改进，它可能无法建议合理的移动。如果没有充分访问节点，这可能会导致估计不准确。 但是，可以使用一些技术来改进 MCTS。它涉及特定领域以及与领域无关的技术。 在特定领域的技术中，模拟阶段产生更真实的播放，而不是随机模拟。虽然它需要了解游戏特定的技术和规则。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_monte_carlo_tree_search/","tags":["Data Structures"],"title":"蒙特卡洛树在 Java 中搜索井字游戏"},{"categories":["Reactive"],"contents":"1. 概述 有时在反应式编程中，我们可能有一个发布大量项目的发布者。在某些情况下，此发布者的消费者可能无法一次性处理所有项目。因此，我们可能需要异步发布每个项目以匹配消费者的处理速度。 在本教程中，我们将研究一些可以将 Collection 的Mono转换为Flux of Collection**的项目的方法。 2. 问题描述 在使用 Reactive Streams 时，我们使用 Publisher及其两个实现，Flux 和 Mono。虽然Mono是Publisher的一种类型，它可以发出 0 或 1 个T类型的项目，但Flux可以发出 0 到N个T类型的项目。 假设我们有一个Mono发布者，它持有一个 Mono\u0026lt;List\u0026gt; — 一个T类型的项目的可迭代集合。我们的要求是使用*Flux*异步生成集合项： 在这里，我们可以看到我们需要Mono\u0026lt;List\u0026gt;上的运算符来执行此转换。首先，我们将从流发布者Mono中提取集合项目，然后以Flux的形式异步生成项目。 Mono发布者 包含一个*map运算符，它可以同步转换Mono* ，以及一个*flatMap运算符，用于异步转换Mono*。此外，这两个运算符都会生成单个项目作为输出。 **但是，对于我们的用例在展平Mono\u0026lt;List\u0026gt;后生成许多项目，我们可以使用flatMapMany或flatMapIterable。 让我们探索如何使用这些运算符。 3. flatMapMany 让我们从一个示例字符串**列表开始创建我们的Mono发布者： private Mono\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; monoOfList() { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;one\u0026#34;); list.add(\u0026#34;two\u0026#34;); list.add(\u0026#34;three\u0026#34;); list.add(\u0026#34;four\u0026#34;); return Mono.just(list); } flatMapMany是**Mono上的通用运算符， 它返回一个 *Publisher。*让我们将 flatMapMany应用到我们的解决方案中： private \u0026lt;T\u0026gt; Flux\u0026lt;T\u0026gt; monoTofluxUsingFlatMapMany(Mono\u0026lt;List\u0026lt;T\u0026gt;\u0026gt; monoList) { return monoList .flatMapMany(Flux::fromIterable) .log(); } 在这种情况下，flatMapMany采用Mono的List，将其展平，并使用Flux运算符fromIterable创建一个Flux发布者。我们还在这里使用*log()*来记录生成的每个元素。因此，这将像“一”、“二”、“三”、“四”这样的元素一个一个地输出，然后终止。 4. flatMapIterable 对于相同的String示例**List ，我们现在将探索flatMapIterable — 一个定制的运算符。 在这里，我们不需要从List显式创建**Flux；我们只需要提供List。这个操作符隐式地从它的元素中创建了一个Flux 。让我们使用flatMapIterable作为我们的解决方案： private \u0026lt;T\u0026gt; Flux\u0026lt;T\u0026gt; monoTofluxUsingFlatMapIterable(Mono\u0026lt;List\u0026lt;T\u0026gt;\u0026gt; monoList) { return monoList .flatMapIterable(list -\u0026gt; list) .log(); } 在这里，flatMapIterable采用Mono的List并在内部将其转换为其元素的Flux。因此，与flatMapMany运算符相比，它更加优化。这将输出相同的“一”、“二”、“三”、“四”，然后终止。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mono_list_to_flux/","tags":[],"title":"如何将 Mono\u003cList\u003cT\u003e\u003e 转换为 Flux\u003cT\u003e"},{"categories":["Reactive"],"contents":"1. 概述 在反应式编程中，我们可以通过多种方式创建Mono或Flux类型的发布者。在这里，我们将看看使用defer方法来延迟Mono发布者的执行。 2. Mono.defer 方法是什么？ 我们可以使用Mono的defer 方法创建一个冷发布者，它最多可以产生一个值。让我们看一下方法签名： public static \u0026lt;T\u0026gt; Mono\u0026lt;T\u0026gt; defer(Supplier\u0026lt;? extends Mono\u0026lt;? extends T\u0026gt;\u0026gt; supplier) 在这里，defer接受Mono发布者的Supplier，并在下游订阅时懒惰地返回该Mono 。 然而，问题是，什么是冷出版商或懒惰出版商？让我们研究一下。 **仅当消费者订阅冷发布者时，执行线程才会评估冷发布者。而热门出版商在任何订阅之前都热切地评估。**我们有Mono.just()方法，它提供了Mono类型的热门发布者。 3. 它是如何工作的？ 让我们探索一个具有Mono类型的供应商的示例用例： private Mono\u0026lt;String\u0026gt; sampleMsg(String str) { log.debug(\u0026#34;Call to Retrieve Sample Message!! --\u0026gt; {} at: {}\u0026#34;, str, System.currentTimeMillis()); return Mono.just(str); } 在这里，这个方法返回一个热门的Mono发布者。让我们热切地订阅这个： public void whenUsingMonoJust_thenEagerEvaluation() throws InterruptedException { Mono\u0026lt;String\u0026gt; msg = sampleMsg(\u0026#34;Eager Publisher\u0026#34;); log.debug(\u0026#34;Intermediate Test Message....\u0026#34;); StepVerifier.create(msg) .expectNext(\u0026#34;Eager Publisher\u0026#34;) .verifyComplete(); Thread.sleep(5000); StepVerifier.create(msg) .expectNext(\u0026#34;Eager Publisher\u0026#34;) .verifyComplete(); } 在执行时，我们可以在日志中看到以下内容： 20:44:30.250 [main] DEBUG com.codingman.mono.MonoUnitTest - Call to Retrieve Sample Message!! --\u0026gt; Eager Publisher at: 1622819670247 20:44:30.365 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework 20:44:30.365 [main] DEBUG com.codingman.mono.MonoUnitTest - Intermediate Test Message.... 在这里，我们可以注意到：  根据指令顺序，main线程急切地执行方法sampleMsg。 在使用StepVerifier的两个订阅中，main线程使用 sampleMsg 的相同输出。因此，没有新的评价。  让我们看看*Mono.defer()*如何将其转换为冷（懒惰）发布者： public void whenUsingMonoDefer_thenLazyEvaluation() throws InterruptedException { Mono\u0026lt;String\u0026gt; deferMsg = Mono.defer(() -\u0026gt; sampleMsg(\u0026#34;Lazy Publisher\u0026#34;)); log.debug(\u0026#34;Intermediate Test Message....\u0026#34;); StepVerifier.create(deferMsg) .expectNext(\u0026#34;Lazy Publisher\u0026#34;) .verifyComplete(); Thread.sleep(5000); StepVerifier.create(deferMsg) .expectNext(\u0026#34;Lazy Publisher\u0026#34;) .verifyComplete(); } 执行此方法时，我们可以在控制台中看到以下日志： 20:01:05.149 [main] DEBUG com.codingman.mono.MonoUnitTest - Intermediate Test Message.... 20:01:05.187 [main] DEBUG com.codingman.mono.MonoUnitTest - Call to Retrieve Sample Message!! --\u0026gt; Lazy Publisher at: 1622817065187 20:01:10.197 [main] DEBUG com.codingman.mono.MonoUnitTest - Call to Retrieve Sample Message!! --\u0026gt; Lazy Publisher at: 1622817070197 在这里，我们可以从日志序列中注意到几点：  StepVerifier在每个订阅上执行方法sampleMsg，而不是在我们定义它的时候。 延迟 5 秒后，订阅方法sampleMsg的第二个消费者再次执行它。  这就是defer方法如何将热发布者变成冷发布者。 4. Mono.defer的用例？ 让我们看看可以使用*Mono.defer()*方法的可能用例：  当我们必须有条件地订阅发布者时 当每个订阅的执行可能产生不同的结果时 deferContextual可用于当前基于上下文的发布者评估  4.1 示例使用 让我们看一个使用条件*Mono.defer()*方法的示例： public void whenEmptyList_thenMonoDeferExecuted() { Mono\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; emptyList = Mono.defer(() -\u0026gt; monoOfEmptyList()); //Empty list, hence Mono publisher in switchIfEmpty executed after condition evaluation  Flux\u0026lt;String\u0026gt; emptyListElements = emptyList.flatMapIterable(l -\u0026gt; l) .switchIfEmpty(Mono.defer(() -\u0026gt; sampleMsg(\u0026#34;EmptyList\u0026#34;))) .log(); StepVerifier.create(emptyListElements) .expectNext(\u0026#34;EmptyList\u0026#34;) .verifyComplete(); } 这里，Mono发布者sampleMsg的提供者被放置在switchIfEmpty方法中，用于条件执行。因此，sampleMsg仅在它被延迟订阅时执行。 现在，让我们看一下非空列表的相同代码： public void whenNonEmptyList_thenMonoDeferNotExecuted() { Mono\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; nonEmptyist = Mono.defer(() -\u0026gt; monoOfList()); //Non empty list, hence Mono publisher in switchIfEmpty won\u0026#39;t evaluated.  Flux\u0026lt;String\u0026gt; listElements = nonEmptyist.flatMapIterable(l -\u0026gt; l) .switchIfEmpty(Mono.defer(() -\u0026gt; sampleMsg(\u0026#34;NonEmptyList\u0026#34;))) .log(); StepVerifier.create(listElements) .expectNext(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;) .verifyComplete(); } 这里， sampleMsg没有被执行，因为它没有被订阅。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mono_defer/","tags":[],"title":"Mono.defer() 做什么？"},{"categories":["NoSQL"],"contents":"1. 概述 $push是 MongoDB 中的更新运算符，用于将值添加到数组中。相比之下，$set运算符用于更新文档中现有字段的值。 在这个简短的教程中，我们将介绍如何在单个更新查询中同时执行*$push和$set*操作。 2. 数据库初始化 在我们继续执行多个更新操作之前，我们首先需要设置一个数据库demodb和样本收集marks： use demodb; db.createCollection(marks); 让我们使用 MongoDB 的insertMany方法将一些文档插入到集合marks中： db.marks.insertMany([ { \u0026#34;studentId\u0026#34;: 1023, \u0026#34;studentName\u0026#34;:\u0026#34;James Broad\u0026#34;, \u0026#34;joiningYear\u0026#34;:\u0026#34;2018\u0026#34;, \u0026#34;totalMarks\u0026#34;:100, \u0026#34;subjectDetails\u0026#34;:[ { \u0026#34;subjectId\u0026#34;:123, \u0026#34;subjectName\u0026#34;:\u0026#34;Operating Systems Concepts\u0026#34;, \u0026#34;marks\u0026#34;:40 }, { \u0026#34;subjectId\u0026#34;:124, \u0026#34;subjectName\u0026#34;:\u0026#34;Numerical Analysis\u0026#34;, \u0026#34;marks\u0026#34;:60 } ] }, { \u0026#34;studentId\u0026#34;: 1024, \u0026#34;studentName\u0026#34;:\u0026#34;Chris Overton\u0026#34;, \u0026#34;joiningYear\u0026#34;:\u0026#34;2018\u0026#34;, \u0026#34;totalMarks\u0026#34;:110, \u0026#34;subjectDetails\u0026#34;:[ { \u0026#34;subjectId\u0026#34;:123, \u0026#34;subjectName\u0026#34;:\u0026#34;Operating Systems Concepts\u0026#34;, \u0026#34;marks\u0026#34;:50 }, { \u0026#34;subjectId\u0026#34;:124, \u0026#34;subjectName\u0026#34;:\u0026#34;Numerical Analysis\u0026#34;, \u0026#34;marks\u0026#34;:60 } ] } ]); 成功插入后，上述查询将返回以下响应： { \u0026#34;acknowledged\u0026#34; : true, \u0026#34;insertedIds\u0026#34; : [ ObjectId(\u0026#34;622300cc85e943405d04b567\u0026#34;), ObjectId(\u0026#34;622300cc85e943405d04b568\u0026#34;) ] } 到目前为止，我们已经成功地将一些示例文档插入到集合marks中。 3. 理解问题 为了理解问题，我们先来了解一下我们刚刚插入的文档。它包括学生的详细信息以及他们在不同科目中获得的分数。totalMarks是在不同科目中获得的分数之和。 让我们考虑一种情况，我们希望在subjectDetails数组中添加一个新主题。为了使数据保持一致，我们还需要更新totalMarks字段。 在 MongoDB 中，首先，我们将使用*$push运算符将新主题添加到数组中。然后我们将使用$set运算符将totalMarks* 字段设置为特定值。 这两个操作都可以分别使用*$push和$set*运算符单独执行。但是我们可以编写 MongoDB 查询来同时执行这两个操作。 4. 使用 MongoDB Shell 查询 在 MongoDB 中，我们可以使用不同的更新运算符更新文档的多个字段。在这里，我们将在updateOne查询中同时使用*$push和$set*运算符。 让我们一起检查包含 $push和*$set*运算符的示例： db.marks.updateOne( { \u0026#34;studentId\u0026#34;: 1023 }, { $set: { totalMarks: 170 }, $push: { \u0026#34;subjectDetails\u0026#34;:{ \u0026#34;subjectId\u0026#34;: 126, \u0026#34;subjectName\u0026#34;: \u0026#34;Java Programming\u0026#34;, \u0026#34;marks\u0026#34;: 70 } } } ); 在这里，在上面的查询中，我们添加了基于studentId 的过滤查询。一旦我们得到过滤后的文档，我们就使用 $set 运算符更新totalMarks 。除此之外，我们使用$push运算符将新的主题数据插入到subjectDetails数组中。 因此，上述查询将返回以下输出： { \u0026#34;acknowledged\u0026#34;:true, \u0026#34;matchedCount\u0026#34;:1, \u0026#34;modifiedCount\u0026#34;:1 } 这里， matchedCount包含匹配过滤器的文档计数，而modifiedCount包含修改文档的数量。 5. Java驱动代码 到目前为止，我们讨论了结合使用*$push和$set*运算符的 mongo shell 查询。在这里，我们将学习使用 Java 驱动程序代码来实现相同的功能。 在我们继续之前，让我们首先连接到数据库和所需的集合： MongoClient mongoClient = new MongoClient(new MongoClientURI(\u0026#34;localhost\u0026#34;, 27017); MongoDatabase database = mongoClient.getDatabase(\u0026#34;demodb\u0026#34;); MongoCollection\u0026lt;Document\u0026gt; collection = database.getCollection(\u0026#34;marks\u0026#34;); 在这里，我们连接到 MongoDB，它在 localhost 的默认端口 27017 上运行。 现在让我们看看 Java 驱动程序代码： Document subjectData = new Document() .append(\u0026#34;subjectId\u0026#34;, 126) .append(\u0026#34;subjectName\u0026#34;, \u0026#34;Java Programming\u0026#34;) .append(\u0026#34;marks\u0026#34;, 70); UpdateResult updateQueryResult = collection.updateOne(Filters.eq(\u0026#34;studentId\u0026#34;, 1023), Updates.combine(Updates.set(\u0026#34;totalMarks\u0026#34;, 170), Updates.push(\u0026#34;subjectDetails\u0026#34;, subjectData))); 在此代码段中，我们使用了updateOne方法，该方法仅根据应用的过滤器studentId 1023更新单个文档。然后，我们使用Updates.combine在单个调用中执行多个操作。字段totalMarks将更新为 170，新文档subjectData 将被推送到数组字段*“subjectDetails”*。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mongodb_push_set/","tags":["MongoDB"],"title":"在同一 MongoDB 更新中推送和设置操作"},{"categories":["NoSQL","Persistence"],"contents":"1. 概述 有时，我们需要刚刚插入MongoDB数据库的文档的 ID。例如，我们可能希望将 ID 作为响应发回给调用者，或者记录创建的对象以进行调试。 在本教程中，我们将了解如何在 MongoDB 中实现 ID，以及如何通过 Java 程序检索我们刚刚插入到集合中的文档的 ID。 2. MongoDB 文档的 ID 是什么？ 与每个数据存储系统一样，MongoDB 需要为存储在集合中的每个文档提供一个唯一标识符。这个标识符相当于关系数据库中的主键。 在 MongoDB 中，此 ID 由 12 个字节组成：  一个 4 字节的时间戳值表示自 Unix 纪元以来的秒数 每个进程生成一次的 5 字节随机值。这个随机值对于机器和过程是唯一的。 一个 3 字节递增计数器  *ID 存储在名为_id*的字段 中，由客户端生成。**这意味着必须在将文档发送到数据库之前生成 ID。在客户端，我们可以使用驱动程序生成的 ID 或生成自定义 ID。 我们可以看到，同一个客户端在同一秒内创建的文档的前 9 个字节是相同的。因此，在这种情况下，ID 的唯一性依赖于计数器。该计数器可让客户在同一秒内创建超过 1600 万份文档。 虽然它以时间戳开头，但我们应该注意标识符不用作排序标准。这是因为不能保证在同一秒内创建的文档按创建日期排序，因为不能保证计数器是单调的。此外，不同的客户端可能有不同的系统时钟。 Java 驱动程序为计数器使用随机数生成器，它不是单调的。这就是为什么我们不应该使用驱动程序生成的 ID 来按创建日期排序。 3. ObjectId类 唯一标识符存储在ObjectId类中，该类提供了方便的方法来获取存储在 ID 中的数据，而无需手动解析。 例如，我们可以通过以下方式获取 ID 的创建日期： Date creationDate = objectId.getDate(); 同样，我们可以以秒为单位检索 ID 的时间戳： int timestamp = objectId.getTimestamp(); ObjectId类还提供了获取计数器、机器标识符或进程标识符的方法，但它们都已被弃用。 4. 检索 ID 要记住的主要事情是，在 MongoDB 中，客户端在将Document发送到集群之前生成它的唯一标识符。这与关系数据库中的序列形成对比。这使得该 ID 的检索非常容易。 4.1 驱动程序生成的 ID **生成Document唯一 ID 的标准且简单的方法是让驱动程序完成这项工作。当我们向Collection插入一个新的Document时，如果Document中不存在_id 字段，驱动程序会在向集群发送插入命令之前生成一个新的ObjectId 。 我们将新文档插入您的集合的代码可能如下所示： Document document = new Document(); document.put(\u0026#34;name\u0026#34;, \u0026#34;ann\u0026#34;); document.put(\u0026#34;company\u0026#34;, \u0026#34;ABC\u0026#34;); collection.insertOne(document); 我们可以看到，我们从未指明必须如何生成 ID。 当insertOne()方法返回时，我们可以从Document中获取生成的ObjectId： ObjectId objectId = document.getObjectId(\u0026#34;_id\u0026#34;); 我们还可以像Document的标准字段一样检索ObjectId，然后将其转换为ObjectId： ObjectId oId = (ObjectId) document.get(\u0026#34;_id\u0026#34;); 4.2. 自定义 ID **检索 ID 的另一种方法是在我们的代码中生成它，然后像任何其他字段一样将其放入Document中。如果我们向驱动程序发送一个带有_id字段的文档，它不会生成一个新的。 在某些情况下，在将Document插入**Collection之前，我们可能需要 MongoDB Document的 ID 。 我们可以通过创建类的新实例来生成新的ObjectId ： ObjectId generatedId = new ObjectId(); 或者，我们也可以调用ObjectId类的静态*get()*方法： ObjectId generatedId = ObjectId.get(); 然后，我们只需要创建我们的Document并使用生成的 ID。为此，我们可以在Document构造函数中提供它： Document document = new Document(\u0026#34;_id\u0026#34;, generatedId); 或者，我们可以使用*put()*方法： document.put(\u0026#34;_id\u0026#34;, generatedId); 当使用用户生成的 ID 时，我们必须小心在每次插入之前生成一个新的ObjectId，因为重复的 ID 是被禁止的。重复的 ID 将导致带有重复键消息的MongoWriteException 。 ObjectId类提供了其他几个构造函数，它们允许我们设置标识符的某些部分： public ObjectId(final Date date) public ObjectId(final Date date, final int counter) public ObjectId(final int timestamp, final int counter) public ObjectId(final String hexString) public ObjectId(final byte[] bytes) public ObjectId(final ByteBuffer buffer) 但是，当我们使用这些构造函数时，我们应该非常小心，因为提供给驱动程序的 ID 的唯一性完全依赖于我们的代码。在这些特殊情况下，我们可能会遇到重复键错误：  如果我们多次使用相同的日期（或时间戳）和计数器组合 如果我们多次使用相同的十六进制String、字节数组或ByteBuffer \u0026quot;  ","permalink":"http://itcodingman.github.io/java_mongodb_last_inserted_id/","tags":["MongoDB"],"title":"使用 Java 驱动程序在 MongoDB 中获取最后插入的文档 ID"},{"categories":["Java","Youtube"],"contents":"10分钟学习Java Log   ","permalink":"http://itcodingman.github.io/10_mins_java_log/","tags":["JUL","Slf4j","Log4j","Log4j2","JCL","Logback","Commons logging"],"title":"10分钟学习Java Log"},{"categories":["NoSQL"],"contents":"1. 概述 默认情况下，MongoDB引擎在对提取的数据进行排序时会考虑字符大小写。通过指定Aggregations或Collations可以执行不区分大小写的排序查询。 在这个简短的教程中，我们将看看使用 MongoDB Shell 和 Java 的两种解决方案。 2. 搭建环境 首先，我们需要运行一个 MongoDB 服务器。让我们使用 Docker 映像： $ docker run -d -p 27017:27017 --name example-mongo mongo:latest 这将创建一个名为“ example-mongo ”的新临时 Docker 容器，公开端口27017。现在，我们需要使用测试解决方案所需的数据创建一个基本的 Mongo 数据库。 首先，让我们在容器内打开一个 Mongo Shell： $ docker exec -it example-mongo mongosh 进入 shell 后，让我们切换上下文并进入名为“ sorting ”的数据库： \u0026gt; use sorting 最后，让我们插入一些数据来尝试我们的排序操作： \u0026gt; db.users.insertMany([ {name: \u0026#34;ben\u0026#34;, surname: \u0026#34;ThisField\u0026#34; }, {name: \u0026#34;aen\u0026#34;, surname: \u0026#34;Does\u0026#34; }, {name: \u0026#34;Aen\u0026#34;, surname: \u0026#34;Not\u0026#34; }, {name: \u0026#34;Ben\u0026#34;, surname: \u0026#34;Matter\u0026#34; }, ]) 我们在一些文档的名称字段中插入了类似的值。唯一的区别是第一个字母的大小写。此时，已创建数据库并正确插入数据，因此我们已准备好采取行动。 3. 默认排序 让我们在没有自定义的情况下运行标准查询： \u0026gt; db.getCollection(\u0026#39;users\u0026#39;).find({}).sort({name:1}) 返回的数据将根据情况进行排序。这意味着，例如，**大写字符“ *B”*将在小写字符“ *a”***之前被考虑： [ { _id: ..., name: \u0026#39;Aen\u0026#39;, surname: \u0026#39;Not\u0026#39; }, { _id: ..., name: \u0026#39;Ben\u0026#39;, surname: \u0026#39;Matter\u0026#39; }, { _id: ..., name: \u0026#39;aen\u0026#39;, surname: \u0026#39;Does\u0026#39; }, { _id: ..., name: \u0026#39;ben\u0026#39;, surname: \u0026#39;ThisField\u0026#39; } ] 现在让我们看看如何使我们的排序不区分大小写，以便Ben和 ben一起出现。 4. Mongo Shell 中不区分大小写的排序 4.1 使用排序规则排序 让我们尝试使用MongoDB Collation。仅在 MongoDB 3.4 及后续版本中可用，它启用了特定于语言的字符串比较规则。 **Collation ICU语言环境参数驱动数据库如何进行排序。*让我们使用“en”*（英语）语言环境： \u0026gt; db.getCollection(\u0026#39;users\u0026#39;).find({}).collation({locale: \u0026#34;en\u0026#34;}).sort({name:1}) 这会产生名称按字母聚集的输出： [ { _id: ..., name: \u0026#39;aen\u0026#39;, surname: \u0026#39;Does\u0026#39; }, { _id: ..., name: \u0026#39;Aen\u0026#39;, surname: \u0026#39;Not\u0026#39; }, { _id: ..., name: \u0026#39;ben\u0026#39;, surname: \u0026#39;ThisField\u0026#39; }, { _id: ..., name: \u0026#39;Ben\u0026#39;, surname: \u0026#39;Matter\u0026#39; } ] 4.2. 使用聚合排序 现在让我们使用聚合函数： \u0026gt; db.getCollection(\u0026#39;users\u0026#39;).aggregate([{ \u0026#34;$project\u0026#34;: { \u0026#34;name\u0026#34;: 1, \u0026#34;surname\u0026#34;: 1, \u0026#34;lowerName\u0026#34;: { \u0026#34;$toLower\u0026#34;: \u0026#34;$name\u0026#34; } } }, { \u0026#34;$sort\u0026#34;: { \u0026#34;lowerName\u0026#34;: 1 } } ]) 使用$project功能，我们添加了一个lowerName字段作为名称字段的小写版本。这允许我们使用该字段进行排序。它将以所需的排序顺序为我们提供一个带有附加字段的结果对象： [ { _id: ..., name: \u0026#39;aen\u0026#39;, surname: \u0026#39;Does\u0026#39;, lowerName: \u0026#39;aen\u0026#39; }, { _id: ..., name: \u0026#39;Aen\u0026#39;, surname: \u0026#39;Not\u0026#39;, lowerName: \u0026#39;aen\u0026#39; }, { _id: ..., name: \u0026#39;ben\u0026#39;, surname: \u0026#39;ThisField\u0026#39;, lowerName: \u0026#39;ben\u0026#39; }, { _id: ..., name: \u0026#39;Ben\u0026#39;, surname: \u0026#39;Matter\u0026#39;, lowerName: \u0026#39;ben\u0026#39; } ] 5. Java 中不区分大小写的排序 让我们尝试在 Java 中实现相同的方法。 5.1 配置样板代码 我们先添加mongo-java-driver依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mongodb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mongo-java-driver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.10\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后，让我们使用MongoClient进行连接： MongoClient mongoClient = new MongoClient(); MongoDatabase db = mongoClient.getDatabase(\u0026#34;sorting\u0026#34;); MongoCollection\u0026lt;Document\u0026gt; collection = db.getCollection(\u0026#34;users\u0026#34;); 5.2. 在 Java 中使用排序规则进行排序 让我们看看如何在 Java中实现*“排序规则”解决方案：* FindIterable\u0026lt;Document\u0026gt; nameDoc = collection.find().sort(ascending(\u0026#34;name\u0026#34;)) .collation(Collation.builder().locale(\u0026#34;en\u0026#34;).build()); *在这里，我们使用“en”*语言环境构建了排序规则。然后，我们将创建的 Collation 对象传递给 FindIterable对象的collation方法。 接下来，让我们使用MongoCursor来一一读取结果： MongoCursor cursor = nameDoc.cursor(); List expectedNamesOrdering = Arrays.asList(\u0026#34;aen\u0026#34;, \u0026#34;Aen\u0026#34;, \u0026#34;ben\u0026#34;, \u0026#34;Ben\u0026#34;, \u0026#34;cen\u0026#34;, \u0026#34;Cen\u0026#34;); List actualNamesOrdering = new ArrayList\u0026lt;\u0026gt;(); while (cursor.hasNext()) { Document document = cursor.next(); actualNamesOrdering.add(document.get(\u0026#34;name\u0026#34;).toString()); } assertEquals(expectedNamesOrdering, actualNamesOrdering); 5.3. 在 Java 中使用聚合进行排序 我们还可以使用Aggregation对集合进行排序。让我们使用 Java API 重新创建我们的命令行版本。 首先，我们依靠project方法来创建一个Bson对象。此对象还将包括通过使用Projections类将名称的每个字符转换为小写来计算的lowerName字段： Bson projectBson = project( Projections.fields( Projections.include(\u0026#34;name\u0026#34;,\u0026#34;surname\u0026#34;), Projections.computed(\u0026#34;lowerName\u0026#34;, Projections.computed(\u0026#34;$toLower\u0026#34;, \u0026#34;$name\u0026#34;)))); 接下来，我们为聚合方法提供一个包含前一个片段的Bson和sort 方法的列表： AggregateIterable\u0026lt;Document\u0026gt; nameDoc = collection.aggregate( Arrays.asList(projectBson, sort(Sorts.ascending(\u0026#34;lowerName\u0026#34;)))); 在这种情况下，和前一个一样，我们可以使用*MongoCursor*轻松读取结果。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mongodb_case_insensitive_sorting/","tags":["MongoDB"],"title":"MongoDB中不区分大小写的排序"},{"categories":["Java","BiliBili"],"contents":"一小时学习Servlet 本教程将讲解如何使用 Java Servlet 来开发基于 web 的应用程序。 \r","permalink":"http://itcodingman.github.io/1_hour_servlet/","tags":[],"title":"一小时学习Servlet"},{"categories":["NoSQL","Persistence"],"contents":"1. 概述 在本文中，我们将了解MongoDB的集成，这是一个非常流行的 NoSQL 开源数据库与独立的 Java 客户端。 MongoDB 是用 C++ 编写的，具有许多可靠的特性，例如 map-reduce、自动分片、复制、高可用性等。 2. MongoDB 让我们从关于 MongoDB 本身的几个关键点开始：  将数据存储在可以具有各种结构的类似JSON的文档中 使用动态模式，这意味着我们可以创建记录而无需预先定义任何东西 只需添加新字段或删除现有字段即可更改记录的结构  上述数据模型使我们能够表示层次关系，轻松存储数组和其他更复杂的结构。 3. 术语 如果我们可以将它们与关系数据库结构进行比较，那么理解 MongoDB 中的概念会变得更容易。 让我们看看 Mongo 和传统 MySQL 系统的类比：  MySQL 中的Table成为Mongo中的Collection Row成为Document Column 成为Field Joins 被定义为linking 和embedded文档  当然，这是查看 MongoDB 核心概念的一种简单方式，但仍然很有用。 现在，让我们深入了解这个强大的数据库的实现。 4. Maven依赖 我们需要首先定义 MongoDB 的 Java 驱动程序的依赖关系： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mongodb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mongo-java-driver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查是否已发布任何新版本的库 -在此处跟踪发布。 5. 使用MongoDB 现在，让我们开始使用 Java 实现 Mongo 查询。我们将遵循基本的 CRUD 操作，因为它们是最好的开始。 5.1 与MongoClient建立连接 首先，让我们连接到 MongoDB 服务器。如果版本 \u0026gt;= 2.10.0，我们将使用MongoClient： MongoClient mongoClient = new MongoClient(\u0026#34;localhost\u0026#34;, 27017); 对于旧版本，请使用Mongo类： Mongo mongo = new Mongo(\u0026#34;localhost\u0026#34;, 27017); 5.2. 连接到数据库 现在，让我们连接到我们的数据库。有趣的是，我们不需要创建一个。当 Mongo 看到该数据库不存在时，它会为我们创建它： DB database = mongoClient.getDB(\u0026#34;myMongoDb\u0026#34;); 有时，默认情况下，MongoDB 以身份验证模式运行。在这种情况下，我们需要在连接到数据库时进行身份验证。 我们可以如下所示进行： MongoClient mongoClient = new MongoClient(); DB database = mongoClient.getDB(\u0026#34;myMongoDb\u0026#34;); boolean auth = database.authenticate(\u0026#34;username\u0026#34;, \u0026#34;pwd\u0026#34;.toCharArray()); 5.3. 显示现有数据库 让我们显示所有现有的数据库。当我们想使用命令行时，显示数据库的语法类似于 MySQL： show databases; 在 Java 中，我们使用以下代码段显示数据库： mongoClient.getDatabaseNames().forEach(System.out::println); 输出将是： local 0.000GB myMongoDb 0.000GB 上面，local是默认的 Mongo 数据库。 5.4. 创建一个Collection 让我们从为我们的数据库创建一个Collection（MongoDB 等效的表）开始。一旦我们连接到我们的数据库，我们可以将Collection设置为： database.createCollection(\u0026#34;customers\u0026#34;, null); 现在，让我们显示当前数据库的所有现有集合： database.getCollectionNames().forEach(System.out::println); 输出将是： customers 5.5. 保存 - 插入 save操作具有save-or-update 语义：如果存在id，则执行update，否则执行insert。 当我们save一个新客户时： DBCollection collection = database.getCollection(\u0026#34;customers\u0026#34;); BasicDBObject document = new BasicDBObject(); document.put(\u0026#34;name\u0026#34;, \u0026#34;Shubham\u0026#34;); document.put(\u0026#34;company\u0026#34;, \u0026#34;ABC\u0026#34;); collection.insert(document); 该实体将被插入到数据库中： { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;33a52bb7830b8c9b233b4fe6\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;Shubham\u0026#34;, \u0026#34;company\u0026#34; : \u0026#34;ABC\u0026#34; } 接下来，我们将查看具有更新语义的相同操作——save。 5.6. 保存 - 更新 现在让我们看看使用更新语义的save*，对现有客户进行操作： { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;33a52bb7830b8c9b233b4fe6\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;Shubham\u0026#34;, \u0026#34;company\u0026#34; : \u0026#34;ABC\u0026#34; } 现在，当我们保存现有客户时——我们将对其进行更新： BasicDBObject query = new BasicDBObject(); query.put(\u0026#34;name\u0026#34;, \u0026#34;Shubham\u0026#34;); BasicDBObject newDocument = new BasicDBObject(); newDocument.put(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;); BasicDBObject updateObject = new BasicDBObject(); updateObject.put(\u0026#34;$set\u0026#34;, newDocument); collection.update(query, updateObject); 数据库将如下所示： { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;33a52bb7830b8c9b233b4fe6\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;John\u0026#34;, \u0026#34;company\u0026#34; : \u0026#34;ABC\u0026#34; } 如您所见，在这个特定示例中，save使用update的语义，因为我们使用具有给定*_id*的对象。 5.7. 从Collection中读取文档 让我们通过查询来搜索集合中的文档： BasicDBObject searchQuery = new BasicDBObject(); searchQuery.put(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;); DBCursor cursor = collection.find(searchQuery); while (cursor.hasNext()) { System.out.println(cursor.next()); } 它将显示我们现在在Collection中拥有的唯一**Document： [ { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;33a52bb7830b8c9b233b4fe6\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;John\u0026#34;, \u0026#34;company\u0026#34; : \u0026#34;ABC\u0026#34; } ] 5.8. 删除文档 让我们继续我们的最后一个 CRUD 操作，删除： BasicDBObject searchQuery = new BasicDBObject(); searchQuery.put(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;); collection.remove(searchQuery); 执行上述命令后，我们唯一的Document将从Collection中删除。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mongodb/","tags":["MongoDB"],"title":"使用 Java 的 MongoDB 指南"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将了解如何将货币金额转换为 Java 中的文字表示。 我们还将通过外部库Tradukisto了解自定义实现的外观。 2. 实施 让我们首先从我们自己的实现开始。第一步是声明两个包含以下元素的String数组： public static String[] ones = { \u0026#34;\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;, \u0026#34;five\u0026#34;, \u0026#34;six\u0026#34;, \u0026#34;seven\u0026#34;, \u0026#34;eight\u0026#34;, \u0026#34;nine\u0026#34;, \u0026#34;ten\u0026#34;, \u0026#34;eleven\u0026#34;, \u0026#34;twelve\u0026#34;, \u0026#34;thirteen\u0026#34;, \u0026#34;fourteen\u0026#34;, \u0026#34;fifteen\u0026#34;, \u0026#34;sixteen\u0026#34;, \u0026#34;seventeen\u0026#34;, \u0026#34;eighteen\u0026#34;, \u0026#34;nineteen\u0026#34; }; public static String[] tens = { \u0026#34;\u0026#34;, // 0  \u0026#34;\u0026#34;, // 1  \u0026#34;twenty\u0026#34;, // 2  \u0026#34;thirty\u0026#34;, // 3  \u0026#34;forty\u0026#34;, // 4  \u0026#34;fifty\u0026#34;, // 5  \u0026#34;sixty\u0026#34;, // 6  \u0026#34;seventy\u0026#34;, // 7  \u0026#34;eighty\u0026#34;, // 8  \u0026#34;ninety\u0026#34; // 9 }; 当我们收到输入时，我们需要处理无效值（零值和负值）。收到有效输入后，我们可以将美元和美分的数量提取到变量中： long dollars = (long) money; long cents = Math.round((money - dollars) * 100); 如果给定的数字小于 20，那么我们将根据索引从数组中获取适当的元素： if (n \u0026lt; 20) { return ones[(int) n]; } 我们将对小于 100 的数字使用类似的方法，但现在我们也必须使用tens数组： if (n \u0026lt; 100) { return tens[(int) n / 10] + ((n % 10 != 0) ? \u0026#34; \u0026#34; : \u0026#34;\u0026#34;) + ones[(int) n % 10]; } 对于小于一千的数字，我们也这样做。 接下来，我们使用递归调用来处理小于一百万的数字，如下所示： if (n \u0026lt; 1_000_000) { return convert(n / 1000) + \u0026#34; thousand\u0026#34; + ((n % 1000 != 0) ? \u0026#34; \u0026#34; : \u0026#34;\u0026#34;) + convert(n % 1000); } 相同的方法用于小于 10 亿的数字，依此类推。 这是可以调用来执行此转换的主要方法： public static String getMoneyIntoWords(double money) { long dollars = (long) money; long cents = Math.round((money - dollars) * 100); if (money == 0D) { return \u0026#34;\u0026#34;; } if (money \u0026lt; 0) { return INVALID_INPUT_GIVEN; } String dollarsPart = \u0026#34;\u0026#34;; if (dollars \u0026gt; 0) { dollarsPart = convert(dollars) + \u0026#34; dollar\u0026#34; + (dollars == 1 ? \u0026#34;\u0026#34; : \u0026#34;s\u0026#34;); } String centsPart = \u0026#34;\u0026#34;; if (cents \u0026gt; 0) { if (dollarParts.length() \u0026gt; 0) { centsPart = \u0026#34; and \u0026#34;; } centsPart += convert(cents) + \u0026#34; cent\u0026#34; + (cents == 1 ? \u0026#34;\u0026#34; : \u0026#34;s\u0026#34;); } return dollarsPart + centsPart; } 让我们测试我们的代码以确保它有效： @Test public void whenGivenDollarsAndCents_thenReturnWords() { String expectedResult = \u0026#34;nine hundred twenty four dollars and sixty cents\u0026#34;; assertEquals( expectedResult, NumberWordConverter.getMoneyIntoWords(924.6)); } @Test public void whenTwoBillionDollarsGiven_thenReturnWords() { String expectedResult = \u0026#34;two billion one hundred thirty three million two hundred\u0026#34; + \u0026#34; forty seven thousand eight hundred ten dollars\u0026#34;; assertEquals( expectedResult, NumberWordConverter.getMoneyIntoWords(2_133_247_810)); } @Test public void whenThirtyMillionDollarsGiven_thenReturnWords() { String expectedResult = \u0026#34;thirty three million three hundred forty eight thousand nine hundred seventy eight dollars\u0026#34;; assertEquals( expectedResult, NumberWordConverter.getMoneyIntoWords(33_348_978)); } 让我们也测试一些边缘情况，并确保我们也涵盖了它们： @Test public void whenZeroDollarsGiven_thenReturnEmptyString() { assertEquals(\u0026#34;\u0026#34;, NumberWordConverter.getMoneyIntoWords(0)); } @Test public void whenNoDollarsAndNineFiveNineCents_thenCorrectRounding() { assertEquals( \u0026#34;ninety six cents\u0026#34;, NumberWordConverter.getMoneyIntoWords(0.959)); } @Test public void whenNoDollarsAndOneCent_thenReturnCentSingular() { assertEquals( \u0026#34;one cent\u0026#34;, NumberWordConverter.getMoneyIntoWords(0.01)); } 3. 使用Libary 现在我们已经实现了自己的算法，让我们使用现有的库来进行这种转换。 Tradukisto是 Java 8+ 的库，它可以帮助我们将数字转换为它们的单词表示形式。首先，我们需要将它导入到我们的项目中（这个库的最新版本可以在这里找到）： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;pl.allegro.finance\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tradukisto\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 我们现在可以使用MoneyConverters的*asWords()*方法来进行这种转换： public String getMoneyIntoWords(String input) { MoneyConverters converter = MoneyConverters.ENGLISH_BANKING_MONEY_VALUE; return converter.asWords(new BigDecimal(input)); } 让我们用一个简单的测试用例来测试这个方法： @Test public void whenGivenDollarsAndCents_thenReturnWordsVersionTwo() { assertEquals( \u0026#34;three hundred ten £ 00/100\u0026#34;, NumberWordConverter.getMoneyIntoWords(\u0026#34;310\u0026#34;)); } 我们也可以使用ICU4J库来执行此操作，但它是一个很大的库，并带有许多其他功能，超出了本文的范围。 但是，如果需要 Unicode 和全球化支持，请查看它。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_money_into_words/","tags":[],"title":"用文字显示金额"},{"categories":["Java"],"contents":"1. 概述 JSR 354 –“Money and Currency”解决了 Java 中货币和货币金额的标准化问题。 它的目标是为 Java 生态系统添加一个灵活且可扩展的 API，并使处理货币金额变得更简单、更安全。 JSR 没有进入 JDK 9，但它是未来 JDK 版本的候选者。 2. 设置 首先，让我们将依赖项定义到我们的pom.xml文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javamoney\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;moneta\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处检查最新版本的依赖项。 3. JSR-354 特性 “货币和货币” API 的目标：  提供用于处理和计算货币金额的 API 定义表示货币和货币金额以及货币四舍五入的类 处理货币汇率 处理货币和货币金额的格式化和解析  4. 型号 JSR-354 规范的主要类如下图所示： 该模型包含两个主要接口CurrencyUnit和*MonetaryAmount，*将在以下部分进行说明。 5. CurrencyUnit CurrencyUnit模拟货币的最小属性。它的实例可以使用Monetary.getCurrency方法获得： @Test public void givenCurrencyCode_whenString_thanExist() { CurrencyUnit usd = Monetary.getCurrency(\u0026#34;USD\u0026#34;); assertNotNull(usd); assertEquals(usd.getCurrencyCode(), \u0026#34;USD\u0026#34;); assertEquals(usd.getNumericCode(), 840); assertEquals(usd.getDefaultFractionDigits(), 2); } 我们使用货币的字符串表示创建**CurrencyUnit，这可能导致我们尝试使用不存在的代码创建货币的情况。使用不存在的代码创建货币会引发UnknownCurrency异常： @Test(expected = UnknownCurrencyException.class) public void givenCurrencyCode_whenNoExist_thanThrowsError() { Monetary.getCurrency(\u0026#34;AAA\u0026#34;); } 6. MonetaryAmount MonetaryAmount是货币金额的数字表示。它始终与CurrencyUnit相关联并定义货币的货币表示。 金额可以以不同的方式实现，重点关注由每个具体用例定义的货币表示要求的行为。例如。Money和FastMoney是MonetaryAmount接口的实现。 FastMoney使用long作为数字表示来实现MonetaryAmount ，并且以精度为代价比*BigDecimal更快；*当我们需要性能并且精度不是问题时可以使用它。 可以使用默认工厂创建通用实例。让我们展示获取MonetaryAmount实例的不同方式： @Test public void givenAmounts_whenStringified_thanEquals() { CurrencyUnit usd = Monetary.getCurrency(\u0026#34;USD\u0026#34;); MonetaryAmount fstAmtUSD = Monetary.getDefaultAmountFactory() .setCurrency(usd).setNumber(200).create(); Money moneyof = Money.of(12, usd); FastMoney fastmoneyof = FastMoney.of(2, usd); assertEquals(\u0026#34;USD\u0026#34;, usd.toString()); assertEquals(\u0026#34;USD 200\u0026#34;, fstAmtUSD.toString()); assertEquals(\u0026#34;USD 12\u0026#34;, moneyof.toString()); assertEquals(\u0026#34;USD 2.00000\u0026#34;, fastmoneyof.toString()); } 7 . MonetaryAmount 我们可以在Money和FastMoney之间执行货币算术，但是当我们组合这两个类的实例时我们需要小心。 例如，当我们将FastMoney的一个 Euro 实例与Money的一个 Euro 实例进行比较时，结果是它们不一样： @Test public void givenCurrencies_whenCompared_thanNotequal() { MonetaryAmount oneDolar = Monetary.getDefaultAmountFactory() .setCurrency(\u0026#34;USD\u0026#34;).setNumber(1).create(); Money oneEuro = Money.of(1, \u0026#34;EUR\u0026#34;); assertFalse(oneEuro.equals(FastMoney.of(1, \u0026#34;EUR\u0026#34;))); assertTrue(oneDolar.equals(Money.of(1, \u0026#34;USD\u0026#34;))); } 我们可以使用MonetaryAmount类提供的方法执行加、减、乘、除和其他货币算术运算。 算术运算应该抛出一个ArithmeticException，如果数量之间的算术运算优于所使用的数字表示类型的能力，例如，如果我们尝试用一除以三，我们会得到一个ArithmeticException因为结果是无限的： @Test(expected = ArithmeticException.class) public void givenAmount_whenDivided_thanThrowsException() { MonetaryAmount oneDolar = Monetary.getDefaultAmountFactory() .setCurrency(\u0026#34;USD\u0026#34;).setNumber(1).create(); oneDolar.divide(3); } 在添加或减去金额时，最好使用MonetaryAmount实例的参数，因为我们需要确保两个金额具有相同的货币来执行金额之间的操作。 7.1 计算金额 可以通过多种方式计算总金额，一种方法是简单地将金额与： @Test public void givenAmounts_whenSummed_thanCorrect() { MonetaryAmount[] monetaryAmounts = new MonetaryAmount[] { Money.of(100, \u0026#34;CHF\u0026#34;), Money.of(10.20, \u0026#34;CHF\u0026#34;), Money.of(1.15, \u0026#34;CHF\u0026#34;)}; Money sumAmtCHF = Money.of(0, \u0026#34;CHF\u0026#34;); for (MonetaryAmount monetaryAmount : monetaryAmounts) { sumAmtCHF = sumAmtCHF.add(monetaryAmount); } assertEquals(\u0026#34;CHF 111.35\u0026#34;, sumAmtCHF.toString()); } 链接也可以应用于减法： Money calcAmtUSD = Money.of(1, \u0026#34;USD\u0026#34;).subtract(fstAmtUSD); 乘法： MonetaryAmount multiplyAmount = oneDolar.multiply(0.25); 或划分： MonetaryAmount divideAmount = oneDolar.divide(0.25); 让我们使用字符串比较我们的算术结果，因为结果还包含货币： @Test public void givenArithmetic_whenStringified_thanEqualsAmount() { CurrencyUnit usd = Monetary.getCurrency(\u0026#34;USD\u0026#34;); Money moneyof = Money.of(12, usd); MonetaryAmount fstAmtUSD = Monetary.getDefaultAmountFactory() .setCurrency(usd).setNumber(200.50).create(); MonetaryAmount oneDolar = Monetary.getDefaultAmountFactory() .setCurrency(\u0026#34;USD\u0026#34;).setNumber(1).create(); Money subtractedAmount = Money.of(1, \u0026#34;USD\u0026#34;).subtract(fstAmtUSD); MonetaryAmount multiplyAmount = oneDolar.multiply(0.25); MonetaryAmount divideAmount = oneDolar.divide(0.25); assertEquals(\u0026#34;USD\u0026#34;, usd.toString()); assertEquals(\u0026#34;USD 1\u0026#34;, oneDolar.toString()); assertEquals(\u0026#34;USD 200.5\u0026#34;, fstAmtUSD.toString()); assertEquals(\u0026#34;USD 12\u0026#34;, moneyof.toString()); assertEquals(\u0026#34;USD -199.5\u0026#34;, subtractedAmount.toString()); assertEquals(\u0026#34;USD 0.25\u0026#34;, multiplyAmount.toString()); assertEquals(\u0026#34;USD 4\u0026#34;, divideAmount.toString()); } 8. 货币四舍五入 货币四舍五入只不过是从具有未确定精度的金额转换为四舍五入的金额。 我们将使用Monetary类提供的getDefaultRounding API进行转换。默认舍入值由货币提供： @Test public void givenAmount_whenRounded_thanEquals() { MonetaryAmount fstAmtEUR = Monetary.getDefaultAmountFactory() .setCurrency(\u0026#34;EUR\u0026#34;).setNumber(1.30473908).create(); MonetaryAmount roundEUR = fstAmtEUR.with(Monetary.getDefaultRounding()); assertEquals(\u0026#34;EUR 1.30473908\u0026#34;, fstAmtEUR.toString()); assertEquals(\u0026#34;EUR 1.3\u0026#34;, roundEUR.toString()); } 9. 货币兑换 货币兑换是处理金钱的一个重要方面。不幸的是，这些转换具有多种不同的实现和用例。 API 侧重于基于来源、目标货币和汇率的货币转换的常见方面。 货币转换或汇率访问可以参数化： @Test public void givenAmount_whenConversion_thenNotNull() { MonetaryAmount oneDollar = Monetary.getDefaultAmountFactory().setCurrency(\u0026#34;USD\u0026#34;) .setNumber(1).create(); CurrencyConversion conversionEUR = MonetaryConversions.getConversion(\u0026#34;EUR\u0026#34;); MonetaryAmount convertedAmountUSDtoEUR = oneDollar.with(conversionEUR); assertEquals(\u0026#34;USD 1\u0026#34;, oneDollar.toString()); assertNotNull(convertedAmountUSDtoEUR); } 转换始终与货币绑定。MonetaryAmount可以简单地通过将CurrencyConversion传递给金额的with方法进行转换。 10. 货币格式 格式化允许访问基于java.util.Locale的格式。与 JDK 不同，此 API 定义的格式化程序是线程安全的： @Test public void givenLocale_whenFormatted_thanEquals() { MonetaryAmount oneDollar = Monetary.getDefaultAmountFactory() .setCurrency(\u0026#34;USD\u0026#34;).setNumber(1).create(); MonetaryAmountFormat formatUSD = MonetaryFormats.getAmountFormat(Locale.US); String usFormatted = formatUSD.format(oneDollar); assertEquals(\u0026#34;USD 1\u0026#34;, oneDollar.toString()); assertNotNull(formatUSD); assertEquals(\u0026#34;USD1.00\u0026#34;, usFormatted); } 在这里，我们使用预定义格式并为我们的货币创建自定义格式。使用MonetaryFormats类的方法格式可以直接使用标准格式。我们定义了自定义格式设置格式查询构建器的模式属性。 和以前一样，因为货币包含在结果中，我们使用Strings测试我们的结果： @Test public void givenAmount_whenCustomFormat_thanEquals() { MonetaryAmount oneDollar = Monetary.getDefaultAmountFactory() .setCurrency(\u0026#34;USD\u0026#34;).setNumber(1).create(); MonetaryAmountFormat customFormat = MonetaryFormats.getAmountFormat(AmountFormatQueryBuilder. of(Locale.US).set(CurrencyStyle.NAME).set(\u0026#34;pattern\u0026#34;, \u0026#34;00000.00 ¤\u0026#34;).build()); String customFormatted = customFormat.format(oneDollar); assertNotNull(customFormat); assertEquals(\u0026#34;USD 1\u0026#34;, oneDollar.toString()); assertEquals(\u0026#34;00001.00 US Dollar\u0026#34;, customFormatted); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_money_and_currency/","tags":["Math"],"title":"Java Money 和货币 API"},{"categories":["Java"],"contents":"1. 概述 Java 平台模块系统(JPMS) 提供了更强的封装性、更高的可靠性和更好的关注点分离。 但所有这些方便的功能都是有代价的。由于模块化应用程序建立在依赖于其他模块才能正常工作的模块网络上，因此在许多情况下，模块之间是紧密耦合的。 这可能会让我们认为模块化和松耦合是不能在同一个系统中共存的特性。但实际上，他们可以！ 在本教程中，我们将深入研究两种众所周知的设计模式，我们可以使用它们轻松解耦 Java 模块。 2.父模块 为了展示我们将用于解耦 Java 模块的设计模式，我们将构建一个演示多模块 Maven 项目。 为了保持代码简单，项目最初将包含两个 Maven 模块，每个 Maven 模块将被包装到一个 Java 模块中。 第一个模块将包括一个服务接口，以及两个实现——服务提供者。第二个模块将使用提供程序来解析字符串值。 让我们从创建名为demoproject的项目根目录开始，我们将定义项目的父 POM： \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;servicemodule\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;consumermodule\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; \u0026lt;build\u0026gt; \u0026lt;pluginManagement\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;11\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;11\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/pluginManagement\u0026gt; \u0026lt;/build\u0026gt; 在父 POM 的定义中有一些细节值得强调。 首先，该文件包含我们上面提到的两个子模块，即servicemodule和consumermodule（我们稍后会详细讨论它们）。 接下来，由于我们使用的是 Java 11，**我们的系统上至少需要 Maven 3.5.0 ，因为 Maven 从该版本开始支持 Java 9 及更高版本。 最后，我们还需要至少 3.8.0 版的Maven 编译器插件。因此，为了确保我们是最新的，我们将检查Maven Central 以获取最新版本的 Maven 编译器插件。 3. 服务模块 出于演示的目的，让我们使用一种快速而简单的方法来实现servicemodule模块，这样我们就可以清楚地发现这种设计出现的缺陷。 让我们将服务接口和服务提供者公开，方法是将它们放在同一个包中并导出它们。这似乎是一个相当不错的设计选择，但正如我们稍后会看到的，它极大地提高了项目模块之间的耦合程度。 在项目的根目录下，我们将创建servicemodule/src/main/java目录。然后，我们需要定义包com.codingman.servicemodule，并在其中放置以下TextService接口： public interface TextService { String processText(String text); } TextService接口非常简单，所以现在让我们定义服务提供者*。* 在同一个包中，让我们添加一个小写实现： public class LowercaseTextService implements TextService { @Override public String processText(String text) { return text.toLowerCase(); } } 现在，让我们添加一个大写实现： public class UppercaseTextService implements TextService { @Override public String processText(String text) { return text.toUpperCase(); } } 最后，在servicemodule/src/main/java目录下，让我们包含模块描述符module-info.java： module com.codingman.servicemodule { exports com.codingman.servicemodule; } 4. 消费模块 现在我们需要创建一个使用我们之前创建的服务提供者之一的消费者模块。 让我们添加以下com.codingman.consumermodule。应用类： public class Application { public static void main(String args[]) { TextService textService = new LowercaseTextService(); System.out.println(textService.processText(\u0026#34;Hello World!\u0026#34;)); } } 现在，让我们在源根目录中包含模块描述符module-info.java，它应该是consumermodule/src/main/java： module com.codingman.consumermodule { requires com.codingman.servicemodule; } 最后，让我们编译源文件并运行应用程序，无论是在我们的 IDE 中还是从命令控制台。 正如我们所料，我们应该看到以下输出： hello world! 这确实有效，但有一个重要的警告值得注意：我们不必要地将服务提供者耦合到消费者模块。 由于我们使提供者对外界可见，因此消费者模块知道它们。 此外，这反对使软件组件依赖于抽象。 5. 服务商工厂 我们可以通过只导出服务接口来轻松去除模块之间的耦合。相比之下，服务提供者不会被导出，因此对消费者模块是隐藏的。消费者模块只看到服务接口类型。 为此，我们需要：  将服务接口放在单独的包中，对外导出 将服务提供者放在不导出的不同包中 创建一个工厂类，将其导出。消费者模块使用工厂类来查找服务提供者  我们可以将上述步骤以设计模式的形式概念化：公共服务接口、私有服务提供者和公共服务提供者工厂。 5.1 公共服务接口 为了清楚地了解这种模式是如何工作的，让我们将服务接口和服务提供者放在不同的包中。接口将被导出，但提供者实现不会。 所以，让我们将TextService移动到一个新的包中，我们将调用 它 com.codingman.servicemodule.external。 5.2. 私人服务提供商 然后，让我们同样将我们的LowercaseTextService和UppercaseTextService移动到com.codingman.servicemodule.internal。 5.3. 公共服务提供者工厂 由于服务提供者类现在是私有的，不能从其他模块访问，我们将使用公共工厂类来提供一个简单的机制，消费者模块可以使用它来获取服务提供者的实例。 在com.codingman.servicemodule.external 包中，我们定义如下TextServiceFactory类： public class TextServiceFactory { private TextServiceFactory() {} public static TextService getTextService(String name) { return name.equalsIgnoreCase(\u0026#34;lowercase\u0026#34;) ? new LowercaseTextService(): new UppercaseTextService(); } } 当然，我们可以让工厂类稍微复杂一些。不过，为了简单起见，服务提供者只是根据传递给getTextService()方法的字符串值创建的。 现在，让我们替换我们的module-info.java文件以仅导出我们的 外部包： module com.codingman.servicemodule { exports com.codingman.servicemodule.external; } 请注意，我们只导出服务接口和工厂类。这些实现是私有的，因此它们对其他模块不可见。 5.4. 应用类 现在，让我们重构Application类，以便它可以使用服务提供者工厂类： public static void main(String args[]) { TextService textService = TextServiceFactory.getTextService(\u0026#34;lowercase\u0026#34;); System.out.println(textService.processText(\u0026#34;Hello from Baeldung!\u0026#34;)); } 正如预期的那样，如果我们运行应用程序，我们应该会看到相同的文本打印到控制台： hello world! 通过公开服务接口和私有服务提供者，我们可以通过一个简单的工厂类有效地解耦服务和消费者模块。 当然，任何模式都不是灵丹妙药。与往常一样，我们应该首先分析我们的用例是否合适。 6. 服务和消费者模块 JPMS 通过提供…使用和使用指令为服务和消费者模块提供开箱即用的支持。 因此，我们可以使用此功能来解耦模块，而无需创建额外的工厂类。 为了让服务和消费者模块一起工作，我们需要做以下事情：  将服务接口放在一个模块中，该模块导出接口 将服务提供者放在另一个模块中——提供者被导出 在提供者的模块描述符中指定我们想要提供一个TextService实现与提供…with指令 将Application类放在它自己的模块中——消费者模块 在使用者模块的模块描述符中指定该模块是具有使用指令的使用者模块 使用消费者模块中的服务加载器 API来查找服务提供者  这种方法非常强大，因为它利用了服务和消费者模块带来的所有功能。但这也有些棘手。 一方面，我们使消费者模块只依赖于服务接口，而不依赖于服务提供者。另一方面，我们甚至可以根本不定义服务提供者，应用程序仍然可以编译。 6.1 父模块 要实现这种模式，我们还需要重构父 POM 和现有模块。 由于服务接口、服务提供者和消费者现在将生活在不同的模块中，我们首先需要修改父 POM 的**部分，以反映这种新结构： \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;servicemodule\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;providermodule\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;consumermodule\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; 6.2. 服务模块 我们的TextService接口将返回到com.codingman.servicemodule。 我们将相应地更改模块描述符： module com.codingman.servicemodule { exports com.codingman.servicemodule; } 6.3. 提供者模块 如前所述，提供程序模块用于我们的实现，所以现在让我们将 LowerCaseTextService和 U ppercaseTextService 放在这里。我们将它们放在一个名为 com.codingman.providermodule 的包中。 最后，让我们添加一个module-info.java文件： module com.codingman.providermodule { requires com.codingman.servicemodule; provides com.codingman.servicemodule.TextService with com.codingman.providermodule.LowercaseTextService; } 6.4. 消费模块 现在，让我们重构消费者模块。首先，我们将 Application放回 com.codingman.consumermodule包中。 接下来，我们将重构Application类的*main()*方法，以便它可以使用ServiceLoader类来发现适当的实现： public static void main(String[] args) { ServiceLoader\u0026lt;TextService\u0026gt; services = ServiceLoader.load(TextService.class); for (final TextService service: services) { System.out.println(\u0026#34;The service \u0026#34; + service.getClass().getSimpleName() + \u0026#34; says: \u0026#34; + service.parseText(\u0026#34;Hello World!\u0026#34;)); } } 最后，我们将重构module-info.java文件： module com.codingman.consumermodule { requires com.codingman.servicemodule; uses com.codingman.servicemodule.TextService; } 现在，让我们运行应用程序。正如预期的那样，我们应该看到以下文本打印到控制台： The service LowercaseTextService says: hello world! 正如我们所见，实现这种模式比使用工厂类的模式稍微复杂一些。即便如此，额外的努力也会得到更灵活、松耦合的设计的高度回报。 消费者模块依赖于抽象，并且在运行时也很容易放入不同的服务提供者。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_modules_decoupling_design_strategies/","tags":["Core Java","Java 9"],"title":"解耦 Java 模块的设计策略"},{"categories":["Architecture","Java"],"contents":"1. 概述 领域驱动设计 (DDD) 是一组原则和工具，可帮助我们设计有效的软件架构以提供更高的业务价值。限界上下文是通过将整个应用程序域分离为多个语义一致的部分来从大泥球中拯救架构的核心和基本模式之一。 同时，借助Java 9 模块系统，我们可以创建强封装的模块。 在本教程中，我们将创建一个简单的商店应用程序，并了解如何在为有界上下文定义显式边界的同时利用 Java 9 模块。 2. DDD 有界上下文 如今，软件系统不是简单的CRUD 应用程序。实际上，典型的单体企业系统由一些遗留代码库和新添加的特性组成。但是，随着每次更改，维护此类系统变得越来越难。最终，它可能变得完全无法维护。 2.1 限界上下文和无处不在的语言 为了解决已解决的问题，DDD 提供了有界上下文的概念。有界上下文是特定术语和规则一致适用的域的逻辑边界。在这个边界内，所有的术语、定义和概念都构成了无处不在的语言。 特别是，通用语言的主要好处是将来自特定业务领域不同领域的项目成员组合在一起。 此外，多个上下文可能适用于同一事物。但是，在这些上下文中，它可能具有不同的含义。 2.2. 订单上下文 让我们通过定义 Order Context 开始实现我们的应用程序。此上下文包含两个实体：OrderItem和CustomerOrder。 CustomerOrder实体是一个聚合 根： public class CustomerOrder { private int orderId; private String paymentMethod; private String address; private List\u0026lt;OrderItem\u0026gt; orderItems; public float calculateTotalPrice() { return orderItems.stream().map(OrderItem::getTotalPrice) .reduce(0F, Float::sum); } } 如我们所见，该类包含calculateTotalPrice业务方法。但是，在现实世界的项目中，它可能会复杂得多——例如，在最终价格中包括折扣和税收。 接下来，让我们创建OrderItem类： public class OrderItem { private int productId; private int quantity; private float unitPrice; private float unitWeight; } 我们已经定义了实体，但我们还需要向应用程序的其他部分公开一些 API。让我们创建CustomerOrderService类： public class CustomerOrderService implements OrderService { public static final String EVENT_ORDER_READY_FOR_SHIPMENT = \u0026#34;OrderReadyForShipmentEvent\u0026#34;; private CustomerOrderRepository orderRepository; private EventBus eventBus; @Override public void placeOrder(CustomerOrder order) { this.orderRepository.saveCustomerOrder(order); Map\u0026lt;String, String\u0026gt; payload = new HashMap\u0026lt;\u0026gt;(); payload.put(\u0026#34;order_id\u0026#34;, String.valueOf(order.getOrderId())); ApplicationEvent event = new ApplicationEvent(payload) { @Override public String getType() { return EVENT_ORDER_READY_FOR_SHIPMENT; } }; this.eventBus.publish(event); } } 在这里，我们有一些重点要强调。placeOrder方法负责处理客户订单。处理完订单后，将事件发布到EventBus。我们将在接下来的章节中讨论事件驱动的通信。此服务提供OrderService接口的默认实现： public interface OrderService extends ApplicationService { void placeOrder(CustomerOrder order); void setOrderRepository(CustomerOrderRepository orderRepository); } 此外，此服务需要CustomerOrderRepository来保存订单： public interface CustomerOrderRepository { void saveCustomerOrder(CustomerOrder order); } 重要的是**这个接口不是在这个上下文中实现的，而是由基础设施模块提供的，**我们稍后会看到。 2.3. Shipping Context 现在，让我们定义 Shipping Context。它也很简单，包含三个实体：Parcel、PackageItem和ShippableOrder。 让我们从ShippableOrder实体开始： public class ShippableOrder { private int orderId; private String address; private List\u0026lt;PackageItem\u0026gt; packageItems; } 在这种情况下，实体不包含paymentMethod字段。这是因为，在我们的运输上下文中，我们不关心使用哪种付款方式。Shipping Context 只负责处理订单的发货。 此外，Parcel实体特定于 Shipping Context： public class Parcel { private int orderId; private String address; private String trackingId; private List\u0026lt;PackageItem\u0026gt; packageItems; public float calculateTotalWeight() { return packageItems.stream().map(PackageItem::getWeight) .reduce(0F, Float::sum); } public boolean isTaxable() { return calculateEstimatedValue() \u0026gt; 100; } public float calculateEstimatedValue() { return packageItems.stream().map(PackageItem::getWeight) .reduce(0F, Float::sum); } } 如我们所见，它还包含特定的业务方法并充当聚合根。 最后，让我们定义ParcelShippingService： public class ParcelShippingService implements ShippingService { public static final String EVENT_ORDER_READY_FOR_SHIPMENT = \u0026#34;OrderReadyForShipmentEvent\u0026#34;; private ShippingOrderRepository orderRepository; private EventBus eventBus; private Map\u0026lt;Integer, Parcel\u0026gt; shippedParcels = new HashMap\u0026lt;\u0026gt;(); @Override public void shipOrder(int orderId) { Optional\u0026lt;ShippableOrder\u0026gt; order = this.orderRepository.findShippableOrder(orderId); order.ifPresent(completedOrder -\u0026gt; { Parcel parcel = new Parcel(completedOrder.getOrderId(), completedOrder.getAddress(), completedOrder.getPackageItems()); if (parcel.isTaxable()) { // Calculate additional taxes  } // Ship parcel  this.shippedParcels.put(completedOrder.getOrderId(), parcel); }); } @Override public void listenToOrderEvents() { this.eventBus.subscribe(EVENT_ORDER_READY_FOR_SHIPMENT, new EventSubscriber() { @Override public \u0026lt;E extends ApplicationEvent\u0026gt; void onEvent(E event) { shipOrder(Integer.parseInt(event.getPayloadValue(\u0026#34;order_id\u0026#34;))); } }); } @Override public Optional\u0026lt;Parcel\u0026gt; getParcelByOrderId(int orderId) { return Optional.ofNullable(this.shippedParcels.get(orderId)); } } 该服务类似地使用ShippingOrderRepository按 id 获取订单。**更重要的是，它订阅了由另一个上下文发布的OrderReadyForShipmentEvent事件。**发生此事件时，服务会应用一些规则并发送订单。为了简单起见，我们将发货的订单存储在HashMap中。 3. 上下文映射 到目前为止，我们定义了两个上下文。但是，我们没有在它们之间设置任何明确的关系。为此，DDD 有了 Context Mapping 的概念。上下文映射是系统不同上下文之间关系的可视化描述。该地图显示了不同部分如何共存以形成域。 限界上下文之间的关系主要有五种类型：  伙伴关系——两种环境之间的关系，通过合作使两个团队与相关目标保持一致 Shared Kernel – 将多个上下文的公共部分提取到另一个上下文/模块以减少代码重复的一种关系 客户-供应商——两个上下文之间的连接，一个上下文（上游）产生数据，另一个（下游）使用它。在这种关系中，双方都有兴趣建立尽可能好的沟通 Conformist – 这种关系也有上游和下游，但是下游总是遵循上游的 API 反腐败层——这种类型的关系被广泛用于遗留系统，以使它们适应新的架构并逐渐从遗留代码库迁移。反腐败层充当适配器来转换来自上游的数据并防止意外更改  在我们的特定示例中，我们将使用共享内核关系。我们不会以纯粹的形式定义它，但它主要充当系统中事件的中介。 因此，SharedKernel 模块不包含任何具体的实现，只包含接口。 让我们从EventBus接口开始： public interface EventBus { \u0026lt;E extends ApplicationEvent\u0026gt; void publish(E event); \u0026lt;E extends ApplicationEvent\u0026gt; void subscribe(String eventType, EventSubscriber subscriber); \u0026lt;E extends ApplicationEvent\u0026gt; void unsubscribe(String eventType, EventSubscriber subscriber); } 这个接口稍后将在我们的基础设施模块中实现。 接下来，我们使用默认方法创建一个基础服务接口来支持事件驱动的通信： public interface ApplicationService { default \u0026lt;E extends ApplicationEvent\u0026gt; void publishEvent(E event) { EventBus eventBus = getEventBus(); if (eventBus != null) { eventBus.publish(event); } } default \u0026lt;E extends ApplicationEvent\u0026gt; void subscribe(String eventType, EventSubscriber subscriber) { EventBus eventBus = getEventBus(); if (eventBus != null) { eventBus.subscribe(eventType, subscriber); } } default \u0026lt;E extends ApplicationEvent\u0026gt; void unsubscribe(String eventType, EventSubscriber subscriber) { EventBus eventBus = getEventBus(); if (eventBus != null) { eventBus.unsubscribe(eventType, subscriber); } } EventBus getEventBus(); void setEventBus(EventBus eventBus); } 因此，有界上下文中的服务接口扩展此接口以具有通用的事件相关功能。 4. Java 9 模块化 现在，是时候探索 Java 9 模块系统如何支持已定义的应用程序结构了。 **Java 平台模块系统 (JPMS) 鼓励构建更可靠且封装更强大的模块。**因此，这些功能可以帮助隔离我们的上下文并建立清晰的边界。 让我们看看我们最终的模块图： 4.1 共享内核模块 让我们从 SharedKernel 模块开始，它对其他模块没有任何依赖关系。因此，module-info.java看起来像： module com.codingman.dddmodules.sharedkernel { exports com.codingman.dddmodules.sharedkernel.events; exports com.codingman.dddmodules.sharedkernel.service; } 我们导出模块接口，因此它们可用于其他模块。 4.2. OrderContext模块 接下来，让我们将注意力转移到 OrderContext 模块上。它只需要在 SharedKernel 模块中定义的接口： module com.codingman.dddmodules.ordercontext { requires com.codingman.dddmodules.sharedkernel; exports com.codingman.dddmodules.ordercontext.service; exports com.codingman.dddmodules.ordercontext.model; exports com.codingman.dddmodules.ordercontext.repository; provides com.codingman.dddmodules.ordercontext.service.OrderService with com.codingman.dddmodules.ordercontext.service.CustomerOrderService; } 此外，我们可以看到该模块导出了OrderService接口的默认实现。 4.3. ShippingContext模块 与上一个模块类似，让我们创建 ShippingContext 模块定义文件： module com.codingman.dddmodules.shippingcontext { requires com.codingman.dddmodules.sharedkernel; exports com.codingman.dddmodules.shippingcontext.service; exports com.codingman.dddmodules.shippingcontext.model; exports com.codingman.dddmodules.shippingcontext.repository; provides com.codingman.dddmodules.shippingcontext.service.ShippingService with com.codingman.dddmodules.shippingcontext.service.ParcelShippingService; } 同样，我们导出ShippingService 接口的默认实现。 4.4. 基础设施模块 现在是描述基础设施模块的时候了。该模块包含已定义接口的实现细节。我们将从为EventBus接口创建一个简单的实现开始： public class SimpleEventBus implements EventBus { private final Map\u0026lt;String, Set\u0026lt;EventSubscriber\u0026gt;\u0026gt; subscribers = new ConcurrentHashMap\u0026lt;\u0026gt;(); @Override public \u0026lt;E extends ApplicationEvent\u0026gt; void publish(E event) { if (subscribers.containsKey(event.getType())) { subscribers.get(event.getType()) .forEach(subscriber -\u0026gt; subscriber.onEvent(event)); } } @Override public \u0026lt;E extends ApplicationEvent\u0026gt; void subscribe(String eventType, EventSubscriber subscriber) { Set\u0026lt;EventSubscriber\u0026gt; eventSubscribers = subscribers.get(eventType); if (eventSubscribers == null) { eventSubscribers = new CopyOnWriteArraySet\u0026lt;\u0026gt;(); subscribers.put(eventType, eventSubscribers); } eventSubscribers.add(subscriber); } @Override public \u0026lt;E extends ApplicationEvent\u0026gt; void unsubscribe(String eventType, EventSubscriber subscriber) { if (subscribers.containsKey(eventType)) { subscribers.get(eventType).remove(subscriber); } } } 接下来，我们需要实现CustomerOrderRepository和ShippingOrderRepository接口。在大多数情况下，Order实体将存储在同一个表中，但在有界上下文中用作不同的实体模型。 很常见的是，单个实体包含来自业务领域不同区域或低级数据库映射的混合代码。对于我们的实现，我们根据有界上下文拆分了实体：CustomerOrder和ShippableOrder。 首先，让我们创建一个代表整个持久模型的类： public static class PersistenceOrder { public int orderId; public String paymentMethod; public String address; public List\u0026lt;OrderItem\u0026gt; orderItems; public static class OrderItem { public int productId; public float unitPrice; public float itemWeight; public int quantity; } } 我们可以看到这个类包含来自CustomerOrder和ShippableOrder实体的所有字段。 为简单起见，让我们模拟一个内存数据库： public class InMemoryOrderStore implements CustomerOrderRepository, ShippingOrderRepository { private Map\u0026lt;Integer, PersistenceOrder\u0026gt; ordersDb = new HashMap\u0026lt;\u0026gt;(); @Override public void saveCustomerOrder(CustomerOrder order) { this.ordersDb.put(order.getOrderId(), new PersistenceOrder(order.getOrderId(), order.getPaymentMethod(), order.getAddress(), order .getOrderItems() .stream() .map(orderItem -\u0026gt; new PersistenceOrder.OrderItem(orderItem.getProductId(), orderItem.getQuantity(), orderItem.getUnitWeight(), orderItem.getUnitPrice())) .collect(Collectors.toList()) )); } @Override public Optional\u0026lt;ShippableOrder\u0026gt; findShippableOrder(int orderId) { if (!this.ordersDb.containsKey(orderId)) return Optional.empty(); PersistenceOrder orderRecord = this.ordersDb.get(orderId); return Optional.of( new ShippableOrder(orderRecord.orderId, orderRecord.orderItems .stream().map(orderItem -\u0026gt; new PackageItem(orderItem.productId, orderItem.itemWeight, orderItem.quantity * orderItem.unitPrice) ).collect(Collectors.toList()))); } } 在这里，我们通过将持久模型转换为适当的类型或从适当的类型转换来持久和检索不同类型的实体。 最后，让我们创建模块定义： module com.codingman.dddmodules.infrastructure { requires transitive com.codingman.dddmodules.sharedkernel; requires transitive com.codingman.dddmodules.ordercontext; requires transitive com.codingman.dddmodules.shippingcontext; provides com.codingman.dddmodules.sharedkernel.events.EventBus with com.codingman.dddmodules.infrastructure.events.SimpleEventBus; provides com.codingman.dddmodules.ordercontext.repository.CustomerOrderRepository with com.codingman.dddmodules.infrastructure.db.InMemoryOrderStore; provides com.codingman.dddmodules.shippingcontext.repository.ShippingOrderRepository with com.codingman.dddmodules.infrastructure.db.InMemoryOrderStore; } 使用provide with子句，我们提供了一些在其他模块中定义的接口的实现。 此外，该模块充当依赖项的聚合器，因此我们使用requires 传递关键字。因此，需要 Infrastructure 模块的模块将传递获得所有这些依赖项。 4.5. 主模块 最后，让我们定义一个模块作为我们应用程序的入口点： module com.codingman.dddmodules.mainapp { uses com.codingman.dddmodules.sharedkernel.events.EventBus; uses com.codingman.dddmodules.ordercontext.service.OrderService; uses com.codingman.dddmodules.ordercontext.repository.CustomerOrderRepository; uses com.codingman.dddmodules.shippingcontext.repository.ShippingOrderRepository; uses com.codingman.dddmodules.shippingcontext.service.ShippingService; requires transitive com.codingman.dddmodules.infrastructure; } 由于我们刚刚在 Infrastructure 模块上设置了传递依赖项，因此我们不需要在这里显式地要求它们。 另一方面，我们使用 uses关键字列出这些依赖项。uses子句指示ServiceLoader ，我们将在下一章中发现，该模块想要使用这些接口。但是，它不需要实现在编译时可用。 5. 运行应用程序 最后，我们几乎准备好构建我们的应用程序了。我们将利用Maven来构建我们的项目。这使得使用模块变得更加容易。 5.1 项目结构 我们的项目包含五个模块和父模块。让我们看一下我们的项目结构： ddd-modules (the root directory) pom.xml |-- infrastructure |-- src |-- main | -- java module-info.java |-- com.codingman.dddmodules.infrastructure pom.xml |-- mainapp |-- src |-- main | -- java module-info.java |-- com.codingman.dddmodules.mainapp pom.xml |-- ordercontext |-- src |-- main | -- java module-info.java |--com.codingman.dddmodules.ordercontext pom.xml |-- sharedkernel |-- src |-- main | -- java module-info.java |-- com.codingman.dddmodules.sharedkernel pom.xml |-- shippingcontext |-- src |-- main | -- java module-info.java |-- com.codingman.dddmodules.shippingcontext pom.xml 5.2. 主要应用 至此，除了主应用程序之外，我们已经拥有了一切，所以让我们定义我们的main方法： public static void main(String args[]) { Map\u0026lt;Class\u0026lt;?\u0026gt;, Object\u0026gt; container = createContainer(); OrderService orderService = (OrderService) container.get(OrderService.class); ShippingService shippingService = (ShippingService) container.get(ShippingService.class); shippingService.listenToOrderEvents(); CustomerOrder customerOrder = new CustomerOrder(); int orderId = 1; customerOrder.setOrderId(orderId); List\u0026lt;OrderItem\u0026gt; orderItems = new ArrayList\u0026lt;OrderItem\u0026gt;(); orderItems.add(new OrderItem(1, 2, 3, 1)); orderItems.add(new OrderItem(2, 1, 1, 1)); orderItems.add(new OrderItem(3, 4, 11, 21)); customerOrder.setOrderItems(orderItems); customerOrder.setPaymentMethod(\u0026#34;PayPal\u0026#34;); customerOrder.setAddress(\u0026#34;Full address here\u0026#34;); orderService.placeOrder(customerOrder); if (orderId == shippingService.getParcelByOrderId(orderId).get().getOrderId()) { System.out.println(\u0026#34;Order has been processed and shipped successfully\u0026#34;); } } 让我们简要讨论一下我们的主要方法。在这种方法中，我们通过使用先前定义的服务来模拟一个简单的客户订单流。起初，我们创建了包含三个项目的订单，并提供了必要的运输和付款信息。接下来，我们提交订单，最后检查是否发货并处理成功。 但是我们是如何获得所有依赖项的，为什么createContainer方法返回Map\u0026lt;Class, Object\u0026gt;？让我们仔细看看这个方法。 5.3. 使用 ServiceLoader 进行依赖注入 在这个项目中，我们没有任何Spring IoC依赖项，因此，我们将使用ServiceLoader API来发现服务的实现。这不是一个新特性*——ServiceLoader* API 本身自 Java 6 以来就已经存在。 我们可以通过调用ServiceLoader类的静态加载方法之一来获取加载器实例。load方法返回Iterable类型，以便我们可以迭代发现的实现。 现在，让我们应用加载器来解决我们的依赖关系： public static Map\u0026lt;Class\u0026lt;?\u0026gt;, Object\u0026gt; createContainer() { EventBus eventBus = ServiceLoader.load(EventBus.class).findFirst().get(); CustomerOrderRepository customerOrderRepository = ServiceLoader.load(CustomerOrderRepository.class) .findFirst().get(); ShippingOrderRepository shippingOrderRepository = ServiceLoader.load(ShippingOrderRepository.class) .findFirst().get(); ShippingService shippingService = ServiceLoader.load(ShippingService.class).findFirst().get(); shippingService.setEventBus(eventBus); shippingService.setOrderRepository(shippingOrderRepository); OrderService orderService = ServiceLoader.load(OrderService.class).findFirst().get(); orderService.setEventBus(eventBus); orderService.setOrderRepository(customerOrderRepository); HashMap\u0026lt;Class\u0026lt;?\u0026gt;, Object\u0026gt; container = new HashMap\u0026lt;\u0026gt;(); container.put(OrderService.class, orderService); container.put(ShippingService.class, shippingService); return container; } 在这里，**我们为我们需要的每个接口调用静态加载方法，每次都会创建一个新的加载器实例。**因此，它不会缓存已解析的依赖项——相反，它每次都会创建新实例。 通常，可以通过以下两种方式之一创建服务实例。服务实现类必须具有公共无参数构造函数，或者必须使用静态提供程序方法。 因此，我们的大多数服务都有无参数的构造函数和依赖项的设置方法。但是，正如我们已经看到的，InMemoryOrderStore类实现了两个接口：CustomerOrderRepository和ShippingOrderRepository。 但是，如果我们使用load方法请求这些接口中的每一个，我们将获得InMemoryOrderStore的不同实例。这是不可取的行为，所以让我们使用提供者方法技术来缓存实例： public class InMemoryOrderStore implements CustomerOrderRepository, ShippingOrderRepository { private volatile static InMemoryOrderStore instance = new InMemoryOrderStore(); public static InMemoryOrderStore provider() { return instance; } } 我们应用了单例模式来缓存InMemoryOrderStore类的单个实例，并从提供者方法中返回它。 如果服务提供者声明了一个提供者方法，那么ServiceLoader调用这个方法来获取一个服务的实例。否则，它将尝试通过Reflection使用无参数构造函数创建一个实例。因此，我们可以在不影响我们的createContainer方法的情况下更改服务提供者机制。 最后，我们通过 setter 向服务提供已解析的依赖项并返回配置的服务。 最后，我们可以运行应用程序了。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_modules_ddd_bounded_contexts/","tags":["DDD","Java 9"],"title":"DDD 有界上下文和 Java 模块"},{"categories":["Python","BiliBili"],"contents":"conda的安装和使用、国内源、常用命令 conda的安装和使用、国内源、常用命令 \r","permalink":"http://itcodingman.github.io/conda_install_introduce/","tags":[],"title":"conda的安装和使用、国内源、常用命令"},{"categories":["Java","XML"],"contents":"1. 简介 当我们使用 XML 时，一项常见的活动是使用它的属性。在本教程中，我们将探讨如何使用 Java 修改 XML 属性。 2. 依赖 为了运行我们的测试，我们需要将JUnit和*xmlunit-assertj* 依赖项添加到我们的Maven项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.8.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xmlunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xmlunit-assertj\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.3\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 3. 使用 JAXP 让我们从一个 XML 文档开始： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;notification id=\u0026#34;5\u0026#34;\u0026gt; \u0026lt;to customer=\u0026#34;true\u0026#34;\u0026gt;[[email protected]](cdn-cgi/l/email-protection)\u0026lt;/to\u0026gt; \u0026lt;from\u0026gt;[[email protected]](cdn-cgi/l/email-protection)\u0026lt;/from\u0026gt; \u0026lt;/notification\u0026gt; 为了处理它，我们将使用 Java API for XML Processing (JAXP)，它从 1.4 版开始与 Java 捆绑在一起。 让我们修改customer属性并将其值更改为false。 首先，我们需要从 XML 文件构建一个Document对象，为此，我们将使用DocumentBuilderFactory： DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true); factory.setFeature(\u0026#34;http://apache.org/xml/features/disallow-doctype-decl\u0026#34;, true); Document input = factory .newDocumentBuilder() .parse(resourcePath); 请注意，为了禁用 DocumentBuilderFactory类的**[外部实体处理 (XXE)](https://owasp.org/www-community/vulnerabilities/XML_External_Entity_(XXE)_Processing)** ，我们配置了XMLConstants.FEATURE_SECURE_PROCESSING和http://apache.org/xml/features/disallow-doctype-decl 特征。当我们解析不受信任的 XML 文件时，配置它是一个很好的做法。 初始化我们的输入对象后，我们需要找到具有我们想要更改的属性的节点。让我们使用XPath 表达式来选择它： XPath xpath = XPathFactory .newInstance() .newXPath(); String expr = String.format(\u0026#34;//*[contains(@%s, \u0026#39;%s\u0026#39;)]\u0026#34;, attribute, oldValue); NodeList nodes = (NodeList) xpath.evaluate(expr, input, XPathConstants.NODESET); 在这种情况下，XPath评估方法返回给我们一个包含匹配节点的节点列表。 让我们遍历列表以更改值： for (int i = 0; i \u0026lt; nodes.getLength(); i++) { Element value = (Element) nodes.item(i); value.setAttribute(attribute, newValue); } 或者，我们可以使用IntStream来代替for循环： IntStream .range(0, nodes.getLength()) .mapToObj(i -\u0026gt; (Element) nodes.item(i)) .forEach(value -\u0026gt; value.setAttribute(attribute, newValue)); 现在，让我们使用Transformer对象来应用更改： TransformerFactory factory = TransformerFactory.newInstance(); factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true); Transformer xformer = factory.newTransformer(); xformer.setOutputProperty(OutputKeys.INDENT, \u0026#34;yes\u0026#34;); Writer output = new StringWriter(); xformer.transform(new DOMSource(input), new StreamResult(output)); 如果我们打印输出对象的内容，我们将得到修改了客户属性的结果 XML： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;notification id=\u0026#34;5\u0026#34;\u0026gt; \u0026lt;to customer=\u0026#34;false\u0026#34;\u0026gt;[[email protected]](cdn-cgi/l/email-protection)\u0026lt;/to\u0026gt; \u0026lt;from\u0026gt;[[email protected]](cdn-cgi/l/email-protection)\u0026lt;/from\u0026gt; \u0026lt;/notification\u0026gt; 此外，如果我们需要在单元测试中验证它，我们可以使用XMLUnit的assertThat方法： assertThat(output.toString()).hasXPath(\u0026#34;//*[contains(@customer, \u0026#39;false\u0026#39;)]\u0026#34;); 4. 使用dom4j dom4j是一个用于处理 XML 的开源框架，它与 XPath 集成并完全支持 DOM、SAX、JAXP 和 Java 集合。 4.1 Maven 依赖 我们需要将dom4j和jaxen依赖项添加到我们的pom.xml以在我们的项目中使用 dom4j： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dom4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dom4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;jaxen\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxen\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 我们可以在我们的 XML 库支持文章中了解更多关于 dom4j 的信息。 4.2. 使用org.dom4j.Element.addAttribute dom4j 提供Element接口作为 XML 元素的抽象。我们将使用addAttribute方法来更新我们的客户属性。 让我们看看这是如何工作的。 首先，我们需要从 XML 文件构建一个Document对象——这一次，我们将使用SAXReader： SAXReader xmlReader = new SAXReader(); Document input = xmlReader.read(resourcePath); xmlReader.setFeature(\u0026#34;http://apache.org/xml/features/disallow-doctype-decl\u0026#34;, true); xmlReader.setFeature(\u0026#34;http://xml.org/sax/features/external-general-entities\u0026#34;, false); xmlReader.setFeature(\u0026#34;http://xml.org/sax/features/external-parameter-entities\u0026#34;, false); 我们设置附加功能是为了防止 XXE。 像 JAXP 一样，我们可以使用 XPath 表达式来选择节点： String expr = String.format(\u0026#34;//*[contains(@%s, \u0026#39;%s\u0026#39;)]\u0026#34;, attribute, oldValue); XPath xpath = DocumentHelper.createXPath(expr); List\u0026lt;Node\u0026gt; nodes = xpath.selectNodes(input); 现在，我们可以迭代和更新属性： for (int i = 0; i \u0026lt; nodes.size(); i++) { Element element = (Element) nodes.get(i); element.addAttribute(attribute, newValue); } 请注意，使用此方法，如果给定名称的属性已存在，它将被替换。否则，它将被添加。 为了打印结果，我们可以重用前面 JAXP 部分的代码。 5. 使用 jOOX jOOX (jOOX Object-Oriented XML) 是org.w3c.dom包的包装器，允许在需要 DOM 但过于冗长的情况下流畅地创建和操作 XML 文档。jOOX 仅包装底层文档，可用于增强 DOM，而不是作为替代方案。 5.1 Maven 依赖 我们需要将依赖项添加到我们的pom.xml以在我们的项目中使用 jOOX。 对于 Java 9+，我们可以使用： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.jooq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;joox\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 或者使用 Java 6+，我们有： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.jooq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;joox-java-6\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 我们可以在 Maven 中央存储库中找到最新版本的*joox* 和*joox-java-6* 。 5.2. 使用org.w3c.dom.Element.setAttribute jOOX API 本身受到jQuery的启发，我们可以在下面的示例中看到。让我们看看如何使用它。 首先，我们需要加载Document： DocumentBuilder builder = JOOX.builder(); Document input = builder.parse(resourcePath); 现在，我们需要选择它： Match $ = $(input); 为了选择客户元素，我们可以使用find方法或 XPath 表达式。在这两种情况下，我们都会得到一个匹配它的元素列表。 让我们看看实际的find方法： $.find(\u0026#34;to\u0026#34;) .get() .stream() .forEach(e -\u0026gt; e.setAttribute(attribute, newValue)); 要获得String形式的结果，我们只需要调用*toString()*方法： $.toString(); 6. 基准 为了比较这些库的性能，我们使用了JMH基准。 让我们看看结果： | Benchmark Mode Cnt Score Error Units | |--------------------------------------------------------------------| | AttributeBenchMark.dom4jBenchmark avgt 5 0.150 ± 0.003 ms/op | | AttributeBenchMark.jaxpBenchmark avgt 5 0.166 ± 0.003 ms/op | | AttributeBenchMark.jooxBenchmark avgt 5 0.230 ± 0.033 ms/op | 正如我们所见，对于这个用例和我们的实现，dom4j 和 JAXP 比 jOOX 得分更高。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_modify_xml_attribute/","tags":[],"title":"在 Java 中修改 XML 属性"},{"categories":["Python","Youtube"],"contents":"扫雷——pygame项目实战   ","permalink":"http://itcodingman.github.io/pygame_minesweeper/","tags":[],"title":"扫雷——pygame项目实战"},{"categories":["Data","Java Collections"],"contents":"1. 概述 在本教程中，我们将解释如何使用ModelMapper框架映射不同元素类型的列表。这涉及使用 Java 中的泛型类型作为将不同类型的数据从一个列表转换为另一个列表的解决方案。 2. 模型映射器 ModelMapper 的主要作用是通过确定一个对象模型如何映射到另一个称为数据转换对象 (DTO) 的对象模型来映射对象。 为了使用ModelMapper，我们首先将依赖项添加到我们的pom.xml： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.modelmapper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;modelmapper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.1 配置 ModelMapper 提供了多种配置来简化映射过程。我们通过启用或禁用配置中的适当属性来自定义配置。将fieldMatchingEnabled属性设置为true并允许私有字段匹配是一种常见的做法： modelMapper.getConfiguration() .setFieldMatchingEnabled(true) .setFieldAccessLevel(Configuration.AccessLevel.PRIVATE); 通过这样做，ModelMapper 可以比较映射类（对象）中的私有字段。在这种配置中，两个类中都存在具有相同名称的所有字段并不是绝对必要的。允许使用多种匹配策略。默认情况下，标准匹配策略要求必须以任意顺序匹配所有源和目标属性。这非常适合我们的场景。 2.2. TypeToken ModelMapper 使用TypeToken来映射泛型类型。要了解为什么这是必要的，让我们看看当我们将Integer列表映射到Character列表时会发生什么： List\u0026lt;Integer\u0026gt; integers = new ArrayList\u0026lt;Integer\u0026gt;(); integers.add(1); integers.add(2); integers.add(3); List\u0026lt;Character\u0026gt; characters = new ArrayList\u0026lt;Character\u0026gt;(); modelMapper.map(integers, characters); 此外，如果我们打印出字符列表的元素，我们会看到一个空列表。这是由于在运行时执行期间发生了类型擦除。 但是，如果我们将map调用更改为使用TypeToken，我们可以为*List*创建一个类型文字： List\u0026lt;Character\u0026gt; characters = modelMapper.map(integers, new TypeToken\u0026lt;List\u0026lt;Character\u0026gt;\u0026gt;() {}.getType()); **在编译的时候，TokenType匿名内壳保留了 *List***参数类型，这一次我们的转换就成功了。 3. 使用自定义类型映射 Java 中的列表可以使用自定义元素类型进行映射。 例如，假设我们要将用户实体列表映射到UserDTO列表。为此，我们将为每个元素调用map ： List\u0026lt;UserDTO\u0026gt; dtos = users .stream() .map(user -\u0026gt; modelMapper.map(user, UserDTO.class)) .collect(Collectors.toList()); 当然，通过更多的工作，我们可以制作一个通用的参数化方法： \u0026lt;S, T\u0026gt; List\u0026lt;T\u0026gt; mapList(List\u0026lt;S\u0026gt; source, Class\u0026lt;T\u0026gt; targetClass) { return source .stream() .map(element -\u0026gt; modelMapper.map(element, targetClass)) .collect(Collectors.toList()); } 那么，我们可以改为： List\u0026lt;UserDTO\u0026gt; userDtoList = mapList(users, UserDTO.class); 4. 类型映射和属性映射 可以将特定属性（例如列表或集合）添加到User-UserDTO模型中。TypeMap 提供了一种显式定义这些属性映射的方法。TypeMap对象存储特定类型（类）的映射信息： TypeMap\u0026lt;UserList, UserListDTO\u0026gt; typeMap = modelMapper.createTypeMap(UserList.class, UserListDTO.class); UserList类包含User的集合。在这里，我们希望将此集合中的用户名列表映射到UserListDTO类的属性列表。为此，我们将创建第一个UsersListConverter类并将*List 和List *作为参数类型传递给它以进行转换： public class UsersListConverter extends AbstractConverter\u0026lt;List\u0026lt;User\u0026gt;, List\u0026lt;String\u0026gt;\u0026gt; { @Override protected List\u0026lt;String\u0026gt; convert(List\u0026lt;User\u0026gt; users) { return users .stream() .map(User::getUsername) .collect(Collectors.toList()); } } 从创建的TypeMap对象中，我们通过调用UsersListConverter类的实例显式添加属性映射： typeMap.addMappings(mapper -\u0026gt; mapper.using(new UsersListConverter()) .map(UserList::getUsers, UserListDTO::setUsernames)); 在addMappings方法中，表达式映射允许我们使用 lambda 表达式定义源到目标属性。最后，它将用户列表转换为生成的用户名列表。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_modelmapper_lists/","tags":[],"title":"使用 ModelMapper 映射列表"},{"categories":["Java"],"contents":"1. 简介 在之前的教程中，我们已经了解了如何使用 ModelMapper 映射列表。 在本教程中，我们将展示如何在 ModelMapper 中的不同结构对象之间映射我们的数据。 尽管 ModelMapper 的默认转换在典型情况下效果很好，但我们将主要关注如何匹配不够相似的对象，无法使用默认配置进行处理。 因此，我们这次将着眼于属性映射和配置更改。 2. Maven依赖 要开始使用 ModelMapper库，我们将依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.modelmapper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;modelmapper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 默认配置 当我们的源对象和目标对象彼此相似时，ModelMapper 提供了一个插入式解决方案。 让我们看看Game和*GameDTO，*分别是我们的领域对象和对应的数据传输对象： public class Game { private Long id; private String name; private Long timestamp; private Player creator; private List\u0026lt;Player\u0026gt; players = new ArrayList\u0026lt;\u0026gt;(); private GameSettings settings; // constructors, getters and setters } public class GameDTO { private Long id; private String name; // constructors, getters and setters } GameDTO仅包含两个字段，但字段类型和名称与源完美匹配。 在这种情况下，ModelMapper 无需额外配置即可处理转换： @BeforeEach public void setup() { this.mapper = new ModelMapper(); } @Test public void whenMapGameWithExactMatch_thenConvertsToDTO() { // when similar source object is provided  Game game = new Game(1L, \u0026#34;Game 1\u0026#34;); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then it maps by default  assertEquals(game.getId(), gameDTO.getId()); assertEquals(game.getName(), gameDTO.getName()); } 4. 什么是ModelMapper中的属性映射 在我们的项目中，大多数时候，我们需要定制我们​​的 DTO。当然，这将导致不同的字段、层次结构以及它们彼此之间的不规则映射。有时，我们还需要多个 DTO 用于单个源，反之亦然。 因此，属性映射为我们提供了一种扩展映射逻辑的强大方法。 让我们通过添加一个新字段creationTime来自定义我们的GameDTO： public class GameDTO { private Long id; private String name; private Long creationTime; // constructors, getters and setters } 而且，我们会将Game的时间戳字段映射到GameDTO的creationTime字段。我们注意到，这次源字段名称与目标字段名称不同。 要定义属性映射，我们将使用 ModelMapper 的TypeMap。所以，让我们创建一个TypeMap对象并通过它的addMapping方法添加一个属性映射： @Test public void whenMapGameWithBasicPropertyMapping_thenConvertsToDTO() { // setup  TypeMap\u0026lt;Game, GameDTO\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, GameDTO.class); propertyMapper.addMapping(Game::getTimestamp, GameDTO::setCreationTime); // when field names are different  Game game = new Game(1L, \u0026#34;Game 1\u0026#34;); game.setTimestamp(Instant.now().getEpochSecond()); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then it maps via property mapper  assertEquals(game.getId(), gameDTO.getId()); assertEquals(game.getName(), gameDTO.getName()); assertEquals(game.getTimestamp(), gameDTO.getCreationTime()); } 4.1 深度映射 也有不同的映射方式。例如，ModelMapper 可以映射层次结构——不同层次的字段可以被深度映射。  让我们在GameDTO中定义一个名为creator的字符串字段。然而，Game域中的 source creator字段不是一个简单的类型，而是一个对象—— Player： public class Player { private Long id; private String name; // constructors, getters and setters } public class Game { // ...  private Player creator; // ... } public class GameDTO { // ...  private String creator; // ... } 因此，我们不会将整个Player对象的数据，而只会将name字段传输到GameDTO。为了定义深度映射，我们使用TypeMap的addMappings方法并添加一个ExpressionMap： @Test public void whenMapGameWithDeepMapping_thenConvertsToDTO() { // setup  TypeMap\u0026lt;Game, GameDTO\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, GameDTO.class); // add deep mapping to flatten source\u0026#39;s Player object into a single field in destination  propertyMapper.addMappings( mapper -\u0026gt; mapper.map(src -\u0026gt; src.getCreator().getName(), GameDTO::setCreator) ); // when map between different hierarchies  Game game = new Game(1L, \u0026#34;Game 1\u0026#34;); game.setCreator(new Player(1L, \u0026#34;John\u0026#34;)); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then  assertEquals(game.getCreator().getName(), gameDTO.getCreator()); } 4.2. 跳过属性 有时，我们不想公开 DTO 中的所有数据。无论是保持我们的 DTO 更轻或隐藏一些敏感数据，这些原因都会导致我们在转移到 DTO 时排除某些字段。 幸运的是，ModelMapper 通过 skipping 支持属性排除。 让我们借助skip方法将id字段排除在传输之外： @Test public void whenMapGameWithSkipIdProperty_thenConvertsToDTO() { // setup  TypeMap\u0026lt;Game, GameDTO\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, GameDTO.class); propertyMapper.addMappings(mapper -\u0026gt; mapper.skip(GameDTO::setId)); // when id is skipped  Game game = new Game(1L, \u0026#34;Game 1\u0026#34;); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then destination id is null  assertNull(gameDTO.getId()); assertEquals(game.getName(), gameDTO.getName()); } 因此，GameDTO的**id字段被跳过而不设置。 4.3. 转换器 ModelMapper 的另一个规定是Converter。我们可以自定义特定源到目标映射的转换。 假设我们在Game域中有一个Player的集合。让我们将Player的计数转移到GameDTO。 作为第一步，我们在GameDTO中定义一个整数字段**totalPlayers： public class GameDTO { // ...  private int totalPlayers; // constructors, getters and setters } 我们分别创建了collectionToSize 转换器： Converter\u0026lt;Collection, Integer\u0026gt; collectionToSize = c -\u0026gt; c.getSource().size(); 最后，我们在添加ExpressionMap时通过using方法注册我们的转换器： propertyMapper.addMappings( mapper -\u0026gt; mapper.using(collectionToSize).map(Game::getPlayers, GameDTO::setTotalPlayers) ); 结果，我们将Game的getPlayers().size()映射到GameDTO的totalPlayers字段： @Test public void whenMapGameWithCustomConverter_thenConvertsToDTO() { // setup  TypeMap\u0026lt;Game, GameDTO\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, GameDTO.class); Converter\u0026lt;Collection, Integer\u0026gt; collectionToSize = c -\u0026gt; c.getSource().size(); propertyMapper.addMappings( mapper -\u0026gt; mapper.using(collectionToSize).map(Game::getPlayers, GameDTO::setTotalPlayers) ); // when collection to size converter is provided  Game game = new Game(); game.addPlayer(new Player(1L, \u0026#34;John\u0026#34;)); game.addPlayer(new Player(2L, \u0026#34;Bob\u0026#34;)); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then it maps the size to a custom field  assertEquals(2, gameDTO.getTotalPlayers()); } 4.4. Provider 在另一个用例中，我们有时需要为目标对象提供一个实例，而不是让 ModalMapper 对其进行初始化。这就是Provider派上用场的地方。 因此，ModelMapper 的Provider是自定义目标对象实例化的内置方式。 让我们进行转换，这次不是从游戏到 DTO，而是从游戏到游戏。 所以，原则上，我们有一个持久化的游戏域，我们从它的存储库中获取它。之后，我们通过合并另一个Game对象来更新Game实例： @Test public void whenUsingProvider_thenMergesGameInstances() { // setup  TypeMap\u0026lt;Game, Game\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, Game.class); // a provider to fetch a Game instance from a repository  Provider\u0026lt;Game\u0026gt; gameProvider = p -\u0026gt; this.gameRepository.findById(1L); propertyMapper.setProvider(gameProvider); // when a state for update is given  Game update = new Game(1L, \u0026#34;Game Updated!\u0026#34;); update.setCreator(new Player(1L, \u0026#34;John\u0026#34;)); Game updatedGame = this.mapper.map(update, Game.class); // then it merges the updates over on the provided instance  assertEquals(1L, updatedGame.getId().longValue()); assertEquals(\u0026#34;Game Updated!\u0026#34;, updatedGame.getName()); assertEquals(\u0026#34;John\u0026#34;, updatedGame.getCreator().getName()); } 4.5. 条件映射 ModelMapper 还支持条件映射。我们可以使用的内置条件方法之一是Conditions.isNull()。 让我们跳过id字段，以防它在我们的源游戏对象中为空： @Test public void whenUsingConditionalIsNull_thenMergesGameInstancesWithoutOverridingId() { // setup  TypeMap\u0026lt;Game, Game\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, Game.class); propertyMapper.setProvider(p -\u0026gt; this.gameRepository.findById(2L)); propertyMapper.addMappings(mapper -\u0026gt; mapper.when(Conditions.isNull()).skip(Game::getId, Game::setId)); // when game has no id  Game update = new Game(null, \u0026#34;Not Persisted Game!\u0026#34;); Game updatedGame = this.mapper.map(update, Game.class); // then destination game id is not overwritten  assertEquals(2L, updatedGame.getId().longValue()); assertEquals(\u0026#34;Not Persisted Game!\u0026#34;, updatedGame.getName()); } 正如我们所注意到的，通过结合使用isNull条件和skip方法，我们可以保护我们的目标id不被**null值覆盖。 此外，我们**还可以定义自定义Condition。**让我们定义一个条件来检查Game的时间戳字段是否有值： Condition\u0026lt;Long, Long\u0026gt; hasTimestamp = ctx -\u0026gt; ctx.getSource() != null \u0026amp;\u0026amp; ctx.getSource() \u0026gt; 0; 接下来，我们在属性映射器中使用when方法： TypeMap\u0026lt;Game, GameDTO\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, GameDTO.class); Condition\u0026lt;Long, Long\u0026gt; hasTimestamp = ctx -\u0026gt; ctx.getSource() != null \u0026amp;\u0026amp; ctx.getSource() \u0026gt; 0; propertyMapper.addMappings( mapper -\u0026gt; mapper.when(hasTimestamp).map(Game::getTimestamp, GameDTO::setCreationTime) ); 最后，ModelMapper 仅在时间戳的值大于零时更新GameDTO 的 creationTime字段： @Test public void whenUsingCustomConditional_thenConvertsDTOSkipsZeroTimestamp() { // setup  TypeMap\u0026lt;Game, GameDTO\u0026gt; propertyMapper = this.mapper.createTypeMap(Game.class, GameDTO.class); Condition\u0026lt;Long, Long\u0026gt; hasTimestamp = ctx -\u0026gt; ctx.getSource() != null \u0026amp;\u0026amp; ctx.getSource() \u0026gt; 0; propertyMapper.addMappings( mapper -\u0026gt; mapper.when(hasTimestamp).map(Game::getTimestamp, GameDTO::setCreationTime) ); // when game has zero timestamp  Game game = new Game(1L, \u0026#34;Game 1\u0026#34;); game.setTimestamp(0L); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then timestamp field is not mapped  assertEquals(game.getId(), gameDTO.getId()); assertEquals(game.getName(), gameDTO.getName()); assertNotEquals(0L ,gameDTO.getCreationTime()); // when game has timestamp greater than zero  game.setTimestamp(Instant.now().getEpochSecond()); gameDTO = this.mapper.map(game, GameDTO.class); // then timestamp field is mapped  assertEquals(game.getId(), gameDTO.getId()); assertEquals(game.getName(), gameDTO.getName()); assertEquals(game.getTimestamp() ,gameDTO.getCreationTime()); } 5. 其他映射方式 在大多数情况下，属性映射是一种很好的方法，因为它允许我们做出明确的定义并清楚地看到映射是如何流动的。 但是，对于某些对象，尤其是当它们具有不同的属性层次结构时，我们可以使用LOOSE匹配策略而不是TypeMap。 5.1 匹配策略LOOSE 为了演示松散匹配的好处，让我们在GameDTO中再添加两个属性： public class GameDTO { //...  private GameMode mode; private int maxPlayers; // constructors, getters and setters } 我们应该注意到mode和maxPlayers对应于GameSettings 的属性，它是我们Game源类中的一个内部对象： public class GameSettings { private GameMode mode; private int maxPlayers; // constructors, getters and setters } 因此，我们可以在不定义任何TypeMap的情况下执行从Game到GameDTO以及其他方式的双向映射： @Test public void whenUsingLooseMappingStrategy_thenConvertsToDomainAndDTO() { // setup  this.mapper.getConfiguration().setMatchingStrategy(MatchingStrategies.LOOSE); // when dto has flat fields for GameSetting  GameDTO gameDTO = new GameDTO(); gameDTO.setMode(GameMode.TURBO); gameDTO.setMaxPlayers(8); Game game = this.mapper.map(gameDTO, Game.class); // then it converts to inner objects without property mapper  assertEquals(gameDTO.getMode(), game.getSettings().getMode()); assertEquals(gameDTO.getMaxPlayers(), game.getSettings().getMaxPlayers()); // when the GameSetting\u0026#39;s field names match  game = new Game(); game.setSettings(new GameSettings(GameMode.NORMAL, 6)); gameDTO = this.mapper.map(game, GameDTO.class); // then it flattens the fields on dto  assertEquals(game.getSettings().getMode(), gameDTO.getMode()); assertEquals(game.getSettings().getMaxPlayers(), gameDTO.getMaxPlayers()); } 5.2. 自动跳过空属性 此外，ModelMapper 具有一些有用的全局配置。其中之一是setSkipNullEnabled设置。 因此，如果源属性为空，我们可以自动跳过源属性，而无需编写任何条件映射： @Test public void whenConfigurationSkipNullEnabled_thenConvertsToDTO() { // setup  this.mapper.getConfiguration().setSkipNullEnabled(true); TypeMap\u0026lt;Game, Game\u0026gt; propertyMap = this.mapper.createTypeMap(Game.class, Game.class); propertyMap.setProvider(p -\u0026gt; this.gameRepository.findById(2L)); // when game has no id  Game update = new Game(null, \u0026#34;Not Persisted Game!\u0026#34;); Game updatedGame = this.mapper.map(update, Game.class); // then destination game id is not overwritten  assertEquals(2L, updatedGame.getId().longValue()); assertEquals(\u0026#34;Not Persisted Game!\u0026#34;, updatedGame.getName()); } 5.3. 循环引用对象 有时，我们需要处理具有自身引用的对象。通常，这会导致循环依赖并导致著名的StackOverflowError： org.modelmapper.MappingException: ModelMapper mapping errors: 1) Error mapping com.bealdung.domain.Game to com.bealdung.dto.GameDTO 1 error ... Caused by: java.lang.StackOverflowError ... 因此，在这种情况下，另一个配置setPreferNestedProperties将帮助我们： @Test public void whenConfigurationPreferNestedPropertiesDisabled_thenConvertsCircularReferencedToDTO() { // setup  this.mapper.getConfiguration().setPreferNestedProperties(false); // when game has circular reference: Game -\u0026gt; Player -\u0026gt; Game  Game game = new Game(1L, \u0026#34;Game 1\u0026#34;); Player player = new Player(1L, \u0026#34;John\u0026#34;); player.setCurrentGame(game); game.setCreator(player); GameDTO gameDTO = this.mapper.map(game, GameDTO.class); // then it resolves without any exception  assertEquals(game.getId(), gameDTO.getId()); assertEquals(game.getName(), gameDTO.getName()); } 因此，当我们将false传递给setPreferNestedProperties时，映射将毫无例外地工作。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_modelmapper/","tags":[],"title":"ModelMapper 使用指南"},{"categories":["Java","Testing"],"contents":"1. 简介 Mockito是一个流行的 Java 模拟框架。有了它，创建模拟对象、配置模拟行为、捕获方法参数以及验证与模拟的交互都很简单。 **现在，我们将专注于指定模拟行为。我们有两种方法可以做到这一点： when().thenDoSomething()和doSomething().when()语法。 在这个简短的教程中，我们将了解为什么我们同时拥有它们。 2. *when()*方法 让我们考虑以下Employee接口： interface Employee { String greet(); void work(DayOfWeek day); } 在我们的测试中，我们使用这个接口的模拟。假设我们要配置 mock 的greet()方法以返回字符串“Hello”。使用 Mockito 的*when()*方法很简单： @Test void givenNonVoidMethod_callingWhen_shouldConfigureBehavior() { // given  when(employee.greet()).thenReturn(\u0026#34;Hello\u0026#34;); // when  String greeting = employee.greet(); // then  assertThat(greeting, is(\u0026#34;Hello\u0026#34;)); } 怎么了？员工对象是一个模拟对象。*当我们调用它的任何方法时，Mockito 会注册该调用。通过调用*when()方法，Mockito 知道此调用不是业务逻辑的交互。这是我们想要为模拟对象分配一些行为的声明。之后，使用thenXxx()方法之一，我们指定预期的行为。 直到这一点，这是很好的老嘲讽。*同样，当我们使用 Sunday 参数调用work()*方法时，我们希望将其配置为抛出异常： @Test void givenVoidMethod_callingWhen_wontCompile() { // given  when(employee.work(DayOfWeek.SUNDAY)).thenThrow(new IAmOnHolidayException()); // when  Executable workCall = () -\u0026gt; employee.work(DayOfWeek.SUNDAY); // then  assertThrows(IAmOnHolidayException.class, workCall); } **不幸的是，这段代码无法编译，因为在*work(employee.work(…))*调用中，work()方法的返回类型为void ；因此我们不能将它包装到另一个方法调用中。**这是否意味着我们不能模拟 void 方法？我们当然可以。doXxx方法来救援！ 3. *doXxx()*方法 让我们看看如何使用*doThrow()*方法配置异常抛出： @Test void givenVoidMethod_callingDoThrow_shouldConfigureBehavior() { // given  doThrow(new IAmOnHolidayException()).when(employee).work(DayOfWeek.SUNDAY); // when  Executable workCall = () -\u0026gt; employee.work(DayOfWeek.SUNDAY); // then  assertThrows(IAmOnHolidayException.class, workCall); } 这种语法与前一种略有不同：我们不会尝试将void方法调用包装在另一个方法调用中。因此，此代码编译。 让我们看看刚刚发生了什么。*首先，我们声明我们要抛出异常。接下来，我们调用了*when()方法，并传递了模拟对象。之后，我们指定了我们想要配置的模拟交互行为。 请注意，这与我们之前使用的*when()方法不同。另外，请注意，我们在调用when() 之后链接了模拟交互。*同时，我们用第一种语法在括号内定义了它。 为什么我们有第一个when().thenXxx()，当它不能完成像配置void调用这样的常见任务时？*它与doXxx().when()*语法相比具有多个优点。 首先，开发人员编写和阅读诸如“当一些交互时，然后做某事”之类的语句比“做某事，当一些交互时”更合乎逻辑。 其次，我们可以通过链接将多个行为添加到同一个交互中。那是因为*when()返回类OngoingStubbing的实例，而thenXxx()*方法返回相同的类型。 另一方面，doXxx()方法返回一个Stubber实例，而Stubber.when(T mock)返回 T，所以我们可以指定我们想要配置什么样的方法调用。但是T是我们应用程序的一部分，例如，我们的代码片段中的Employee。但是T不会返回 Mockito 类，因此我们将无法通过链接添加多个行为。 4. BDDMockito BDDMockito使用我们介绍的替代语法。这很简单：在我们的模拟配置中，我们必须将关键字“ *when”*替换为“ given ”，将关键字“ do ”替换为“ will ”。除此之外，我们的代码保持不变： @Test void givenNonVoidMethod_callingGiven_shouldConfigureBehavior() { // given  given(employee.greet()).willReturn(\u0026#34;Hello\u0026#34;); // when  String greeting = employee.greet(); // then  assertThat(greeting, is(\u0026#34;Hello\u0026#34;)); } @Test void givenVoidMethod_callingWillThrow_shouldConfigureBehavior() { // given  willThrow(new IAmOnHolidayException()).given(employee).work(DayOfWeek.SUNDAY); // when  Executable workCall = () -\u0026gt; employee.work(DayOfWeek.SUNDAY); // then  assertThrows(IAmOnHolidayException.class, workCall); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_mockito_when_vs_do/","tags":["Mockito"],"title":"Mockito 中 when() 和 doXxx() 方法的区别"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将研究 Java 开发过程中的一个常见错误。通常，初学者会面临这个问题，Java 应用程序中缺少返回语句错误。 缺少返回语句错误是编译时错误。它在编译阶段抛出。现代 IDE 会即时检查此错误。因此，这种类型的错误往往很容易被发现。 主要原因是：  错误地省略了 return 语句 该方法不返回任何值，但方法签名中未声明类型 void  2. 缺少return声明 首先，我们将看几个例子。这些示例与错误省略的 return 语句有关。然后，我们将在方法签名中寻找缺少 void 类型的示例。每个示例都展示了我们如何解决 java 缺少返回语句错误。 2.1 省略return声明 接下来，让我们定义一个简单的pow方法： public int pow(int number) { int pow = number * number; } 作为编译前面代码的结果，我们得到： java: missing return statement 为了解决这个问题，我们只需在pow变量后添加一个 return 语句： public int pow(int number) { int pow = number * number; return pow; } 因此，如果我们调用方法*pow，*我们会得到预期的结果。 同样，但使用条件结构时，会出现此错误： public static String checkNumber(int number) { if (number == 0) { return \u0026#34;It\u0026#39;s equals to zero\u0026#34;; } for (int i = 0; i \u0026lt; number; i++) { if (i \u0026gt; 100) { return \u0026#34;It\u0026#39;s a big number\u0026#34;; } } } 上面的代码检查输入的数字。首先，将输入的数字与 0 进行比较。如果条件为真，则返回一个字符串值。然后，如果数字大于 0，我们会找到一个带有内部条件的for 循环。如果“ i ”大于 100，则我们在 for 循环中的条件语句得到满足。但是，负输入数呢？是的你是对的。我们错过了默认的退货声明。因此，如果我们编译我们的代码，我们会再次得到java: missing return statement错误。 所以，为了修复它，我们只需要在方法的末尾添加一个默认的 return 语句： public static String checkNumber(int number) { if (number == 0) { return \u0026#34;It\u0026#39;s equals to zero\u0026#34;; } for (int i = 0; i \u0026lt; number; i++) { if (i \u0026gt; 100) { return \u0026#34;It\u0026#39;s a big number\u0026#34;; } } return \u0026#34;It\u0026#39;s a negative number\u0026#34;; } 2.2. Lambda 中的缺失return 此外，当我们使用 lambdas 时，可能会出现此错误。对于函数，检测此错误可能有点棘手。流中的*map*方法是发生此错误的常见地方。让我们检查一下我们的代码： public Map\u0026lt;String, Integer\u0026gt; createDictionary() { List\u0026lt;String\u0026gt; words = Arrays.asList(\u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;); Map\u0026lt;String, Integer\u0026gt; dictionary = new HashMap\u0026lt;\u0026gt;(); words.stream().map(s -\u0026gt; {dictionary.put(s, 1);}); return dictionary; } 前面的代码看起来不错。有退货声明。我们的返回数据类型等于方法签名。但是，流中map方法中的代码呢？map方法需要一个函数作为参数。在这种情况下，我们只将数据放入 map 方法中的字典中。结果，如果我们尝试编译这段代码，我们会再次得到java: missing return statement错误。 接下来，要解决错误，我们只需将map替换为流中的*forEach*方法： words.forEach(s -\u0026gt; {dictionary.put(s, 1);}); 或者，直接从流中返回一个地图： dictionary = words.stream().collect(Collectors.toMap(s -\u0026gt; s, s -\u0026gt; 1)) 2.3. 缺少方法签名 最后，最后一种情况是我们错过了在方法签名中添加返回类型。因此，当我们尝试编译我们的方法时，我们会得到一个错误。以下代码示例向我们展示了这种行为： public pow(int number) { int pow = number * number; return pow; } 我们忘记将 int 添加为返回类型。如果我们将它添加到我们的方法签名将修复这个错误： public int pow(int number) { int pow = number * number; return pow; } \u0026quot; ","permalink":"http://itcodingman.github.io/java_missing_return_statement/","tags":[],"title":"Java 缺少返回语句"},{"categories":["Python","BiliBili"],"contents":"PIP安装和使用、国内源、常用命令 PIP安装和使用、国内源、常用命令 \r","permalink":"http://itcodingman.github.io/pip_install_introduce/","tags":[],"title":"PIP安装和使用、国内源、常用命令"},{"categories":["Algorithms","Programming"],"contents":"1. 概述 在本文中，我们将讨论Minimax 算法及其在 AI 中的应用。由于它是一种博弈论算法，我们将使用它来实现一个简单的游戏。 我们还将讨论使用该算法的优势，并了解如何改进它。 2. 简介 Minimax 是一种决策算法，通常用于基于回合的两人游戏。该算法的目标是找到最优的下一步行动。 在算法中，一个玩家被称为最大化者，另一个玩家被称为最小化者。如果我们给棋盘分配一个评价分数，一个玩家试图选择一个得分最高的游戏状态，而另一个玩家选择一个得分最低的状态。 换句话说，最大化者努力获得最高分，而最小化者试图通过反击来获得最低分。 它基于零和游戏的概念。**在零和游戏中，总效用得分在玩家之间进行分配。一个玩家得分的增加会导致另一个玩家得分的减少。**因此，总分始终为零。一名球员获胜，另一名球员必须输球。此类游戏的示例是国际象棋、扑克、跳棋、井字游戏。 一个有趣的事实——1997 年，IBM 的国际象棋计算机 Deep Blue（使用 Minimax 构建）击败了 Garry Kasparov（国际象棋世界冠军）。 3. 极小极大算法 我们的目标是为玩家找到最佳移动。为此，我们可以选择具有最佳评估分数的节点。为了使过程更智能，我们还可以向前看并评估潜在对手的动作。 对于每一步，我们可以在我们的计算能力允许的范围内预测尽可能多的移动。该算法假设对手打得最好。 从技术上讲，我们从根节点开始，选择最好的节点。我们根据节点的评估分数来评估节点。在我们的例子中，评估函数只能将分数分配给结果节点（叶子）。因此，我们递归地到达带有分数的叶子并反向传播分数。 考虑下面的博弈树： Maximizer从根节点开始，选择得分最高的移动。不幸的是，只有叶子有评估分数，因此算法必须递归地到达叶子节点。在给定的博弈树中，目前轮到最小化器从叶节点中选择移动，因此得分最小的节点（此处为节点 3 和 4）将被选中。它不断地选择最好的节点，直到它到达根节点。 现在，让我们正式定义算法的步骤：   构建完整的博弈树   使用评估函数评估叶子的分数   考虑玩家类型，从叶子到根的备份分数：  对于最大玩家，选择得分最高的孩子 对于 min player，选择得分最低的孩子    在根节点，选择最大值的节点并进行相应的移动   4. 实施 现在，让我们实现一个游戏。 在游戏中，我们有一个有n个骨头的堆。两名玩家必须轮流拿起 1,2 或 3 块骨头。不能拿走骨头的玩家输掉游戏。每个球员发挥最佳。给定n的值，让我们编写一个 AI。 为了定义游戏规则，我们将实现GameOfBones类： class GameOfBones { static List\u0026lt;Integer\u0026gt; getPossibleStates(int noOfBonesInHeap) { return IntStream.rangeClosed(1, 3).boxed() .map(i -\u0026gt; noOfBonesInHeap - i) .filter(newHeapCount -\u0026gt; newHeapCount \u0026gt;= 0) .collect(Collectors.toList()); } } 此外，我们还需要Node和Tree类的实现： public class Node { int noOfBones; boolean isMaxPlayer; int score; List\u0026lt;Node\u0026gt; children; // setters and getters } public class Tree { Node root; // setters and getters } 现在我们将实现算法。它需要一个博弈树来向前看并找到最佳移动。让我们实现它： public class MiniMax { Tree tree; public void constructTree(int noOfBones) { tree = new Tree(); Node root = new Node(noOfBones, true); tree.setRoot(root); constructTree(root); } private void constructTree(Node parentNode) { List\u0026lt;Integer\u0026gt; listofPossibleHeaps = GameOfBones.getPossibleStates(parentNode.getNoOfBones()); boolean isChildMaxPlayer = !parentNode.isMaxPlayer(); listofPossibleHeaps.forEach(n -\u0026gt; { Node newNode = new Node(n, isChildMaxPlayer); parentNode.addChild(newNode); if (newNode.getNoOfBones() \u0026gt; 0) { constructTree(newNode); } }); } } 现在，我们将实现checkWin方法，该方法将通过为两个玩家选择最佳动作来模拟比赛。它将分数设置为：  +1，如果最大化者获胜 -1，如果最小化器获胜  如果第一个玩家（在我们的例子中 – 最大化者）获胜，则checkWin将返回 true： public boolean checkWin() { Node root = tree.getRoot(); checkWin(root); return root.getScore() == 1; } private void checkWin(Node node) { List\u0026lt;Node\u0026gt; children = node.getChildren(); boolean isMaxPlayer = node.isMaxPlayer(); children.forEach(child -\u0026gt; { if (child.getNoOfBones() == 0) { child.setScore(isMaxPlayer ? 1 : -1); } else { checkWin(child); } }); Node bestChild = findBestChild(isMaxPlayer, children); node.setScore(bestChild.getScore()); } 在这里，如果玩家是最大化者， findBestChild方法会找到得分最高的节点。否则，它返回具有最低分数的孩子： private Node findBestChild(boolean isMaxPlayer, List\u0026lt;Node\u0026gt; children) { Comparator\u0026lt;Node\u0026gt; byScoreComparator = Comparator.comparing(Node::getScore); return children.stream() .max(isMaxPlayer ? byScoreComparator : byScoreComparator.reversed()) .orElseThrow(NoSuchElementException::new); } 最后，让我们用一些n值（堆中的骨头数）来实现一个测试用例： @Test public void givenMiniMax_whenCheckWin_thenComputeOptimal() { miniMax.constructTree(6); boolean result = miniMax.checkWin(); assertTrue(result); miniMax.constructTree(8); result = miniMax.checkWin(); assertFalse(result); } 5. 改进 对于大多数问题，构建一棵完整的博弈树是不可行的。在实践中，我们可以开发部分树（仅将树构建到预定义的级别数）。 然后，我们必须实现一个**评估函数，**它应该能够为玩家决定当前状态有多好。 即使我们不构建完整的博弈树，计算具有高分支因子的博弈的移动也可能很耗时。 幸运的是，有一个选项可以找到最佳移动，而无需探索博弈树的每个节点。我们可以通过遵循一些规则跳过一些分支，并且不会影响最终结果。这个过程称为剪枝。Alpha-beta 剪枝是极小极大算法的一种流行变体。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_minimax_algorithm/","tags":[],"title":"使用 Java 实现的 Minimax 算法简介"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将了解如何在 Java中实现最小-最大堆。 2. 最小-最大堆 首先，我们来看看堆的定义和特点。min-max heap 是一棵完全二叉树，同时具有 min heap 和 max heap 的特征： 正如我们在上面看到的，树中偶数层的每个节点都小于其所有后代，而树中奇数层的每个节点都大于其所有后代，其中根位于零层。 最小-最大堆中的每个节点都有一个通常称为键的数据成员。根在最小-最大堆中具有最小的键，第二级的两个节点之一是最大的键。对于最小-最大堆中的每个节点（如X ）：  如果X处于最小（甚至）级别，则X.key是具有根**X的子树中所有键中的最小键 如果X处于最大（或奇数）级别，则X.key是具有根**X的子树中所有键中的最大键  像 min-heap 或 max-heap 一样，插入和删除可以在O(logN)的时间复杂度内发生。 3. Java实现 让我们从一个代表我们的 min-max 堆的简单类开始： public class MinMaxHeap\u0026lt;T extends Comparable\u0026lt;T\u0026gt;\u0026gt; { private List\u0026lt;T\u0026gt; array; private int capacity; private int indicator; } 正如我们在上面看到的，我们使用一个指标来计算添加到数组中的最后一项索引。但在我们继续之前，我们需要记住数组索引从零开始，但我们假设索引从堆中的一开始。 我们可以使用以下方法找到左右孩子的索引： private int getLeftChildIndex(int i) { return 2 * i; } private int getRightChildIndex(int i) { return ((2 * i) + 1); } 同样，我们可以通过以下代码找到数组中项的父辈和祖辈的索引： private int getParentIndex(int i) { return i / 2; } private int getGrandparentIndex(int i) { return i / 4; } 现在，让我们继续完成我们简单的 min-max 堆类： public class MinMaxHeap\u0026lt;T extends Comparable\u0026lt;T\u0026gt;\u0026gt; { private List\u0026lt;T\u0026gt; array; private int capacity; private int indicator; MinMaxHeap(int capacity) { array = new ArrayList\u0026lt;\u0026gt;(); this.capacity = capacity; indicator = 1; } MinMaxHeap(List\u0026lt;T\u0026gt; array) { this.array = array; this.capacity = array.size(); this.indicator = array.size() + 1; } } 我们可以在这里以两种方式创建最小-最大堆的实例。首先，我们使用ArrayList和特定容量初始化一个数组，其次，我们从现有数组中创建一个最小-最大堆。 现在，让我们讨论堆上的操作。 3.1 创造 让我们首先看一下从现有数组构建一个最小-最大堆。在这里，我们使用了弗洛伊德算法，并进行了一些调整，例如Heapify 算法： public List\u0026lt;T\u0026gt; create() { for (int i = Math.floorDiv(array.size(), 2); i \u0026gt;= 1; i--) { pushDown(array, i); } return array; } 让我们仔细看看下面代码中的pushDown ，看看上面代码中到底发生了什么： private void pushDown(List\u0026lt;T\u0026gt; array, int i) { if (isEvenLevel(i)) { pushDownMin(array, i); } else { pushDownMax(array, i); } } 正如我们所见，对于所有偶数级别，我们使用pushDownMin 检查数组项。这个算法就像我们将用于removeMin和removeMax的 heapify-down ： private void pushDownMin(List\u0026lt;T\u0026gt; h, int i) { while (getLeftChildIndex(i) \u0026lt; indicator) { int indexOfSmallest = getIndexOfSmallestChildOrGrandChild(h, i); //...  i = indexOfSmallest; } } 首先，我们找到“ i” 元素的最小子或孙的索引。然后我们根据以下条件进行。 如果最小的子或孙不小于当前元素，我们就中断。换句话说，当前的元素排列就像最小堆： if (h.get(indexOfSmallest - 1).compareTo(h.get(i - 1)) \u0026lt; 0) { //... } else { break; } 如果最小的子元素或孙子元素小于当前元素，我们将其与其父元素或祖父元素交换： if (getParentIndex(getParentIndex(indexOfSmallest)) == i) { if (h.get(indexOfSmallest - 1).compareTo(h.get(i - 1)) \u0026lt; 0) { swap(indexOfSmallest - 1, i - 1, h); if (h.get(indexOfSmallest - 1) .compareTo(h.get(getParentIndex(indexOfSmallest) - 1)) \u0026gt; 0) { swap(indexOfSmallest - 1, getParentIndex(indexOfSmallest) - 1, h); } } } else if (h.get(indexOfSmallest - 1).compareTo(h.get(i - 1)) \u0026lt; 0) { swap(indexOfSmallest - 1, i - 1, h); } 我们将继续上述操作，直到找到元素“i”的子元素。 现在，让我们看看getIndexOfSmallestChildOrGrandChild是如何工作的。这很容易！首先，我们假设左孩子的值最小，然后将其与其他孩子进行比较： private int getIndexOfSmallestChildOrGrandChild(List\u0026lt;T\u0026gt; h, int i) { int minIndex = getLeftChildIndex(i); T minValue = h.get(minIndex - 1); // rest of the implementation } 在每一步中，如果指标大于指标，则找到的最后一个最小值就是答案。 例如，让我们将min-value与右孩子进行比较： if (getRightChildIndex(i) \u0026lt; indicator) { if (h.get(getRightChildIndex(i) - 1).compareTo(minValue) \u0026lt; 0) { minValue = h.get(getRightChildIndex(i)); minIndex = getRightChildIndex(i); } } else { return minIndex; } 现在，让我们创建一个测试来验证从无序数组创建最小-最大堆是否正常工作： @Test public void givenUnOrderedArray_WhenCreateMinMaxHeap_ThenIsEqualWithMinMaxHeapOrdered() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(34, 12, 28, 9, 30, 19, 1, 40); MinMaxHeap\u0026lt;Integer\u0026gt; minMaxHeap = new MinMaxHeap\u0026lt;\u0026gt;(list); minMaxHeap.create(); Assert.assertEquals(List.of(1, 40, 34, 9, 30, 19, 28, 12), list); } pushDownMax的算法与pushDownMin的算法相同，但在所有比较中，运算符都颠倒了。** 3.2. 插入 让我们看看如何向 min-max Heap 添加元素： public void insert(T item) { if (isEmpty()) { array.add(item); indicator++; } else if (!isFull()) { array.add(item); pushUp(array, indicator); indicator++; } else { throw new RuntimeException(\u0026#34;invalid operation !!!\u0026#34;); } } 首先，我们检查堆是否为空。如果堆为空，我们追加新元素并增加指示符。否则，新添加的元素可能会改变 min-max 堆的顺序，所以我们需要使用pushUp调整堆： private void pushUp(List\u0026lt;T\u0026gt;h,int i) { if (i != 1) { if (isEvenLevel(i)) { if (h.get(i - 1).compareTo(h.get(getParentIndex(i) - 1)) \u0026lt; 0) { pushUpMin(h, i); } else { swap(i - 1, getParentIndex(i) - 1, h); i = getParentIndex(i); pushUpMax(h, i); } } else if (h.get(i - 1).compareTo(h.get(getParentIndex(i) - 1)) \u0026gt; 0) { pushUpMax(h, i); } else { swap(i - 1, getParentIndex(i) - 1, h); i = getParentIndex(i); pushUpMin(h, i); } } } 正如我们在上面看到的，新元素比较它的父元素，然后：  如果发现它小于（大于）父元素，那么它肯定小于（大于）位于堆根路径上的最大（最小）级别上的所有其他元素 从新元素到根的路径（仅考虑最小/最大级别）应该按照插入之前的降序（升序）顺序。所以，我们需要将新元素二进制插入到这个序列中  现在，让我们看一下pushUpMin，如下所示： private void pushUpMin(List\u0026lt;T\u0026gt; h , int i) { while(hasGrandparent(i) \u0026amp;\u0026amp; h.get(i - 1) .compareTo(h.get(getGrandparentIndex(i) - 1)) \u0026lt; 0) { swap(i - 1, getGrandparentIndex(i) - 1, h); i = getGrandparentIndex(i); } } 从技术上讲，当父元素更大时，将新元素与其父元素交换更简单。此外，pushUpMax与pushUpMin相同，但在所有比较中，运算符都颠倒了。 现在，让我们创建一个测试来验证将新元素插入到 min-max 堆中是否正常工作： @Test public void givenNewElement_WhenInserted_ThenIsEqualWithMinMaxHeapOrdered() { MinMaxHeap\u0026lt;Integer\u0026gt; minMaxHeap = new MinMaxHeap(8); minMaxHeap.insert(34); minMaxHeap.insert(12); minMaxHeap.insert(28); minMaxHeap.insert(9); minMaxHeap.insert(30); minMaxHeap.insert(19); minMaxHeap.insert(1); minMaxHeap.insert(40); Assert.assertEquals(List.of(1, 40, 28, 12, 30, 19, 9, 34), minMaxHeap.getMinMaxHeap()); } 3.3. 查找最小值 最小-最大堆中的主要元素始终位于根，因此我们可以在时间复杂度 O(1) 中找到它： public T min() { if (!isEmpty()) { return array.get(0); } return null; } 3.4. 找到最大 最小-最大堆中的最大元素始终位于第一个奇数级别，因此我们可以通过简单的比较以时间复杂度 O(1) 找到它： public T max() { if (!isEmpty()) { if (indicator == 2) { return array.get(0); } if (indicator == 3) { return array.get(1); } return array.get(1).compareTo(array.get(2)) \u0026lt; 0 ? array.get(2) : array.get(1); } return null; } 3.5. 删除最小值 在这种情况下，我们将找到 min 元素，然后将其替换为数组的最后一个元素： public T removeMin() { T min = min(); if (min != null) { if (indicator == 2) { array.remove(indicator--); return min; } array.set(0, array.get(--indicator - 1)); array.remove(indicator - 1); pushDown(array, 1); } return min; } 3.6. 删除最大值 删除最大元素与删除最小元素相同，唯一的变化是我们找到最大元素的索引然后调用pushDown： public T removeMax() { T max = max(); if (max != null) { int maxIndex; if (indicator == 2) { maxIndex = 0; array.remove(--indicator - 1); return max; } else if (indicator == 3) { maxIndex = 1; array.remove(--indicator - 1); return max; } else { maxIndex = array.get(1).compareTo(array.get(2)) \u0026lt; 0 ? 2 : 1; } array.set(maxIndex, array.get(--indicator - 1)); array.remove(indicator - 1); pushDown(array, maxIndex + 1); } return max; } \u0026quot; ","permalink":"http://itcodingman.github.io/java_min_max_heap/","tags":["Data Structures"],"title":"如何在 Java 中实现 Min-Max Heap"},{"categories":["C++","Youtube"],"contents":"C++中地址和引用的区别   ","permalink":"http://itcodingman.github.io/c_plus_point_reference_diffrence/","tags":[],"title":"C++中地址和引用的区别"},{"categories":["Data"],"contents":"1. 概述 Apache POI是一个 Java 库，用于处理基于 Office Open XML 标准 (OOXML) 和 Microsoft 的 OLE 2 复合文档格式 (OLE2) 的各种文件格式。 本教程重点介绍Apache POI 对 Microsoft Word（最常用的 Office 文件格式）的支持。它介绍了格式化和生成 MS Word 文件所需的步骤以及如何解析该文件。 2. Maven依赖 Apache POI 处理 MS Word 文件所需的唯一依赖项是： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 请单击此处获取此工件的最新版本。 3. 准备 现在让我们看看一些用于促进生成 MS Word 文件的元素。 3.1 资源文件 我们将收集三个文本文件的内容并将它们写入一个名为rest-with-spring.docx的 MS Word 文件中。 此外，logo-leaf.png文件用于将图像插入到该新文件中。所有这些文件确实存在于类路径中，并由几个静态变量表示： public static String logo = \u0026#34;logo-leaf.png\u0026#34;; public static String paragraph1 = \u0026#34;poi-word-para1.txt\u0026#34;; public static String paragraph2 = \u0026#34;poi-word-para2.txt\u0026#34;; public static String paragraph3 = \u0026#34;poi-word-para3.txt\u0026#34;; public static String output = \u0026#34;rest-with-spring.docx\u0026#34;; 对于那些好奇的人，存储库中这些资源文件的内容，其链接在本教程的最后一节中给出，是从网站上的这个课程页面中提取的。 3.2. 辅助方法 由用于生成 MS Word 文件的逻辑组成的 main 方法（将在下一节中描述）使用辅助方法： public String convertTextFileToString(String fileName) { try (Stream\u0026lt;String\u0026gt; stream = Files.lines(Paths.get(ClassLoader.getSystemResource(fileName).toURI()))) { return stream.collect(Collectors.joining(\u0026#34; \u0026#34;)); } catch (IOException | URISyntaxException e) { return null; } } 此方法提取位于类路径上的文本文件中包含的内容，其名称是传入的字符串参数。然后，它连接此文件中的行并返回加入的String。 4. MS Word 文件生成 本节提供有关如何格式化和生成 Microsoft Word 文件的说明。在处理文件的任何部分之前，我们需要有一个XWPFDocument实例： XWPFDocument document = new XWPFDocument(); 4.1 格式化标题和副标题 为了创建标题，我们需要首先实例化XWPFParagraph类并在新对象上设置对齐方式： XWPFParagraph title = document.createParagraph(); title.setAlignment(ParagraphAlignment.CENTER); 段落的内容需要包装在XWPFRun对象中。我们可以配置这个对象来设置一个文本值及其相关的样式： XWPFRun titleRun = title.createRun(); titleRun.setText(\u0026#34;Build Your REST API with Spring\u0026#34;); titleRun.setColor(\u0026#34;009933\u0026#34;); titleRun.setBold(true); titleRun.setFontFamily(\u0026#34;Courier\u0026#34;); titleRun.setFontSize(20); 人们应该能够从它们的名称中推断出集合方法的用途。 以类似的方式，我们创建一个包含字幕的XWPFParagraph实例： XWPFParagraph subTitle = document.createParagraph(); subTitle.setAlignment(ParagraphAlignment.CENTER); 让我们也格式化字幕： XWPFRun subTitleRun = subTitle.createRun(); subTitleRun.setText(\u0026#34;from HTTP fundamentals to API Mastery\u0026#34;); subTitleRun.setColor(\u0026#34;00CC44\u0026#34;); subTitleRun.setFontFamily(\u0026#34;Courier\u0026#34;); subTitleRun.setFontSize(16); subTitleRun.setTextPosition(20); subTitleRun.setUnderline(UnderlinePatterns.DOT_DOT_DASH); setTextPosition方法设置字幕和后续图像之间的距离，而setUnderline确定下划线图案。 请注意，我们对标题和副标题的内容进行了硬编码，因为这些语句太短而无法证明使用辅助方法的合理性。 4.2. 插入图像 图像还需要包装在XWPFParagraph实例中。我们希望图像水平居中并放置在字幕下方，因此以下代码段必须放在上面给出的代码下方： XWPFParagraph image = document.createParagraph(); image.setAlignment(ParagraphAlignment.CENTER); 以下是如何设置此图像与其下方文本之间的距离： XWPFRun imageRun = image.createRun(); imageRun.setTextPosition(20); 从类路径上的文件中获取图像，然后插入到具有指定尺寸的 MS Word 文件中： Path imagePath = Paths.get(ClassLoader.getSystemResource(logo).toURI()); imageRun.addPicture(Files.newInputStream(imagePath), XWPFDocument.PICTURE_TYPE_PNG, imagePath.getFileName().toString(), Units.toEMU(50), Units.toEMU(50)); 4.3. 格式化段落 下面是我们如何使用poi-word-para1.txt文件中的内容创建第一段： XWPFParagraph para1 = document.createParagraph(); para1.setAlignment(ParagraphAlignment.BOTH); String string1 = convertTextFileToString(paragraph1); XWPFRun para1Run = para1.createRun(); para1Run.setText(string1); 显然，段落的创建类似于标题或副标题的创建。这里唯一的区别是使用辅助方法而不是硬编码字符串。 以类似的方式，我们可以使用poi-word-para2.txt和poi-word-para3.txt文件中的内容创建另外两个段落： XWPFParagraph para2 = document.createParagraph(); para2.setAlignment(ParagraphAlignment.RIGHT); String string2 = convertTextFileToString(paragraph2); XWPFRun para2Run = para2.createRun(); para2Run.setText(string2); para2Run.setItalic(true); XWPFParagraph para3 = document.createParagraph(); para3.setAlignment(ParagraphAlignment.LEFT); String string3 = convertTextFileToString(paragraph3); XWPFRun para3Run = para3.createRun(); para3Run.setText(string3); 这三个段落的创建几乎相同，除了一些样式，例如对齐或斜体。 4.4. 生成 MS Word 文件 现在我们准备从文档变量中将 Microsoft Word 文件写入内存： FileOutputStream out = new FileOutputStream(output); document.write(out); out.close(); document.close(); 本节中的所有代码片段都包含在一个名为handleSimpleDoc的方法中。 5. 解析与测试 本节概述了 MS Word 文件的解析和结果的验证。 5.1 准备 我们在测试类中声明一个静态字段： static WordDocument wordDocument; 该字段用于引用包含第 3 节和第 4 节中显示的所有代码片段的类的实例。 在解析和测试之前，我们需要初始化上面声明的静态变量，并通过调用handleSimpleDoc方法在当前工作目录下生成rest-with-spring.docx文件： @BeforeClass public static void generateMSWordFile() throws Exception { WordTest.wordDocument = new WordDocument(); wordDocument.handleSimpleDoc(); } 让我们进入最后一步：解析 MS Word 文件并验证结果。 5.2. 解析 MS Word 文件和验证 首先，我们从项目目录中给定的 MS Word 文件中提取内容，并将内容存储在XWPFParagraph的List中： Path msWordPath = Paths.get(WordDocument.output); XWPFDocument document = new XWPFDocument(Files.newInputStream(msWordPath)); List\u0026lt;XWPFParagraph\u0026gt; paragraphs = document.getParagraphs(); document.close(); 接下来，让我们确保标题的内容和样式与我们之前设置的相同： XWPFParagraph title = paragraphs.get(0); XWPFRun titleRun = title.getRuns().get(0); assertEquals(\u0026#34;Build Your REST API with Spring\u0026#34;, title.getText()); assertEquals(\u0026#34;009933\u0026#34;, titleRun.getColor()); assertTrue(titleRun.isBold()); assertEquals(\u0026#34;Courier\u0026#34;, titleRun.getFontFamily()); assertEquals(20, titleRun.getFontSize()); 为简单起见，我们只验证文件其他部分的内容，省略样式。他们的风格验证类似于我们对标题所做的： assertEquals(\u0026#34;from HTTP fundamentals to API Mastery\u0026#34;, paragraphs.get(1).getText()); assertEquals(\u0026#34;What makes a good API?\u0026#34;, paragraphs.get(3).getText()); assertEquals(wordDocument.convertTextFileToString (WordDocument.paragraph1), paragraphs.get(4).getText()); assertEquals(wordDocument.convertTextFileToString (WordDocument.paragraph2), paragraphs.get(5).getText()); assertEquals(wordDocument.convertTextFileToString (WordDocument.paragraph3), paragraphs.get(6).getText()); 现在我们可以确信rest-with-spring.docx文件的创建已经成功了。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_microsoft_word_with_apache_poi/","tags":[],"title":"使用 Apache POI 在 Java 中进行 Microsoft Word 处理"},{"categories":["Data"],"contents":"1. 概述 在本教程中，我们将演示如何使用Apache POI 和 JExcel API 来处理 Excel 电子表格。 这两个库都可用于动态读取、写入和修改 Excel 电子表格的内容，并提供将 Microsoft Excel 集成到 Java 应用程序的有效方法。 2. Maven依赖 首先，我们需要将以下依赖项添加到我们的pom.xml文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; poi-ooxml和jxls-jexcel的最新版本可以从 Maven Central 下载。 3. Apache POI Apache POI库支持*.xls和.xlsx*文件，是一个比其他 Java 库更复杂的库，用于处理 Excel 文件。 它提供了为Excel文件建模的Workbook接口，以及为 Excel 文件的元素建模的Sheet、Row 和Cell接口，以及两种文件格式的每个接口的实现。 在使用较新的*.xlsx文件格式时，我们将使用XSSFWorkbook*、XSSFSheet、XSSFRow 和 XSSFCell类*。* 要使用较旧的*.xls格式，我们使用HSSFWorkbook*、HSSFSheet、HSSFRow和HSSFCell类。 3.1 从 Excel 中读取 让我们创建一个方法来打开一个*.xlsx*文件，然后从文件的第一页读取内容。 读取单元格内容的方法因单元格中的数据类型而异。可以使用Cell接口的*getCellType()*方法确定单元格内容的类型。 首先，让我们从给定位置打开文件： FileInputStream file = new FileInputStream(new File(fileLocation)); Workbook workbook = new XSSFWorkbook(file); 接下来，让我们检索文件的第一张表并遍历每一行： Sheet sheet = workbook.getSheetAt(0); Map\u0026lt;Integer, List\u0026lt;String\u0026gt;\u0026gt; data = new HashMap\u0026lt;\u0026gt;(); int i = 0; for (Row row : sheet) { data.put(i, new ArrayList\u0026lt;String\u0026gt;()); for (Cell cell : row) { switch (cell.getCellType()) { case STRING: ... break; case NUMERIC: ... break; case BOOLEAN: ... break; case FORMULA: ... break; default: data.get(new Integer(i)).add(\u0026#34; \u0026#34;); } } i++; } **Apache POI 有不同的方法来读取每种类型的数据。**让我们扩展上面每个 switch 案例的内容。 当单元格类型枚举值为STRING时，将使用Cell接口的*getRichStringCellValue()*方法读取内容： data.get(new Integer(i)).add(cell.getRichStringCellValue().getString()); 具有NUMERIC内容类型的单元格可以包含日期或数字，并按以下方式读取： if (DateUtil.isCellDateFormatted(cell)) { data.get(i).add(cell.getDateCellValue() + \u0026#34;\u0026#34;); } else { data.get(i).add(cell.getNumericCellValue() + \u0026#34;\u0026#34;); } 对于BOOLEAN值，我们有*getBooleanCellValue()*方法： data.get(i).add(cell.getBooleanCellValue() + \u0026#34;\u0026#34;); 当单元格类型为FORMULA时，我们可以使用*getCellFormula()*方法： data.get(i).add(cell.getCellFormula() + \u0026#34;\u0026#34;); 3.2. 写入 Excel Apache POI 使用上一节中介绍的相同接口来写入 Excel 文件，并且对样式的支持比 JExcel 更好。 让我们创建一个将人员列表写入标题为*“Persons”*的工作表的方法。 首先，我们将创建一个包含*“姓名”和“年龄”*单元格的标题行并为其设置样式： Workbook workbook = new XSSFWorkbook(); Sheet sheet = workbook.createSheet(\u0026#34;Persons\u0026#34;); sheet.setColumnWidth(0, 6000); sheet.setColumnWidth(1, 4000); Row header = sheet.createRow(0); CellStyle headerStyle = workbook.createCellStyle(); headerStyle.setFillForegroundColor(IndexedColors.LIGHT_BLUE.getIndex()); headerStyle.setFillPattern(FillPatternType.SOLID_FOREGROUND); XSSFFont font = ((XSSFWorkbook) workbook).createFont(); font.setFontName(\u0026#34;Arial\u0026#34;); font.setFontHeightInPoints((short) 16); font.setBold(true); headerStyle.setFont(font); Cell headerCell = header.createCell(0); headerCell.setCellValue(\u0026#34;Name\u0026#34;); headerCell.setCellStyle(headerStyle); headerCell = header.createCell(1); headerCell.setCellValue(\u0026#34;Age\u0026#34;); headerCell.setCellStyle(headerStyle); 接下来，让我们用不同的样式来编写表格的内容： CellStyle style = workbook.createCellStyle(); style.setWrapText(true); Row row = sheet.createRow(2); Cell cell = row.createCell(0); cell.setCellValue(\u0026#34;John Smith\u0026#34;); cell.setCellStyle(style); cell = row.createCell(1); cell.setCellValue(20); cell.setCellStyle(style); 最后，让我们将内容写入当前目录中的*“temp.xlsx”*文件并关闭工作簿： File currDir = new File(\u0026#34;.\u0026#34;); String path = currDir.getAbsolutePath(); String fileLocation = path.substring(0, path.length() - 1) + \u0026#34;temp.xlsx\u0026#34;; FileOutputStream outputStream = new FileOutputStream(fileLocation); workbook.write(outputStream); workbook.close(); 让我们在JUnit测试中测试上述方法，该测试将内容写入temp.xlsx文件，然后读取同一文件以验证它是否包含我们编写的文本： public class ExcelTest { private ExcelPOIHelper excelPOIHelper; private static String FILE_NAME = \u0026#34;temp.xlsx\u0026#34;; private String fileLocation; @Before public void generateExcelFile() throws IOException { File currDir = new File(\u0026#34;.\u0026#34;); String path = currDir.getAbsolutePath(); fileLocation = path.substring(0, path.length() - 1) + FILE_NAME; excelPOIHelper = new ExcelPOIHelper(); excelPOIHelper.writeExcel(); } @Test public void whenParsingPOIExcelFile_thenCorrect() throws IOException { Map\u0026lt;Integer, List\u0026lt;String\u0026gt;\u0026gt; data = excelPOIHelper.readExcel(fileLocation); assertEquals(\u0026#34;Name\u0026#34;, data.get(0).get(0)); assertEquals(\u0026#34;Age\u0026#34;, data.get(0).get(1)); assertEquals(\u0026#34;John Smith\u0026#34;, data.get(1).get(0)); assertEquals(\u0026#34;20\u0026#34;, data.get(1).get(1)); } } 4. JExcel JExcel 库是一个轻量级库，其优点是它比 Apache POI 更易于使用，但缺点是它仅支持处理*.xls* (1997-2003) 格式的 Excel 文件。 目前，不支持.xlsx文件。** 4.1 从 Excel 中读取 为了使用 Excel 文件，该库提供了一系列代表 Excel 文件不同部分的类。Workbook**类代表整个工作表集合。Sheet类表示单个工作表，而Cell类表示电子表格的单个单元格。 让我们编写一个方法，从指定的 Excel 文件创建工作簿，获取文件的第一个工作表，然后遍历其内容并将每一行添加到HashMap中： public class JExcelHelper { public Map\u0026lt;Integer, List\u0026lt;String\u0026gt;\u0026gt; readJExcel(String fileLocation) throws IOException, BiffException { Map\u0026lt;Integer, List\u0026lt;String\u0026gt;\u0026gt; data = new HashMap\u0026lt;\u0026gt;(); Workbook workbook = Workbook.getWorkbook(new File(fileLocation)); Sheet sheet = workbook.getSheet(0); int rows = sheet.getRows(); int columns = sheet.getColumns(); for (int i = 0; i \u0026lt; rows; i++) { data.put(i, new ArrayList\u0026lt;String\u0026gt;()); for (int j = 0; j \u0026lt; columns; j++) { data.get(i) .add(sheet.getCell(j, i) .getContents()); } } return data; } } 4.2. 写入 Excel 为了写入 Excel 文件，JExcel 库提供了与上面使用的类类似的类，它们对电子表格文件进行建模：WritableWorkbook、WritableSheet 和WritableCell。 WritableCell类具有对应于可以写入的不同类型内容的子类：Label、DateTime、Number、Boolean、Blank 和Formula。 该库还提供对基本格式的支持，例如控制字体、颜色和单元格宽度。 让我们编写一个方法，在当前目录中创建一个名为*“temp.xls”*的工作簿，然后写入我们在 Apache POI 部分中编写的相同内容。 首先，让我们创建工作簿： File currDir = new File(\u0026#34;.\u0026#34;); String path = currDir.getAbsolutePath(); String fileLocation = path.substring(0, path.length() - 1) + \u0026#34;temp.xls\u0026#34;; WritableWorkbook workbook = Workbook.createWorkbook(new File(fileLocation)); 接下来，让我们创建第一个工作表并写入 excel 文件的标题，其中包含*“姓名”和“年龄”*单元格： WritableSheet sheet = workbook.createSheet(\u0026#34;Sheet 1\u0026#34;, 0); WritableCellFormat headerFormat = new WritableCellFormat(); WritableFont font = new WritableFont(WritableFont.ARIAL, 16, WritableFont.BOLD); headerFormat.setFont(font); headerFormat.setBackground(Colour.LIGHT_BLUE); headerFormat.setWrap(true); Label headerLabel = new Label(0, 0, \u0026#34;Name\u0026#34;, headerFormat); sheet.setColumnView(0, 60); sheet.addCell(headerLabel); headerLabel = new Label(1, 0, \u0026#34;Age\u0026#34;, headerFormat); sheet.setColumnView(0, 40); sheet.addCell(headerLabel); 使用新样式，让我们编写我们创建的表格的内容： WritableCellFormat cellFormat = new WritableCellFormat(); cellFormat.setWrap(true); Label cellLabel = new Label(0, 2, \u0026#34;John Smith\u0026#34;, cellFormat); sheet.addCell(cellLabel); Number cellNumber = new Number(1, 2, 20, cellFormat); sheet.addCell(cellNumber); 记住写入文件并在最后关闭它是非常重要的，这样它就可以被其他进程使用，使用Workbook类的*write()和close()*方法： workbook.write(); workbook.close(); \u0026quot; ","permalink":"http://itcodingman.github.io/java_microsoft_excel/","tags":["Excel"],"title":"在 Java 中使用 Microsoft Excel"},{"categories":["Java"],"contents":"1. 简介 这篇快速文章的重点是 JMH（Java Microbenchmark Harness）。首先，我们熟悉 API 并了解其基础知识。然后我们会看到一些在编写微基准测试时应该考虑的最佳实践。 简而言之，JMH 负责诸如 JVM 预热和代码优化路径之类的事情，使基准测试尽可能简单。 2. 入门 首先，我们实际上可以继续使用 Java 8 并简单地定义依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jmh\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jmh-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jmh\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jmh-generator-annprocess\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在 Maven Central 中找到最新版本的JMH Core和JMH Annotation Processor 。 接下来，通过使用*@Benchmark*注释（在任何公共类中）创建一个简单的基准： @Benchmark public void init() { // Do nothing } 然后我们添加启动基准测试过程的主类： public class BenchmarkRunner { public static void main(String[] args) throws Exception { org.openjdk.jmh.Main.main(args); } } 现在运行BenchmarkRunner将执行我们可以说有些无用的基准测试。运行完成后，将显示一个汇总表： # Run complete. Total time: 00:06:45 Benchmark Mode Cnt Score Error Units BenchMark.init thrpt 200 3099210741.962 ± 17510507.589 ops/s 3. 基准类型 JMH 支持一些可能的基准测试：Throughput、 AverageTime、 SampleTime和SingleShotTime。这些可以通过*@BenchmarkMode*注释进行配置： @Benchmark @BenchmarkMode(Mode.AverageTime) public void init() { // Do nothing } 结果表将具有平均时间度量（而不是吞吐量）： # Run complete. Total time: 00:00:40 Benchmark Mode Cnt Score Error Units BenchMark.init avgt 20 ≈ 10⁻⁹ s/op 4. 配置预热和执行 通过使用*@Fork*注解，我们可以设置基准测试的执行方式：value参数控制基准测试将执行多少次，warmup参数控制基准测试在收集结果之前将运行多少次，例如： @Benchmark @Fork(value = 1, warmups = 2) @BenchmarkMode(Mode.Throughput) public void init() { // Do nothing } 这指示 JMH 在进行实时基准测试之前运行两个预热分叉并丢弃结果。 此外，@Warmup注释可用于控制预热迭代的次数。例如，*@Warmup(iterations = 5)*告诉 JMH 5 次预热迭代就足够了，而不是默认的 20 次。 5. 状态 现在让我们看看如何通过利用State来执行对哈希算法进行基准测试的不那么琐碎和更具指示性的任务。假设我们决定通过对密码进行数百次散列处理来增加对密码数据库的字典攻击的额外保护。 我们可以通过使用State对象来探索性能影响： @State(Scope.Benchmark) public class ExecutionPlan { @Param({ \u0026#34;100\u0026#34;, \u0026#34;200\u0026#34;, \u0026#34;300\u0026#34;, \u0026#34;500\u0026#34;, \u0026#34;1000\u0026#34; }) public int iterations; public Hasher murmur3; public String password = \u0026#34;4v3rys3kur3p455w0rd\u0026#34;; @Setup(Level.Invocation) public void setUp() { murmur3 = Hashing.murmur3_128().newHasher(); } } 我们的基准测试方法将如下所示： @Fork(value = 1, warmups = 1) @Benchmark @BenchmarkMode(Mode.Throughput) public void benchMurmur3_128(ExecutionPlan plan) { for (int i = plan.iterations; i \u0026gt; 0; i--) { plan.murmur3.putString(plan.password, Charset.defaultCharset()); } plan.murmur3.hash(); } 在这里，当 JMH 将 @Param 注释传递给基准方法时，将使用来自*@Param注释的适当值填充字段迭代。@Setup注释方法在每次调用基准之前调用，并创建一个新的Hasher**以*确保隔离。 执行完成后，我们会得到类似下面的结果： # Run complete. Total time: 00:06:47 Benchmark (iterations) Mode Cnt Score Error Units BenchMark.benchMurmur3_128 100 thrpt 20 92463.622 ± 1672.227 ops/s BenchMark.benchMurmur3_128 200 thrpt 20 39737.532 ± 5294.200 ops/s BenchMark.benchMurmur3_128 300 thrpt 20 30381.144 ± 614.500 ops/s BenchMark.benchMurmur3_128 500 thrpt 20 18315.211 ± 222.534 ops/s BenchMark.benchMurmur3_128 1000 thrpt 20 8960.008 ± 658.524 ops/s 6. 死代码消除 运行微基准测试时，了解优化非常重要。否则，它们可能会以非常误导的方式影响基准测试结果。 为了让事情更具体一点，让我们考虑一个例子： @Benchmark @OutputTimeUnit(TimeUnit.NANOSECONDS) @BenchmarkMode(Mode.AverageTime) public void doNothing() { } @Benchmark @OutputTimeUnit(TimeUnit.NANOSECONDS) @BenchmarkMode(Mode.AverageTime) public void objectCreation() { new Object(); } 我们期望对象分配的成本高于什么都不做。但是，如果我们运行基准测试： Benchmark Mode Cnt Score Error Units BenchMark.doNothing avgt 40 0.609 ± 0.006 ns/op BenchMark.objectCreation avgt 40 0.613 ± 0.007 ns/op 显然在TLAB中找到一个位置，创建和初始化一个对象几乎是免费的！仅通过查看这些数字，我们应该知道这里并没有完全加起来。 在这里，我们是死代码消除的受害者。编译器非常擅长优化冗余代码。事实上，这正是 JIT 编译器在这里所​​做的。 **为了防止这种优化，我们应该以某种方式欺骗编译器，让它认为代码被其他组件使用。**实现此目的的一种方法是返回创建的对象： @Benchmark @OutputTimeUnit(TimeUnit.NANOSECONDS) @BenchmarkMode(Mode.AverageTime) public Object pillarsOfCreation() { return new Object(); } 此外，我们可以让 黑洞 消耗它： @Benchmark @OutputTimeUnit(TimeUnit.NANOSECONDS) @BenchmarkMode(Mode.AverageTime) public void blackHole(Blackhole blackhole) { blackhole.consume(new Object()); } 让Blackhole 使用该对象是一种说服 JIT 编译器不应用死代码消除优化的方法。无论如何，如果我们再次运行这些基准测试，这些数字会更有意义： Benchmark Mode Cnt Score Error Units BenchMark.blackHole avgt 20 4.126 ± 0.173 ns/op BenchMark.doNothing avgt 20 0.639 ± 0.012 ns/op BenchMark.objectCreation avgt 20 0.635 ± 0.011 ns/op BenchMark.pillarsOfCreation avgt 20 4.061 ± 0.037 ns/op 7. 恒定折叠 让我们考虑另一个例子： @Benchmark public double foldedLog() { int x = 8; return Math.log(x); } **无论执行次数如何，基于常量的计算都可能返回完全相同的输出。**因此，JIT 编译器很有可能会用其结果替换对数函数调用： @Benchmark public double foldedLog() { return 2.0794415416798357; } 这种部分求值的形式称为常量折叠。在这种情况下，常量折叠完全避免了 Math.log调用，这是基准测试的重点。 为了防止常量折叠，我们可以将常量状态封装在一个状态对象中： @State(Scope.Benchmark) public static class Log { public int x = 8; } @Benchmark public double log(Log input) { return Math.log(input.x); } 如果我们对彼此运行这些基准测试： Benchmark Mode Cnt Score Error Units BenchMark.foldedLog thrpt 20 449313097.433 ± 11850214.900 ops/s BenchMark.log thrpt 20 35317997.064 ± 604370.461 ops/s 显然， 与*foldedLog相比，*日志 基准做了一些严肃的工作 ，这是明智的。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_microbenchmark_harness/","tags":[],"title":"使用 Java 进行微基准测试"},{"categories":["DevOps","Java"],"contents":"1. 概述 在这个快速教程中，我们将讨论如何在 Java 中监控关键指标。我们将专注于磁盘空间、内存使用和线程数据——仅使用核心 Java API。 在我们的第一个示例中，我们将使用File类来查询特定的磁盘信息。 然后，我们将通过深入 ManagementFactory 类来分析内存使用情况和处理器信息。 最后，我们将讨论如何使用 Java Profilers 在运行时监控这些关键指标。 2. File类介绍 简单地说，File类代表文件或目录的抽象。它可用于获取有关文件系统的关键信息并维护 文件路径的**操作系统独立性。**在本教程中，我们将使用这个类来检查 Windows 和 Linux 机器上的根分区。 3. ManagementFactory Java 提供 ManagementFactory类作为获取托管 bean (MXBean)的工厂，其中包含 有关 JVM 的特定信息。我们将在以下代码示例中检查两个： 3.1 MemoryMXBean MemoryMXBean代表 JVM 内存系统的管理接口。在运行时，JVM 创建此接口的单个​​实例，我们可以使用 ManagementFactory的 getMemoryMXBean() 方法检索该实例。 3.2. ThreadMXBean 与MemoryMXBean类似，ThreadMXBean是 JVM 线程系统的管理接口。它可以使用 getThreadMXBean() 方法调用并保存有关线程的关键数据。 在以下示例中，我们将使用ThreadMXBean来了解 JVM 的 ThreadInfo类——它包含有关在 JVM 上运行的线程的特定信息。 3.监控磁盘使用情况 在此代码示例中，我们将使用 File 类来包含有关分区的关键信息。以下示例将返回 Windows 机器上 C: 驱动器的可用空间、总空间和可用空间： File cDrive = new File(\u0026#34;C:\u0026#34;); System.out.println(String.format(\u0026#34;Total space: %.2f GB\u0026#34;, (double)cDrive.getTotalSpace() /1073741824)); System.out.println(String.format(\u0026#34;Free space: %.2f GB\u0026#34;, (double)cDrive.getFreeSpace() /1073741824)); System.out.println(String.format(\u0026#34;Usable space: %.2f GB\u0026#34;, (double)cDrive.getUsableSpace() /1073741824)); 同样，我们可以为Linux 机器的根目录返回相同的信息： File root = new File(\u0026#34;/\u0026#34;); System.out.println(String.format(\u0026#34;Total space: %.2f GB\u0026#34;, (double)root.getTotalSpace() /1073741824)); System.out.println(String.format(\u0026#34;Free space: %.2f GB\u0026#34;, (double)root.getFreeSpace() /1073741824)); System.out.println(String.format(\u0026#34;Usable space: %.2f GB\u0026#34;, (double)root.getUsableSpace() /1073741824)); 上面的代码打印出定义文件的总空间、可用空间和可用空间。默认情况下，上述方法提供字节数。我们已将这些字节转换为千兆字节，以使结果更易于阅读。 4. 监控内存使用情况 我们现在将使用ManagementFactory类通过调用MemoryMXBean来查询 JVM 可用的内存。 在这个例子中，我们将主要关注堆内存的查询。需要注意的是，也可以使用MemoryMXBean查询非堆内存： MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean(); System.out.println(String.format(\u0026#34;Initial memory: %.2f GB\u0026#34;, (double)memoryMXBean.getHeapMemoryUsage().getInit() /1073741824)); System.out.println(String.format(\u0026#34;Used heap memory: %.2f GB\u0026#34;, (double)memoryMXBean.getHeapMemoryUsage().getUsed() /1073741824)); System.out.println(String.format(\u0026#34;Max heap memory: %.2f GB\u0026#34;, (double)memoryMXBean.getHeapMemoryUsage().getMax() /1073741824)); System.out.println(String.format(\u0026#34;Committed memory: %.2f GB\u0026#34;, (double)memoryMXBean.getHeapMemoryUsage().getCommitted() /1073741824)); 上面的示例分别返回初始、使用、最大和提交的内存。这是对这意味着什么的简短解释 ：  Initial：JVM在启动期间向操作系统请求的初始内存 Used：JVM当前使用的内存量 Max：JVM 可用的最大内存。如果达到此限制， 可能会抛出*OutOfMemoryException* Committed：保证JVM可用的内存量  5. CPU 使用率 接下来，我们将使用ThreadMXBean获取 ThreadInfo对象的完整列表并查询它们以获取有关当前在 JVM 上运行的线程的有用信息。 ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); for(Long threadID : threadMXBean.getAllThreadIds()) { ThreadInfo info = threadMXBean.getThreadInfo(threadID); System.out.println(\u0026#34;Thread name: \u0026#34; + info.getThreadName()); System.out.println(\u0026#34;Thread State: \u0026#34; + info.getThreadState()); System.out.println(String.format(\u0026#34;CPU time: %s ns\u0026#34;, threadMXBean.getThreadCpuTime(threadID))); } 首先，代码使用 getAllThreadIds方法获取当前线程的列表。对于每个线程，它会输出线程的名称和状态，然后是线程的 CPU 时间（以纳秒为单位）。 6. 使用 Profiler 监控指标 最后，值得一提的是，我们可以在不使用任何 Java 代码的情况下监控这些关键指标。Java Profilers 密切监视 JVM 级别的关键构造和操作，并提供对内存、线程等的实时分析。 VisualVM 就是这样的 Java 分析器示例之一，自 Java 6 起就与 JDK 捆绑在一起。 许多集成开发环境 (IDE) 包含插件，可在开发新代码时利用分析器。您可以在此处了解有关 Java Profilers 和 VisualVM 的更多信息。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_metrics/","tags":["Metrics"],"title":"在 Java 中监控磁盘使用情况和其他指标"},{"categories":["Java"],"contents":"1. 概述 Java 8 引入了方法引用的概念。我们经常将它们视为类似于 lambda 表达式。 但是，方法引用和 lambda 表达式并不完全相同。在本文中，我们将展示它们为何不同以及以错误方式使用它们的风险是什么。 2. Lambda 和方法引用语法 首先，让我们看几个 lambda 表达式的例子： Runnable r1 = () -\u0026gt; \u0026#34;some string\u0026#34;.toUpperCase(); Consumer\u0026lt;String\u0026gt; c1 = x -\u0026gt; x.toUpperCase(); 还有一些方法参考的例子： Function\u0026lt;String, String\u0026gt; f1 = String::toUpperCase; Runnable r2 = \u0026#34;some string\u0026#34;::toUpperCase; Runnable r3 = String::new; 这些示例可以让我们将方法引用视为 lambdas 的缩写符号。 但是让我们看一下Oracle 官方文档。我们可以在那里找到一个有趣的例子： (test ? list.replaceAll(String::trim) : list) :: iterator 正如我们所见，Java 语言规范允许我们在双冒号运算符之前使用不同类型的表达式。::之前的部分称为目标引用。 接下来，我们将讨论方法参考评估的过程。 3. 方法参考评价 当我们运行以下代码时会发生什么？ public static void main(String[] args) { Runnable runnable = (f(\u0026#34;some\u0026#34;) + f(\u0026#34;string\u0026#34;))::toUpperCase; } private static String f(String string) { System.out.println(string); return string; } 我们刚刚创建了一个Runnable对象。不多也不少。但是，输出是： some string 这是因为在**第一次发现声明时评估了目标引用。**因此，我们失去了想要的懒惰。**目标参考也只评估一次。**因此，如果我们将这一行添加到上面的示例中： runnable.run() 我们不会看到任何输出。下一个案例呢？ SomeWorker worker = null; Runnable workLambda = () -\u0026gt; worker.work() // ok Runnable workMethodReference = worker::work; // boom! NullPointerException 前面提到的文档提供的解释： “如果目标引用为 null，则调用实例方法的方法调用表达式 (§15.12) 将引发 NullPointerException。” 防止意外情况的最佳方法可能是永远不要使用变量访问和复杂表达式作为目标引用。 一个好主意可能是将方法引用仅用作其 lambda 等效项的简洁、简短的符号。在**::**运算符之前只有一个类名可以保证安全。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_methods_references_eval/","tags":["Core Java"],"title":"Java中方法引用的评估"},{"categories":["Java"],"contents":"1. 简介 在 Java 中，方法是我们定义应用程序业务逻辑的地方。它们定义了包含在对象中的数据之间的交互。 在本教程中，我们将介绍 Java 方法的语法、方法签名的定义以及如何调用和重载方法。 2. 方法语法 首先，一个方法由六个部分组成：  *访问修饰符：*可选地，我们可以指定代码可以从哪里访问方法 *返回类型：*方法返回值的类型，如果有的话 *方法标识符：*我们赋予方法的名称 *参数列表：*该方法的可选输入的逗号分隔列表 *异常列表：*方法可以抛出的可选异常列表 *Body：*逻辑的定义（可以为空）  让我们看一个例子： 让我们仔细看看 Java 方法的这六个部分。 2.1 访问修饰符 访问修饰符允许我们指定哪些对象可以访问该方法。有四种可能的访问修饰符：public、protected、private和 default（也称为package-private）。 方法**还可以在访问修饰符之前或之后包含静态关键字。**这意味着该方法属于类而不属于实例，因此，我们可以在不创建类的实例的情况下调用该方法。没有static关键字的方法称为实例方法，只能在类的实例上调用。 关于性能，静态方法将仅在类加载期间加载到内存中一次，因此内存效率更高。 2.2. 返回类型 方法可以将数据返回到调用它们的代码。方法可以返回原始值或对象引用，或者如果我们使用void关键字作为返回类型，它可以不返回任何内容。 让我们看一个void方法的示例： public void printFullName(String firstName, String lastName) { System.out.println(firstName + \u0026#34; \u0026#34; + lastName); } **如果我们声明一个返回类型，那么我们必须在方法体中指定一个返回语句。**一旦return语句执行完毕，方法体的执行就结束了，如果还有更多的语句，则不再处理。 另一方面，void方法不返回任何值，因此没有返回语句。 2.3. 方法标识符 方法标识符是我们分配给方法规范的名称。使用信息性和描述性名称是一种很好的做法。值得一提的是，方法标识符最多可以有 65536 个字符（虽然名称很长）。 2.4. 参数列表 我们可以在其参数列表中**指定方法的输入值，该列表括在括号中。**一个方法可以有 0 到 255 个以逗号分隔的参数。参数可以是对象、原形或枚举。我们可以在方法参数级别使用 Java 注释（例如Spring 注释 @RequestParam）。 2.5. 例外列表 我们可以使用throws子句指定方法抛出哪些异常。在 检查异常的情况下，要么我们必须将代码包含在try -catch子句中，要么我们必须在方法签名中提供throws子句。 所以，让我们看一下我们之前方法的一个更复杂的变体，它会抛出一个检查异常： public void writeName(String name) throws IOException { PrintWriter out = new PrintWriter(new FileWriter(\u0026#34;OutFile.txt\u0026#34;)); out.println(\u0026#34;Name: \u0026#34; + name); out.close(); } 2.6. 方法体 **Java 方法的最后一部分是方法体，它包含我们要执行的逻辑。**在方法体中，我们可以编写任意多行代码——或者在静态方法的情况下根本不写。如果我们的方法声明了一个返回类型，那么方法体必须包含一个返回语句。 3. 方法签名 根据其定义，方法签名仅由两个组件组成——方法的名称和参数列表。 所以，让我们写一个简单的方法： public String getName(String firstName, String lastName) { return firstName + \u0026#34; \u0026#34; + middleName + \u0026#34; \u0026#34; + lastName; } 此方法的签名是getName(String firstName, String lastName)。 方法标识符可以是任何标识符。但是，如果我们遵循常见的 Java 编码约定，方法标识符应该是一个小写动词，后面可以跟形容词和/或名词。 4. 调用方法 现在，让我们探索如何在 Java 中调用方法。按照前面的示例，假设这些方法包含在名为 PersonName的Java 类中： public class PersonName { public String getName(String firstName, String lastName) { return firstName + \u0026#34; \u0026#34; + middleName + \u0026#34; \u0026#34; + lastName; } } 由于我们的getName方法是实例方法而不是静态方法，为了调用getName方法，我们需要创建 PersonName类的实例： PersonName personName = new PersonName(); String fullName = personName.getName(\u0026#34;Alan\u0026#34;, \u0026#34;Turing\u0026#34;); 如我们所见，我们使用创建的对象来调用getName方法。 最后，我们来看看如何调用静态方法。在静态方法的情况下，我们不需要类实例来进行调用。相反，我们调用该方法，其名称以类名为前缀。 让我们使用前面示例的变体来演示： public class PersonName { public static String getName(String firstName, String lastName) { return firstName + \u0026#34; \u0026#34; + middleName + \u0026#34; \u0026#34; + lastName; } } 在这种情况下，方法调用是： String fullName = PersonName.getName(\u0026#34;Alan\u0026#34;, \u0026#34;Turing\u0026#34;); 5. 方法重载 Java 允许我们拥有两个或多个具有相同标识符但参数列表不同的方法——不同的方法签名。在这种情况下，我们说方法是重载的。让我们举个例子： public String getName(String firstName, String lastName) { return getName(firstName, \u0026#34;\u0026#34;, lastName); } public String getName(String firstName, String middleName, String lastName) { if (!middleName.isEqualsTo(\u0026#34;\u0026#34;)) { return firstName + \u0026#34; \u0026#34; + lastName; } return firstName + \u0026#34; \u0026#34; + middleName + \u0026#34; \u0026#34; + lastName; } 方法重载对于示例中的情况很有用，在这种情况下，我们可以有一个方法实现相同功能的简化版本。 最后，一个好的设计习惯是确保重载方法的行为方式相似。否则，如果具有相同标识符的方法以不同的方式运行，则代码将令人困惑。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_methods/","tags":["Core Java"],"title":"Java中的方法"},{"categories":["Python","Youtube"],"contents":"10分钟学习PyScript   ","permalink":"http://itcodingman.github.io/10_mins_pyscript/","tags":[],"title":"10分钟学习PyScript"},{"categories":["Java","BiliBili"],"contents":"50分钟学习JSP JSP教程主要提供JSP基础知识以及部分常用的JSP进阶知识，大家在学习JSP之前，需要具备一定的HTML及Java基础。 \r","permalink":"http://itcodingman.github.io/50_mins_jsp/","tags":[],"title":"50分钟学习JSP"},{"categories":["Java"],"contents":"1. 概述 方法签名只是 Java 中整个方法定义的一个子集。因此，签名的确切结构可能会引起混淆。 在本教程中，我们将学习方法签名的元素及其在 Java 编程中的含义。 2. 方法签名 Java 中的方法支持重载，这意味着可以在同一个类或类的层次结构中定义多个具有相同名称的方法。因此，编译器必须能够静态绑定客户端代码引用的方法。因此，方法签名唯一地标识每个方法。 根据Oracle的说法，方法签名由名称和参数类型组成。因此，方法声明的所有其他元素，例如修饰符、返回类型、参数名称、异常列表和主体都不是签名的一部分。 让我们仔细看看方法重载以及它与方法签名的关系。 3. 重载错误 让我们考虑以下代码*：* public void print() { System.out.println(\u0026#34;Signature is: print()\u0026#34;); } public void print(int parameter) { System.out.println(\u0026#34;Signature is: print(int)\u0026#34;); } 正如我们所看到的，代码编译为方法具有不同的参数类型列表。实际上，编译器可以确定性地将任何调用绑定到其中一个。 现在让我们通过添加以下方法来测试重载是否合法： public int print() { System.out.println(\u0026#34;Signature is: print()\u0026#34;); return 0; } 当我们编译时，我们得到一个“方法已在类中定义”的错误。这证明方法返回类型不是方法签名的一部分。 让我们尝试使用修饰符： private final void print() { System.out.println(\u0026#34;Signature is: print()\u0026#34;); } 我们仍然看到相同的“方法已在类中定义”错误。因此，方法签名不依赖于修饰符。 可以通过添加以下内容来测试通过更改抛出的异常进行的重载： public void print() throws IllegalStateException { System.out.println(\u0026#34;Signature is: print()\u0026#34;); throw new IllegalStateException(); } 我们再次看到“方法已在类中定义”错误，表明throw 声明不能是签名的一部分。 我们可以测试的最后一件事是更改参数名称是否允许重载。让我们添加以下方法： public void print(int anotherParameter) { System.out.println(\u0026#34;Signature is: print(int)\u0026#34;); } 正如预期的那样，我们得到了相同的编译错误。这意味着参数名称不会影响方法签名。 3. 泛型和类型擦除 使用泛型参数**， 类型擦除会更改有效签名**。实际上，它可能会导致与另一个使用泛型类型上限而不是泛型标记的方法发生冲突。 让我们考虑以下代码： public class OverloadingErrors\u0026lt;T extends Serializable\u0026gt; { public void printElement(T t) { System.out.println(\u0026#34;Signature is: printElement(T)\u0026#34;); } public void printElement(Serializable o) { System.out.println(\u0026#34;Signature is: printElement(Serializable)\u0026#34;); } } 即使签名看起来不同，编译器也无法在类型擦除后静态绑定正确的方法。  由于类型擦除，我们可以看到编译器将T替换为上限Serializable 。因此，它与显式使用Serializable的方法发生冲突。 当泛型类型没有界限时，我们会看到与基类型Object相同的结果。 4. 参数列表和多态性 方法签名考虑了确切的类型。这意味着我们可以重载参数类型为子类或超类的方法。 但是，我们必须特别注意，因为静态绑定会尝试使用多态性、自动装箱和类型提升进行匹配。 我们来看看下面的代码： public Number sum(Integer term1, Integer term2) { System.out.println(\u0026#34;Adding integers\u0026#34;); return term1 + term2; } public Number sum(Number term1, Number term2) { System.out.println(\u0026#34;Adding numbers\u0026#34;); return term1.doubleValue() + term2.doubleValue(); } public Number sum(Object term1, Object term2) { System.out.println(\u0026#34;Adding objects\u0026#34;); return term1.hashCode() + term2.hashCode(); } 上面的代码是完全合法的，可以编译。调用这些方法时可能会出现混淆，因为我们不仅需要知道我们正在调用的确切方法签名，还需要知道 Java 如何根据实际值进行静态绑定。 让我们探索一些最终绑定到*sum(Integer, Integer)*的方法调用： StaticBinding obj = new StaticBinding(); obj.sum(Integer.valueOf(2), Integer.valueOf(3)); obj.sum(2, 3); obj.sum(2, 0x1); 对于第一次调用，我们有确切的参数类型Integer、Integer。在第二次调用中，Java 将自动为我们将int装箱为Integer 。最后，Java 会通过类型提升将字节值0x1转换为int，然后将其自动装箱为Integer。 *同样，我们有以下绑定到sum(Number, Number)*的调用： obj.sum(2.0d, 3.0d); obj.sum(Float.valueOf(2), Float.valueOf(3)); 在第一次调用时，我们有自动装箱为Double的double值。然后，通过多态，Double匹配Number。同样，Float匹配Number用于第二次调用。 让我们观察一下Float和Double都继承自Number和Object的事实。但是，默认绑定是Number。这是因为 Java 会自动匹配与方法签名匹配的最近的超类型。 现在让我们考虑以下方法调用： obj.sum(2, \u0026#34;John\u0026#34;); 在此示例中，我们为第一个参数设置了一个int到Integer的自动框。但是，此方法名称没有sum(Integer, String)重载。因此，Java 将遍历所有参数超类型以从最近的父对象转换为Object，直到找到匹配项。在这种情况下，它绑定到sum(Object, Object)。 要更改默认绑定，我们可以使用显式参数转换，如下所示： obj.sum((Object) 2, (Object) 3); obj.sum((Number) 2, (Number) 3); 5. 可变参数 现在让我们将注意力转移到**可变参数如何影响方法的有效签名**和静态绑定。 这里我们有一个使用varargs的重载方法： public Number sum(Object term1, Object term2) { System.out.println(\u0026#34;Adding objects\u0026#34;); return term1.hashCode() + term2.hashCode(); } public Number sum(Object term1, Object... term2) { System.out.println(\u0026#34;Adding variable arguments: \u0026#34; + term2.length); int result = term1.hashCode(); for (Object o : term2) { result += o.hashCode(); } return result; } 那么方法的有效签名是什么？我们已经看到sum(Object, Object)是第一个的签名。变量参数本质上是数组，所以编译后第二个的有效签名是sum(Object, Object[])。 一个棘手的问题是，当我们只有两个参数时，我们如何选择方法绑定？ 让我们考虑以下调用： obj.sum(new Object(), new Object()); obj.sum(new Object(), new Object(), new Object()); obj.sum(new Object(), new Object[]{new Object()}); 显然，第一个调用将绑定到sum(Object, Object)，第二个调用将绑定到 sum( *Object, Object[])。*要强制 Java 用两个对象调用第二个方法，我们必须像第三次调用一样将它包装在一个数组中。 最后要注意的是，声明以下方法将与 vararg 版本冲突： public Number sum(Object term1, Object[] term2) { // ... } \u0026quot; ","permalink":"http://itcodingman.github.io/java_method_signature_return_type/","tags":["Core Java"],"title":"Java 中方法的签名是否包含返回类型？"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将学习从 Java 方法返回多个值的不同方法。 首先，我们将返回数组和集合。然后，我们将展示如何将容器类用于复杂数据，并学习如何创建通用元组类。 最后，我们将看到如何使用第三方库返回多个值的示例。 2. 使用数组 数组可用于返回原始数据类型和引用数据类型。 例如，以下getCoordinates方法返回一个包含两个双精度值的数组： double[] getCoordinatesDoubleArray() { double[] coordinates = new double[2]; coordinates[0] = 10; coordinates[1] = 12.5; return coordinates; } 如果我们想返回一个不同引用类型的数组，我们可以使用一个共同的父类型作为数组的类型： Number[] getCoordinatesNumberArray() { Number[] coordinates = new Number[2]; coordinates[0] = 10; // Integer  coordinates[1] = 12.5; // Double  return coordinates; } 这里我们定义了Number类型的**坐标数组，因为它是Integer和Double元素之间的公共类。 3. 使用集合 使用泛型Java 集合，我们可以返回一个通用类型的多个值。 集合框架具有广泛的类和接口。但是，在本节中，我们将讨论仅限于List和Map接口。 3.1 返回列表中相似类型的值 首先，让我们使用*List*重写前面的数组示例： List\u0026lt;Number\u0026gt; getCoordinatesList() { List\u0026lt;Number\u0026gt; coordinates = new ArrayList\u0026lt;\u0026gt;(); coordinates.add(10); // Integer  coordinates.add(12.5); // Double  return coordinates; } 与*Number[]*一样，*List*集合包含一系列混合类型的元素，它们都是相同的通用类型。 3.2. 返回映射中的命名值 如果我们想命名集合中的每个条目，可以使用Map代替： Map\u0026lt;String, Number\u0026gt; getCoordinatesMap() { Map\u0026lt;String, Number\u0026gt; coordinates = new HashMap\u0026lt;\u0026gt;(); coordinates.put(\u0026#34;longitude\u0026#34;, 10); coordinates.put(\u0026#34;latitude\u0026#34;, 12.5); return coordinates; } getCoordinatesMap方法的用户可以使用*Map#get方法的“**经度”*或“纬度” 键来检索相应的值。 4. 使用容器类 与数组和集合不同，容器类 (POJO) 可以包装具有不同数据类型的多个字段。 例如，下面的Coordinates类有两种不同的数据类型，double和String： public class Coordinates { private double longitude; private double latitude; private String placeName; public Coordinates(double longitude, double latitude, String placeName) { this.longitude = longitude; this.latitude = latitude; this.placeName = placeName; } // getters and setters } 使用像Coordinates这样的容器类使我们能够对具有有意义名称的复杂数据类型进行建模。 下一步是实例化并返回Coordinates的实例： Coordinates getCoordinates() { double longitude = 10; double latitude = 12.5; String placeName = \u0026#34;home\u0026#34;; return new Coordinates(longitude, latitude, placeName); } 我们应该注意，**建议我们将Coordinates这样的数据类设置为不可变**的。通过这样做，我们创建了简单的、线程安全的、可共享的对象。 5. 使用元组 像容器一样，元组存储不同类型的字段。但是，它们的不同之处在于它们不是特定于应用程序的。 当我们使用它们来描述我们希望它们处理哪些类型时，它们是专门的，但它们是一定数量值的通用容器。这意味着我们不需要编写自定义代码来拥有它们，我们可以使用库，或者创建一个通用的单个实现。 元组可以是任意数量的字段，通常称为元组n，其中 n 是字段数。例如，Tuple2 是二字段元组，Tuple3 是三字段元组，以此类推。 为了演示元组的重要性，让我们考虑以下示例。假设我们想要找到一个Coordinates点与*List*内所有其他点之间的距离。然后，我们需要返回最远的 Coordinate 对象以及距离。 让我们首先创建一个通用的两字段元组： public class Tuple2\u0026lt;K, V\u0026gt; { private K first; private V second; public Tuple2(K first, V second){ this.first = first; this.second = second; } // getters and setters } 接下来，让我们实现我们的逻辑并使用*Tuple2\u0026lt;Coordinates, Double\u0026gt;*实例来包装结果： Tuple2\u0026lt;Coordinates, Double\u0026gt; getMostDistantPoint(List\u0026lt;Coordinates\u0026gt; coordinatesList, Coordinates target) { return coordinatesList.stream() .map(coor -\u0026gt; new Tuple2\u0026lt;\u0026gt;(coor, coor.calculateDistance(target))) .max((d1, d2) -\u0026gt; Double.compare(d1.getSecond(), d2.getSecond())) // compare distances  .get(); } *在前面的示例中使用*Tuple2\u0026lt;Coordinates, Double\u0026gt;使我们免于创建一个单独的容器类，以便一次性使用这个特定的方法。 像容器一样，元组应该是不可变的。此外，由于它们的通用性，我们应该在内部使用元组，而不是作为公共 API 的一部分。 6. 第三方库 一些第三方库已经实现了不可变的Pair或Triple类型。Apache Commons Lang和javatuples就是最好的例子。一旦我们将这些库作为应用程序中的依赖项，我们就可以直接使用库提供的Pair或Triple类型，而不是自己创建它们。 让我们看一个使用 Apache Commons Lang 返回Pair或Triple对象的示例。 在我们更进一步之前，让我们在pom.xml中添加commons-lang3依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 6.1 来自 Apache Commons Lang 的ImmutablePair 来自 Apache Commons Lang的*ImmutablePair*类型正是我们想要的：一个使用简单的不可变类型。 它包含两个字段：left和right。让我们看看如何让我们的getMostDistantPoint方法返回一个ImmutablePair类型的对象： ImmutablePair\u0026lt;Coordinates, Double\u0026gt; getMostDistantPoint( List\u0026lt;Coordinates\u0026gt; coordinatesList, Coordinates target) { return coordinatesList.stream() .map(coordinates -\u0026gt; ImmutablePair.of(coordinates, coordinates.calculateDistance(target))) .max(Comparator.comparingDouble(Pair::getRight)) .get(); } 6.2. 来自 Apache Commons Lang 的ImmutableTriple ImmutableTriple与ImmutablePair非常相似。唯一的区别是，正如其名称所示，ImmutableTriple包含三个字段：left、middle和right。 现在，让我们在坐标计算中添加一个新方法来展示如何使用ImmutableTriple类型。 我们将遍历List中的所有点，以找出到给定目标点的最小、平均和最大距离。 让我们看看如何使用ImmutableTriple类通过单个方法返回三个值： ImmutableTriple\u0026lt;Double, Double, Double\u0026gt; getMinAvgMaxTriple( List\u0026lt;Coordinates\u0026gt; coordinatesList, Coordinates target) { List\u0026lt;Double\u0026gt; distanceList = coordinatesList.stream() .map(coordinates -\u0026gt; coordinates.calculateDistance(target)) .collect(Collectors.toList()); Double minDistance = distanceList.stream().mapToDouble(Double::doubleValue).min().getAsDouble(); Double avgDistance = distanceList.stream().mapToDouble(Double::doubleValue).average().orElse(0.0D); Double maxDistance = distanceList.stream().mapToDouble(Double::doubleValue).max().getAsDouble(); return ImmutableTriple.of(minDistance, avgDistance, maxDistance); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_method_return_multiple_values/","tags":[],"title":"如何从 Java 方法返回多个值"},{"categories":["Java"],"contents":"1. 概述 在这篇简短的文章中，我们将快速了解如何使用 Java 反射 API 在运行时调用方法。 2. 准备 让我们创建一个简单的类，我们将在下面的示例中使用它： public class Operations { public double publicSum(int a, double b) { return a + b; } public static double publicStaticMultiply(float a, long b) { return a * b; } private boolean privateAnd(boolean a, boolean b) { return a \u0026amp;\u0026amp; b; } protected int protectedMax(int a, int b) { return a \u0026gt; b ? a : b; } } 3. 获取Method对象 首先，我们需要获取一个反映我们要调用的方法的Method对象。Class对象，表示定义方法的类型，提供了两种方法来执行此操作。 3.1 getMethod() 我们可以使用*getMethod()*来查找该类或其任何超类的任何公共方法。 基本上，它接收方法名称作为第一个参数，然后是方法参数的类型： Method sumInstanceMethod = Operations.class.getMethod(\u0026#34;publicSum\u0026#34;, int.class, double.class); Method multiplyStaticMethod = Operations.class.getMethod( \u0026#34;publicStaticMultiply\u0026#34;, float.class, long.class); 3.2. getDeclaredMethod() 我们可以使用*getDeclaredMethod()*来获取任何类型的方法。这包括公共、受保护、默认访问，甚至私有方法，但不包括继承的方法。 *它接收与getMethod()*相同的参数： Method andPrivateMethod = Operations.class.getDeclaredMethod( \u0026#34;privateAnd\u0026#34;, boolean.class, boolean.class); Method maxProtectedMethod = Operations.class.getDeclaredMethod(\u0026#34;protectedMax\u0026#34;, int.class, int.class); 4. 调用方法 有了Method实例，我们现在可以调用*invoke()*来执行底层方法并获取返回的对象。 4.1 实例方法 要调用实例方法，invoke()的第一个参数必须是反映被调用方法的Method实例： @Test public void givenObject_whenInvokePublicMethod_thenCorrect() { Method sumInstanceMethod = Operations.class.getMethod(\u0026#34;publicSum\u0026#34;, int.class, double.class); Operations operationsInstance = new Operations(); Double result = (Double) sumInstanceMethod.invoke(operationsInstance, 1, 3); assertThat(result, equalTo(4.0)); } 4.2. 静态方法 由于这些方法不需要调用实例，我们可以将null作为第一个参数传递： @Test public void givenObject_whenInvokeStaticMethod_thenCorrect() { Method multiplyStaticMethod = Operations.class.getDeclaredMethod( \u0026#34;publicStaticMultiply\u0026#34;, float.class, long.class); Double result = (Double) multiplyStaticMethod.invoke(null, 3.5f, 2); assertThat(result, equalTo(7.0)); } 5. 方法可访问性 **默认情况下，并非所有反射方法都可以访问。**这意味着 JVM 在调用它们时会强制执行访问控制检查。 例如，如果我们尝试在其定义类之外调用私有方法或从子类或其类的包之外调用受保护方法，我们将得到IllegalAccessException： @Test(expected = IllegalAccessException.class) public void givenObject_whenInvokePrivateMethod_thenFail() { Method andPrivateMethod = Operations.class.getDeclaredMethod( \u0026#34;privateAnd\u0026#34;, boolean.class, boolean.class); Operations operationsInstance = new Operations(); Boolean result = (Boolean) andPrivateMethod.invoke(operationsInstance, true, false); assertFalse(result); } @Test(expected = IllegalAccessException.class) public void givenObject_whenInvokeProtectedMethod_thenFail() { Method maxProtectedMethod = Operations.class.getDeclaredMethod( \u0026#34;protectedMax\u0026#34;, int.class, int.class); Operations operationsInstance = new Operations(); Integer result = (Integer) maxProtectedMethod.invoke(operationsInstance, 2, 4); assertThat(result, equalTo(4)); } 5.1 AccessibleObject#setAccesible 通过在反射方法对象上调用setAccesible(true) ，JVM 抑制访问控制检查并允许我们调用该方法而不抛出异常： @Test public void givenObject_whenInvokePrivateMethod_thenCorrect() throws Exception { Method andPrivatedMethod = Operations.class.getDeclaredMethod(\u0026#34;privateAnd\u0026#34;, boolean.class, boolean.class); andPrivatedMethod.setAccessible(true); Operations operationsInstance = new Operations(); Boolean result = (Boolean) andPrivatedMethod.invoke(operationsInstance, true, false); assertFalse(result); } 5.2. AccessibleObject#canAccess Java 9提供了一种全新的方法来检查调用者是否可以访问反射的方法对象。 为此，它提供了canAccess作为已弃用的方法*isAccessible 的替代品。* 让我们看看它的实际效果： @Test public void givenObject_whenInvokePrivateMethod_thenCheckAccess() throws Exception { Operations operationsInstance = new Operations(); Method andPrivatedMethod = Operations.class.getDeclaredMethod(\u0026#34;privateAnd\u0026#34;, boolean.class, boolean.class); boolean isAccessEnabled = andPrivatedMethod.canAccess(operationsInstance); assertFalse(isAccessEnabled); } 在使用setAccessible(true)将ccessible标志设置为true之前，我们可以使用canAccess检查调用者是否已经可以访问反射方法。 5.3. AccessibleObject#trySetAccessible trySetAccessible是另一个方便的方法，我们可以使用它来使反射对象可访问。 这种新方法的好处是，如果无法启用访问，它会返回false。但是，旧方法setAccessible(true)在失败时会抛出InaccessibleObjectException 。 让我们举例说明trySetAccessible方法的使用： @Test public void givenObject_whenInvokePublicMethod_thenEnableAccess() throws Exception { Operations operationsInstance = new Operations(); Method andPrivatedMethod = Operations.class.getDeclaredMethod(\u0026#34;privateAnd\u0026#34;, boolean.class, boolean.class); andPrivatedMethod.trySetAccessible(); boolean isAccessEnabled = andPrivatedMethod.canAccess(operationsInstance); assertTrue(isAccessEnabled); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_method_reflection/","tags":["Core Java","Reflection"],"title":"使用 Java 反射在运行时调用方法"},{"categories":["Java"],"contents":"1. 概述 Java 8 中最受欢迎的变化之一是引入 lambda 表达式，因为这些允许我们放弃匿名类，从而大大减少样板代码并提高可读性。 方法引用是一种特殊类型的 lambda 表达式。它们通常用于通过引用现有方法来创建简单的 lambda 表达式。 有四种方法引用：  静态方法 特定对象的实例方法 特定类型的任意对象的实例方法 构造函数  在本教程中，我们将探讨 Java 中的方法引用。 2. 引用静态方法 我们将从一个非常简单的示例开始，大写并打印一个字符串列表： List\u0026lt;String\u0026gt; messages = Arrays.asList(\u0026#34;hello\u0026#34;, \u0026#34;ann\u0026#34;, \u0026#34;bob!\u0026#34;); 我们可以通过利用一个简单的 lambda 表达式直接调用StringUtils.capitalize()方法来实现这一点： messages.forEach(word -\u0026gt; StringUtils.capitalize(word)); 或者，我们可以使用方法引用来简单地引用大写静态方法： messages.forEach(StringUtils::capitalize); 请注意，方法引用总是使用::运算符。 3. 引用特定对象的实例方法 为了演示这种类型的方法引用，让我们考虑两个类： public class Bicycle { private String brand; private Integer frameSize; // standard constructor, getters and setters } public class BicycleComparator implements Comparator { @Override public int compare(Bicycle a, Bicycle b) { return a.getFrameSize().compareTo(b.getFrameSize()); } } 并且，让我们创建一个BicycleComparator对象来比较自行车车架尺寸： BicycleComparator bikeFrameSizeComparator = new BicycleComparator(); 我们可以使用 lambda 表达式按车架尺寸对自行车进行排序，但我们需要指定两辆自行车进行比较： createBicyclesList().stream() .sorted((a, b) -\u0026gt; bikeFrameSizeComparator.compare(a, b)); 相反，我们可以使用方法引用让编译器为我们处理参数传递： createBicyclesList().stream() .sorted(bikeFrameSizeComparator::compare); 方法参考更加清晰易读，代码清楚地表明了我们的意图。 4. 引用特定类型的任意对象的实例方法 这种类型的方法引用类似于前面的示例，但无需创建自定义对象来执行比较。 让我们创建一个 要排序的整数列表： List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(5, 3, 50, 24, 40, 2, 9, 18); 如果我们使用经典的 lambda 表达式，两个参数都需要显式传递，而使用方法引用要简单得多： numbers.stream() .sorted((a, b) -\u0026gt; a.compareTo(b)); numbers.stream() .sorted(Integer::compareTo); 尽管它仍然是单行的，但方法参考更容易阅读和理解。 5. 对构造函数的引用 我们可以像在第一个示例中引用静态方法一样引用构造函数。唯一的区别是我们将使用new关键字。 让我们用不同品牌的字符串列表创建一个Bicycle数组： List\u0026lt;String\u0026gt; bikeBrands = Arrays.asList(\u0026#34;Giant\u0026#34;, \u0026#34;Scott\u0026#34;, \u0026#34;Trek\u0026#34;, \u0026#34;GT\u0026#34;); 首先，我们将向Bicycle类添加一个新的构造函数： public Bicycle(String brand) { this.brand = brand; this.frameSize = 0; } 接下来，我们将使用方法引用中的新构造函数，并从原始字符串列表中创建一个**Bicycle数组： bikeBrands.stream() .map(Bicycle::new) .toArray(Bicycle[]::new); 请注意我们如何使用方法引用调用Bicycle和Array构造函数，从而使我们的代码外观更加简洁明了。 6. 其他示例和限制 到目前为止，我们已经看到，方法引用是使我们的代码和意图非常清晰易读的好方法。但是，我们不能用它们来替换各种 lambda 表达式，因为它们有一些限制。 它们的主要限制是它们最大的优势： 前一个表达式的输出需要与引用的方法签名的输入参数相匹配。 让我们看一个这个限制的例子： createBicyclesList().forEach(b -\u0026gt; System.out.printf( \u0026#34;Bike brand is \u0026#39;%s\u0026#39; and frame size is \u0026#39;%d\u0026#39;%n\u0026#34;, b.getBrand(), b.getFrameSize())); 这种简单的情况不能用方法引用来表达，因为在我们的例子中printf方法需要 3 个参数，而使用*createBicyclesList().forEach()*只会允许方法引用推断一个参数（Bicycle对象）。 最后，让我们探索如何创建一个可以从 lambda 表达式引用的无操作函数。 在这种情况下，我们希望使用 lambda 表达式而不使用其参数。 首先，让我们创建doNothingAtAll方法： private static \u0026lt;T\u0026gt; void doNothingAtAll(Object... o) { } 由于它是一个可变参数方法，它可以在任何 lambda 表达式中工作，无论引用的对象或推断的参数数量如何。 现在，让我们看看它的实际效果： createBicyclesList() .forEach((o) -\u0026gt; MethodReferenceExamples.doNothingAtAll(o)); \u0026quot; ","permalink":"http://itcodingman.github.io/java_method_references/","tags":["Core Java"],"title":"Java 中的方法引用"},{"categories":["Java","BiliBili"],"contents":"Eclipse、Tomcat和Java Web的安装、配置及开发 Eclipse、Tomcat和Java Web的安装、配置及开发 \r","permalink":"http://itcodingman.github.io/eclipse_tomcat_java_web_install_introduce/","tags":[],"title":"Eclipse、Tomcat和Java Web的安装、配置及开发"},{"categories":["Java"],"contents":"1. 概述 方法重载和覆盖是 Java 编程语言的关键概念，因此值得深入了解。 在本文中，我们将了解这些概念的基础知识，并了解它们在哪些情况下有用。 2.方法重载 **方法重载是一种强大的机制，它允许我们定义内聚的类 API。**为了更好地理解为什么方法重载是一个如此有价值的特性，让我们看一个简单的例子。 假设我们编写了一个简单的实用程序类，它实现了两个数字相乘、三个数字相乘等的不同方法。 如果我们给方法提供了误导性或模棱两可的名称，例如multiply2()、multiply3()、*multiply4() ，*那么这将是一个设计糟糕的类 API。这就是方法重载发挥作用的地方。 简单地说，我们可以通过两种不同的方式实现方法重载：  实现两个或多个具有相同名称但采用不同数量参数的方法 实现两个或多个具有相同名称但采用不同类型参数的方法  2.1 不同数量的参数 简而言之，Multiplier类显示了如何通过简单地定义两个采用不同数量参数的实现来重载multiply()方法： public class Multiplier { public int multiply(int a, int b) { return a * b; } public int multiply(int a, int b, int c) { return a * b * c; } } 2.2. 不同类型的参数 同样，我们可以通过使其接受不同类型的参数来重载multiply()方法： public class Multiplier { public int multiply(int a, int b) { return a * b; } public double multiply(double a, double b) { return a * b; } } 此外，使用两种类型的方法重载定义Multiplier类是合法的： public class Multiplier { public int multiply(int a, int b) { return a * b; } public int multiply(int a, int b, int c) { return a * b * c; } public double multiply(double a, double b) { return a * b; } } 然而，值得注意的是，不可能有两个仅在返回类型上有所不同的方法实现。 要了解原因——让我们考虑以下示例： public int multiply(int a, int b) { return a * b; } public double multiply(int a, int b) { return a * b; } 在这种情况下，由于方法调用不明确，代码根本无法编译——编译器不知道要调用哪个*multiply()*实现。 2.3. 类型推广 方法重载提供的一个简洁特性是所谓的类型提升，也就是扩大原始转换。 简单来说，当传递给重载方法的参数类型与特定方法实现之间不匹配时，一种给定类型会隐式提升为另一种类型。 要更清楚地了解类型提升的工作原理，请考虑以下*multiply()*方法的实现： public double multiply(int a, long b) { return a * b; } public int multiply(int a, int b, int c) { return a * b * c; } 现在，使用两个int参数调用该方法将导致第二个参数被提升为long，因为在这种情况下，没有一个具有两个int参数的方法的匹配实现。 让我们看一个快速的单元测试来演示类型提升： @Test public void whenCalledMultiplyAndNoMatching_thenTypePromotion() { assertThat(multiplier.multiply(10, 10)).isEqualTo(100.0); } 相反，如果我们调用具有匹配实现的方法，则不会发生类型提升： @Test public void whenCalledMultiplyAndMatching_thenNoTypePromotion() { assertThat(multiplier.multiply(10, 10, 10)).isEqualTo(1000); } 以下是适用于方法重载的类型提升规则的摘要：  byte可以提升为short、int、long、float或double short可以提升为int、long、float或double char可以提升为int、long、float或double int可以提升为long、float或double long可以提升为float或double float可以提升为double  2.4. 静态绑定 将特定方法调用关联到方法主体的能力称为绑定。 在方法重载的情况下，绑定是在编译时静态执行的，因此称为静态绑定。 编译器可以通过简单地检查方法的签名在编译时有效地设置绑定。 3. 方法覆盖 方法覆盖允许我们在子类中为基类中定义的方法提供细粒度的实现。 虽然方法覆盖是一个强大的功能 - 考虑到这是使用继承的逻辑结果， OOP的最大支柱之一-应该在每个用例的基础上仔细分析何时何地使用它。 现在让我们看看如何通过创建一个简单的、基于继承的（“is-a”）关系来使用方法覆盖。 这是基类： public class Vehicle { public String accelerate(long mph) { return \u0026#34;The vehicle accelerates at : \u0026#34; + mph + \u0026#34; MPH.\u0026#34;; } public String stop() { return \u0026#34;The vehicle has stopped.\u0026#34;; } public String run() { return \u0026#34;The vehicle is running.\u0026#34;; } } 这是一个人为的子类： public class Car extends Vehicle { @Override public String accelerate(long mph) { return \u0026#34;The car accelerates at : \u0026#34; + mph + \u0026#34; MPH.\u0026#34;; } } 在上面的层次结构中，我们简单地覆盖了Accelerator()方法，以便为子类型Car 提供更精细的实现。 在这里，可以清楚地看到，如果应用程序使用Vehicle类的实例，那么它也可以使用Car的实例，因为*加速（）*方法的两个实现具有相同的签名和相同的返回类型。 让我们编写一些单元测试来检查Vehicle和Car类： @Test public void whenCalledAccelerate_thenOneAssertion() { assertThat(vehicle.accelerate(100)) .isEqualTo(\u0026#34;The vehicle accelerates at : 100 MPH.\u0026#34;); } @Test public void whenCalledRun_thenOneAssertion() { assertThat(vehicle.run()) .isEqualTo(\u0026#34;The vehicle is running.\u0026#34;); } @Test public void whenCalledStop_thenOneAssertion() { assertThat(vehicle.stop()) .isEqualTo(\u0026#34;The vehicle has stopped.\u0026#34;); } @Test public void whenCalledAccelerate_thenOneAssertion() { assertThat(car.accelerate(80)) .isEqualTo(\u0026#34;The car accelerates at : 80 MPH.\u0026#34;); } @Test public void whenCalledRun_thenOneAssertion() { assertThat(car.run()) .isEqualTo(\u0026#34;The vehicle is running.\u0026#34;); } @Test public void whenCalledStop_thenOneAssertion() { assertThat(car.stop()) .isEqualTo(\u0026#34;The vehicle has stopped.\u0026#34;); } 现在，让我们看一些单元测试，这些测试显示了未覆盖的run()和stop()方法如何为Car和Vehicle返回相等的值： @Test public void givenVehicleCarInstances_whenCalledRun_thenEqual() { assertThat(vehicle.run()).isEqualTo(car.run()); } @Test public void givenVehicleCarInstances_whenCalledStop_thenEqual() { assertThat(vehicle.stop()).isEqualTo(car.stop()); } 在我们的例子中，我们可以访问这两个类的源代码，因此我们可以清楚地看到，在基础Vehicle实例上调用accelerate()方法和在Car实例上调用*accelerate()*将针对相同的参数返回不同的值。 因此，以下测试演示了为Car的实例调用了重写的方法： @Test public void whenCalledAccelerateWithSameArgument_thenNotEqual() { assertThat(vehicle.accelerate(100)) .isNotEqualTo(car.accelerate(100)); } 3.1 类型可替代性 OOP 中的一个核心原则是类型可替换性原则，它与Liskov 替换原则 (LSP)密切相关。 简单地说，LSP 声明如果应用程序使用给定的基本类型，那么它也应该使用它的任何子类型。这样，类型可替换性就得到了适当的保留。 方法重写的最大问题是派生类中的某些特定方法实现可能不完全遵循 LSP，因此无法保持类型可替换性。 当然，创建一个重写的方法来接受不同类型的参数并返回不同类型是有效的，但要完全遵守以下规则：  如果基类中的方法采用给定类型的参数，则被覆盖的方法应采用相同的类型或超类型（也称为逆变方法参数） 如果基类中的方法返回void，则被覆盖的方法应返回void 如果基类中的方法返回原语，则被覆盖的方法应返回相同的原语 如果基类中的方法返回某种类型，则被覆盖的方法应返回相同的类型或子类型（也称为协变返回类型） 如果基类中的方法抛出异常，被覆盖的方法必须抛出相同的异常或基类异常的子类型  3.2. 动态绑定 考虑到方法覆盖只能通过继承实现，其中存在基类型和子类型的层次结构，编译器无法在编译时确定调用什么方法，因为基类和子类都定义了相同的方法。 因此，编译器需要检查对象的类型以了解应该调用什么方法。 由于这种检查发生在运行时，方法覆盖是动态绑定的典型示例。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_method_overload_override/","tags":["Core Java"],"title":"Java中的方法重载和覆盖"},{"categories":["Java"],"contents":"1. 简介 在本文中，我们将探讨 Java 7 中引入并在以下版本中得到增强的重要 API，即*java.lang.invoke.MethodHandles*。 特别是，我们将学习什么是方法句柄，如何创建它们以及如何使用它们。 2. 什么是方法句柄？ 如API文档中所述，对其定义进行了说明：  方法句柄是对底层方法、构造函数、字段或类似的低级操作的类型化、直接可执行的引用，具有参数或返回值的可选转换。  以更简单的方式，方法句柄是一种用于查找、调整和调用方法的低级机制。 方法句柄是不可变的并且没有可见状态。 要创建和使用MethodHandle，需要 4 个步骤：  创建查找 创建方法类型 查找方法句柄 调用方法句柄  2.1 方法句柄与反射 引入方法句柄是为了与现有的*java.lang.reflect* API 一起工作，因为它们服务于不同的目的并具有不同的特性。 从性能的角度来看，MethodHandles API 可以比 Reflection API 快得多，因为访问检查是在创建时而不是在执行时进行的。如果存在安全管理器，则这种差异会被放大，因为成员和类查找需要进行额外检查。 然而，考虑到性能并不是任务的唯一适用性衡量标准，我们还必须考虑MethodHandles API 更难使用，因为缺少成员类枚举、可访问性标志检查等机制。 即便如此，MethodHandles API 提供了对方法进行柯里化、更改参数类型和更改顺序的可能性。 有了MethodHandles API 的明确定义和目标，我们现在可以开始使用它们，从查找开始。 3. 创建查找 当我们想要创建方法句柄时，首先要做的是检索查找，工厂对象负责为查找类可见的方法、构造函数和字段创建方法句柄。 通过MethodHandles API，可以创建具有不同访问模式的查找对象。 让我们创建提供对公共方法的访问的查找： MethodHandles.Lookup publicLookup = MethodHandles.publicLookup(); 但是，如果我们还想访问私有和受保护的方法，我们可以使用*lookup()*方法： MethodHandles.Lookup lookup = MethodHandles.lookup(); 4. 创建一个MethodType 为了能够创建MethodHandle，查找对象需要定义其类型，这是通过MethodType类实现的。 特别是，MethodType表示方法句柄接受和返回的参数和返回类型，或者方法句柄调用者传递和预期的参数和返回类型。 MethodType的结构很简单，它由返回类型和适当数量的参数类型组成，这些参数类型必须在方法句柄及其所有调用者之间正确匹配。 与MethodHandle 一样，即使是MethodType的实例也是不可变的。 让我们看看如何定义一个MethodType，将java.util.List类指定为返回类型，将Object数组指定为输入类型： MethodType mt = MethodType.methodType(List.class, Object[].class); 如果方法返回原始类型或void作为其返回类型，我们将使用表示这些类型的类（void.class、int.class \u0026hellip;）。 让我们定义一个MethodType，它返回一个 int 值并接受一个Object： MethodType mt = MethodType.methodType(int.class, Object.class); 我们现在可以继续创建MethodHandle。 5. 寻找MethodHandle 一旦我们定义了我们的方法类型，为了创建一个MethodHandle，我们必须通过查找或publicLookup对象找到它，同时提供原始类和方法名称。 特别是，查找工厂提供了一组方法，允许我们在考虑方法范围的情况下以适当的方式查找方法句柄。从最简单的场景开始，让我们探索主要的场景。 5.1 方法的方法句柄 使用*findVirtual()方法允许我们为对象方法创建 MethodHandle。让我们根据String类的concat()*方法创建一个： MethodType mt = MethodType.methodType(String.class, String.class); MethodHandle concatMH = publicLookup.findVirtual(String.class, \u0026#34;concat\u0026#34;, mt); 5.2. 静态方法的方法句柄 当我们想要访问静态方法时，我们可以使用*findStatic()*方法： MethodType mt = MethodType.methodType(List.class, Object[].class); MethodHandle asListMH = publicLookup.findStatic(Arrays.class, \u0026#34;asList\u0026#34;, mt); 在这种情况下，我们创建了一个方法句柄，将对象数组转换为它们的列表。 5.3. 构造函数的方法句柄 可以使用*findConstructor()*方法访问构造函数。 让我们创建一个方法句柄，其行为类似于Integer类的构造函数，接受String属性： MethodType mt = MethodType.methodType(void.class, String.class); MethodHandle newIntegerMH = publicLookup.findConstructor(Integer.class, mt); 5.4. 字段的方法句柄 使用方法句柄也可以访问字段。 让我们开始定义Book类： public class Book { String id; String title; // constructor  } 以方法句柄和声明的属性之间的直接访问可见性为前提，我们可以创建一个充当 getter 的方法句柄： MethodHandle getTitleMH = lookup.findGetter(Book.class, \u0026#34;title\u0026#34;, String.class); 有关处理变量/字段的更多信息，请查看Java 9 Variable Handles Demystified，其中我们讨论了Java 9 中添加的java.lang.invoke.VarHandle API。 5.5。私有方法的方法句柄 在java.lang.reflect API的帮助下，可以为私有方法创建方法句柄。 让我们开始为Book类添加一个私有方法： private String formatBook() { return id + \u0026#34; \u0026gt; \u0026#34; + title; } *现在我们可以创建一个与formatBook()*方法完全相同的方法句柄： Method formatBookMethod = Book.class.getDeclaredMethod(\u0026#34;formatBook\u0026#34;); formatBookMethod.setAccessible(true); MethodHandle formatBookMH = lookup.unreflect(formatBookMethod); 6.调用方法句柄 一旦我们创建了方法句柄，下一步就是使用它们。特别是，MethodHandle类提供了 3 种不同的方式来执行方法句柄：invoke()、invokeWithArugments()和invokeExact()。 让我们从调用选项开始。 6.1 调用方法句柄 使用*invoke()*方法时，我们强制参数的数量（arity）是固定的，但我们允许对参数和返回类型进行强制转换和装箱/拆箱。 让我们看看如何将*invoke()*与盒装参数一起使用： MethodType mt = MethodType.methodType(String.class, char.class, char.class); MethodHandle replaceMH = publicLookup.findVirtual(String.class, \u0026#34;replace\u0026#34;, mt); String output = (String) replaceMH.invoke(\u0026#34;jovo\u0026#34;, Character.valueOf(\u0026#39;o\u0026#39;), \u0026#39;a\u0026#39;); assertEquals(\u0026#34;java\u0026#34;, output); 在这种情况下，replaceMH需要char参数，但invoke()在执行之前对**Character参数执行拆箱。 6.2. 使用参数调用 使用invokeWithArguments方法调用方法句柄是三个选项中限制最少的。 事实上，除了参数和返回类型的强制转换和装箱/拆箱外，它还允许变量 arity 调用。 开始实践，这允许我们从一个int值数组开始创建一个整数**列表： MethodType mt = MethodType.methodType(List.class, Object[].class); MethodHandle asList = publicLookup.findStatic(Arrays.class, \u0026#34;asList\u0026#34;, mt); List\u0026lt;Integer\u0026gt; list = (List\u0026lt;Integer\u0026gt;) asList.invokeWithArguments(1,2); assertThat(Arrays.asList(1,2), is(list)); 6.3. 调用精确 如果我们希望在执行方法句柄（参数的数量及其类型）的方式上更加严格，我们必须使用*invokeExact()*方法。 事实上，它不提供对提供的类的任何转换，并且需要固定数量的参数。 让我们看看如何使用方法句柄对两个int值**求和： MethodType mt = MethodType.methodType(int.class, int.class, int.class); MethodHandle sumMH = lookup.findStatic(Integer.class, \u0026#34;sum\u0026#34;, mt); int sum = (int) sumMH.invokeExact(1, 11); assertEquals(12, sum); 如果在这种情况下，我们决定向invokeExact方法传递一个不是int的数字，则调用将导致WrongMethodTypeException。 7. 使用数组 MethodHandles不仅适用于字段或对象，还适用于数组。事实上，使用asSpreader() API，可以处理数组扩展方法。 在这种情况下，方法句柄接受一个数组参数，将其元素作为位置参数展开，并且可以选择数组的长度。 让我们看看如何传播方法句柄来检查数组中的元素是否相等： MethodType mt = MethodType.methodType(boolean.class, Object.class); MethodHandle equals = publicLookup.findVirtual(String.class, \u0026#34;equals\u0026#34;, mt); MethodHandle methodHandle = equals.asSpreader(Object[].class, 2); assertTrue((boolean) methodHandle.invoke(new Object[] { \u0026#34;java\u0026#34;, \u0026#34;java\u0026#34; })); 8. 增强方法句柄 一旦我们定义了一个方法句柄，就可以通过将方法句柄绑定到一个参数而不实际调用它来增强它。 例如，在 Java 9 中，这种行为用于优化字符串连接。 让我们看看如何执行连接，将后缀绑定到我们的concatMH： MethodType mt = MethodType.methodType(String.class, String.class); MethodHandle concatMH = publicLookup.findVirtual(String.class, \u0026#34;concat\u0026#34;, mt); MethodHandle bindedConcatMH = concatMH.bindTo(\u0026#34;Hello \u0026#34;); assertEquals(\u0026#34;Hello World!\u0026#34;, bindedConcatMH.invoke(\u0026#34;World!\u0026#34;)); 9. Java 9 增强功能 在 Java 9 中，对MethodHandles API 进行了一些改进，目的是使其更易于使用。 增强功能影响了 3 个主要主题：  查找函数——允许从不同的上下文中查找类并支持接口中的非抽象方法 论点处理——改进论点折叠、论点收集和论点传播功能 其他组合——添加循环（loop、whileLoop、doWhileLoop… ）以及使用tryFinally提供更好的异常处理支持  这些变化带来了一些额外的好处：  增加了 JVM 编译器优化 实例化减少 在MethodHandles API的使用中启用精度  MethodHandles API Javadoc中提供了增强的详细信息。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_method_handles/","tags":[],"title":"Java中的方法句柄"},{"categories":["Java","Youtube"],"contents":"20分钟学习Ant安装和使用   ","permalink":"http://itcodingman.github.io/20_mins_ant/","tags":[],"title":"20分钟学习Ant安装和使用"},{"categories":["Java"],"contents":"1. 简介 在这个简短的教程中，我们将重点介绍如何将两个或多个 Java Properties对象合并为一个。 我们将探索三种解决方案，首先从使用迭代的示例开始。接下来，我们将研究使用*putAll()*方法，并在结束本教程时，我们将研究一种使用 Java 8 Streams 的更现代的方法。 要了解如何开始使用 Java 属性，请查看我们的介绍性文章。 2. 使用属性的快速回顾 让我们首先提醒自己一些属性的关键概念。 我们通常在应用程序中使用属性来定义配置值。在 Java 中，我们使用简单的键/值对来表示这些值。此外，每个对中的键和值都是字符串值。 通常我们使用java.util.Properties类来表示和管理这些值对。重要的是要注意这个类继承自Hashtable。 要了解有关Hashtable数据结构的更多信息，请阅读我们的Java.util.Hashtable 简介。 2.1 设置属性 为了简单起见，我们将以编程方式为我们的示例设置属性： private Properties propertiesA() { Properties properties = new Properties(); properties.setProperty(\u0026#34;application.name\u0026#34;, \u0026#34;my-app\u0026#34;); properties.setProperty(\u0026#34;application.version\u0026#34;, \u0026#34;1.0\u0026#34;); return properties; } 在上面的示例中，我们创建了一个Properties对象，并使用setProperty()方法设置了两个属性。在内部，它从Hashtable类调用put()方法， 但确保对象是字符串值。 注意，强烈建议不要直接使用put()方法，因为它允许调用者插入键或值不是字符串的条目。 3. 使用迭代合并属性 现在让我们看看如何使用迭代合并两个或多个属性对象： private Properties mergePropertiesByIteratingKeySet(Properties... properties) { Properties mergedProperties = new Properties(); for (Properties property : properties) { Set\u0026lt;String\u0026gt; propertyNames = property.stringPropertyNames(); for (String name : propertyNames) { String propertyValue = property.getProperty(name); mergedProperties.setProperty(name, propertyValue); } } return mergedProperties; } 让我们把这个例子分解成几个步骤：  首先，我们创建一个Properties对象来保存我们所有的合并属性 接下来，我们遍历 要合并的Properties对象 然后我们调用*stringPropertyNames()*方法来获取一组属性名称 然后我们遍历所有的属性名称并获取每个名称的属性值 最后，我们将属性值设置到我们在步骤 1 中创建的变量中  *4. 使用*putAll()方法 现在我们将看看另一个使用*putAll()*方法合并属性的常见解决方案： private Properties mergePropertiesByUsingPutAll(Properties... properties) { Properties mergedProperties = new Properties(); for (Properties property : properties) { mergedProperties.putAll(property); } return mergedProperties; } 在我们的第二个示例中，我们首先创建一个 Properties对象来保存我们所有的合并属性，称为mergeProperties。同样，然后我们遍历要合并的Properties对象，但这次我们使用putAll()方法将每个Properties对象添加到mergeProperties变量中。 putAll()方法是从Hashtable继承的另一种方法。此方法允许我们将所有映射从指定的Properties复制 到我们的新Properties对象中。 值得一提的是，不鼓励将putAll()与任何类型的Map一起使用，因为我们最终可能会得到键或值不是字符串的条目 5. 使用 Stream API 合并属性 最后，我们将看看如何使用 Stream API 来合并多个Properties对象： private Properties mergePropertiesByUsingStreamApi(Properties... properties) { return Stream.of(properties) .collect(Properties::new, Map::putAll, Map::putAll); } 在我们的最后一个示例中，我们从属性列表创建一个Stream，然后使用collect方法将流中的值序列减少到一个新的Collection中。第一个参数是一个Supplier函数，用于创建一个新的结果容器，在我们的例子中是一个新的Properties对象。 Stream API 是在 Java 8 中引入的，我们有一个使用这个 API 的指南。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_merging_properties/","tags":[],"title":"合并 java.util.Properties 对象"},{"categories":["Java"],"contents":"1. 概述 在这篇快速文章中，我们解释了合并 Java Streams的不同方法——这不是一个非常直观的操作。 2. 使用纯 Java JDK 8 Stream类有一些有用的静态实用方法。让我们仔细看看*concat()*方法。 2.1 合并两个流 组合 2 个Stream最简单的方法是使用静态*Stream.concat()*方法： @Test public void whenMergingStreams_thenResultStreamContainsElementsFromBoth() { Stream\u0026lt;Integer\u0026gt; stream1 = Stream.of(1, 3, 5); Stream\u0026lt;Integer\u0026gt; stream2 = Stream.of(2, 4, 6); Stream\u0026lt;Integer\u0026gt; resultingStream = Stream.concat(stream1, stream2); assertEquals( Arrays.asList(1, 3, 5, 2, 4, 6), resultingStream.collect(Collectors.toList())); } 2.2. 合并多个Stream 当我们需要合并超过 2 个*Streams 时，*事情变得有点复杂。一种可能性是连接前两个流，然后将结果与下一个流连接，依此类推。 下一个代码片段显示了这一点： @Test public void given3Streams_whenMerged_thenResultStreamContainsAllElements() { Stream\u0026lt;Integer\u0026gt; stream1 = Stream.of(1, 3, 5); Stream\u0026lt;Integer\u0026gt; stream2 = Stream.of(2, 4, 6); Stream\u0026lt;Integer\u0026gt; stream3 = Stream.of(18, 15, 36); Stream\u0026lt;Integer\u0026gt; resultingStream = Stream.concat( Stream.concat(stream1, stream2), stream3); assertEquals( Arrays.asList(1, 3, 5, 2, 4, 6, 18, 15, 36), resultingStream.collect(Collectors.toList())); } 正如我们所看到的，这种方法对于更多的流变得不可行。当然，我们可以创建中间变量或辅助方法以使其更具可读性，但这里有一个更好的选择： @Test public void given4Streams_whenMerged_thenResultStreamContainsAllElements() { Stream\u0026lt;Integer\u0026gt; stream1 = Stream.of(1, 3, 5); Stream\u0026lt;Integer\u0026gt; stream2 = Stream.of(2, 4, 6); Stream\u0026lt;Integer\u0026gt; stream3 = Stream.of(18, 15, 36); Stream\u0026lt;Integer\u0026gt; stream4 = Stream.of(99); Stream\u0026lt;Integer\u0026gt; resultingStream = Stream.of( stream1, stream2, stream3, stream4) .flatMap(i -\u0026gt; i); assertEquals( Arrays.asList(1, 3, 5, 2, 4, 6, 18, 15, 36, 99), resultingStream.collect(Collectors.toList())); } 这里发生的是：  我们首先创建一个包含 4 个Stream 的新Stream ，这会导致Stream\u0026lt;Stream\u0026gt; 然后我们使用标识函数将其flatMap()转换为Stream  3. 使用 StreamEx StreamEx是一个开源 Java 库，它扩展了 Java 8 Streams 的可能性。它使用StreamEx类作为对 JDK 的Stream接口的增强。 3.1 合并Stream StreamEx 库允许我们使用*append()*实例方法合并流： @Test public void given4Streams_whenMerged_thenResultStreamContainsAllElements() { Stream\u0026lt;Integer\u0026gt; stream1 = Stream.of(1, 3, 5); Stream\u0026lt;Integer\u0026gt; stream2 = Stream.of(2, 4, 6); Stream\u0026lt;Integer\u0026gt; stream3 = Stream.of(18, 15, 36); Stream\u0026lt;Integer\u0026gt; stream4 = Stream.of(99); Stream\u0026lt;Integer\u0026gt; resultingStream = StreamEx.of(stream1) .append(stream2) .append(stream3) .append(stream4); assertEquals( Arrays.asList(1, 3, 5, 2, 4, 6, 18, 15, 36, 99), resultingStream.collect(Collectors.toList())); } 由于它是一个实例方法，我们可以轻松地链接它并附加多个流。 请注意，如果我们将resultStream变量键入StreamEx类型，我们还可以使用toList()从流中创建一个**List。 **3.2. 使用prepend()合并流 StreamEx 还包含一种在另一个之前添加元素的方法，称为prepend()： @Test public void given3Streams_whenPrepended_thenResultStreamContainsAllElements() { Stream\u0026lt;String\u0026gt; stream1 = Stream.of(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;); Stream\u0026lt;String\u0026gt; openingBracketStream = Stream.of(\u0026#34;[\u0026#34;); Stream\u0026lt;String\u0026gt; closingBracketStream = Stream.of(\u0026#34;]\u0026#34;); Stream\u0026lt;String\u0026gt; resultingStream = StreamEx.of(stream1) .append(closingBracketStream) .prepend(openingBracketStream); assertEquals( Arrays.asList(\u0026#34;[\u0026#34;, \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;]\u0026#34;), resultingStream.collect(Collectors.toList())); } 4. 使用 jOOL jOOL是一个兼容 JDK 8 的库，它为 JDK 提供了有用的扩展。这里最重要的流抽象称为Seq。请注意，这是一个顺序且有序的流，因此调用*parallel()*将不起作用。 4.1 合并流 就像 StreamEx 库一样，jOOλ 有一个*append()*方法： @Test public void given2Streams_whenMerged_thenResultStreamContainsAllElements() { Stream\u0026lt;Integer\u0026gt; seq1 = Stream.of(1, 3, 5); Stream\u0026lt;Integer\u0026gt; seq2 = Stream.of(2, 4, 6); Stream\u0026lt;Integer\u0026gt; resultingSeq = Seq.ofType(seq1, Integer.class) .append(seq2); assertEquals( Arrays.asList(1, 3, 5, 2, 4, 6), resultingSeq.collect(Collectors.toList())); } 此外，如果我们将 resultSeq 变量键入 jOOλ Seq类型，还有一个方便的*toList()*方法。 **4.2. 使用prepend()合并流 正如所料，由于存在*append()方法，因此jOOλ中也存在prepend()*方法： @Test public void given3Streams_whenPrepending_thenResultStreamContainsAllElements() { Stream\u0026lt;String\u0026gt; seq = Stream.of(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;); Stream\u0026lt;String\u0026gt; openingBracketSeq = Stream.of(\u0026#34;[\u0026#34;); Stream\u0026lt;String\u0026gt; closingBracketSeq = Stream.of(\u0026#34;]\u0026#34;); Stream\u0026lt;String\u0026gt; resultingStream = Seq.ofType(seq, String.class) .append(closingBracketSeq) .prepend(openingBracketSeq); Assert.assertEquals( Arrays.asList(\u0026#34;[\u0026#34;, \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;]\u0026#34;), resultingStream.collect(Collectors.toList())); } \u0026quot; ","permalink":"http://itcodingman.github.io/java_merge_streams/","tags":["Java Streams"],"title":"在 Java 中合并流"},{"categories":["Algorithms","Java"],"contents":"1. 概述 在这个简短的教程中，我们将看到如何使用堆有效地合并排序数组。 2. 算法 由于我们的问题陈述是使用堆来合并数组，因此我们将使用最小堆来解决我们的问题。最小堆只不过是一棵二叉树，其中每个节点的值都小于其子节点的值。 通常，最小堆是使用一个数组实现的，其中数组在查找节点的父节点和子节点时满足特定规则。 对于数组A[]和索引i处的元素：  *A[(i-1)/2]*将返回其父级 *A[(2*i)+1]*将返回左孩子 *A[(2*i)+2]*将返回右孩子  这是最小堆及其数组表示的图片： 现在让我们创建合并一组排序数组的算法：  创建一个数组来存储结果，其大小通过添加所有输入数组的长度来确定。 创建第二个大小等于输入数组数量的数组，并用所有输入数组的第一个元素填充它。 通过对所有节点及其子节点应用最小堆规则，将先前创建的数组转换为最小堆。 重复接下来的步骤，直到结果数组被完全填充。 从最小堆中获取根元素并将其存储在结果数组中。 将根元素替换为填充当前根的数组中的下一个元素。 在我们的最小堆数组上再次应用最小堆规则。  我们的算法有一个递归流程来创建最小堆，我们必须访问输入数组的所有元素。 该算法的时间复杂度为O(k log n)，其中k是所有输入数组中元素的总数，n是排序数组的总数。 现在让我们看看运行算法后的示例输入和预期结果，以便我们更好地理解问题。所以对于这些数组： { { 0, 6 }, { 1, 5, 10, 100 }, { 2, 4, 200, 650 } } 该算法应返回一个结果数组： { 0, 1, 2, 4, 5, 6, 10, 100, 200, 650 } 3. Java实现 现在我们对什么是最小堆以及合并算法的工作原理有了基本的了解，让我们看一下 Java 实现。我们将使用两个类——一个代表堆节点，另一个实现合并算法。 3.1 堆节点表示 在实现算法本身之前，让我们创建一个表示堆节点的类。这将存储节点值和两个支持字段： public class HeapNode { int element; int arrayIndex; int nextElementIndex = 1; public HeapNode(int element, int arrayIndex) { this.element = element; this.arrayIndex = arrayIndex; } } 请注意，为了简单起见，我们故意省略了getter和setter。我们将使用arrayIndex属性来存储当前堆节点元素所在的数组的索引。我们将使用nextElementIndex属性来存储在将根节点移动到结果数组后我们将采用的元素的索引。 最初，nextElementIndex的值为1。我们将在替换最小堆的根节点后增加它的值。 3.2. 最小堆合并算法 我们的下一个类是表示最小堆本身并实现合并算法： public class MinHeap { HeapNode[] heapNodes; public MinHeap(HeapNode heapNodes[]) { this.heapNodes = heapNodes; heapifyFromLastLeafsParent(); } int getParentNodeIndex(int index) { return (index - 1) / 2; } int getLeftNodeIndex(int index) { return (2 * index + 1); } int getRightNodeIndex(int index) { return (2 * index + 2); } HeapNode getRootNode() { return heapNodes[0]; } // additional implementation methods } 现在我们已经创建了最小堆类，让我们添加一个方法来堆化子树，其中子树的根节点位于数组的给定索引处： void heapify(int index) { int leftNodeIndex = getLeftNodeIndex(index); int rightNodeIndex = getRightNodeIndex(index); int smallestElementIndex = index; if (leftNodeIndex \u0026lt; heapNodes.length \u0026amp;\u0026amp; heapNodes[leftNodeIndex].element \u0026lt; heapNodes[index].element) { smallestElementIndex = leftNodeIndex; } if (rightNodeIndex \u0026lt; heapNodes.length \u0026amp;\u0026amp; heapNodes[rightNodeIndex].element \u0026lt; heapNodes[smallestElementIndex].element) { smallestElementIndex = rightNodeIndex; } if (smallestElementIndex != index) { swap(index, smallestElementIndex); heapify(smallestElementIndex); } } 当我们使用数组来表示最小堆时，最后一个叶子节点将始终位于数组的末尾。所以当通过迭代调用*heapify()*方法将数组转换为最小堆时，我们只需要从最后一个叶子的父节点开始迭代： void heapifyFromLastLeafsParent() { int lastLeafsParentIndex = getParentNodeIndex(heapNodes.length); while (lastLeafsParentIndex \u0026gt;= 0) { heapify(lastLeafsParentIndex); lastLeafsParentIndex--; } } 我们的下一个方法将实际实现我们的算法。为了更好地理解，让我们将方法分成两部分，看看它是如何工作的： int[] merge(int[][] array) { // transform input arrays  // run the minheap algorithm  // return the resulting array } 第一部分将输入数组转换为一个堆节点数组，其中包含第一个数组的所有元素并找到结果数组的大小： HeapNode[] heapNodes = new HeapNode[array.length]; int resultingArraySize = 0; for (int i = 0; i \u0026lt; array.length; i++) { HeapNode node = new HeapNode(array[i][0], i); heapNodes[i] = node; resultingArraySize += array[i].length; } 下一部分通过实现我们算法的步骤 4、5、6 和 7 来填充结果数组： MinHeap minHeap = new MinHeap(heapNodes); int[] resultingArray = new int[resultingArraySize]; for (int i = 0; i \u0026lt; resultingArraySize; i++) { HeapNode root = minHeap.getRootNode(); resultingArray[i] = root.element; if (root.nextElementIndex \u0026lt; array[root.arrayIndex].length) { root.element = array[root.arrayIndex][root.nextElementIndex++]; } else { root.element = Integer.MAX_VALUE; } minHeap.heapify(0); } 4. 测试算法 现在让我们使用之前提到的相同输入来测试我们的算法： int[][] inputArray = { { 0, 6 }, { 1, 5, 10, 100 }, { 2, 4, 200, 650 } }; int[] expectedArray = { 0, 1, 2, 4, 5, 6, 10, 100, 200, 650 }; int[] resultArray = MinHeap.merge(inputArray); assertThat(resultArray.length, is(equalTo(10))); assertThat(resultArray, is(equalTo(expectedArray))); \u0026quot; ","permalink":"http://itcodingman.github.io/java_merge_sorted_sequences/","tags":[],"title":"高效合并已排序的 Java 序列"},{"categories":["Java","BiliBili"],"contents":"Eclipse和Java的安装 Eclipse和Java的安装 \r","permalink":"http://itcodingman.github.io/eclipse_java_install_introduce/","tags":[],"title":"Eclipse和Java的安装"},{"categories":["Algorithms","Java"],"contents":"1. 简介 在本教程中，我们将了解合并排序算法及其在 Java 中的实现。 归并排序是最有效的排序技术之一，它基于“分而治之”范式。 2. 算法 **合并排序是一种“分而治之”的算法，我们首先将问题划分为子问题。**当子问题的解决方案准备就绪时，我们将它们组合在一起以获得问题的最终解决方案。 我们可以使用递归轻松实现该算法，因为我们处理的是子问题而不是主要问题。 我们可以将算法描述为以下两步过程：  除法：在这一步中，我们将输入数组分成两半，枢轴是数组的中点。对所有半数组递归执行此步骤，直到没有更多半数组要划分。 征服：在这一步中，我们从下到上对分割后的数组进行排序合并，得到排序后的数组。  下图显示了示例数组 {10, 6, 8, 5, 7, 3, 4} 的完整归并排序过程。 如果我们仔细看这个图，我们可以看到数组被递归地分成两半，直到大小变为 1。一旦大小变为 1，合并过程开始起作用，并在排序时开始合并数组： 3. 实施 对于实现，我们将编写一个合并排序函数，该函数将输入数组及其长度作为参数。这将是一个递归函数，因此我们需要基础和递归条件。 基本条件检查数组长度是否为 1，它只会返回。对于其余情况，将执行递归调用。 **对于递归情况，我们获取中间索引并创建两个临时数组l[]和r[]。**然后我们对两个子数组递归调用mergeSort函数： public static void mergeSort(int[] a, int n) { if (n \u0026lt; 2) { return; } int mid = n / 2; int[] l = new int[mid]; int[] r = new int[n - mid]; for (int i = 0; i \u0026lt; mid; i++) { l[i] = a[i]; } for (int i = mid; i \u0026lt; n; i++) { r[i - mid] = a[i]; } mergeSort(l, mid); mergeSort(r, n - mid); merge(a, l, r, mid, n - mid); } 接下来，我们调用合并函数，它接受输入和两个子数组，以及两个子数组的开始和结束索引。 合并函数将两个子数组的元素一一比较，并将较小的元素放入输入数组中。 当我们到达一个子数组的末尾时，另一个数组中的其余元素被复制到输入数组中，从而为我们提供了最终的排序数组： public static void merge( int[] a, int[] l, int[] r, int left, int right) { int i = 0, j = 0, k = 0; while (i \u0026lt; left \u0026amp;\u0026amp; j \u0026lt; right) { if (l[i] \u0026lt;= r[j]) { a[k++] = l[i++]; } else { a[k++] = r[j++]; } } while (i \u0026lt; left) { a[k++] = l[i++]; } while (j \u0026lt; right) { a[k++] = r[j++]; } } 该程序的单元测试是： @Test public void positiveTest() { int[] actual = { 5, 1, 6, 2, 3, 4 }; int[] expected = { 1, 2, 3, 4, 5, 6 }; MergeSort.mergeSort(actual, actual.length); assertArrayEquals(expected, actual); } 4. 复杂性 由于归并排序是一种递归算法，时间复杂度可以表示为以下递归关系： T(n) = 2T(n/2) + O(n) *2T(n/2)*对应的是对子数组进行排序所需的时间，*O(n)*是合并整个数组的时间。 解决后，时间复杂度将达到O(nLogn)。 这适用于最坏、平均和最好的情况，因为它总是将数组分成两部分然后合并。 该算法的空间复杂度为*O(n)，*因为我们在每个递归调用中创建临时数组。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_merge_sort/","tags":[],"title":"Java中的合并排序"},{"categories":["Java","Java Collections"],"contents":"1. 简介 在本快速教程中，我们将演示如何使用 Java 8 功能合并两个地图。 更具体地说，我们将检查不同的合并场景，包括具有重复条目的地图。 2. 初始化 首先，让我们定义两个Map实例： private static Map\u0026lt;String, Employee\u0026gt; map1 = new HashMap\u0026lt;\u0026gt;(); private static Map\u0026lt;String, Employee\u0026gt; map2 = new HashMap\u0026lt;\u0026gt;(); Employee类如下所示： public class Employee { private Long id; private String name; // constructor, getters, setters } 然后，我们可以将一些数据推送到Map实例中： Employee employee1 = new Employee(1L, \u0026#34;Henry\u0026#34;); map1.put(employee1.getName(), employee1); Employee employee2 = new Employee(22L, \u0026#34;Annie\u0026#34;); map1.put(employee2.getName(), employee2); Employee employee3 = new Employee(8L, \u0026#34;John\u0026#34;); map1.put(employee3.getName(), employee3); Employee employee4 = new Employee(2L, \u0026#34;George\u0026#34;); map2.put(employee4.getName(), employee4); Employee employee5 = new Employee(3L, \u0026#34;Henry\u0026#34;); map2.put(employee5.getName(), employee5); 请注意，我们的映射中的 employee1和employee5条目具有相同的键，稍后我们将使用它们。 3. Map.merge() *Java 8在java.util.Map接口中添加了一个新的*merge()函数。 下面是*merge()*函数的工作原理：如果指定的键尚未与值关联或值为空，则它将键与给定值关联。 否则，它将用给定重映射函数的结果替换该值。如果重映射函数的结果为空，则删除结果。 首先，让我们通过复制map1中的所有条目来构造一个新的HashMap： Map\u0026lt;String, Employee\u0026gt; map3 = new HashMap\u0026lt;\u0026gt;(map1); 接下来介绍*merge()*函数和合并规则： map3.merge(key, value, (v1, v2) -\u0026gt; new Employee(v1.getId(),v2.getName()) 最后，我们将遍历map2并将条目合并到map3 中： map2.forEach( (key, value) -\u0026gt; map3.merge(key, value, (v1, v2) -\u0026gt; new Employee(v1.getId(),v2.getName()))); 让我们运行程序并打印map3的内容： John=Employee{id=8, name=\u0026#39;John\u0026#39;} Annie=Employee{id=22, name=\u0026#39;Annie\u0026#39;} George=Employee{id=2, name=\u0026#39;George\u0026#39;} Henry=Employee{id=1, name=\u0026#39;Henry\u0026#39;} 结果，我们的组合Map具有之前HashMap条目的所有元素。具有重复键的条目已合并为一个条目。 此外，我们注意到最后一个条目 的Employee对象具有来自map1的id，而 value 是从map2中选取的。 这是因为我们在合并函数中定义的规则： (v1, v2) -\u0026gt; new Employee(v1.getId(), v2.getName()) 4. Stream.concat() Java 8 中的Stream API 也可以为我们的问题提供简单的解决方案。首先，我们需要将我们的Map实例合并到一个Stream中。这正是Stream.concat() 操作所做的： Stream combined = Stream.concat(map1.entrySet().stream(), map2.entrySet().stream()); 在这里，我们将映射条目集作为参数传递。接下来，我们需要将结果收集到一个新的Map中。为此，我们可以使用Collectors.toMap()： Map\u0026lt;String, Employee\u0026gt; result = combined.collect( Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue)); 因此，收集器将使用我们地图的现有键和值。但这个解决方案远非完美。一旦我们的收集器遇到具有重复键的条目，它就会抛出 IllegalStateException。 为了解决这个问题，我们只需在收集器中添加第三个“合并”lambda 参数： (value1, value2) -\u0026gt; new Employee(value2.getId(), value1.getName()) 每次检测到重复键时，它将使用 lambda 表达式。 最后，将所有内容放在一起： Map\u0026lt;String, Employee\u0026gt; result = Stream.concat(map1.entrySet().stream(), map2.entrySet().stream()) .collect(Collectors.toMap( Map.Entry::getKey, Map.Entry::getValue, (value1, value2) -\u0026gt; new Employee(value2.getId(), value1.getName()))); 最后，让我们运行一下代码，看看结果： George=Employee{id=2, name=\u0026#39;George\u0026#39;} John=Employee{id=8, name=\u0026#39;John\u0026#39;} Annie=Employee{id=22, name=\u0026#39;Annie\u0026#39;} Henry=Employee{id=3, name=\u0026#39;Henry\u0026#39;} 正如我们所见，键为*“Henry”的重复条目被合并到一个新的键值对中，其中新员工*的 id是从map2中挑选出来的，而 value 是从map1中挑选出来的。 5. Stream.of() 要继续使用Stream API，我们可以借助Stream.of()将我们的Map实例变成一个统一的流。 在这里，我们不必创建额外的集合来处理流： Map\u0026lt;String, Employee\u0026gt; map3 = Stream.of(map1, map2) .flatMap(map -\u0026gt; map.entrySet().stream()) .collect(Collectors.toMap( Map.Entry::getKey, Map.Entry::getValue, (v1, v2) -\u0026gt; new Employee(v1.getId(), v2.getName()))); 首先，我们将map1和map2转换为单个流。接下来，我们将流转换为地图。正如我们所见，toMap()的最后一个参数是一个合并函数。它通过从v1条目中选择 id 字段和从v2中选择名称来解决重复键问题。 运行程序后打印出来的map3实例： George=Employee{id=2, name=\u0026#39;George\u0026#39;} John=Employee{id=8, name=\u0026#39;John\u0026#39;} Annie=Employee{id=22, name=\u0026#39;Annie\u0026#39;} Henry=Employee{id=1, name=\u0026#39;Henry\u0026#39;} 6. 简单的流媒体 此外，我们可以使用stream()管道来组装我们的地图条目。下面的代码片段演示了如何通过忽略重复条目来添加来自map2和 map1的条目： Map\u0026lt;String, Employee\u0026gt; map3 = map2.entrySet() .stream() .collect(Collectors.toMap( Map.Entry::getKey, Map.Entry::getValue, (v1, v2) -\u0026gt; new Employee(v1.getId(), v2.getName()), () -\u0026gt; new HashMap\u0026lt;\u0026gt;(map1))); 正如我们所料，合并后的结果是： {John=Employee{id=8, name=\u0026#39;John\u0026#39;}, Annie=Employee{id=22, name=\u0026#39;Annie\u0026#39;}, George=Employee{id=2, name=\u0026#39;George\u0026#39;}, Henry=Employee{id=1, name=\u0026#39;Henry\u0026#39;}} 7. StreamEx 除了 JDK 提供的解决方案之外，我们还可以使用流行的 StreamEx库。 简单地说，StreamEx 是对Stream API的增强，并提供了许多额外的有用方法。我们将使用一个 EntryStream 实例来操作键值对： Map\u0026lt;String, Employee\u0026gt; map3 = EntryStream.of(map1) .append(EntryStream.of(map2)) .toMap((e1, e2) -\u0026gt; e1); 这个想法是将我们的地图流合并为一个。然后我们将条目收集到新的map3实例中。值得一提的是*(e1, e2) -\u0026gt; e1表达式，因为它有助于定义处理重复键的规则。没有它，我们的代码将抛出IllegalStateException*。 现在，结果： {George=Employee{id=2, name=\u0026#39;George\u0026#39;}, John=Employee{id=8, name=\u0026#39;John\u0026#39;}, Annie=Employee{id=22, name=\u0026#39;Annie\u0026#39;}, Henry=Employee{id=1, name=\u0026#39;Henry\u0026#39;}} \u0026quot; ","permalink":"http://itcodingman.github.io/java_merge_maps/","tags":["Java 8","Java Map"],"title":"使用 Java 8 合并两个地图"},{"categories":["Java","Youtube"],"contents":"30分钟学习MyBatis通用CRUD Mapper   ","permalink":"http://itcodingman.github.io/30_mins_mybatis_generic_mapper/","tags":[],"title":"30分钟学习MyBatis通用CRUD Mapper"},{"categories":["Java"],"contents":"1. 简介 Java 的核心优势之一是借助内置垃圾收集器（或简称GC）的自动内存管理。GC 隐式地负责分配和释放内存，因此能够处理大多数内存泄漏问题。 虽然 GC 有效地处理了很大一部分内存，但它并不能保证为内存泄漏提供一个万无一失的解决方案。GC 非常聪明，但并非完美无缺。即使在尽职尽责的开发人员的应用程序中，内存泄漏仍然可以偷偷摸摸。 仍然可能存在应用程序生成大量多余对象的情况，从而耗尽关键内存资源，有时会导致整个应用程序失败。 内存泄漏是 Java 中的一个真正问题。在本教程中，我们将了解内存泄漏的潜在原因是什么，如何在运行时识别它们，以及如何在我们的应用程序中处理它们。 2. 什么是内存泄漏 内存泄漏是一种情况**，即堆中存在不再使用的对象，但垃圾收集器无法将它们从内存中删除**，因此它们被不必要地维护。 内存泄漏很糟糕，因为它会阻塞内存资源并随着时间的推移降低系统性能。如果不处理，应用程序最终将耗尽其资源，最终以致命的java.lang.OutOfMemoryError终止。 有两种不同类型的对象驻留在堆内存中——引用的和未引用的。引用对象是那些在应用程序中仍然具有活动引用的对象，而未引用对象没有任何活动引用。 **垃圾收集器定期删除未引用的对象，但它从不收集仍被引用的对象。**这是可能发生内存泄漏的地方： 内存泄漏的症状  应用程序长时间连续运行时性能严重下降 应用程序中的OutOfMemoryError堆错误 自发和奇怪的应用程序崩溃 应用程序偶尔会用完连接对象  让我们仔细看看其中一些场景以及如何处理它们。 3. Java 中的内存泄漏类型 在任何应用程序中，都可能由于多种原因发生内存泄漏。在本节中，我们将讨论最常见的。 3.1 通过静态字段的内存泄漏 可能导致潜在内存泄漏的第一种情况是大量使用静态变量。 在 Java 中，静态字段的生命周期通常与正在运行的应用程序的整个生命周期相匹配（除非ClassLoader符合垃圾回收条件）。 让我们创建一个填充静态 列表的简单 Java 程序 ： public class StaticTest { public static List\u0026lt;Double\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public void populateList() { for (int i = 0; i \u0026lt; 10000000; i++) { list.add(Math.random()); } Log.info(\u0026#34;Debug Point 2\u0026#34;); } public static void main(String[] args) { Log.info(\u0026#34;Debug Point 1\u0026#34;); new StaticTest().populateList(); Log.info(\u0026#34;Debug Point 3\u0026#34;); } } 现在，如果我们在程序执行期间分析堆内存，那么我们将看到在调试点 1 和 2 之间，正如预期的那样，堆内存增加了。 但是当我们在调试点 3离开 *populateList()*方法时，堆内存还没有被垃圾回收，正如我们在这个 VisualVM 响应中看到的那样： 但是，在上面的程序中，在第 2 行中，如果我们只是去掉关键字 static，那么它将给内存使用带来巨大的变化，这个 Visual VM 响应显示： 直到调试点的第一部分与我们在*静态情况下获得的几乎相同。*但是这次我们离开 populateList() 方法后，列表的所有内存都被垃圾回收了，因为我们没有对它的任何引用。 因此，我们需要非常注意静态变量的使用。如果集合或大对象被声明为static，那么它们在应用程序的整个生命周期中都保留在内存中，从而阻塞了原本可以在其他地方使用的重要内存。 如何预防？  尽量减少静态变量的使用 使用单例时，依赖于延迟加载对象而不是急切加载的实现  3.2. 通过未封闭的资源 每当我们建立新连接或打开流时，JVM 都会为这些资源分配内存。一些示例包括数据库连接、输入流和会话对象。 忘记关闭这些资源会阻塞内存，从而使它们远离 GC。这甚至可能发生在阻止程序执行到达处理代码以关闭这些资源的语句的异常的情况下。 在任何一种情况下，资源留下的开放连接都会消耗内存，如果我们不处理它们，它们会降低性能，甚至可能导致OutOfMemoryError。 如何预防？  总是使用finally块来关闭资源 关闭资源的代码（即使在 finally块中）本身不应有任何异常 使用 Java 7+ 时，我们可以使用try -with-resources 块  *3.3. 不正确的*equals()和hashCode()实现 *在定义新类时，一个非常常见的疏忽是没有为equals()和hashCode()*方法编写适当的重写方法。 HashSet 和 HashMap 在许多操作中使用这些方法，如果它们没有被正确覆盖，那么它们可能成为潜在内存泄漏问题的根源。 让我们以一个普通的 Person 类为例，并将其用作 HashMap中的键： public class Person { public String name; public Person(String name) { this.name = name; } } 现在我们将重复的Person对象插入到使用该键的Map中。 请记住，一个Map不能包含重复的键： @Test public void givenMap_whenEqualsAndHashCodeNotOverridden_thenMemoryLeak() { Map\u0026lt;Person, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for(int i=0; i\u0026lt;100; i++) { map.put(new Person(\u0026#34;jon\u0026#34;), 1); } Assert.assertFalse(map.size() == 1); } 这里我们使用Person作为键。由于Map不允许重复键，我们作为键插入的大量重复的Person对象不应该增加内存。 但是*由于我们没有定义正确的*equals()方法，重复的对象会堆积起来并增加内存，这就是为什么我们在内存中看到多个对象的原因。VisualVM 中的堆内存如下所示： 但是，*如果我们正确地覆盖了equals() 和*hashCode()方法，那么这个Map中将只存在一个Person对象。 让我们看一下 Person 类的*equals()和hashCode()*的正确实现： public class Person { public String name; public Person(String name) { this.name = name; } @Override public boolean equals(Object o) { if (o == this) return true; if (!(o instanceof Person)) { return false; } Person person = (Person) o; return person.name.equals(name); } @Override public int hashCode() { int result = 17; result = 31 * result + name.hashCode(); return result; } } 在这种情况下，以下断言将是正确的： @Test public void givenMap_whenEqualsAndHashCodeNotOverridden_thenMemoryLeak() { Map\u0026lt;Person, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for(int i=0; i\u0026lt;2; i++) { map.put(new Person(\u0026#34;jon\u0026#34;), 1); } Assert.assertTrue(map.size() == 1); } 正确覆盖*equals()和hashCode()*后，同一程序的堆内存如下所示： 另一个例子是使用像 Hibernate 这样的 ORM 工具，它使用equals() 和*hashCode()*方法来分析对象并将它们保存在缓存中。 **如果这些方法没有被覆盖，内存泄漏的可能性非常高，**因为 Hibernate 将无法比较对象并且会用重复的对象填充其缓存。 如何预防？  根据经验，在定义新实体时，始终覆盖*equals()和hashCode()*方法 覆盖不仅足够，还必须以最佳方式覆盖这些方法  有关更多信息，请访问我们的教程 使用 Eclipse生成equals()和hashCode()和 Java中的hashCode()指南。 3.4. 引用外部类的内部类 这发生在非静态内部类（匿名类）的情况下。对于初始化，这些内部类总是需要一个封闭类的实例。 默认情况下，每个非静态内部类都有对其包含类的隐式引用。如果我们在应用程序中使用这个内部类的对象，那么即使我们的包含类的对象超出范围，它也不会被垃圾回收。 考虑一个持有对大量庞大对象的引用并具有非静态内部类的类。现在，当我们创建一个仅包含内部类的对象时，内存模型如下所示： 但是，如果我们只是将内部类声明为静态，那么相同的内存模型如下所示： 发生这种情况是因为内部类对象隐含地持有对外部类对象的引用，从而使其成为垃圾回收的无效候选对象。同样的情况也发生在匿名类的情况下。 如何预防？  如果内部类不需要访问包含的类成员，请考虑将其转换为静态类  *3.5. 通过*finalize()方法 使用终结器是潜在内存泄漏问题的另一个来源。每当一个类的 *finalize()*方法被覆盖**时，该类的对象不会立即被垃圾回收。**相反，GC 将它们排队等待最终确定，这将在稍后的时间点发生。 *此外，如果finalize()*方法中编写的代码不是最优的，并且如果 finalizer 队列无法跟上 Java 垃圾收集器的速度，那么我们的应用程序迟早会遇到 OutOfMemoryError。 为了证明这一点，让我们假设我们有一个覆盖了 *finalize()*方法的类，并且该方法需要一些时间来执行。当该类的大量对象被垃圾回收时，在 VisualVM 中，它看起来像： 但是，如果我们只是删除覆盖的*finalize()*方法，那么同一个程序会给出以下响应： 如何预防？  我们应该始终避免使用终结器  有关*finalize()*的更多详细信息，请阅读我们的 Java 中的 finalize 方法指南中的第 3 节（避免终结器）。 3.6. Interned 字符串 Java字符串池在从 PermGen 转移到 HeapSpace 时在 Java 7 中发生了重大变化。但是对于在 6 及以下版本上运行的应用程序，我们在处理大字符串时应该更加注意。 **如果我们读取一个巨大的String对象，并在该对象上调用intern()，那么它会进入位于 PermGen（永久内存）中的字符串池，并且只要我们的应用程序运行，它就会一直留在那里。**这会阻塞内存并在我们的应用程序中造成严重的内存泄漏。 JVM 1.6 中这种情况的 PermGen 在 VisualVM 中如下所示： 与此相反，在一个方法中，如果我们只是从文件中读取一个字符串并且不对其进行实习，那么 PermGen 看起来像： 如何预防？  解决此问题的最简单方法是升级到最新的 Java 版本，因为字符串池从 Java 版本 7 开始移至 HeapSpace 如果处理大型Strings，请增加 PermGen 空间的大小以避免任何潜在的OutOfMemoryErrors：  -XX:MaxPermSize=512m 3.7. 使用ThreadLocal ThreadLocal （在 Java教程中的ThreadLocal简介 中有详细讨论 ）是一种构造，它使我们能够将状态隔离到特定线程，从而使我们能够实现线程安全。 使用此构造时， 每个线程都将持有对其ThreadLocal变量副本的隐式引用，并将维护自己的副本，而不是在多个线程之间共享资源，只要线程处于活动状态。 尽管有其优势，但ThreadLocal 变量的使用仍存在争议，因为如果使用不当，它们会因引入内存泄漏而臭名昭著。Joshua Bloch 曾经评论过线程本地使用：  “正如在许多地方所指出的那样，随意使用线程池和随意使用线程局部变量可能会导致意外的对象保留。但是把责任归咎于线程本地人是没有根据的。”  ThreadLocals的内存泄漏 一旦持有线程不再活动，应该对ThreadLocals进行垃圾收集。但是当ThreadLocals与现代应用程序服务器一起使用时，问题就出现了。 现代应用程序服务器使用线程池来处理请求，而不是创建新请求（例如 Apache Tomcat 中的Executor）。此外，它们还使用单独的类加载器。 由于应用服务器中的线程池 基于线程重用的概念，它们永远不会被垃圾收集——相反，它们被重用于服务另一个请求。 现在，如果任何类创建了 ThreadLocal变量但没有显式删除它，那么即使在 Web 应用程序停止后，该对象的副本仍将保留在工作线程中，从而防止对象被垃圾收集。 如何预防？  当不再使用 ThreadLocals时，清理它们是一个好习惯*——ThreadLocals*提供了 remove()方法，该方法删除了当前线程对该变量的值 **不要使用 ThreadLocal.set(null)清除值 ——它实际上并没有清除值，而是会查找与当前线程关联的Map并将键值对分别设置为当前线程和null 最好将 ThreadLocal视为需要在 finally块中关闭的资源，以确保它始终处于关闭状态，即使在出现异常的情况下也是如此：  try { threadLocal.set(System.nanoTime()); //... further processing } finally { threadLocal.remove(); } 4. 处理内存泄漏的其他策略 尽管在处理内存泄漏时没有万能的解决方案，但我们可以通过一些方法来最小化这些泄漏。 4.1 启用分析 Java 分析器是通过应用程序监视和诊断内存泄漏的工具。他们分析我们应用程序内部发生的事情——例如，内存是如何分配的。 使用分析器，我们可以比较不同的方法并找到可以最佳利用资源的领域。 我们在本教程的第 3 节中使用了Java VisualVM 。请查看我们的 Java Profiler 指南 以了解不同类型的分析器，例如 Mission Control、JProfiler、YourKit、Java VisualVM 和 Netbeans Profiler。 4.2. 详细垃圾收集 通过启用详细垃圾收集，我们可以跟踪 GC 的详细跟踪。要启用此功能，我们需要将以下内容添加到我们的 JVM 配置中： -verbose:gc 通过添加这个参数，我们可以看到 GC 内部发生的细节： 4.3. 使用引用对象避免内存泄漏 我们还可以借助java.lang.ref包中内置的 Java 中的引用对象来处理内存泄漏。使用java.lang.ref包，我们不是直接引用对象，而是使用对对象的特殊引用，以便轻松地对它们进行垃圾收集。 引用队列旨在让我们了解垃圾收集器执行的操作。有关更多信息，请阅读 Java 教程中的软引用，特别是第 4 节。 4.4. Eclipse 内存泄漏警告 对于 JDK 1.5 及更高版本的项目，Eclipse 在遇到明显的内存泄漏情况时会显示警告和错误。所以在Eclipse中开发时，我们可以定期访问“Problems”选项卡，更加警惕内存泄漏警告（如果有的话）： 4.5. 基准测试 我们可以通过执行基准测试来衡量和分析 Java 代码的性能。这样，我们可以比较执行相同任务的替代方法的性能。这可以帮助我们选择更好的方法，并可以帮助我们节省内存。 有关基准测试的更多信息，请访问我们的 使用 Java进行微基准测试 教程。 4.6. 代码审查 最后，我们总是有经典的、老式的方式来进行简单的代码演练。 在某些情况下，即使是这种看似微不足道的方法也有助于消除一些常见的内存泄漏问题。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_memory_leaks/","tags":[],"title":"了解 Java 中的内存泄漏"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将了解 JVM 如何在堆中布置对象和数组。 首先，我们将从一些理论开始。然后，我们将探索不同情况下的不同对象和数组内存布局。 通常，运行时数据区域的内存布局不是 JVM 规范的一部分，由实现者自行决定。因此，每个 JVM 实现可能有不同的策略来在内存中布局对象和数组。在本教程中，我们将重点关注一种特定的 JVM 实现：HotSpot JVM。 我们也可以互换使用 JVM 和 HotSpot JVM 术语。 2. 普通对象指针（OOP） HotSpot JVM 使用一种称为普通对象指针 ( OOPS ) 的数据结构来表示指向对象的指针。 JVM 中的所有指针（对象和数组）都基于称为 *oopDesc*的特殊数据结构。每个 oopDesc使用以下信息描述指针：  一记字 一个可能是压缩的 类词  标记词描述对象头。HotSpot JVM 使用这个词来存储身份哈希码、偏向锁定模式、锁定信息和 GC 元数据。 此外，标记字状态仅包含一个 *uintptr_t，*因此，它的大小在 32 位和 64 位架构中分别在 4 和 8 个字节之间变化。 此外，有偏见的对象和正常对象的标记词是不同的。但是，我们只会考虑普通对象，因为 Java 15 将弃用偏向锁定。 此外，klass 词封装了语言级别的类信息，例如类名、其修饰符、超类信息等。 对于 Java 中的普通对象，表示为*instanceOop*，对象标头由 mark 和 klass 词以及可能的对齐填充组成。在对象头之后，可能有零个或多个对实例字段的引用。因此，在 64 位架构中，这至少是 16 个字节，因为 8 个字节的标记、4 个字节的 klass 和另外 4 个字节用于填充。 对于表示为 arrayOop*的数组，***对象头包含一个 4 字节的数组长度以及标记、klass 和填充。**同样，由于标记的 8 个字节、klass 的 4 个字节和数组长度的另外 4 个字节，这将至少是 16 个字节。 现在我们对理论有了足够的了解，让我们看看内存布局在实践中是如何工作的。 3. 设置 JOL 为了检查 JVM 中对象的内存布局，我们将广泛使用 Java 对象布局 ( JOL )。因此，我们需要添加jol-core 依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jol\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jol-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.10\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. 内存布局示例 让我们从查看一般 VM 详细信息开始： System.out.println(VM.current().details()); 这将打印： # Running 64-bit HotSpot VM. # Objects are 8 bytes aligned. # Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes] # Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes] 这意味着引用占用 4 个字节， boolean和 byte占用 1 个字节， short和 char占用 2 个字节，int和 float占用 4 个字节，最后，long和 double占用 8 个字节。有趣的是，如果我们将它们用作数组元素，它们会消耗相同数量的内存。 此外，如果我们通过 -XX:-UseCompressedOops 禁用压缩引用，则只有引用大小变为 8 个字节： # Field sizes by type: 8, 1, 1, 2, 2, 4, 4, 8, 8 [bytes] # Array element sizes: 8, 1, 1, 2, 2, 4, 4, 8, 8 [bytes] 4.1 基本的 让我们考虑一个SimpleInt类： public class SimpleInt { private int state; } 如果我们打印它的类布局： System.out.println(ClassLayout.parseClass(SimpleInt.class).toPrintable()); 我们会看到类似的东西： SimpleInt object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 int SimpleInt.state N/A Instance size: 16 bytes Space losses: 0 bytes internal + 0 bytes external = 0 bytes total 如上图，对象头为12个字节，包括8个字节的mark和4个字节的klass。之后，我们有 4 个字节用于int state。总的来说，此类中的任何对象将消耗 16 个字节。 此外，对象头和状态没有值，因为我们正在解析类布局，而不是实例布局。 4.2. 身份哈希码 *hashCode()*是所有 Java 对象的常用方法之一。 **当我们没有为一个类声明 *hashCode()***方法时，Java 将使用它的身份哈希码。 对象的身份哈希码在其生命周期内不会更改。因此，HotSpot JVM 在计算后将该值存储在标记字中。 让我们看看对象实例的内存布局： SimpleInt instance = new SimpleInt(); System.out.println(ClassLayout.parseInstance(instance).toPrintable()); HotSpot JVM 懒惰地计算身份哈希码： SimpleInt object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) # mark 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) # mark 8 4 (object header) 9b 1b 01 f8 (10011011 00011011 00000001 11111000) (-134145125) # klass 12 4 int SimpleInt.state 0 Instance size: 16 bytes Space losses: 0 bytes internal + 0 bytes external = 0 bytes total 如上所示，标记词目前似乎还没有存储任何重要的东西。 但是，如果我们 在对象实例上调用*System.identityHashCode()*甚至 Object.hashCode() ，这将改变： System.out.println(\u0026#34;The identity hash code is \u0026#34; + System.identityHashCode(instance)); System.out.println(ClassLayout.parseInstance(instance).toPrintable()); 现在，我们可以将身份哈希码作为标记词的一部分： The identity hash code is 1702146597 SimpleInt object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 25 b2 74 (00000001 00100101 10110010 01110100) (1957831937) 4 4 (object header) 65 00 00 00 (01100101 00000000 00000000 00000000) (101) 8 4 (object header) 9b 1b 01 f8 (10011011 00011011 00000001 11111000) (-134145125) 12 4 int SimpleInt.state 0 HotSpot JVM 将标识哈希码作为“25 b2 74 65”存储在标记字中。最重要的字节是 65，因为 JVM 以 little-endian 格式存储该值。因此，要恢复十进制的哈希码值（1702146597），我们必须以相反的顺序读取“25 b2 74 65”字节序列： 65 74 b2 25 = 01100101 01110100 10110010 00100101 = 1702146597 4.3. 结盟 默认情况下，JVM 会为对象添加足够的填充以使其大小成为 8 的倍数。 例如，考虑SimpleLong类： public class SimpleLong { private long state; } 如果我们解析类布局： System.out.println(ClassLayout.parseClass(SimpleLong.class).toPrintable()); 然后 JOL 将打印内存布局： SimpleLong object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 (alignment/padding gap) 16 8 long SimpleLong.state N/A Instance size: 24 bytes Space losses: 4 bytes internal + 0 bytes external = 4 bytes total 如上图，object header和 long state一共消耗了20个字节。为了使这个大小成为 8 字节的倍数，JVM 添加了 4 字节的填充。 **我们还可以通过 -XX:ObjectAlignmentInBytes调整标志更改默认对齐大小。**例如，对于同一个类，具有 -XX:ObjectAlignmentInBytes=16的内存布局将是： SimpleLong object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 (alignment/padding gap) 16 8 long SimpleLong.state N/A 24 8 (loss due to the next object alignment) Instance size: 32 bytes Space losses: 4 bytes internal + 8 bytes external = 12 bytes total 对象头和 long变量仍然总共消耗 20 个字节。所以，我们应该再增加 12 个字节，使其成为 16 的倍数。 如上所示，它添加了 4 个内部填充字节以在偏移量 16 处开始 long变量（启用更多对齐的访问）。然后它将剩余的 8 个字节添加到 long变量之后。 4.4. 现场包装 **当一个类有多个字段时，JVM 可能会以最小化填充浪费的方式分配这些字段。**例如，考虑FieldsArrangement类： public class FieldsArrangement { private boolean first; private char second; private double third; private int fourth; private boolean fifth; } 字段声明顺序和它们在内存布局中的顺序不同： OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 int FieldsArrangement.fourth N/A 16 8 double FieldsArrangement.third N/A 24 2 char FieldsArrangement.second N/A 26 1 boolean FieldsArrangement.first N/A 27 1 boolean FieldsArrangement.fifth N/A 28 4 (loss due to the next object alignment) 这背后的主要动机是尽量减少填充浪费。 4.5. 锁定 JVM 还在标记字内维护锁定信息。让我们看看它的实际效果： public class Lock {} 如果我们创建这个类的一个实例，它 的内存布局将是： Lock object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 4 4 (object header) 00 00 00 00 8 4 (object header) 85 23 02 f8 12 4 (loss due to the next object alignment) Instance size: 16 bytes 但是，如果我们在此实例上进行同步： synchronized (lock) { System.out.println(ClassLayout.parseInstance(lock).toPrintable()); } 内存布局更改为： Lock object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) f0 78 12 03 4 4 (object header) 00 70 00 00 8 4 (object header) 85 23 02 f8 12 4 (loss due to the next object alignment) 如上所示，当我们持有监视器锁时，标记字的位模式会发生变化。 4.6. 年代和任期 **为了将一个对象提升到老年代（当然是在分代GC中），JVM 需要跟踪每个对象的存活数。**如前所述，JVM 也在标记词中维护了这些信息。 为了模拟次要 GC，我们将通过将对象分配给 volatile变量来创建大量垃圾。通过这种方式，我们可以防止JIT 编译器消除可能的死代码： volatile Object consumer; Object instance = new Object(); long lastAddr = VM.current().addressOf(instance); ClassLayout layout = ClassLayout.parseInstance(instance); for (int i = 0; i \u0026lt; 10_000; i++) { long currentAddr = VM.current().addressOf(instance); if (currentAddr != lastAddr) { System.out.println(layout.toPrintable()); } for (int j = 0; j \u0026lt; 10_000; j++) { consumer = new Object(); } lastAddr = currentAddr; } **每次活动对象的地址发生变化时，这可能是因为次要 GC 和幸存者空间之间的移动。**对于每次更改，我们还打印新对象布局以查看老化对象。 以下是标记字的前 4 个字节随时间变化的方式： 09 00 00 00 (00001001 00000000 00000000 00000000) ^^^^ 11 00 00 00 (00010001 00000000 00000000 00000000) ^^^^ 19 00 00 00 (00011001 00000000 00000000 00000000) ^^^^ 21 00 00 00 (00100001 00000000 00000000 00000000) ^^^^ 29 00 00 00 (00101001 00000000 00000000 00000000) ^^^^ 31 00 00 00 (00110001 00000000 00000000 00000000) ^^^^ 31 00 00 00 (00110001 00000000 00000000 00000000) ^^^^ 4.7. 虚假分享和*@Contended* jdk.internal.vm.annotation.Contended注解（或 Java 8 上的sun.misc.Contended ）是 JVM 隔离注解字段以避免错误共享的提示。** 简而言之， Contended注释在每个注释字段周围添加了一些填充，以将每个字段隔离在其自己的缓存行上。因此，这将影响内存布局。 为了更好地理解这一点，让我们考虑一个例子： public class Isolated { @Contended private int v1; @Contended private long v2; } 如果我们检查这个类的内存布局，我们会看到如下内容： Isolated object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 128 (alignment/padding gap) 140 4 int Isolated.i N/A 144 128 (alignment/padding gap) 272 8 long Isolated.l N/A Instance size: 280 bytes Space losses: 256 bytes internal + 0 bytes external = 256 bytes total 如上所示，JVM 在每个带注释的字段周围添加了 128 个字节的填充。**大多数现代机器中的缓存行大小约为 64/128 字节，因此填充了 128 字节。当然，我们可以 使用-XX:ContendedPaddingWidth调整标志来控制Contended padding 的大小 。 请注意， 竞争注解是 JDK 内部的，因此我们应该避免使用它。 此外，我们应该使用-XX:-RestrictContended调整标志运行我们的代码；否则，注释不会生效。基本上，默认情况下，此注释仅供内部使用，禁用RestrictContended将为公共 API 解锁此功能。 4.8. 数组 **正如我们之前提到的，数组长度也是数组oop的一部分。**例如，对于包含 3 个元素的布尔数组： boolean[] booleans = new boolean[3]; System.out.println(ClassLayout.parseInstance(booleans).toPrintable()); 内存布局如下： [Z object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 # mark 4 4 (object header) 00 00 00 00 # mark 8 4 (object header) 05 00 00 f8 # klass 12 4 (object header) 03 00 00 00 # array length 16 3 boolean [Z.\u0026lt;elements\u0026gt; N/A 19 5 (loss due to the next object alignment) Instance size: 24 bytes Space losses: 0 bytes internal + 5 bytes external = 5 bytes total 在这里，我们有 16 个字节的对象头，其中包含 8 个字节的标记字、4 个字节的 klass 字和 4 个字节的长度。在对象头之后，我们有 3 个字节的布尔数组，其中包含 3 个元素。 4.9. 压缩参考 到目前为止，我们的示例是在启用了压缩引用的 64 位架构中执行的。 通过 8 字节对齐，我们可以使用多达32 GB 的带有压缩引用的堆。如果我们超出这个限制，甚至手动禁用压缩引用，那么 klass 字将消耗 8 个字节而不是 4 个字节。 让我们看看使用-XX:-UseCompressedOops调整标志禁用压缩 oops 时相同数组示例的内存布局 ： [Z object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 # mark 4 4 (object header) 00 00 00 00 # mark 8 4 (object header) 28 60 d2 11 # klass 12 4 (object header) 01 00 00 00 # klass 16 4 (object header) 03 00 00 00 # length 20 4 (alignment/padding gap) 24 3 boolean [Z.\u0026lt;elements\u0026gt; N/A 27 5 (loss due to the next object alignment) 正如所承诺的，现在 klass 字多了 4 个字节。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_memory_layout/","tags":["JVM"],"title":"Java中对象的内存布局"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将了解 Memento 设计模式是什么以及如何使用它。 首先，我们将通过一些理论。然后，我们将创建一个示例来说明该模式的用法。 2. 什么是纪念品设计模式？ 在书中描述的纪念品设计模式是一种行为设计模式。**Memento 设计模式提供了一种实现可撤销操作的解决方案。**我们可以通过在给定时刻保存对象的状态并在需要撤消执行的操作时恢复它来做到这一点。 实际上，需要保存其状态的对象称为 Originator。Caretaker 是触发状态保存和恢复的对象，称为 Memento。 Memento 对象应尽可能少地向看守人公开信息。这是为了确保我们不会将 Originator 的内部状态暴露给外界，因为这会破坏封装原则。但是，发起者应该访问足够的信息以恢复到原始状态。 让我们看一个快速的类图，说明不同的对象如何相互交互： 正如我们所见，Originator 可以生产和消费 Memento。同时，看守者只保留恢复之前的状态。Originator 的内部表示对外部世界是隐藏的。 在这里，我们使用单个字段来表示 Originator 的状态，尽管我们不限于一个字段，并且可以根据需要使用尽可能多的字段。此外，Memento 对象中的状态不必与 Originator 的完整状态相匹配。只要保留的信息足以恢复 Originator 的状态，我们就可以开始了。 3. 何时使用 Memento 设计模式？ 通常，备忘录设计模式将用于某些操作不可撤销的情况，因此需要回滚到以前的状态。但是，如果 Originator 的状态很重，使用 Memento 设计模式可能会导致昂贵的创建过程和增加的内存使用。 4. 备忘录模式示例 4.1 初始样本 现在让我们看一个备忘录设计模式的例子。假设我们有一个文本编辑器： public class TextEditor { private TextWindow textWindow; public TextEditor(TextWindow textWindow) { this.textWindow = textWindow; } } 它有一个文本窗口，其中包含当前输入的文本，并提供了一种添加更多文本的方法： public class TextWindow { private StringBuilder currentText; public TextWindow() { this.currentText = new StringBuilder(); } public void addText(String text) { currentText.append(text); } } 4.2. Memento 现在，假设我们希望我们的文本编辑器实现一些保存和撤消功能。保存时，我们希望保存当前文本。因此，在撤消后续更改时，我们将恢复保存的文本。 为了做到这一点，我们将使用 Memento 设计模式。首先，我们将创建一个包含当前窗口文本的对象： public class TextWindowState { private String text; public TextWindowState(String text) { this.text = text; } public String getText() { return text; } } 这个对象是我们的纪念品。如我们所见，我们选择使用String而不是 StringBuilder来防止外部人员对当前文本的任何更新。 4.3. Originator 之后，我们必须为 TextWindow类提供创建和使用 Memento 对象的方法，使TextWindow成为我们的 Originator： private StringBuilder currentText; public TextWindowState save() { return new TextWindowState(currentText.toString()); } public void restore(TextWindowState save) { currentText = new StringBuilder(save.getText()); } *save()*方法允许我们创建对象，而 *restore()*方法使用它来恢复之前的状态。 4.4. 看守人 最后，我们必须更新我们的TextEditor类。作为看守者，它将保持 Originator 的状态，并在需要时要求恢复它： private TextWindowState savedTextWindow; public void hitSave() { savedTextWindow = textWindow.save(); } public void hitUndo() { textWindow.restore(savedTextWindow); } 4.5. 测试解决方案 让我们看看它是否可以通过示例运行。想象一下，我们在编辑器中添加一些文本，保存它，然后再添加一些，最后撤消。为了实现这一点，我们将在TextEditor上添加一个**print()方法， 该方法返回 当前文本的字符串： TextEditor textEditor = new TextEditor(new TextWindow()); textEditor.write(\u0026#34;The Memento Design Pattern\\n\u0026#34;); textEditor.write(\u0026#34;How to implement it in Java?\\n\u0026#34;); textEditor.hitSave(); textEditor.write(\u0026#34;Buy milk and eggs before coming home\\n\u0026#34;); textEditor.hitUndo(); assertThat(textEditor.print()).isEqualTo(\u0026#34;The Memento Design Pattern\\nHow to implement it in Java?\\n\u0026#34;); 正如我们所见，最后一句不是当前文本的一部分，因为 Memento 在添加之前已保存。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_memento_design_pattern/","tags":["Pattern"],"title":"Java中的备忘录设计模式"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将了解**GoF 行为模式****之一的中介者**模式。我们将描述它的用途并解释何时应该使用它。 像往常一样，我们还将提供一个简单的代码示例。 2. 中介者模式 在面向对象编程中，我们应该始终尝试以组件松散耦合和可重用的方式设计系统。这种方法使我们的代码更易于维护和测试。 然而，在现实生活中，我们经常需要处理一组复杂的依赖对象。这时中介者模式可能会派上用场。 中介者模式的目的是减少紧密耦合的对象之间直接相互通信的复杂性和依赖性。这是通过创建一个处理依赖对象之间交互的中介对象来实现的。因此，所有的通信都通过中介。 这促进了松散耦合，因为一组一起工作的组件不再需要直接交互。相反，它们只引用单个中介对象。这样，也更容易在系统的其他部分重用这些对象。 3. 中介者模式的UML图 现在让我们直观地看一下模式： 在上面的 UML 图中，我们可以识别出以下参与者：  Mediator定义了Colleague对象用来通信的接口 Colleague定义了持有对Mediator的单个引用的抽象类 ConcreteMediator封装了Colleague对象之间的交互逻辑 ConcreteColleague1和ConcreteColleague2仅通过Mediator进行通信  正如我们所见，Colleague对象并不直接相互引用。相反，所有的通信都是由Mediator执行的。 因此，ConcreteColleague1和ConcreteColleague2可以更容易地重用。 此外，如果我们需要改变Colleague对象协同工作的方式，我们只需要修改ConcreteMediator逻辑。或者我们可以创建Mediator 的新实现。 4. Java实现 现在我们对理论有了清晰的认识，让我们看一个例子来更好地理解实践中的概念。 4.1 示例场景 想象一下，我们正在构建一个由风扇、电源和按钮组成的简单冷却系统。按下按钮将打开或关闭风扇。在我们打开风扇之前，我们需要打开电源。同样，我们必须在关闭风扇后立即关闭电源。 现在让我们看一下示例实现： public class Button { private Fan fan; // constructor, getters and setters  public void press(){ if(fan.isOn()){ fan.turnOff(); } else { fan.turnOn(); } } } public class Fan { private Button button; private PowerSupplier powerSupplier; private boolean isOn = false; // constructor, getters and setters  public void turnOn() { powerSupplier.turnOn(); isOn = true; } public void turnOff() { isOn = false; powerSupplier.turnOff(); } } public class PowerSupplier { public void turnOn() { // implementation  } public void turnOff() { // implementation  } } 接下来，让我们测试一下功能： @Test public void givenTurnedOffFan_whenPressingButtonTwice_fanShouldTurnOnAndOff() { assertFalse(fan.isOn()); button.press(); assertTrue(fan.isOn()); button.press(); assertFalse(fan.isOn()); } 一切似乎都很好。但请注意Button、Fan和PowerSupplier类是如何紧密耦合的**。Button直接在Fan上运行，Fan与Button和PowerSupplier 交互。 在其他模块中重用Button类会很困难。此外，如果我们需要在我们的系统中添加第二个电源，那么我们将不得不修改Fan类的逻辑。 4.2. 添加中介者模式 现在，让我们实现中介者模式来减少我们类之间的依赖关系，并使代码更具可重用性。 首先，我们来介绍一下Mediator类： public class Mediator { private Button button; private Fan fan; private PowerSupplier powerSupplier; // constructor, getters and setters  public void press() { if (fan.isOn()) { fan.turnOff(); } else { fan.turnOn(); } } public void start() { powerSupplier.turnOn(); } public void stop() { powerSupplier.turnOff(); } } 接下来，让我们修改剩下的类： public class Button { private Mediator mediator; // constructor, getters and setters  public void press() { mediator.press(); } } public class Fan { private Mediator mediator; private boolean isOn = false; // constructor, getters and setters  public void turnOn() { mediator.start(); isOn = true; } public void turnOff() { isOn = false; mediator.stop(); } } 再次，让我们测试一下功能： @Test public void givenTurnedOffFan_whenPressingButtonTwice_fanShouldTurnOnAndOff() { assertFalse(fan.isOn()); button.press(); assertTrue(fan.isOn()); button.press(); assertFalse(fan.isOn()); } 我们的冷却系统按预期工作。 现在我们已经实现了中介者模式，Button、Fan或PowerSupplier类都没有直接通信。它们只有一个对调解器的引用。 如果以后需要添加第二个电源，我们只需要更新Mediator的逻辑即可；Button和Fan类保持不变。 这个例子展示了我们可以多么容易地分离依赖对象并使我们的系统更容易维护。 5. 何时使用中介者模式 **如果我们必须处理一组紧密耦合且难以维护的对象，中介者模式是一个不错的选择。**这样我们可以减少对象之间的依赖关系并降低整体复杂性。 此外，通过使用中介对象，我们将通信逻辑提取到单个组件，因此我们遵循单一责任原则。此外，我们可以引入新的中介，而无需更改系统的其余部分。因此，我们遵循开闭原则。 但是，有时由于系统设计错误，我们可能有太多紧密耦合的对象。如果是这种情况，我们不应该应用中介者模式。相反，我们应该退后一步，重新思考我们为类建模的方式。 与所有其他模式一样，我们需要在盲目实施 Mediator Pattern 之前考虑我们的特定用例。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mediator_pattern/","tags":["Pattern"],"title":"Java中的中介者模式"},{"categories":["Java","BiliBili"],"contents":"100分钟学习Java 这是一门针对初学者的完整课程，学习有关Java的所有知识。包括：语法、语句、字符串、操作符、函数、文件等 \r","permalink":"http://itcodingman.github.io/100_mins_java/","tags":[],"title":"100分钟学习Java"},{"categories":["Java"],"contents":"1. 概述 在本文中，我们将了解如何在 Java 中测量经过的时间。虽然这听起来很容易，但我们必须注意一些陷阱。 我们将探索提供测量经过时间功能的标准 Java 类和外部包。 2. 简单测量 2.1 currentTimeMillis() 当我们遇到在 Java 中测量经过时间的需求时，我们可能会尝试这样做： long start = System.currentTimeMillis(); // ... long finish = System.currentTimeMillis(); long timeElapsed = finish - start; 如果我们看一下代码，它就很有意义。我们在开始时得到一个时间戳，当代码完成时我们得到另一个时间戳。经过的时间是这两个值之间的差异。 但是，由于**System.currentTimeMillis()测量挂钟时间结果可能并且将会不准确。**挂钟时间可能会因多种原因而改变，例如更改系统时间会影响结果，或者闰秒会破坏结果。 2.2. nanoTime() java.lang.System 类中的另一个方法是nanoTime()。如果我们查看Java 文档，我们会发现以下语句： “这种方法只能用于测量经过的时间，与系统或挂钟时间的任何其他概念无关。” 让我们使用它： long start = System.nanoTime(); // ... long finish = System.nanoTime(); long timeElapsed = finish - start; 代码与之前基本相同。唯一的区别是用于获取时间戳的方法—— nanoTime()而不是currentTimeMillis()。 我们还要注意*nanoTime()*显然以纳秒为单位返回时间。因此，如果以不同的时间单位测量经过的时间，我们必须相应地对其进行转换。 例如，要转换为毫秒，我们必须将结果（以纳秒为单位）除以 1.000.000。 *nanoTime()*的另一个缺陷是，即使它提供纳秒精度，它也不能保证纳秒分辨率（即值的更新频率）。 但是，它确实保证分辨率至少与 *currentTimeMillis()*一样好。 3. Java 8 如果我们使用 Java 8 – 我们可以尝试新的*java.time.Instant* 和java.time.Duration类。两者都是不可变的、线程安全的，并且使用自己的时间尺度，即 Java 时间尺度，新的**java.time API中的所有类也是如此。 3.1 Java 时间刻度 测量时间的传统方法是将一天划分为 24 小时 60 分 60 秒，即每天 86.400 秒。然而，太阳日并不总是一样长。 UTC 时间刻度实际上允许一天有 86.399 或 86.401 SI 秒。SI 秒是科学的“国际标准秒”，由铯 133 原子的辐射周期定义）。这是保持白天与太阳对齐所必需的。 Java Time-Scale 将每个日历日精确地划分为 86.400 个细分，称为 seconds。没有闰秒。 3.2. Instant类 Instant类代表时间线上的一个瞬间。基本上，它是自标准 Java 纪元1970-01-01T00:00:00Z以来的数字时间戳。 为了获取当前时间戳，我们可以使用 *Instant.now()*静态方法。此方法允许传入可选的时钟 参数。如果省略，则使用默认时区的系统时钟。 **我们可以将开始时间和结束时间存储在两个变量中，如前面的示例所示。**接下来，我们可以计算两个瞬间之间经过的时间。 我们还可以使用 Duration类和它的 between()方法来获取两个Instant对象之间的持续时间。最后，我们需要将Duration转换为毫秒： Instant start = Instant.now(); // CODE HERE Instant finish = Instant.now(); long timeElapsed = Duration.between(start, finish).toMillis(); 4. StopWatch 继续到库，Apache Commons Lang 提供了 可用于测量经过时间的StopWatch类。 4.1 Maven 依赖 我们可以通过更新 pom.xml 来获取最新版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在 此处检查最新版本的依赖项。 4.2. 用StopWatch测量经过的时间 首先，我们需要获取该类的一个实例，然后我们可以简单地测量经过的时间： StopWatch watch = new StopWatch(); watch.start(); 一旦我们运行了一个手表，我们就可以执行我们想要进行基准测试的代码，然后在最后，我们只需调用stop()方法。最后，为了得到实际结果，我们调用getTime()： watch.stop(); System.out.println(\u0026#34;Time Elapsed: \u0026#34; + watch.getTime()); // Prints: Time Elapsed: 2501 **StopWatch 有一些额外的辅助方法，我们可以使用它们来暂停或恢复我们的测量。**如果我们需要使我们的基准测试更复杂，这可能会有所帮助。 最后，让我们注意这个类不是线程安全的。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_measure_elapsed_time/","tags":[],"title":"在 Java 中测量经过的时间"},{"categories":["Java","Security"],"contents":"1. 概述 MD5 是一种广泛使用的加密散列函数，它产生 128 位的散列。 在本文中，我们将看到使用各种 Java 库创建 MD5 哈希的不同方法。 2. MD5 使用MessageDigest类 java.security.MessageDigest类中有一个散列功能。这个想法是首先使用您想要用作参数的算法来实例化MessageDigest ： MessageDigest.getInstance(String Algorithm) 然后继续使用*update()*函数更新消息摘要： public void update(byte [] input) 当您正在读取一个长文件时，可以多次调用上述函数。最后我们需要使用*digest()*函数来生成哈希码： public byte[] digest() 下面是一个为密码生成哈希然后验证它的示例： @Test public void givenPassword_whenHashing_thenVerifying() throws NoSuchAlgorithmException { String hash = \u0026#34;35454B055CC325EA1AF2126E27707052\u0026#34;; String password = \u0026#34;ILoveJava\u0026#34;; MessageDigest md = MessageDigest.getInstance(\u0026#34;MD5\u0026#34;); md.update(password.getBytes()); byte[] digest = md.digest(); String myHash = DatatypeConverter .printHexBinary(digest).toUpperCase(); assertThat(myHash.equals(hash)).isTrue(); } 同样，我们也可以验证文件的校验和： @Test public void givenFile_generatingChecksum_thenVerifying() throws NoSuchAlgorithmException, IOException { String filename = \u0026#34;src/test/resources/test_md5.txt\u0026#34;; String checksum = \u0026#34;5EB63BBBE01EEED093CB22BB8F5ACDC3\u0026#34;; MessageDigest md = MessageDigest.getInstance(\u0026#34;MD5\u0026#34;); md.update(Files.readAllBytes(Paths.get(filename))); byte[] digest = md.digest(); String myChecksum = DatatypeConverter .printHexBinary(digest).toUpperCase(); assertThat(myChecksum.equals(checksum)).isTrue(); } 我们需要注意，MessageDigest 不是线程安全的。因此，我们应该为每个线程使用一个新实例。 3. 使用 Apache Commons 的 MD5 org.apache.commons.codec.digest.DigestUtils类使事情变得更简单。 让我们看一个哈希和验证密码的例子： @Test public void givenPassword_whenHashingUsingCommons_thenVerifying() { String hash = \u0026#34;35454B055CC325EA1AF2126E27707052\u0026#34;; String password = \u0026#34;ILoveJava\u0026#34;; String md5Hex = DigestUtils .md5Hex(password).toUpperCase(); assertThat(md5Hex.equals(hash)).isTrue(); } 4. MD5 使用Guava 下面是我们可以使用com.google.common.io.Files.hash生成 MD5 校验和的另一种方法： @Test public void givenFile_whenChecksumUsingGuava_thenVerifying() throws IOException { String filename = \u0026#34;src/test/resources/test_md5.txt\u0026#34;; String checksum = \u0026#34;5EB63BBBE01EEED093CB22BB8F5ACDC3\u0026#34;; HashCode hash = com.google.common.io.Files .hash(new File(filename), Hashing.md5()); String myChecksum = hash.toString() .toUpperCase(); assertThat(myChecksum.equals(checksum)).isTrue(); } 请注意，不推荐使用Hashing.md5。然而，正如官方文档所表明的那样，出于安全考虑，建议不要使用 MD5。这意味着我们仍然可以使用这种方法，例如，如果我们需要与需要 MD5 的遗留系统集成。否则，我们最好考虑更安全的选择，例如SHA-256。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_md5/","tags":[],"title":"Java中的MD5哈希"},{"categories":["Algorithms"],"contents":"1. 概述 最大子数组问题是在任何给定数组中找到具有最大和的一系列连续元素的任务。 例如，在下面的数组中，突出显示的子数组具有最大 sum(6)： 在本教程中，我们将介绍两种在数组中查找最大子数组的解决方案。我们将使用O(n) 时间和空间复杂度来设计其中之一。 2. 蛮力算法 蛮力是解决问题的迭代方法。在大多数情况下，解决方案需要对数据结构进行多次迭代。在接下来的几节中，我们将应用这种方法来解决最大子数组问题。 2.1 方法 一般来说，想到的第一个解决方案是计算每个可能子数组的总和，并返回总和最大的那个。 首先，我们将计算从索引 0 开始的每个子数组的总和。类似地，我们将找到从0到n-1的每个索引开始的所有子数组，其中n是数组的长度： 因此，我们将从索引0开始，并将每个元素添加到迭代中的运行总和中。我们还将跟踪迄今为止看到的最大金额。此迭代显示在上图的左侧。 在图像的右侧，我们可以看到从索引3开始的迭代。在这张图片的最后一部分，我们得到了索引3和6之间总和最大的子数组。 但是，我们的算法将继续查找从0到n-1之间的索引开始的所有子数组。 2.2. 执行 现在让我们看看如何在 Java 中实现这个解决方案： public int maxSubArray(int[] nums) { int n = nums.length; int maximumSubArraySum = Integer.MIN_VALUE; int start = 0; int end = 0; for (int left = 0; left \u0026lt; n; left++) { int runningWindowSum = 0; for (int right = left; right \u0026lt; n; right++) { runningWindowSum += nums[right]; if (runningWindowSum \u0026gt; maximumSubArraySum) { maximumSubArraySum = runningWindowSum; start = left; end = right; } } } logger.info(\u0026#34;Found Maximum Subarray between {} and {}\u0026#34;, start, end); return maximumSubArraySum; } 正如预期的那样， 如果当前总和大于先前的最大总和，我们将更新*maximumSubArraySum 。*值得注意的是，我们还更新了 start和 end以找出这个子数组的索引位置。 2.3. 复杂 一般来说，蛮力解决方案会多次迭代数组以获得所有可能的解决方案。这意味着此解决方案所花费的时间随着数组中元素的数量呈二次方增长。对于小尺寸的数组，这可能不是问题。但是随着数组大小的增长，这种解决方案效率不高。 通过检查代码，我们还可以看到有两个嵌套的 for循环。因此，我们可以得出结论，该算法的时间复杂度为O(n 2 )。 在后面的部分中，我们将使用动态规划以O(n)复杂度解决这个问题。 3.动态规划 动态规划通过将问题划分为更小的子问题来解决问题。这与分治算法求解技术非常相似。然而，主要区别在于动态规划仅解决子问题一次。 然后它存储这个子问题的结果，然后再使用这个结果来解决其他相关的子问题。这个过程被称为记忆。 3.1 Kadane 算法 Kadane 算法是最大子阵列问题的一种流行解决方案，该解决方案基于动态规划。 解决动态规划问题最重要的挑战是找到最优子问题。 3.2. 方法 让我们以不同的方式理解这个问题： 在上图中，我们假设最大子数组在最后一个索引位置结束。因此，子数组的最大和将是： maximumSubArraySum = max_so_far + arr[n-1] max_so_far是在索引n-2**处结束的子数组的最大总和。这也显示在上图中。 现在，我们可以将此假设应用于数组中的任何索引。例如，以n-2结尾的最大子数组和可以计算为： maximumSubArraySum[n-2] = max_so_far[n-3] + arr[n-2] 因此，我们可以得出结论： maximumSubArraySum[i] = maximumSubArraySum[i-1] + arr[i] 现在，由于数组中的每个元素都是大小为 1 的特殊子数组，我们还需要检查元素是否大于最大和本身： maximumSubArraySum[i] = Max(arr[i], maximumSubArraySum[i-1] + arr[i]) 通过查看这些方程，我们可以看到我们需要在数组的每个索引处找到最大的子数组和。因此，我们将问题划分为n个子问题。我们可以通过仅迭代数组一次来找到每个索引处的最大和： 突出显示的元素显示迭代中的当前元素。在每个索引处，我们将应用前面推导的公式来计算max_ending_here的值。这有助于我们确定是应该在子数组中包含当前元素还是从该索引开始新的子数组。 另一个变量max_so_far用于存储迭代期间找到的最大子数组和。一旦我们遍历最后一个索引，max_so_far将存储最大子数组的总和。 3.3. 执行 同样，让我们看看我们现在如何按照上述方法在 Java 中实现 Kadane 算法： public int maxSubArraySum(int[] arr) { int size = arr.length; int start = 0; int end = 0; int maxSoFar = arr[0], maxEndingHere = arr[0]; for (int i = 1; i \u0026lt; size; i++) { if (arr[i] \u0026gt; maxEndingHere + arr[i]) { start = i; maxEndingHere = arr[i]; } else maxEndingHere = maxEndingHere + arr[i]; if (maxSoFar \u0026lt; maxEndingHere) { maxSoFar = maxEndingHere; end = i; } } logger.info(\u0026#34;Found Maximum Subarray between {} and {}\u0026#34;, Math.min(start, end), end); return maxSoFar; } 在这里，我们更新了start和 end以找到最大的子数组索引。 请注意，我们将Math.min(start, end)而不是 start作为最大子数组的开始索引。这是因为，如果数组仅包含负数，则最大子数组将是最大元素本身。在这种情况下，if (arr[i] \u0026gt; maxEndingHere + arr[i])将始终为true。即start的值大于end 的值。 3.4. 复杂度 由于我们只需要对数组进行一次迭代，因此该算法的时间复杂度为O(n)。 所以我们可以看到，这个解决方案所花费的时间随着数组中元素的数量线性增长。因此，它比我们在上一节中讨论的蛮力方法更有效。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_maximum_subarray/","tags":["Java Array"],"title":"Java中的最大子数组问题"},{"categories":["Java","Spring","Youtube"],"contents":"15分钟学习MyBatis Generator   ","permalink":"http://itcodingman.github.io/15_mins_mybatis_generator/","tags":[],"title":"15分钟学习MyBatis Generator"},{"categories":["Algorithms","Java"],"contents":"1. 概述 在本教程中，我们将了解如何在 Java 中将两个矩阵相乘。 由于矩阵概念在语言中不存在，我们将自己实现它，我们还将与一些库一起工作，看看它们如何处理矩阵乘法。 最后，我们将对我们探索的不同解决方案进行一些基准测试，以确定最快的解决方案。 2. 例子 让我们从设置一个我们可以在本教程中引用的示例开始。 首先，我们将想象一个 3×2 矩阵： 现在让我们想象第二个矩阵，这次是两行四列： 然后，将第一个矩阵与第二个矩阵相乘，得到一个 3×4 矩阵： 提醒一下，此结果是通过使用以下公式计算结果矩阵的每个单元格获得的： 其中 r是矩阵 A的行数，c是矩阵 B的列数， n是矩阵A的列数，它必须与矩阵**B的行数匹配。 3. 矩阵乘法 3.1 自己的实现 让我们从我们自己的矩阵实现开始。 我们将保持简单，只使用二维double数组： double[][] firstMatrix = { new double[]{1d, 5d}, new double[]{2d, 3d}, new double[]{1d, 7d} }; double[][] secondMatrix = { new double[]{1d, 2d, 3d, 7d}, new double[]{5d, 2d, 8d, 1d} }; 这些是我们示例的两个矩阵。让我们创建一个预期作为它们相乘结果的结果： double[][] expected = { new double[]{26d, 12d, 43d, 12d}, new double[]{17d, 10d, 30d, 17d}, new double[]{36d, 16d, 59d, 14d} }; 现在一切都设置好了，让我们实现乘法算法。我们将首先创建一个空的结果数组并遍历其单元格以在每个单元格中存储预期值： double[][] multiplyMatrices(double[][] firstMatrix, double[][] secondMatrix) { double[][] result = new double[firstMatrix.length][secondMatrix[0].length]; for (int row = 0; row \u0026lt; result.length; row++) { for (int col = 0; col \u0026lt; result[row].length; col++) { result[row][col] = multiplyMatricesCell(firstMatrix, secondMatrix, row, col); } } return result; } 最后，让我们实现单个单元格的计算。为了实现这一点，我们将使用前面示例演示中显示的公式： double multiplyMatricesCell(double[][] firstMatrix, double[][] secondMatrix, int row, int col) { double cell = 0; for (int i = 0; i \u0026lt; secondMatrix.length; i++) { cell += firstMatrix[row][i] * secondMatrix[i][col]; } return cell; } 最后，让我们检查一下算法的结果是否符合我们的预期结果： double[][] actual = multiplyMatrices(firstMatrix, secondMatrix); assertThat(actual).isEqualTo(expected); 3.2. EJML 我们要看的第一个库是 EJML，它代表Efficient Java Matrix Library。在编写本教程时，它是最近更新的 Java 矩阵库之一。其目的是在计算和内存使用方面尽可能高效。 我们必须在pom.xml中将依赖项添加到库中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.ejml\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ejml-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.38\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 我们将使用与之前几乎相同的模式：根据我们的示例创建两个矩阵，并检查它们相乘的结果是否是我们之前计算的结果。 因此，让我们使用 EJML 创建矩阵。为了实现这一点，我们将使用库提供的 SimpleMatrix类。 它可以将二维双精度数组作为其构造函数的输入： SimpleMatrix firstMatrix = new SimpleMatrix( new double[][] { new double[] {1d, 5d}, new double[] {2d, 3d}, new double[] {1d ,7d} } ); SimpleMatrix secondMatrix = new SimpleMatrix( new double[][] { new double[] {1d, 2d, 3d, 7d}, new double[] {5d, 2d, 8d, 1d} } ); 现在，让我们定义我们期望的乘法矩阵： SimpleMatrix expected = new SimpleMatrix( new double[][] { new double[] {26d, 12d, 43d, 12d}, new double[] {17d, 10d, 30d, 17d}, new double[] {36d, 16d, 59d, 14d} } ); 现在我们都设置好了，让我们看看如何将两个矩阵相乘。**SimpleMatrix 类提供了一个 mult()方法，将另一个SimpleMatrix作为参数并返回两个矩阵的乘积： SimpleMatrix actual = firstMatrix.mult(secondMatrix); 让我们检查获得的结果是否与预期的结果相符。 由于 SimpleMatrix没有覆盖 equals()方法，我们不能依赖它来进行验证。但是，它提供了另一种选择： *isIdentical()*方法不仅采用另一个矩阵参数，而且采用双容错方法来忽略由于双精度引起的微小差异： assertThat(actual).matches(m -\u0026gt; m.isIdentical(expected, 0d)); 使用 EJML 库的矩阵乘法到此结束。让我们看看其他人提供了什么。 3.3. ND4J 现在让我们试试ND4J 库。ND4J 是一个计算库，是deeplearning4j项目的一部分。除其他外，ND4J 还提供矩阵计算功能。 首先，我们必须得到库依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.nd4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nd4j-native\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0-beta4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，我们在这里使用的是 beta 版本，因为 GA 版本似乎存在一些错误。 为简洁起见，我们不会重写二维双精度数组，而只关注它们如何与每个库一起使用。因此，对于 ND4J，我们必须创建一个INDArray。为了做到这一点，我们将调用 Nd4j.create()工厂方法并向其传递一个表示矩阵的双精度数组： INDArray matrix = Nd4j.create(/* a two dimensions double array */); 与上一节一样，我们将创建三个矩阵：我们将要相乘的两个矩阵和一个作为预期结果的矩阵。 之后，我们想要使用*INDArray.mmul()*方法实际执行前两个矩阵之间的乘法： INDArray actual = firstMatrix.mmul(secondMatrix); 然后，我们再次检查实际结果是否与预期结果相符。这次我们可以依靠相等性检查： assertThat(actual).isEqualTo(expected); 这演示了如何使用 ND4J 库进行矩阵计算。 3.4. Apache Commons Math3 现在让我们谈谈Apache Commons Math3 模块，它为我们提供了包括矩阵操作在内的数学计算。 同样，我们必须在pom.xml中指定依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-math3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 设置完成后，我们可以使用RealMatrix接口及其 Array2DRowRealMatrix实现来创建我们常用的矩阵。实现类的构造函数以一个二维双精度数组为参数： RealMatrix matrix = new Array2DRowRealMatrix(/* a two dimensions double array */); 至于矩阵乘法，*RealMatrix 接口提供了一个以另一个 RealMatrix参数为参数的multiply()*方法： RealMatrix actual = firstMatrix.multiply(secondMatrix); 我们终于可以验证结果是否与我们期望的一样： assertThat(actual).isEqualTo(expected); 让我们看看下一个图书馆！ 3.5. LA4J 这个被命名为 LA4J，代表Java 的线性代数。 让我们也为这个添加依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.la4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;la4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在，LA4J 的工作方式与其他库非常相似。它提供了一个 带有 Basic2DMatrix实现的Matrix接口，该实现将二维双精度数组作为输入： Matrix matrix = new Basic2DMatrix(/* a two dimensions double array */); 与 Apache Commons Math3 模块中一样，乘法方法是 *multiply()*并将另一个 Matrix作为其参数： Matrix actual = firstMatrix.multiply(secondMatrix); 再一次，我们可以检查结果是否符合我们的预期： assertThat(actual).isEqualTo(expected); 现在让我们看看我们的最后一个库：Colt。 3.6. Colt Colt是 CERN 开发的一个库。它提供了支持高性能科学和技术计算的功能。 与之前的库一样，我们必须获得正确的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;colt\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;colt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 为了使用 Colt 创建矩阵，我们必须使用DoubleFactory2D 类。它带有三个工厂实例：dense、sparse和 rowCompressed。每个都经过优化以创建匹配类型的矩阵。 出于我们的目的，我们将使用密集实例。这一次，调用的方法是 make()，它再次接受一个二维双精度数组，生成一个DoubleMatrix2D对象： DoubleMatrix2D matrix = doubleFactory2D.make(/* a two dimensions double array */); 一旦我们的矩阵被实例化，我们就会想要将它们相乘。这一次，矩阵对象上没有方法可以做到这一点。我们必须创建一个**Algebra类的实例，它有一个 mult()方法，采用两个矩阵作为参数： Algebra algebra = new Algebra(); DoubleMatrix2D actual = algebra.mult(firstMatrix, secondMatrix); 然后，我们可以将实际结果与预期结果进行比较： assertThat(actual).isEqualTo(expected); 4. 基准测试 现在我们已经完成了对矩阵乘法不同可能性的探索，让我们来看看哪些是性能最高的。 4.1 小矩阵 让我们从小矩阵开始。在这里，一个 3×2 和一个 2×4 矩阵。 为了实现性能测试，我们将使用JMH 基准测试库。让我们使用以下选项配置一个基准测试类： public static void main(String[] args) throws Exception { Options opt = new OptionsBuilder() .include(MatrixMultiplicationBenchmarking.class.getSimpleName()) .mode(Mode.AverageTime) .forks(2) .warmupIterations(5) .measurementIterations(10) .timeUnit(TimeUnit.MICROSECONDS) .build(); new Runner(opt).run(); } 这样，JMH 将为使用*@Benchmark*注释的每种方法进行两次完整运行，每次运行五次预热迭代（不计入平均计算）和十次测量迭代。至于测量，它将收集不同库的平均执行时间，以微秒为单位。 然后我们必须创建一个包含我们的数组的状态对象： @State(Scope.Benchmark) public class MatrixProvider { private double[][] firstMatrix; private double[][] secondMatrix; public MatrixProvider() { firstMatrix = new double[][] { new double[] {1d, 5d}, new double[] {2d, 3d}, new double[] {1d ,7d} }; secondMatrix = new double[][] { new double[] {1d, 2d, 3d, 7d}, new double[] {5d, 2d, 8d, 1d} }; } } 这样，我们确保数组初始化不是基准测试的一部分。之后，我们仍然需要创建执行矩阵乘法的方法，使用MatrixProvider对象作为数据源。我们不会在这里重复代码，因为我们之前看到了每个库。 最后，我们将使用我们的 main方法运行基准测试过程。这给了我们以下结果： Benchmark Mode Cnt Score Error Units MatrixMultiplicationBenchmarking.apacheCommonsMatrixMultiplication avgt 20 1,008 ± 0,032 us/op MatrixMultiplicationBenchmarking.coltMatrixMultiplication avgt 20 0,219 ± 0,014 us/op MatrixMultiplicationBenchmarking.ejmlMatrixMultiplication avgt 20 0,226 ± 0,013 us/op MatrixMultiplicationBenchmarking.homemadeMatrixMultiplication avgt 20 0,389 ± 0,045 us/op MatrixMultiplicationBenchmarking.la4jMatrixMultiplication avgt 20 0,427 ± 0,016 us/op MatrixMultiplicationBenchmarking.nd4jMatrixMultiplication avgt 20 12,670 ± 2,582 us/op 正如我们所看到的， EJML和Colt的性能非常好，每次操作大约五分之一微秒，而ND4j的性能较差，每次操作超过十微秒。其他图书馆的表演介于两者之间。 此外，值得注意的是，当预热迭代次数从 5 次增加到 10 次时，所有库的性能都在提高。 4.2. 大型矩阵 现在，如果我们采用更大的矩阵，比如 3000×3000，会发生什么？为了检查会发生什么，让我们首先创建另一个状态类，提供该大小的生成矩阵： @State(Scope.Benchmark) public class BigMatrixProvider { private double[][] firstMatrix; private double[][] secondMatrix; public BigMatrixProvider() {} @Setup public void setup(BenchmarkParams parameters) { firstMatrix = createMatrix(); secondMatrix = createMatrix(); } private double[][] createMatrix() { Random random = new Random(); double[][] result = new double[3000][3000]; for (int row = 0; row \u0026lt; result.length; row++) { for (int col = 0; col \u0026lt; result[row].length; col++) { result[row][col] = random.nextDouble(); } } return result; } } 正如我们所见，我们将创建 3000×3000 的二维双精度数组，其中填充了随机实数。 现在让我们创建基准测试类： public class BigMatrixMultiplicationBenchmarking { public static void main(String[] args) throws Exception { Map\u0026lt;String, String\u0026gt; parameters = parseParameters(args); ChainedOptionsBuilder builder = new OptionsBuilder() .include(BigMatrixMultiplicationBenchmarking.class.getSimpleName()) .mode(Mode.AverageTime) .forks(2) .warmupIterations(10) .measurementIterations(10) .timeUnit(TimeUnit.SECONDS); new Runner(builder.build()).run(); } @Benchmark public Object homemadeMatrixMultiplication(BigMatrixProvider matrixProvider) { return HomemadeMatrix .multiplyMatrices(matrixProvider.getFirstMatrix(), matrixProvider.getSecondMatrix()); } @Benchmark public Object ejmlMatrixMultiplication(BigMatrixProvider matrixProvider) { SimpleMatrix firstMatrix = new SimpleMatrix(matrixProvider.getFirstMatrix()); SimpleMatrix secondMatrix = new SimpleMatrix(matrixProvider.getSecondMatrix()); return firstMatrix.mult(secondMatrix); } @Benchmark public Object apacheCommonsMatrixMultiplication(BigMatrixProvider matrixProvider) { RealMatrix firstMatrix = new Array2DRowRealMatrix(matrixProvider.getFirstMatrix()); RealMatrix secondMatrix = new Array2DRowRealMatrix(matrixProvider.getSecondMatrix()); return firstMatrix.multiply(secondMatrix); } @Benchmark public Object la4jMatrixMultiplication(BigMatrixProvider matrixProvider) { Matrix firstMatrix = new Basic2DMatrix(matrixProvider.getFirstMatrix()); Matrix secondMatrix = new Basic2DMatrix(matrixProvider.getSecondMatrix()); return firstMatrix.multiply(secondMatrix); } @Benchmark public Object nd4jMatrixMultiplication(BigMatrixProvider matrixProvider) { INDArray firstMatrix = Nd4j.create(matrixProvider.getFirstMatrix()); INDArray secondMatrix = Nd4j.create(matrixProvider.getSecondMatrix()); return firstMatrix.mmul(secondMatrix); } @Benchmark public Object coltMatrixMultiplication(BigMatrixProvider matrixProvider) { DoubleFactory2D doubleFactory2D = DoubleFactory2D.dense; DoubleMatrix2D firstMatrix = doubleFactory2D.make(matrixProvider.getFirstMatrix()); DoubleMatrix2D secondMatrix = doubleFactory2D.make(matrixProvider.getSecondMatrix()); Algebra algebra = new Algebra(); return algebra.mult(firstMatrix, secondMatrix); } } 当我们运行这个基准测试时，我们会得到完全不同的结果： Benchmark Mode Cnt Score Error Units BigMatrixMultiplicationBenchmarking.apacheCommonsMatrixMultiplication avgt 20 511.140 ± 13.535 s/op BigMatrixMultiplicationBenchmarking.coltMatrixMultiplication avgt 20 197.914 ± 2.453 s/op BigMatrixMultiplicationBenchmarking.ejmlMatrixMultiplication avgt 20 25.830 ± 0.059 s/op BigMatrixMultiplicationBenchmarking.homemadeMatrixMultiplication avgt 20 497.493 ± 2.121 s/op BigMatrixMultiplicationBenchmarking.la4jMatrixMultiplication avgt 20 35.523 ± 0.102 s/op BigMatrixMultiplicationBenchmarking.nd4jMatrixMultiplication avgt 20 0.548 ± 0.006 s/op 正如我们所看到的，自制的实现和 Apache 库现在比以前差了很多，需要将近 10 分钟来执行两个矩阵的乘法。 Colt 用了 3 分钟多一点，这更好，但仍然很长。EJML 和 LA4J 的表现相当不错，因为它们的运行时间接近 30 秒。但是，是 ND4J 在CPU 后端 上在一秒钟内赢得了这个基准测试。 4.3. 分析 这向我们表明，基准测试结果确实取决于矩阵的特征，因此很难指出一个赢家。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_matrix_multiplication/","tags":["Math"],"title":"Java中的矩阵乘法"},{"categories":["Algorithms","Java"],"contents":"1. 简介 在这个简短的教程中，我们将了解如何使用 Java 的 *Math.sin()*函数计算正弦值，以及如何在度数和弧度之间转换角度值。 2. 弧度与度数 默认情况下，Java Math库期望其三角函数的值以弧度表示。 **提醒一下， 弧度只是表示角度度量的另一种方式，**转换为： double inRadians = inDegrees * PI / 180; inDegrees = inRadians * 180 / PI; Java 使用toRadians和 toDegrees使这变得容易： double inRadians = Math.toRadians(inDegrees); double inDegrees = Math.toDegrees(inRadians); 每当我们使用 Java 的任何三角函数时，我们都应该首先考虑输入的单位是什么。 3. 使用Math.sin 我们可以通过查看Math.sin方法来了解这一原理，这是 Java 提供的众多方法之一： public static double sin(double a) 它等效于数学正弦函数，它期望其输入为弧度。所以，假设我们有一个角度，我们知道它是度数： double inDegrees = 30; 我们首先需要将其转换为弧度： double inRadians = Math.toRadians(inDegrees); 然后我们可以计算正弦值： double sine = Math.sin(inRadians); 但是，如果我们知道它已经是弧度，那么我们不需要进行转换： @Test public void givenAnAngleInDegrees_whenUsingToRadians_thenResultIsInRadians() { double angleInDegrees = 30; double sinForDegrees = Math.sin(Math.toRadians(angleInDegrees)); // 0.5  double thirtyDegreesInRadians = 1/6 * Math.PI; double sinForRadians = Math.sin(thirtyDegreesInRadians); // 0.5  assertTrue(sinForDegrees == sinForRadians); } 由于 30DegreesInRadians已经是弧度，我们不需要先转换它来获得相同的结果。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_math_sin_degrees/","tags":["Math"],"title":"使用带度数的 Math.sin"},{"categories":["Java"],"contents":"1. 概述 数的幂是指在乘法中使用该数的次数。这可以在 Java 中轻松计算。 2. Math.pow示例 在看示例之前，让我们看一下方法的签名： public double pow(double a, double b) 该方法将a提高到**b的幂并将结果返回为double。换句话说，a自身乘以b次。 现在让我们看一个简单的例子： int intResult = (int) Math.pow(2, 3); 输出将为 8。请注意，如果我们想要一个整数结果，则需要上面示例中的int强制转换。 现在让我们将double作为参数传递并查看结果： double dblResult = Math.pow(4.2, 3); 输出将为 74.08800000000001。 在这里，我们没有将结果转换为int，因为我们对double值感兴趣。由于我们有一个双精度值，我们可以轻松配置和使用DecimalFormat将值四舍五入到小数点后两位，得到 74.09： DecimalFormat df = new DecimalFormat(\u0026#34;.00\u0026#34;); double dblResult = Math.pow(4.2, 3); \u0026quot; ","permalink":"http://itcodingman.github.io/java_math_pow/","tags":["Core Java","Math"],"title":"在 Java 中使用 Math.pow"},{"categories":["Java"],"contents":"1. 概述 在 Java 中使用正则表达式时，我们通常希望在字符序列中搜索给定的Pattern。为了促进这一点，Java 正则表达式 API提供了Matcher类，我们可以使用它来匹配给定的正则表达式与文本。 作为一般规则，我们几乎总是希望使用Matcher类的两种流行方法之一：  find() matches()  在本快速教程中，我们将通过一组简单的示例了解这些方法之间的区别。 2. *find()*方法 **简而言之，find()方法试图在给定的字符串中查找正则表达式模式的出现。如果在字符串中发现多次出现，那么第一次调用*find()*将跳转到第一次出现。*此后，对find()*方法的每个后续调用都将一个接一个地转到下一个匹配项。 假设我们只想在提供的字符串*“goodbye 2019 and welcome 2020”*中搜索四位数字。 为此，我们将使用模式*“\\d\\d\\d\\d”*： @Test public void whenFindFourDigitWorks_thenCorrect() { Pattern stringPattern = Pattern.compile(\u0026#34;\\\\d\\\\d\\\\d\\\\d\u0026#34;); Matcher m = stringPattern.matcher(\u0026#34;goodbye 2019 and welcome 2020\u0026#34;); assertTrue(m.find()); assertEquals(8, m.start()); assertEquals(\u0026#34;2019\u0026#34;, m.group()); assertEquals(12, m.end()); assertTrue(m.find()); assertEquals(25, m.start()); assertEquals(\u0026#34;2020\u0026#34;, m.group()); assertEquals(29, m.end()); assertFalse(m.find()); } 由于我们在此示例中出现了两次*——2019 年和2020 年*—— find()方法将返回两次true，一旦到达匹配区域的末尾，它将返回false。 一旦找到任何匹配项，我们就可以使用**start()、group()和end()等方法来获取有关匹配项的更多详细信息，如上所示。 *start()*方法将给出匹配的开始索引，end *()*将返回匹配结束后字符的最后一个索引，**group()将返回匹配的实际值。 3. *find(int)*方法 我们还有 find 方法的重载版本—— find(int)。它将起始索引作为参数，并将起始索引视为在字符串中查找出现的起点。 让我们看看如何在与之前相同的示例中使用此方法： @Test public void givenStartIndex_whenFindFourDigitWorks_thenCorrect() { Pattern stringPattern = Pattern.compile(\u0026#34;\\\\d\\\\d\\\\d\\\\d\u0026#34;); Matcher m = stringPattern.matcher(\u0026#34;goodbye 2019 and welcome 2020\u0026#34;); assertTrue(m.find(20)); assertEquals(25, m.start()); assertEquals(\u0026#34;2020\u0026#34;, m.group()); assertEquals(29, m.end()); } 由于我们提供了20的起始索引，我们可以看到现在只找到一个事件 - 2020，它按预期发生在该索引之后。而且，与find()的情况一样，我们可以使用start()、*group()和end()*等方法来提取有关匹配的更多详细信息。 4. *matches()*方法 另一方面，*matches()*方法尝试将整个字符串与 pattern 进行匹配。 对于同一个示例，matches()将返回false： @Test public void whenMatchFourDigitWorks_thenFail() { Pattern stringPattern = Pattern.compile(\u0026#34;\\\\d\\\\d\\\\d\\\\d\u0026#34;); Matcher m = stringPattern.matcher(\u0026#34;goodbye 2019 and welcome 2020\u0026#34;); assertFalse(m.matches()); } 这是因为它将尝试将*“\\d\\d\\d\\d”*与整个字符串“ goodbye 2019 and welcome 2020”进行匹配——**这与find()和find(int)方法不同，这两个方法都会在字符串中的任何位置查找模式的出现。 如果我们将字符串更改为四位数字*“2019”，那么matches()将返回true*： @Test public void whenMatchFourDigitWorks_thenCorrect() { Pattern stringPattern = Pattern.compile(\u0026#34;\\\\d\\\\d\\\\d\\\\d\u0026#34;); Matcher m = stringPattern.matcher(\u0026#34;2019\u0026#34;); assertTrue(m.matches()); assertEquals(0, m.start()); assertEquals(\u0026#34;2019\u0026#34;, m.group()); assertEquals(4, m.end()); assertTrue(m.matches()); } 如上所示，我们还可以使用start()、group()和end()等方法来收集有关比赛的更多详细信息。**需要注意的一个有趣的点是， 多次调用find()可能会在调用这些方法后返回不同的输出，正如我们在第一个示例中看到的那样，但matches()将始终返回相同的值。* 5. *matcher()和Pattern.matches()*的区别 正如我们在上一节中看到的，matcher()方法返回一个匹配器，它将给定输入与模式匹配。 另一方面，*Pattern.matches()*是一种静态方法，它编译正则表达式并将整个输入与它匹配。 让我们创建测试用例来突出差异： @Test public void whenUsingMatcher_thenReturnTrue() { Pattern pattern = Pattern.compile(REGEX); Matcher matcher = pattern.matcher(STRING_INPUT); assertTrue(matcher.find()); } 简而言之，当我们使用*matcher()*时，我们会问一个问题：字符串是否包含模式？ 使用Pattern.matches()，我们问：字符串是模式吗？ 让我们看看它的实际效果： @Test public void whenUsingMatches_thenReturnFalse() { assertFalse(Pattern.matches(REGEX, STRING_INPUT)); } 由于Pattern.matches()尝试匹配整个字符串，因此它返回false。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_matcher_find_vs_matches/","tags":["Regex"],"title":"Java Matcher find() 和 matches() 之间的区别"},{"categories":["Java"],"contents":"1. 简介 在这个快速教程中，我们将学习 Java 中的标记接口。 2. 标记接口 标记接口是其中没有方法或常量的接口。它提供有关对象的运行时类型信息，因此编译器和 JVM 具有 有关对象的附加信息。 标记接口也称为标记接口。 尽管标记接口仍在使用中，但它们很可能指向代码异味，应谨慎使用。这样做的主要原因是它们模糊了界面所代表的界限，因为标记没有定义任何行为。较新的开发有利于注释来解决一些相同的问题。 3. JDK 标记接口 Java 有许多内置的标记接口，例如Serializable、Cloneable和 Remote 。 我们以Cloneable接口为例。如果我们试图克隆一个没有实现这个接口的对象，JVM 会抛出一个CloneNotSupportedException。因此，Cloneable 标记接口是 JVM 的一个指标 ，我们可以调用*Object.clone()*方法。 同样，在调用 ObjectOutputStream.writeObject()方法时，**JVM 会检查对象是否实现了Serializable标记接口**。如果不是这种情况， 则会引发NotSerializableException 。因此，对象不会序列化到输出流。 4. 自定义标记界面 让我们创建自己的标记界面。 例如，我们可以创建一个标记来指示是否可以从数据库中删除对象： public interface Deletable { } 为了从数据库中删除一个实体，代表这个实体的对象必须实现我们的可删除标记接口： public class Entity implements Deletable { // implementation details } 假设我们有一个 DAO 对象，该对象具有从数据库中删除实体的方法。我们可以编写我们的*delete()*方法，这样 只有实现了我们的标记接口的对象才能被删除： public class ShapeDao { // other dao methods  public boolean delete(Object object) { if (!(object instanceof Deletable)) { return false; } // delete implementation details  return true; } } 正如我们所见，我们正在向 JVM 提供有关对象运行时行为的指示。 如果对象实现了我们的标记接口，它可以从数据库中删除。 5. 标记接口与注释 通过引入注解，Java 为我们提供了一种替代方法来实现与标记接口相同的结果。此外，像标记接口一样，我们可以将注释应用于任何类，并且可以将它们用作指示符来执行某些操作。 那么关键的区别是什么？ 与注解不同，接口允许我们利用多态性。因此，我们可以为标记界面添加额外的限制。 例如，让我们添加一个限制，即只能从数据库中删除Shape 类型： public interface Shape { double getArea(); double getCircumference(); } 在这种情况下，我们的标记接口，我们称之为 *DeletableShape，*将如下所示： public interface DeletableShape extends Shape { } 然后我们的类将实现标记接口： public class Rectangle implements DeletableShape { // implementation details } 因此，所有 的DeletableShape实现也是 Shape实现。显然，我们不能使用 annotations 来做到这一点。 然而，每个设计决策都有权衡，多态性可以用作反对标记接口的反驳。在我们的示例中，每个扩展Rectangle的类都会自动实现 DeletableShape。 6. 标记接口与典型接口 在前面的示例中，我们可以通过修改 DAO 的 delete()方法来测试我们的对象是否为Shape而不是测试它是否是可删除的，从而获得相同的结果： public class ShapeDao { // other dao methods  public boolean delete(Object object) { if (!(object instanceof Shape)) { return false; } // delete implementation details  return true; } } 那么，当我们可以使用典型界面获得相同的结果时，为什么还要创建标记界面呢？ 让我们想象一下，除了Shape类型之外，我们还想 从数据库中删除Person类型。在这种情况下，有两种选择可以实现： 第一个选项是 在我们之前的*delete()*方法中添加一个额外的检查， 以验证要删除的对象是否是Person的实例。 public boolean delete(Object object) { if (!(object instanceof Shape || object instanceof Person)) { return false; } // delete implementation details  return true; } 但是，如果我们还想从数据库中删除更多类型怎么办？显然，这不是一个好的选择，因为我们必须为每个新类型更改我们的方法。 第二个选项是 让Person类型实现Shape接口，它充当标记接口。但是Person对象真的是Shape吗？答案显然是否定的，这使得第二种选择比第一种更糟糕。 因此，虽然 我们可以通过使用典型界面作为标记来获得相同的结果，但我们最终会得到一个糟糕的设计。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_marker_interfaces/","tags":["Core Java"],"title":"Java 中的标记接口"},{"categories":["Java","BiliBili"],"contents":"Visual Studio Code Java 的安装及使用 VisualStudioCode和Java的安装及使用 \r","permalink":"http://itcodingman.github.io/vscode_java_install_introduce/","tags":[],"title":"Visual Studio Code Java 的安装及使用"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将了解如何使用 MapStruct 映射对象集合。 由于本文假设您已经对 MapStruct 有基本的了解，因此初学者应该首先查看我们的MapStruct 快速指南。 2. 映射集合 通常，使用 MapStruct 映射集合的工作方式与简单类型相同。 基本上，我们必须创建一个简单的接口或抽象类并声明映射方法。根据我们的声明，MapStruct 会自动生成映射代码。通常，生成的代码将遍历源集合，将每个元素转换为目标类型，并将它们中的每一个都包含在目标集合中。 让我们看一个简单的例子。 2.1 映射列表 首先，对于我们的示例，让我们考虑一个简单的 POJO 作为我们映射器的映射源： public class Employee { private String firstName; private String lastName; // constructor, getters and setters } 目标将是一个简单的 DTO： public class EmployeeDTO { private String firstName; private String lastName; // getters and setters } 接下来，让我们定义我们的映射器： @Mapper public interface EmployeeMapper { List\u0026lt;EmployeeDTO\u0026gt; map(List\u0026lt;Employee\u0026gt; employees); } 最后，让我们看一下从我们的EmployeeMapper接口生成的 MapStruct 代码： public class EmployeeMapperImpl implements EmployeeMapper { @Override public List\u0026lt;EmployeeDTO\u0026gt; map(List\u0026lt;Employee\u0026gt; employees) { if (employees == null) { return null; } List\u0026lt;EmployeeDTO\u0026gt; list = new ArrayList\u0026lt;EmployeeDTO\u0026gt;(employees.size()); for (Employee employee : employees) { list.add(employeeToEmployeeDTO(employee)); } return list; } protected EmployeeDTO employeeToEmployeeDTO(Employee employee) { if (employee == null) { return null; } EmployeeDTO employeeDTO = new EmployeeDTO(); employeeDTO.setFirstName(employee.getFirstName()); employeeDTO.setLastName(employee.getLastName()); return employeeDTO; } } 有一件重要的事情需要注意。具体来说，MapStruct 自动为我们生成了从Employee到EmployeeDTO的映射。 在某些情况下，这是不可能的。例如，假设我们要将Employee模型映射到以下模型： public class EmployeeFullNameDTO { private String fullName; // getter and setter } 在这种情况下，如果我们只是声明从 Employee 列表到 EmployeeFullNameDTO 列表的映射方法，我们将收到如下编译时错误或警告： Warning:(11, 31) java: Unmapped target property: \u0026#34;fullName\u0026#34;. Mapping from Collection element \u0026#34;com.codingman.mapstruct.mappingCollections.model.Employee employee\u0026#34; to \u0026#34;com.codingman.mapstruct.mappingCollections.dto.EmployeeFullNameDTO employeeFullNameDTO\u0026#34;. 基本上，这意味着MapStruct在这种情况下无法为我们自动生成映射 。因此，我们需要手动定义Employee和EmployeeFullNameDTO 之间的映射。 鉴于这些点，让我们手动定义它： @Mapper public interface EmployeeFullNameMapper { List\u0026lt;EmployeeFullNameDTO\u0026gt; map(List\u0026lt;Employee\u0026gt; employees); default EmployeeFullNameDTO map(Employee employee) { EmployeeFullNameDTO employeeInfoDTO = new EmployeeFullNameDTO(); employeeInfoDTO.setFullName(employee.getFirstName() + \u0026#34; \u0026#34; + employee.getLastName()); return employeeInfoDTO; } } 生成的代码将使用我们定义的方法将源List的元素映射到目标List。 这也适用于一般情况。如果我们定义了一个将源元素类型映射到目标元素类型的方法，MapStruct 将使用它。 2.2. 映射集和映射 使用 MapStruct 映射集的工作方式与使用列表相同。例如，假设我们想要将一组Employee实例映射到一组EmployeeDTO实例。 和以前一样，我们需要一个映射器： @Mapper public interface EmployeeMapper { Set\u0026lt;EmployeeDTO\u0026gt; map(Set\u0026lt;Employee\u0026gt; employees); } MapStruct 将生成相应的代码： public class EmployeeMapperImpl implements EmployeeMapper { @Override public Set\u0026lt;EmployeeDTO\u0026gt; map(Set\u0026lt;Employee\u0026gt; employees) { if (employees == null) { return null; } Set\u0026lt;EmployeeDTO\u0026gt; set = new HashSet\u0026lt;EmployeeDTO\u0026gt;(Math.max((int)(employees.size() / .75f ) + 1, 16)); for (Employee employee : employees) { set.add(employeeToEmployeeDTO(employee)); } return set; } protected EmployeeDTO employeeToEmployeeDTO(Employee employee) { if (employee == null) { return null; } EmployeeDTO employeeDTO = new EmployeeDTO(); employeeDTO.setFirstName(employee.getFirstName()); employeeDTO.setLastName(employee.getLastName()); return employeeDTO; } } 这同样适用于地图。假设我们想要将Map\u0026lt;String, Employee\u0026gt;映射到Map\u0026lt;String, EmployeeDTO\u0026gt;。 然后，我们可以按照与之前相同的步骤进行操作： @Mapper public interface EmployeeMapper { Map\u0026lt;String, EmployeeDTO\u0026gt; map(Map\u0026lt;String, Employee\u0026gt; idEmployeeMap); } MapStruct 完成了它的工作： public class EmployeeMapperImpl implements EmployeeMapper { @Override public Map\u0026lt;String, EmployeeDTO\u0026gt; map(Map\u0026lt;String, Employee\u0026gt; idEmployeeMap) { if (idEmployeeMap == null) { return null; } Map\u0026lt;String, EmployeeDTO\u0026gt; map = new HashMap\u0026lt;String, EmployeeDTO\u0026gt;(Math.max((int)(idEmployeeMap.size() / .75f) + 1, 16)); for (java.util.Map.Entry\u0026lt;String, Employee\u0026gt; entry : idEmployeeMap.entrySet()) { String key = entry.getKey(); EmployeeDTO value = employeeToEmployeeDTO(entry.getValue()); map.put(key, value); } return map; } protected EmployeeDTO employeeToEmployeeDTO(Employee employee) { if (employee == null) { return null; } EmployeeDTO employeeDTO = new EmployeeDTO(); employeeDTO.setFirstName(employee.getFirstName()); employeeDTO.setLastName(employee.getLastName()); return employeeDTO; } } 3. 集合映射策略 通常，我们需要映射具有父子关系的数据类型。通常，我们有一个数据类型（父），其字段是另一个数据类型（子）的集合。 对于这种情况，MapStruct 提供了一种方法来选择如何将子项设置或添加到父类型。特别是，@Mapper注释有一个collectionMappingStrategy属性，它可以是ACCESSOR_ONLY、SETTER_PREFERRED、ADDER_PREFERRED或TARGET_IMMUTABLE。 所有这些值都指应将子级设置或添加到父类型的方式。默认值为ACCESSOR_ONLY，这意味着只有访问器可以用于设置子集合。 当Collection字段的设置器不可用但我们有一个加法器时，此选项会派上用场。另一种有用的情况是Collection在父类型上是不可变的。通常，我们会在生成的目标类型中遇到这些情况。 3.1 ACCESSOR_ONLY集合映射策略 让我们举个例子来更好地理解它是如何工作的。 对于我们的示例，让我们创建一个Company类作为我们的映射源： public class Company { private List\u0026lt;Employee\u0026gt; employees; // getter and setter } 我们映射的目标将是一个简单的 DTO： public class CompanyDTO { private List\u0026lt;EmployeeDTO\u0026gt; employees; public List\u0026lt;EmployeeDTO\u0026gt; getEmployees() { return employees; } public void setEmployees(List\u0026lt;EmployeeDTO\u0026gt; employees) { this.employees = employees; } public void addEmployee(EmployeeDTO employeeDTO) { if (employees == null) { employees = new ArrayList\u0026lt;\u0026gt;(); } employees.add(employeeDTO); } } 请注意，我们同时提供了 setter setEmployees和 adder addEmployee。此外，对于加法器，我们负责集合初始化。 现在，假设我们要将Company映射到*CompanyDTO。*然后，和以前一样，我们需要一个映射器： @Mapper(uses = EmployeeMapper.class) public interface CompanyMapper { CompanyDTO map(Company company); } 请注意，我们重用了EmployeeMapper和默认的collectionMappingStrategy。 现在，让我们看一下 MapStruct 生成的代码： public class CompanyMapperImpl implements CompanyMapper { private final EmployeeMapper employeeMapper = Mappers.getMapper(EmployeeMapper.class); @Override public CompanyDTO map(Company company) { if (company == null) { return null; } CompanyDTO companyDTO = new CompanyDTO(); companyDTO.setEmployees(employeeMapper.map(company.getEmployees())); return companyDTO; } } 可以看出，MapStruct使用 setter setEmployees来设置EmployeeDTO实例列表。发生这种情况是因为这里我们使用默认的collectionMappingStrategy， ACCESSOR_ONLY。 此外，MapStruct 在 EmployeeMapper 中找到了一个将List 映射到 *List*的方法并重用了它。 3.2. ADDER_PREFERRED集合映射策略 相反，假设我们使用了 ADDER_PREFERRED作为collectionMappingStrategy： @Mapper(collectionMappingStrategy = CollectionMappingStrategy.ADDER_PREFERRED, uses = EmployeeMapper.class) public interface CompanyMapperAdderPreferred { CompanyDTO map(Company company); } 同样，我们想重用 EmployeeMapper。但是，我们需要先显式添加一个可以将单个 Employee转换为 EmployeeDTO的方法： @Mapper public interface EmployeeMapper { EmployeeDTO map(Employee employee); List map(List employees); Set map(Set employees); Map\u0026lt;String, EmployeeDTO\u0026gt; map(Map\u0026lt;String, Employee\u0026gt; idEmployeeMap); } 这是因为 MapStruct 将使用加法器将EmployeeDTO实例一一添加到目标CompanyDTO实例中**： public class CompanyMapperAdderPreferredImpl implements CompanyMapperAdderPreferred { private final EmployeeMapper employeeMapper = Mappers.getMapper( EmployeeMapper.class ); @Override public CompanyDTO map(Company company) { if ( company == null ) { return null; } CompanyDTO companyDTO = new CompanyDTO(); if ( company.getEmployees() != null ) { for ( Employee employee : company.getEmployees() ) { companyDTO.addEmployee( employeeMapper.map( employee ) ); } } return companyDTO; } } 如果加法器不可用，则将使用设置器。 我们可以在 MapStruct 的参考文档中找到所有集合映射策略的完整描述。 4. 目标集合的实现类型 MapStruct 支持集合接口作为映射方法的目标类型。 在这种情况下，生成的代码中使用了一些默认实现。例如，List的默认实现是ArrayList，从我们上面的示例中可以看出。 我们可以在参考文档中找到 MapStruct 支持的接口的完整列表以及它为每个接口使用的默认实现。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mapstruct_mapping_collections/","tags":[],"title":"使用 MapStruct 映射集合"},{"categories":["Java","Java Collections"],"contents":"1. 简介 在本教程中，我们将讨论如何使用 Java Stream与 Map一起工作的一些示例。值得注意的是，其中一些练习可以使用双向Map数据结构来解决，但我们对函数方法感兴趣。 首先，我们将解释我们将用于处理Maps和Stream的基本思想。然后我们将介绍几个与Maps相关的不同问题以及它们使用Stream*的具体解决方案 。 2. 基本思路 需要注意的主要事情是Stream是可以从Collection轻松获得的元素序列。 映射具有不同的结构，从键到值的映射，没有顺序。但是，这并不意味着我们不能将Map结构转换为不同的序列，从而使我们能够以自然的方式使用 Stream API。 让我们看看从Map获取不同 Collection的方法，然后我们可以将其转换为Stream： Map\u0026lt;String, Integer\u0026gt; someMap = new HashMap\u0026lt;\u0026gt;(); 我们可以得到一组键值对： Set\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; entries = someMap.entrySet(); 我们还可以获取与Map关联的键集： Set\u0026lt;String\u0026gt; keySet = someMap.keySet(); 或者我们可以直接使用一组值： Collection\u0026lt;Integer\u0026gt; values = someMap.values(); 这些都为我们提供了一个入口点，通过从中获取流来处理这些集合： Stream\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; entriesStream = entries.stream(); Stream\u0026lt;Integer\u0026gt; valuesStream = values.stream(); Stream\u0026lt;String\u0026gt; keysStream = keySet.stream(); 3. 使用Stream获取Map的键 3.1 输入数据 假设我们有一个Map： Map\u0026lt;String, String\u0026gt; books = new HashMap\u0026lt;\u0026gt;(); books.put( \u0026#34;978-0201633610\u0026#34;, \u0026#34;Design patterns : elements of reusable object-oriented software\u0026#34;); books.put( \u0026#34;978-1617291999\u0026#34;, \u0026#34;Java 8 in Action: Lambdas, Streams, and functional-style programming\u0026#34;); books.put(\u0026#34;978-0134685991\u0026#34;, \u0026#34;Effective Java\u0026#34;); 我们有兴趣找到名为“Effective Java”的书的 ISBN。 3.2. 检索匹配 由于书名不能存在于我们的 Map中，我们希望能够表明它没有关联的 ISBN。我们可以使用**Optional**来表达： 让我们假设对于这个例子，我们对匹配该标题的书的任何键感兴趣： Optional\u0026lt;String\u0026gt; optionalIsbn = books.entrySet().stream() .filter(e -\u0026gt; \u0026#34;Effective Java\u0026#34;.equals(e.getValue())) .map(Map.Entry::getKey) .findFirst(); assertEquals(\u0026#34;978-0134685991\u0026#34;, optionalIsbn.get()); 让我们分析一下代码。首先，我们从*Map中获取entrySet***，就像我们之前看到的那样。 我们只想考虑以“Effective Java”为标题的条目，所以第一个中间操作将是一个过滤器。 **我们对整个Map条目不感兴趣，而是对每个条目的键感兴趣。**所以下一个链式中间操作就是这样做的：它是一个映射操作，它将生成一个新的流作为输出，它只包含与我们正在寻找的标题匹配的条目的键。 **由于我们只想要一个结果，我们可以应用findFirst()终端操作，它将Stream中的初始值作为Optional对象提供。 让我们看一个标题不存在的情况： Optional\u0026lt;String\u0026gt; optionalIsbn = books.entrySet().stream() .filter(e -\u0026gt; \u0026#34;Non Existent Title\u0026#34;.equals(e.getValue())) .map(Map.Entry::getKey).findFirst(); assertEquals(false, optionalIsbn.isPresent()); 3.3. 检索多个结果 现在让我们改变问题，看看我们如何处理返回多个结果而不是一个。 要返回多个结果，让我们将以下书添加到我们的 Map： books.put(\u0026#34;978-0321356680\u0026#34;, \u0026#34;Effective Java: Second Edition\u0026#34;); 所以现在如果我们查找所有以“Effective Java”开头的书，我们会得到不止一个结果： List\u0026lt;String\u0026gt; isbnCodes = books.entrySet().stream() .filter(e -\u0026gt; e.getValue().startsWith(\u0026#34;Effective Java\u0026#34;)) .map(Map.Entry::getKey) .collect(Collectors.toList()); assertTrue(isbnCodes.contains(\u0026#34;978-0321356680\u0026#34;)); assertTrue(isbnCodes.contains(\u0026#34;978-0134685991\u0026#34;)); 在这种情况下，我们所做的是替换过滤条件来验证Map中的值是否以“Effective Java”开头，而不是比较字符串是否相等。 这次我们收集结果，而不是只选择第一个，并将匹配项放入List中。 4. 使用Stream获取Map的值 现在让我们关注地图的另一个问题。我们不会根据标题获取 ISBN，而是尝试 根据 ISBN 获取标题。 让我们使用原始的Map。我们想查找 ISBN 以“978-0”开头的标题。 List\u0026lt;String\u0026gt; titles = books.entrySet().stream() .filter(e -\u0026gt; e.getKey().startsWith(\u0026#34;978-0\u0026#34;)) .map(Map.Entry::getValue) .collect(Collectors.toList()); assertEquals(2, titles.size()); assertTrue(titles.contains( \u0026#34;Design patterns : elements of reusable object-oriented software\u0026#34;)); assertTrue(titles.contains(\u0026#34;Effective Java\u0026#34;)); 这个解决方案类似于我们之前的一组问题的解决方案；我们流式传输条目集，然后过滤、映射和收集。 和以前一样，如果我们只想返回第一个匹配项，那么在map方法之后我们可以调用findFirst()方法，而不是将所有结果收集到List中。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_maps_streams/","tags":["Java Map","Java Streams"],"title":"使用流处理地图"},{"categories":["Java","Spring","Youtube"],"contents":"15分钟学习Spring Boot和MyBatis   ","permalink":"http://itcodingman.github.io/15_mins_spring_boot_mybatis/","tags":[],"title":"15分钟学习Spring Boot和MyBatis"},{"categories":["Java"],"contents":"1. 概述 在这篇快速文章中，我们将查看java.nio包中的*MappedByteBuffer 。* 该实用程序对于高效的文件读取非常有用。 2. MappedByteBuffer 是如何工作的 当我们加载文件的一个区域时，我们可以将它加载到以后可以访问的特定内存区域。 当我们知道我们需要多次读取文件的内容时，最好优化代价高昂的过程，例如将内容保存在内存中。多亏了这一点，随后对该文件部分的查找将仅转到主存储器，而无需从磁盘加载数据，从而大大减少了延迟。 使用MappedByteBuffer时需要注意的一件事是，当我们处理来自磁盘的非常大的文件时——我们需要确保文件适合内存。 否则，我们可能会填满整个内存，结果会遇到常见的*OutOfMemoryException。*我们可以通过仅加载文件的一部分来克服这个问题——例如基于使用模式。 3. 使用MappedByteBuffer读取文件 假设我们有一个名为fileToRead.txt的文件，其内容如下： This is a content of the file 该文件位于*/resource*目录中，因此我们可以使用以下函数加载它： Path getFileURIFromResources(String fileName) throws Exception { ClassLoader classLoader = getClass().getClassLoader(); return Paths.get(classLoader.getResource(fileName).getPath()); } 要从文件创建MappedByteBuffer，首先我们需要从中创建一个FileChannel。一旦我们创建了我们的通道，我们就可以调用它的map()方法，传入MapMode、我们想要读取的位置以及指定我们想要多少字节的size参数： CharBuffer charBuffer = null; Path pathToRead = getFileURIFromResources(\u0026#34;fileToRead.txt\u0026#34;); try (FileChannel fileChannel (FileChannel) Files.newByteChannel( pathToRead, EnumSet.of(StandardOpenOption.READ))) { MappedByteBuffer mappedByteBuffer = fileChannel .map(FileChannel.MapMode.READ_ONLY, 0, fileChannel.size()); if (mappedByteBuffer != null) { charBuffer = Charset.forName(\u0026#34;UTF-8\u0026#34;).decode(mappedByteBuffer); } } 一旦我们将文件映射到内存映射缓冲区，我们就可以将其中的数据读入CharBuffer。需要注意的重要一点是，虽然我们在调用传递MappedByteBuffer的*decode()*方法时正在读取文件的内容，但我们是从内存中读取的，而不是从磁盘中读取的。因此，读取将非常快。 我们可以断言我们从文件中读取的内容是fileToRead.txt文件的实际内容： assertNotNull(charBuffer); assertEquals( charBuffer.toString(), \u0026#34;This is a content of the file\u0026#34;); 从mappedByteBuffer读取的每个后续都将非常快，因为文件的内容已映射到内存中，并且无需从磁盘中查找数据即可完成读取。 4. 使用MappedByteBuffer写入文件 假设我们想使用MappedByteBuffer API 将一些内容写入文件**fileToWriteTo.txt。为此，我们需要打开FileChannel并在其上调用map()方法，传入FileChannel.MapMode.READ_WRITE。 接下来，我们可以使用 MappedByteBuffer 中的put()方法将CharBuffer的内容保存到文件中： CharBuffer charBuffer = CharBuffer .wrap(\u0026#34;This will be written to the file\u0026#34;); Path pathToWrite = getFileURIFromResources(\u0026#34;fileToWriteTo.txt\u0026#34;); try (FileChannel fileChannel = (FileChannel) Files .newByteChannel(pathToWrite, EnumSet.of( StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.TRUNCATE_EXISTING))) { MappedByteBuffer mappedByteBuffer = fileChannel .map(FileChannel.MapMode.READ_WRITE, 0, charBuffer.length()); if (mappedByteBuffer != null) { mappedByteBuffer.put( Charset.forName(\u0026#34;utf-8\u0026#34;).encode(charBuffer)); } } 我们可以通过读取文件的内容来断言charBuffer的实际内容已写入文件： List\u0026lt;String\u0026gt; fileContent = Files.readAllLines(pathToWrite); assertEquals(fileContent.get(0), \u0026#34;This will be written to the file\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/java_mapped_byte_buffer/","tags":[],"title":"使用 Java"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将回顾Java 16 中引入的Stream::mapMulti方法。我们将编写简单的示例来说明如何使用它。特别是，**我们会看到这个方法类似于Stream::flatMap。**我们将介绍在什么情况下我们更喜欢使用mapMulti而不是flatMap。 请务必查看我们关于Java Streams的文章，以深入了解 Stream API。 2. 方法签名 省略通配符，mapMulti方法可以写得更简洁： \u0026lt;R\u0026gt; Stream\u0026lt;R\u0026gt; mapMulti(BiConsumer\u0026lt;T, Consumer\u0026lt;R\u0026gt;\u0026gt; mapper) 这是一个Stream中间操作。它需要一个BiConsumer功能接口的实现作为参数。BiConsumer的实现采用Stream元素T，如有必要，将其转换为类型R，并调用映射器的Consumer::accept。 在 Java 的mapMulti方法实现中，mapper是一个实现Consumer功能接口的缓冲区。 每次我们调用*Consumer::accept 时，*它都会累积缓冲区中的元素并将它们传递给流管道。 3. 简单实现示例 让我们考虑一个整数列表来执行以下操作： List\u0026lt;Integer\u0026gt; integers = Arrays.asList(1, 2, 3, 4, 5); double percentage = .01; List\u0026lt;Double\u0026gt; evenDoubles = integers.stream() .\u0026lt;Double\u0026gt;mapMulti((integer, consumer) -\u0026gt; { if (integer % 2 == 0) { consumer.accept((double) integer * ( 1 + percentage)); } }) .collect(toList()); 在我们的BiConsumer\u0026lt;T, Consumer\u0026gt; 映射器的 lambda 实现中，我们首先只选择偶数整数，然后我们将百分比指定的数量添加到它们，将结果转换为双精度， 并完成调用consumer.accept。 正如我们之前看到的，消费者只是一个将返回元素传递给流管道的缓冲区。（作为旁注，请注意我们必须使用类型见证*mapMulti作为返回值，否则编译器无法在方法的签名中推断出正确的R类型。）* 这是一对零或一对一的转换，具体取决于元素是奇数还是偶数。 请注意，前面代码示例中的if 语句扮演Stream::filter的角色，并将整数转换为 double，即Stream::map的角色。因此，我们可以使用Stream 的 过滤器和映射来实现相同的结果： List\u0026lt;Integer\u0026gt; integers = Arrays.asList(1, 2, 3, 4, 5); double percentage = .01; List\u0026lt;Double\u0026gt; evenDoubles = integers.stream() .filter(integer -\u0026gt; integer % 2 == 0) .\u0026lt;Double\u0026gt;map(integer -\u0026gt; ((double) integer * ( 1 + percentage))) .collect(toList()); 但是，mapMulti实现更直接，因为我们不需要调用这么多的流中间操作。 另一个优点是mapMulti实现是必要的，让我们可以更自由地进行元素转换。 为了支持int、long和double基本类型，我们有mapMultiToDouble、mapMultiToInt和mapMultiToLong的**mapMulti变体。 例如，我们可以使用mapMultiToDouble来求上一个**List of doubles的总和： List\u0026lt;Integer\u0026gt; integers = Arrays.asList(1, 2, 3, 4, 5); double percentage = .01; double sum = integers.stream() .mapMultiToDouble((integer, consumer) -\u0026gt; { if (integer % 2 == 0) { consumer.accept(integer * (1 + percentage)); } }) .sum(); 4. 更现实的例子 让我们考虑一个Album的集合： public class Album { private String albumName; private int albumCost; private List\u0026lt;Artist\u0026gt; artists; Album(String albumName, int albumCost, List\u0026lt;Artist\u0026gt; artists) { this.albumName = albumName; this.albumCost = albumCost; this.artists = artists; } // ... } 每个专辑都有一个Artist列表： public class Artist { private final String name; private boolean associatedMajorLabels; private List\u0026lt;String\u0026gt; majorLabels; Artist(String name, boolean associatedMajorLabels, List\u0026lt;String\u0026gt; majorLabels) { this.name = name; this.associatedMajorLabels = associatedMajorLabels; this.majorLabels = majorLabels; } // ... } 如果我们想收集艺术家-专辑名称对的列表，我们可以使用mapMulti来实现它： List\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; artistAlbum = albums.stream() .\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; mapMulti((album, consumer) -\u0026gt; { for (Artist artist : album.getArtists()) { consumer.accept(new ImmutablePair\u0026lt;String, String\u0026gt;(artist.getName(), album.getAlbumName())); } }) 对于流中的每个专辑，我们迭代艺术家，创建艺术家专辑名称的 Apache Commons ImmutablePair，并调用 C onsumer::accept。mapMulti的实现会累积消费者接受的元素，并将它们传递给流管道。 这具有一对多转换的效果，其中结果在消费者中累积，但最终被扁平化为新的流。这本质上就是Stream::flatMap所做的，因此我们可以通过以下实现获得相同的结果： List\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; artistAlbum = albums.stream() .flatMap(album -\u0026gt; album.getArtists() .stream() .map(artist -\u0026gt; new ImmutablePair\u0026lt;String, String\u0026gt;(artist.getName(), album.getAlbumName()))) .collect(toList()); 我们看到这两种方法都给出了相同的结果。接下来我们将介绍在哪些情况下使用mapMulti更有利。 5. 何时使用mapMulti而不是flatMap 5.1 用少量元素替换流元素 正如 Java 文档中所述：“用少量（可能为零）的元素替换每个流元素时。使用这种方法避免了为每组结果元素创建一个新的Stream实例的开销，正如flatMap 所要求的那样。 让我们写一个简单的例子来说明这个场景： int upperCost = 9; List\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; artistAlbum = albums.stream() .\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; mapMulti((album, consumer) -\u0026gt; { if (album.getAlbumCost() \u0026lt; upperCost) { for (Artist artist : album.getArtists()) { consumer.accept(new ImmutablePair\u0026lt;String, String\u0026gt;(artist.getName(), album.getAlbumName())); } } }) 对于每张专辑，我们迭代艺术家并累积零个或少数几个艺术家-专辑对，具体取决于专辑的价格与变量upperCost的比较。 使用flatMap完成相同的结果： int upperCost = 9; List\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; artistAlbum = albums.stream() .flatMap(album -\u0026gt; album.getArtists() .stream() .filter(artist -\u0026gt; upperCost \u0026gt; album.getAlbumCost()) .map(artist -\u0026gt; new ImmutablePair\u0026lt;String, String\u0026gt;(artist.getName(), album.getAlbumName()))) .collect(toList()); 我们看到mapMulti的命令式实现更高效——我们不必像使用flatMap的声明性方法那样为每个处理过的元素创建中间流。 5.2. 何时更容易生成结果元素 让我们在Album类中编写一个方法，将所有艺术家-专辑对及其相关的主要标签传递给消费者： public class Album { //...  public void artistAlbumPairsToMajorLabels(Consumer\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; consumer) { for (Artist artist : artists) { if (artist.isAssociatedMajorLabels()) { String concatLabels = artist.getMajorLabels().stream().collect(Collectors.joining(\u0026#34;,\u0026#34;)); consumer.accept(new ImmutablePair\u0026lt;\u0026gt;(artist.getName()+ \u0026#34;:\u0026#34; + albumName, concatLabels)); } } } // ... } 如果艺术家与主要标签有关联，则实现将标签连接成逗号分隔的字符串。然后它创建一对带有标签的艺术家专辑名称并调用 C onsumer::accept。 如果我们想获得所有对的列表，就像使用mapMulti和方法引用Album::artistAlbumPairsToMajorLabels一样简单： List\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; copyrightedArtistAlbum = albums.stream() .\u0026lt;Pair\u0026lt;String, String\u0026gt;\u0026gt; mapMulti(Album::artistAlbumPairsToMajorLabels) .collect(toList()); 我们看到，在更复杂的情况下，我们可以对方法引用进行非常复杂的实现。例如，Java 文档给出了一个使用递归的例子。 通常，使用flatMap复制相同的结果将非常困难。因此，在生成结果元素比在flatMap中以Stream的形式返回它们要容易得多的情况下，我们应该使用mapMulti。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mapmulti/","tags":["Java 16","Java Streams"],"title":"Stream API 中的 mapMulti 指南"},{"categories":["Java Collections"],"contents":"1. 概述 Map是 Java 中最常见的数据结构之一，而String是最常见的 map 键类型之一。默认情况下，此类映射具有区分大小写的键。 在这个简短的教程中，我们将探索不同的Map实现，它们接受String的所有大小写变体作为相同的 key。 2. 使用不区分大小写的键仔细查看地图 让我们更详细地检查我们试图解决的问题。 假设我们有一个包含一个条目的Map\u0026lt;String, Integer\u0026gt; ： 让我们添加下一个条目： map.put(\u0026#34;ABC\u0026#34;, 2); 当使用区分大小写键的Map时，我们将得到两个条目： 但是当使用不区分大小写键的Map时，内容将是： 在接下来的示例中，我们将深入探讨一些流行的Map实现的不区分大小写的实现： TreeMap、HashMap和LinkedHashMap。 3.TreeMap TreeMap是NavigableMap的一个实现，这意味着它总是在插入后根据给定的Comparator对条目进行排序。此外， TreeMap使用比较器来查找插入的键是重复键还是新键。 因此，如果我们提供一个不区分大小写的String Comparator，我们将得到一个不区分大小写的TreeMap。 幸运的是，String已经提供了这个静态Comparator： public static final Comparator \u0026lt;String\u0026gt; CASE_INSENSITIVE_ORDER 我们可以在构造函数中提供： Map\u0026lt;String, Integer\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;(String.CASE_INSENSITIVE_ORDER); treeMap.put(\u0026#34;abc\u0026#34;, 1); treeMap.put(\u0026#34;ABC\u0026#34;, 2); 现在，当我们运行测试时，我们可以看到Map的大小是 1： assertEquals(1, treeMap.size()); 并且值更新为2： assertEquals(2, treeMap.get(\u0026#34;aBc\u0026#34;).intValue()); assertEquals(2, treeMap.get(\u0026#34;ABc\u0026#34;).intValue()); 现在让我们使用相同的String删除条目，但使用另一种情况： treeMap.remove(\u0026#34;aBC\u0026#34;); assertEquals(0, treeMap.size()); 我们应该记住，与提供 O(1) 插入和查找的HashMap相比TreeMap的put和get函数平均花费 O(log n) 时间。 还值得注意的是TreeMap不允许空键。 4. Apache 的CaseInsensitiveMap Apache 的 Commons-Collections是一个非常流行的 Java 库，提供了大量有用的类，其中有CaseInsensitiveMap。 **CaseInsensitiveMap是一个基于哈希的Map，它在添加或检索键之前将它们转换为小写。与TreeMap不同， CaseInsensitiveMap允许插入空 键。 首先我们需要添加*commons-collections4*依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在，我们可以使用CaseInsensitiveMap并添加两个条目： Map\u0026lt;String, Integer\u0026gt; commonsHashMap = new CaseInsensitiveMap\u0026lt;\u0026gt;(); commonsHashMap.put(\u0026#34;abc\u0026#34;, 1); commonsHashMap.put(\u0026#34;ABC\u0026#34;, 2); 当我们测试它时，我们期望得到与之前看到的相同的结果： assertEquals(1, commonsHashMap.size()); assertEquals(2, commonsHashMap.get(\u0026#34;aBc\u0026#34;).intValue()); assertEquals(2, commonsHashMap.get(\u0026#34;ABc\u0026#34;).intValue()); commonsHashMap.remove(\u0026#34;aBC\u0026#34;); assertEquals(0, commonsHashMap.size()); 5. Spring的LinkedCaseInsensitiveMap Spring Core是一个 Spring Framework 模块，它还提供实用程序类，包括LinkedCaseInsensitiveMap。 LinkedCaseInsensitiveMap包装了一个*LinkedHashMap，它是一个基于哈希表和链表的Map 。与LinkedHashMap不同，它不允许插入空键。**LinkedCaseInsensitiveMap保留原始顺序以及键的原始大小写，同时允许在任何情况下调用诸如get和remove之类的函数。** 首先，让我们添加spring-core依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在，我们可以初始化一个新的LinkedCaseInsensitiveMap： Map\u0026lt;String, Integer\u0026gt; linkedHashMap = new LinkedCaseInsensitiveMap\u0026lt;\u0026gt;(); linkedHashMap.put(\u0026#34;abc\u0026#34;, 1); linkedHashMap.put(\u0026#34;ABC\u0026#34;, 2); 添加测试它： assertEquals(1, linkedHashMap.size()); assertEquals(2, linkedHashMap.get(\u0026#34;aBc\u0026#34;).intValue()); assertEquals(2, linkedHashMap.get(\u0026#34;ABc\u0026#34;).intValue()); linkedHashMap.remove(\u0026#34;aBC\u0026#34;); assertEquals(0, linkedHashMap.size()); \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_with_case_insensitive_keys/","tags":["Java Map"],"title":"具有不区分大小写键的 Java 映射"},{"categories":["Java Collections"],"contents":"1. 概述 Map和 HashMap的区别在于第一个是接口，第二个是实现。但是，在本文中，我们将深入挖掘并解释接口为何有用。此外，我们将学习如何使用接口使代码更加灵活，以及为什么我们对同一个接口有不同的实现。 2. 接口的用途 接口是只定义行为的契约。**每个实现特定接口的类都应该履行这个契约。**为了更好地理解它，我们可以举一个现实生活中的例子。想象一辆汽车。每个人心中都会有不同的形象。汽车一词暗示了一些品质和行为。任何具有这些品质的物体都可以称为汽车。这就是为什么我们每个人都想象着一辆不同的汽车。 接口的工作方式相同。地图是定义某些品质和行为的抽象。只有具有所有这些特性的类才能成为Map。 3. 不同的实现 出于同样的原因，我们有不同的汽车型号，我们有不同的*Map接口实现。*所有的实现都有不同的目的。**总体上找不到最佳实现是不可能的。出于某种目的，只有最好的实现。**跑车虽然速度快而且看起来很酷，但它并不是家庭野餐或去家具店旅行的最佳选择。 HashMap是Map接口的最简单实现，并提供基本功能。大多数情况下，此实现涵盖了所有需求。另外两个广泛使用的实现是TreeMap和 LinkedHashMap提供附加功能。 这是一个更详细但不完整的层次结构： 4. 编程到实现 想象一下，我们想在控制台中打印*HashMap*的键和值： public class HashMapPrinter { public void printMap(final HashMap\u0026lt;?, ?\u0026gt; map) { for (final Entry\u0026lt;?, ?\u0026gt; entry : map.entrySet()) { System.out.println(entry.getKey() + \u0026#34; \u0026#34; + entry.getValue()); } } } 这是一个完成这项工作的小班。但是，它包含一个问题。它只能与*HashMap一起使用。* 因此，任何尝试传入Map引用的TreeMap甚至 HashMap方法都将导致编译错误： public class Main { public static void main(String[] args) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); HashMap\u0026lt;String, String\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); TreeMap\u0026lt;String, String\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;(); HashMapPrinter hashMapPrinter = new HashMapPrinter(); hashMapPrinter.printMap(hashMap); // hashMapPrinter.printMap(treeMap); Compile time error // hashMapPrinter.printMap(map); Compile time error  } } 让我们试着理解它为什么会发生。在这两种情况下，编译器都不能确定在这个方法中，不会有任何对HashMap特定方法的调用。 TreeMap位于 Map 实现的不同分支（没有双关语），因此它可能缺少一些在HashMap中定义的方法。 在第二种情况下，尽管*HashMap类型是真正的底层对象，但它被Map接口引用。因此，该对象将只能公开Map中定义的方法，而不能公开HashMap中的方法。* 因此，即使我们的HashMapPrinter是一个非常简单的类，它也太具体了。使用这种方法，我们需要为每个Map实现创建一个特定的打印机。 5. 接口编程 初学者常常对“程序到接口”或“代码对接口”的含义感到困惑。让我们考虑下面的例子，它会更清楚一点。我们将参数的类型更改为可能的最通用类型，即Map： public class MapPrinter { public void printMap(final Map\u0026lt;?, ?\u0026gt; map) { for (final Entry\u0026lt;?, ?\u0026gt; entry : map.entrySet()) { System.out.println(entry.getKey() + \u0026#34; \u0026#34; + entry.getValue()); } } } 正如我们所看到的，实际的实现保持不变，而唯一的变化是参数的类型。这表明该方法没有使用HashMap的任何特定方法。Map接口中已经定义了所有需要的功能，即方法entrySet()。 结果，这个微小的变化产生了巨大的差异。现在，此类可以与任何Map实现一起使用： public class Main { public static void main(String[] args) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); HashMap\u0026lt;String, String\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); TreeMap\u0026lt;String, String\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;(); MapPrinter mapPrinter = new MapPrinter(); mapPrinter.printMap(hashMap); mapPrinter.printMap(treeMap); mapPrinter.printMap(map); } } **接口编码帮助我们创建了一个通用类，可以与Map接口的任何实现一起使用。**这种方法可以消除代码重复并确保我们的类和方法具有明确定义的目的。 6. 在哪里使用接口 总的来说，参数应该是最一般的类型。我们在前面的示例中看到，只需对方法签名进行简单更改就可以改进我们的代码。我们应该采用相同方法的另一个地方是构造函数： public class MapReporter { private final Map\u0026lt;?, ?\u0026gt; map; public MapReporter(final Map\u0026lt;?, ?\u0026gt; map) { this.map = map; } public void printMap() { for (final Entry\u0026lt;?, ?\u0026gt; entry : this.map.entrySet()) { System.out.println(entry.getKey() + \u0026#34; \u0026#34; + entry.getValue()); } } } 此类可以与 Map 的任何实现一起使用，只是因为我们在构造函数中使用了正确的类型。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_vs_hashmap/","tags":["Java Map"],"title":"Java中Map和HashMap的区别"},{"categories":["C++","BiliBili"],"contents":"Visaul Studio Code C++ 安装及使用 Visaul Studio Code C++ 安装及使用 \r","permalink":"http://itcodingman.github.io/vscode_c_install_introduce/","tags":[],"title":"Visaul Studio Code C++ 安装及使用"},{"categories":["Java Collections"],"contents":"1. 概述 在本教程中，我们将学习如何使用原始键和值构建映射。 众所周知，核心 Java Map不允许存储原始键或值。这就是为什么我们将介绍一些提供原始地图实现的外部第三方库。 2. Eclipse 集合 Eclipse Collections是一个高性能的 Java 集合框架。它提供了改进的实现以及一些额外的数据结构，包括几个原始集合。 2.1 可变和不可变映射 让我们创建一个空映射，其中键和值都是原始int。为此，我们将使用IntIntMaps工厂类： MutableIntIntMap mutableIntIntMap = IntIntMaps.mutable.empty(); IntIntMaps工厂类是创建原始地图最方便的方法。它允许我们创建所需地图类型的可变和不可变实例。在我们的示例中，我们创建了IntIntMap的可变实例。同样，我们可以通过简单地将IntIntMaps.mutable静态工厂调用替换为IntIntMaps.immutable来创建不可变实例： ImmutableIntIntMap immutableIntIntMap = IntIntMaps.immutable.empty(); 所以，让我们在可变映射中添加一个键值对： mutableIntIntMap.addToValue(1, 1); 同样，**我们可以使用引用和原始类型键值对创建混合映射。让我们用字符串键和双精度值创建一个映射 ： MutableObjectDoubleMap dObject = ObjectDoubleMaps.mutable.empty(); 在这里，我们使用ObjectDoubleMaps工厂类为MutableObjectDoubleMap创建一个可变实例。 现在让我们添加一些条目： dObject.addToValue(\u0026#34;price\u0026#34;, 150.5); dObject.addToValue(\u0026#34;quality\u0026#34;, 4.4); dObject.addToValue(\u0026#34;stability\u0026#34;, 0.8); 2.2. 原始 API 树 在 Eclipse Collections 中，有一个名为PrimitiveIterable 的基本接口。这是库的每个原始容器的基本接口。所有这些都被命名为 PrimitiveTypeIterable，其中 PrimitiveType可以是Int、Long、Short、Byte、Char、Float、Double或Boolean。 反过来，所有这些基本接口都有它们的XY Map实现树，根据映射是 mutable 还是 immutable 进行划分。例如，对于IntIntMap，我们有MutableIntIntMap 和ImmutableIntIntMap。 最后，正如我们在上面看到的，我们有接口来涵盖原始值和对象值的键和值的各种类型组合。因此，例如，我们可以将IntObjectMap用于具有Object值的原始键或*ObjectIntMap*用于相反的情况。 3. HPPC HPPC是一个面向高性能和内存效率的库。这意味着该库的抽象程度低于其他库。但是，这样做的好处是将内部暴露给有用的低级操作。它提供地图和集合。 3.1 一个简单的例子 让我们首先创建一个具有int键和long值的映射。使用它非常熟悉： IntLongHashMap intLongHashMap = new IntLongHashMap(); intLongHashMap.put(25, 1L); intLongHashMap.put(150, Long.MAX_VALUE); intLongHashMap.put(1, 0L); intLongHashMap.get(150); HPPC 为键和值的所有组合提供映射：  原始键和原始值 原始键和对象类型值 对象类型键和原始值 对象类型的键和值  对象类型映射支持泛型： IntObjectOpenHashMap\u0026lt;BigDecimal\u0026gt; ObjectIntOpenHashMap\u0026lt;LocalDate\u0026gt; 第一个映射有一个原始int键和一个BigDecimal值。第二个地图的键为LocalDate ，其值为int 3.2. 哈希图与散点图 由于传统上实现密钥散列和分布函数的方式，我们在散列密钥时可能会发生冲突。根据密钥的分布方式，这可能会导致大型地图上的性能问题。默认情况下，HPPC 实现了避免此问题的解决方案。 但是，具有更简单分布功能的地图仍有一席之地。**如果映射用作查找表或计数，或者一旦加载它们不需要大量写入操作，**这将非常有用。HHPC 提供散点图以进一步提高性能。 所有 scatter-map 类都保持与地图相同的命名约定，但使用Scatter这个词：  IntScatterSet IntIntScatterMap IntObjectScatterMap  4. 快速实用程序 Fastutil是一个快速而紧凑的框架，它提供特定类型的集合，包括原始类型映射。 4.1 快速示例 类似于 Eclipse Collections 和 HPPC。Fastutil 还提供了原始到原始和原始到对象类型的关联映射。 让我们创建一个int到boolean的映射： Int2BooleanMap int2BooleanMap = new Int2BooleanOpenHashMap(); 现在，让我们添加一些条目： int2BooleanMap.put(1, true); int2BooleanMap.put(7, false); int2BooleanMap.put(4, true); 然后，我们可以从中检索值： boolean value = int2BooleanMap.get(1); 4.2. 就地迭代 实现Iterable接口的标准 JVM 集合通常在每个迭代步骤中创建一个新的临时迭代器对象。对于大量收集，这可能会产生垃圾收集问题。 Fastutil 提供了一种替代方案，可以极大地缓解这种情况： Int2FloatMap map = new Int2FloatMap(); //Add keys here for(Int2FloatMap.Entry e : Fastutil.fastIterable(map)) { //e will be reused on each iteration, so it will be only one object } Fastutil 还提供了fastForeach方法。这将采用Consumer 功能接口并为每个循环执行一个 lambda 表达式： Int2FloatMap map = new Int2FloatMap(); //Add keys here Int2FloatMaps.fastForEach(map , e -\u0026gt; { // e is also reused across iterations }); 这与标准的 Java foreach结构非常相似： Int2FloatMap map = new Int2FloatMap(); //Add keys here map.forEach((key,value) -\u0026gt; { // use each key/value entry }); \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_primitives/","tags":["Java Map"],"title":"Java中的基元映射"},{"categories":["Java Collections"],"contents":"1. 概述 在本教程中，我们将讨论如何使用 Java 的内置类、第三方库和我们的自定义实现来创建一个表示Map中键值关联的Entry对象。 2.使用Java内置类 Java 提供了Map。Entry接口用两个简单的实现来创建一个Entry。让我们来看看它们。 2.1 使用AbstractMap简单输入* SimpleEntry类是 AbstractMap 类中的静态嵌套**类。它提供了两个不同的构造函数来初始化一个实例： AbstractMap.SimpleEntry\u0026lt;String, String\u0026gt; firstEntry = new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); AbstractMap.SimpleEntry\u0026lt;String, String\u0026gt; secondEntry = new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); AbstractMap.SimpleEntry\u0026lt;String, String\u0026gt; thirdEntry = new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(firstEntry); thirdEntry.setValue(\u0026#34;a different value\u0026#34;); assertThat(Stream.of(firstEntry, secondEntry, thirdEntry)) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly( tuple(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;), tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;), tuple(\u0026#34;key1\u0026#34;, \u0026#34;a different value\u0026#34;)); 正如我们在这里看到的，其中一个构造函数接受键和值，而另一个接受一个Entry实例来初始化一个新的Entry实例。 2.2. 使用AbstractMap.SimpleImmutableEntry 就像SimpleEntry 一样，我们可以使用SimpleImmutableEntry创建条目： AbstractMap.SimpleImmutableEntry\u0026lt;String, String\u0026gt; firstEntry = new AbstractMap.SimpleImmutableEntry\u0026lt;\u0026gt;(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); AbstractMap.SimpleImmutableEntry\u0026lt;String, String\u0026gt; secondEntry = new AbstractMap.SimpleImmutableEntry\u0026lt;\u0026gt;(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); AbstractMap.SimpleImmutableEntry\u0026lt;String, String\u0026gt; thirdEntry = new AbstractMap.SimpleImmutableEntry\u0026lt;\u0026gt;(firstEntry); assertThat(Stream.of(firstEntry, secondEntry, thirdEntry)) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly( tuple(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;), tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;), tuple(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;)); 与SimpleEntry 相比，SimpleImmutableEntry不允许我们在初始化Entry实例后更改值。**如果我们尝试更改该值，则会抛出java.lang.UnsupportedOperationException。 2.3. 使用Map.Entry 从版本 9 开始，Java在Map接口中有一个静态方法entry()来创建一个Entry： Map.Entry\u0026lt;String, String\u0026gt; entry = Map.entry(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); assertThat(entry.getKey()).isEqualTo(\u0026#34;key\u0026#34;); assertThat(entry.getValue()).isEqualTo(\u0026#34;value\u0026#34;); 我们需要记住，以这种方式创建的条目也是不可变的，如果我们在初始化后尝试更改值，则会导致java.lang.UnsupportedOperationException 。 3. 第三方库 除了 Java 本身，还有一些流行的库提供了创建条目的好方法。 3.1 使用 Apache Commons-Collections4库 让我们首先包含我们的Maven依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 值得一提的是，除了Entry接口之外，该库还提供了一个名为KeyValue 的接口： Map.Entry\u0026lt;String, String\u0026gt; firstEntry = new DefaultMapEntry\u0026lt;\u0026gt;(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); KeyValue\u0026lt;String, String\u0026gt; secondEntry = new DefaultMapEntry\u0026lt;\u0026gt;(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); KeyValue\u0026lt;String, String\u0026gt; thirdEntry = new DefaultMapEntry\u0026lt;\u0026gt;(firstEntry); KeyValue\u0026lt;String, String\u0026gt; fourthEntry = new DefaultMapEntry\u0026lt;\u0026gt;(secondEntry); firstEntry.setValue(\u0026#34;a different value\u0026#34;); assertThat(firstEntry) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly(\u0026#34;key1\u0026#34;, \u0026#34;a different value\u0026#34;); assertThat(Stream.of(secondEntry, thirdEntry, fourthEntry)) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly( tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;), tuple(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;), tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;)); DefaultMapEntry类提供了三个不同的构造函数。第一个接受键值对，第二个和第三个分别接受Entry和KeyValue的参数类型。 UnmodifiableMapEntry类的行为也相同： Map.Entry\u0026lt;String, String\u0026gt; firstEntry = new UnmodifiableMapEntry\u0026lt;\u0026gt;(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); KeyValue\u0026lt;String, String\u0026gt; secondEntry = new UnmodifiableMapEntry\u0026lt;\u0026gt;(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); KeyValue\u0026lt;String, String\u0026gt; thirdEntry = new UnmodifiableMapEntry\u0026lt;\u0026gt;(firstEntry); KeyValue\u0026lt;String, String\u0026gt; fourthEntry = new UnmodifiableMapEntry\u0026lt;\u0026gt;(secondEntry); assertThat(firstEntry) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); assertThat(Stream.of(secondEntry, thirdEntry, fourthEntry)) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly( tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;), tuple(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;), tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;)); 但是，正如我们从它的名字可以理解的那样，UnmodifiableMapEntry*也不允许我们在初始化后更改值。 3.2. 使用 Google Guava 库 让我们首先包含我们的Maven依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 现在，让我们看看如何使用*immutableEntry()*方法： Map.Entry\u0026lt;String, String\u0026gt; firstEntry = Maps.immutableEntry(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); Map.Entry\u0026lt;String, String\u0026gt; secondEntry = Maps.immutableEntry(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); assertThat(Stream.of(firstEntry, secondEntry)) .extracting(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) .containsExactly( tuple(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;), tuple(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;)); 由于它创建了一个不可变的条目，如果我们尝试更改值，它会抛出java.lang.UnsupportedOperationException。 4.自定义实现 到目前为止，我们已经看到了一些创建Entry实例来表示键值关联的选项。这些类的设计方式必须符合Map接口实现的内部逻辑，例如HashMap。 这意味着只要我们遵守相同的规定，我们就可以创建自己的Entry接口实现。首先，让我们添加一个简单的实现： public class SimpleCustomKeyValue\u0026lt;K, V\u0026gt; implements Map.Entry\u0026lt;K, V\u0026gt; { private final K key; private V value; public SimpleCustomKeyValue(K key, V value) { this.key = key; this.value = value; } // standard getters and setters  // standard equals and hashcode  // standard toString } 最后，让我们看几个用法示例： Map.Entry\u0026lt;String, String\u0026gt; firstEntry = new SimpleCustomKeyValue\u0026lt;\u0026gt;(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); Map.Entry\u0026lt;String, String\u0026gt; secondEntry = new SimpleCustomKeyValue\u0026lt;\u0026gt;(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); secondEntry.setValue(\u0026#34;different value\u0026#34;); Map\u0026lt;String, String\u0026gt; map = Map.ofEntries(firstEntry, secondEntry); assertThat(map) .isEqualTo(ImmutableMap.\u0026lt;String, String\u0026gt;builder() .put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;) .put(\u0026#34;key2\u0026#34;, \u0026#34;different value\u0026#34;) .build()); \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_new_entry/","tags":["Java Map"],"title":"如何在地图中创建新条目"},{"categories":["Java","Spring","Youtube"],"contents":"15分钟学习Spring和MyBatis   ","permalink":"http://itcodingman.github.io/15_mins_spring_mybatis/","tags":[],"title":"15分钟学习Spring和MyBatis"},{"categories":["Java","Java Collections"],"contents":"1. 简介 **在这个快速教程中，我们将演示三种不同的方法来从给定值的映射中检索键。**我们还将讨论各种解决方案的优点和缺点。 要了解更多关于Map界面的信息，您可以查看这篇文章。 2. 一种迭代方法 Java Collections的Map接口提供了一个名为*entrySet()*的方法。它在Set中返回映射的所有条目或键值对。 这个想法是迭代这个条目集并返回值与提供的值匹配的键： public \u0026lt;K, V\u0026gt; K getKey(Map\u0026lt;K, V\u0026gt; map, V value) { for (Entry\u0026lt;K, V\u0026gt; entry : map.entrySet()) { if (entry.getValue().equals(value)) { return entry.getKey(); } } return null; } 但是，可能有多个键指向同一个值。 在这种情况下，如果找到匹配的值，我们将键添加到Set并继续循环。最后，我们返回包含所有所需键的Set ： public \u0026lt;K, V\u0026gt; Set\u0026lt;K\u0026gt; getKeys(Map\u0026lt;K, V\u0026gt; map, V value) { Set\u0026lt;K\u0026gt; keys = new HashSet\u0026lt;\u0026gt;(); for (Entry\u0026lt;K, V\u0026gt; entry : map.entrySet()) { if (entry.getValue().equals(value)) { keys.add(entry.getKey()); } } return keys; } 尽管这是一个非常简单的实现，但即使在几次迭代后找到了所有匹配项，它也会比较所有条目。 3. 一种功能方法 **随着 Java 8 中 Lambda 表达式的引入，我们可以用一种更灵活、更易读的方式来完成它。**我们将条目集转换为Stream并提供 lambda 以仅过滤具有给定值的条目。 然后我们使用 map 方法从过滤的条目中返回一个键流： public \u0026lt;K, V\u0026gt; Stream\u0026lt;K\u0026gt; keys(Map\u0026lt;K, V\u0026gt; map, V value) { return map .entrySet() .stream() .filter(entry -\u0026gt; value.equals(entry.getValue())) .map(Map.Entry::getKey); } **返回流的好处是它可以满足广泛的客户需求。**调用代码可能只需要一个键或所有指向所提供值的键。由于流的评估是惰性的，客户端可以根据其要求控制迭代次数。 此外，客户端可以使用适当的收集器将流转换为任何集合： Stream\u0026lt;String\u0026gt; keyStream1 = keys(capitalCountryMap, \u0026#34;South Africa\u0026#34;); String capital = keyStream1.findFirst().get(); Stream\u0026lt;String\u0026gt; keyStream2 = keys(capitalCountryMap, \u0026#34;South Africa\u0026#34;); Set\u0026lt;String\u0026gt; capitals = keyStream2.collect(Collectors.toSet()); 4. 使用 Apache Commons 集合 如果我们需要非常频繁地为特定地图调用函数，上述想法不会很有帮助。它将不必要地一次又一次地迭代其键集。 在这种情况下，维护另一个值到键的映射会更有意义，因为检索值的键需要恒定的时间。 Apache的Commons Collections库提供了一个名为BidiMap的双向地图。它有一个名为*getKey()*的方法 ，用于检索给定值的键： BidiMap\u0026lt;String, String\u0026gt; capitalCountryMap = new DualHashBidiMap\u0026lt;\u0026gt;(); capitalCountryMap.put(\u0026#34;Berlin\u0026#34;, \u0026#34;Germany\u0026#34;); capitalCountryMap.put(\u0026#34;Cape Town\u0026#34;, \u0026#34;South Africa\u0026#34;); String capitalOfGermany = capitalCountryMap.getKey(\u0026#34;Germany\u0026#34;); 但是，BidiMap在其键和值之间强加了 1:1 的关系。如果我们尝试将值已存在于Map中的键值对放入，它会删除旧条目。换句话说，它根据值更新键。 此外，它需要更多的内存来保存反向映射。 本教程中有关如何使用BidiMap的更多详细信息。 5. 使用谷歌Guava 我们可以使用 Google 开发的 Guava 中的另一个双向Map ，称为BiMap 。**该类提供了一个名为*inverse()*的方法来获取 value-key Map或 reverse Map以根据给定值获取键： HashBiMap\u0026lt;String, String\u0026gt; capitalCountryMap = HashBiMap.create(); capitalCountryMap.put(\u0026#34;Berlin\u0026#34;, \u0026#34;Germany\u0026#34;); capitalCountryMap.put(\u0026#34;Cape Town\u0026#34;, \u0026#34;South Africa\u0026#34;); String capitalOfGermany = capitalCountryMap.inverse().get(\u0026#34;Germany\u0026#34;); 和BidiMap一样，BiMap也不允许多个键引用同一个值。如果我们尝试进行 这样的尝试，它 会抛出 java.lang.IllegalArgumentException。 不用说，BiMap也使用了大量的内存，因为它必须在里面存储逆映射。如果您有兴趣了解有关BiMap的更多信息，可以查看本教程。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_key_from_value/","tags":["Java Map"],"title":"从 Java 映射中获取值的键"},{"categories":["Java","Java Collections"],"contents":"1. 概述 在这个简短的教程中，我们将研究检查Map中是否存在键的方法 。 具体来说，我们将重点关注containsKey和 get。 2.包含键 如果我们看一下Map#containsKey的 JavaDoc：   如果此映射包含指定键的映射，则返回 true  我们可以看到，这种方法非常适合做我们想做的事情。 让我们创建一个非常简单的地图并使用containsKey验证其内容： @Test public void whenKeyIsPresent_thenContainsKeyReturnsTrue() { Map\u0026lt;String, String\u0026gt; map = Collections.singletonMap(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); assertTrue(map.containsKey(\u0026#34;key\u0026#34;)); assertFalse(map.containsKey(\u0026#34;missing\u0026#34;)); } 简单地说， containsKey告诉我们地图是否包含该键。 3. get 现在，get有时也可以工作，但它带有一些包袱，这取决于Map实现是否支持空值。 再次查看 Map的 JavaDoc，这次是 Map#put，我们看到它只会抛出 NullPointerException：  如果指定的键或值是 null并且此映射不允许 null 键或值  由于Map的某些实现可以具有空值（例如HashMap），因此即使存在键， get也可能返回 空值。 因此，如果我们的目标是查看键是否具有值，那么 get将起作用： @Test public void whenKeyHasNullValue_thenGetStillWorks() { Map\u0026lt;String, String\u0026gt; map = Collections.singletonMap(\u0026#34;nothing\u0026#34;, null); assertTrue(map.containsKey(\u0026#34;nothing\u0026#34;)); assertNull(map.get(\u0026#34;nothing\u0026#34;)); } 但是，如果我们只是想检查密钥是否存在，那么我们应该坚持使用containsKey。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_key_exists/","tags":["Java Map"],"title":"如何检查映射中是否存在键"},{"categories":["Python","BiliBili"],"contents":"jupyter notebook安装及使用 Jupyter Notebook是以网页的形式打开，可以在网页页面中直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示的程序。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。 \r","permalink":"http://itcodingman.github.io/jupyter_notebook_install_introduce/","tags":[],"title":"jupyter notebook安装及使用"},{"categories":["Java Collections"],"contents":"1. 简介 在本教程中，我们将学习如何在HashMap中使用字节数组作为键。由于HashMap的工作原理，不幸的是，我们不能直接这样做。我们将调查为什么会这样，并研究解决该问题的几种方法。 2. 为HashMap设计一个好的key 2.1 HashMap 的工作原理 HashMap使用散列机制来存储和检索自身的值。**当我们调用*put(key, value)方法时，HashMap会根据 key 的hashCode()*方法计算哈希码。**此哈希用于标识最终存储该值的存储桶： public V put(K key, V value) { if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; } *当我们使用get(key)方法检索一个值时，会涉及到类似的过程。密钥用于计算哈希码，然后找到存储桶。**然后使用equals()*方法检查存储桶中的每个条目是否相等。**最后，返回匹配条目的值： public V get(Object key) { if (key == null) return getForNullKey(); int hash = hash(key.hashCode()); for (Entry e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || key.equals(k))) return e.value; } return null; } 2.2. equals() 和*hashCode()*之间的约定 equals和hashCode方法都有应遵守的约定。在HashMaps的上下文中，一个方面特别重要：彼此相等的对象必须返回相同的hashCode。但是，返回相同hashCode的对象不需要彼此相等。这就是为什么我们可以在一个桶中存储多个值。 2.3. 不变性 **HashMap中键的hashCode不应该改变。**虽然这不是强制性的，但强烈建议密钥是不可变的。如果一个对象是不可变的，它的hashCode就没有机会改变，不管hashCode方法的实现如何。 默认情况下，哈希是根据对象的所有字段计算的。如果我们想要一个可变键，我们需要重写hashCode方法以确保在其计算中不使用可变字段。为了维护合约，我们还需要更改equals方法。 2.4. 有意义的平等 为了能够成功地从映射中检索值，相等性必须是有意义的。在大多数情况下，我们需要能够创建一个新的键对象，该对象将与映射中的某个现有键相等。出于这个原因，对象标识在这种情况下不是很有用。 这也是为什么不能使用原始字节数组的主要原因。Java 中的数组使用对象标识来确定相等性。如果我们以字节数组为键创建HashMap，我们将能够仅使用完全相同的数组对象来检索值。 让我们创建一个以字节数组为键的简单实现： byte[] key1 = {1, 2, 3}; byte[] key2 = {1, 2, 3}; Map\u0026lt;byte[], String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(key1, \u0026#34;value1\u0026#34;); map.put(key2, \u0026#34;value2\u0026#34;); 我们不仅有两个具有几乎相同键的条目，而且我们无法使用新创建的具有相同值的数组检索任何内容： String retrievedValue1 = map.get(key1); String retrievedValue2 = map.get(key2); String retrievedValue3 = map.get(new byte[]{1, 2, 3}); assertThat(retrievedValue1).isEqualTo(\u0026#34;value1\u0026#34;); assertThat(retrievedValue2).isEqualTo(\u0026#34;value2\u0026#34;); assertThat(retrievedValue3).isNull(); 3. 使用现有容器 除了字节数组，我们可以使用现有的类，其相等性实现基于内容，而不是对象标识。 3.1 String 字符串相等基于字符数组的内容： public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = count; if (n == anotherString.count) { char v1[] = value; char v2[] = anotherString.value; int i = offset; int j = anotherString.offset; while (n-- != 0) { if (v1[i++] != v2[j++]) return false; } return true; } } return false; } String也是不可变的，基于字节数组创建String相当简单。我们可以使用Base64方案轻松地对字符串进行编码和解码： String key1 = Base64.getEncoder().encodeToString(new byte[]{1, 2, 3}); String key2 = Base64.getEncoder().encodeToString(new byte[]{1, 2, 3}); 现在我们可以创建一个以字符串为键而不是字节数组的HashMap 。我们将以类似于上一个示例的方式将值放入M​​ap中： Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(key1, \u0026#34;value1\u0026#34;); map.put(key2, \u0026#34;value2\u0026#34;); 然后我们可以从地图中检索一个值。对于这两个键，我们将获得相同的第二个值。我们还可以检查键是否真正彼此相等： String retrievedValue1 = map.get(key1); String retrievedValue2 = map.get(key2); assertThat(key1).isEqualTo(key2); assertThat(retrievedValue1).isEqualTo(\u0026#34;value2\u0026#34;); assertThat(retrievedValue2).isEqualTo(\u0026#34;value2\u0026#34;); 3.2. List 与String类似，List#equals方法将检查其每个元素的相等性。如果这些元素具有合理的equals()方法并且是不可变的，则List将作为HashMap键正常工作。我们只需要确保我们使用的是不可变的List实现： List\u0026lt;Byte\u0026gt; key1 = ImmutableList.of((byte)1, (byte)2, (byte)3); List\u0026lt;Byte\u0026gt; key2 = ImmutableList.of((byte)1, (byte)2, (byte)3); Map\u0026lt;List\u0026lt;Byte\u0026gt;, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(key1, \u0026#34;value1\u0026#34;); map.put(key2, \u0026#34;value2\u0026#34;); assertThat(map.get(key1)).isEqualTo(map.get(key2)); 请注意，字节对象的列表将比字节基元数组占用更多的内存。因此，该解决方案虽然方便，但在大多数情况下并不可行。 4. 实现自定义容器 我们还可以实现自己的包装器来完全控制哈希码计算和相等性。这样，我们可以确保解决方案快速且不会占用大量内存。 让我们创建一个具有最终私有字节数组字段的类。它没有 setter，它的 getter 将制作一个防御性副本以确保完全不变性： public final class BytesKey { private final byte[] array; public BytesKey(byte[] array) { this.array = array; } public byte[] getArray() { return array.clone(); } } 我们还需要实现自己的equals和hashCode方法。幸运的是，我们可以使用Arrays实用程序类来完成这两个任务： @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; BytesKey bytesKey = (BytesKey) o; return Arrays.equals(array, bytesKey.array); } @Override public int hashCode() { return Arrays.hashCode(array); } 最后，我们可以将包装器用作HashMap中的键： BytesKey key1 = new BytesKey(new byte[]{1, 2, 3});\rBytesKey key2 = new BytesKey(new byte[]{1, 2, 3});\rMap\u0026lt;BytesKey, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;();\rmap.put(key1, \u0026#34;value1\u0026#34;);\rmap.put(key2, \u0026#34;value2\u0026#34;); 然后，我们可以使用任何一个声明的键来检索第二个值，或者我们可以使用动态创建的一个： String retrievedValue1 = map.get(key1); String retrievedValue2 = map.get(key2); String retrievedValue3 = map.get(new BytesKey(new byte[]{1, 2, 3})); assertThat(retrievedValue1).isEqualTo(\u0026#34;value2\u0026#34;); assertThat(retrievedValue2).isEqualTo(\u0026#34;value2\u0026#34;); assertThat(retrievedValue3).isEqualTo(\u0026#34;value2\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_key_byte_array/","tags":["Java Map"],"title":"在 Java 中使用字节数组作为映射键"},{"categories":["Java Collections"],"contents":"1. 概述 我们经常使用映射来存储键值对的集合。然后，在某些时候，我们经常需要遍历它们。 在本教程中，我们将比较不同的地图迭代方法，突出显示何时使用Map.Entry可能是有益的。然后，我们将学习如何 使用Map.Entry创建一个元组。最后，我们将创建一个有序的元组列表。 2.优化Map迭代 假设我们有一个以作者姓名为键的书名地图： Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;Robert C. Martin\u0026#34;, \u0026#34;Clean Code\u0026#34;); map.put(\u0026#34;Joshua Bloch\u0026#34;, \u0026#34;Effective Java\u0026#34;); 让我们比较从地图中获取所有键和值的两种方法。 2.1 使用Map.keySet 首先，考虑以下几点： for (String key : bookMap.keySet()) { System.out.println(\u0026#34;key: \u0026#34; + key + \u0026#34; value: \u0026#34; + bookMap.get(key)); } 在这里，循环遍历keySet。对于每个键，我们使用Map.get获取相应的值。虽然这是使用映射中所有条目的明显方式，但它需要对每个条目进行两次操作- 一个获取next，另一个使用get查找值。 如果我们只需要映射中的键，keySet是一个不错的选择。但是，有一种更快的方法可以同时获取键和值。 2.2. 使用 Map.entrySet代替 让我们重写我们的迭代以使用entrySet： for (Map.Entry\u0026lt;String, String\u0026gt; book: bookMap.entrySet()) { System.out.println(\u0026#34;key: \u0026#34; + book.getKey() + \u0026#34; value: \u0026#34; + book.getValue()); } 在这个例子中，我们的循环在Map.Entry对象的集合上。由于 Map.Entry将键和值都存储在一个类中，因此我们在一个操作中获取它们。 相同的规则适用于使用 Java 8 流操作。在entrySet上进行流式传输并使用 Entry对象更有效，并且需要的代码更少。 3. 使用元组 元组是具有固定数量和顺序的元素的数据结构。我们可以认为 Map.Entry是一个存储两个元素的元组——一个键和一个值。但是，由于 Map.Entry是一个接口，我们需要一个实现类。在本节中，我们将探讨 JDK 提供的一种实现：AbstractMap.SimpleEntry。 3.1 创建一个元组 首先，考虑Book类： public class Book { private String title; private String author; public Book(String title, String author) { this.title = title; this.author = author; } ... 接下来，让我们创建一个Map.Entry元组，其中 ISBN 为键，Book对象为值： Map.Entry\u0026lt;String, Book\u0026gt; tuple; 最后，让我们用AbstractMap.SimpleEntry实例化我们的元组 ： tuple = new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(\u0026#34;9780134685991\u0026#34;, new Book(\u0026#34;Effective Java 3d Edition\u0026#34;, \u0026#34;Joshua Bloch\u0026#34;)); 3.2. 创建元组的有序列表 使用元组时，将它们作为有序列表通常很有用。 首先，我们将定义我们的元组列表： List\u0026lt;Map.Entry\u0026lt;String, Book\u0026gt;\u0026gt; orderedTuples = new ArrayList\u0026lt;\u0026gt;(); 其次，让我们在列表中添加一些条目： orderedTuples.add(new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(\u0026#34;9780134685991\u0026#34;, new Book(\u0026#34;Effective Java 3d Edition\u0026#34;, \u0026#34;Joshua Bloch\u0026#34;))); orderedTuples.add(new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(\u0026#34;9780132350884\u0026#34;, new Book(\u0026#34;Clean Code\u0026#34;,\u0026#34;Robert C Martin\u0026#34;))); 3.3. 与Map比较 为了与Map比较差异，让我们添加一个新条目，其中包含一个已经存在的键： orderedTuples.add(new AbstractMap.SimpleEntry\u0026lt;\u0026gt;(\u0026#34;9780132350884\u0026#34;, new Book(\u0026#34;Clean Code\u0026#34;, \u0026#34;Robert C Martin\u0026#34;))); 其次，我们将遍历我们的列表，显示所有的键和值： for (Map.Entry\u0026lt;String, Book\u0026gt; tuple : orderedTuples) { System.out.println(\u0026#34;key: \u0026#34; + tuple.getKey() + \u0026#34; value: \u0026#34; + tuple.getValue()); } 最后，让我们看看输出： key: 9780134685991 value: Book{title=\u0026#39;Effective Java 3d Edition\u0026#39;, author=\u0026#39;Joshua Bloch\u0026#39;} key: 9780132350884 value: Book{title=\u0026#39;Clean Code\u0026#39;, author=\u0026#39;Robert C Martin\u0026#39;} key: 9780132350884 value: Book{title=\u0026#39;Clean Code\u0026#39;, author=\u0026#39;Robert C Martin\u0026#39;} 请注意，我们可以有重复的键，这与基本的 Map不同，其中每个键都必须是唯一的。这是因为我们使用List实现来存储SimpleEntry对象，这意味着所有对象都是相互独立的。 3.4. Entry对象列表 我们应该注意， Entry的目的不是充当通用元组。库类通常为此目的提供一个通用的Pair类。 但是，我们可能会发现在为Map准备数据或从中提取数据时，我们需要临时处理条目列表 。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_entry/","tags":["Java Map"],"title":"使用 Map.Entry Java 类"},{"categories":["Java Collections"],"contents":"1. 概述 在本教程中，我们将讨论Java中Map接口的三个方法keySet()、*entrySet()和values() 。*这些方法分别用于检索一组键、一组键值映射和一组值。 2. Map初始化 虽然我们可以在任何实现Map接口的类（如*HashMap、 TreeMap和LinkedHashMap* ）上使用这些方法，但我们将在此处使用HashMap。 让我们创建并初始化一个HashMap，它的键是String类型，值是Integer类型： Map\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;one\u0026#34;, 1); map.put(\u0026#34;two\u0026#34;, 2); 3. *keySet()*方法 keySet()方法返回Map中包含的键集合。 让我们将方法keySet()应用于Map并将其存储在Set变量actualValues 中： Set\u0026lt;String\u0026gt; actualValues = map.keySet(); 现在，让我们确认返回的Set的大小为 2： assertEquals(2, actualValues.size()); 此外，我们可以看到返回的Set包含Map的键： assertTrue(actualValues.contains(\u0026#34;one\u0026#34;)); assertTrue(actualValues.contains(\u0026#34;two\u0026#34;)); 4. *entrySet()*方法 **entrySet()方法返回一组键值映射。**该方法不带任何参数，并具有 Map.Entry 的返回类型Set。 让我们将方法entrySet()应用于Map： Set\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; actualValues = map.entrySet(); 正如我们所见，actualValues是一组Map.Entry对象。 Map.Entry是一个包含键和值的静态接口。在内部，它有两个实现—— AbstractMap.SimpleEntry和AbstractMap.SimpleImmutableEntry。 和之前一样，让我们确认返回的Set的大小为 2： assertEquals(2, actualValues.size()); 此外，我们可以看到返回的Set包含**Map的键值条目： assertTrue(actualValues.contains(new SimpleEntry\u0026lt;\u0026gt;(\u0026#34;one\u0026#34;, 1))); assertTrue(actualValues.contains(new SimpleEntry\u0026lt;\u0026gt;(\u0026#34;two\u0026#34;, 2))); 在这里，我们为我们的测试选择了接口Map.Entry的**AbstractMap.SimpleEntry实现。 5. *values()*方法 *values()方法返回Map中包含的值的集合。**该方法不接受任何参数，并且返回类型为Collection。 让我们将方法values()应用于Map并将其存储在Collection变量actualValues 中： Collection\u0026lt;Integer\u0026gt; actualValues = map.values(); 现在，让我们验证返回的Collection 的大小： assertEquals(2, actualValues.size()); 此外，我们可以看到返回的Set包含Map的值： assertTrue(actualValues.contains(1)); assertTrue(actualValues.contains(2)); \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_entries_methods/","tags":["Java Map"],"title":"Java Map – keySet() vs. entrySet() vs. values() 方法"},{"categories":["Guava","Java","Java Collections"],"contents":"1. 概述 在本教程中，我们将探索处理具有重复键的Map的可用选项，或者换句话说，允许为单个键存储多个值的Map 。 2. 标准Map Java 有多种接口Map的实现，每一种都有自己的特殊性。 但是，现有的 Java 核心 Map 实现中没有一个允许Map处理单个 key 的多个值。 如我们所见，如果我们尝试为同一个键插入两个值，则将存储第二个值，而删除第一个值。 *它也将被返回（通过put(K key, V value)*方法的每个正确实现）： Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); assertThat(map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;)).isEqualTo(null); assertThat(map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;)).isEqualTo(\u0026#34;value1\u0026#34;); assertThat(map.get(\u0026#34;key1\u0026#34;)).isEqualTo(\u0026#34;value2\u0026#34;); 那么我们如何才能实现所需的行为呢？ 3. Collection Value 显然，对我们Map的每个值使用Collection就可以完成这项工作： Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); map.put(\u0026#34;key1\u0026#34;, list); map.get(\u0026#34;key1\u0026#34;).add(\u0026#34;value1\u0026#34;); map.get(\u0026#34;key1\u0026#34;).add(\u0026#34;value2\u0026#34;); assertThat(map.get(\u0026#34;key1\u0026#34;).get(0)).isEqualTo(\u0026#34;value1\u0026#34;); assertThat(map.get(\u0026#34;key1\u0026#34;).get(1)).isEqualTo(\u0026#34;value2\u0026#34;); 但是，这种冗长的解决方案有多个缺点并且容易出错。这意味着我们需要为每个值实例化一个Collection，在添加或删除一个值之前检查它的存在，当没有值时手动删除它等等。 从 Java 8 开始，我们可以利用*compute()*方法并对其进行改进： Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.computeIfAbsent(\u0026#34;key1\u0026#34;, k -\u0026gt; new ArrayList\u0026lt;\u0026gt;()).add(\u0026#34;value1\u0026#34;); map.computeIfAbsent(\u0026#34;key1\u0026#34;, k -\u0026gt; new ArrayList\u0026lt;\u0026gt;()).add(\u0026#34;value2\u0026#34;); assertThat(map.get(\u0026#34;key1\u0026#34;).get(0)).isEqualTo(\u0026#34;value1\u0026#34;); assertThat(map.get(\u0026#34;key1\u0026#34;).get(1)).isEqualTo(\u0026#34;value2\u0026#34;); 虽然这是值得知道的，但我们应该避免它，除非有很好的理由不这样做，比如限制性的公司政策阻止我们使用第三方库。 否则，在编写我们自己的自定义Map实现并重新发明轮子之前，我们应该在开箱即用的几个可用选项中进行选择。 4. Apache Commons 集合 像往常一样，Apache为我们的问题提供了解决方案。 让我们从导入最新版本的Common Collections开始（从现在开始 CC）： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4.1 MultiMap org.apache.commons.collections4。*MultiMap*接口定义了一个 Map，其中包含针对每个键的值的集合。 它由*org.apache.commons.collections4.map 实现。MultiValueMap*类，它自动处理引擎盖下的大部分样板： MultiMap\u0026lt;String, String\u0026gt; map = new MultiValueMap\u0026lt;\u0026gt;(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;key1\u0026#34;)) .contains(\u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;); 虽然此类从 CC 3.2 开始可用，但它不是线程安全的，并且在 CC 4.1 中已被弃用。只有在无法升级到较新版本时才应使用它。 4.2. 多值映射 MultiMap的继承者是*org.apache.commons.collections4。多值映射*接口。它有多种实现可供使用。 让我们看看如何将我们的多个值存储到ArrayList中，它保留重复项： MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;key1\u0026#34;)) .containsExactly(\u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;, \u0026#34;value2\u0026#34;); 或者，我们可以使用HashSet来删除重复项： MultiValuedMap\u0026lt;String, String\u0026gt; map = new HashSetValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;key1\u0026#34;)) .containsExactly(\u0026#34;value1\u0026#34;); 上述两种实现都不是线程安全的。 让我们看看如何使用UnmodifiableMultiValuedMap装饰器使它们不可变： @Test(expected = UnsupportedOperationException.class) public void givenUnmodifiableMultiValuedMap_whenInserting_thenThrowingException() { MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); MultiValuedMap\u0026lt;String, String\u0026gt; immutableMap = MultiMapUtils.unmodifiableMultiValuedMap(map); immutableMap.put(\u0026#34;key1\u0026#34;, \u0026#34;value3\u0026#34;); } 5. Guava Multimap Guava 是 Java API 的 Google 核心库。 让我们从在我们的项目中导入 Guava 开始： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;31.0.1-jre\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Guava 从一开始就遵循了多种实现的路径。 最常见的是*com.google.common.collect。ArrayListMultimap，它为每个值使用由ArrayList支持的HashMap ：* Multimap\u0026lt;String, String\u0026gt; map = ArrayListMultimap.create(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;key1\u0026#34;)) .containsExactly(\u0026#34;value2\u0026#34;, \u0026#34;value1\u0026#34;); 与往常一样，我们应该更喜欢 Multimap 接口的不可变实现：com.google.common.collect。ImmutableListMultimap和com.google.common.collect。不可变集多映射。 5.1 通用Map实现 当我们需要一个特定的Map实现时，首先要做的是检查它是否存在，因为可能 Guava 已经实现了它。 例如，我们可以使用*com.google.common.collect。LinkedHashMultimap*，保留键和值的插入顺序： Multimap\u0026lt;String, String\u0026gt; map = LinkedHashMultimap.create(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value3\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;key1\u0026#34;)) .containsExactly(\u0026#34;value3\u0026#34;, \u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;); 或者，我们可以使用*com.google.common.collect。TreeMultimap*，它以自然顺序迭代键和值： Multimap\u0026lt;String, String\u0026gt; map = TreeMultimap.create(); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value3\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;key1\u0026#34;, \u0026#34;value2\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;key1\u0026#34;)) .containsExactly(\u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;, \u0026#34;value3\u0026#34;); 5.2. 锻造我们的自定义MultiMap 许多其他实现是可用的。 但是，我们可能想要装饰尚未实现的Map或List 。 幸运的是，Guava 有一个工厂方法允许我们这样做：Multimap.newMultimap()。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_duplicate_keys/","tags":["Java Map"],"title":"如何在 Java 中的地图中存储重复的键？"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将简要介绍 Java 8 中引入 的Map接口的新默认方法computeIfAbsent 。 具体来说，我们将看看它的签名、用法以及它如何处理不同的情况。 2. Map.computeIfAbsent 方法 让我们从查看computeIfAbsent的签名开始： default V computeIfAbsent(K key, Function\u0026lt;? super K, ? extends V\u0026gt; mappingFunction) computeIfAbsent方法有 两个参数。第一个参数是key，第二个参数是*mappingFunction。*重要的是要知道只有在映射不存在时才会调用映射函数。 2.1 与非空值相关的键 首先，它检查密钥是否存在于地图中。如果键存在并且非空值与键相关，则返回该值： Map\u0026lt;String, Integer\u0026gt; stringLength = new HashMap\u0026lt;\u0026gt;(); stringLength.put(\u0026#34;John\u0026#34;, 5); assertEquals((long)stringLength.computeIfAbsent(\u0026#34;John\u0026#34;, s -\u0026gt; s.length()), 5); 正如我们所见，*键“John”*存在一个非空映射，它返回值 5。如果使用我们的映射函数，我们希望该函数返回 4 的长度。 2.2. 使用映射函数计算值 此外，如果映射中不存在该键或空值与该键相关，则它会尝试使用给定的mappingFunction计算该值。此外，除非计算值为空，否则它将计算值输入到地图中。 我们看一下computeIfAbsent方法中mappingFunction的用法 ： Map\u0026lt;String, Integer\u0026gt; stringLength = new HashMap\u0026lt;\u0026gt;(); assertEquals((long)stringLength.computeIfAbsent(\u0026#34;John\u0026#34;, s -\u0026gt; s.length()), 4); assertEquals((long)stringLength.get(\u0026#34;John\u0026#34;), 4); 由于键“John”不存在，它通过将键作为参数传递给mappingFunction来计算值。 2.3. 映射函数返回null 此外，如果mappingFunction返回null，则映射不记录映射： Map\u0026lt;String, Integer\u0026gt; stringLength = new HashMap\u0026lt;\u0026gt;(); assertEquals(stringLength.computeIfAbsent(\u0026#34;John\u0026#34;, s -\u0026gt; null), null); assertNull(stringLength.get(\u0026#34;John\u0026#34;)); 2.4. 映射函数抛出异常 最后，如果mappingFunction抛出未经检查的异常，则重新抛出异常，map不记录映射： @Test(expected = RuntimeException.class) public void whenMappingFunctionThrowsException_thenExceptionIsRethrown() { Map\u0026lt;String, Integer\u0026gt; stringLength = new HashMap\u0026lt;\u0026gt;(); stringLength.computeIfAbsent(\u0026#34;John\u0026#34;, s -\u0026gt; { throw new RuntimeException(); }); } 我们看到mappingFunction抛出了一个RuntimeException，它会传播回computeIfAbsent方法。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_map_computeifabsent/","tags":["Java Map"],"title":"Map.computeIfAbsent() 方法"},{"categories":["Java","Youtube"],"contents":"40分钟学习MyBatis   ","permalink":"http://itcodingman.github.io/40_mins_mybatis/","tags":[],"title":"40分钟学习MyBatis"},{"categories":["DevOps","Java"],"contents":"1. 简介 Java 管理扩展 (JMX) 框架是在 Java 1.5 中引入的，并且从一开始就在 Java 开发人员社区中得到广泛接受。 它为本地或远程管理 Java 应用程序提供了一个易于配置、可扩展、可靠且或多或少友好的基础架构。该框架引入了用于实时管理应用程序的 MBean 概念。 本文是初学者创建和设置基本 MBean 并通过 JConsole 管理它的分步指南。 2. JMX架构 JMX 架构遵循三层方法：  **仪表层：**向 JMX 代理注册的 MBean，通过它管理资源 **JMX 代理层：**核心组件（MbeanServer），维护托管 MBean 的注册表并提供访问它们的接口 **远程管理层：**通常是客户端工具，如 JConsole  3. 创建 MBean 类 在创建 MBean 时，我们必须遵守一个特定的设计模式。模型 MBean 类必须实现具有以下名称的接口：“模型类名称”加上 MBean。 所以让我们定义我们的 MBean 接口和实现它的类： public interface GameMBean { public void playFootball(String clubName); public String getPlayerName(); public void setPlayerName(String playerName); } public class Game implements GameMBean { private String playerName; @Override public void playFootball(String clubName) { System.out.println( this.playerName + \u0026#34; playing football for \u0026#34; + clubName); } @Override public String getPlayerName() { System.out.println(\u0026#34;Return playerName \u0026#34; + this.playerName); return playerName; } @Override public void setPlayerName(String playerName) { System.out.println(\u0026#34;Set playerName to value \u0026#34; + playerName); this.playerName = playerName; } } Game类覆盖了父接口的playFootball ()方法。除此之外，该类还有一个成员变量playerName和 getter/setter。 请注意，getter/setter 也在父接口中声明。 4. 使用 JMX 代理进行检测 JMX 代理是本地或远程运行的实体，它们提供对向它们注册的 MBean 的管理访问。 让我们使用PlatformMbeanServer ——JMX 代理的核心组件，并用它注册Game MBean。 我们将使用另一个实体*——ObjectName e——向**PlatformMbeanServer注册Game*类实例；这是一个由两部分组成的字符串：  domain : 可以是任意字符串，但根据 MBean 命名约定，它应该有 Java 包名（避免命名冲突） **key：**以逗号分隔的“ key=value ”对列表  在本例中，我们将使用：“com.codingman.tutorial:type=basic,name=game”。 我们将从工厂类java.lang.management.ManagementFactory 中获取MBeanServer 。 然后我们将使用创建的ObjectName 注册模型 MBean： try { ObjectName objectName = new ObjectName(\u0026#34;com.codingman.tutorial:type=basic,name=game\u0026#34;); MBeanServer server = ManagementFactory.getPlatformMBeanServer(); server.registerMBean(new Game(), objectName); } catch (MalformedObjectNameException | InstanceAlreadyExistsException | MBeanRegistrationException | NotCompliantMBeanException e) { // handle exceptions } 最后，为了能够测试它——我们将添加一个while循环来防止应用程序在我们可以通过 JConsole 访问 MBean 之前终止： while (true) { } 5. 访问 MBean 5.1 从客户端连接  在 Eclipse 中启动应用程序 启动Jconsole（位于你机器JDK安装目录的bin文件夹下） Connection -\u0026gt; new Connection -\u0026gt; 选择本教程的本地Java进程 -\u0026gt; Connect -\u0026gt; Insecure SSl connection warning -\u0026gt; Continue with insecure connection 建立连接后，单击 View 窗格右上角的 MBeans 选项卡 已注册的 MBean 列表将出现在左栏中 点击 com.codingman.tutorial -\u0026gt; 基础 -\u0026gt; 游戏 游戏下会有两排，属性和操作各一排  以下是该过程的 JConsole 部分的快速浏览： 5.2. 管理 MBean MBean 管理的基础很简单：  属性可以读取或写入 可以调用方法并且可以向它们提供参数或从它们返回值  让我们看看这在实践中对Game MBean意味着什么：  属性：为属性playerName输入一个新值——例如“梅西”，然后单击刷新按钮  以下日志将出现在 Eclipse 控制台中： 将 playerName 设置为 Messi  操作：为*playFootBall()*方法的 String 参数键入一个值——例如“Barcelona”，然后单击方法按钮。将出现的窗口提示  eclipse控制台中会出现以下日志： 梅西为巴塞罗那踢球 \u0026quot; ","permalink":"http://itcodingman.github.io/java_management_extensions/","tags":[],"title":"JMX基本介绍"},{"categories":["Java"],"contents":"1. 概述 每个程序都需要一个开始执行的地方；谈论Java程序，这是main方法。 我们已经习惯了在代码会话期间编写main方法，以至于我们甚至不注意它的细节。在这篇快速文章中，我们将分析此方法并展示其他一些编写方法。 2. 共同签名 最常见的主方法模板是： public static void main(String[] args) { } 这就是我们学习它的方式，这就是 IDE 为我们自动完成代码的方式。但这不是此方法可以采用的唯一形式，我们可以使用一些有效的变体，并不是每个开发人员都注意这一事实。 在深入研究这些方法签名之前，让我们回顾一下常见签名的每个关键字的含义：  public – 访问修饰符，表示全局可见性 static – 该方法可以直接从类中访问，我们不必实例化一个对象来获得引用并使用它 void – 表示此方法不返回值 main – 方法的名称，这是 JVM 在执行 Java 程序时查找的标识符  至于args参数，它表示方法接收到的值。这就是我们第一次启动程序时向程序传递参数的方式。 参数args是一个String数组。在以下示例中： java CommonMainMethodSignature foo bar 我们正在执行一个名为CommonMainMethodSignature的 Java 程序并传递 2 个参数：foo和bar。这些值可以在main方法内部作为args[0]（以foo作为值）和args[1]（以bar作为值）访问。 在下一个示例中，我们将检查 args 以决定是否加载测试或生产参数： public static void main(String[] args) { if (args.length \u0026gt; 0) { if (args[0].equals(\u0026#34;test\u0026#34;)) { // load test parameters  } else if (args[0].equals(\u0026#34;production\u0026#34;)) { // load production parameters  } } } 记住 IDE 也可以将参数传递给程序总是好的。 *3. 编写*main()方法的不同方法 让我们检查一些不同的方法来编写main方法。虽然它们不是很常见，但它们是有效的签名。 请注意，这些都不是特定于main方法的，它们可以与任何 Java 方法一起使用，但它们也是main方法的有效部分。 方括号可以放在String附近，就像在通用模板中一样，也可以放在两边的args附近： public static void main(String []args) { } public static void main(String args[]) { } 参数可以表示为可变参数： public static void main(String...args) { } 我们甚至可以为main()方法添加strictfp，用于处理浮点值时处理器之间的兼容性： public strictfp static void main(String[] args) { } synchronized和final也是main方法的有效关键字，但它们在这里不起作用。 另一方面，final可以应用于args以防止数组被修改： public static void main(final String[] args) { } 为了结束这些示例，我们还可以使用上述所有关键字编写main方法（当然，您可能永远不会在实际应用中使用）： final static synchronized strictfp void main(final String[] args) { } 4. 拥有多个*main()*方法 我们还可以在应用程序中定义多个main方法。 事实上，有些人使用它作为一种原始的测试技术来验证单个类（尽管像JUnit这样的测试框架更适合这种活动）。 为了指定 JVM 应该执行哪个main方法作为我们应用程序的入口点，我们使用MANIFEST.MF文件。在清单中，我们可以指明主类： Main-Class: mypackage.ClassWithMainMethod 这主要在创建可执行*.jar文件时使用。我们通过位于META-INF/MANIFEST.MF的清单文件（以 UTF-8 编码）指示哪个类具有启动执行的main方法。* \u0026quot; ","permalink":"http://itcodingman.github.io/java_main_method/","tags":["Core Java"],"title":"Java main() 方法解释"},{"categories":["DevOps","Java"],"contents":"1. 简介 在本教程中，我们将使用 Java 获取本地机器的 MAC 地址。 MAC 地址是物理网络接口卡的唯一标识符。 我们将仅介绍 MAC 地址，但有关网络接口的更一般概述，请参阅使用 Java 中的网络接口。 2. 例子 在下面的示例中，我们将使用java.net.NetworkInterface 和java.net.InetAddress API。 2.1 机器本地主机 首先，让我们获取我们机器 localhost 的 MAC 地址： InetAddress localHost = InetAddress.getLocalHost(); NetworkInterface ni = NetworkInterface.getByInetAddress(localHost); byte[] hardwareAddress = ni.getHardwareAddress(); 由于 NetworkInterface.getHardwareAddress返回一个字节数组，我们可以格式化结果： String[] hexadecimal = new String[hardwareAddress.length]; for (int i = 0; i \u0026lt; hardwareAddress.length; i++) { hexadecimal[i] = String.format(\u0026#34;%02X\u0026#34;, hardwareAddress[i]); } String macAddress = String.join(\u0026#34;-\u0026#34;, hexadecimal); 请注意我们如何使用String#format将数组中的每个字节格式化为十六进制数。 之后，我们可以用“-”（破折号）连接所有格式化的元素。 2.2. 本地 IP 其次，让我们获取给定本地 IP 地址的 MAC 地址： InetAddress localIP = InetAddress.getByName(\u0026#34;192.168.1.108\u0026#34;); NetworkInterface ni = NetworkInterface.getByInetAddress(localIP); byte[] macAddress = ni.getHardwareAddress(); 同样，请注意我们如何获得 MAC 地址的字节数组。 2.3. 所有网络接口 最后，让我们获取机器上所有网络接口的 MAC 地址： Enumeration\u0026lt;NetworkInterface\u0026gt; networkInterfaces = NetworkInterface.getNetworkInterfaces(); while (networkInterfaces.hasMoreElements()) { NetworkInterface ni = networkInterfaces.nextElement(); byte[] hardwareAddress = ni.getHardwareAddress(); if (hardwareAddress != null) { String[] hexadecimalFormat = new String[hardwareAddress.length]; for (int i = 0; i \u0026lt; hardwareAddress.length; i++) { hexadecimalFormat[i] = String.format(\u0026#34;%02X\u0026#34;, hardwareAddress[i]); } System.out.println(String.join(\u0026#34;-\u0026#34;, hexadecimalFormat)); } } 由于 getNetworkInterfaces返回物理和虚拟接口，我们需要过滤掉虚拟接口。 例如，我们可以通过对 getHardwareAddress进行空检查来做到这一点。 \u0026quot; ","permalink":"http://itcodingman.github.io/java_mac_address/","tags":[],"title":"在 Java 中获取 MAC 地址"},{"categories":["C++","BiliBili"],"contents":"100分钟学习C++ 这是一门针对初学者的完整课程，学习有关C++的所有知识。包括：语法、语句、字符串、操作符、函数、文件等 \r","permalink":"http://itcodingman.github.io/100_mins_c/","tags":[],"title":"100分钟学习C++"},{"categories":["Java","Spring","Youtube"],"contents":"40分钟学习Spring Boot Web   ","permalink":"http://itcodingman.github.io/40_mins_spring_boot_web/","tags":[],"title":"40分钟学习Spring Boot Web"},{"categories":["Python","BiliBili"],"contents":"15分钟学习Numpy的通用函数 这是一门针对初学者的完整课程，学习有关NumPy的通用函数知识。包括：ufunc、计算、连接、差分等 \r","permalink":"http://itcodingman.github.io/15_mins_numpy_ufunc/","tags":[],"title":"15分钟学习Numpy的通用函数"},{"categories":["Java","Spring","Youtube"],"contents":"30分钟学习Spring MVC和Thymeleaf   ","permalink":"http://itcodingman.github.io/30_mins_spring_mvc_thymeleaf/","tags":[],"title":"30分钟学习Spring MVC和Thymeleaf"},{"categories":["Python","BiliBili"],"contents":"15分钟学习NumPy和数据分布 这是一门针对初学者的完整课程，学习有关NumPy的数据分布知识。包括：随机数、正态分布、泊松分布等数据分布 \r","permalink":"http://itcodingman.github.io/15_mins_numpy_data_distribution/","tags":[],"title":"15分钟学习NumPy和数据分布"},{"categories":["Java","Youtube"],"contents":"50分钟学习Thymeleaf   ","permalink":"http://itcodingman.github.io/50_mins_thymeleaf/","tags":[],"title":"50分钟学习Thymeleaf"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和SciPy 这是一门针对初学者的完整课程，学习有关SciPy的所有知识。包括：常数、优化器、稀疏矩阵、图、空间数据、MatLib、统计等 \r","permalink":"http://itcodingman.github.io/30_mins_scipy/","tags":[],"title":"30分钟学习Python和SciPy"},{"categories":["Java","Youtube"],"contents":"40分钟学习JPA   ","permalink":"http://itcodingman.github.io/40_mins_jpa/","tags":[],"title":"40分钟学习JPA"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和NumPy 这是一门针对初学者的完整课程，学习有关NumPy的所有知识。包括：数组、索引、切片、连接、拆分、排序、查询等 \r","permalink":"http://itcodingman.github.io/30_mins_numpy/","tags":[],"title":"30分钟学习Python和NumPy"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring Data JPA   ","permalink":"http://itcodingman.github.io/10_mins_spring_data_jpa/","tags":[],"title":"10分钟学习Spring Data JPA"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和Matplotlib 这是一门针对初学者的完整课程，学习有关MatplotLib的所有知识。包括：绘图、标记、标签、网格、多图、散点图、柱状图、直方图、饼图等 \r","permalink":"http://itcodingman.github.io/30_mins_matplotlib/","tags":[],"title":"30分钟学习Python和Matplotlib"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和Pandas Pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。 \r","permalink":"http://itcodingman.github.io/30_mins_pandas/","tags":[],"title":"30分钟学习Python和Pandas"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring JPA   ","permalink":"http://itcodingman.github.io/10_mins_spring_jpa/","tags":[],"title":"10分钟学习Spring JPA"},{"categories":["Python","BiliBili"],"contents":"100分钟学习Python 这是一门针对初学者的完整课程，学习有关Python的所有知识。包括：语法、语句、字符串、操作符、函数、文件等 \r","permalink":"http://itcodingman.github.io/100_mins_python/","tags":[],"title":"100分钟学习Python"},{"categories":["Java","Youtube"],"contents":"30分钟学习JDBC   ","permalink":"http://itcodingman.github.io/30_mins_jdbc/","tags":[],"title":"30分钟学习JDBC"},{"categories":["Python","BiliBili"],"contents":"一小时学习Python和Flask 这是一门针对初学者的完整课程，学习有关Flask的所有知识。包括：基础知识（路由、变量及URL规则、 模板、 静态文件、 重定向和错误 ）和高级知识（Cookies及会话、 消息闪现、 WTF表单、文件上传、 SQLAlchemy及数据库、Sjiax）。 \r","permalink":"http://itcodingman.github.io/1_hour_flask/","tags":[],"title":"一小时学习Python和Flask"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring Data JDBC   ","permalink":"http://itcodingman.github.io/10_mins_spring_data_jdbc/","tags":[],"title":"10分钟学习Spring Data JDBC"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring Boot JDBC   ","permalink":"http://itcodingman.github.io/10_mins_spring_boot_jdbc/","tags":[],"title":"10分钟学习Spring Boot JDBC"},{"categories":["Python","BiliBili"],"contents":"一小时学习Python和Mediapipe 这是一门针对初学者的完整课程，学习有关MediaPipe的所有知识。包括：人脸识别、匹配、手势、姿势、自拍背景等。 \r","permalink":"http://itcodingman.github.io/1_hour_python_mediapipe/","tags":[],"title":"一小时学习Python和Mediapipe"},{"categories":["Java","Spring","Youtube"],"contents":"40分钟学习Spring Boot Spring Boot 教程包括 Spring Boot 的所有主题，例如特性、项目、maven 项目、启动项目向导、Spring Initializr、CLI、应用程序、注释、依赖管理、属性、启动器、执行器等。   ","permalink":"http://itcodingman.github.io/40_mins_spring_boot/","tags":[],"title":"40分钟学习Spring Boot"},{"categories":["Python","BiliBili"],"contents":"一小时学习Python和OpenCV 这是一门针对初学者的完整课程，学习有关OpenCV的所有知识。包括：基础知识（图像和视频的读取、图像变换、图形绘制）和高级知识（色彩空间、位操作、直方图和边缘检测、滤波）。最后部分讲解人脸检测和识别 。 \r","permalink":"http://itcodingman.github.io/1_hour_python_opencv/","tags":[],"title":"一小时学习Python和OpenCV"},{"categories":["Python","Youtube"],"contents":"使用OpenCV和EasyOCR识别车牌   ","permalink":"http://itcodingman.github.io/opencv_easyocr_anpr/","tags":[],"title":"使用OpenCV和EasyOCR识别车牌"},{"categories":["Java","Spring","Youtube"],"contents":"30分钟学习Spring MVC #SpringMVC   ","permalink":"http://itcodingman.github.io/30_mins_spring_mvc_springmvc/","tags":[],"title":"30分钟学习Spring MVC #SpringMVC"},{"categories":["Python","Youtube"],"contents":"10分钟学习TesseractOCR   ","permalink":"http://itcodingman.github.io/10_mins_tesseractocr/","tags":[],"title":"10分钟学习TesseractOCR"},{"categories":["Python","Youtube"],"contents":"10分钟学习EasyOCR   ","permalink":"http://itcodingman.github.io/10_mins_easyocr/","tags":["EasyOCR","OCR"],"title":"10分钟学习EasyOCR"},{"categories":["Java","Youtube"],"contents":"maven安装和使用   ","permalink":"http://itcodingman.github.io/maven_install_introduce/","tags":[],"title":"maven安装和使用"},{"categories":["Java","Spring","Youtube"],"contents":"Spring Tools 4 安装和使用   ","permalink":"http://itcodingman.github.io/spring_tools_install_introduce/","tags":[],"title":"Spring Tools 4 安装和使用"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring JDBC   ","permalink":"http://itcodingman.github.io/10_mins_spring_jdbc/","tags":[],"title":"10分钟学习Spring JDBC"},{"categories":["Java","Spring","Youtube"],"contents":"45分钟学习Spring Framework   ","permalink":"http://itcodingman.github.io/45_mins_spring_framework/","tags":[],"title":"45分钟学习Spring Framework"},{"categories":["Java","Youtube"],"contents":"30分钟学习Struts2 Struts 2 教程涵盖了 Struts 2 Framework 的所有主题，并为初学者和有经验的人提供了简化的示例。   ","permalink":"http://itcodingman.github.io/30_mins_struts2/","tags":[],"title":"30分钟学习Struts2"},{"categories":["Python","Youtube"],"contents":"10分钟学习Opencv目标跟踪 Object Tracking Opencv目标跟踪 Object Tracking   ","permalink":"http://itcodingman.github.io/10_mins_opencv_object_tracking/","tags":[],"title":"10分钟学习Opencv目标跟踪 Object Tracking"},{"categories":["Java","Spring","Youtube"],"contents":"Visual Studio Code Spring Boot 的安装及使用 Visual Studio Code和Spring Boot的安装及使用   ","permalink":"http://itcodingman.github.io/vscode_spring_boot_install_introduce/","tags":[],"title":"Visual Studio Code Spring Boot 的安装及使用"},{"categories":["Java","Youtube"],"contents":"一小时学习Servlet 本教程将讲解如何使用 Java Servlet 来开发基于 web 的应用程序。   ","permalink":"http://itcodingman.github.io/1_hour_servlet/","tags":[],"title":"一小时学习Servlet"},{"categories":["Python","Youtube"],"contents":"conda的安装和使用、国内源、常用命令 conda的安装和使用、国内源、常用命令   ","permalink":"http://itcodingman.github.io/conda_install_introduce/","tags":[],"title":"conda的安装和使用、国内源、常用命令"},{"categories":["Python","Youtube"],"contents":"PIP安装和使用、国内源、常用命令 PIP安装和使用、国内源、常用命令   ","permalink":"http://itcodingman.github.io/pip_install_introduce/","tags":[],"title":"PIP安装和使用、国内源、常用命令"},{"categories":["Java","Youtube"],"contents":"50分钟学习JSP JSP教程主要提供JSP基础知识以及部分常用的JSP进阶知识，大家在学习JSP之前，需要具备一定的HTML及Java基础。   ","permalink":"http://itcodingman.github.io/50_mins_jsp/","tags":[],"title":"50分钟学习JSP"},{"categories":["Youtube"],"contents":"20分钟学习web技术 本课程将系统学习Web基础知识及常用功能   ","permalink":"http://itcodingman.github.io/20_mins_web/","tags":[],"title":"20分钟学习web技术"},{"categories":["BiliBili"],"contents":"20分钟学习web技术 本课程将系统学习Web基础知识及常用功能 \r","permalink":"http://itcodingman.github.io/20_mins_web/","tags":[],"title":"20分钟学习web技术"},{"categories":["Java","Youtube"],"contents":"Eclipse、Tomcat和Java Web的安装、配置及开发 Eclipse、Tomcat和Java Web的安装、配置及开发   ","permalink":"http://itcodingman.github.io/eclipse_tomcat_java_web_install_introduce/","tags":[],"title":"Eclipse、Tomcat和Java Web的安装、配置及开发"},{"categories":["Java","Youtube"],"contents":"Eclipse和Java的安装 Eclipse和Java的安装   ","permalink":"http://itcodingman.github.io/eclipse_java_install_introduce/","tags":[],"title":"Eclipse和Java的安装"},{"categories":["Java","Youtube"],"contents":"100分钟学习Java 这是一门针对初学者的完整课程，学习有关Java的所有知识。包括：语法、语句、字符串、操作符、函数、文件等   ","permalink":"http://itcodingman.github.io/100_mins_java/","tags":[],"title":"100分钟学习Java"},{"categories":["Java","Youtube"],"contents":"Visual Studio Code Java 的安装及使用 VisualStudioCode和Java的安装及使用   ","permalink":"http://itcodingman.github.io/vscode_java_install_introduce/","tags":[],"title":"Visual Studio Code Java 的安装及使用"},{"categories":["C++","Youtube"],"contents":"Visaul Studio Code C++ 安装及使用 Visaul Studio Code C++ 安装及使用   ","permalink":"http://itcodingman.github.io/vscode_c_install_introduce/","tags":[],"title":"Visaul Studio Code C++ 安装及使用"},{"categories":["Python","Youtube"],"contents":"jupyter notebook安装及使用 Jupyter Notebook是以网页的形式打开，可以在网页页面中直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示的程序。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。   ","permalink":"http://itcodingman.github.io/jupyter_notebook_install_introduce/","tags":[],"title":"jupyter notebook安装及使用"},{"categories":["C++","Youtube"],"contents":"100分钟学习C++ 这是一门针对初学者的完整课程，学习有关C++的所有知识。包括：语法、语句、字符串、操作符、函数、文件等   ","permalink":"http://itcodingman.github.io/100_mins_c/","tags":[],"title":"100分钟学习C++"},{"categories":["Python","Youtube"],"contents":"15分钟学习Numpy的通用函数 这是一门针对初学者的完整课程，学习有关NumPy的通用函数知识。包括：ufunc、计算、连接、差分等   ","permalink":"http://itcodingman.github.io/15_mins_numpy_ufunc/","tags":[],"title":"15分钟学习Numpy的通用函数"},{"categories":["Python","Youtube"],"contents":"15分钟学习NumPy和数据分布 这是一门针对初学者的完整课程，学习有关NumPy的数据分布知识。包括：随机数、正态分布、泊松分布等数据分布   ","permalink":"http://itcodingman.github.io/15_mins_numpy_data_distribution/","tags":[],"title":"15分钟学习NumPy和数据分布"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和SciPy 这是一门针对初学者的完整课程，学习有关SciPy的所有知识。包括：常数、优化器、稀疏矩阵、图、空间数据、MatLib、统计等   ","permalink":"http://itcodingman.github.io/30_mins_scipy/","tags":[],"title":"30分钟学习Python和SciPy"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和NumPy 这是一门针对初学者的完整课程，学习有关NumPy的所有知识。包括：数组、索引、切片、连接、拆分、排序、查询等   ","permalink":"http://itcodingman.github.io/30_mins_numpy/","tags":[],"title":"30分钟学习Python和NumPy"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和Matplotlib 这是一门针对初学者的完整课程，学习有关MatplotLib的所有知识。包括：绘图、标记、标签、网格、多图、散点图、柱状图、直方图、饼图等   ","permalink":"http://itcodingman.github.io/30_mins_matplotlib/","tags":[],"title":"30分钟学习Python和Matplotlib"},{"categories":["Python","Youtube"],"contents":"100分钟学习Python 这是一门针对初学者的完整课程，学习有关Python的所有知识。包括：语法、语句、字符串、操作符、函数、文件等   ","permalink":"http://itcodingman.github.io/100_mins_python/","tags":[],"title":"100分钟学习Python"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和Pandas Pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。   ","permalink":"http://itcodingman.github.io/30_mins_pandas/","tags":[],"title":"30分钟学习Python和Pandas"},{"categories":["Python","Youtube"],"contents":"一小时学习Python和Mediapipe 这是一门针对初学者的完整课程，学习有关MediaPipe的所有知识。包括：人脸识别、匹配、手势、姿势、自拍背景等。   ","permalink":"http://itcodingman.github.io/1_hour_python_mediapipe/","tags":[],"title":"一小时学习Python和Mediapipe"},{"categories":["Python"],"contents":"一小时学习python和flask 这是一门针对初学者的完整课程，学习有关Flask的所有知识。包括：基础知识（路由、变量及URL规则、 模板、 静态文件、重定向和错误 ）和高级知识（Cookies及会话、 消息闪现、 WTF表单、文件上传、 SQLAlchemy及数据库、Sjiax）。   ","permalink":"http://itcodingman.github.io/1_hour_python_flask/","tags":["Python","Flask"],"title":"一小时学习python和flask"},{"categories":["Python","Youtube"],"contents":"一小时学习Python和Flask 这是一门针对初学者的完整课程，学习有关Flask的所有知识。包括：基础知识（路由、变量及URL规则、 模板、 静态文件、 重定向和错误 ）和高级知识（Cookies及会话、 消息闪现、 WTF表单、文件上传、 SQLAlchemy及数据库、Sjiax）。   ","permalink":"http://itcodingman.github.io/1_hour_flask/","tags":[],"title":"一小时学习Python和Flask"},{"categories":["Python","Youtube"],"contents":"一小时学习Python和OpenCV 这是一门针对初学者的完整课程，学习有关OpenCV的所有知识。包括：基础知识（图像和视频的读取、图像变换、图形绘制）和高级知识（色彩空间、位操作、直方图和边缘检测、滤波）。最后部分讲解人脸检测和识别 。   ","permalink":"http://itcodingman.github.io/1_hour_python_opencv/","tags":[],"title":"一小时学习Python和OpenCV"},{"categories":["Jakarta EE"],"contents":"1. 概述 Velocity是一个基于 Java 的模板引擎。 它是一个开源 Web 框架，旨在用作 MVC 架构中的视图组件，它提供了一些现有技术（如 JSP）的替代方案。 Velocity 可用于生成 XML 文件、SQL、PostScript 和大多数其他基于文本的格式。 在本文中，我们将探讨如何使用它来创建动态网页。 2. Velocity是如何工作的 Velocity 的核心类是VelocityEngine。 它使用数据模型和速度模板编排读取、解析和生成内容的整个过程。 简而言之，对于任何典型的速度应用程序，我们需要遵循以下步骤：  初始化Velocity引擎 读入模板 将数据模型放入上下文对象中 将模板与上下文数据合并并渲染视图  让我们按照这些简单的步骤来看一个示例： VelocityEngine velocityEngine = new VelocityEngine(); velocityEngine.init(); Template t = velocityEngine.getTemplate(\u0026#34;index.vm\u0026#34;); VelocityContext context = new VelocityContext(); context.put(\u0026#34;name\u0026#34;, \u0026#34;World\u0026#34;); StringWriter writer = new StringWriter(); t.merge( context, writer ); 3. Maven依赖 要使用 Velocity，我们需要在 Maven 项目中添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.velocity\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;velocity\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.velocity\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;velocity-tools\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这两个依赖项的最新版本可以在这里：velocity和velocity-tools。 4. Velocity模板语言 Velocity 模板语言 (VTL) 通过使用 VTL 引用提供了将动态内容合并到网页中的最简单和最干净的方法。 速度模板中的 VTL 引用以*$开头，用于获取与该引用关联的值。VTL 还提供了一组指令，可用于操作 Java 代码的输出。这些指令以# 开头。* 4.1 参考 Velocity 中有三种类型的引用，变量，属性和方法：  变量——在页面中使用*#set*指令或从 Java 对象的字段返回的值定义：  #set ($message=\u0026#34;Hello World\u0026#34;)  属性——引用对象中的字段；它们还可以引用属性的getter方法：  $customer.name  方法– 指 Java 对象上的方法：  $customer.getName() 每个引用产生的最终值在呈现到最终输出时都会转换为字符串。 4.2. 指令 VTL 提供了丰富的指令集：  set – 可用于设置参考值；此值可以分配给变量或属性引用：  #set ($message = \u0026#34;Hello World\u0026#34;) #set ($customer.name = \u0026#34;Brian Mcdonald\u0026#34;)  条件—— #if、#elseif和*#else*指令提供了一种基于条件检查生成内容的方法：  #if($employee.designation == \u0026#34;Manager\u0026#34;) \u0026lt;h3\u0026gt; Manager \u0026lt;/h3\u0026gt; #elseif($employee.designation == \u0026#34;Senior Developer\u0026#34;) \u0026lt;h3\u0026gt; Senior Software Engineer \u0026lt;/h3\u0026gt; #else \u0026lt;h3\u0026gt; Trainee \u0026lt;/h3\u0026gt; #end  loops – #foreach指令允许循环对象集合：  \u0026lt;ul\u0026gt; #foreach($product in $productList) \u0026lt;li\u0026gt; $product \u0026lt;/li\u0026gt; #end \u0026lt;/ul\u0026gt;  include - #include元素提供将文件导入模板的能力：  #include(\u0026#34;one.gif\u0026#34;,\u0026#34;two.txt\u0026#34;,\u0026#34;three.html\u0026#34;...)  parse – #parse语句允许模板设计者导入另一个包含 VTL 的本地文件；然后 Velocity 将解析内容并呈现它：  #parse (Template)  evaluate– #evaluate指令可用于动态评估 VTL；这允许模板在渲染时评估字符串，例如国际化模板：  #set($firstName = \u0026#34;David\u0026#34;) #set($lastName = \u0026#34;Johnson\u0026#34;) #set($dynamicsource = \u0026#34;$firstName$lastName\u0026#34;) #evaluate($dynamicsource)  break - #break指令停止当前执行范围的任何进一步呈现（即*#foreach*，#parse） stop – #stop指令停止模板的任何进一步渲染和执行。 velocimacros – #macro指令允许模板设计者定义 VTL 的重复段：  #macro(tablerows) \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; #end *这个宏现在可以作为#tablerows()*放在模板中的任何位置： #macro(tablerows $color $productList) #foreach($product in $productList) \u0026lt;tr\u0026gt; \u0026lt;td bgcolor=$color\u0026gt;$product.name\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; #end #end 4.3. 其它功能  math – 一些内置的数学函数，可以在模板中使用：  #set($percent = $number / 100) #set($remainder = $dividend % $divisor)  范围运算符– 可以与*#set和#foreach 结合使用：*  #set($array = [0..10]) #foreach($elem in $arr) $elem #end 5. Velocity Servlet程序 Velocity Engine 的主要工作是根据模板生成内容。 引擎本身不包含任何与网络相关的功能。要实现 Web 应用程序，我们需要使用 servlet 或基于 servlet 的框架。 Velocity 提供了一个开箱即用的实现VelocityViewServlet，它是velocity-tools 子项目的一部分。 为了利用VelocityViewServlet提供的内置功能，我们可以从VelocityViewServlet扩展我们的 servlet并覆盖*handleRequest()*方法： public class ProductServlet extends VelocityViewServlet { ProductService service = new ProductService(); @Override public Template handleRequest( HttpServletRequest request, HttpServletResponse response, Context context) throws Exception { List\u0026lt;Product\u0026gt; products = service.getProducts(); context.put(\u0026#34;products\u0026#34;, products); return getTemplate(\u0026#34;index.vm\u0026#34;); } } 6.配置 6.1 网页配置 现在让我们看看如何在web.xml中配置**VelocityViewServlet。 我们需要指定可选的初始化参数，包括velocity.properties和toolbox.xml： \u0026lt;web-app\u0026gt; \u0026lt;display-name\u0026gt;apache-velocity\u0026lt;/display-name\u0026gt; //... \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;velocity\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.apache.velocity.tools.view.VelocityViewServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;org.apache.velocity.properties\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/velocity.properties\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; //... \u0026lt;/web-app\u0026gt; 我们还需要为这个 servlet 指定映射。所有对速度模板 ( *.vm ) 的请求都需要由速度 servlet 提供服务： \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;velocityLayout\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.vm\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 6.2. 资源加载器 Velocity 提供灵活的资源加载系统。它允许一个或多个资源加载器同时运行：  文件资源加载器 JarResourceLoader 类路径资源加载器 URL资源加载器 数据源资源加载器 WebappResourceLoader  这些资源加载器在velocity.properties 中配置： resource.loader=webapp webapp.resource.loader.class=org.apache.velocity.tools.view.WebappResourceLoader webapp.resource.loader.path = webapp.resource.loader.cache = true 7. Velocity模板 Velocity 模板是编写所有视图生成逻辑的地方。这些页面是使用 Velocity 模板语言 (VTL) 编写的： \u0026lt;html\u0026gt; ... \u0026lt;body\u0026gt; \u0026lt;center\u0026gt; ... \u0026lt;h2\u0026gt;$products.size() Products on Sale!\u0026lt;/h2\u0026gt; \u0026lt;br/\u0026gt; We are proud to offer these fine products at these amazing prices. ... #set( $count = 1 ) \u0026lt;table class=\u0026#34;gridtable\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Serial #\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Product Name\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Price\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; #foreach( $product in $products ) \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;$count)\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;$product.getName()\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;$product.getPrice()\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; #set( $count = $count + 1 ) #end \u0026lt;/table\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 8. 管理页面布局 Velocity 为基于 Velocity Tool 的应用程序提供了简单的布局控制和可定制的错误屏幕。 VelocityLayoutServlet封装了此功能以呈现指定的布局。VelocityLayoutServlet是 VelocityViewServlet 的扩展*。* 8.1 网页配置 让我们看看如何配置VelocityLayoutServlet。servlet 被定义用于拦截速度模板页面的请求，并且布局特定属性在velocity.properties文件中定义： \u0026lt;web-app\u0026gt; // ... \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;velocityLayout\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.apache.velocity.tools.view.VelocityLayoutServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;org.apache.velocity.properties\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/velocity.properties\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; // ... \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;velocityLayout\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.vm\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; // ... \u0026lt;/web-app\u0026gt; 8.2. 布局模板 布局模板定义了速度页面的典型结构。默认情况下，VelocityLayoutServlet在布局文件夹下搜索Default.vm 。覆盖少数属性可以更改此位置： tools.view.servlet.layout.directory = layout/ tools.view.servlet.layout.default.template = Default.vm 布局文件由页眉模板、页脚模板和一个速度变量*$screen_content 组成*，它呈现请求的速度页面的内容： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Velocity\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; #parse(\u0026#34;/fragments/header.vm\u0026#34;) \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;!-- View index.vm is inserted here --\u0026gt; $screen_content \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; #parse(\u0026#34;/fragments/footer.vm\u0026#34;) \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 8.3. 请求屏幕中的布局规范 特定屏幕的布局可以定义为页面开头的速度变量。这是通过将这一行放在页面中来完成的： #set($layout = \u0026#34;MyOtherLayout.vm\u0026#34;) 8.4. 请求参数中的布局规范 我们可以在查询字符串layout=MyOtherLayout.vm中添加一个请求参数，VLS 会找到它并在该布局内渲染屏幕，而不是搜索默认布局。 8.5 错误屏幕 可以使用速度布局实现自定义错误屏幕。VelocityLayoutServlet提供了两个变量*$error_cause和$stack_trace*来呈现异常细节。 错误页面可以在velocity.properties文件中配置： tools.view.servlet.error.template = Error.vm \u0026quot; ","permalink":"http://itcodingman.github.io/apache_velocity/","tags":[],"title":"Apache Velocity 简介"},{"categories":["Security","Spring"],"contents":"1. 概述 在本文中，我们将了解 Tomcat 服务器基础知识、它的工作原理以及如何启用 Tomcat 的单点登录 ( SSO ) 功能。我们将探索 Tomcat 服务器和 Web 应用程序所需的配置。 2.Tomcat架构 构成 Catalina servlet 容器的主要部分是包含定义连接器的服务和由主机构建的引擎的服务器，最后，这些主机将包含上下文或 Web 应用程序。 连接器侦听客户端的请求并发送回响应。在 Tomcat 10 中，我们可以找到以下协议的连接器：HTTP/1.1、HTTP/2和AJP。 引擎将处理连接器收到的请求并生成输出。它将包含一个 处理管道，这是一个进程链，每个请求都会执行以产生响应。这些过程就是 Tomcat 的阀门。例如，Tomcat 上的 SSO 是作为阀门实现的。 之后，我们找到将定义将网络名称与服务器相关联的虚拟主机的主机。这是定义 SSO 阀的级别，因此主机的所有上下文都将位于 SSO 之下。 最后，我们将拥有与主机关联的上下文元素。这些上下文是将在服务器上运行的 Web 应用程序。上下文必须遵循 servlet 规范 2.3 或更高版本。 3. Tomcat 单点登录 Tomcat 在必须在主机级别配置的 Valve 中实现单点登录功能。它的工作方式是 SSO 阀门将存储用户凭据并在需要时传递它们，因此用户无需再次登录。 SSO 阀需要满足以下要求：  Realm或“用户数据库”必须由虚拟主机下的所有 Web 应用程序共享。 Web 应用程序身份验证机制必须是标准身份验证器之一：Basic、Digest、Form、SSL或SPNEGO。 当客户端请求受保护的资源时，服务器将执行 Web 应用程序的身份验证机制。 服务器将使用经过身份验证的用户的角色访问虚拟主机下的 Web 应用程序的受保护资源，而无需再次登录。 当用户退出 Web 应用程序时，服务器将使所有 Web 应用程序中的用户会话无效。 客户端必须接受 cookie。cookie 存储将请求与用户凭据相关联的令牌。  3.1 Tomcat 服务器配置 在服务器端，我们需要配置SingleSignOn阀门和领域或“用户数据库”。这些配置在 Tomcat 安装的 conf 文件夹下的 server.xml 文件中。要添加 SSO 阀，我们需要取消注释以下行： \u0026lt;Valve className=\u0026#34;org.apache.catalina.authenticator.SingleSignOn\u0026#34; /\u0026gt; 对于本文的示例，我们将依赖默认配置的 Realm，我们只需要将用户添加到数据库中。领域定义如下所示： \u0026lt;Realm className=\u0026#34;org.apache.catalina.realm.UserDatabaseRealm\u0026#34; resourceName=\u0026#34;UserDatabase\u0026#34;/\u0026gt; 此配置使用全局 JNDI 资源来定义用户数据库的来源： \u0026lt;Resource name=\u0026#34;UserDatabase\u0026#34; auth=\u0026#34;Container\u0026#34; type=\u0026#34;org.apache.catalina.UserDatabase\u0026#34; description=\u0026#34;User database that can be updated and saved\u0026#34; factory=\u0026#34;org.apache.catalina.users.MemoryUserDatabaseFactory\u0026#34; pathname=\u0026#34;conf/tomcat-users.xml\u0026#34; /\u0026gt; 该资源将实例化一个 org.apache.catalina.UserDatabase 类型的对象，并将使用工厂类**org.apache.catalina.users.MemoryUserDatabaseFactory从 tomcat-users.xml 文件中填充它 。 最后，在这里我们看看如何添加一个具有文章示例所需的管理员角色的用户。我们需要修改tomcat-users.xml文件： \u0026lt;tomcat-users xmlns=\u0026#34;http://tomcat.apache.org/xml\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://tomcat.apache.org/xml tomcat-users.xsd\u0026#34; version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;role rolename=\u0026#34;admin\u0026#34;/\u0026gt; \u0026lt;user username=\u0026#34;demo\u0026#34; password=\u0026#34;demo\u0026#34; roles=\u0026#34;admin\u0026#34;/\u0026gt; \u0026lt;/tomcat-users\u0026gt; 3.2. Web 应用程序配置 一旦我们配置了服务器，让我们通过每个 servlet 的 WEB-INF 文件夹中的 web.xml 配置文件来配置 servlet。 所有需要 SSO 的 Web 应用程序都必须具有受保护的资源并使用一种 Tomcat 身份验证方法。正如 Servlet API 规范 2.3 中定义的那样，Web 应用程序的身份验证机制在web-app元素内的 login-config 元素中定义。此元素将包含需要使用以下值之一的身份验证方法表单：BASIC、DIGEST、FORM 或 CLIENT-CERT。每种身份验证方法都有不同的配置，但我们将在Tomcat Web 应用程序配置部分仅讨论 DIGEST 和 FORM 身份验证方法。 要完成 Web 应用配置，我们需要设置保护区。在 web-app 元素下的 web.xml 文件中，我们可以根据需要添加任意数量的安全约束元素。每个安全约束都定义了受保护资源的 URL 模式，并将设置允许的角色。此外，我们需要为所有角色定义安全角色元素，并且它们必须与 tomcat-users.xml 文件中的定义相匹配。我们将在下一节中看到一个示例。 4. 示例认证机制 现在我们知道如何配置 Web 应用程序，让我们看两个示例：Ping 和 Pong。我们选择了不同的身份验证机制来证明 SSO 可以很好地与不同的机制配合使用。 4.1 Ping 认证机制 在 ping web 应用程序中，我们使用 FORM 身份验证方法。FORM认证方式需要登录表单，网页登录失败。例如，当我们想要将登录页面自定义为 Web 应用程序时，此方法将很有用，配置如下所示： \u0026lt;login-config\u0026gt; \u0026lt;auth-method\u0026gt;FORM\u0026lt;/auth-method\u0026gt; \u0026lt;form-login-config\u0026gt; \u0026lt;form-login-page\u0026gt;/logging.html\u0026lt;/form-login-page\u0026gt; \u0026lt;form-error-page\u0026gt;/logging_error.html\u0026lt;/form-error-page\u0026gt; \u0026lt;/form-login-config\u0026gt; \u0026lt;/login-config\u0026gt; **登录页面必须遵循 servlet 规范 2.3 的登录表单注释中定义的一些严格规则，**因为我们既不能选择表单名称，也不能选择输入字段。它们必须是j_security_check、 j_username和j_password。这是为了实现登录表单与各种资源一起使用，并且无需在服务器中配置出站表单的操作字段。在这里，我们可以看到它必须是什么样子的示例： \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Ping - Login\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;j_security_check\u0026#34;\u0026gt; \u0026lt;table \u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;User name: \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;j_username\u0026#34; size=\u0026#34;20\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Password: \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;j_password\u0026#34; size=\u0026#34;20\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;reset\u0026#34; value=\u0026#34;Reset\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 为了理解服务器收到来自 FORM 认证的 Web 应用的受保护资源的请求时会发生什么，让我们总结一下这种认证机制的流程。 首先，客户端请求一个受保护的资源。如果服务器不包含有效的 SSO 会话 ID，则服务器会将客户端重定向到日志记录表单。用户填写表单并将其凭据发送到服务器后，身份验证机制将启动。 用户认证成功后，服务器会检查用户的角色，如果安全约束至少允许其中之一，服务器会将客户端重定向到请求的 URL。在另一种情况下，服务器会将客户端重定向到错误页面。 4.2. 认证机制 在 Pong Web 应用程序中，我们使用 DIGEST 身份验证机制，配置将如下所示： \u0026lt;login-config\u0026gt; \u0026lt;auth-method\u0026gt;DIGEST\u0026lt;/auth-method\u0026gt; \u0026lt;/login-config\u0026gt; **DIGEST 身份验证机制流程类似于 BASIC 身份验证：**当客户端请求受保护的资源时，服务器返回一个对话框以请求用户凭据。如果认证成功，则服务器返回请求的资源，但在另一种情况下，服务器再次发送认证对话框。 尽管 DIGEST 和 BASIC 身份验证方法相似，但有一个重要区别：密码保留在服务器中。 4.3. Web 应用安全约束配置 在这一点上，我们不打算区分 Ping 和 Pong。尽管它们具有不同值的元素，但配置的重要部分在两个应用程序中将保持不变： \u0026lt;security-constraint\u0026gt; \u0026lt;display-name\u0026gt;Ping Login Auth\u0026lt;/display-name\u0026gt; \u0026lt;web-resource-collection\u0026gt; \u0026lt;web-resource-name\u0026gt;PingRestrictedAccess\u0026lt;/web-resource-name\u0026gt; \u0026lt;url-pattern\u0026gt;/private/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/web-resource-collection\u0026gt; \u0026lt;auth-constraint\u0026gt; \u0026lt;role-name\u0026gt;admin\u0026lt;/role-name\u0026gt; \u0026lt;/auth-constraint\u0026gt; \u0026lt;user-data-constraint\u0026gt; \u0026lt;transport-guarantee\u0026gt;NONE\u0026lt;/transport-guarantee\u0026gt; \u0026lt;/user-data-constraint\u0026gt; \u0026lt;/security-constraint\u0026gt; 安全约束定义私有文件夹下的所有内容都是受保护的资源，并且还定义了需要具有管理员角色才能访问资源。 5. 运行示例 现在我们需要安装一个Tomcat 10服务器，按照文章前面所示调整配置，将 Ping 和 Pong web 应用程序放在 Tomcat 的 web 应用程序文件夹下。 一旦服务器启动并运行，并且两个应用程序都已部署，请求资源 http://localhost:8080/ping/private。 服务器将显示登录身份验证，因为我们没有登录： 然后我们需要引入Tomcat服务器配置部分配置的凭据并提交表单。如果服务器验证了凭据，那么我们将看到一个网页，其中包含指向 pong 私有部分的链接： 如果服务器不验证访问，我们将看到登录错误页面。 成功登录 Ping 应用程序后，我们可以看到 SSO 机制正在运行，单击指向 pong 私有部分的链接。如果会话已经处于活动状态，服务器将发送 Pong 的受保护资源，而无需我们再次登录。 最后，我们可以检查会话过期后，服务器会再次显示登录页面。我们可以通过等待几分钟并单击指向 ping 私人部分的链接来做到这一点。 6. 其他 SSO 解决方案 在本文中，我们介绍了 Tomcat 服务器实现的 Web-SSO。如果我们想探索其他 SSO 选项，这里有一些流行的选项：  Spring Security 和 OpenID Connect 带有KeyCloak的 Spring Security OAuth 带有 Spring Security 的 SAML Apereo 中央认证服务 \u0026quot;  ","permalink":"http://itcodingman.github.io/apache_tomcat_sso/","tags":[],"title":"使用 Apache Tomcat 的 SSO"},{"categories":["Data"],"contents":"1. 概述 Apache Tika是一个工具包，用于从各种类型的文档中提取内容和元数据，例如 Word、Excel 和 PDF，甚至是 JPEG 和 MP4 等多媒体文件。 所有基于文本的和多媒体文件都可以使用一个通用界面进行解析，使 Tika 成为一个功能强大且用途广泛的内容分析库。 在本文中，我们将介绍 Apache Tika，包括它的解析 API 以及它如何自动检测文档的内容类型。还将提供工作示例来说明该库的操作。 2. 入门 为了使用 Apache Tika 解析文档，我们只需要一个 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tika\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tika-parsers\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到此工件的最新版本。 3. Parser API Parser API 是 Apache Tika 的核心，抽象出解析操作的复杂性。此 API 依赖于一个方法： void parse( InputStream stream, ContentHandler handler, Metadata metadata, ParseContext context) throws IOException, SAXException, TikaException 该方法的参数含义如下：  stream —— 从要解析的文档创建的InputStream实例 handler —— 一个ContentHandler对象，接收从输入文档解析的一系列 XHTML SAX 事件；然后，此处理程序将处理事件并以特定形式导出结果 metadata —— 一个Metadata对象，在解析器内外传递元数据属性 context —— 一个ParseContext实例，携带特定于上下文的信息，用于自定义解析过程  如果无法从输入流中读取，则 parse 方法抛出 IOException，如果无法解析从流中获取的文档，则抛出 TikaException ，如果处理程序无法处理事件，则抛出SAXException 。 在解析文档时，Tika 会尽可能地重用现有的解析器库，例如 Apache POI 或 PDFBox。因此，大多数Parser实现类只是这些外部库的适配器。 在第 5 节中，我们将了解如何使用处理程序和元数据参数来提取文档的内容和元数据。 为方便起见，我们可以使用外观类Tika来访问Parser API 的功能。 4. 自动检测 Apache Tika 可以根据文档本身而不是附加信息自动检测文档的类型及其语言。 4.1 文档类型检测 文档类型的检测可以使用Detector接口的实现类来完成，它有一个方法： MediaType detect(java.io.InputStream input, Metadata metadata) throws IOException 此方法获取一个文档及其关联的元数据，然后返回一个MediaType对象，该对象描述有关文档类型的最佳猜测。 元数据并不是检测器所依赖的唯一信息来源。检测器还可以使用魔术字节，这是文件开头附近的一种特殊模式，或者将检测过程委托给更合适的检测器。 事实上，检测器使用的算法是依赖于实现的。 例如，默认检测器首先使用魔术字节，然后是元数据属性。如果此时还没有找到内容类型，它将使用服务加载器来发现所有可用的检测器并依次尝试它们。 4.2. 语言检测 除了文档的类型，即使没有元数据信息的帮助，Tika 也可以识别其语言。 在以前的 Tika 版本中，使用LanguageIdentifier实例检测文档的语言。 但是，LanguageIdentifier已被弃用，取而代之的是 Web 服务，这在Getting Started文档中没有明确说明。 现在通过抽象类LanguageDetector的子类型提供语言检测服务。使用网络服务，您还可以访问成熟的在线翻译服务，例如谷歌翻译或微软翻译。 为简洁起见，我们不会详细介绍这些服务。 5. Tika在行动 本节使用工作示例说明 Apache Tika 功能。 插图方法将包装在一个类中： public class TikaAnalysis { // illustration methods } 5.1 检测文档类型 下面是我们可以用来检测从InputStream读取的文档类型的代码： public static String detectDocTypeUsingDetector(InputStream stream) throws IOException { Detector detector = new DefaultDetector(); Metadata metadata = new Metadata(); MediaType mediaType = detector.detect(stream, metadata); return mediaType.toString(); } 假设我们在类路径中有一个名为tika.txt的 PDF 文件。该文件的扩展名已更改以试图欺骗我们的分析工具。通过测试仍然可以找到并确认文档的真实类型： @Test public void whenUsingDetector_thenDocumentTypeIsReturned() throws IOException { InputStream stream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;tika.txt\u0026#34;); String mediaType = TikaAnalysis.detectDocTypeUsingDetector(stream); assertEquals(\u0026#34;application/pdf\u0026#34;, mediaType); stream.close(); } 很明显，错误的文件扩展名无法阻止 Tika 找到正确的媒体类型，这要归功于文件开头的魔术字节*%PDF 。* 为方便起见，我们可以使用Tika门面类重新编写检测代码，结果相同： public static String detectDocTypeUsingFacade(InputStream stream) throws IOException { Tika tika = new Tika(); String mediaType = tika.detect(stream); return mediaType; } 5.2. 提取内容 现在让我们提取文件的内容并将结果作为字符串返回——使用Parser API： public static String extractContentUsingParser(InputStream stream) throws IOException, TikaException, SAXException { Parser parser = new AutoDetectParser(); ContentHandler handler = new BodyContentHandler(); Metadata metadata = new Metadata(); ParseContext context = new ParseContext(); parser.parse(stream, handler, metadata, context); return handler.toString(); } 给定类路径中包含以下内容的 Microsoft Word 文件： Apache Tika - a content analysis toolkit The Apache Tika™ toolkit detects and extracts metadata and text ... 内容可以提取和验证： @Test public void whenUsingParser_thenContentIsReturned() throws IOException, TikaException, SAXException { InputStream stream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;tika.docx\u0026#34;); String content = TikaAnalysis.extractContentUsingParser(stream); assertThat(content, containsString(\u0026#34;Apache Tika - a content analysis toolkit\u0026#34;)); assertThat(content, containsString(\u0026#34;detects and extracts metadata and text\u0026#34;)); stream.close(); } 同样，使用Tika类可以更方便地编写代码： public static String extractContentUsingFacade(InputStream stream) throws IOException, TikaException { Tika tika = new Tika(); String content = tika.parseToString(stream); return content; } 5.3. 提取元数据 除了文档的内容，Parser API 还可以提取元数据： public static Metadata extractMetadatatUsingParser(InputStream stream) throws IOException, SAXException, TikaException { Parser parser = new AutoDetectParser(); ContentHandler handler = new BodyContentHandler(); Metadata metadata = new Metadata(); ParseContext context = new ParseContext(); parser.parse(stream, handler, metadata, context); return metadata; } 当类路径中存在 Microsoft Excel 文件时，此测试用例确认提取的元数据是正确的： @Test public void whenUsingParser_thenMetadataIsReturned() throws IOException, TikaException, SAXException { InputStream stream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;tika.xlsx\u0026#34;); Metadata metadata = TikaAnalysis.extractMetadatatUsingParser(stream); assertEquals(\u0026#34;org.apache.tika.parser.DefaultParser\u0026#34;, metadata.get(\u0026#34;X-Parsed-By\u0026#34;)); assertEquals(\u0026#34;Microsoft Office User\u0026#34;, metadata.get(\u0026#34;Author\u0026#34;)); stream.close(); } 最后，这是使用Tika外观类的另一个版本的提取方法： public static Metadata extractMetadatatUsingFacade(InputStream stream) throws IOException, TikaException { Tika tika = new Tika(); Metadata metadata = new Metadata(); tika.parse(stream, metadata); return metadata; } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_tika/","tags":[],"title":"使用 Apache Tika 进行内容分析"},{"categories":["Data"],"contents":"1. 概述 在本文中，我们将了解如何借助名为Apache Thrift的 RPC 框架开发跨平台的客户端-服务器应用程序。 我们将涵盖：  使用 IDL 定义数据类型和服务接口 安装库并生成不同语言的源代码 以特定语言实现定义的接口 实施客户端/服务器软件  如果您想直接看示例，请直接进入第 5 节。 2. Apache Thrift Apache Thrift 最初由 Facebook 开发团队开发，目前由 Apache 维护。 与管理跨平台对象序列化/反序列化过程的Protocol Buffers相比， Thrift 主要关注系统组件之间的通信层。 Thrift 使用一种特殊的接口描述语言 (IDL) 来定义数据类型和服务接口，这些数据类型和服务接口存储为*.thrift*文件，稍后用作编译器的输入，用于生成通过不同编程语言进行通信的客户端和服务器软件的源代码。 要在您的项目中使用 Apache Thrift，请添加以下 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.thrift\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;libthrift\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.10.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以在Maven 存储库中找到最新版本。 3.界面描述语言 如前所述，IDL允许以中性语言定义通信接口。您将在下面找到当前支持的类型。 3.1 基本类型  bool – 一个布尔值（真或假） byte – 一个 8 位有符号整数 i16 – 16 位有符号整数 i32 – 32 位有符号整数 i64 – 64 位有符号整数 double – 64 位浮点数 string – 使用 UTF-8 编码编码的文本字符串  3.2. 特殊类型  二进制- 未编码的字节序列 optional – Java 8 的可选类型  3.3. 结构 Thrift结构相当于 OOP 语言中的类，但没有继承。结构有一组强类型字段，每个字段都有一个唯一的名称作为标识符。字段可能有各种注释（数字字段 ID、可选的默认值等）。 3.4. 容器 Thrift 容器是强类型容器：  list – 元素的有序列表 set – 一组无序的唯一元素 map\u0026lt;type1,type2\u0026gt; – 值的严格唯一键映射  容器元素可以是任何有效的 Thrift 类型。 3.5. 例外 异常在功能上等同于structs，只是它们继承自本机异常。 3.6. 服务 服务实际上是使用 Thrift 类型定义的通信接口。它们由一组命名函数组成，每个函数都有一个参数列表和一个返回类型。 4. 源代码生成 4.1 语言支持 当前支持的语言有一长串：  C++ C＃ Go Java Javascript Node.js Perl PHP Python Ruby  您可以在此处查看完整列表。 4.2. 使用库的可执行文件 只需下载最新版本，如有必要，构建并安装它，并使用以下语法： cd path/to/thrift thrift -r --gen [LANGUAGE] [FILENAME] 在上面设置的命令中，[LANGUAGE]是支持的语言之一，[FILENAME ] 是具有 IDL 定义的文件。 注意*-r标志。它告诉 Thrift 一旦注意到包含在给定的.thrift*文件中，就递归地生成代码。 4.3. 使用 Maven 插件 在pom.xml文件中添加插件： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.thrift.tools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-thrift-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.1.11\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;thriftExecutable\u0026gt;path/to/thrift\u0026lt;/thriftExecutable\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;thrift-sources\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;generate-sources\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;compile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 之后只需执行以下命令： mvn clean install 请注意，此插件将不再有任何进一步的维护。请访问此页面了解更多信息。 5. 客户端-服务器应用程序示例 5.1 定义 Thrift 文件 让我们编写一些带有异常和结构的简单服务： namespace cpp com.codingman.thrift.impl namespace java com.codingman.thrift.impl exception InvalidOperationException { 1: i32 code, 2: string description } struct CrossPlatformResource { 1: i32 id, 2: string name, 3: optional string salutation } service CrossPlatformService { CrossPlatformResource get(1:i32 id) throws (1:InvalidOperationException e), void save(1:CrossPlatformResource resource) throws (1:InvalidOperationException e), list \u0026lt;CrossPlatformResource\u0026gt; getList() throws (1:InvalidOperationException e), bool ping() throws (1:InvalidOperationException e) } 如您所见，语法非常简单且不言自明。我们定义了一组命名空间（每种实现语言）、一个异常类型、一个结构，最后是一个服务接口，这些接口将在不同的组件之间共享。 然后将其存储为service.thrift文件。 5.2. 编译和生成代码 现在是时候运行一个编译器来为我们生成代码了： thrift -r -out generated --gen java /path/to/service.thrift 如您所见，我们添加了一个特殊标志*-out*来指定生成文件的输出目录。如果您没有收到任何错误，生成的目录将包含 3 个文件：  CrossPlatformResource.java CrossPlatformService.java InvalidOperationException.java  让我们通过运行以下命令生成服务的 C++ 版本： thrift -r -out generated --gen cpp /path/to/service.thrift 现在我们得到相同服务接口的 2 个不同的有效实现（Java 和 C++）。 5.3. 添加服务实现 尽管 Thrift 为我们完成了大部分工作，但我们仍然需要编写自己的CrossPlatformService实现。为此，我们只需要实现一个CrossPlatformService.Iface接口： public class CrossPlatformServiceImpl implements CrossPlatformService.Iface { @Override public CrossPlatformResource get(int id) throws InvalidOperationException, TException { return new CrossPlatformResource(); } @Override public void save(CrossPlatformResource resource) throws InvalidOperationException, TException { saveResource(); } @Override public List\u0026lt;CrossPlatformResource\u0026gt; getList() throws InvalidOperationException, TException { return Collections.emptyList(); } @Override public boolean ping() throws InvalidOperationException, TException { return true; } } 5.4. 编写服务器 正如我们所说，我们想要构建一个跨平台的客户端-服务器应用程序，因此我们需要一个服务器。Apache Thrift 的伟大之处在于它拥有自己的客户端-服务器通信框架，这让通信变得轻而易举： public class CrossPlatformServiceServer { public void start() throws TTransportException { TServerTransport serverTransport = new TServerSocket(9090); server = new TSimpleServer(new TServer.Args(serverTransport) .processor(new CrossPlatformService.Processor\u0026lt;\u0026gt;(new CrossPlatformServiceImpl()))); System.out.print(\u0026#34;Starting the server... \u0026#34;); server.serve(); System.out.println(\u0026#34;done.\u0026#34;); } public void stop() { if (server != null \u0026amp;\u0026amp; server.isServing()) { System.out.print(\u0026#34;Stopping the server... \u0026#34;); server.stop(); System.out.println(\u0026#34;done.\u0026#34;); } } } 首先是定义一个传输层，实现TServerTransport接口（或者更准确地说是抽象类）。既然我们在谈论服务器，我们需要提供一个端口来监听。然后我们需要定义一个TServer实例并选择一个可用的实现：  TSimpleServer – 用于简单服务器 TThreadPoolServer – 用于多线程服务器 TNonblockingServer – 用于非阻塞多线程服务器  最后，为选择的服务器提供一个处理器实现，它已经由 Thrift 为我们生成，即CrossPlatofformService.Processor类。 5.5. 编写客户端 这是客户端的实现： TTransport transport = new TSocket(\u0026#34;localhost\u0026#34;, 9090); transport.open(); TProtocol protocol = new TBinaryProtocol(transport); CrossPlatformService.Client client = new CrossPlatformService.Client(protocol); boolean result = client.ping(); transport.close(); 从客户的角度来看，这些操作非常相似。 首先，定义传输并将其指向我们的服务器实例，然后选择合适的协议。唯一的区别是我们在这里初始化了客户端实例，它再次由 Thrift 生成，即CrossPlatformService.Client类。 由于它基于*.thrift*文件定义，我们可以直接调用那里描述的方法。在这个特定的示例中，client.ping()将对服务器进行远程调用，该服务器将以true响应。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_thrift/","tags":[],"title":"使用 Apache Thrift"},{"categories":["Java"],"contents":"1. 概述 如今，从社交网络到银行业务，从医疗保健到政府服务，所有活动都可以在线进行。因此，他们严重依赖 Web 应用程序。 Web 应用程序使用户能够消费/享受公司提供的在线服务。同时，它充当后端软件的接口。 在这个介绍性教程中，我们将探索 Apache Tapestry Web 框架并使用它提供的基本功能创建一个简单的 Web 应用程序。 2. Apache Tapestry Apache Tapestry 是一个基于组件的框架，用于构建可扩展的 Web 应用程序。 它遵循约定优于配置的范式，并使用注释和命名约定进行配置。 所有组件都是简单的 POJO。同时，它们是从零开始开发的，不依赖于其他库。 除了 Ajax 支持之外，Tapestry 还具有出色的异常报告功能。它还提供了一个广泛的内置通用组件库。 在其他重要功能中，一个突出的特点是代码的热重载。因此，使用此功能，我们可以立即看到开发环境中的变化。 3. 设置 Apache Tapestry 需要一组简单的工具来创建 Web 应用程序：  Java 1.6 或更高版本 构建工具（Maven 或 Gradle） IDE（Eclipse 或 IntelliJ） 应用服务器（Tomcat 或 Jetty）  在本教程中，我们将结合使用 Java 8、Maven、Eclipse 和 Jetty Server。 要设置最新的Apache Tapestry 项目，我们将使用Maven 原型并按照官方文档提供的说明进行操作： $ mvn archetype:generate -DarchetypeCatalog=http://tapestry.apache.org 或者，如果我们有一个现有项目，我们可以简单地将Tapestry-core Maven 依赖项添加到pom.xml： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tapestry\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tapestry-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.4.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 一旦我们准备好设置，我们可以通过以下 Maven 命令启动应用程序apache-tapestry ： $ mvn jetty:run 默认情况下，可以通过localhost:8080/apache-tapestry 访问该应用程序： 4. 项目结构 让我们探索一下 Apache Tapestry 创建的项目布局： 我们可以看到一个类似 Maven 的项目结构，以及一些基于约定的包。 Java 类被放置在src/main/java并被分类为components、pages和services 。 同样，src/main/resources包含我们的模板（类似于 HTML 文件）——它们具有*.tml*扩展名。 对于放置在组件和页面目录下的每个 Java 类，都应该创建一个同名的模板文件。** src/main/webapp目录包含图像、样式表和 JavaScript 文件等资源。同样，测试文件放在src/test中。 最后，src/site将包含文档文件。 为了更好的理解，我们来看看在 Eclipse IDE 中打开的项目结构： 5. 注释 让我们讨论Apache Tapestry 为日常使用提供的一些方便的注释。展望未来，我们将在我们的实现中使用这些注释。 5.1 @Inject @Inject注解在org.apache.tapestry5.ioc.annotations包中可用，它提供了一种在 Java 类中注入依赖项的简单方法。 这个注解对于注入资产、块、资源和服务非常方便。 5.2. @InjectPage 在org.apache.tapestry5.annotations包中可用，@InjectPage注释允许我们将页面注入另一个组件。此外，注入的页面始终是只读属性。 5.3. @InjectComponent 类似地，@InjectComponent注解允许我们注入模板中定义的组件。 5.4. @Log @Log注释在org.apache.tapestry5.annotations包中可用，并且可以方便地在任何方法上启用 DEBUG 级别的日志记录。它记录方法的进入和退出，以及参数值。 5.5. @Property 在org.apache.tapestry5.annotations包中可用， @Property注释将字段标记为属性。同时，它会自动为属性创建 getter 和 setter。 5.6. @Parameter 类似地，*@Parameter*注解表示一个字段是一个组件参数。 6.页面 因此，我们都准备好探索框架的基本功能。让我们在我们的应用程序中创建一个新的主页。 首先，我们将在src/main/java的pages目录中定义一个 Java 类Home： public class Home { } 6.1模板 然后，我们将在src/main/resources下的pages目录中创建一个对应的Home.tml模板。 扩展名为*.tml*（Tapestry 标记语言）的文件类似于 Apache Tapestry 提供的具有 XML 标记的 HTML/XHTML 文件。 例如，让我们看一下Home.tml模板： \u0026lt;html xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_4.xsd\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;apache-tapestry Home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 瞧！只需重启 Jetty 服务器，我们就可以在localhost:8080/apache-tapestry/home 访问主页： 6.2. Property 让我们探索如何在主页上呈现属性。 为此，我们将在Home类中添加一个属性和一个 getter 方法： @Property private String appName = \u0026#34;apache-tapestry\u0026#34;; public Date getCurrentTime() { return new Date(); } 要在主页上呈现appName属性，我们可以简单地使用*${appName}*。 同样，我们可以编写*${currentTime}从页面访问getCurrentTime*方法。 6.3. 本土化 Apache Tapestry 提供集成的本地化支持。按照惯例，页面名称属性文件保存要在页面上呈现的所有本地消息的列表。 例如，我们将在主页的**pages目录中创建一个带有本地消息的home.properties文件： introMsg=Welcome to the Apache Tapestry Tutorial 消息属性不同于 Java 属性。 出于同样的原因，带有消息前缀的键名用于呈现消息属性——例如，${message:introMsg}。 6.4. 布局组件 让我们通过创建Layout.java类来定义一个基本的布局组件。我们将文件保存在src/main/java的**components目录中： public class Layout { @Property @Parameter(required = true, defaultPrefix = BindingConstants.LITERAL) private String title; } 在这里，title属性被标记为必需，并且绑定的默认前缀设置为文字String。 然后，我们会在src/main/resources的components目录下编写一个对应的模板文件Layout.tml： \u0026lt;html xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_4.xsd\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;${title}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;t:body /\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;© Your Company\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 现在，让我们使用主页上的布局： \u0026lt;html t:type=\u0026#34;layout\u0026#34; title=\u0026#34;apache-tapestry Home\u0026#34; xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_4.xsd\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Home! ${appName}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;${message:introMsg}\u0026lt;/h2\u0026gt; \u0026lt;h3\u0026gt;${currentTime}\u0026lt;/h3\u0026gt; \u0026lt;/html\u0026gt; 请注意，命名空间用于标识Apache Tapestry 提供的元素（ t:type和*t:body ）。*同时，命名空间还提供了组件和属性。 在这里，t:type将设置主页上的布局。并且，t:body元素将插入页面的内容。 让我们看一下带有布局的主页： 7.表格 让我们创建一个带有表单的登录页面，以允许用户登录。 如前所述，我们将首先创建一个 Java 类Login： public class Login { // ...  @InjectComponent private Form login; @Property private String email; @Property private String password; } 在这里，我们定义了两个属性—— email和password。此外，我们还为登录注入了一个表单组件。 然后，让我们创建一个对应的模板login.tml： \u0026lt;html t:type=\u0026#34;layout\u0026#34; title=\u0026#34;apache-tapestry com.example\u0026#34; xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_3.xsd\u0026#34; xmlns:p=\u0026#34;tapestry:parameter\u0026#34;\u0026gt; \u0026lt;t:form t:id=\u0026#34;login\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Please sign in\u0026lt;/h2\u0026gt; \u0026lt;t:textfield t:id=\u0026#34;email\u0026#34; placeholder=\u0026#34;Email address\u0026#34;/\u0026gt; \u0026lt;t:passwordfield t:id=\u0026#34;password\u0026#34; placeholder=\u0026#34;Password\u0026#34;/\u0026gt; \u0026lt;t:submit class=\u0026#34;btn btn-large btn-primary\u0026#34; value=\u0026#34;Sign in\u0026#34;/\u0026gt; \u0026lt;/t:form\u0026gt; \u0026lt;/html\u0026gt; 现在，我们可以在localhost:8080/apache-tapestry/login 访问登录页面： 8. 验证 Apache Tapestry 提供了一些用于表单验证的内置方法。它还提供了处理表单提交成功或失败的方法。 内置方法遵循事件和组件名称的约定。例如，方法onValidationFromLogin将验证Login组件。 同样，像onSuccessFromLogin和onFailureFromLogin这样的方法分别用于成功和失败事件。 因此，让我们将这些内置方法添加到Login类中： public class Login { // ...  void onValidateFromLogin() { if (email == null) System.out.println(\u0026#34;Email is null); if (password == null) System.out.println(\u0026#34;Password is null); } Object onSuccessFromLogin() { System.out.println(\u0026#34;Welcome! Login Successful\u0026#34;); return Home.class; } void onFailureFromLogin() { System.out.println(\u0026#34;Please try again with correct credentials\u0026#34;); } } 9. 警报 如果没有适当的警报，表单验证是不完整的。更不用说，该框架还内置了对警报消息的支持。 为此，我们将首先在Login类中注入AlertManager的实例来管理警报*。然后，将现有方法中的println*语句替换为警告消息： public class Login { // ...  @Inject private AlertManager alertManager; void onValidateFromLogin() { if(email == null || password == null) { alertManager.error(\u0026#34;Email/Password is null\u0026#34;); login.recordError(\u0026#34;Validation failed\u0026#34;); //submission failure on the form  } } Object onSuccessFromLogin() { alertManager.success(\u0026#34;Welcome! Login Successful\u0026#34;); return Home.class; } void onFailureFromLogin() { alertManager.error(\u0026#34;Please try again with correct credentials\u0026#34;); } } 让我们看看登录失败时的警报： 10. Ajax 到目前为止，我们已经探索了使用表单创建一个简单的主页。同时，我们看到了对警报消息的验证和支持。 接下来，让我们探索一下 Apache Tapestry 对 Ajax 的内置支持。 首先，我们将在Home类中注入AjaxResponseRenderer和Block组件的实例。然后，我们将创建一个onCallAjax方法来处理 Ajax 调用： public class Home { // ....  @Inject private AjaxResponseRenderer ajaxResponseRenderer; @Inject private Block ajaxBlock; @Log void onCallAjax() { ajaxResponseRenderer.addRender(\u0026#34;ajaxZone\u0026#34;, ajaxBlock); } } 此外，我们需要在Home.tml中进行一些更改。 首先，我们将添加eventLink以调用onCallAjax方法。然后，我们将添加一个id 为ajaxZone的zone元素来呈现 Ajax 响应。 最后，我们需要一个块组件，该组件将被注入Home类并呈现为 Ajax 响应： \u0026lt;p\u0026gt;\u0026lt;t:eventlink event=\u0026#34;callAjax\u0026#34; zone=\u0026#34;ajaxZone\u0026#34; class=\u0026#34;btn btn-default\u0026#34;\u0026gt;Call Ajax\u0026lt;/t:eventlink\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;t:zone t:id=\u0026#34;ajaxZone\u0026#34;\u0026gt;\u0026lt;/t:zone\u0026gt; \u0026lt;t:block t:id=\u0026#34;ajaxBlock\u0026#34;\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;h2\u0026gt;Rendered through Ajax\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The current time is: \u0026lt;strong\u0026gt;${currentTime}\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/t:block\u0026gt; 我们来看看更新后的主页： 然后，我们可以单击 Call Ajax 按钮并查看ajaxResponseRenderer的运行情况： 11. 记录 要启用内置的日志记录功能，需要注入Logger的实例。然后，我们可以使用它来记录任何级别的日志，例如 TRACE、DEBUG 和 INFO。 因此，让我们在Home类中进行必要的更改： public class Home { // ...  @Inject private Logger logger; void onCallAjax() { logger.info(\u0026#34;Ajax call\u0026#34;); ajaxResponseRenderer.addRender(\u0026#34;ajaxZone\u0026#34;, ajaxBlock); } } 现在，当我们单击 Call Ajax 按钮时，记录器将在 INFO 级别记录： [INFO] pages.Home Ajax call \u0026quot; ","permalink":"http://itcodingman.github.io/apache_tapestry/","tags":[],"title":"Apache Tapestry 简介"},{"categories":["Architecture","Java"],"contents":" 概述   本教程将介绍分布式实时计算系统Apache Storm 。 我们将重点关注并涵盖：  Apache Storm 到底是什么以及它解决了什么问题 它的架构，以及 如何在项目中使用它  什么是 Apache Storm？   Apache Storm 是用于实时计算的免费和开源分布式系统。 它提供容错性、可扩展性和保证数据处理，尤其擅长处理无界数据流。 Storm 的一些很好的用例可以是处理信用卡操作以检测欺诈或处理来自智能家居的数据以检测故障传感器。 Storm 允许与市场上可用的各种数据库和排队系统集成。 Maven依赖   在我们使用 Apache Storm 之前，我们需要在我们的项目中包含storm-core 依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.storm\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;storm-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 如果我们打算在 Storm 集群上运行我们的应用程序，我们应该只使用提供的范围 。 要在本地运行应用程序，我们可以使用所谓的本地模式，在本地进程中模拟 Storm 集群，在这种情况下我们应该删除 提供的。 数据模型   Apache Storm 的数据模型由两个元素组成：元组和流。 4.1 元组 元组是具有动态类型的命名字段的有序列表。 这意味着我们不需要显式声明字段的类型。 Storm 需要知道如何序列化元组中使用的所有值。默认情况下，它已经可以序列化原始类型、字符串和字节数组。 而且由于 Storm 使用 Kryo 序列化，我们需要使用 Config注册序列化器 以使用自定义类型。我们可以通过以下两种方式之一来做到这一点： 首先，我们可以使用其全名注册要序列化的类： Config config = new Config(); config.registerSerialization(User.class); 在这种情况下，Kryo 将使用*FieldSerializer序列化类。*默认情况下，这将序列化类的所有非瞬态字段，包括私有的和公共的。 或者，我们可以同时提供要序列化的类和我们希望 Storm 用于该类的序列化器： Config config = new Config(); config.registerSerialization(User.class, UserSerializer.class); 要创建自定义序列化程序，我们需要扩展具有 写入和 读取两种方法 的通用类Serializer 。 4.2. Stream Stream是 Storm 生态系统中的核心抽象。 Stream是一个无界的元组序列。 Storms 允许并行处理多个流。 每个流都有一个在声明期间提供和分配的 id。 拓扑   实时 Storm 应用的逻辑被封装到拓扑中。拓扑由 spouts和bolts组成。 5.1 Spout Spout 是流的来源。它们向拓扑发出元组。 元组可以从各种外部系统（如 Kafka、Kestrel 或 ActiveMQ）中读取。 Spout 可以是 可靠的 或 不可靠的。可靠 意味着 spout 可以回复 Storm 处理失败的元组。 不可靠意味着 spout 不响应，因为它将使用即发即弃机制来发出元组。 要创建自定义 spout，我们需要实现 IRichSpout接口或扩展任何已经实现该接口的类，例如抽象 BaseRichSpout类。 让我们创建一个 不可靠的spout： public class RandomIntSpout extends BaseRichSpout { private Random random; private SpoutOutputCollector outputCollector; @Override public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) { random = new Random(); outputCollector = spoutOutputCollector; } @Override public void nextTuple() { Utils.sleep(1000); outputCollector.emit(new Values(random.nextInt(), System.currentTimeMillis())); } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { outputFieldsDeclarer.declare(new Fields(\u0026#34;randomInt\u0026#34;, \u0026#34;timestamp\u0026#34;)); } } 我们自定义的 RandomIntSpout将每秒生成随机整数和时间戳。 5.2. Bolts **Bolts 处理流中的元组。**它们可以执行各种操作，如过滤、聚合或自定义函数。 有些操作需要多个步骤，因此在这种情况下我们需要使用多个螺栓。 要创建自定义 Bolt，我们需要实现 IRichBolt或更简单的操作 IBasicBolt接口。 还有多个帮助类可用于实现 *Bolt。*在这种情况下，我们将使用 BaseBasicBolt： public class PrintingBolt extends BaseBasicBolt { @Override public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) { System.out.println(tuple); } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { } } 这个自定义 的PrintingBolt将简单地将所有元组打印到控制台。 创建一个简单的拓扑   让我们把这些想法放在一个简单的拓扑中。我们的拓扑将有一个 spout 和三个 bolt。 6.1 随机数Spout 一开始，我们将创建一个不可靠的 spout。它将每秒从 (0,100) 范围内生成随机整数： public class RandomNumberSpout extends BaseRichSpout { private Random random; private SpoutOutputCollector collector; @Override public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) { random = new Random(); collector = spoutOutputCollector; } @Override public void nextTuple() { Utils.sleep(1000); int operation = random.nextInt(101); long timestamp = System.currentTimeMillis(); Values values = new Values(operation, timestamp); collector.emit(values); } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { outputFieldsDeclarer.declare(new Fields(\u0026#34;operation\u0026#34;, \u0026#34;timestamp\u0026#34;)); } } 6.2. 过滤Bolt 接下来，我们将创建一个Bolt，它将过滤掉所有 操作 等于 0 的元素： public class FilteringBolt extends BaseBasicBolt { @Override public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) { int operation = tuple.getIntegerByField(\u0026#34;operation\u0026#34;); if (operation \u0026gt; 0) { basicOutputCollector.emit(tuple.getValues()); } } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { outputFieldsDeclarer.declare(new Fields(\u0026#34;operation\u0026#34;, \u0026#34;timestamp\u0026#34;)); } } 6.3. 聚合Bolt 接下来，让我们创建一个更复杂的 Bolt，它将汇总每天的所有积极操作。 为此，我们将使用一个专门为实现在窗口上操作而不是在单个元组上操作的Bolt而创建的特定类： BaseWindowedBolt。 Windows是流处理中的一个基本概念，它将无限的流分成有限的块。然后我们可以对每个块应用计算。窗户一般有两种： 时间窗口用于使用时间戳对给定时间段的元素进行分组。时间窗口可能有不同数量的元素。 计数窗口用于创建具有定义大小的窗口。在这种情况下，所有窗口都将具有相同的大小，如果元素少于定义的大小，则不会发出窗口。 我们的AggregatingBolt将生成来自**时间窗口的所有正操作的总和以及它的开始和结束时间戳： public class AggregatingBolt extends BaseWindowedBolt { private OutputCollector outputCollector; @Override public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) { this.outputCollector = collector; } @Override public void declareOutputFields(OutputFieldsDeclarer declarer) { declarer.declare(new Fields(\u0026#34;sumOfOperations\u0026#34;, \u0026#34;beginningTimestamp\u0026#34;, \u0026#34;endTimestamp\u0026#34;)); } @Override public void execute(TupleWindow tupleWindow) { List\u0026lt;Tuple\u0026gt; tuples = tupleWindow.get(); tuples.sort(Comparator.comparing(this::getTimestamp)); int sumOfOperations = tuples.stream() .mapToInt(tuple -\u0026gt; tuple.getIntegerByField(\u0026#34;operation\u0026#34;)) .sum(); Long beginningTimestamp = getTimestamp(tuples.get(0)); Long endTimestamp = getTimestamp(tuples.get(tuples.size() - 1)); Values values = new Values(sumOfOperations, beginningTimestamp, endTimestamp); outputCollector.emit(values); } private Long getTimestamp(Tuple tuple) { return tuple.getLongByField(\u0026#34;timestamp\u0026#34;); } } 请注意，在这种情况下，直接获取列表的第一个元素是安全的。这是因为每个窗口都是使用 元组 的**时间戳字段计算的 ，所以每个窗口中必须****至少有一个元素。 6.4. 文件写入Bolt 最后，我们将创建一个 Bolt，它将所有 sumOfOperations大于 2000 的元素，序列化并将它们写入文件： public class FileWritingBolt extends BaseRichBolt { public static Logger logger = LoggerFactory.getLogger(FileWritingBolt.class); private BufferedWriter writer; private String filePath; private ObjectMapper objectMapper; @Override public void cleanup() { try { writer.close(); } catch (IOException e) { logger.error(\u0026#34;Failed to close writer!\u0026#34;); } } @Override public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) { objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); try { writer = new BufferedWriter(new FileWriter(filePath)); } catch (IOException e) { logger.error(\u0026#34;Failed to open a file for writing.\u0026#34;, e); } } @Override public void execute(Tuple tuple) { int sumOfOperations = tuple.getIntegerByField(\u0026#34;sumOfOperations\u0026#34;); long beginningTimestamp = tuple.getLongByField(\u0026#34;beginningTimestamp\u0026#34;); long endTimestamp = tuple.getLongByField(\u0026#34;endTimestamp\u0026#34;); if (sumOfOperations \u0026gt; 2000) { AggregatedWindow aggregatedWindow = new AggregatedWindow( sumOfOperations, beginningTimestamp, endTimestamp); try { writer.write(objectMapper.writeValueAsString(aggregatedWindow)); writer.newLine(); writer.flush(); } catch (IOException e) { logger.error(\u0026#34;Failed to write data to file.\u0026#34;, e); } } } // public constructor and other methods } 请注意，我们不需要声明输出，因为这将是我们拓扑中的最后一个Bolt 6.5 运行拓扑 最后，我们可以将所有内容放在一起并运行我们的拓扑： public static void runTopology() { TopologyBuilder builder = new TopologyBuilder(); Spout random = new RandomNumberSpout(); builder.setSpout(\u0026#34;randomNumberSpout\u0026#34;); Bolt filtering = new FilteringBolt(); builder.setBolt(\u0026#34;filteringBolt\u0026#34;, filtering) .shuffleGrouping(\u0026#34;randomNumberSpout\u0026#34;); Bolt aggregating = new AggregatingBolt() .withTimestampField(\u0026#34;timestamp\u0026#34;) .withLag(BaseWindowedBolt.Duration.seconds(1)) .withWindow(BaseWindowedBolt.Duration.seconds(5)); builder.setBolt(\u0026#34;aggregatingBolt\u0026#34;, aggregating) .shuffleGrouping(\u0026#34;filteringBolt\u0026#34;); String filePath = \u0026#34;./src/main/resources/data.txt\u0026#34;; Bolt file = new FileWritingBolt(filePath); builder.setBolt(\u0026#34;fileBolt\u0026#34;, file) .shuffleGrouping(\u0026#34;aggregatingBolt\u0026#34;); Config config = new Config(); config.setDebug(false); LocalCluster cluster = new LocalCluster(); cluster.submitTopology(\u0026#34;Test\u0026#34;, config, builder.createTopology()); } 为了使数据流过拓扑中的每一部分，我们需要指出如何连接它们。shuffleGroup允许我们声明 filterBolt 的数据 将来自 randomNumberSpout。 对于每个 Bolt，我们需要添加 shuffleGroup，它定义了这个 Bolt 的元素来源。 元素的来源可能是一个 Spout或另一个 *Bolt。如果我们为多个 bolt 设置相同的源，*源将向它们中的每一个发出所有元素。 在这种情况下，我们的拓扑将使用 LocalCluster 在本地运行作业。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_storm/","tags":[],"title":"Apache Storm 简介"},{"categories":["DevOps"],"contents":"1. 简介 Apache Spark是一个开源集群计算框架。它为 Scala、Java、Python 和 R 提供了优雅的开发 API，允许开发人员跨不同的数据源执行各种数据密集型工作负载，包括 HDFS、Cassandra、HBase、S3 等。 从历史上看，Hadoop 的 MapReduce 被证明对于一些迭代和交互式计算工作效率低下，最终导致了 Spark 的发展。使用 Spark，我们在内存中运行逻辑的速度比使用 Hadoop 快两个数量级，或者在磁盘上运行速度快一个数量级。 2. Spark 架构 Spark 应用程序在集群上作为独立的进程集运行，如下图所述： 这些进程集由主程序（称为驱动程序）中的SparkContext对象协调。**SparkContext连接到几种类型的集群管理器（Spark 自己的独立集群管理器、Mesos 或 YARN），它们在应用程序之间分配资源。 连接后，Spark 会在集群中的节点上获取执行程序，这些节点是为您的应用程序运行计算和存储数据的进程。 接下来，它将您的应用程序代码（由传递给SparkContext的 JAR 或 Python 文件定义）发送到执行程序。最后，SparkContext将任务发送给执行器运行。 3. 核心组件 下图清晰地展示了 Spark 的不同组件： 3.1 Spark Core Spark Core 组件负责所有基本的 I/O 功能、调度和监控 Spark 集群上的作业、任务调度、与不同存储系统的联网、故障恢复和高效的内存管理。 与 Hadoop 不同，Spark 通过使用称为 RDD（弹性分布式数据集）的特殊数据结构，避免将共享数据存储在 Amazon S3 或 HDFS 等中间存储中。 弹性分布式数据集是不可变的，是记录的分区集合，可以并行操作并允许容错“内存中”计算。 RDD 支持两种操作：   转换——Spark RDD 转换是一个从现有 RDD 生成新 RDD 的函数。Transformer 将 RDD 作为输入，并产生一个或多个 RDD 作为输出。转换本质上是惰性的，即当我们调用一个动作时它们会被执行   动作**-**转换从彼此创建 RDD，但是当我们想要使用实际数据集时，此时会执行动作。因此，**Action是提供非 RDD 值的 Spark RDD 操作。**动作值存储到驱动程序或外部存储系统   动作是从 Executor 向驱动程序发送数据的方式之一。 执行者是负责执行任务的代理。而驱动程序是一个 JVM 进程，它协调工作人员和任务的执行。Spark 的一些动作是计数和收集。 3.2. Spark SQL Spark SQL 是用于结构化数据处理的 Spark 模块。它主要用于执行 SQL 查询。DataFrame构成了 Spark SQL 的主要抽象。排序到命名列中的分布式数据集合在 Spark 中称为DataFrame。 Spark SQL 支持从 Hive、Avro、Parquet、ORC、JSON 和 JDBC 等不同来源获取数据。它还可以使用 Spark 引擎扩展到数千个节点和数小时的查询，该引擎提供完整的中间查询容错。 3.3. Spark Streaming Spark Streaming 是核心 Spark API 的扩展，支持实时数据流的可扩展、高吞吐量、容错流处理。可以从多个来源获取数据，例如 Kafka、Flume、Kinesis 或 TCP 套接字。 最后，处理后的数据可以推送到文件系统、数据库和实时仪表板。 3.4. Spark Mlib MLlib 是 Spark 的机器学习 (ML) 库。它的目标是使实用的机器学习变得可扩展且简单。在高层次上，它提供了以下工具：  ML 算法——常见的学习算法，例如分类、回归、聚类和协同过滤 特征化——特征提取、转换、降维和选择 Pipelines——用于构建、评估和调整 ML Pipelines 的工具 持久性——保存和加载算法、模型和管道 实用工具——线性代数、统计、数据处理等。  3.5. Spark GraphX **GraphX 是用于图形和图形并行计算的组件。**在高层次上，GraphX 通过引入新的 Graph 抽象扩展了 Spark RDD：一个有向多重图，其属性附加到每个顶点和边。 为了支持图计算，GraphX 公开了一组基本操作符（例如subgraph、joinVertices和aggregateMessages）。 此外，GraphX 包括越来越多的图形算法和构建器，以简化图形分析任务。 4. Spark 中的“Hello World” 现在我们了解了核心组件，我们可以继续进行简单的基于 Maven 的 Spark 项目——用于计算字数。 我们将演示 Spark 在本地模式下运行，其中所有组件都在同一台机器上本地运行，它是主节点、执行程序节点或 Spark 的独立集群管理器。 4.1 Maven 设置 让我们在pom.xml文件中建立一个带有Spark 相关依赖项的 Java Maven 项目： \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spark-core_2.10\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 4.2. 字数 - Spark 作业 现在让我们编写 Spark 作业来处理包含句子的文件并输出不同的单词及其在文件中的计数： public static void main(String[] args) throws Exception { if (args.length \u0026lt; 1) { System.err.println(\u0026#34;Usage: JavaWordCount \u0026lt;file\u0026gt;\u0026#34;); System.exit(1); } SparkConf sparkConf = new SparkConf().setAppName(\u0026#34;JavaWordCount\u0026#34;); JavaSparkContext ctx = new JavaSparkContext(sparkConf); JavaRDD\u0026lt;String\u0026gt; lines = ctx.textFile(args[0], 1); JavaRDD\u0026lt;String\u0026gt; words = lines.flatMap(s -\u0026gt; Arrays.asList(SPACE.split(s)).iterator()); JavaPairRDD\u0026lt;String, Integer\u0026gt; ones = words.mapToPair(word -\u0026gt; new Tuple2\u0026lt;\u0026gt;(word, 1)); JavaPairRDD\u0026lt;String, Integer\u0026gt; counts = ones.reduceByKey((Integer i1, Integer i2) -\u0026gt; i1 + i2); List\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; output = counts.collect(); for (Tuple2\u0026lt;?, ?\u0026gt; tuple : output) { System.out.println(tuple._1() + \u0026#34;: \u0026#34; + tuple._2()); } ctx.stop(); } 请注意，我们将本地文本文件的路径作为参数传递给 Spark 作业。 SparkContext对象是Spark的主要入口点，表示与已经运行的 Spark 集群的连接。它使用SparkConf对象来描述应用程序配置。SparkContext用于读取内存中的文本文件作为JavaRDD对象。 接下来，我们使用flatmap方法将行**JavaRDD对象转换为单词JavaRDD对象，首先将每行转换为空格分隔的单词，然后将每行处理的输出展平。 我们再次应用变换操作mapToPair，它基本上将每个单词的出现映射到单词的元组和 1 的计数。 然后，我们应用reduceByKey操作将多次出现的计数为 1 的单词分组到单词元组中，并将计数相加。 最后，我们执行收集RDD 动作以获得最终结果。 4.3. 执行——Spark 作业 现在让我们使用 Maven 构建项目以在目标文件夹中生成apache-spark-1.0-SNAPSHOT.jar 。 接下来，我们需要将这个 WordCount 作业提交给 Spark： ${spark-install-dir}/bin/spark-submit --class com.codingman.WordCount --master local ${WordCount-MavenProject}/target/apache-spark-1.0-SNAPSHOT.jar ${WordCount-MavenProject}/src/main/resources/spark_example.txt 在运行上述命令之前，需要更新 Spark 安装目录和 WordCount Maven 项目目录。 在提交时，幕后会发生几个步骤：  从驱动程序代码，SparkContext连接到集群管理器（在我们的例子中，火花独立集群管理器在本地运行） 集群管理器在其他应用程序之间分配资源 Spark 在集群中的节点上获取执行器。在这里，我们的字数统计应用程序将获得自己的执行程序进程 应用程序代码（jar 文件）被发送到执行器 任务由SparkContext发送给执行者。  最后，将 spark 作业的结果返回给驱动程序，我们将看到文件中的字数作为输出： Hello 1 from 2 Baledung 2 Keep 1 Learning 1 Spark 1 Bye 1 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_spark/","tags":["Spark"],"title":"Apache Spark 简介"},{"categories":["Data","NoSQL"],"contents":"1. 概述 Apache Solr是一个建立在 Lucene 之上的开源搜索平台。Apache SolrJ 是一个基于 Java 的 Solr 客户端，它为搜索的主要功能（如索引、查询和删除文档）提供接口。 在本文中，我们将探讨如何使用 SolrJ 与 Apache Solr 服务器交互。 2. 设置 为了在您的机器上安装 Solr 服务器，请参阅Solr 快速入门指南。 安装过程很简单——只需下载 zip/tar 包，解压缩内容，然后从命令行启动服务器。对于本文，我们将创建一个具有名为“bigboxstore”的核心的 Solr 服务器： bin/solr start bin/solr create -c \u0026#39;bigboxstore\u0026#39; 默认情况下，Solr 侦听端口 8983 以获取传入的 HTTP 查询。您可以通过在浏览器中打开http://localhost:8983/solr/#/bigboxstore URL 并观察 Solr Dashboard来验证它是否已成功启动。 3. Maven配置 现在我们已经启动并运行了 Solr 服务器，让我们直接跳到 SolrJ Java 客户端。要在您的项目中使用 SolrJ，您需要在pom.xml文件中声明以下 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.solr\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;solr-solrj\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您总能找到由Maven Central托管的最新版本。 4. Apache SolrJ Java API 让我们通过连接到我们的 Solr 服务器来启动 SolrJ 客户端： String urlString = \u0026#34;http://localhost:8983/solr/bigboxstore\u0026#34;; HttpSolrClient solr = new HttpSolrClient.Builder(urlString).build(); solr.setParser(new XMLResponseParser()); 注意：SolrJ 使用二进制格式而不是 XML作为其默认响应格式。为了与 Solr 兼容，需要将*setParser()*显式调用到 XML，如上所示。可以在此处找到有关此的更多详细信息。 4.1 索引文件 让我们使用SolrInputDocument定义要索引的数据，并使用*add()*方法将其添加到我们的索引中： SolrInputDocument document = new SolrInputDocument(); document.addField(\u0026#34;id\u0026#34;, \u0026#34;123456\u0026#34;); document.addField(\u0026#34;name\u0026#34;, \u0026#34;Ann\u0026#34;); document.addField(\u0026#34;price\u0026#34;, \u0026#34;599.99\u0026#34;); solr.add(document); solr.commit(); 注意：任何修改 Solr 数据库的操作都需要在该操作后跟commit()。 4.2. 使用 Bean 进行索引 您还可以使用 beans 索引 Solr 文档。让我们定义一个 ProductBean，它的属性用 @Field注释： public class ProductBean { String id; String name; String price; @Field(\u0026#34;id\u0026#34;) protected void setId(String id) { this.id = id; } @Field(\u0026#34;name\u0026#34;) protected void setName(String name) { this.name = name; } @Field(\u0026#34;price\u0026#34;) protected void setPrice(String price) { this.price = price; } // getters and constructor omitted for space } 然后，让我们将 bean 添加到我们的索引中： solrClient.addBean( new ProductBean(\u0026#34;888\u0026#34;, \u0026#34;Apple iPhone X\u0026#34;, \u0026#34;299.99\u0026#34;) ); solrClient.commit(); 4.3. 按字段和ID查询索引文档 让我们通过使用SolrQuery查询我们的 Solr 服务器来验证我们的文档是否已添加。 来自服务器的QueryResponse将包含一个SolrDocument对象列表，该对象与格式为field:value 的任何查询匹配。在本例中，我们按价格查询： SolrQuery query = new SolrQuery(); query.set(\u0026#34;q\u0026#34;, \u0026#34;price:599.99\u0026#34;); QueryResponse response = solr.query(query); SolrDocumentList docList = response.getResults(); assertEquals(docList.getNumFound(), 1); for (SolrDocument doc : docList) { assertEquals((String) doc.getFieldValue(\u0026#34;id\u0026#34;), \u0026#34;123456\u0026#34;); assertEquals((Double) doc.getFieldValue(\u0026#34;price\u0026#34;), (Double) 599.99); } 一个更简单的选择是使用getById()按Id查询。如果找到匹配项，它将仅返回一个文档： SolrDocument doc = solr.getById(\u0026#34;123456\u0026#34;); assertEquals((String) doc.getFieldValue(\u0026#34;name\u0026#34;), \u0026#34;Ann\u0026#34;); assertEquals((Double) doc.getFieldValue(\u0026#34;price\u0026#34;), (Double) 599.99); 4.4. 删除文件 当我们想从索引中删除文档时，我们可以使用*deleteById()*并验证它是否已被删除： solr.deleteById(\u0026#34;123456\u0026#34;); solr.commit(); SolrQuery query = new SolrQuery(); query.set(\u0026#34;q\u0026#34;, \u0026#34;id:123456\u0026#34;); QueryResponse response = solr.query(query); SolrDocumentList docList = response.getResults(); assertEquals(docList.getNumFound(), 0); 我们还可以选择deleteByQuery()，所以让我们尝试删除任何具有特定名称的文档： solr.deleteByQuery(\u0026#34;name:Ann\u0026#34;); solr.commit(); SolrQuery query = new SolrQuery(); query.set(\u0026#34;q\u0026#34;, \u0026#34;id:123456\u0026#34;); QueryResponse response = solr.query(query); SolrDocumentList docList = response.getResults(); assertEquals(docList.getNumFound(), 0); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_solrj/","tags":["Lucene"],"title":"Apache SolrJ 在 Java 中使用 Solr 指南"},{"categories":["Security"],"contents":"1. 简介 在本教程中，我们将了解如何使用Apache Shiro Java 安全框架实现细粒度的基于权限的访问控制。 2. 设置 我们将使用与 Shiro 介绍相同的设置——也就是说，我们只会将shiro-core模块添加到我们的依赖项中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 此外，出于测试目的，我们将通过将以下shiro.ini文件放在类路径的根目录中来使用简单的 INI 领域： [users] jane.admin = password, admin john.editor = password2, editor zoe.author = password3, author [roles] admin = * editor = articles:* author = articles:create, articles:edit 然后，我们将使用上述领域初始化 Shiro： IniRealm iniRealm = new IniRealm(\u0026#34;classpath:shiro.ini\u0026#34;); SecurityManager securityManager = new DefaultSecurityManager(iniRealm); SecurityUtils.setSecurityManager(securityManager); 3. 角色和权限 通常，当我们谈论身份验证和授权时，我们会以用户和角色的概念为中心。 特别是，**角色是应用程序或服务的用户的横切类别。**因此，所有具有特定角色的用户都可以访问某些资源和操作，并且可能对应用程序或服务的其他部分具有受限访问权限。 角色集通常是预先设计的，很少更改以适应新的业务需求。但是，角色也可以动态定义——例如，由管理员定义。 使用 Shiro，我们有多种测试用户是否具有特定角色的方法。最直接的方法是使用hasRole方法： Subject subject = SecurityUtils.getSubject(); if (subject.hasRole(\u0026#34;admin\u0026#34;)) { logger.info(\u0026#34;Welcome Admin\u0026#34;); } 3.1 权限 但是，如果我们通过测试用户是否具有特定角色来检查授权，则会出现问题。事实上，**我们正在硬编码角色和权限之间的关系。**换句话说，当我们想要授予或撤销对资源的访问权限时，我们将不得不更改源代码。当然，这也意味着重建和重新部署。 我们可以做得更好；这就是为什么我们现在要介绍权限的概念。权限代表我们可以授权或拒绝的软件可以做什么，而**不是谁可以做。**例如，“编辑当前用户的个人资料”、“批准文档”或“创建新文章”。 Shiro 对权限的假设很少。在最简单的情况下，权限是纯字符串： Subject subject = SecurityUtils.getSubject(); if (subject.isPermitted(\u0026#34;articles:create\u0026#34;)) { //Create a new article } 请注意，权限的使用在 Shiro 中完全是可选的。 3.2. 将权限与用户关联 Shiro 具有将权限与角色或单个用户关联的灵活模型。但是，典型领域，包括我们在本教程中使用的简单 INI 领域，仅将权限与角色相关联。 因此，由Principal标识的用户具有多个角色，并且每个角色具有多个 Permission。 例如，我们可以看到在我们的 INI 文件中，用户zoe.author具有作者角色，这赋予了他们文章：创建和 文章：编辑权限： [users] zoe.author = password3, author #Other users... [roles] author = articles:create, articles:edit #Other roles... 类似地，其他领域类型（例如内置的 JDBC 领域）可以配置为将权限与角色相关联。 4. 通配符权限 **Shiro 中权限的默认实现是通配符权限，**是各种权限方案的灵活表示。 我们在 Shiro 中用字符串表示通配符权限。权限字符串由一个或多个以冒号分隔的组件组成，例如： articles:edit:1 字符串每个部分的含义取决于应用程序，因为 Shiro 不强制执行任何规则。但是，在上面的示例中，我们可以很清楚地将字符串解释为层次结构：  我们公开的资源类别（文章） 对此类资源的操作（编辑） 我们要允许或拒绝操作的特定资源的 id  这种三层结构的 resource:action:id 是 Shiro 应用程序中的一种常见模式，因为它既简单又有效地代表了许多不同的场景。 因此，我们可以重新访问我们之前的示例以遵循此方案： Subject subject = SecurityUtils.getSubject(); if (subject.isPermitted(\u0026#34;articles:edit:123\u0026#34;)) { //Edit article with id 123 } 请注意，通配符权限字符串中的组件数不必是三个，即使通常情况下三个组件也是如此。 4.1 权限含义和实例级粒度 当我们将通配符权限与 Shiro 权限的另一个特性（隐含）结合使用时，通配符权限就会大放异彩。 **当我们测试角色时，我们会测试确切的成员资格：**一个Subject有一个特定的角色，或者没有。换句话说，Shiro 测试角色的平等性。 另一方面，**当我们测试权限时，我们会测试含义：**Subject的权限是否暗示我们正在测试它的权限？ 具体含义取决于权限的实现。事实上，对于通配符权限，其含义是部分字符串匹配，顾名思义，可能存在通配符。 因此，假设我们为作者角色分配了以下权限： [roles] author = articles:* 然后，每个具有作者角色的人都将被允许对文章进行所有可能的操作： Subject subject = SecurityUtils.getSubject(); if (subject.isPermitted(\u0026#34;articles:create\u0026#34;)) { //Create a new article } 也就是说，字符串articles:*将匹配第一个组件是articles 的任何通配符权限。 使用这个方案，我们既可以分配非常具体的权限——对具有给定 id 的特定资源的特定操作——也可以分配广泛的权限，例如编辑任何文章或对任何文章执行任何操作。 当然，出于性能原因，由于这不是简单的相等比较，我们应该始终针对最具体的权限进行测试： if (subject.isPermitted(\u0026#34;articles:edit:1\u0026#34;)) { //Better than \u0026#34;articles:*\u0026#34;  //Edit article } 5. 自定义权限实现 让我们简要介绍一下权限自定义。尽管通配符权限涵盖了广泛的场景，但我们可能希望用为我们的应用程序定制的解决方案来替换它们。 假设我们需要对路径的权限进行建模，以便路径上的权限意味着对所有子路径的权限。实际上，我们可以对任务使用通配符权限，但让我们忽略它。 那么，我们需要什么？  权限实现 告诉四郎这件事  让我们看看如何实现这两点。 5.1编写权限实现 Permission实现是一个只有一个方法的类——意味着： public class PathPermission implements Permission { private final Path path; public PathPermission(Path path) { this.path = path; } @Override public boolean implies(Permission p) { if(p instanceof PathPermission) { return ((PathPermission) p).path.startsWith(path); } return false; } } 如果 这意味着另一个权限对象，则该方法返回true ，否则返回**false。 5.2. 告诉 Shiro 我们的实施 然后，有多种方法可以将Permission实现集成到 Shiro 中，但最直接的方法是将自定义PermissionResolver注入我们的Realm： IniRealm realm = new IniRealm(); Ini ini = Ini.fromResourcePath(Main.class.getResource(\u0026#34;/com/.../shiro.ini\u0026#34;).getPath()); realm.setIni(ini); realm.setPermissionResolver(new PathPermissionResolver()); realm.init(); SecurityManager securityManager = new DefaultSecurityManager(realm); PermissionResolver负责将我们权限的字符串表示形式转换为实际的**Permission对象：** public class PathPermissionResolver implements PermissionResolver { @Override public Permission resolvePermission(String permissionString) { return new PathPermission(Paths.get(permissionString)); } } 我们必须使用基于路径的权限修改我们之前的shiro.ini ： [roles] admin = / editor = /articles author = /articles/drafts 然后，我们将能够检查路径的权限： if(currentUser.isPermitted(\u0026#34;/articles/drafts/new-article\u0026#34;)) { log.info(\u0026#34;You can access articles\u0026#34;); } 请注意，这里我们以编程方式配置一个简单的领域。在典型的应用程序中，我们将使用shiro.ini文件或 Spring 等其他方式来配置 Shiro 和领域。一个真实的 shiro.ini文件可能包含： [main] permissionResolver = com.codingman.shiro.permissions.custom.PathPermissionResolver dataSource = org.apache.shiro.jndi.JndiObjectFactory dataSource.resourceName = java://app/jdbc/myDataSource jdbcRealm = org.apache.shiro.realm.jdbc.JdbcRealm jdbcRealm.dataSource = $dataSource jdbcRealm.permissionResolver = $permissionResolver \u0026quot; ","permalink":"http://itcodingman.github.io/apache_shiro_access_control/","tags":[],"title":"使用 Apache Shiro 的基于权限的访问控制"},{"categories":["Security"],"contents":"1. 概述 在本文中，我们将介绍Apache Shiro，一个通用的 Java 安全框架。 该框架是高度可定制和模块化的，因为它提供身份验证、授权、加密和会话管理。 2.依赖 Apache Shiro 有很多模块。但是，在本教程中，我们仅使用shiro-core工件。 让我们将它添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本的 Apache Shiro 模块可以在 Maven Central 上找到。 3. 配置安全管理器 SecurityManager是 Apache Shiro 框架的核心部分。应用程序通常会运行它的单个实例。 在本教程中，我们将在桌面环境中探索该框架。要配置框架，我们需要在资源文件夹中创建一个shiro.ini文件，内容如下： [users] user = password, admin user2 = password2, editor user3 = password3, author [roles] admin = * editor = articles:* author = articles:compose,articles:save shiro.ini配置文件的*[users]部分定义了SecurityManager*识别的用户凭据。格式为：p rincipal (username) = password, role1, role2, \u0026hellip;, role。 角色及其相关权限在*[roles]部分中声明。管理员角色被授予对应用程序每个部分的权限和访问权限。这由通配符(*)*符号表示。 编辑角色拥有与文章相关的所有权限，而作者角色只能撰写和保存文章。 SecurityManager用于配置SecurityUtils类。从SecurityUtils我们可以获取当前与系统交互的用户，并进行认证和授权操作。 让我们使用IniRealm从shiro.ini文件加载我们的用户和角色定义，然后使用它来配置DefaultSecurityManager对象： IniRealm iniRealm = new IniRealm(\u0026#34;classpath:shiro.ini\u0026#34;); SecurityManager securityManager = new DefaultSecurityManager(iniRealm); SecurityUtils.setSecurityManager(securityManager); Subject currentUser = SecurityUtils.getSubject(); 现在我们有了一个知道shiro.ini文件中定义的用户凭据和角色的SecurityManager，让我们继续进行用户身份验证和授权。 4. 认证 在 Apache Shiro 的术语中，Subject是与系统交互的任何实体。它可以是人、脚本或 REST 客户端。 调用SecurityUtils.getSubject()返回当前Subject的一个实例，即currentUser。 现在我们有了currentUser对象，我们可以对提供的凭据执行身份验证： if (!currentUser.isAuthenticated()) { UsernamePasswordToken token = new UsernamePasswordToken(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); token.setRememberMe(true); try { currentUser.login(token); } catch (UnknownAccountException uae) { log.error(\u0026#34;Username Not Found!\u0026#34;, uae); } catch (IncorrectCredentialsException ice) { log.error(\u0026#34;Invalid Credentials!\u0026#34;, ice); } catch (LockedAccountException lae) { log.error(\u0026#34;Your Account is Locked!\u0026#34;, lae); } catch (AuthenticationException ae) { log.error(\u0026#34;Unexpected Error!\u0026#34;, ae); } } 首先，我们检查当前用户是否尚未通过身份验证。*然后我们使用用户的主体（用户名）和凭证（密码）*创建一个身份验证令牌。 接下来，我们尝试使用令牌登录。如果提供的凭据是正确的，那么一切都会好起来的。 不同的情况有不同的例外。也可以抛出更适合应用程序要求的自定义异常。这可以通过继承 AccountException类来完成。 5. 授权 身份验证试图验证用户的身份，而授权试图控制对系统中某些资源的访问。 回想一下，我们为在shiro.ini文件中创建的每个用户分配了一个或多个角色。此外，在角色部分，我们为每个角色定义了不同的权限或访问级别。 现在让我们看看如何在我们的应用程序中使用它来实施用户访问控制。 在shiro.ini文件中，我们赋予管理员对系统每个部分的完全访问权限。 编辑可以完全访问有关文章的每个资源/操作，并且作者仅限于撰写和保存文章。 让我们根据角色欢迎当前用户： if (currentUser.hasRole(\u0026#34;admin\u0026#34;)) { log.info(\u0026#34;Welcome Admin\u0026#34;); } else if(currentUser.hasRole(\u0026#34;editor\u0026#34;)) { log.info(\u0026#34;Welcome, Editor!\u0026#34;); } else if(currentUser.hasRole(\u0026#34;author\u0026#34;)) { log.info(\u0026#34;Welcome, Author\u0026#34;); } else { log.info(\u0026#34;Welcome, Guest\u0026#34;); } 现在，让我们看看当前用户在系统中被允许做什么： if(currentUser.isPermitted(\u0026#34;articles:compose\u0026#34;)) { log.info(\u0026#34;You can compose an article\u0026#34;); } else { log.info(\u0026#34;You are not permitted to compose an article!\u0026#34;); } if(currentUser.isPermitted(\u0026#34;articles:save\u0026#34;)) { log.info(\u0026#34;You can save articles\u0026#34;); } else { log.info(\u0026#34;You can not save articles\u0026#34;); } if(currentUser.isPermitted(\u0026#34;articles:publish\u0026#34;)) { log.info(\u0026#34;You can publish articles\u0026#34;); } else { log.info(\u0026#34;You can not publish articles\u0026#34;); } 6. 领域配置 在实际应用程序中，我们需要一种从数据库而不是从shiro.ini文件中获取用户凭据的方法。这就是 Realm 概念发挥作用的地方。 在 Apache Shiro 的术语中，Realm是一个 DAO，它指向身份验证和授权所需的用户凭据存储。 要创建领域，我们只需要实现领域接口。这可能很乏味；但是，该框架带有默认实现，我们可以从中继承。这些实现之一是JdbcRealm。 我们创建了一个自定义领域实现，它扩展了 JdbcRealm类并覆盖了以下方法：doGetAuthenticationInfo()、doGetAuthorizationInfo()、getRoleNamesForUser()和getPermissions()。 让我们通过继承 JdbcRealm类来创建一个领域： public class MyCustomRealm extends JdbcRealm { //... } 为了简单起见，我们使用java.util.Map来模拟一个数据库： private Map\u0026lt;String, String\u0026gt; credentials = new HashMap\u0026lt;\u0026gt;(); private Map\u0026lt;String, Set\u0026lt;String\u0026gt;\u0026gt; roles = new HashMap\u0026lt;\u0026gt;(); private Map\u0026lt;String, Set\u0026lt;String\u0026gt;\u0026gt; perm = new HashMap\u0026lt;\u0026gt;(); { credentials.put(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); credentials.put(\u0026#34;user2\u0026#34;, \u0026#34;password2\u0026#34;); credentials.put(\u0026#34;user3\u0026#34;, \u0026#34;password3\u0026#34;); roles.put(\u0026#34;user\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;admin\u0026#34;))); roles.put(\u0026#34;user2\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;editor\u0026#34;))); roles.put(\u0026#34;user3\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;author\u0026#34;))); perm.put(\u0026#34;admin\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;*\u0026#34;))); perm.put(\u0026#34;editor\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;articles:*\u0026#34;))); perm.put(\u0026#34;author\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;articles:compose\u0026#34;, \u0026#34;articles:save\u0026#34;))); } 让我们继续并覆盖doGetAuthenticationInfo()： protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { UsernamePasswordToken uToken = (UsernamePasswordToken) token; if(uToken.getUsername() == null || uToken.getUsername().isEmpty() || !credentials.containsKey(uToken.getUsername())) { throw new UnknownAccountException(\u0026#34;username not found!\u0026#34;); } return new SimpleAuthenticationInfo( uToken.getUsername(), credentials.get(uToken.getUsername()), getName()); } 我们首先将提供的AuthenticationToken转换为UsernamePasswordToken。从uToken中，我们提取用户名（uToken.getUsername()）并使用它从数据库中获取用户凭据（密码）。 如果没有找到记录——我们抛出一个UnknownAccountException，否则我们使用凭证和用户名来构造一个从该方法返回的SimpleAuthenticatioInfo对象。 如果用户凭证使用盐进行哈希处理，我们需要返回一个SimpleAuthenticationInfo以及相关的盐： return new SimpleAuthenticationInfo( uToken.getUsername(), credentials.get(uToken.getUsername()), ByteSource.Util.bytes(\u0026#34;salt\u0026#34;), getName() ); 我们还需要覆盖doGetAuthorizationInfo()以及getRoleNamesForUser()和getPermissions()。 最后，让我们将自定义领域插入到securityManager中。我们需要做的就是用我们的自定义领域替换上面的IniRealm，并将其传递给DefaultSecurityManager的构造函数： Realm realm = new MyCustomRealm(); SecurityManager securityManager = new DefaultSecurityManager(realm); 代码的所有其他部分都与以前相同。这就是我们使用自定义领域正确配置securityManager所需的全部内容。 现在的问题是——框架如何匹配凭证？ 默认情况下，JdbcRealm使用SimpleCredentialsMatcher ，它仅通过比较**AuthenticationToken和AuthenticationInfo中的凭据来检查是否相等。 如果我们散列密码，我们需要通知框架使用HashedCredentialsMatcher。可以在此处找到具有散列密码的领域的 INI 配置。 7. 登出 现在我们已经验证了用户，是时候实现注销了。这只需调用一个方法即可完成——该方法使用户会话无效并将用户注销： currentUser.logout(); 8. 会话管理 该框架自然带有其会话管理系统。如果在 Web 环境中使用，则默认为HttpSession实现。 对于独立应用程序，它使用其企业会话管理系统。好处是即使在桌面环境中，您也可以像在典型 Web 环境中那样使用会话对象。 让我们看一个简单的示例并与当前用户的会话进行交互： Session session = currentUser.getSession(); session.setAttribute(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); String value = (String) session.getAttribute(\u0026#34;key\u0026#34;); if (value.equals(\u0026#34;value\u0026#34;)) { log.info(\u0026#34;Retrieved the correct value! [\u0026#34; + value + \u0026#34;]\u0026#34;); } 9. Shiro 用于使用 Spring 的 Web 应用程序 到目前为止，我们已经概述了 Apache Shiro 的基本结构，并且我们已经在桌面环境中实现了它。让我们继续将框架集成到 Spring Boot 应用程序中。 请注意，这里的主要焦点是 Shiro，而不是 Spring 应用程序——我们只会使用它来支持一个简单的示例应用程序。 9.1 依赖项 首先，我们需要将 Spring Boot 父依赖添加到我们的pom.xml中： \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 接下来，我们必须将以下依赖项添加到同一个pom.xml文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-freemarker\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-spring-boot-web-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${apache-shiro-core-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 9.2. 配置 将shiro-spring-boot-web-starter依赖添加到我们的pom.xml将默认配置 Apache Shiro 应用程序的一些功能，例如SecurityManager。 但是，我们仍然需要配置Realm和 Shiro 安全过滤器。我们将使用上面定义的相同自定义领域。 因此，在运行 Spring Boot 应用程序的主类中，让我们添加以下Bean定义： @Bean public Realm realm() { return new MyCustomRealm(); } @Bean public ShiroFilterChainDefinition shiroFilterChainDefinition() { DefaultShiroFilterChainDefinition filter = new DefaultShiroFilterChainDefinition(); filter.addPathDefinition(\u0026#34;/secure\u0026#34;, \u0026#34;authc\u0026#34;); filter.addPathDefinition(\u0026#34;/**\u0026#34;, \u0026#34;anon\u0026#34;); return filter; } 在ShiroFilterChainDefinition中，我们将authc过滤器应用于*/secure路径，并使用 Ant 模式将anon过滤器应用于其他路径。* Web 应用程序默认提供 authc和anon过滤器。其他默认过滤器可以在这里找到。 如果我们没有定义Realm bean，ShiroAutoConfiguration将默认提供一个IniRealm实现，该实现期望在src/main/resources或src/main/resources/META-INF中找到一个**shiro.ini文件。 如果我们不定义ShiroFilterChainDefinition bean，框架会保护所有路径并将登录 URL 设置为login.jsp。 我们可以通过将以下条目添加到我们的application.properties来更改此默认登录 URL 和其他默认值： shiro.loginUrl = /login shiro.successUrl = /secure shiro.unauthorizedUrl = /login 现在authc过滤器已应用于*/secure*，对该路由的所有请求都需要表单身份验证。 9.3. 认证和授权 让我们创建一个具有以下路径映射的ShiroSpringController ： /index、/login、/logout和*/secure。* *login()*方法是我们实现如上所述的实际用户身份验证的地方。如果身份验证成功，用户将被重定向到安全页面： Subject subject = SecurityUtils.getSubject(); if(!subject.isAuthenticated()) { UsernamePasswordToken token = new UsernamePasswordToken( cred.getUsername(), cred.getPassword(), cred.isRememberMe()); try { subject.login(token); } catch (AuthenticationException ae) { ae.printStackTrace(); attr.addFlashAttribute(\u0026#34;error\u0026#34;, \u0026#34;Invalid Credentials\u0026#34;); return \u0026#34;redirect:/login\u0026#34;; } } return \u0026#34;redirect:/secure\u0026#34;; 现在在*secure()实现中，currentUser是通过调用SecurityUtils.getSubject() 获得的。*用户的角色和权限以及用户的主体被传递到安全页面： Subject currentUser = SecurityUtils.getSubject(); String role = \u0026#34;\u0026#34;, permission = \u0026#34;\u0026#34;; if(currentUser.hasRole(\u0026#34;admin\u0026#34;)) { role = role + \u0026#34;You are an Admin\u0026#34;; } else if(currentUser.hasRole(\u0026#34;editor\u0026#34;)) { role = role + \u0026#34;You are an Editor\u0026#34;; } else if(currentUser.hasRole(\u0026#34;author\u0026#34;)) { role = role + \u0026#34;You are an Author\u0026#34;; } if(currentUser.isPermitted(\u0026#34;articles:compose\u0026#34;)) { permission = permission + \u0026#34;You can compose an article, \u0026#34;; } else { permission = permission + \u0026#34;You are not permitted to compose an article!, \u0026#34;; } if(currentUser.isPermitted(\u0026#34;articles:save\u0026#34;)) { permission = permission + \u0026#34;You can save articles, \u0026#34;; } else { permission = permission + \u0026#34;\\nYou can not save articles, \u0026#34;; } if(currentUser.isPermitted(\u0026#34;articles:publish\u0026#34;)) { permission = permission + \u0026#34;\\nYou can publish articles\u0026#34;; } else { permission = permission + \u0026#34;\\nYou can not publish articles\u0026#34;; } modelMap.addAttribute(\u0026#34;username\u0026#34;, currentUser.getPrincipal()); modelMap.addAttribute(\u0026#34;permission\u0026#34;, permission); modelMap.addAttribute(\u0026#34;role\u0026#34;, role); return \u0026#34;secure\u0026#34;; **我们完成了。**这就是我们如何将 Apache Shiro 集成到 Spring Boot 应用程序中。 另外，请注意，该框架提供了额外的注释，可以与过滤器链定义一起使用以保护我们的应用程序。 10. JEE 集成 将 Apache Shiro 集成到 JEE 应用程序中只需配置web.xml文件。配置期望shiro.ini在类路径中。此处提供了详细的示例配置。此外，可以在此处找到 JSP 标记。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_shiro/","tags":[],"title":"Apache Shiro 简介"},{"categories":["Data","Spring Boot"],"contents":"1. 简介 在本教程中，我们将使用 Spring Boot 和开源分布式消息传递和流数据平台 Apache RocketMQ 创建消息生产者和消费者。 2. 依赖 对于 Maven 项目，我们需要添加RocketMQ Spring Boot Starter依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 产生消息 对于我们的示例，我们将创建一个基本的消息生产者，每当用户在购物车中添加或删除商品时，它都会发送事件。 首先，让我们在application.properties中设置我们的服务器位置和组名： rocketmq.name-server=127.0.0.1:9876 rocketmq.producer.group=cart-producer-group 请注意，如果我们有多个名称服务器，我们可以将它们列出为 host:port;host:port。 现在，为了简单起见，我们将创建一个CommandLineRunner应用程序并在应用程序启动期间生成一些事件： @SpringBootApplication public class CartEventProducer implements CommandLineRunner { @Autowired private RocketMQTemplate rocketMQTemplate; public static void main(String[] args) { SpringApplication.run(CartEventProducer.class, args); } public void run(String... args) throws Exception { rocketMQTemplate.convertAndSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); rocketMQTemplate.convertAndSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;computer\u0026#34;, 2)); rocketMQTemplate.convertAndSend(\u0026#34;cart-item-removed-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); } } CartItemEvent仅包含两个属性——商品的 id 和数量： class CartItemEvent { private String itemId; private int quantity; // constructor, getters and setters } 在上面的例子中，我们使用了convertAndSend()方法，一个由AbstractMessageSendingTemplate抽象类定义的通用方法，来发送我们的购物车事件。它有两个参数：一个目的地，在我们的例子中是一个主题名称，以及一个消息负载。 4.消息消费者 使用 RocketMQ 消息就像创建一个带有*@RocketMQMessageListener注解的 Spring 组件并实现RocketMQListener*接口一样简单： @SpringBootApplication public class CartEventConsumer { public static void main(String[] args) { SpringApplication.run(CartEventConsumer.class, args); } @Service @RocketMQMessageListener( topic = \u0026#34;cart-item-add-topic\u0026#34;, consumerGroup = \u0026#34;cart-consumer_cart-item-add-topic\u0026#34; ) public class CardItemAddConsumer implements RocketMQListener\u0026lt;CartItemEvent\u0026gt; { public void onMessage(CartItemEvent addItemEvent) { log.info(\u0026#34;Adding item: {}\u0026#34;, addItemEvent); // additional logic  } } @Service @RocketMQMessageListener( topic = \u0026#34;cart-item-removed-topic\u0026#34;, consumerGroup = \u0026#34;cart-consumer_cart-item-removed-topic\u0026#34; ) public class CardItemRemoveConsumer implements RocketMQListener\u0026lt;CartItemEvent\u0026gt; { public void onMessage(CartItemEvent removeItemEvent) { log.info(\u0026#34;Removing item: {}\u0026#34;, removeItemEvent); // additional logic  } } } 我们需要为我们正在监听的每个消息主题创建一个单独的组件。在每一个监听器中，我们通过@RocketMQMessageListener 注解定义主题名称和消费组名称*。* 5. 同步和异步传输 在前面的示例中，我们使用了convertAndSend方法来发送我们的消息。不过，我们还有其他一些选择。 例如，我们可以调用与 convertAndSend不同的syncSend ，因为它返回SendResult对象。 例如，它可以用来验证我们的消息是否成功发送或获取它的 id： public void run(String... args) throws Exception { SendResult addBikeResult = rocketMQTemplate.syncSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); SendResult addComputerResult = rocketMQTemplate.syncSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;computer\u0026#34;, 2)); SendResult removeBikeResult = rocketMQTemplate.syncSend(\u0026#34;cart-item-removed-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); } 与*convertAndSend 一样，*此方法仅在发送过程完成时返回。 在需要高可靠性的情况下，比如重要的通知消息或短信通知，我们应该使用同步传输。 另一方面，我们可能希望异步发送消息并在发送完成时收到通知。 我们可以使用 asyncSend来做到这一点，它接受一个 SendCallback作为参数并立即返回： rocketMQTemplate.asyncSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1), new SendCallback() { @Override public void onSuccess(SendResult sendResult) { log.error(\u0026#34;Successfully sent cart item\u0026#34;); } @Override public void onException(Throwable throwable) { log.error(\u0026#34;Exception during cart item sending\u0026#34;, throwable); } }); 我们在需要高吞吐量的情况下使用异步传输。 最后，对于吞吐量要求非常高的场景，我们可以使用sendOneWay代替asyncSend。 sendOneWay 与**asyncSend的不同之处在于它不保证消息会被发送。 单向传输也可以用于普通的可靠性情况，例如收集日志。 6. 在事务中发送消息 RocketMQ 为我们提供了在事务中发送消息的能力。我们可以使用*sendInTransaction()*方法来做到这一点： MessageBuilder.withPayload(new CartItemEvent(\u0026#34;bike\u0026#34;, 1)).build(); rocketMQTemplate.sendMessageInTransaction(\u0026#34;test-transaction\u0026#34;, \u0026#34;topic-name\u0026#34;, msg, null); 另外，我们必须实现一个RocketMQLocalTransactionListener接口： @RocketMQTransactionListener(txProducerGroup=\u0026#34;test-transaction\u0026#34;) class TransactionListenerImpl implements RocketMQLocalTransactionListener { @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) { // ... local transaction process, return ROLLBACK, COMMIT or UNKNOWN  return RocketMQLocalTransactionState.UNKNOWN; } @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) { // ... check transaction status and return ROLLBACK, COMMIT or UNKNOWN  return RocketMQLocalTransactionState.COMMIT; } } 在sendMessageInTransaction()中，第一个参数是事务名称。它必须与@RocketMQTransactionListener的成员字段txProducerGroup 相同。 7. 消息生产者配置 我们还可以配置消息生产者本身的各个方面：  Rocketmq.producer.send-message-timeout：消息发送超时时间，以毫秒为单位——默认值为 3000 RocketMQ.producer.compress-message-body-threshold：超过该阈值，RocketMQ 将压缩消息 - 默认值为 1024。 Rocketmq.producer.max-message-size：最大消息大小（以字节为单位）——默认值为 4096。 Rocketmq.producer.retry-times-when-send-async-failed：发送失败前在异步模式下内部执行的最大重试次数——默认值为 2。 Rocketmq.producer.retry-next-server：指示是否在内部发送失败时重试另一个代理 - 默认值为false。 Rocketmq.producer.retry-times-when-send-failed：发送失败前在异步模式下内部执行的最大重试次数——默认值为 2。 \u0026quot;  ","permalink":"http://itcodingman.github.io/apache_rocketmq_spring_boot/","tags":["Messaging"],"title":"带有 Spring Boot 的 Apache RocketMQ"},{"categories":["Architecture","Java"],"contents":"1. 简介 Apache Pulsar是 Yahoo 开发的基于分布式开源发布/订阅的消息传递系统。 它的创建是为了支持 Yahoo 的关键应用程序，如 Yahoo Mail、Yahoo Finance、Yahoo Sports 等。然后，在 2016 年，它在 Apache 软件基金会下开源。 2. 架构 Pulsar 是一种用于服务器到服务器消息传递的多租户、高性能解决方案。它由一组代理和 bookie 以及用于配置和管理的内置Apache ZooKeeper组成。bookie来自*Apache BookKeeper* ，它为消息提供存储，直到它们被使用。 在一个集群中，我们将拥有：  多个集群代理处理来自生产者的传入消息并将消息分发给消费者 Apache BookKeeper 支持消息持久化 Apache ZooKeeper 存储集群配置  为了更好地理解这一点，让我们看一下文档中的架构图： 3. 主要特点 让我们从快速浏览一些关键特性开始：  对多个集群的内置支持 支持跨多个集群的消息地理复制 多种订阅模式 可扩展到数百万个主题 使用 Apache BookKeeper 来保证消息传递。 低延迟  现在，让我们详细讨论一些关键功能。 3.1 消息模型 该框架提供了一个灵活的消息传递模型。一般来说，消息传递架构有两种消息传递模型，即队列和发布者/订阅者。发布者/订阅者是一个广播消息系统，其中消息被发送给所有消费者。另一方面，排队是点对点通信。 Pulsar 将这两个概念结合在一个通用 API中。发布者将消息发布到不同的主题。然后这些消息被广播到所有订阅者。 消费者订阅以获取消息。该库允许消费者选择不同的方式来消费同一订阅中的消息，包括独占、共享和故障转移。我们将在后面的部分详细讨论这些订阅类型。 3.2. 部署模式 Pulsar 内置了对不同环境中部署的支持。这意味着我们可以在标准的本地机器上使用它，或者将它部署在 Kubernetes 集群、谷歌或 AWS 云中。 它可以作为单个节点执行以用于开发和测试目的。在这种情况下，所有组件（代理、BookKeeper 和 ZooKeeper）都在单个进程中运行。 3.3. 异地复制 该库为数据的异地复制提供了开箱即用的支持。 我们可以通过配置不同的地理区域来启用多个集群之间的消息复制。 消息数据近乎实时地复制。如果跨集群发生网络故障，数据始终是安全的并存储在 BookKeeper 中。复制系统会继续重试，直到复制成功。 地理复制功能还允许组织跨不同的云提供商部署 Pulsar 并复制数据。这有助于他们避免使用专有的云提供商 API。 3.4. 持久性 Pulsar 读取并确认数据后，保证数据不丢失。数据持久性与配置为存储数据的磁盘数量有关。 Pulsar 通过使用在存储节点中运行的 bookies（Apache BookKeeper 实例）来确保持久性。每当 bookie 收到消息时，它都会在内存中保存一份副本，并将数据写入 WAL（预写日志）。此日志的工作方式与数据库 WAL 相同。Bookies 操作数据库事务原理，确保即使机器发生故障也不会丢失数据。 除此之外，Pulsar 还可以承受多个节点故障。库将数据复制到多个 bookie，然后向生产者发送确认消息。这种机制即使在多个硬件故障的情况下也能保证零数据丢失。 4. 单节点设置 现在让我们看看如何搭建 Apache Pulsar 的单节点集群。 Apache 还提供了一个简单的 客户端 API ，其中包含 Java、Python 和 C++ 的绑定。稍后我们将创建一个简单的 Java 生产者和订阅示例。 4.1 安装 Apache Pulsar 以二进制发行版的形式提供。让我们从下载它开始： wget https://archive.apache.org/dist/incubator/pulsar/pulsar-2.1.1-incubating/apache-pulsar-2.1.1-incubating-bin.tar.gz 下载完成后，我们可以解压缩 zip 文件。未归档的发行版将包含bin、conf、example、licenses 和lib文件夹。 之后，我们需要下载内置的连接器。这些现在作为一个单独的包发货： wget https://archive.apache.org/dist/incubator/pulsar/pulsar-2.1.1-incubating/apache-pulsar-io-connectors-2.1.1-incubating-bin.tar.gz 让我们解压连接器并将连接器文件夹复制到 Pulsar 文件夹中。 4.2. 启动实例 要启动一个独立实例，我们可以执行： bin/pulsar standalone 5. Java客户端 现在我们将创建一个 Java 项目来生成和使用消息。我们还将为不同的订阅类型创建示例。 5.1 设置项目 我们首先将pulsar-client依赖项添加到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.pulsar\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pulsar-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1-incubating\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5.2. 生产者 让我们继续创建一个Producer示例。在这里，我们将创建一个主题和一个生产者。 首先，我们需要创建一个 PulsarClient ，它将使用自己的协议**连接到特定主机和端口上的 Pulsar 服务 。**许多生产者和消费者可以共享一个客户端对象。 现在，我们将创建一个 具有特定主题名称的Producer ： private static final String SERVICE_URL = \u0026#34;pulsar://localhost:6650\u0026#34;; private static final String TOPIC_NAME = \u0026#34;test-topic\u0026#34;; PulsarClient client = PulsarClient.builder() .serviceUrl(SERVICE_URL) .build(); Producer\u0026lt;byte[]\u0026gt; producer = client.newProducer() .topic(TOPIC_NAME) .compressionType(CompressionType.LZ4) .create(); 生产者将发送 5 条消息： IntStream.range(1, 5).forEach(i -\u0026gt; { String content = String.format(\u0026#34;hi-pulsar-%d\u0026#34;, i); Message\u0026lt;byte[]\u0026gt; msg = MessageBuilder.create() .setContent(content.getBytes()) .build(); MessageId msgId = producer.send(msg); }); 5.3. 消费者 接下来，我们将创建消费者以获取生产者创建的消息。消费者也需要相同的PulsarClient 来连接我们的服务器： Consumer\u0026lt;byte[]\u0026gt; consumer = client.newConsumer() .topic(TOPIC_NAME) .subscriptionType(SubscriptionType.Shared) .subscriptionName(SUBSCRIPTION_NAME) .subscribe(); 在这里，我们创建了具有 共享订阅类型的客户端*。*这允许多个消费者附加到同一个订阅并获取消息。 5.4. 消费者订阅类型 在上面的消费者示例中，我们创建了一个共享类型的订阅。我们还可以创建 独占和故障转移订阅。 独占 订阅只允许订阅一个消费者。 另一方面，af ailover 订阅 允许用户定义后备消费者，以防一个消费者失败，如下面的 Apache 图表所示： \u0026quot; ","permalink":"http://itcodingman.github.io/apache_pulsar/","tags":["Messaging"],"title":"Apache Pulsar 简介"},{"categories":["Data"],"contents":"1. 简介 我们可以使用 Apache POI 在 Microsoft Excel 电子表格中以编程方式创建多行文本。但是，它不会显示为多行。这是因为使用代码向单元格添加文本不会自动调整单元格高度并应用所需的格式将其转换为多行文本。 这个简短的教程将演示正确显示此类文本所需的代码。 2. Apache POI 和 Maven 依赖 Apache POI 是一个开源库，允许软件开发人员创建和操作 Microsoft Office 文档。作为先决条件，读者可以参考我们关于在 Java 中使用 Microsoft Excel \u0026ldquo;在 Java 中使用 Microsoft Excel\u0026quot;的文章以及关于如何使用 Apache POI 在 Excel 中插入行 \u0026ldquo;使用 Apache POI 在 Excel 中插入一行\u0026quot;的教程。 首先，我们首先需要将Apache POI 依赖项添加到我们的项目 pom.xml 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 添加和格式化多行文本 让我们从一个包含多行文本的单元格开始： cell.setCellValue(\u0026#34;Hello \\n world!\u0026#34;); 如果我们要使用上面的代码生成并保存一个 Excel 文件。它将如下图所示： 我们可以点击上图中的 1 和 2 来验证文本确实是多行文本。 使用代码格式化单元格并将其行高扩展为等于或大于两行文本的任何值： cell.getRow() .setHeightInPoints(cell.getSheet().getDefaultRowHeightInPoints() * 2); 之后，我们需要设置单元格样式来换行： CellStyle cellStyle = cell.getSheet().getWorkbook().createCellStyle(); cellStyle.setWrapText(true); cell.setCellStyle(cellStyle); 保存使用上述代码生成的文件并在 Microsoft Excel 中查看它会在单元格中显示多行文本。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_write_multiline_text/","tags":["Excel"],"title":"使用 Apache POI 的 Excel 单元格中的多行文本"},{"categories":["Java"],"contents":"1. 简介 在本文中，我们将了解如何使用Apache POI创建演示文稿。 该库使我们能够创建 PowerPoint 演示文稿、阅读现有演示文稿并更改其内容。 2.Maven依赖 首先，我们需要将以下依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以从 Maven Central 下载这两个库的最新版本。 3. Apache POI Apache POI库支持*.ppt和*.pptx文件，它为 Powerpoint \u0026lsquo;97(-2007) 文件格式提供 HSLF 实现，为 PowerPoint 2007 OOXML 文件格式提供 XSLF。 由于这两种实现不存在通用接口，因此在使用较新的.pptx文件格式时，我们必须记住使用XMLSlideShow、XSLFSlide和XSLFTextShape类。 而且，当需要使用较旧的*.ppt格式时，请使用HSLFSlideShow*、HSLFSlide和HSLFTextParagraph类。 我们将在示例中使用新的*.pptx*文件格式，我们要做的第一件事是创建一个新的演示文稿，向其中添加一张幻灯片（可能使用预定义的布局）并保存它。 一旦这些操作变得清晰，我们就可以开始处理图像、文本和表格。 3.1 创建新演示文稿 让我们首先创建新的演示文稿： XMLSlideShow ppt = new XMLSlideShow(); ppt.createSlide(); 3.2. 添加新幻灯片 在向演示文稿添加新幻灯片时，我们还可以选择从预定义的布局创建它。为此，我们首先必须检索保存布局的XSLFSlideMaster（第一个是默认主控）： XSLFSlideMaster defaultMaster = ppt.getSlideMasters().get(0); 现在，我们可以检索XSLFSlideLayout并在创建新幻灯片时使用它： XSLFSlideLayout layout = defaultMaster.getLayout(SlideLayout.TITLE_AND_CONTENT); XSLFSlide slide = ppt.createSlide(layout); 让我们看看如何在模板中填充占位符： XSLFTextShape titleShape = slide.getPlaceholder(0); XSLFTextShape contentShape = slide.getPlaceholder(1); 请记住，每个模板都有其占位符，即XSLFAutoShape子类的实例，其数量可能因模板而异。 让我们看看如何从幻灯片中快速检索所有占位符： for (XSLFShape shape : slide.getShapes()) { if (shape instanceof XSLFAutoShape) { // this is a template placeholder  } } 3.3. 保存演示文稿 一旦我们创建了幻灯片，下一步就是保存它： FileOutputStream out = new FileOutputStream(\u0026#34;powerpoint.pptx\u0026#34;); ppt.write(out); out.close(); 4. 使用对象 现在我们已经了解了如何创建新的演示文稿、向其中添加幻灯片（使用或不使用预定义模板）并保存它，我们可以开始添加文本、图像、链接和表格。 让我们从文本开始。 4.1 文本 在演示文稿中处理文本时，如在 MS PowerPoint 中，我们必须在幻灯片中创建文本框，添加段落，然后将文本添加到段落中： XSLFTextBox shape = slide.createTextBox(); XSLFTextParagraph p = shape.addNewTextParagraph(); XSLFTextRun r = p.addNewTextRun(); r.setText(\u0026#34;Codingman\u0026#34;); r.setFontColor(Color.green); r.setFontSize(24.); 配置XSLFTextRun时，可以通过选择字体系列以及文本是否应为粗体、斜体或下划线来自定义其样式。 4.2. 超链接 在演示文稿中添加文本时，有时添加超链接会很有用。 一旦我们创建了XSLFTextRun对象，我们现在可以添加一个链接： XSLFHyperlink link = r.createHyperlink(); link.setAddress(\u0026#34;http://www.google.com\u0026#34;); 4.3. 图片 我们也可以添加图片： byte[] pictureData = IOUtils.toByteArray( new FileInputStream(\u0026#34;logo-leaf.png\u0026#34;)); XSLFPictureData pd = ppt.addPicture(pictureData, PictureData.PictureType.PNG); XSLFPictureShape picture = slide.createPicture(pd); 但是，如果没有适当的配置，图像将被放置在幻灯片的左上角。为了正确放置它，我们必须配置它的锚点： picture.setAnchor(new Rectangle(320, 230, 100, 92)); XSLFPictureShape接受一个矩形作为锚点，它允许我们使用前两个参数配置 x/y 坐标，并使用后两个参数配置图像的宽度/高度*。* 4.4. 列表 演示文稿中的文本通常以列表的形式表示，无论是否编号。 现在让我们定义一个要点列表： XSLFTextShape content = slide.getPlaceholder(1); XSLFTextParagraph p1 = content.addNewTextParagraph(); p1.setIndentLevel(0); p1.setBullet(true); r1 = p1.addNewTextRun(); r1.setText(\u0026#34;Bullet\u0026#34;); 同样，我们可以定义一个编号列表： XSLFTextParagraph p2 = content.addNewTextParagraph(); p2.setBulletAutoNumber(AutoNumberingScheme.alphaLcParenRight, 1); p2.setIndentLevel(1); XSLFTextRun r2 = p2.addNewTextRun(); r2.setText(\u0026#34;Numbered List Item - 1\u0026#34;); 如果我们使用多个列表，定义indentLevel以实现项目的正确缩进总是很重要的。 4.5. 表 表格是演示文稿中的另一个关键对象，在我们想要显示数据时很有帮助。 让我们从创建一个表开始： XSLFTable tbl = slide.createTable(); tbl.setAnchor(new Rectangle(50, 50, 450, 300)); 现在，我们可以添加一个标题： int numColumns = 3; XSLFTableRow headerRow = tbl.addRow(); headerRow.setHeight(50); for (int i = 0; i \u0026lt; numColumns; i++) { XSLFTableCell th = headerRow.addCell(); XSLFTextParagraph p = th.addNewTextParagraph(); p.setTextAlign(TextParagraph.TextAlign.CENTER); XSLFTextRun r = p.addNewTextRun(); r.setText(\u0026#34;Header \u0026#34; + (i + 1)); tbl.setColumnWidth(i, 150); } 完成表头后，我们可以在表格中添加行和单元格以显示数据： for (int rownum = 1; rownum \u0026lt; numRows; rownum++) { XSLFTableRow tr = tbl.addRow(); tr.setHeight(50); for (int i = 0; i \u0026lt; numColumns; i++) { XSLFTableCell cell = tr.addCell(); XSLFTextParagraph p = cell.addNewTextParagraph(); XSLFTextRun r = p.addNewTextRun(); r.setText(\u0026#34;Cell \u0026#34; + (i*rownum + 1)); } } 使用表格时，重要的是要提醒您可以自定义每个单元格的边框和背景。 5. 更改演示文稿 并非总是在制作幻灯片时，我们必须创建一个新的，但我们必须更改已经存在的。 让我们看一下我们在上一节中创建的那个，然后我们可以开始修改它： 5.1 阅读演示文稿 阅读演示文稿非常简单，可以使用接受FileInputStream的**XMLSlideShow重载构造函数来完成： XMLSlideShow ppt = new XMLSlideShow( new FileInputStream(\u0026#34;slideshow.pptx\u0026#34;)); 5.2. 更改幻灯片顺序 在我们的演示文稿中添加幻灯片时，最好将它们按正确的顺序放置以使幻灯片正确流动。 如果没有发生这种情况，则可以重新排列幻灯片的顺序。让我们看看如何将第四张幻灯片移动到第二张： List\u0026lt;XSLFSlide\u0026gt; slides = ppt.getSlides(); XSLFSlide slide = slides.get(3); ppt.setSlideOrder(slide, 1); 5.3. 删除幻灯片 也可以从演示文稿中删除幻灯片。 让我们看看如何删除第四张幻灯片： ppt.removeSlide(3); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_slideshow/","tags":[],"title":"用 Java 创建 MS PowerPoint 演示文稿"},{"categories":["Data"],"contents":"1. 简介 在 Java 中读取 Excel 文件时，我们通常希望读取单元格的值以执行一些计算或生成报告。但是，我们可能会遇到一个或多个包含公式而不是原始数据值的单元格。那么，我们如何获得这些单元格的实际数据值呢？ 在本教程中，我们将研究使用Apache POI Java 库读取 Excel 单元格值的不同方法——而不是计算单元格值的公式。 有两种方法可以解决这个问题：  获取单元格的最后一个缓存值 在运行时评估公式以获取单元格值  2. Maven依赖 我们需要在我们的 pom.xml 文件中为 Apache POI 添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  可以从 Maven Central 下载最新版本的poi-ooxml 。 3.获取最后一个缓存值 当公式计算单元格的值时，Excel 会为单元格存储两个对象。一是公式本身，二是缓存值。缓存的值包含公式计算的最后一个值。 所以这里的想法是我们可以获取最后一个缓存值并将其视为单元格值。最后一个缓存值是正确的单元格值可能并不总是正确的。但是，当我们使用已保存的 Excel 文件并且最近没有对文件进行修改时，最后缓存的值应该是单元格值。 让我们看看如何获取单元格的最后一个缓存值： FileInputStream inputStream = new FileInputStream(new File(\u0026#34;temp.xlsx\u0026#34;)); Workbook workbook = new XSSFWorkbook(inputStream); Sheet sheet = workbook.getSheetAt(0); CellAddress cellAddress = new CellAddress(\u0026#34;C2\u0026#34;); Row row = sheet.getRow(cellAddress.getRow()); Cell cell = row.getCell(cellAddress.getColumn()); if (cell.getCellType() == CellType.FORMULA) { switch (cell.getCachedFormulaResultType()) { case BOOLEAN: System.out.println(cell.getBooleanCellValue()); break; case NUMERIC: System.out.println(cell.getNumericCellValue()); break; case STRING: System.out.println(cell.getRichStringCellValue()); break; } } 4.评估公式以获取单元格值 Apache POI 提供了一个** FormulaEvaluator类，它使我们能够计算**Excel 表格中公式的结果。 因此，我们可以直接使用FormulaEvaluator在运行时计算单元格值。FormulaEvaluator类提供了一个名为evaluateFormulaCell 的方法，该方法计算给定Cell对象的单元格值并返回一个CellType对象，该对象表示单元格值的数据类型。 让我们看看这种方法的实际效果： // existing Workbook setup  FormulaEvaluator evaluator = workbook.getCreationHelper().createFormulaEvaluator(); // existing Sheet, Row, and Cell setup  if (cell.getCellType() == CellType.FORMULA) { switch (evaluator.evaluateFormulaCell(cell)) { case BOOLEAN: System.out.println(cell.getBooleanCellValue()); break; case NUMERIC: System.out.println(cell.getNumericCellValue()); break; case STRING: System.out.println(cell.getStringCellValue()); break; } } 5. 选择哪种方法 这两种方法之间的简单区别在于，第一种方法使用最后一个缓存值，第二种方法在运行时计算公式。 如果我们正在使用已保存的 Excel 文件并且我们不打算在运行时对该电子表格进行更改，那么缓存值方法会更好，因为我们不必评估公式。 但是，如果我们知道我们将在运行时进行频繁的更改，那么最好在运行时评估公式以获取单元格值。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_read_cell_value_formula/","tags":["Excel"],"title":"使用 Apache POI 读取 Excel 单元格值而不是公式"},{"categories":["Data"],"contents":"1. 概述 在本快速教程中，我们将演示如何使用 Apache POI 在 Excel 中格式化数字单元格。 2. Apache POI Apache POI是一个开源的纯 Java 项目。它提供了用于读取和写入 Microsoft Office 格式文件的库，例如 Word、PowerPoint 和Excel。 在使用较新的*.xlsx* 文件格式时，我们将使用 XSSFWorkbook类，对于*.xls* 格式，我们使用 HSSFWorkbook类*。* 3. 数字格式 Apache POI的setCellValue方法只接受**double作为输入或可以隐式转换为double并返回double作为数值的输入。setCellStyle方法用于添加所需的样式。Excel 数字格式中的 # 字符意味着如果需要在此处放置一个数字，而字符 0 意味着始终在此处放置一个数字，即使它是不必要的 0。 3.1 仅显示值的格式 让我们使用 0.00 或 #.## 等模式格式化*双精度值。*首先，我们将创建一个简单的实用方法来格式化单元格值： public static void applyNumericFormat(Workbook outWorkbook, Row row, Cell cell, Double value, String styleFormat) { CellStyle style = outWorkbook.createCellStyle(); DataFormat format = outWorkbook.createDataFormat(); style.setDataFormat(format.getFormat(styleFormat)); cell.setCellValue(value); cell.setCellStyle(style); } 让我们验证一个简单的代码来验证上述方法： File file = new File(\u0026#34;number_test.xlsx\u0026#34;); try (Workbook outWorkbook = new XSSFWorkbook()) { Sheet sheet = outWorkbook.createSheet(\u0026#34;Numeric Sheet\u0026#34;); Row row = sheet.createRow(0); Cell cell = row.createCell(0); ExcelNumericFormat.applyNumericFormat(outWorkbook, row, cell, 10.251, \u0026#34;0.00\u0026#34;); FileOutputStream fileOut = new FileOutputStream(file); outWorkbook.write(fileOut); fileOut.close(); } 这将在电子表格中添加数字单元格： 注意：显示值为格式化后的值，实际值不变。如果我们尝试访问同一个单元格，我们仍然会得到 10.251。 让我们验证实际值： try (Workbook inWorkbook = new XSSFWorkbook(\u0026#34;number_test.xlsx\u0026#34;)) { Sheet sheet = inWorkbook.cloneSheet(0); Row row = sheet.getRow(0); Assertions.assertEquals(10.251, row.getCell(0).getNumericCellValue()); } 3.2. 实际值和显示值的格式 让我们使用模式格式化显示和实际值： File file = new File(\u0026#34;number_test.xlsx\u0026#34;); try (Workbook outWorkbook = new HSSFWorkbook()) { Sheet sheet = outWorkbook.createSheet(\u0026#34;Numeric Sheet\u0026#34;); Row row = sheet.createRow(0); Cell cell = row.createCell(0); DecimalFormat df = new DecimalFormat(\u0026#34;#,###.##\u0026#34;); ExcelNumericFormat.applyNumericFormat(outWorkbook, row, cell, Double.valueOf(df.format(10.251)), \u0026#34;#,###.##\u0026#34;); FileOutputStream fileOut = new FileOutputStream(file); outWorkbook.write(fileOut); fileOut.close(); } 这将在电子表格中添加数字单元格并显示格式化的值，并且还会更改实际值： 让我们在上述情况下断言实际值： try (Workbook inWorkbook = new XSSFWorkbook(\u0026#34;number_test.xlsx\u0026#34;)) { Sheet sheet = inWorkbook.cloneSheet(0); Row row = sheet.getRow(0); Assertions.assertEquals(10.25, row.getCell(0).getNumericCellValue()); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_numeric_format/","tags":["Excel"],"title":"使用 POI 的数字格式"},{"categories":["Data"],"contents":"1. 简介 Apache POI是一个开源库，供软件开发人员创建和操作 Microsoft Office 文档。除其他功能外，它还允许开发人员以编程方式更改文档格式。 在本文中，我们将讨论在使用名为CellStyle的类时如何在 Microsoft Excel 中更改单元格的样式。也就是说，使用这个类，我们可以编写代码来修改Microsoft Excel 文档中单元格的样式。首先，它是 Apache POI 库提供的一项功能，允许在工作簿中创建具有多种格式属性的样式。其次，可以将样式应用于该工作簿中的多个单元格。 除此之外，我们还将了解使用CellStyle类的常见缺陷。 2. Apache POI 和 Maven 依赖 让我们将Apache POI作为依赖项添加到我们的项目pom.xml 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 创建CellStyle 让我们从实例化CellStyle开始： Workbook workbook = new XSSFWorkbook(fileLocation); CellStyle cellStyle = wb.createCellStyle(); 接下来，设置好所需的格式化属性。例如，下面的代码会将其设置为日期格式： cellStyle.setDataFormat(createHelper.createDataFormat().getFormat(\u0026#34;m/d/yy h:mm\u0026#34;)); 最重要的是，我们可以设置CellStyle的多个格式属性来获得所需的样式组合。例如，我们将以下代码应用于同一个CellStyle对象。因此，它具有日期格式样式以及居中对齐的文本样式： cellStyle.setAlignment(HorizontalAlignment.CENTER); 请注意，CellStyle有几个我们可以修改的格式属性：    财产 描述     数据格式 单元格的数据格式，例如日期   结盟 单元格的水平对齐类型   隐 是否要隐藏单元格   缩进 用于缩进单元格中文本的空格数   边框底部,    左边框，     右边框， 边框顶部 | 用于单元格的底部、左侧、右侧和顶部边框的边框类型 | | 字体 | 此样式的字体属性，例如字体颜色 | 稍后我们将在使用Font属性更改字体样式时再次查看它。 4. 使用CellStyle格式化字体 CellStyle的Font属性是我们设置字体相关格式的地方。例如，我们可以设置字体名称、颜色和大小。我们可以设置字体是粗体还是斜体。Font的两个属性都可以是true或false。我们还可以将下划线样式设置为：    价值 财产     U_NONE 没有下划线的文字   U_SINGLE 单下划线文本，其中只有单词带下划线   U_SINGLE_ACCOUNTING 几乎整个单元格宽度都带有下划线的单个下划线文本   U_DOUBLE 双下划线文本，其中只有单词带下划线   U_DOUBLE_ACCOUNTING 双下划线文本，几乎整个单元格宽度都带有下划线    让我们从前面的例子继续。我们将编写一个名为CellStyler的类，其中包含一个为警告文本创建样式的方法： public class CellStyler { public CellStyle createWarningColor(Workbook workbook) { CellStyle style = workbook.createCellStyle(); Font font = workbook.createFont(); font.setFontName(\u0026#34;Courier New\u0026#34;); font.setBold(true); font.setUnderline(Font.U_SINGLE); font.setColor(HSSFColorPredefined.DARK_RED.getIndex()); style.setFont(font); style.setAlignment(HorizontalAlignment.CENTER); style.setVerticalAlignment(VerticalAlignment.CENTER); return style; } } 现在，让我们创建一个 Apache POI 工作簿并获取第一个工作表： Workbook workbook = new XSSFWorkbook(fileLocation); Sheet sheet = workbook.getSheetAt(0); 请注意，我们正在设置行高，以便我们可以看到文本对齐的效果： Row row1 = sheet.createRow(0); row1.setHeightInPoints((short) 40); 让我们实例化该类并使用它来设置样式 CellStyler styler = new CellStyler(); CellStyle style = styler.createWarningColor(workbook); Cell cell1 = row1.createCell(0); cell1.setCellStyle(style); cell1.setCellValue(\u0026#34;Hello\u0026#34;); Cell cell2 = row1.createCell(1); cell2.setCellStyle(style); cell2.setCellValue(\u0026#34;world!\u0026#34;); 现在，让我们将此工作簿保存到一个文件中，并在 Microsoft Excel 中打开该文件以查看字体样式效果，我们应该在其中看到：  5. 常见的陷阱 让我们看看使用CellStyle 时常犯的两个错误。 5.1 意外修改所有单元格样式 首先，从单元格中获取CellStyle并开始修改它是一个常见的错误。getCellStyle方法的 Apache POI 文档提到单元格的getCellStyle方法将始终返回非空值。这意味着单元格有一个默认值，这也是工作簿中所有单元格最初使用的默认样式。因此，下面的代码将使所有单元格都具有日期格式： cell.setCellValue(rdf.getEffectiveDate()); cell.getCellStyle().setDataFormat(HSSFDataFormat.getBuiltinFormat(\u0026#34;d-mmm-yy\u0026#34;)); 5.2. 为每个单元格创建新样式 另一个常见的错误是工作簿中有太多相似的样式： CellStyle style1 = codeToCreateCellStyle(); Cell cell1 = row1.createCell(0); cell1.setCellStyle(style1); CellStyle style2 = codeToCreateCellStyle(); Cell cell2 = row1.createCell(1); cell2.setCellStyle(style2); 一个CellStyle的范围是一个工作簿。因此，多个单元格应共享类似的样式。在上面的示例中，样式应该只创建一次并在cell1和cell2之间共享： CellStyle style1 = codeToCreateCellStyle(); Cell cell1 = row1.createCell(0); cell1.setCellStyle(style1); cell1.setCellValue(\u0026#34;Hello\u0026#34;); Cell cell2 = row1.createCell(1); cell2.setCellStyle(style1); cell2.setCellValue(\u0026#34;world!\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_change_cell_font/","tags":["Excel"],"title":"使用 Apache POI 更改单元格字体样式"},{"categories":["Data"],"contents":"1. 概述 在 Excel 工作表上，当我们通过更改表头的背景颜色来突出显示表头时，它总是看起来很优雅。本文介绍如何使用Apache POI更改单元格背景颜色。 此外，我们建议阅读我们在 Java 中使用 Microsoft Excel教程，以了解在 Java 中使用 Excel 的一些基础知识。 2. Maven依赖 首先，我们需要在pom.xml中添加**poi-ooxml作为依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.更改单元格背景颜色 3.1 关于单元格背景 在 Excel 工作表上，我们可以通过填充颜色或图案来更改单元格背景。在下图中，单元格A1填充有浅蓝色背景，而单元格B1填充有图案。此图案有黑色背景和顶部的浅蓝色斑点： 3.2. 更改背景颜色的代码 Apache POI 提供了三种更改背景颜色的方法。在CellStyle类中，我们可以为此目的使用setFillForegroundColor、setFillPattern和setFillBackgroundColor方法。**在IndexedColors类中定义了一个颜色列表。同样，在FillPatternType中定义了一个模式列表。 有时，名称setFillBackgroundColor可能会误导我们。但是，该方法本身不足以改变单元格背景。要通过填充纯色来更改单元格背景，我们使用setFillForegroundColor和setFillPattern方法。第一种方法告诉要填充什么颜色，而第二种方法指定要使用的纯色填充图案。 以下代码段是更改单元格背景的示例方法，如单元格A1所示： public void changeCellBackgroundColor(Cell cell) { CellStyle cellStyle = cell.getCellStyle(); if(cellStyle == null) { cellStyle = cell.getSheet().getWorkbook().createCellStyle(); } cellStyle.setFillForegroundColor(IndexedColors.LIGHT_BLUE.getIndex()); cellStyle.setFillPattern(FillPatternType.SOLID_FOREGROUND); cell.setCellStyle(cellStyle); } 要使用图案更改单元格背景，我们需要使用两种颜色：一种颜色填充整个背景，另一种颜色在第一种颜色之上填充图案。在这里，我们需要使用所有这三种方法。 这里使用方法setFillBackgroundColor来指定背景颜色。仅使用此方法不会产生任何效果。我们需要使用setFillForegroundColor选择第二种颜色并使用setFillPattern来说明图案类型。 以下代码段是更改单元格背景的示例方法，如单元格B1所示： public void changeCellBackgroundColorWithPattern(Cell cell) { CellStyle cellStyle = cell.getCellStyle(); if(cellStyle == null) { cellStyle = cell.getSheet().getWorkbook().createCellStyle(); } cellStyle.setFillBackgroundColor(IndexedColors.BLACK.index); cellStyle.setFillPattern(FillPatternType.BIG_SPOTS); cellStyle.setFillForegroundColor(IndexedColors.LIGHT_BLUE.getIndex()); cell.setCellStyle(cellStyle); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_background_color/","tags":["Excel"],"title":"使用 Apache POI 设置单元格的背景颜色"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将学习如何使用Apache POI Java 库为 Excel 工作表添加边框。 有关 excel 处理的更多基础知识，我们可以从使用 Java 中的 Microsoft Excel开始。 2.Excel边框 我们可以为 Excel 单元格或一系列单元格创建边框。这些边界线可以有多种样式。一些示例样式包括粗线、细线、中线、虚线。为了增加更多种类，我们可以有彩色边框。 此图像显示了其中一些品种边界：  单元格B2带有粗线边框 D2细胞具有宽紫色边框 F2单元格有一个疯狂的边框，边框的每一边都有不同的样式和颜色 范围B4:F6带有中等大小的边框 区域B8:F9带有中等大小的橙色边框  3. Excel 边框编码 Apache POI 库提供了多种处理边界的方法。一种简单的方法是引用单元格范围并应用边框。 3.1 单元格范围或区域 要引用一系列单元格，我们可以使用CellRangeAddress类： CellRangeAddress region = new CellRangeAddress(7, 8, 1, 5); CellRangeAddress构造函数采用第一行、最后一行、第一列和最后一列四个参数。每个行和列索引都从零开始。在上面的代码中，它指的是单元格范围B8:F9。 我们还可以使用CellRangeAddress类引用一个单元格： CellRangeAddress region = new CellRangeAddress(1, 1, 5, 5); 上面的代码是指F2单元格。 3.2. 单元格边界 每个边框有四个边：上、下、左和右边框。我们必须分别设置边框样式的每一侧。BorderStyle类提供了多种样式。 我们可以使用RangeUtil类设置边框： RegionUtil.setBorderTop(BorderStyle.DASH_DOT, region, sheet); RegionUtil.setBorderBottom(BorderStyle.DOUBLE, region, sheet); RegionUtil.setBorderLeft(BorderStyle.DOTTED, region, sheet); RegionUtil.setBorderRight(BorderStyle.SLANTED_DASH_DOT, region, sheet); 3.3. 边框颜色 边框颜色也必须在每一侧单独设置。IndexedColors类提供了一系列要使用的颜色。 我们可以使用RangeUtil类设置边框颜色： RegionUtil.setTopBorderColor(IndexedColors.RED.index, region, sheet); RegionUtil.setBottomBorderColor(IndexedColors.GREEN.index, region, sheet); RegionUtil.setLeftBorderColor(IndexedColors.BLUE.index, region, sheet); RegionUtil.setRightBorderColor(IndexedColors.VIOLET.index, region, sheet); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_add_borders/","tags":["Excel"],"title":"使用 Apache POI 为 Excel 单元格添加边框"},{"categories":["Algorithms"],"contents":"1. 概述 Apache OpenNLP 是一个开源的自然语言处理 Java 库。 它具有用于命名实体识别、句子检测、POS 标记和标记化等用例的 API。 在本教程中，我们将了解如何将此 API 用于不同的用例。 2. Maven 设置 首先，我们需要将主要依赖添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.opennlp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opennlp-tools\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新的稳定版本可以在Maven Central上找到。 一些用例需要经过训练的模型。您可以在此处下载预定义模型，并在此处下载有关这些模型的详细信息。 3. 句子检测 让我们从了解什么是句子开始。 句子检测是关于识别句子的开头和结尾，这通常取决于手头的语言。这也称为“句子边界消歧”（SBD）。 在某些情况下，由于句号的模棱两可，句子检测非常具有挑战性。句点通常表示句子的结尾，但也可以出现在电子邮件地址、缩写、小数点和许多其他地方。 对于大多数 NLP 任务，对于句子检测，我们需要一个经过训练的模型作为输入，我们希望它位于*/resources*文件夹中。 为了实现句子检测，我们加载模型并将其传递给 SentenceDetectorME的实例。然后，我们只需将文本传递给*sentDetect()*方法以在句子边界处拆分它： @Test public void givenEnglishModel_whenDetect_thenSentencesAreDetected() throws Exception { String paragraph = \u0026#34;This is a statement. This is another statement.\u0026#34; + \u0026#34;Now is an abstract word for time, \u0026#34; + \u0026#34;that is always flying. And my email address is [[email protected]](cdn-cgi/l/email-protection)\u0026#34;; InputStream is = getClass().getResourceAsStream(\u0026#34;/models/en-sent.bin\u0026#34;); SentenceModel model = new SentenceModel(is); SentenceDetectorME sdetector = new SentenceDetectorME(model); String sentences[] = sdetector.sentDetect(paragraph); assertThat(sentences).contains( \u0026#34;This is a statement.\u0026#34;, \u0026#34;This is another statement.\u0026#34;, \u0026#34;Now is an abstract word for time, that is always flying.\u0026#34;, \u0026#34;And my email address is [[email protected]](cdn-cgi/l/email-protection)\u0026#34;); } 注意：后缀“ME”用于 Apache OpenNLP 的许多类名中，表示基于“最大熵”的算法。 4. 分词 现在我们可以将文本语料库划分为句子，我们可以开始更详细地分析句子。 标记化的目标是将一个句子分成更小的部分，称为标记。通常，这些标记是单词、数字或标点符号。 OpenNLP 中提供了三种类型的标记器。 4.1 使用TokenizerME 在这种情况下，我们首先需要加载模型。我们可以从这里下载模型文件，将它放在*/resources*文件夹中，然后从那里加载它。 接下来，我们将使用加载的模型创建TokenizerME的实例 ，并使用tokenize()方法对任何字符串执行标记化： @Test public void givenEnglishModel_whenTokenize_thenTokensAreDetected() throws Exception { InputStream inputStream = getClass() .getResourceAsStream(\u0026#34;/models/en-token.bin\u0026#34;); TokenizerModel model = new TokenizerModel(inputStream); TokenizerME tokenizer = new TokenizerME(model); String[] tokens = tokenizer.tokenize(\u0026#34;Demo is a Spring Resource.\u0026#34;); assertThat(tokens).contains( \u0026#34;Demo\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;Spring\u0026#34;, \u0026#34;Resource\u0026#34;, \u0026#34;.\u0026#34;); } 正如我们所见，分词器已将所有单词和句点字符识别为单独的令牌。此标记器也可以与自定义训练模型一起使用。 **4.2. WhitespaceTokenizer ** 顾名思义，这个分词器只是使用空白字符作为分隔符将句子拆分为分词： @Test public void givenWhitespaceTokenizer_whenTokenize_thenTokensAreDetected() throws Exception { WhitespaceTokenizer tokenizer = WhitespaceTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;Demo is a Spring Resource.\u0026#34;); assertThat(tokens) .contains(\u0026#34;Demo\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;Spring\u0026#34;, \u0026#34;Resource.\u0026#34;); } 我们可以看到句子被空格分割，因此我们得到“资源”。（末尾带有句点字符）作为单个标记，而不是单词“资源”和句点字符的两个不同标记。 **4.3. SimpleTokenizer ** 这个分词器比WhitespaceTokenizer稍微复杂一点，它将句子分成单词、数字和标点符号。这是默认行为，不需要任何模型： @Test public void givenSimpleTokenizer_whenTokenize_thenTokensAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer .tokenize(\u0026#34;Demo is a Spring Resource.\u0026#34;); assertThat(tokens) .contains(\u0026#34;Demo\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;Spring\u0026#34;, \u0026#34;Resource\u0026#34;, \u0026#34;.\u0026#34;); } 5. 命名实体识别 现在我们已经了解了标记化，让我们看一下基于成功标记化的第一个用例：命名实体识别 (NER)。 NER 的目标是在给定文本中找到命名实体，例如人、位置、组织和其他命名事物。 OpenNLP 使用人名、日期和时间、位置和组织的预定义模型。我们需要使用TokenNameFinderModel加载模型并将其传递给*NameFinderME 的实例。然后我们可以使用find()*方法在给定文本中查找命名实体： @Test public void givenEnglishPersonModel_whenNER_thenPersonsAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer .tokenize(\u0026#34;John is 26 years old. His best friend\u0026#39;s \u0026#34; + \u0026#34;name is Leonard. He has a sister named Penny.\u0026#34;); InputStream inputStreamNameFinder = getClass() .getResourceAsStream(\u0026#34;/models/en-ner-person.bin\u0026#34;); TokenNameFinderModel model = new TokenNameFinderModel( inputStreamNameFinder); NameFinderME nameFinderME = new NameFinderME(model); List\u0026lt;Span\u0026gt; spans = Arrays.asList(nameFinderME.find(tokens)); assertThat(spans.toString()) .isEqualTo(\u0026#34;[[0..1) person, [13..14) person, [20..21) person]\u0026#34;); } 正如我们在断言中看到的，结果是一个Span对象列表，其中包含组成文本中命名实体的标记的开始和结束索引。 6. 词性标注 另一个需要标记列表作为输入的用例是词性标记。 **词性（POS）识别词的类型。**OpenNLP 对不同的词性使用以下标签：  **NN –**名词、单数或质量 **DT——**确定者 **VB——**动词，基本形式 **VBD——**动词，过去式 **VBZ –**动词，第三人称单数现在时 **IN——**介词或从属连词 **NNP –**专有名词，单数 TO—— “到”这个词 **JJ——**形容词  这些标签与 Penn Tree Bank 中定义的标签相同。如需完整列表，请参阅 此列表。 与 NER 示例类似，我们加载适当的模型，然后 在一组标记上使用POSTaggerME 及其方法tag()来标记句子： @Test public void givenPOSModel_whenPOSTagging_thenPOSAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;John has a sister named Penny.\u0026#34;); InputStream inputStreamPOSTagger = getClass() .getResourceAsStream(\u0026#34;/models/en-pos-maxent.bin\u0026#34;); POSModel posModel = new POSModel(inputStreamPOSTagger); POSTaggerME posTagger = new POSTaggerME(posModel); String tags[] = posTagger.tag(tokens); assertThat(tags).contains(\u0026#34;NNP\u0026#34;, \u0026#34;VBZ\u0026#34;, \u0026#34;DT\u0026#34;, \u0026#34;NN\u0026#34;, \u0026#34;VBN\u0026#34;, \u0026#34;NNP\u0026#34;, \u0026#34;.\u0026#34;); } *tag()*方法将标记映射到 POS 标签列表中。示例中的结果是：  “John” - NNP（专有名词） “has” – VBZ（动词） “a” – DT（决定者） “sister”——NN（名词） “named” – VBZ（动词） “Penny” – NNP（专有名词） “.” - 时期  7. 词形还原 现在我们有了句子中标记的词性信息，我们可以进一步分析文本。 词形还原是将具有时态、性别、情绪或其他信息的词形映射到词****的基本形式的过程——也称为“引理”。 lemmatizer 将标记及其词性标记作为输入并返回单词的 lemma。因此，在词形还原之前，句子应该通过分词器和词性标注器。 Apache OpenNLP 提供两种类型的词形还原：  统计 - 需要使用训练数据构建的 lemmatizer 模型来查找给定单词的 lemma 基于字典 - 需要包含单词、POS 标签和相应引理的所有有效组合的字典  对于统计词形还原，我们需要训练一个模型，而对于字典词形还原，我们只需要一个像这样的字典文件。 让我们看一个使用字典文件的代码示例： @Test public void givenEnglishDictionary_whenLemmatize_thenLemmasAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;John has a sister named Penny.\u0026#34;); InputStream inputStreamPOSTagger = getClass() .getResourceAsStream(\u0026#34;/models/en-pos-maxent.bin\u0026#34;); POSModel posModel = new POSModel(inputStreamPOSTagger); POSTaggerME posTagger = new POSTaggerME(posModel); String tags[] = posTagger.tag(tokens); InputStream dictLemmatizer = getClass() .getResourceAsStream(\u0026#34;/models/en-lemmatizer.dict\u0026#34;); DictionaryLemmatizer lemmatizer = new DictionaryLemmatizer( dictLemmatizer); String[] lemmas = lemmatizer.lemmatize(tokens, tags); assertThat(lemmas) .contains(\u0026#34;O\u0026#34;, \u0026#34;have\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;sister\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;O\u0026#34;, \u0026#34;O\u0026#34;); } 正如我们所见，我们得到了每个标记的引理。“O”表示无法确定引理，因为该词是专有名词。所以，我们没有“John”和“Penny”的引理。 但是我们已经确定了句子其他单词的引理：  有——有 一个 - 一个 姐姐——姐姐 命名——名字  8. 分块 词性信息在分块中也很重要—— 将句子分成语法上有意义的词组，如名词组或动词组。 *与之前类似，我们标记一个句子并在调用chunk()*方法之前对标记使用词性标记 ： @Test public void givenChunkerModel_whenChunk_thenChunksAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;He reckons the current account deficit will narrow to only 8 billion.\u0026#34;); InputStream inputStreamPOSTagger = getClass() .getResourceAsStream(\u0026#34;/models/en-pos-maxent.bin\u0026#34;); POSModel posModel = new POSModel(inputStreamPOSTagger); POSTaggerME posTagger = new POSTaggerME(posModel); String tags[] = posTagger.tag(tokens); InputStream inputStreamChunker = getClass() .getResourceAsStream(\u0026#34;/models/en-chunker.bin\u0026#34;); ChunkerModel chunkerModel = new ChunkerModel(inputStreamChunker); ChunkerME chunker = new ChunkerME(chunkerModel); String[] chunks = chunker.chunk(tokens, tags); assertThat(chunks).contains( \u0026#34;B-NP\u0026#34;, \u0026#34;B-VP\u0026#34;, \u0026#34;B-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;B-VP\u0026#34;, \u0026#34;I-VP\u0026#34;, \u0026#34;B-PP\u0026#34;, \u0026#34;B-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;O\u0026#34;); } 正如我们所看到的，我们从分块器中获得了每个标记的输出。“B”代表块的开始，“I”代表块的延续，“O”代表没有块。 解析我们示例的输出，我们得到 6 个块：  “他”——名词短语 “估计” - 动词短语 “经常账户赤字”——名词短语 “将缩小” - 动词短语 “to”——介词短语 “只有 80 亿”——名词短语  9. 语言检测 除了已经讨论过的用例之外，OpenNLP 还提供了一个语言检测 API，允许识别特定文本的语言。 对于语言检测，我们需要一个训练数据文件。这样的文件包含带有某种语言句子的行。每一行都标有正确的语言，为机器学习算法提供输入。 可以在此处下载用于语言检测的样本训练数据文件。 我们可以将训练数据文件加载到 LanguageDetectorSampleStream 中， 定义一些训练数据参数，创建模型，然后使用该模型检测文本的语言： @Test public void givenLanguageDictionary_whenLanguageDetect_thenLanguageIsDetected() throws FileNotFoundException, IOException { InputStreamFactory dataIn = new MarkableFileInputStreamFactory( new File(\u0026#34;src/main/resources/models/DoccatSample.txt\u0026#34;)); ObjectStream lineStream = new PlainTextByLineStream(dataIn, \u0026#34;UTF-8\u0026#34;); LanguageDetectorSampleStream sampleStream = new LanguageDetectorSampleStream(lineStream); TrainingParameters params = new TrainingParameters(); params.put(TrainingParameters.ITERATIONS_PARAM, 100); params.put(TrainingParameters.CUTOFF_PARAM, 5); params.put(\u0026#34;DataIndexer\u0026#34;, \u0026#34;TwoPass\u0026#34;); params.put(TrainingParameters.ALGORITHM_PARAM, \u0026#34;NAIVEBAYES\u0026#34;); LanguageDetectorModel model = LanguageDetectorME .train(sampleStream, params, new LanguageDetectorFactory()); LanguageDetector ld = new LanguageDetectorME(model); Language[] languages = ld .predictLanguages(\u0026#34;estava em uma marcenaria na Rua Bruno\u0026#34;); assertThat(Arrays.asList(languages)) .extracting(\u0026#34;lang\u0026#34;, \u0026#34;confidence\u0026#34;) .contains( tuple(\u0026#34;pob\u0026#34;, 0.9999999950605625), tuple(\u0026#34;ita\u0026#34;, 4.939427661577956E-9), tuple(\u0026#34;spa\u0026#34;, 9.665954064665144E-15), tuple(\u0026#34;fra\u0026#34;, 8.250349924885834E-25))); } 结果是最可能的语言列表以及置信度分数。 并且，通过丰富的模型，我们可以通过这种类型的检测实现非常高的准确度。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_open_nlp/","tags":[],"title":"Apache OpenNLP 简介"},{"categories":["Architecture"],"contents":"1. 概述 我们通常在同一个机器集群上部署各种应用程序。例如，现在很常见的是 在同一个集群中拥有像Apache Spark或Apache Flink这样的分布式处理引擎和像Apache Cassandra这样的分布式数据库。 Apache Mesos 是一个允许此类应用程序之间有效资源共享的平台。 在本文中，我们将首先讨论部署在同一集群上的应用程序中的资源分配问题。稍后，我们将看到 Apache Mesos 如何在应用程序之间提供更好的资源利用率。 2. 共享集群 许多应用程序需要共享一个集群。总的来说，有两种常见的方法：  静态分区集群并在每个分区上运行应用程序 将一组机器分配给一个应用程序  尽管这些方法允许应用程序彼此独立运行，但它并没有实现高资源利用率。 例如，考虑一个应用程序，它只运行了很短的时间，然后是一段时间的不活动。现在，由于我们为该应用程序分配了静态机器或分区，因此在非活动期间我们有未使用的资源。 我们可以通过将非活动期间的空闲资源重新分配给其他应用程序来优化资源利用率。 Apache Mesos 有助于在应用程序之间进行动态资源分配。 3. Apache Mesos 使用我们上面讨论的两种集群共享方法，应用程序只知道它们正在运行的特定分区或机器的资源。但是，Apache Mesos 为应用程序提供了集群中所有资源的抽象视图。 我们很快就会看到，Mesos 充当机器和应用程序之间的接口。它为应用程序提供**集群中所有机器上的可用资源。它经常更新此信息以包括由已达到完成状态的应用程序释放的资源。**这允许应用程序就在哪台机器上执行哪个任务做出最佳决定。 为了理解 Mesos 是如何工作的，让我们来看看它的架构：  此图像是 Mesos 官方文档的一部分（来源）。在这里，Hadoop和MPI是共享集群的两个应用程序。 我们将在接下来的几节中讨论此处显示的每个组件。 3.1 Mesos 大师 Master 是此设置中的核心组件，用于存储集群中资源的当前状态。此外，它通过传递有关资源和任务等信息，充当代理和应用程序之间的协调器。 由于 master 中的任何故障都会导致有关资源和任务的状态丢失，因此我们将其部署在高可用性配置中。从上图中可以看出，Mesos 部署了备用主守护进程和一个领导者。这些守护进程依靠 Zookeeper 来在发生故障时恢复状态。 3.2. Mesos 代理 Mesos 集群必须在每台机器上运行一个代理。这些代理会定期向主服务器报告它们的资源，并依次接收应用程序已安排运行的任务。此循环在计划任务完成或丢失后重复。 我们将在以下部分中了解应用程序如何在这些代理上调度和执行任务。 3.3. 中观框架 Mesos 允许应用程序实现一个抽象组件，该组件与 Master 交互以**接收集群中的可用资源，并根据它们做出调度决策。**这些组件称为框架。 一个 Mesos 框架由两个子组件组成：  调度程序- 使应用程序能够根据所有代理上的可用资源来调度任务 Executor – 在所有代理上运行，并包含在该代理上执行任何计划任务所需的所有信息  这个流程描述了整个过程： 首先，代理向主报告他们的资源。此时，master 将这些资源提供给所有已注册的调度程序。此过程称为资源提供，我们将在下一节中详细讨论。 然后调度程序选择最好的代理并通过 Master 在其上执行各种任务。一旦执行者完成分配的任务，代理就会重新将他们的资源发布给主节点。Master 对集群中的所有框架重复这个资源共享过程。 Mesos 允许应用程序以各种编程语言实现其自定义调度程序和执行程序。调度程序的Java 实现必须实现调度程序接口： public class HelloWorldScheduler implements Scheduler { @Override public void registered(SchedulerDriver schedulerDriver, Protos.FrameworkID frameworkID, Protos.MasterInfo masterInfo) { } @Override public void reregistered(SchedulerDriver schedulerDriver, Protos.MasterInfo masterInfo) { } @Override public void resourceOffers(SchedulerDriver schedulerDriver, List\u0026lt;Offer\u0026gt; list) { } @Override public void offerRescinded(SchedulerDriver schedulerDriver, OfferID offerID) { } @Override public void statusUpdate(SchedulerDriver schedulerDriver, Protos.TaskStatus taskStatus) { } @Override public void frameworkMessage(SchedulerDriver schedulerDriver, Protos.ExecutorID executorID, Protos.SlaveID slaveID, byte[] bytes) { } @Override public void disconnected(SchedulerDriver schedulerDriver) { } @Override public void slaveLost(SchedulerDriver schedulerDriver, Protos.SlaveID slaveID) { } @Override public void executorLost(SchedulerDriver schedulerDriver, Protos.ExecutorID executorID, Protos.SlaveID slaveID, int i) { } @Override public void error(SchedulerDriver schedulerDriver, String s) { } } 可以看出，它主要由各种回调方法组成，特别是用于与主设备通信。 同样，执行器的实现必须实现Executor接口： public class HelloWorldExecutor implements Executor { @Override public void registered(ExecutorDriver driver, Protos.ExecutorInfo executorInfo, Protos.FrameworkInfo frameworkInfo, Protos.SlaveInfo slaveInfo) { } @Override public void reregistered(ExecutorDriver driver, Protos.SlaveInfo slaveInfo) { } @Override public void disconnected(ExecutorDriver driver) { } @Override public void launchTask(ExecutorDriver driver, Protos.TaskInfo task) { } @Override public void killTask(ExecutorDriver driver, Protos.TaskID taskId) { } @Override public void frameworkMessage(ExecutorDriver driver, byte[] data) { } @Override public void shutdown(ExecutorDriver driver) { } } 我们将在后面的部分中看到调度器和执行器的操作版本。 4. 资源管理 4.1 资源优惠 正如我们之前所讨论的，代理将其资源信息发布给主节点。反过来，主节点将这些资源提供给集群中运行的框架。此过程称为资源报价。 资源报价由两部分组成——资源和属性。 资源用于发布代理机器的内存、CPU、磁盘等硬件信息。 每个代理都有五种预定义资源：  中央处理器 显卡 内存 磁盘 港口  这些资源的值可以定义为以下三种类型之一：  标量- 用于使用浮点数表示数字信息以允许小数值，例如 1.5G 内存 范围——用于表示标量值的范围——例如，端口范围 Set – 用于表示多个文本值  默认情况下，Mesos 代理会尝试从机器上检测这些资源。 但是，在某些情况下，我们可以在代理上配置自定义资源。此类自定义资源的值应再次采用上述任何一种类型。 例如，我们可以使用以下资源启动我们的代理： --resources=\u0026#39;cpus:24;gpus:2;mem:24576;disk:409600;ports:[21000-24000,30000-34000];bugs(debug_role):{a,b,c}\u0026#39; 可以看出，我们已经为代理配置了一些预定义资源和一个名为bugs的自定义资源，它是 集合类型。 除了资源之外，代理还可以向主服务器发布键值属性。这些属性充当代理的附加元数据，并帮助框架进行调度决策。 一个有用的示例可以是将代理添加到不同的机架或区域，然后在同一机架或区域上安排各种任务以实现数据本地化： --attributes=\u0026#39;rack:abc;zone:west;os:centos5;level:10;keys:[1000-1500]\u0026#39; 与资源类似，属性值可以是标量、范围或文本类型。 4.2. 资源角色 许多现代操作系统支持多个用户。同样，Mesos 也支持同一个集群中的多个用户。这些用户称为角色。我们可以将每个角色视为集群中的资源消费者。 因此，Mesos 代理可以根据不同的分配策略对不同角色下的资源进行划分。此外，框架可以在集群中订阅这些角色，并对不同角色下的资源进行细粒度控制。 例如，考虑一个集群托管应用程序，这些应用程序为组织中的不同用户提供服务。因此，通过将资源划分为角色，每个应用程序都可以彼此隔离工作。 此外，框架可以使用这些角色来实现数据局部性。 例如，假设我们在集群中有两个应用程序，名为生产者和 消费者。在这里， 生产者将数据写入一个持久卷， 消费者随后可以读取该卷。我们可以 通过与生产者共享卷 来优化消费者 应用程序。 由于 Mesos 允许多个应用程序订阅同一个角色，我们可以将持久卷与资源角色相关联。此外，生产者和 消费者的框架都将订阅相同的资源角色。因此，消费者应用程序现在可以在与生产者应用程序相同的卷上启动数据读取任务。 4.3. 资源预留 现在可能会出现关于 Mesos 如何将集群资源分配给不同角色的问题。Mesos 通过预留分配资源。 有两种类型的预订：  静态预留 动态预订  静态预留类似于我们在前面部分讨论的代理启动时的资源分配： --resources=\u0026#34;cpus:4;mem:2048;cpus(Demo):8;mem(Demo):4096\u0026#34; 这里唯一的区别是，现在 Mesos 代理为名为Demo的角色保留了 8 个 CPU 和 4096m 内存。 与静态预留不同，动态预留允许我们重新调整角色内的资源。Mesos 允许框架和集群操作员通过框架消息作为对资源提供的响应或通过HTTP 端点动态更改资源分配。 Mesos 将所有没有任何角色的资源分配给一个名为 (*) 的默认角色。Master 向所有框架提供此类资源，无论它们是否订阅。 4.4. 资源权重和配额 通常，Mesos 主节点使用公平策略提供资源。它使用加权的优势资源公平 (wDRF) 来识别缺乏资源的角色。然后，master 向订阅了这些角色的框架提供更多资源。 尽管在应用程序之间公平共享资源是 Mesos 的一个重要特性，但它并不总是必要的。假设一个集群托管具有低资源占用的应用程序以及具有高资源需求的应用程序。在此类部署中，我们希望根据应用程序的性质分配资源。 Mesos 允许框架**通过订阅角色并为该角色添加更高的权重值来要求更多资源。**因此，如果有两个角色，一个是权重 1，另一个是权重 2，Mesos 会将两倍的公平资源分配给第二个角色。 与资源类似，我们可以通过HTTP 端点配置权重。 除了确保为具有权重的角色分配公平的资源外，Mesos 还确保为角色分配最少的资源。 Mesos 允许我们为资源角色添加配额。配额指定角色可以保证接收的最小资源量。 5. 实施框架 正如我们在前面部分中讨论的，Mesos 允许应用程序以他们选择的语言提供框架实现。在 Java 中，使用主类（作为框架进程的入口点）以及前面讨论的调度器和 执行器 的实现来实现框架。 5.1 框架主类 在我们实现调度器和执行器之前，我们将首先实现我们框架的入口点：  向主人注册自己 向代理提供执行程序运行时信息 启动调度程序  我们将首先为 Mesos添加一个Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.mesos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mesos\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.28.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，我们将为我们的框架实现 HelloWorldMain。我们要做的第一件事是在 Mesos 代理上启动执行器进程： public static void main(String[] args) { String path = System.getProperty(\u0026#34;user.dir\u0026#34;) + \u0026#34;/target/libraries2-1.0.0-SNAPSHOT.jar\u0026#34;; CommandInfo.URI uri = CommandInfo.URI.newBuilder().setValue(path).setExtract(false).build(); String helloWorldCommand = \u0026#34;java -cp libraries2-1.0.0-SNAPSHOT.jar com.codingman.mesos.executors.HelloWorldExecutor\u0026#34;; CommandInfo commandInfoHelloWorld = CommandInfo.newBuilder() .setValue(helloWorldCommand) .addUris(uri) .build(); ExecutorInfo executorHelloWorld = ExecutorInfo.newBuilder() .setExecutorId(Protos.ExecutorID.newBuilder() .setValue(\u0026#34;HelloWorldExecutor\u0026#34;)) .setCommand(commandInfoHelloWorld) .setName(\u0026#34;Hello World (Java)\u0026#34;) .setSource(\u0026#34;java\u0026#34;) .build(); } 在这里，我们首先配置了执行器二进制位置。Mesos 代理将在框架注册时下载此二进制文件。接下来，代理将运行给定的命令来启动执行程序进程。 接下来，我们将初始化我们的框架并启动调度程序： FrameworkInfo.Builder frameworkBuilder = FrameworkInfo.newBuilder() .setFailoverTimeout(120000) .setUser(\u0026#34;\u0026#34;) .setName(\u0026#34;Hello World Framework (Java)\u0026#34;); frameworkBuilder.setPrincipal(\u0026#34;test-framework-java\u0026#34;); MesosSchedulerDriver driver = new MesosSchedulerDriver(new HelloWorldScheduler(), frameworkBuilder.build(), args[0]); 最后，**我们将启动向 Master 注册自身的MesosSchedulerDriver。为了成功注册，我们必须将 Master 的 IP 作为程序参数 args[0]传递给这个主类： int status = driver.run() == Protos.Status.DRIVER_STOPPED ? 0 : 1; driver.stop(); System.exit(status); 在上面显示的类中， CommandInfo、ExecutorInfo 和FrameworkInfo都是master 和框架之间的protobuf 消息的 Java 表示。 5.2. 实现调度器 从 Mesos 1.0 开始，我们可以从任何 Java 应用程序调用HTTP 端点来向 Mesos 主机发送和接收消息。其中一些消息包括，例如，框架注册、资源报价和报价拒绝。 对于Mesos 0.28 或更早版本，我们需要实现Scheduler接口： 在大多数情况下，我们将只关注 调度程序的**resourceOffers方法 。让我们看看调度程序如何接收资源并根据它们初始化任务。 首先，我们将了解调度程序如何为任务分配资源： @Override public void resourceOffers(SchedulerDriver schedulerDriver, List\u0026lt;Offer\u0026gt; list) { for (Offer offer : list) { List\u0026lt;TaskInfo\u0026gt; tasks = new ArrayList\u0026lt;TaskInfo\u0026gt;(); Protos.TaskID taskId = Protos.TaskID.newBuilder() .setValue(Integer.toString(launchedTasks++)).build(); System.out.println(\u0026#34;Launching printHelloWorld \u0026#34; + taskId.getValue() + \u0026#34; Hello World Java\u0026#34;); Protos.Resource.Builder cpus = Protos.Resource.newBuilder() .setName(\u0026#34;cpus\u0026#34;) .setType(Protos.Value.Type.SCALAR) .setScalar(Protos.Value.Scalar.newBuilder() .setValue(1)); Protos.Resource.Builder mem = Protos.Resource.newBuilder() .setName(\u0026#34;mem\u0026#34;) .setType(Protos.Value.Type.SCALAR) .setScalar(Protos.Value.Scalar.newBuilder() .setValue(128)); 在这里，我们为我们的任务分配了 1 个 CPU 和 128M 内存。接下来，我们将使用SchedulerDriver在代理上启动任务： TaskInfo printHelloWorld = TaskInfo.newBuilder() .setName(\u0026#34;printHelloWorld \u0026#34; + taskId.getValue()) .setTaskId(taskId) .setSlaveId(offer.getSlaveId()) .addResources(cpus) .addResources(mem) .setExecutor(ExecutorInfo.newBuilder(helloWorldExecutor)) .build(); List\u0026lt;OfferID\u0026gt; offerIDS = new ArrayList\u0026lt;\u0026gt;(); offerIDS.add(offer.getId()); tasks.add(printHelloWorld); schedulerDriver.launchTasks(offerIDS, tasks); } } 或者， 调度程序经常发现需要拒绝资源提供。例如，如果 调度程序由于缺乏资源而无法在代理上启动任务，它必须立即拒绝该提议： schedulerDriver.declineOffer(offer.getId()); 5.3. 执行者 正如我们前面所讨论的，框架的执行器组件负责在 Mesos 代理上执行应用程序任务。 我们使用 HTTP 端点在 Mesos 1.0中实现*调度程序。*同样，我们可以将HTTP 端点用于执行程序。 在前面的部分中，我们讨论了框架如何配置代理以启动执行程序进程： java -cp libraries2-1.0.0-SNAPSHOT.jar com.codingman.mesos.executors.HelloWorldExecutor 值得注意的是，此命令将 HelloWorldExecutor视为主类。我们将实现这个main方法来初始化与 Mesos 代理连接的MesosExecutorDriver以接收任务并共享其他信息，例如任务状态： public class HelloWorldExecutor implements Executor { public static void main(String[] args) { MesosExecutorDriver driver = new MesosExecutorDriver(new HelloWorldExecutor()); System.exit(driver.run() == Protos.Status.DRIVER_STOPPED ? 0 : 1); } } 现在要做的最后一件事是接受来自框架的任务并在代理上启动它们。启动任何任务的信息都包含在HelloWorldExecutor 中： public void launchTask(ExecutorDriver driver, TaskInfo task) { Protos.TaskStatus status = Protos.TaskStatus.newBuilder() .setTaskId(task.getTaskId()) .setState(Protos.TaskState.TASK_RUNNING) .build(); driver.sendStatusUpdate(status); System.out.println(\u0026#34;Execute Task!!!\u0026#34;); status = Protos.TaskStatus.newBuilder() .setTaskId(task.getTaskId()) .setState(Protos.TaskState.TASK_FINISHED) .build(); driver.sendStatusUpdate(status); } 当然，这只是一个简单的实现，但它解释了 executor 如何在每个阶段与 master 共享任务状态，然后在发送完成状态之前执行任务。 在某些情况下，执行器还可以将数据发送回调度器： String myStatus = \u0026#34;Hello Framework\u0026#34;; driver.sendFrameworkMessage(myStatus.getBytes()); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_mesos/","tags":[],"title":"Apache Mesos 指南"},{"categories":["REST"],"contents":"1. 概述 在本教程中，我们将探索 Apache Meecrowave框架的基本功能。 Meecrowave 是来自 Apache 的轻量级微服务框架，它与 CDI、JAX-RS 和 JSON API 配合得非常好。设置和部署非常简单。它还消除了部署重型应用服务器（如 Tomcat、Glassfish、Wildfly 等）的麻烦。 2.Maven依赖 要使用 Meecrowave，让我们在 pom.xml 中定义依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.meecrowave\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;meecrowave-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在Maven Central上检查最新版本。 3. 启动一个简单的服务器 我要启动一个 Meecrowave 服务器，我们需要做的就是编写 main方法，**创建一个Meecrowave实例并调用 main bake()方法： public static void main(String[] args) { try (Meecrowave meecrowave = new Meecrowave()) { meecrowave.bake().await(); } } 如果我们把应用打包成分发包，就不需要这个main方法；我们将在后面的部分中对此进行研究。在从 IDE 测试应用程序时，主类很有用。 作为一个优势，在 IDE 中开发时，一旦我们使用主类运行应用程序，它会随着代码更改自动重新加载，从而省去了一次又一次地重新启动服务器以进行测试的麻烦。 请注意，如果我们使用的是 Java 9，请不要忘记将 javax .xml.bind模块添加到 VM： --add-module javax.xml.bind 以这种方式创建服务器将使用默认配置启动它。我们可以使用 Meecrowave.Builder类以编程方式更新默认配置*：* Meecrowave.Builder builder = new Meecrowave.Builder(); builder.setHttpPort(8080); builder.setScanningPackageIncludes(\u0026#34;com.codingman.meecrowave\u0026#34;); builder.setJaxrsMapping(\u0026#34;/api/*\u0026#34;); builder.setJsonpPrettify(true); 并在烘焙服务器时使用此 构建器实例： try (Meecrowave meecrowave = new Meecrowave(builder)) { meecrowave.bake().await(); } 这里有更多可配置的属性 。 4. REST 端点 现在，一旦服务器准备就绪，让我们创建一些 REST 端点： @RequestScoped @Path(\u0026#34;article\u0026#34;) public class ArticleEndpoints { @GET public Response getArticle() { return Response.ok().entity(new Article(\u0026#34;name\u0026#34;, \u0026#34;author\u0026#34;)).build(); } @POST public Response createArticle(Article article) { return Response.status(Status.CREATED).entity(article).build(); } } 请注意，我们主要使用 JAX-RS 注释来创建 REST 端点。在此处阅读有关 JAX-RS 的更多信息。 在下一节中，我们将看到如何测试这些端点。 5. 测试 使用 Meecrowave 编写的 REST API 编写单元测试用例就像编写带注释的 JUnit 测试用例一样简单。 让我们首先将测试依赖项添加到我们的 pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.meecrowave\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;meecrowave-junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 要查看最新版本，请查看Maven Central。 另外，让我们添加OkHttp作为我们测试的 HTTP 客户端： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.squareup.okhttp3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;okhttp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.10.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在这里查看最新版本。 现在有了依赖关系，让我们继续编写测试： @RunWith(MonoMeecrowave.Runner.class) public class ArticleEndpointsIntegrationTest { @ConfigurationInject private Meecrowave.Builder config; private static OkHttpClient client; @BeforeClass public static void setup() { client = new OkHttpClient(); } @Test public void whenRetunedArticle_thenCorrect() { String base = \u0026#34;http://localhost:\u0026#34; + config.getHttpPort(); Request request = new Request.Builder() .url(base + \u0026#34;/article\u0026#34;) .build(); Response response = client.newCall(request).execute(); assertEquals(200, response.code()); } } 在编写测试用例时，使用MonoMeecrowave.Runner类注释测试类 ，同时注入配置，以访问 Meecrowave 用于测试服务器的随机端口 6. 依赖注入 要将依赖项注入到类中，我们需要在特定范围内注释这些类。 让我们以ArticleService类为例 ： @ApplicationScoped public class ArticleService { public Article createArticle(Article article) { return article; } } 现在让我们使用javax.inject.Inject注释将其注入到我们的 ArticleEndpoints实例中 ： @Inject ArticleService articleService; 7. 打包应用程序 使用 Meecrowave Maven 插件创建分发包变得非常简单： \u0026lt;build\u0026gt; ... \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.meecrowave\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;meecrowave-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 一旦我们有了插件，让我们使用 Maven 目标 meecrowave:bundle来打包应用程序。 打包后，它将在目标目录中创建一个 zip： meecrowave-meecrowave-distribution.zip 此 zip 包含部署应用程序所需的工件： |____meecrowave-distribution | |____bin | | |____meecrowave.sh | |____logs | | |____you_can_safely_delete.txt | |____lib | |____conf | | |____log4j2.xml | | |____meecrowave.properties 让我们导航到 bin 目录并启动应用程序： ./meecrowave.sh start 要停止应用程序： ./meecrowave.sh stop \u0026quot; ","permalink":"http://itcodingman.github.io/apache_meecrowave/","tags":[],"title":"使用 Apache Meecrowave 构建微服务"},{"categories":["Algorithms","DevOps"],"contents":"1. 概述 在本教程中，我们将使用 Apache Kafka 进入事件驱动架构的数据建模领域。 2. 设置 Kafka 集群由多个注册到 Zookeeper 集群的 Kafka 代理组成。为了简单起见，我们将使用由 Confluent 发布的**现成 Docker 镜像和docker-compose**配置。 首先，让我们为 3 节点 Kafka 集群下载docker-compose.yml ： $ BASE_URL=\u0026#34;https://raw.githubusercontent.com/confluentinc/cp-docker-images/5.3.3-post/examples/kafka-cluster\u0026#34; $ curl -Os \u0026#34;$BASE_URL\u0026#34;/docker-compose.yml 接下来，让我们启动 Zookeeper 和 Kafka 代理节点： $ docker-compose up -d 最后，我们可以验证所有 Kafka 代理都已启动： $ docker-compose logs kafka-1 kafka-2 kafka-3 | grep started kafka-1_1 | [2020-12-27 10:15:03,783] INFO [KafkaServer id=1] started (kafka.server.KafkaServer) kafka-2_1 | [2020-12-27 10:15:04,134] INFO [KafkaServer id=2] started (kafka.server.KafkaServer) kafka-3_1 | [2020-12-27 10:15:03,853] INFO [KafkaServer id=3] started (kafka.server.KafkaServer) 3. 活动基础 在我们开始为事件驱动系统进行数据建模之前，我们需要了解一些概念，例如事件、事件流、生产者-消费者和主题。 3.1 事件 Kafka 世界中的事件是域世界中发生的事情的信息日志。它通过将信息记录为键值对消息以及一些其他属性（例如时间戳、元信息和标头）来实现这一点。 假设我们正在模拟一个国际象棋游戏；那么一个事件可能是一个动作： 我们可以注意到，事件保存了参与者、动作和发生时间的关键信息。在这种情况下，Player1是演员，动作是在12/2020/25 00:08:30将车从单元格**a1移动到a5。 3.2. 消息流 Apache Kafka 是一种流处理系统，可将事件捕获为消息流。在我们的国际象棋游戏中，我们可以将事件流视为玩家下棋的日志。 在每个事件发生时，板的快照将代表其状态。使用传统的表模式存储对象的最新静态状态通常很常见。 另一方面，事件流可以帮助我们以事件的形式捕捉两个连续状态之间的动态变化。如果我们播放一系列这些不可变的事件，我们可以从一种状态转换到另一种状态。这就是事件流和传统表之间的关系，通常称为流表对偶性。 让我们可视化棋盘上只有两个连续事件的事件流： 4. 话题 在本节中，我们将学习如何对通过 Apache Kafka 路由的消息进行分类。 4.1分类 在 Apache Kafka 这样的消息传递系统中，任何产生事件的东西通常都称为生产者。而阅读和消费这些消息的人称为消费者。 在现实世界的场景中，每个生产者都可以生成不同类型的事件，所以如果我们期望消费者过滤与他们相关的消息而忽略其余的消息，那将是浪费大量精力。 为了解决这个基本问题，Apache Kafka 使用的主题本质上是属于一起的消息组。因此，消费者在使用事件消息时可以更有效率。 在我们的棋盘示例中，可以使用一个主题将所有移动分组到chess-moves主题下： $ docker run \\  --net=host --rm confluentinc/cp-kafka:5.0.0 \\  kafka-topics --create --topic chess-moves \\  --if-not-exists \\  --partitions 1 --replication-factor 1 \\  --zookeeper localhost:32181 Created topic \u0026#34;chess-moves\u0026#34;. 4.2. 生产者-消费者 现在，让我们看看生产者和消费者如何使用 Kafka 的主题进行消息处理。我们将使用Kafka 发行版附带的kafka-console-producer和kafka-console-consumer实用程序来演示这一点。 让我们启动一个名为kafka-producer的容器，我们将在其中调用 producer 实用程序： $ docker run \\ --net=host \\ --name=kafka-producer \\ -it --rm \\ confluentinc/cp-kafka:5.0.0 /bin/bash # kafka-console-producer --broker-list localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves \\ --property parse.key=true --property key.separator=: 同时，我们可以启动一个名为kafka-consumer的容器，我们将在其中调用消费者实用程序： $ docker run \\ --net=host \\ --name=kafka-consumer \\ -it --rm \\ confluentinc/cp-kafka:5.0.0 /bin/bash # kafka-console-consumer --bootstrap-server localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves --from-beginning \\ --property print.key=true --property print.value=true --property key.separator=: 现在，让我们通过制作人记录一些游戏动作： \u0026gt;{Player1 : Rook, a1-\u0026gt;a5} 当消费者处于活动状态时，它将使用作为Player1的键接收此消息： {Player1 : Rook, a1-\u0026gt;a5} 5. 分区 接下来，让我们看看如何使用分区创建进一步的消息分类并提高整个系统的性能。 5.1 并发 我们可以将一个主题划分为多个分区，调用多个消费者来消费来自不同分区的消息。通过启用这种并发行为，可以提高系统的整体性能。 默认情况下，在创建主题期间支持–bootstrap-server选项的 Kafka 版本将创建主题的单个分区，**除非在创建主题时明确指定。但是，对于预先存在的主题，我们可以增加分区的数量。让我们将chess-moves主题的分区号设置为3 ： $ docker run \\ --net=host \\ --rm confluentinc/cp-kafka:5.0.0 \\ bash -c \u0026#34;kafka-topics --alter --zookeeper localhost:32181 --topic chess-moves --partitions 3\u0026#34; WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected Adding partitions succeeded! 5.2. 分区键 在一个主题中，Kafka 使用分区键跨多个分区处理消息。一方面，生产者隐式使用它来将消息路由到其中一个分区。另一方面，每个消费者都可以从特定分区读取消息。 默认情况下，生产者将生成键的哈希值，后跟带有分区数的模数。然后，它会将消息发送到计算出的标识符所标识的分区。 让我们使用kafka-console-producer实用程序创建新的事件消息，但这次我们将记录两个玩家的动作： # kafka-console-producer --broker-list localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves \\ --property parse.key=true --property key.separator=: \u0026gt;{Player1: Rook, a1 -\u0026gt; a5} \u0026gt;{Player2: Bishop, g3 -\u0026gt; h4} \u0026gt;{Player1: Rook, a5 -\u0026gt; e5} \u0026gt;{Player2: Bishop, h4 -\u0026gt; g3} 现在，我们可以有两个消费者，一个从分区 1 读取，另一个从分区 2 读取： # kafka-console-consumer --bootstrap-server localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves --from-beginning \\ --property print.key=true --property print.value=true \\ --property key.separator=: \\ --partition 1 {Player2: Bishop, g3 -\u0026gt; h4} {Player2: Bishop, h4 -\u0026gt; g3} 我们可以看到 Player2 的所有移动都被记录到分区 1 中。以同样的方式，我们可以检查 Player1 的移动是否被记录到 partition-0 中。 6. 缩放 我们如何概念化主题和分区对于水平扩展至关重要。一方面，主题更像是数据的预定义分类。另一方面，分区是动态发生的数据的动态分类。 此外，我们可以在一个主题中配置多少个分区是有实际限制的。这是因为每个分区都映射到代理节点的文件系统中的一个目录。当我们增加分区数量时，我们也会增加操作系统上打开文件句柄的数量。 根据经验，Confluent 的专家建议将每个代理的分区数限制为100 x b x r，其中b是 Kafka 集群中代理的数量，r是复制因子。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_kafka_data_modeling/","tags":["Kafka"],"title":"使用 Apache Kafka 进行数据建模"},{"categories":["Spring Data","Spring Persistence"],"contents":"1. 概述 在本快速指南中，我们将重点介绍如何将 Spring Data API 与 Apache Ignite 平台集成。 要了解 Apache Ignite，请查看我们之前的指南。 2. Maven 设置 除了现有的依赖项，我们还必须启用 Spring Data 支持： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ignite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ignite-spring-data\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${ignite.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; ignite-spring-data工件可以从Maven Central下载。 3. 模型和存储库 为了演示集成，我们将构建一个应用程序，使用 Spring Data API将员工存储到 Ignite 的缓存中。 EmployeeDTO的 POJO将如下所示： public class EmployeeDTO implements Serializable { @QuerySqlField(index = true) private Integer id; @QuerySqlField(index = true) private String name; @QuerySqlField(index = true) private boolean isEmployed; // getters, setters } 在这里，@QuerySqlField注释允许使用 SQL 查询字段。 接下来，我们将创建存储库来持久化 Employee对象： @RepositoryConfig(cacheName = \u0026#34;demoCache\u0026#34;) public interface EmployeeRepository extends IgniteRepository\u0026lt;EmployeeDTO, Integer\u0026gt; { EmployeeDTO getEmployeeDTOById(Integer id); } **Apache Ignite 使用自己的IgniteRepository，它从 Spring Data 的CrudRepository扩展而来。**它还允许从 Spring Data 访问 SQL 网格。 这支持标准的 CRUD 方法，除了一些不需要 id 的方法。我们将在我们的测试部分更详细地了解原因。 ** @RepositoryConfig注释将EmployeeRepository映射到 Ignite 的demoCache。** 4. Spring配置 现在让我们创建我们的 Spring 配置类。 我们将使用 @EnableIgniteRepositories 注释来添加对 Ignite 存储库的支持： @Configuration @EnableIgniteRepositories public class SpringDataConfig { @Bean public Ignite igniteInstance() { IgniteConfiguration config = new IgniteConfiguration(); CacheConfiguration cache = new CacheConfiguration(\u0026#34;demoCache\u0026#34;); cache.setIndexedTypes(Integer.class, EmployeeDTO.class); config.setCacheConfiguration(cache); return Ignition.start(config); } } 在这里，igniteInstance() 方法创建Ignite实例并将其传递给IgniteRepositoryFactoryBean以便访问 Apache Ignite 集群。 我们还定义并设置了demoCache配置。*setIndexedTypes()*方法设置缓存的 SQL 模式。 5. 测试存储库 为了测试应用程序，让我们在应用程序上下文中注册SpringDataConfiguration并从中获取EmployeeRepository： AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.register(SpringDataConfig.class); context.refresh(); EmployeeRepository repository = context.getBean(EmployeeRepository.class); 然后，我们要创建EmployeeDTO实例并将其保存在缓存中： EmployeeDTO employeeDTO = new EmployeeDTO(); employeeDTO.setId(1); employeeDTO.setName(\u0026#34;John\u0026#34;); employeeDTO.setEmployed(true); repository.save(employeeDTO.getId(), employeeDTO); 这里我们使用了IgniteRepository的save (key, value)方法。原因是尚不支持**标准的CrudRepository save(entity)、save(entities)、delete(entity)操作。 *这背后的问题是CrudRepository.save()*方法生成的 ID 在集群中不是唯一的。 相反，我们必须使用 save *(key, value)、save(Map\u0026lt;ID, Entity\u0026gt; values)、deleteAll(Iterableids)*方法。 之后，我们可以使用 Spring Data 的*getEmployeeDTOById()*方法从缓存中获取员工对象： EmployeeDTO employee = repository.getEmployeeDTOById(employeeDTO.getId()); System.out.println(employee); 输出显示我们成功获取了初始对象： EmployeeDTO{id=1, name=\u0026#39;John\u0026#39;, isEmployed=true} 或者，我们可以使用IgniteCache API 检索相同的对象： IgniteCache\u0026lt;Integer, EmployeeDTO\u0026gt; cache = ignite.cache(\u0026#34;demoCache\u0026#34;); EmployeeDTO employeeDTO = cache.get(employeeId); 或者使用标准 SQL： SqlFieldsQuery sql = new SqlFieldsQuery( \u0026#34;select * from EmployeeDTO where isEmployed = \u0026#39;true\u0026#39;\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_ignite_spring_data/","tags":[],"title":"Apache Ignite 与 Spring Data"},{"categories":["Persistence"],"contents":"1. 简介 Apache Ignite 是一个以内存为中心的开源分布式平台。我们可以将它用作数据库、缓存系统或用于内存数据处理。 该平台使用内存作为存储层，因此具有令人印象深刻的性能。简单地说，这是目前生产使用中最快的原子数据处理平台之一。 2. 安装和设置 首先，请查看 入门页面 以获取初始设置和安装说明。 我们将要构建的应用程序的 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ignite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ignite-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${ignite.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ignite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ignite-indexing\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${ignite.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; ignite-core是项目的唯一强制依赖。由于我们还想与 SQL 交互，所以这里也ignite-indexing${ignite.version}是 Apache Ignite 的最新版本。 作为最后一步，我们启动 Ignite 节点： Ignite node started OK (id=53c77dea) Topology snapshot [ver=1, servers=1, clients=0, CPUs=4, offheap=1.2GB, heap=1.0GB] Data Regions Configured: ^-- default [initSize=256.0 MiB, maxSize=1.2 GiB, persistenceEnabled=false] 上面的控制台输出表明我们准备好了。 3. 内存架构 该平台基于持久内存架构。这使得能够在磁盘和内存中存储和处理数据。它通过有效利用集群的 RAM 资源来提高性能。 内存和磁盘中的数据具有相同的二进制表示。这意味着在从一层移动到另一层时无需额外转换数据。 持久内存架构分为称为页面的固定大小的块。页面存储在 Java 堆之外并组织在 RAM 中。它有一个唯一标识符：FullPageId。 页面使用PageMemory抽象与内存交互 。 它有助于读取、写入页面，还有助于分配页面 id。在内存中，Ignite 将页面与Memory Buffers相关联。 4. 内存页 一个页面可以有以下状态：  Unloaded – 内存中没有加载页面缓冲区 清除——页面缓冲区被加载并与磁盘上的数据同步 Durty – 页缓冲区保存的数据与磁盘中的数据不同 检查点脏——在第一个修改保存到磁盘之前，还有另一个修改开始。这里开始一个检查点，PageMemory为每个 Page 保留两个内存缓冲区。  **持久内存在本地分配一个称为Data Region的内存段。**默认情况下，它的容量为集群内存的 20%。多区域配置允许将可用数据保存在内存中。 该区域的最大容量是一个内存段。它是物理内存或连续字节数组。 为了避免内存碎片，一个页面包含多个键值条目。每个新条目都将添加到最佳页面。如果键值对大小超过页面的最大容量，Ignite 会将数据存储在多个页面中。相同的逻辑适用于更新数据。 SQL 和缓存索引存储在称为 B+ 树的结构中。缓存键按其键值排序。 5. 生命周期 每个 Ignite 节点都在单个 JVM 实例上运行。但是，可以配置为在单个 JVM 进程中运行多个 Ignite 节点。 让我们来看看生命周期事件类型：  BEFORE_NODE_START – 在 Ignite 节点启动之前 AFTER_NODE_START – 在 Ignite 节点启动后触发 BEFORE_NODE_STOP – 在启动节点停止之前 AFTER_NODE_STOP – Ignite 节点停止后  要启动默认的 Ignite 节点： Ignite ignite = Ignition.start(); 或者从配置文件： Ignite ignite = Ignition.start(\u0026#34;config/example-cache.xml\u0026#34;); 如果我们需要对初始化过程进行更多控制，还有另一种借助LifecycleBean接口的方法： public class CustomLifecycleBean implements LifecycleBean { @Override public void onLifecycleEvent(LifecycleEventType lifecycleEventType) throws IgniteException { if(lifecycleEventType == LifecycleEventType.AFTER_NODE_START) { // ...  } } } 在这里，我们可以使用生命周期事件类型在节点启动/停止之前或之后执行操作。 为此，我们将带有CustomLifecycleBean的配置实例传递给 start 方法： IgniteConfiguration configuration = new IgniteConfiguration(); configuration.setLifecycleBeans(new CustomLifecycleBean()); Ignite ignite = Ignition.start(configuration); 6. 内存数据网格 Ignite 数据网格是一种分布式键值存储，对于分区 HashMap非常熟悉。它是水平缩放的。这意味着我们添加更多的集群节点，更多的数据被缓存或存储在内存中。 作为缓存的附加层，它可以为 NoSql、RDMS 数据库等 3rd 方软件提供显着的性能提升。 6.1 缓存支持 数据访问 API 基于 JCache JSR 107 规范。 例如，让我们使用模板配置创建缓存： IgniteCache\u0026lt;Employee, Integer\u0026gt; cache = ignite.getOrCreateCache( \u0026#34;baeldingCache\u0026#34;); 让我们看看这里发生了什么以了解更多详细信息。首先，Ignite 找到缓存存储的内存区域。 然后，B+树索引Page会根据key hash code来定位。如果索引存在，就会定位到对应key的数据Page。 当索引为 NULL 时，平台使用给定的键创建新的数据条目。 接下来，让我们添加一些Employee对象： cache.put(1, new Employee(1, \u0026#34;John\u0026#34;, true)); cache.put(2, new Employee(2, \u0026#34;Anna\u0026#34;, false)); cache.put(3, new Employee(3, \u0026#34;George\u0026#34;, true)); 同样，持久内存将寻找缓存所属的内存区域。根据缓存键，索引页将位于 B+ 树结构中。 当索引页面不存在时，会请求一个新页面并将其添加到树中。 接下来，将数据页分配给索引页。 要从缓存中读取员工，我们只需使用键值： Employee employee = cache.get(1); 6.2. 流媒体支持 内存数据流为基于磁盘和文件系统的数据处理应用程序提供了另一种方法。Streaming API 将高负载数据流拆分为多个阶段并路由它们进行处理。 我们可以修改我们的示例并从文件中流式传输数据。首先，我们定义一个数据流送器： IgniteDataStreamer\u0026lt;Integer, Employee\u0026gt; streamer = ignite .dataStreamer(cache.getName()); 接下来，我们可以注册一个流转换器来将接收到的员工标记为已雇用： streamer.receiver(StreamTransformer.from((e, arg) -\u0026gt; { Employee employee = e.getValue(); employee.setEmployed(true); e.setValue(employee); return employee; })); 作为最后一步，我们遍历employees.txt文件行并将它们转换为 Java 对象： Path path = Paths.get(IgniteStream.class.getResource(\u0026#34;employees.txt\u0026#34;) .toURI()); Gson gson = new Gson(); Files.lines(path) .forEach(l -\u0026gt; streamer.addData( employee.getId(), gson.fromJson(l, Employee.class))); *使用*streamer.addData()将员工对象放入流中。 7. SQL 支持 该平台提供以内存为中心、容错的 SQL 数据库。 我们可以使用纯 SQL API 或 JDBC 进行连接。这里的 SQL 语法是 ANSI-99，因此支持查询中的所有标准聚合函数，DML，DDL 语言操作。 7.1 JDBC 为了更实用，让我们创建一个员工表并向其中添加一些数据。 为此，我们注册一个 JDBC 驱动程序并打开一个连接作为下一步： Class.forName(\u0026#34;org.apache.ignite.IgniteJdbcThinDriver\u0026#34;); Connection conn = DriverManager.getConnection(\u0026#34;jdbc:ignite:thin://127.0.0.1/\u0026#34;); 在标准 DDL 命令的帮助下，我们填充Employee表： sql.executeUpdate(\u0026#34;CREATE TABLE Employee (\u0026#34; + \u0026#34; id LONG PRIMARY KEY, name VARCHAR, isEmployed tinyint(1)) \u0026#34; + \u0026#34; WITH \\\u0026#34;template=replicated\\\u0026#34;\u0026#34;); 在 WITH 关键字之后，我们可以设置缓存配置模板。这里我们使用REPLICATED。默认情况下，模板模式为PARTITIONED。要指定数据的副本数，我们也可以在此处指定BACKUPS参数，默认为 0。 然后，让我们使用 INSERT DML 语句添加一些数据： PreparedStatement sql = conn.prepareStatement( \u0026#34;INSERT INTO Employee (id, name, isEmployed) VALUES (?, ?, ?)\u0026#34;); sql.setLong(1, 1); sql.setString(2, \u0026#34;James\u0026#34;); sql.setBoolean(3, true); sql.executeUpdate(); // add the rest 之后，我们选择记录： ResultSet rs = sql.executeQuery(\u0026#34;SELECT e.name, e.isEmployed \u0026#34; + \u0026#34; FROM Employee e \u0026#34; + \u0026#34; WHERE e.isEmployed = TRUE \u0026#34;) 7.2. 查询对象 还可以对缓存中存储的 Java 对象执行查询。Ignite 将 Java 对象视为单独的 SQL 记录： IgniteCache\u0026lt;Integer, Employee\u0026gt; cache = ignite.cache(\u0026#34;demoCache\u0026#34;); SqlFieldsQuery sql = new SqlFieldsQuery( \u0026#34;select name from Employee where isEmployed = \u0026#39;true\u0026#39;\u0026#34;); QueryCursor\u0026lt;List\u0026lt;?\u0026gt;\u0026gt; cursor = cache.query(sql); for (List\u0026lt;?\u0026gt; row : cursor) { // do something with the row } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_ignite/","tags":[],"title":"Apache Ignite 指南"},{"categories":["HTTP Client-Side"],"contents":"1. 概述 Apache HttpClient是一个流行的 Java 库，它提供了高效且功能丰富的包，实现了最新 HTTP 标准的客户端。该库专为扩展而设计，同时为基本 HTTP 方法提供强大的支持。 在本教程中，我们将了解 Apache HttpClient API 设计。我们将解释HttpClient和CloseableHttpClient之间的区别。此外，我们将检查如何使用HttpClients或HttpClientBuilder创建**CloseableHttpClient实例。 最后，我们将推荐我们应该在自定义代码中使用哪些上述 API。此外，我们将查看哪些 API 类实现了Closeable接口，因此需要我们关闭它们的实例以释放资源。 2. API 设计 让我们先来看看 API 是如何设计的，重点是它的高级类和接口。在下面的类图中，我们将展示经典执行 HTTP 请求和处理 HTTP 响应所需的 API 的一部分： 此外，Apache HttpClient API 还支持异步HTTP 请求/响应交换，以及使用RxJava的反应式消息交换。 3. HttpClient与CloseableHttpClient HttpClient是一个高级接口，代表了 HTTP 请求执行的基本契约。它对请求执行过程没有任何限制。此外，它还保留了状态管理、身份验证和重定向到各个客户端实现等细节。 我们可以将任何客户端实现转换为HttpClient接口。因此，我们可以使用它通过默认的客户端实现来执行基本的 HTTP 请求： HttpClient httpClient = HttpClients.createDefault(); HttpGet httpGet = new HttpGet(serviceUrl); HttpResponse response = httpClient.execute(httpGet); assertThat(response.getCode()).isEqualTo(HttpStatus.SC_OK); 但是，上面的代码会导致SonarQube出现阻塞问题。原因是默认客户端实现返回一个Closeable HttpClient的实例，它需要关闭。 CloseableHttpClient是一个抽象类，表示HttpClient接口的****基本实现。但是，它也实现了Closeable接口。因此，我们应该在使用后关闭它的所有实例。我们可以使用try-with-resources或在finally子句中调用close方法来关闭它们： try (CloseableHttpClient httpClient = HttpClients.createDefault()) { HttpGet httpGet = new HttpGet(serviceUrl); HttpResponse response = httpClient.execute(httpGet); assertThat(response.getCode()).isEqualTo(HttpStatus.SC_OK); } 因此，在我们的自定义代码中，我们应该使用CloseableHttpClient类，而不是HttpClient接口。 4. HttpClients与HttpClientBuilder 在上面的示例中，我们使用HttpClients类中的静态方法来获取默认客户端实现。HttpClients是一个实用类，包含用于创建CloseableHttpClient实例的工厂方法： CloseableHttpClient httpClient = HttpClients.createDefault(); 我们可以使用HttpClientBuilder类实现相同的目的*。HttpClientBuilder是**用于创建CloseableHttpClient*实例的Builder 设计模式**的实现： CloseableHttpClient httpClient = HttpClientBuilder.create().build(); 在内部，HttpClients使用HttpClientBuilder创建客户端实现实例。因此，我们应该更喜欢在我们的自定义代码中使用*HttpClients 。*鉴于它是一个更高级别的类，它的内部结构可能会随着新版本的发布而改变。 5. 资源管理 我们需要在CloseableHttpClient实例超出范围后关闭它们的原因是关闭关联的连接管理器。此外，我们还应该使用CloseableHttpResponse以确保正确释放系统资源。 5.1 CloseableHttpResponse CloseableHttpResponse是一个实现ClassicHttpResponse接口的类。但是，ClassicHttpResponse还扩展了HttpResponse、HttpEntityContainer和Closeable接口。 底层HTTP 连接由响应对象持有，以允许直接从网络套接字流式传输响应内容。因此，我们应该在自定义代码中使用CloseableHttpResponse类而不是HttpResponse接口。我们还需要确保在使用响应后调用close方法： try (CloseableHttpClient httpClient = HttpClientBuilder.create().build()) { HttpGet httpGet = new HttpGet(serviceUrl); try (CloseableHttpResponse response = httpClient.execute(httpGet)) { HttpEntity entity = response.getEntity(); EntityUtils.consume(entity); } } 我们应该注意到，当响应内容没有被完全消耗时，底层连接不能被安全地重用。在这种情况下，连接将被连接管理器关闭并丢弃。 5.2. 重用客户端 关闭CloseableHttpClient实例并为每个请求创建一个新实例可能是一项昂贵的操作。相反，我们可以重用CloseableHttpClient的单个实例来发送多个请求： try (CloseableHttpClient httpClient = HttpClientBuilder.create().build()) { HttpGet httpGetOne = new HttpGet(serviceOneUrl); try (CloseableHttpResponse responseOne = httpClient.execute(httpGetOne)) { HttpEntity entityOne = responseOne.getEntity(); EntityUtils.consume(entityOne); assertThat(responseOne.getCode()).isEqualTo(HttpStatus.SC_OK); } HttpGet httpGetTwo = new HttpGet(serviceTwoUrl); try (CloseableHttpResponse responseTwo = httpClient.execute(httpGetTwo)) { HttpEntity entityTwo = responseTwo.getEntity(); EntityUtils.consume(entityTwo); assertThat(responseTwo.getCode()).isEqualTo(HttpStatus.SC_OK); } } 因此，我们避免关闭内部关联的连接管理器并创建一个新的。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_vs_closeablehttpclient/","tags":["Apache HttpClient"],"title":"Apache HttpClient 与 CloseableHttpClient"},{"categories":["HTTP Client-Side","Security"],"contents":"1. 简介 Apache HttpClient 是一个用于与 HTTP 服务器通信的低级、轻量级客户端 HTTP 库。在本教程中，我们将学习如何在使用HttpClient时配置支持的传输层安全 (TLS) 版本。我们将从概述客户端和服务器之间的 TLS 版本协商如何工作开始。之后，我们将了解在使用 HttpClient 时配置支持的 TLS 版本的三种不同方式。 2. TLS版本协商 TLS 是一种互联网协议，可在两方之间提供安全、可信的通信。它封装了 HTTP 等应用层协议。自 1999 年首次发布以来，TLS 协议已经进行了多次修订。**因此，客户端和服务器首先就建立新连接时将使用哪个版本的 TLS 达成一致非常重要。**客户端和服务器交换 hello 消息后就 TLS 版本达成一致：  客户端发送支持的 TLS 版本列表。 服务器选择一个并在响应中包含所选版本。 客户端和服务器使用所选版本继续连接设置。  由于存在降级攻击的风险，正确配置 Web 客户端支持的 TLS 版本非常重要。请注意，为了使用最新版本的 TLS (TLS 1.3)，我们必须使用 Java 11 或更高版本。 3. 静态设置 TLS 版本 3.1 SSLConnectionSocketFactory 让我们使用HttpClients #custom构建器方法公开的HttpClientBuilder 来自定义我们的HTTPClient配置。此构建器模式允许我们传入我们自己的SSLConnectionSocketFactory，它将使用所需的支持 TLS 版本集进行实例化： SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( SSLContexts.createDefault(), new String[] { \u0026#34;TLSv1.2\u0026#34;, \u0026#34;TLSv1.3\u0026#34; }, null, SSLConnectionSocketFactory.getDefaultHostnameVerifier()); CloseableHttpClient httpClient = HttpClients.custom().setSSLSocketFactory(sslsf).build(); 返回的Httpclient对象现在可以执行 HTTP 请求。通过在SSLConnectionSocketFactory构造函数中显式设置支持的协议，客户端将仅支持通过 TLS 1.2 或 TLS 1.3 进行通信。请注意，在 4.3 之前的 Apache HttpClient 版本中，该类称为SSLSocketFactory。 3.2. Java 运行时参数 或者，我们可以使用 Java 的https.protocols系统属性配置支持的 TLS 版本。这种方法可以避免将值硬编码到应用程序代码中。相反，我们将配置HttpClient以在设置连接时使用系统属性。HttpClient API 提供了两种方法来做到这一点。第一个是通过HttpClients#createSystem： CloseableHttpClient httpClient = HttpClients.createSystem(); 如果需要更多的客户端配置，我们可以使用 builder 方法来代替： CloseableHttpClient httpClient = HttpClients.custom().useSystemProperties().build(); 这两种方法都告诉HttpClient在连接配置期间使用系统属性。这允许我们在应用程序运行时使用命令行参数设置所需的 TLS 版本。例如： $ java -Dhttps.protocols=TLSv1.1,TLSv1.2,TLSv1.3 -jar webClient.jar 4. 动态设置TLS版本 还可以根据主机名和端口等连接详细信息设置 TLS 版本。我们将扩展SSLConnectionSocketFactory并覆盖prepareSocket方法。客户端在发起新连接之前调用*prepareSocket方法。***这将让我们决定在每个连接的基础上使用哪些 TLS 协议。**也可以启用对旧 TLS 版本的支持，但前提是远程主机具有特定的子域： SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(SSLContexts.createDefault()){ @Override protected void prepareSocket(SSLSocket socket) { String hostname = socket.getInetAddress().getHostName(); if (hostname.endsWith(\u0026#34;internal.system.com\u0026#34;)){ socket.setEnabledProtocols(new String[] { \u0026#34;TLSv1\u0026#34;, \u0026#34;TLSv1.1\u0026#34;, \u0026#34;TLSv1.2\u0026#34;, \u0026#34;TLSv1.3\u0026#34; }); } else { socket.setEnabledProtocols(new String[] {\u0026#34;TLSv1.3\u0026#34;}); } } };\u0026lt;br /\u0026gt; CloseableHttpClient httpClient = HttpClients.custom().setSSLSocketFactory(sslsf).build(); 在上面的示例中，prepareSocket方法首先获取SSLSocket将连接到的远程主机名。**然后使用主机名来确定要启用的 TLS 协议。**现在，我们的 HTTP 客户端将对每个请求强制执行 TLS 1.3，除非目标主机名的格式为 * .internal.example.com。通过在创建新SSLSocket之前插入自定义逻辑的能力，我们的应用程序现在可以自定义 TLS 通信细节。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_tls/","tags":[],"title":"如何在 Apache HttpClient 中设置 TLS 版本"},{"categories":["HTTP Client-Side"],"contents":"1. 简介 HttpClient是 Apache HttpComponents 项目的一部分，该项目提供了一个专注于 HTTP 和相关协议的低级 Java 组件工具集。HttpClient 最基本的功能是执行 HTTP 方法。 在这个简短的教程中，我们将讨论向HttpClient请求添加参数。我们将学习如何将UriBuilder与 String 名称-值对以及NameValuePair一起使用。同样，我们将看到如何使用UrlEncodedFormEntity传递参数。 2. 使用UriBuilder为HttpClient请求添加参数 UriBuilder帮助我们通过构建器模式轻松创建 URI 和添加参数。我们可以使用字符串名称-值对添加参数，或者为此目的使用NameValuePair的类。 在此示例中，最终到达 URL 应如下所示： https://example.com?param1=value1\u0026amp;param2=value2 让我们看看如何使用字符串名称-值对： public CloseableHttpResponse sendHttpRequest() { HttpGet httpGet = new HttpGet(\u0026#34;https://example.com\u0026#34;); URI uri = new URIBuilder(httpGet.getURI()) .addParameter(\u0026#34;param1\u0026#34;, \u0026#34;value1\u0026#34;) .addParameter(\u0026#34;param2\u0026#34;, \u0026#34;value2\u0026#34;) .build(); ((HttpRequestBase) httpGet).setURI(uri); CloseableHttpResponse response = client.execute(httpGet); client.close(); } 此外，我们可以使用HttpClient请求的NameValuePair列表： public CloseableHttpResponse sendHttpRequest() { List nameValuePairs = new ArrayList(); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param1\u0026#34;, \u0026#34;value1\u0026#34;)); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param2\u0026#34;, \u0026#34;value2\u0026#34;)); HttpGet httpGet = new HttpGet(\u0026#34;https://example.com\u0026#34;); URI uri = new URIBuilder(httpGet.getURI()) .addParameters(nameValuePairs) .build(); ((HttpRequestBase) httpGet).setURI(uri); CloseableHttpResponse response = client.execute(httpGet); client.close(); } 类似地，UriBuilder可用于向其他 HttpClient 请求方法添加参数。 3. 使用UrlEncodedFormEntity为HttpClient请求添加参数 另一种方法是利用UrlEncodedFormEntity： public CloseableHttpResponse sendHttpRequest() { List nameValuePairs = new ArrayList(); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param1\u0026#34;, \u0026#34;value1\u0026#34;)); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param2\u0026#34;, \u0026#34;value2\u0026#34;)); HttpPost httpPost = new HttpPost(\u0026#34;https://example.com\u0026#34;); httpPost.setEntity(new UrlEncodedFormEntity(nameValuePairs, StandardCharsets.UTF_8)); CloseableHttpResponse response = client.execute(httpPost); client.close(); } 请注意，** UrlEncodedFormEntity不能用于 GET 请求**，因为 GET 请求没有可以包含实体的主体。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_parameters/","tags":["Apache HttpClient"],"title":"向 Apache HttpClient 请求添加参数"},{"categories":["HTTP Client-Side"],"contents":"1. 概述 在本文中，我们将展示如何使用HttpClient扩展 URL 。 一个简单的例子是原始 URL 被缩短了一次- 被诸如bit.ly之类的服务所缩短。 一个更复杂的例子是，当URL 被不同的此类服务多次缩短时，需要多次传递才能到达原始的完整 URL。 如果您想更深入地挖掘并学习可以使用 HttpClient 做的其他很酷的事情 - 前往**主要的 HttpClient 教程 \u0026ldquo;你可以用 HttpClient 4 做一些很酷的基本和更高级的事情\u0026rdquo;**。 2. 展开 URL 让我们从简单的开始，扩展一个仅通过一次缩短 URL 服务的 URL。 我们首先需要的是一个不会自动跟随重定向的 HTTP 客户端： CloseableHttpClient client = HttpClientBuilder.create().disableRedirectHandling().build(); 这是必要的，因为我们需要手动拦截重定向响应并从中提取信息。 我们首先向缩短的 URL 发送请求——我们得到的响应将是301 Moved Permanently。 然后，我们需要提取指向下一个的Location标头，在本例中是最终 URL： public String expandSingleLevel(String url) throws IOException { HttpHead request = null; try { request = new HttpHead(url); HttpResponse httpResponse = client.execute(request); int statusCode = httpResponse.getStatusLine().getStatusCode(); if (statusCode != 301 \u0026amp;\u0026amp; statusCode != 302) { return url; } Header[] headers = httpResponse.getHeaders(HttpHeaders.LOCATION); Preconditions.checkState(headers.length == 1); String newUrl = headers[0].getValue(); return newUrl; } catch (IllegalArgumentException uriEx) { return url; } finally { if (request != null) { request.releaseConnection(); } } } 最后，使用“未缩短”的 URL 进行简单的实时测试： @Test public final void givenShortenedOnce_whenUrlIsExpanded_thenCorrectResult() throws IOException { final String expectedResult = \u0026#34;https://www.codingman.com/rest-versioning\u0026#34;; final String actualResult = expandSingleLevel(\u0026#34;http://bit.ly/3LScTri\u0026#34;); assertThat(actualResult, equalTo(expectedResult)); } 3. 处理多个 URL 短 URL 的问题在于，它们可能会被完全不同的服务**多次缩短。**扩展这样的 URL 需要多次传递才能到达原始 URL。 我们将应用之前定义的expandSingleLevel原始操作来简单地遍历所有中间 URL 并到达最终目标： public String expand(String urlArg) throws IOException { String originalUrl = urlArg; String newUrl = expandSingleLevel(originalUrl); while (!originalUrl.equals(newUrl)) { originalUrl = newUrl; newUrl = expandSingleLevel(originalUrl); } return newUrl; } 现在，通过扩展多级 URL 的新机制，让我们定义一个测试并使其工作： @Test public final void givenShortenedMultiple_whenUrlIsExpanded_thenCorrectResult() throws IOException { final String expectedResult = \u0026#34;https://www.codingman.com/rest-versioning\u0026#34;; final String actualResult = expand(\u0026#34;http://t.co/e4rDDbnzmk\u0026#34;); assertThat(actualResult, equalTo(expectedResult)); } 这一次，短 URL—— http://t.co/e4rDDbnzmk——实际上被缩短了两次——一次通过bit.ly，第二次通过t.co服务——被正确地扩展为原始 URL。 4. 检测重定向循环 最后，某些 URL 无法扩展，因为它们形成了重定向循环。这种类型的问题会被HttpClient检测到，但是由于我们关闭了重定向的自动跟踪，它不再这样做了。 URL 扩展机制的最后一步是检测重定向循环，并在发生此类循环时快速失败。 为了使其生效，我们需要从之前定义的expandSingleLevel方法中获取一些附加信息——主要是，我们还需要返回响应的状态码以及 URL。 由于 java 不支持多个返回值，我们将把信息包装在org.apache.commons.lang3.tuple.Pair对象中——该方法的新签名现在将是： public Pair\u0026lt;Integer, String\u0026gt; expandSingleLevelSafe(String url) throws IOException { 最后，让我们在主扩展机制中包含重定向循环检测： public String expandSafe(String urlArg) throws IOException { String originalUrl = urlArg; String newUrl = expandSingleLevelSafe(originalUrl).getRight(); List\u0026lt;String\u0026gt; alreadyVisited = Lists.newArrayList(originalUrl, newUrl); while (!originalUrl.equals(newUrl)) { originalUrl = newUrl; Pair\u0026lt;Integer, String\u0026gt; statusAndUrl = expandSingleLevelSafe(originalUrl); newUrl = statusAndUrl.getRight(); boolean isRedirect = statusAndUrl.getLeft() == 301 || statusAndUrl.getLeft() == 302; if (isRedirect \u0026amp;\u0026amp; alreadyVisited.contains(newUrl)) { throw new IllegalStateException(\u0026#34;Likely a redirect loop\u0026#34;); } alreadyVisited.add(newUrl); } return newUrl; } 就是这样*——expandSafe*机制能够通过任意数量的 URL 缩短服务扩展 URL，同时在重定向循环中快速正确地失败。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_expand_url/","tags":["Apache HttpClient"],"title":"使用 Apache HttpClient 展开缩短的 URL"},{"categories":["HTTP Client-Side"],"contents":"1. 概述 在本教程中，我们将展示如何在**Apache 的 HttpClient**中启用日志记录。此外，我们将解释如何在库中实现日志记录。之后，我们将展示如何启用不同级别的日志记录。 2. 日志实现 HttpClient 库提供了高效、最新且功能丰富的 HTTP 协议实现客户端站点。 事实上，作为一个库，HttpClient 并不强制实现日志记录。为此，4.5 版提供了带有Commons Logging的日志。同样，最新版本 5.1 使用SLF4J提供的日志外观。两个版本都使用层次结构模式来匹配记录器及其配置。 因此，可以为单个类或与相同功能相关的所有类设置记录器。 3. 日志类型 让我们看一下库定义的日志级别。我们可以区分 3 种类型的日志：  上下文日志——记录有关 HttpClient 的所有内部操作的信息。它还包含电线和标题日志。 线路日志记录——仅记录传输到服务器和从服务器传输的数据 标头日志记录——仅记录 HTTP 标头  在 4.5 版本中，对应的包是org.apache.http.impl.client和org.apache.http.wire、org.apache.http.headers。 因此，在 5.1 版中，有包org.apache.hc.client5.http、org.apache.hc.client5.http.wire和 org.apache.hc.client5.http.headers。 4. Log4j 配置 让我们看看如何启用两个版本的登录。我们的目标是在两个版本中实现相同的灵活性。在 4.1 版中，我们会将日志重定向到 SLF4j。因此，可以使用不同的日志记录框架。 4.1 4.5版配置 让我们添加httpclient依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.8\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;commons-logging\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;commons-logging\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 我们将使用jul-to-slf4j将日志重定向到 SLF4J。因此我们排除了 commons-logging。然后让我们在 JUL 和 SLF4J 之间的桥上添加一个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jul-to-slf4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.26\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 因为 SLF4J 只是一个门面，我们需要一个绑定。在我们的示例中，我们将使用logback： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在让我们创建ApacheHttpClientUnitTest类： public class ApacheHttpClientUnitTest { private final Logger logger = LoggerFactory.getLogger(this.getClass()); public static final String DUMMY_URL = \u0026#34;https://postman-echo.com/get\u0026#34;; @Test public void whenUseApacheHttpClient_thenCorrect() throws IOException { HttpGet request = new HttpGet(DUMMY_URL); try (CloseableHttpClient client = HttpClients.createDefault(); CloseableHttpResponse response = client.execute(request)) { HttpEntity entity = response.getEntity(); logger.debug(\u0026#34;Response -\u0026gt; {}\u0026#34;, EntityUtils.toString(entity)); } } } 测试获取一个虚拟网页并将内容打印到日志中。 现在让我们用我们的logback.xml文件定义一个记录器配置： \u0026lt;configuration debug=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender name=\u0026#34;stdout\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%date [%level] %logger - %msg %n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;com.codingman.httpclient.readresponsebodystring\u0026#34; level=\u0026#34;debug\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.apache.http\u0026#34; level=\u0026#34;debug\u0026#34;/\u0026gt; \u0026lt;root level=\u0026#34;WARN\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;stdout\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 运行我们的测试后，可以在控制台中找到所有 HttpClient 的日志： ... 2021-06-19 22:24:45,378 [DEBUG] org.apache.http.impl.execchain.MainClientExec - Executing request GET /get HTTP/1.1 2021-06-19 22:24:45,378 [DEBUG] org.apache.http.impl.execchain.MainClientExec - Target auth state: UNCHALLENGED 2021-06-19 22:24:45,379 [DEBUG] org.apache.http.impl.execchain.MainClientExec - Proxy auth state: UNCHALLENGED 2021-06-19 22:24:45,382 [DEBUG] org.apache.http.headers - http-outgoing-0 \u0026gt;\u0026gt; GET /get HTTP/1.1 ... 4.2. 5.1版本配置 现在让我们看看更高版本。**它包含重新设计的日志记录。因此，它使用 SLF4J 而不是 Commons Logging。**因此，记录器外观的绑定是唯一的附加依赖项。因此，我们将像第一个示例一样使用logback-classic 。 让我们添加httpclient5依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents.client5\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 让我们添加一个与上一个示例类似的测试： public class ApacheHttpClient5UnitTest { private final Logger logger = LoggerFactory.getLogger(this.getClass()); public static final String DUMMY_URL = \u0026#34;https://postman-echo.com/get\u0026#34;; @Test public void whenUseApacheHttpClient_thenCorrect() throws IOException, ParseException { HttpGet request = new HttpGet(DUMMY_URL); try (CloseableHttpClient client = HttpClients.createDefault(); CloseableHttpResponse response = client.execute(request)) { HttpEntity entity = response.getEntity(); logger.debug(\u0026#34;Response -\u0026gt; {}\u0026#34;, EntityUtils.toString(entity)); } } } 接下来，我们需要在logback.xml文件中添加一个记录器： \u0026lt;configuration debug=\u0026#34;false\u0026#34;\u0026gt; ... \u0026lt;logger name=\u0026#34;org.apache.hc.client5.http\u0026#34; level=\u0026#34;debug\u0026#34;/\u0026gt; ... \u0026lt;/configuration\u0026gt; 让我们运行测试类ApacheHttpClient5UnitTest并检查输出。它类似于旧版本： ... 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.classic.InternalHttpClient - ep-0000000000 endpoint connected 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.classic.MainClientExec - ex-0000000001 executing GET /get HTTP/1.1 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.classic.InternalHttpClient - ep-0000000000 start execution ex-0000000001 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager - ep-0000000000 executing exchange ex-0000000001 over http-outgoing-0 2021-06-19 22:27:16,960 [DEBUG] org.apache.hc.client5.http.headers - http-outgoing-0 \u0026gt;\u0026gt; GET /get HTTP/1.1 ... \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_enable_logging/","tags":["Apache HttpClient"],"title":"为 Apache HttpClient 启用日志记录"},{"categories":["Persistence"],"contents":"1. 概述 Apache Geode是一个分布式内存数据网格，支持缓存和数据计算。 在本教程中，我们将介绍 Geode 的关键概念并使用其 Java 客户端运行一些代码示例。 2. 设置 首先，我们需要下载并安装 Apache Geode 并设置gfsh环境。为此，我们可以按照Geode 官方指南中的说明进行操作。 其次，本教程将创建一些文件系统工件。因此，我们可以通过创建一个临时目录并从那里启动东西来隔离它们。 2.1 安装和配置 从我们的临时目录中，我们需要启动一个Locator实例： gfsh\u0026gt; start locator --name=locator --bind-address=localhost **定位器 负责 Geode Cluster的不同成员之间的协调，**我们可以通过 JMX 进一步管理它。 接下来，让我们启动一个Server实例来托管一个或多个数据Region： gfsh\u0026gt; start server --name=server1 --server-port=0 我们将*\u0026ndash;server-port选项设置为 0，以便 Geode 选择任何可用端口。虽然如果我们忽略它，服务器将使用默认端口 40404。**服务器是集群的可配置成员，作为长期进程运行并负责管理数据区域***。 最后，我们需要一个 Region： gfsh\u0026gt; create region --name=demo --type=REPLICATE 该区域最终是我们存储数据的地方。 2.2. 确认 在我们继续之前，让我们确保一切正常。 首先，让我们检查一下我们是否有我们的 Server和我们的 Locator： gfsh\u0026gt; list members Name | Id ------- | ---------------------------------------------------------- server1 | 192.168.0.105(server1:6119)\u0026lt;v1\u0026gt;:1024 locator | 127.0.0.1(locator:5996:locator)\u0026lt;ec\u0026gt;\u0026lt;v0\u0026gt;:1024 [Coordinator] 接下来，我们有我们的 Region： gfsh\u0026gt; describe region --name=demo .......................................................... Name : demo Data Policy : replicate Hosting Members : server1 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ----------- | --------------- Region | data-policy | REPLICATE | size | 0 | scope | distributed-ack 此外，我们的临时目录下的文件系统上应该有一些目录，称为“locator”和“server1”。 有了这个输出，我们知道我们已经准备好继续前进了。 3. Maven依赖 现在我们有了一个正在运行的 Geode，让我们开始查看客户端代码。 要在我们的 Java 代码中使用 Geode，我们需要将 Apache Geode Java 客户端库添加到我们的 pom中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.geode\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geode-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 让我们从在几个区域中简单地存储和检索一些数据开始。 4. 简单的存储和检索 让我们演示如何存储单个值、批量值以及自定义对象。 要开始在我们的“demo”区域中存储数据，让我们使用定位器连接到它： @Before public void connect() { this.cache = new ClientCacheFactory() .addPoolLocator(\u0026#34;localhost\u0026#34;, 10334) .create(); this.region = cache.\u0026lt;String, String\u0026gt; createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY) .create(\u0026#34;demo\u0026#34;); } 4.1 保存单个值 现在，我们可以简单地在我们的区域中存储和检索数据： @Test public void whenSendMessageToRegion_thenMessageSavedSuccessfully() { this.region.put(\u0026#34;A\u0026#34;, \u0026#34;Hello\u0026#34;); this.region.put(\u0026#34;B\u0026#34;, \u0026#34;demo\u0026#34;); assertEquals(\u0026#34;Hello\u0026#34;, region.get(\u0026#34;A\u0026#34;)); assertEquals(\u0026#34;demo\u0026#34;, region.get(\u0026#34;B\u0026#34;)); } 4.2. 一次保存多个值 我们还可以一次保存多个值，例如在尝试减少网络延迟时： @Test public void whenPutMultipleValuesAtOnce_thenValuesSavedSuccessfully() { Supplier\u0026lt;Stream\u0026lt;String\u0026gt;\u0026gt; keys = () -\u0026gt; Stream.of(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;); Map\u0026lt;String, String\u0026gt; values = keys.get() .collect(Collectors.toMap(Function.identity(), String::toLowerCase)); this.region.putAll(values); keys.get() .forEach(k -\u0026gt; assertEquals(k.toLowerCase(), this.region.get(k))); } 4.3. 保存自定义对象 字符串很有用，但我们迟早需要存储自定义对象。 假设我们有一个要使用以下键类型存储的客户记录： public class CustomerKey implements Serializable { private long id; private String country; // getters and setters  // equals and hashcode } 以及以下值类型： public class Customer implements Serializable { private CustomerKey key; private String firstName; private String lastName; private Integer age; // getters and setters } 有几个额外的步骤可以存储这些： 首先，**他们应该实现 Serializable。**虽然这不是一个严格的要求，但通过使它们可序列化，Geode 可以更健壮地存储它们。 其次，它们需要位于我们应用程序的类路径以及 Geode Server的类路径中。 为了让它们进入服务器的类路径，让我们将它们打包，比如使用 mvn clean package。 然后我们可以在新的启动服务器命令中引用生成的 jar ： gfsh\u0026gt; stop server --name=server1 gfsh\u0026gt; start server --name=server1 --classpath=../lib/apache-geode-1.0-SNAPSHOT.jar --server-port=0 同样，我们必须从临时目录运行这些命令。 最后，让我们使用与创建“demo”区域相同的命令在服务器上创建一个名为“demo-customers”的新区域： gfsh\u0026gt; create region --name=demo-customers --type=REPLICATE 在代码中，我们将像以前一样访问定位器，指定自定义类型： @Before public void connect() { // ... connect through the locator  this.customerRegion = this.cache.\u0026lt;CustomerKey, Customer\u0026gt; createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY) .create(\u0026#34;demo-customers\u0026#34;); } 然后，我们可以像以前一样存储我们的客户： @Test public void whenPutCustomKey_thenValuesSavedSuccessfully() { CustomerKey key = new CustomerKey(123); Customer customer = new Customer(key, \u0026#34;William\u0026#34;, \u0026#34;Russell\u0026#34;, 35); this.customerRegion.put(key, customer); Customer storedCustomer = this.customerRegion.get(key); assertEquals(\u0026#34;William\u0026#34;, storedCustomer.getFirstName()); assertEquals(\u0026#34;Russell\u0026#34;, storedCustomer.getLastName()); } 5. 区域类型 对于大多数环境，我们将拥有多个副本或多个分区，具体取决于我们的读写吞吐量要求。 到目前为止，我们已经使用了内存中的复制区域。让我们仔细看看。 5.1 复制区域 顾名思义，**复制区域在多个服务器上维护其数据的副本。**让我们测试一下。 从工作目录中的gfsh控制台，让我们再向集群添加一个名为server2的**服务器： gfsh\u0026gt; start server --name=server2 --classpath=../lib/apache-geode-1.0-SNAPSHOT.jar --server-port=0 请记住，当我们制作“demo”时，我们使用了*–type=REPLICATE*。因此，Geode 会自动将我们的数据复制到新服务器。 让我们通过停止server1 来验证这一点： gfsh\u0026gt; stop server --name=server1 然后，让我们对“demo”区域执行快速查询。 如果数据复制成功，我们将返回结果： gfsh\u0026gt; query --query=\u0026#39;select e.key from /demo.entries e\u0026#39; Result : true Limit : 100 Rows : 5 Result ------ C B A E D 所以，看起来复制成功了！ 向我们的区域添加副本可提高数据可用性。而且，因为不止一台服务器可以响应查询，我们也将获得更高的读取吞吐量。 但是，*如果他们俩都崩溃了怎么办？由于这些是内存区域，因此数据将丢失。***为此，我们可以改为使用 –type=REPLICATE_PERSISTENT，它还在复制时将数据存储在磁盘上。 5.2. 分区区域 对于更大的数据集，我们可以通过配置 Geode 将一个区域拆分为单独的分区或存储桶来更好地扩展系统。 让我们创建一个名为“demo-partitioned”的分区区域： gfsh\u0026gt; create region --name=demo-partitioned --type=PARTITION 添加一些数据： gfsh\u0026gt; put --region=demo-partitioned --key=\u0026#34;1\u0026#34; --value=\u0026#34;one\u0026#34; gfsh\u0026gt; put --region=demo-partitioned --key=\u0026#34;2\u0026#34; --value=\u0026#34;two\u0026#34; gfsh\u0026gt; put --region=demo-partitioned --key=\u0026#34;3\u0026#34; --value=\u0026#34;three\u0026#34; 并快速验证： gfsh\u0026gt; query --query=\u0026#39;select e.key, e.value from /demo-partitioned.entries e\u0026#39; Result : true Limit : 100 Rows : 3 key | value --- | ----- 2 | two 1 | one 3 | three 然后，为了验证数据是否已分区，让我们再次停止server1并重新查询： gfsh\u0026gt; stop server --name=server1 gfsh\u0026gt; query --query=\u0026#39;select e.key, e.value from /demo-partitioned.entries e\u0026#39; Result : true Limit : 100 Rows : 1 key | value --- | ----- 2 | two 这次我们只取回了一些数据条目，因为那台服务器只有一个数据分区，所以当 server1掉线时，它的数据也丢失了。 **但是如果我们需要分区和冗余呢？**Geode 还支持许多其他类型。以下三个很方便：  PARTITION_REDUNDANT在集群的不同成员之间分区 和复制我们的数据 PARTITION_PERSISTENT像**PARTITION 一样对数据进行分区，但是到磁盘，并且 PARTITION_REDUNDANT_PERSISTENT为我们提供了所有三种行为。  6.对象查询语言 Geode 还支持对象查询语言或 OQL，它比简单的键查找功能更强大。这有点像 SQL。 对于这个例子，让我们使用我们之前构建的“demo-customer”区域。 如果我们再添加几个客户： Map\u0026lt;CustomerKey, Customer\u0026gt; data = new HashMap\u0026lt;\u0026gt;(); data.put(new CustomerKey(1), new Customer(\u0026#34;Gheorge\u0026#34;, \u0026#34;Manuc\u0026#34;, 36)); data.put(new CustomerKey(2), new Customer(\u0026#34;Allan\u0026#34;, \u0026#34;McDowell\u0026#34;, 43)); this.customerRegion.putAll(data); 然后我们可以使用 QueryService查找名字为“Allan”的客户： QueryService queryService = this.cache.getQueryService(); String query = \u0026#34;select * from /demo-customers c where c.firstName = \u0026#39;Allan\u0026#39;\u0026#34;; SelectResults\u0026lt;Customer\u0026gt; results = (SelectResults\u0026lt;Customer\u0026gt;) queryService.newQuery(query).execute(); assertEquals(1, results.size()); 7. 功能 内存数据网格更强大的概念之一是“将计算应用于数据”的想法。 简而言之，由于 Geode 是纯 Java，我们不仅可以轻松发送数据，还可以轻松地对这些数据执行逻辑。 这可能会让我们想起 PL-SQL 或 Transact-SQL 等 SQL 扩展的想法。 7.1 定义函数 为了给 Geode 定义一个工作单元，我们实现了 Geode 的 Function接口。 例如，假设我们需要将所有客户的姓名都更改为大写。 我们可以只实现Function，而不是查询数据并让我们的应用程序完成工作： public class UpperCaseNames implements Function\u0026lt;Boolean\u0026gt; { @Override public void execute(FunctionContext\u0026lt;Boolean\u0026gt; context) { RegionFunctionContext regionContext = (RegionFunctionContext) context; Region\u0026lt;CustomerKey, Customer\u0026gt; region = regionContext.getDataSet(); for ( Map.Entry\u0026lt;CustomerKey, Customer\u0026gt; entry : region.entrySet() ) { Customer customer = entry.getValue(); customer.setFirstName(customer.getFirstName().toUpperCase()); } context.getResultSender().lastResult(true); } @Override public String getId() { return getClass().getName(); } } 请注意， getId必须返回一个唯一值，因此类名通常是一个不错的选择。 FunctionContext包含我们所有的区域数据，因此我们可以对其进行更复杂的查询，或者像我们在这里所做的那样，对其进行变异。 而且Function比这更强大，所以请查看官方手册，尤其是getResultSender方法。 7.2. 部署功能 我们需要让 Geode 知道我们的函数才能运行它。就像我们对自定义数据类型所做的那样，我们将打包 jar。 但这一次，我们可以只使用 deploy命令： gfsh\u0026gt; deploy --jar=./lib/apache-geode-1.0-SNAPSHOT.jar 7.3. 执行功能 现在，我们可以使用FunctionService 从应用程序中执行Function： @Test public void whenExecuteUppercaseNames_thenCustomerNamesAreUppercased() { Execution execution = FunctionService.onRegion(this.customerRegion); execution.execute(UpperCaseNames.class.getName()); Customer customer = this.customerRegion.get(new CustomerKey(1)); assertEquals(\u0026#34;GHEORGE\u0026#34;, customer.getFirstName()); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_geode/","tags":[],"title":"Apache Geode 快速指南"},{"categories":["Data"],"contents":"1. 概述 Apache Flink 是一个大数据处理框架，它允许程序员以非常高效和可扩展的方式处理大量数据。 在本文中，我们将介绍***Apache Flink*** Java API****中可用的一些核心 API 概念和标准数据转换。这个 API 的流畅风格使得使用 Flink 的中心结构——分布式集合变得容易。 首先，我们将看一下 Flink 的DataSet API 转换，并使用它们来实现一个字数统计程序。然后我们将简要介绍 Flink 的DataStream API，它允许您以实时方式处理事件流。 2. Maven依赖 首先，我们需要将 Maven 依赖项添加到flink-java和flink-test-utils库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-test-utils_2.10\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;scope\u0026gt; \u0026lt;/dependency\u0026gt; 3. 核心 API 概念 在使用 Flink 时，我们需要了解与它的 API 相关的几件事：  **每个 Flink 程序都会对分布式数据集合进行转换。**提供了用于转换数据的各种功能，包括过滤、映射、连接、分组和聚合 Flink 中的sink操作触发流的执行以产生程序所需的结果，例如将结果保存到文件系统或打印到标准输出 Flink 转换是惰性的，这意味着它们在调用sink操作之前不会执行 **Apache Flink API 支持两种操作模式——批处理和实时。**如果您正在处理可以在批处理模式下处理的有限数据源，您将使用DataSet API。如果您想实时处理无限的数据流，则需要使用DataStream API  4. 数据集 API 转换 Flink 程序的入口点是ExecutionEnvironment类的实例——它定义了程序执行的上下文。 让我们创建一个ExecutionEnvironment来开始我们的处理： ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); **请注意，当您在本地机器上启动应用程序时，它将在本地 JVM 上执行处理。**如果您想在机器集群上开始处理，则需要在这些机器上安装Apache Flink并相应地配置ExecutionEnvironment。 4.1 创建数据集 要开始执行数据转换，我们需要为我们的程序提供数据。 让我们使用ExecutionEnvironement创建**DataSet类的实例： DataSet\u0026lt;Integer\u0026gt; amounts = env.fromElements(1, 29, 40, 50); 您可以从多个源创建数据集，例如 Apache Kafka、CSV、文件或几乎任何其他数据源。 4.2. 过滤和减少 创建DataSet类的实例后，您可以对其应用转换。 假设您要过滤高于某个阈值的数字，然后将它们全部相加*。您可以使用filter()和reduce()*转换来实现这一点： int threshold = 30; List\u0026lt;Integer\u0026gt; collect = amounts .filter(a -\u0026gt; a \u0026gt; threshold) .reduce((integer, t1) -\u0026gt; integer + t1) .collect(); assertThat(collect.get(0)).isEqualTo(90); 请注意，collect()方法是触发实际数据转换的接收器操作。 4.3. 地图 假设您有一个Person对象的DataSet ： private static class Person { private int age; private String name; // standard constructors/getters/setters } 接下来，让我们创建这些对象的DataSet： DataSet\u0026lt;Person\u0026gt; personDataSource = env.fromCollection( Arrays.asList( new Person(23, \u0026#34;Tom\u0026#34;), new Person(75, \u0026#34;Michael\u0026#34;))); 假设您只想从集合的每个对象中提取年龄字段。您可以使用map()转换仅获取**Person类的特定字段： List\u0026lt;Integer\u0026gt; ages = personDataSource .map(p -\u0026gt; p.age) .collect(); assertThat(ages).hasSize(2); assertThat(ages).contains(23, 75); 4.4. 加入 当您有两个数据集时，您可能希望将它们加入某个id字段。为此，您可以使用*join()*转换。 让我们创建用户的交易和地址的集合： Tuple3\u0026lt;Integer, String, String\u0026gt; address = new Tuple3\u0026lt;\u0026gt;(1, \u0026#34;5th Avenue\u0026#34;, \u0026#34;London\u0026#34;); DataSet\u0026lt;Tuple3\u0026lt;Integer, String, String\u0026gt;\u0026gt; addresses = env.fromElements(address); Tuple2\u0026lt;Integer, String\u0026gt; firstTransaction = new Tuple2\u0026lt;\u0026gt;(1, \u0026#34;Transaction_1\u0026#34;); DataSet\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;\u0026gt; transactions = env.fromElements(firstTransaction, new Tuple2\u0026lt;\u0026gt;(12, \u0026#34;Transaction_2\u0026#34;)); 两个元组中的第一个字段都是整数类型，这是一个id字段，我们要在其上连接两个数据集。 要执行实际的加入逻辑，我们需要为地址和交易实现一个*KeySelector接口：* private static class IdKeySelectorTransaction implements KeySelector\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;, Integer\u0026gt; { @Override public Integer getKey(Tuple2\u0026lt;Integer, String\u0026gt; value) { return value.f0; } } private static class IdKeySelectorAddress implements KeySelector\u0026lt;Tuple3\u0026lt;Integer, String, String\u0026gt;, Integer\u0026gt; { @Override public Integer getKey(Tuple3\u0026lt;Integer, String, String\u0026gt; value) { return value.f0; } } 每个选择器只返回应该执行连接的字段。 不幸的是，这里不能使用 lambda 表达式，因为 Flink 需要泛型类型信息。 接下来，让我们使用这些选择器实现合并逻辑： List\u0026lt;Tuple2\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;, Tuple3\u0026lt;Integer, String, String\u0026gt;\u0026gt;\u0026gt; joined = transactions.join(addresses) .where(new IdKeySelectorTransaction()) .equalTo(new IdKeySelectorAddress()) .collect(); assertThat(joined).hasSize(1); assertThat(joined).contains(new Tuple2\u0026lt;\u0026gt;(firstTransaction, address)); 4.5. 种类 假设您有以下Tuple2 集合： Tuple2\u0026lt;Integer, String\u0026gt; secondPerson = new Tuple2\u0026lt;\u0026gt;(4, \u0026#34;Tom\u0026#34;); Tuple2\u0026lt;Integer, String\u0026gt; thirdPerson = new Tuple2\u0026lt;\u0026gt;(5, \u0026#34;Scott\u0026#34;); Tuple2\u0026lt;Integer, String\u0026gt; fourthPerson = new Tuple2\u0026lt;\u0026gt;(200, \u0026#34;Michael\u0026#34;); Tuple2\u0026lt;Integer, String\u0026gt; firstPerson = new Tuple2\u0026lt;\u0026gt;(1, \u0026#34;Jack\u0026#34;); DataSet\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;\u0026gt; transactions = env.fromElements( fourthPerson, secondPerson, thirdPerson, firstPerson); 如果要按元组的第一个字段对该集合进行排序，可以使用*sortPartitions()*转换： List\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;\u0026gt; sorted = transactions .sortPartition(new IdKeySelectorTransaction(), Order.ASCENDING) .collect(); assertThat(sorted) .containsExactly(firstPerson, secondPerson, thirdPerson, fourthPerson); 5. 字数统计 字数统计问题是一种常用来展示大数据处理框架能力的问题。基本解决方案涉及计算文本输入中的单词出现次数。让我们使用 Flink 来实现这个问题的解决方案。 作为我们解决方案的第一步，我们创建了一个LineSplitter类，它将我们的输入拆分为标记（单词），为每个标记收集一个Tuple2键值对。在每个元组中，键是在文本中找到的单词，值是整数一 (1)。 此类实现了*FlatMapFunction* 接口，该接口将String作为输入并生成*Tuple2 \u0026lt;String, Integer\u0026gt;：* public class LineSplitter implements FlatMapFunction\u0026lt;String, Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; { @Override public void flatMap(String value, Collector\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; out) { Stream.of(value.toLowerCase().split(\u0026#34;\\\\W+\u0026#34;)) .filter(t -\u0026gt; t.length() \u0026gt; 0) .forEach(token -\u0026gt; out.collect(new Tuple2\u0026lt;\u0026gt;(token, 1))); } } 我们在Collector类上调用*collect()*方法，在处理管道中向前推送数据。 我们的下一步也是最后一步是按元组的第一个元素（单词）对元组进行分组，然后对第二个元素执行求和聚合以产生单词出现的计数： public static DataSet\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; startWordCount( ExecutionEnvironment env, List\u0026lt;String\u0026gt; lines) throws Exception { DataSet\u0026lt;String\u0026gt; text = env.fromCollection(lines); return text.flatMap(new LineSplitter()) .groupBy(0) .aggregate(Aggregations.SUM, 1); } 我们使用了三种类型的 Flink 转换：flatMap()、groupBy()和aggregate()。 让我们编写一个测试来断言字数统计实现按预期工作： List\u0026lt;String\u0026gt; lines = Arrays.asList( \u0026#34;This is a first sentence\u0026#34;, \u0026#34;This is a second sentence with a one word\u0026#34;); DataSet\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; result = WordCount.startWordCount(env, lines); List\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; collect = result.collect(); assertThat(collect).containsExactlyInAnyOrder( new Tuple2\u0026lt;\u0026gt;(\u0026#34;a\u0026#34;, 3), new Tuple2\u0026lt;\u0026gt;(\u0026#34;sentence\u0026#34;, 2), new Tuple2\u0026lt;\u0026gt;(\u0026#34;word\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;is\u0026#34;, 2), new Tuple2\u0026lt;\u0026gt;(\u0026#34;this\u0026#34;, 2), new Tuple2\u0026lt;\u0026gt;(\u0026#34;second\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;first\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;with\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;one\u0026#34;, 1)); 6.数据流API 6.1 创建数据流 Apache Flink 还支持通过其 DataStream API 处理事件流。如果我们想开始消费事件，我们首先需要使用StreamExecutionEnvironment类： StreamExecutionEnvironment executionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment(); 接下来，我们可以使用来自各种来源的executionEnvironment创建一个事件流。它可能是一些像Apache Kafka这样的消息总线，但在这个例子中，我们将简单地从几个字符串元素创建一个源： DataStream\u0026lt;String\u0026gt; dataStream = executionEnvironment.fromElements( \u0026#34;This is a first sentence\u0026#34;, \u0026#34;This is a second sentence with a one word\u0026#34;); 我们可以对DataStream的每个元素应用转换，就像在普通的DataSet类中一样： SingleOutputStreamOperator\u0026lt;String\u0026gt; upperCase = text.map(String::toUpperCase); 为了触发执行，我们需要调用一个接收器操作，例如print()，它只会将转换结果打印到标准输出，然后是StreamExecutionEnvironment类的*execute()*方法： upperCase.print(); env.execute(); 它将产生以下输出： 1\u0026gt; THIS IS A FIRST SENTENCE 2\u0026gt; THIS IS A SECOND SENTENCE WITH A ONE WORD 6.2. 事件窗口化 在实时处理事件流时，您有时可能需要将事件组合在一起并在这些事件的窗口上应用一些计算。 假设我们有一个事件流，其中每个事件都是由事件编号和事件发送到我们系统时的时间戳组成的对，并且我们可以容忍无序的事件，但前提是它们是无序的。迟到了二十多秒。 对于这个例子，让我们首先创建一个流来模拟两个相隔几分钟的事件，并定义一个时间戳提取器来指定我们的延迟阈值： SingleOutputStreamOperator\u0026lt;Tuple2\u0026lt;Integer, Long\u0026gt;\u0026gt; windowed = env.fromElements( new Tuple2\u0026lt;\u0026gt;(16, ZonedDateTime.now().plusMinutes(25).toInstant().getEpochSecond()), new Tuple2\u0026lt;\u0026gt;(15, ZonedDateTime.now().plusMinutes(2).toInstant().getEpochSecond())) .assignTimestampsAndWatermarks( new BoundedOutOfOrdernessTimestampExtractor \u0026lt;Tuple2\u0026lt;Integer, Long\u0026gt;\u0026gt;(Time.seconds(20)) { @Override public long extractTimestamp(Tuple2\u0026lt;Integer, Long\u0026gt; element) { return element.f1 * 1000; } }); 接下来，让我们定义一个窗口操作，将我们的事件分组为 5 秒的窗口，并对这些事件应用转换： SingleOutputStreamOperator\u0026lt;Tuple2\u0026lt;Integer, Long\u0026gt;\u0026gt; reduced = windowed .windowAll(TumblingEventTimeWindows.of(Time.seconds(5))) .maxBy(0, true); reduced.print(); 它将获取每五秒窗口的最后一个元素，因此它会打印出： 1\u0026gt; (15,1491221519) 请注意，我们看不到第二个事件，因为它晚于指定的延迟阈值到达。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_flink/","tags":[],"title":"Apache Flink 与 Java 简介"},{"categories":["Data"],"contents":"1. 简介 在本教程中，我们将了解如何使用事件数据和Apache Druid。我们将介绍事件数据和 Druid 架构的基础知识。作为其中的一部分，我们将创建一个简单的数据管道，利用 Druid 的各种功能，涵盖各种数据摄取模式和查询准备数据的不同方式。 2.基本概念 在深入了解 Apache Druid 的操作细节之前，我们先来了解一些基本概念。我们感兴趣的领域是大规模事件数据的实时分析。 因此，必须了解我们所说的事件数据的含义以及大规模实时分析它们需要什么。 2.1 什么是事件数据？ 事件数据是指关于在特定时间点发生的变化的一条信息。事件数据在当今的应用程序中几乎无处不在。从经典的应用程序日志到由事物生成的现代传感器数据，它几乎无处不在。这些通常以大规模生成的机器可读信息为特征。 它们为预测、自动化、通信和集成等多种功能提供支持，仅举几例。此外，它们在事件驱动架构中也很重要。 2.2. 什么是阿帕奇德鲁伊？ Apache Druid 是一个实时分析数据库，旨在对面向事件的数据进行快速分析。Druid 于 2011 年启动，2012 年在 GPL 许可下开源，并于 2015 年迁移到 Apache 许可。它由 Apache 基金会管理，社区贡献了多个组织。它提供实时摄取、快速查询性能和高可用性。 Druid 这个名字指的是它的架构可以转变来解决不同类型的数据问题。它通常用于商业智能应用程序以分析大量实时和历史数据。 3. Druid架构 Druid 是一个用 Java 编写的面向列的分布式数据源。它能够摄取大量事件数据并在这些数据之上提供低延迟查询。此外，它提供了任意切片和切块数据的可能性。 了解 Druid 架构如何支持这些特性非常有趣。在本节中，我们将介绍 Druid 架构的一些重要部分。 3.1数据存储设计 了解 Druid 如何构建和存储其数据非常重要，这允许分区和分布。Druid在处理过程中默认对数据进行分区，并将它们存储到块和段中： Druid**将数据存储在我们所知的“数据源”**中，这在逻辑上类似于关系数据库中的表。一个 Druid 集群可以并行处理多个数据源，从各种来源摄取。 每个数据源都是分区的——默认情况下基于时间，如果配置了其他属性，则进一步基于其他属性。数据的时间范围称为“块” ——例如，如果数据按小时分区，则为一小时的数据。 每个块进一步划分为一个或多个“段”，这些“段”是由多行数据组成的单个文件。一个数据源可能有从几个段到数百万个段的任何地方。 3.2. 德鲁伊进程 Druid 具有多进程和分布式架构。因此，每个过程都可以独立扩展，从而使我们能够创建灵活的集群。让我们了解作为 Druid 一部分的重要过程：  Coordinator：该进程主要负责段管理和分发，并与历史进程通信，根据配置加载或删除段 Overlord：这是负责接受任务、协调任务分发、围绕任务创建锁以及向调用者返回状态的主要进程 Broker：这是所有查询都发送到分布式集群中执行的进程；它从 Zookeeper 收集元数据并将查询路由到具有正确段的进程 路由器：这是一个可选进程，可用于将查询路由到不同的代理进程，从而为更重要数据的查询提供查询隔离 历史：这些是存储可查询数据的进程；他们与 Zookeeper 保持持续的联系，并监视他们必须加载和服务的分段信息 MiddleManager：这些是执行提交任务的工作进程；他们将任务转发给在不同 JVM 中运行的 Peons，从而提供资源和日志隔离  3.3. 外部依赖 除了核心进程之外，Druid 还依赖于几个外部依赖项才能使其集群按预期运行。 让我们看看Druid集群是如何与核心进程和外部依赖一起形成的：  Druid 使用深度存储来存储已摄取到系统中的任何数据。这些不用于响应查询，而是用作数据备份和在进程之间传输数据。这些可以是从本地文件系统到分布式对象存储（如 S3 和 HDFS）的任何内容。 元数据存储用于保存共享系统元数据，如段使用信息和任务信息。但是，它从未用于存储实际数据。它是一个关系数据库，如 Apache Derby、PostgreSQL 或 MySQL。 Druid 使用 Apache Zookeeper 来管理当前的集群状态。它促进了 Druid 集群中的许多操作，例如协调者/霸主领导者选举、段发布协议和段加载/删除协议。 4. Druid设置 Druid 旨在部署为可扩展的容错集群。但是，建立生产级 Druid 集群并非易事。正如我们之前看到的，有许多流程和外部依赖项需要设置和配置。由于可以以灵活的方式创建集群，因此我们必须注意我们的要求，以适当地设置各个流程。 此外，Druid仅在类 Unix 环境中受支持，而不在 Windows 上受支持。此外，运行 Druid 进程需要 Java 8 或更高版本。有几种单服务器配置可用于在单台机器上设置 Druid 以运行教程和示例。但是，为了运行生产工作负载，建议设置一个具有多台机器的成熟 Druid 集群。 出于本教程的目的，我们将借助Docker Hub 上发布的官方 Docker 镜像在单台机器上设置 Druid。这使我们也可以在 Windows 上运行 Druid，正如我们之前讨论的那样，它不受其他支持。有一个Docker compose 文件可用，它为每个 Druid 进程及其外部依赖项创建一个容器。 我们必须将配置值作为环境变量提供给 Druid。实现这一点的最简单方法是在与 Docker compose 文件相同的目录中提供一个名为“environment”的文件。 一旦我们有了 Docker compose 和环境文件，启动 Druid 就像在同一目录中运行命令一样简单： docker-compose up 这将调出单机 Druid 设置所需的所有容器。我们必须小心为 Docker 机器提供足够的内存，因为 Druid 会消耗大量资源。 5. 读取数据 使用 Druid 构建数据管道的第一步是将数据加载到 Druid 中。这个过程在 Druid 架构中称为数据读取或索引。我们必须找到合适的数据集才能继续本教程。 现在，正如我们迄今为止所收集的那样，我们必须收集事件数据并具有一些时间性质，以充分利用 Druid 基础设施。 Druid 的官方指南使用简单而优雅的数据，其中包含特定日期的 Wikipedia 页面编辑。我们将继续在此处的教程中使用它。 5.1 数据模型 让我们首先检查我们拥有的数据的结构。我们创建的大多数数据管道对数据异常非常敏感，因此有必要尽可能地清理数据。 尽管执行数据分析有复杂的方法和工具，但我们将从目视检查开始。快速分析表明，输入数据具有以 JSON 格式捕获的事件，其中单个事件包含典型属性： { \u0026#34;time\u0026#34;: \u0026#34;2015-09-12T02:10:26.679Z\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#pt.wikipedia\u0026#34;, \u0026#34;cityName\u0026#34;: null, \u0026#34;comment\u0026#34;: \u0026#34;Houveram problemas na última edição e tive de refazê-las, junto com as atualizações da página.\u0026#34;, \u0026#34;countryIsoCode\u0026#34;: \u0026#34;BR\u0026#34;, \u0026#34;countryName\u0026#34;: \u0026#34;Brazil\u0026#34;, \u0026#34;isAnonymous\u0026#34;: true, \u0026#34;isMinor\u0026#34;: false, \u0026#34;isNew\u0026#34;: false, \u0026#34;isRobot\u0026#34;: false, \u0026#34;isUnpatrolled\u0026#34;: true, \u0026#34;metroCode\u0026#34;: null, \u0026#34;namespace\u0026#34;: \u0026#34;Main\u0026#34;, \u0026#34;page\u0026#34;: \u0026#34;Catarina Muniz\u0026#34;, \u0026#34;regionIsoCode\u0026#34;: null, \u0026#34;regionName\u0026#34;: null, \u0026#34;user\u0026#34;: \u0026#34;181.213.37.148\u0026#34;, \u0026#34;delta\u0026#34;: 197, \u0026#34;added\u0026#34;: 197, \u0026#34;deleted\u0026#34;: 0 } 虽然定义此事件的属性有很多，但在使用 Druid 时，有一些是我们特别感兴趣的：  时间戳 方面 指标  Druid 需要一个特定的属性来标识为时间戳列。在大多数情况下，Druid 的数据解析器能够自动检测出最佳候选者。但是我们总是有选择的余地，特别是如果我们的数据中没有合适的属性。 维度是 Druid 按原样存储的属性。我们可以将它们用于任何目的，例如分组、过滤或应用聚合器。我们可以在摄取规范中选择维度，我们将在本教程中进一步讨论。 与维度不同，指标是默认**以聚合形式存储的属性。**我们可以为 Druid 选择一个聚合函数，以便在摄取期间应用到这些属性。与启用汇总一起，这些可以导致紧凑的数据表示。 5.2. 读取方法 现在，我们将讨论在 Druid 中执行数据读取的各种方法。通常，事件驱动的数据本质上是流式传输的，这意味着它们会随着时间的推移以不同的速度生成，就像维基百科的编辑一样。 但是，我们可能会在一段时间内对数据进行批处理，其中数据本质上更加静态，就像去年发生的所有 Wikipedia 编辑一样。 我们可能还需要解决不同的数据用例，而 Druid 对其中的大多数都提供了出色的支持。让我们回顾一下在数据管道中使用 Druid 的两种最常见的方式：  流式读取 批量读取  在 Druid 中读取数据的最常见方式是通过 Apache Streaming 服务，Druid 可以直接从 Kafka 读取数据。Druid 也支持 Kinesis 等其他平台。我们必须在 Overload 进程上启动主管，该进程创建和管理 Kafka 索引任务。我们可以通过 Overload 进程的 HTTP POST 命令提交作为 JSON 文件的主管规范来启动主管。 或者，我们可以批量读取数据——例如，从本地或远程文件。它为基于 Hadoop 的批量摄取提供了一种选择，用于从 Hadoop 文件系统中以 Hadoop 文件格式摄取数据。更常见的是，我们可以选择顺序或并行的原生批量摄取。这是一种更方便、更简单的方法，因为它没有任何外部依赖项。 5.3. 定义任务规范 在本教程中，我们将为我们拥有的输入数据设置一个本机批量读取任务。我们可以选择从 Druid 控制台配置任务，这为我们提供了直观的图形界面。或者，我们可以将任务规范定义为 JSON 文件，并使用脚本或命令行将其提交给霸主进程。 让我们首先定义一个简单的任务规范，用于在名为wikipedia-index.json的文件中摄取我们的数据： { \u0026#34;type\u0026#34; : \u0026#34;index_parallel\u0026#34;, \u0026#34;spec\u0026#34; : { \u0026#34;dataSchema\u0026#34; : { \u0026#34;dataSource\u0026#34; : \u0026#34;wikipedia\u0026#34;, \u0026#34;dimensionsSpec\u0026#34; : { \u0026#34;dimensions\u0026#34; : [ \u0026#34;channel\u0026#34;, \u0026#34;cityName\u0026#34;, \u0026#34;comment\u0026#34;, \u0026#34;countryIsoCode\u0026#34;, \u0026#34;countryName\u0026#34;, \u0026#34;isAnonymous\u0026#34;, \u0026#34;isMinor\u0026#34;, \u0026#34;isNew\u0026#34;, \u0026#34;isRobot\u0026#34;, \u0026#34;isUnpatrolled\u0026#34;, \u0026#34;metroCode\u0026#34;, \u0026#34;namespace\u0026#34;, \u0026#34;page\u0026#34;, \u0026#34;regionIsoCode\u0026#34;, \u0026#34;regionName\u0026#34;, \u0026#34;user\u0026#34;, { \u0026#34;name\u0026#34;: \u0026#34;added\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;deleted\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;delta\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } ] }, \u0026#34;timestampSpec\u0026#34;: { \u0026#34;column\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;iso\u0026#34; }, \u0026#34;metricsSpec\u0026#34; : [], \u0026#34;granularitySpec\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;uniform\u0026#34;, \u0026#34;segmentGranularity\u0026#34; : \u0026#34;day\u0026#34;, \u0026#34;queryGranularity\u0026#34; : \u0026#34;none\u0026#34;, \u0026#34;intervals\u0026#34; : [\u0026#34;2015-09-12/2015-09-13\u0026#34;], \u0026#34;rollup\u0026#34; : false } }, \u0026#34;ioConfig\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;index_parallel\u0026#34;, \u0026#34;inputSource\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;local\u0026#34;, \u0026#34;baseDir\u0026#34; : \u0026#34;quickstart/tutorial/\u0026#34;, \u0026#34;filter\u0026#34; : \u0026#34;wikiticker-2015-09-12-sampled.json.gz\u0026#34; }, \u0026#34;inputFormat\u0026#34; : { \u0026#34;type\u0026#34;: \u0026#34;json\u0026#34; }, \u0026#34;appendToExisting\u0026#34; : false }, \u0026#34;tuningConfig\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;index_parallel\u0026#34;, \u0026#34;maxRowsPerSegment\u0026#34; : 5000000, \u0026#34;maxRowsInMemory\u0026#34; : 25000 } } } 让我们根据我们在前面的小节中介绍的基础知识来理解这个任务规范：  我们选择了index_parallel任务，它为我们提供了并行的本地批量摄取 我们将在此任务中使用的数据源名称为“ wikipedia” 我们数据的时间戳来自属性“时间” 我们正在添加许多数据属性作为维度 在当前任务中，我们没有为我们的数据使用任何指标 此任务应禁用默认启用的汇总 该任务的输入源是一个名为wikiticker-2015-09-12-sampled.json.gz的本地文件 我们没有使用任何辅助分区，我们可以在tuneConfig中定义  此任务规范假设我们已下载数据文件 wikiticker-2015-09-12-sampled.json.gz并将其保存在运行 Druid 的本地计算机上。当我们将 Druid 作为 Docker 容器运行时，这可能会更棘手。幸运的是，Druid在quickstart/tutorial位置默认提供了这个示例数据。 5.4. 提交任务规范 最后，我们可以使用curl之类的工具通过命令行将此任务规范提交给霸主进程： curl -X \u0026#39;POST\u0026#39; -H \u0026#39;Content-Type:application/json\u0026#39; -d @wikipedia-index.json http://localhost:8081/druid/indexer/v1/task 通常，如果提交成功，**上述命令会返回任务的 ID 。**我们可以通过 Druid 控制台或执行查询来验证我们的摄取任务的状态，我们将在下一节中介绍。 5.5. 高级读取概念 Druid 最适合我们需要处理大量数据的情况——当然不是我们在本教程中看到的那种数据！现在，要大规模启用功能，Druid 架构必须提供合适的工具和技巧。 虽然我们不会在本教程中使用它们，但让我们快速讨论汇总和分区。 事件数据很快就会增长到海量，这会影响我们可以实现的查询性能。在许多情况下，我们可能会随着时间的推移汇总数据。这就是我们在 Druid 中所熟知的 roll-up。启用汇总后，Druid 会在摄取期间努力汇总具有相同维度和时间戳的行。虽然它可以节省空间，但roll-up确实会导致查询精度的损失，因此我们必须合理使用它。 面对不断增长的数据量，实现更好性能的另一种潜在方法是分配数据，从而分配工作负载。默认情况下，Druid根据时间戳将数据划分为包含一个或多个段的时间块。此外，我们可以决定使用自然维度进行二次分区以提高数据局部性。此外，Druid 首先按时间戳对每个段内的数据进行排序，然后按我们配置的其他维度进行排序。 6. 查询数据 一旦我们成功地执行了数据摄取，它应该可以供我们查询了。在 Druid 中有多种查询数据的方法。在 Druid 中执行查询的最简单方法是通过 Druid 控制台。但是，我们也可以通过发送 HTTP 命令或使用命令行工具来执行查询。 在 Druid 中构造查询的两种突出方式是原生查询和类似 SQL 的查询。我们将以这两种方式构建一些基本查询，并使用curl通过 HTTP 发送它们。让我们看看如何对我们之前在 Druid 中摄取的数据创建一些简单的查询。 6.1 本机查询 Druid 中的原生查询使用 JSON 对象，我们可以将其发送到代理或路由器进行处理。我们可以通过 HTTP POST 命令发送查询，以及其他方式来执行相同的操作。 让我们创建一个名为simple_query_native.json的 JSON 文件： { \u0026#34;queryType\u0026#34; : \u0026#34;topN\u0026#34;, \u0026#34;dataSource\u0026#34; : \u0026#34;wikipedia\u0026#34;, \u0026#34;intervals\u0026#34; : [\u0026#34;2015-09-12/2015-09-13\u0026#34;], \u0026#34;granularity\u0026#34; : \u0026#34;all\u0026#34;, \u0026#34;dimension\u0026#34; : \u0026#34;page\u0026#34;, \u0026#34;metric\u0026#34; : \u0026#34;count\u0026#34;, \u0026#34;threshold\u0026#34; : 10, \u0026#34;aggregations\u0026#34; : [ { \u0026#34;type\u0026#34; : \u0026#34;count\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;count\u0026#34; } ] } 这是一个简单的查询，用于获取 2019 年 9 月 12 日至 13 日期间页面编辑次数最多的前十个页面。 让我们使用curl通过 HTTP 发布： curl -X \u0026#39;POST\u0026#39; -H \u0026#39;Content-Type:application/json\u0026#39; -d @simple_query_native.json http://localhost:8888/druid/v2?pretty 此响应包含 JSON 格式的前十页的详细信息： [ { \u0026#34;timestamp\u0026#34; : \u0026#34;2015-09-12T00:46:58.771Z\u0026#34;, \u0026#34;result\u0026#34; : [ { \u0026#34;count\u0026#34; : 33, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:Vandalismusmeldung\u0026#34; }, { \u0026#34;count\u0026#34; : 28, \u0026#34;page\u0026#34; : \u0026#34;User:Cyde/List of candidates for speedy deletion/Subpage\u0026#34; }, { \u0026#34;count\u0026#34; : 27, \u0026#34;page\u0026#34; : \u0026#34;Jeremy Corbyn\u0026#34; }, { \u0026#34;count\u0026#34; : 21, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:Administrators\u0026#39; noticeboard/Incidents\u0026#34; }, { \u0026#34;count\u0026#34; : 20, \u0026#34;page\u0026#34; : \u0026#34;Flavia Pennetta\u0026#34; }, { \u0026#34;count\u0026#34; : 18, \u0026#34;page\u0026#34; : \u0026#34;Total Drama Presents: The Ridonculous Race\u0026#34; }, { \u0026#34;count\u0026#34; : 18, \u0026#34;page\u0026#34; : \u0026#34;User talk:Dudeperson176123\u0026#34; }, { \u0026#34;count\u0026#34; : 18, \u0026#34;page\u0026#34; : \u0026#34;Wikipédia:Le Bistro/12 septembre 2015\u0026#34; }, { \u0026#34;count\u0026#34; : 17, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:In the news/Candidates\u0026#34; }, { \u0026#34;count\u0026#34; : 17, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:Requests for page protection\u0026#34; } ] } ] 6.2. Druid SQL Druid 有一个内置的 SQL 层，它为我们提供了以熟悉的类似 SQL 的结构构建查询的自由。它利用 Apache Calcite 来解析和规划查询。但是，Druid SQL 将 SQL 查询转换为查询代理上的本机查询，然后再将它们发送到数据进程。 让我们看看如何创建与以前相同的查询，但使用 Druid SQL。和以前一样，我们将创建一个名为simple_query_sql.json的 JSON 文件： { \u0026#34;query\u0026#34;:\u0026#34;SELECT page, COUNT(*) AS counts / FROM wikipedia WHERE \\\u0026#34;__time\\\u0026#34; / BETWEEN TIMESTAMP \u0026#39;2015-09-12 00:00:00\u0026#39; AND TIMESTAMP \u0026#39;2015-09-13 00:00:00\u0026#39; / GROUP BY page ORDER BY Edits DESC LIMIT 10\u0026#34; } 请注意，为了便于阅读，查询已分成多行，但它应该出现在单行上。同样，和以前一样，我们将通过 HTTP 发布此查询，但发送到不同的端点： curl -X \u0026#39;POST\u0026#39; -H \u0026#39;Content-Type:application/json\u0026#39; -d @simple_query_sql.json http://localhost:8888/druid/v2/sql 输出应该与我们之前使用本机查询实现的非常相似。 6.3. 查询类型 在前面的部分中，我们看到了一种查询类型，我们根据间隔获取度量“计数”的前十个结果。这只是 Druid 支持的一种查询类型，称为TopN查询。当然，我们可以通过使用过滤器和聚合使这个简单的TopN查询更有趣。但这不在本教程的范围内。但是，我们可能会对 Druid 中的其他几个查询感兴趣。 一些流行的包括 Timeseries 和 GroupBy。 时间序列查询返回一个 JSON 对象数组，其中每个对象表示时间序列查询中描述的一个值——例如，过去一个月的一个维度的每日平均值。 GroupBy查询返回一个 JSON 对象数组，其中每个对象代表一个分组，如 group-by 查询中所述。例如，我们可以查询一个维度在过去一个月中按另一个维度分组的日平均值。 还有其他几种查询类型，包括Scan、Search、TimeBoundary、SegmentMetadata和DatasourceMetadata。 6.4. 高级查询概念 Druid 提供了一些复杂的方法来创建复杂的查询，以创建有趣的数据应用程序。这些包括各种对数据进行切片和切块的方法，同时仍然能够提供令人难以置信的查询性能。 虽然对它们的详细讨论超出了本教程的范围，但让我们讨论一些重要的，例如连接和查找、多租户和查询缓存。 Druid 支持两种加入数据的方式。第一个是连接运算符，第二个是查询时查找。但是，为了获得更好的查询性能，建议避免查询时连接。 多租户是指在同一个 Druid 基础设施上支持多个租户的特性，同时仍然为它们提供逻辑隔离。在 Druid 中，可以通过每个租户的单独数据源或租户的数据分区来实现这一点。 最后，查询缓存是数据密集型应用程序性能的关键。Druid 支持分段和查询结果级别的查询结果缓存。此外，缓存数据可以驻留在内存中或外部持久存储中。 7. 语言绑定 尽管 Druid 对在 JSON 中创建摄取规范和定义查询具有出色的支持，但有时在 JSON 中定义这些查询可能很乏味，尤其是在查询变得复杂时。不幸的是，Druid 没有提供任何特定语言的客户端库来帮助我们在这方面。但是社区已经开发了相当多的语言绑定。一个这样的客户端库也可用于 Java。 我们将快速了解如何使用 Java 中的这个客户端库构建我们之前使用的TopN查询。 让我们首先在 Maven 中定义所需的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;in.zapr.druid\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druidry\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在此之后，我们应该能够使用客户端库并创建我们的TopN查询： DateTime startTime = new DateTime(2015, 9, 12, 0, 0, 0, DateTimeZone.UTC); DateTime endTime = new DateTime(2015, 9, 13, 0, 0, 0, DateTimeZone.UTC); Interval interval = new Interval(startTime, endTime); Granularity granularity = new SimpleGranularity(PredefinedGranularity.ALL); DruidDimension dimension = new SimpleDimension(\u0026#34;page\u0026#34;); TopNMetric metric = new SimpleMetric(\u0026#34;count\u0026#34;); DruidTopNQuery query = DruidTopNQuery.builder() .dataSource(\u0026#34;wikipedia\u0026#34;) .dimension(dimension) .threshold(10) .topNMetric(metric) .granularity(granularity) .filter(filter) .aggregators(Arrays.asList(new LongSumAggregator(\u0026#34;count\u0026#34;, \u0026#34;count\u0026#34;))) .intervals(Collections.singletonList(interval)).build(); 在此之后，我们可以简单地生成所需的 JSON 结构，我们可以在 HTTP POST 调用中使用它： ObjectMapper mapper = new ObjectMapper(); String requiredJson = mapper.writeValueAsString(query); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_druid_event_driven_data/","tags":[],"title":"使用 Apache Druid 的事件驱动数据"},{"categories":["Spring"],"contents":"1. 概述 本教程的重点是配置和使用Apache CXF框架以及 Spring - 使用 Java 或 XML 配置。 这是 Apache CXF 系列的第二篇；第一个侧重于将 CXF 的基础知识作为 JAX-WS 标准 API 的实现。 2. Maven依赖 与上一个教程类似，需要包含以下两个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-frontend-jaxws\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-transports-http\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 有关最新版本的 Apache CXF 工件，请查看apache-cxf。 此外，支持 Spring 还需要以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 Spring 工件。 最后，因为我们将使用 Java Servlet 3.0+ API 而不是传统的web.xml部署描述符以编程方式配置应用程序，所以我们需要以下工件： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在这里我们可以找到最新版本的 Servlet API。 3. 服务器端组件 现在让我们看一下为了发布 Web 服务端点而需要在服务器端出现的组件。 3.1 WebApplicationInitilizer接口 WebApplicationInitializer接口被实现为以编程方式为应用程序配置ServletContext接口。当出现在类路径上时，它的onStartup方法由 servlet 容器自动调用，然后ServletContext被实例化和初始化。 下面是如何定义一个类来实现WebApplicationInitializer接口： public class AppInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext container) { // Method implementation  } } onStartup *()*方法是使用如下所示的代码片段实现的。 首先，创建并配置 Spring 应用程序上下文以注册包含配置元数据的类： AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(ServiceConfiguration.class); ServiceConfiguration类使用@Configuration注解进行注解，以提供 bean 定义。这个类将在下一小节中讨论。 以下片段显示了如何将 Spring 应用程序上下文添加到 servlet 上下文中： container.addListener(new ContextLoaderListener(context)); 由 Apache CXF 定义的CXFServlet类被生成并注册以处理传入的请求： ServletRegistration.Dynamic dispatcher = container.addServlet(\u0026#34;dispatcher\u0026#34;, new CXFServlet()); 应用程序上下文加载配置文件中定义的 Spring 元素。在这种情况下，servlet 的名称是cxf ，因此默认情况下，上下文会在名为cxf-servlet.xml的文件中查找这些元素。 最后，CXF servlet 被映射到一个相对 URL： dispatcher.addMapping(\u0026#34;/services\u0026#34;); 3.2. 好旧的web.xml 或者，如果我们想使用（有点过时的）部署描述符而不是WebApplicationInitilizer接口，则相应的web.xml文件应该包含以下 servlet 定义： \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;cxf\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.apache.cxf.transport.servlet.CXFServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;cxf\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/services/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 3.3. 服务配置类 现在让我们看一下服务配置——首先是一个包含 Web 服务端点的 bean 定义的基本框架： @Configuration public class ServiceConfiguration { // Bean definitions } 第一个需要的 bean 是*SpringBus——*它为 Apache CXF 提供扩展以与 Spring 框架一起工作： @Bean public SpringBus springBus() { return new SpringBus(); } 还需要使用SpringBus bean和 Web 服务实现器来创建**EnpointImpl bean 。此 bean 用于在给定的 HTTP 地址发布端点： @Bean public Endpoint endpoint() { EndpointImpl endpoint = new EndpointImpl(springBus(), new DemoImpl()); endpoint.publish(\u0026#34;http://localhost:8080/services/demo\u0026#34;); return endpoint; } DemoImpl类用于实现 Web 服务接口。其定义在下一小节中给出。 或者，我们也可以在 XML 配置文件中声明服务器端点。具体来说，下面的cxf-servlet.xml文件与 3.1 小节中定义的web.xml部署描述符一起使用，并描述了完全相同的端点： \u0026lt;jaxws:endpoint id=\u0026#34;demo\u0026#34; implementor=\u0026#34;com.codingman.cxf.spring.DemoImpl\u0026#34; address=\u0026#34;http://localhost:8080/services/demo\u0026#34; /\u0026gt; 请注意，XML 配置文件以部署描述符中定义的 servlet 名称命名，即cxf。 3.4. 类型定义 接下来——这里是前面小节中已经提到的实现者的定义： @WebService(endpointInterface = \u0026#34;com.codingman.cxf.spring.demo\u0026#34;) public class DemoImpl implements Demo { private int counter; public String hello(String name) { return \u0026#34;Hello \u0026#34; + name + \u0026#34;!\u0026#34;; } public String register(Student student) { counter++; return student.getName() + \u0026#34; is registered student number \u0026#34; + counter; } } 此类为Apache CXF 将包含在已发布的 WSDL 元数据中的Demo端点接口提供了一个实现： @WebService public interface Demo { String hello(String name); String register(Student student); } 端点接口和实现者都使用Student类，定义如下： public class Student { private String name; // constructors, getters and setters } 4. 客户端 Bean 为了利用 Spring 框架，我们在*@Configuration*注解的类中声明一个 bean： @Configuration public class ClientConfiguration { // Bean definitions } 定义了一个名为client的 bean ： @Bean(name = \u0026#34;client\u0026#34;) public Object generateProxy() { return proxyFactoryBean().create(); } 客户端bean 代表Web 服务的代理。它是通过调用JaxWsProxyFactoryBean bean 上的**create方法创建的，这是一个用于创建 JAX-WS 代理的工厂。 JaxWsProxyFactoryBean对象通过以下方法创建和配置： @Bean public JaxWsProxyFactoryBean proxyFactoryBean() { JaxWsProxyFactoryBean proxyFactory = new JaxWsProxyFactoryBean(); proxyFactory.setServiceClass(Demo.class); proxyFactory.setAddress(\u0026#34;http://localhost:8080/services/demo\u0026#34;); return proxyFactory; } 工厂的serviceClass属性表示 Web 服务接口，而address属性表示代理进行远程调用的 URL 地址。 此外，对于客户端的 Spring bean，可以恢复为 XML 配置文件。以下元素声明了与我们上面以编程方式配置的相同的 bean： \u0026lt;bean id=\u0026#34;client\u0026#34; factory-bean=\u0026#34;clientFactory\u0026#34; factory-method=\u0026#34;create\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;clientFactory\u0026#34; class=\u0026#34;org.apache.cxf.jaxws.JaxWsProxyFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;serviceClass\u0026#34; value=\u0026#34;com.codingman.cxf.spring.demo\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;address\u0026#34; value=\u0026#34;http://localhost:8080/services/demo\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 5. 测试用例 本节描述用于说明 Apache CXF 对 Spring 的支持的测试用例。测试用例在名为StudentTest的类中定义。 首先，我们需要从前面提到的ServiceConfiguration配置类中加载一个 Spring 应用上下文，并将其缓存在context字段中： private ApplicationContext context = new AnnotationConfigApplicationContext(ClientConfiguration.class); 接下来，声明服务端点接口的代理并从应用程序上下文加载： private Demo demoProxy = (Demo) context.getBean(\u0026#34;client\u0026#34;); 这个Demo代理将用于下面描述的测试用例。 在第一个测试用例中，我们证明当在代理上本地调用hello方法时，响应与端点**实现者从远程 Web 服务返回的响应完全相同： @Test public void whenUsingHelloMethod_thenCorrect() { String response = demoProxy.hello(\u0026#34;John Bob\u0026#34;); assertEquals(\u0026#34;Hello John Bob!\u0026#34;, response); } 在第二个测试用例中，学生通过在本地调用代理上的register方法注册课程，代理反过来又调用 Web 服务。然后，该远程服务将计算学生人数并将其返回给呼叫者。以下代码片段证实了我们的预期： @Test public void whenUsingRegisterMethod_thenCorrect() { Student student1 = new Student(\u0026#34;Adam\u0026#34;); Student student2 = new Student(\u0026#34;Eve\u0026#34;); String student1Response = demoProxy.register(student1); String student2Response = demoProxy.register(student2); assertEquals(\u0026#34;Adam is registered student number 1\u0026#34;, student1Response); assertEquals(\u0026#34;Eve is registered student number 2\u0026#34;, student2Response); } 6. 集成测试 为了在服务器上部署为 Web 应用程序，需要先将本教程中的代码片段打包到 WAR 文件中。这可以通过在 POM 文件中声明包装属性来实现： \u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt; 打包作业由 Maven WAR 插件实现： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 该插件将编译后的源代码打包成 WAR 文件。由于我们使用 Java 代码配置 servlet 上下文，因此不需要存在传统的web.xml部署描述符。因此，failOnMissingWebXml属性必须设置为false以避免在执行插件时失败。 我们可以通过此链接获取最新版本的 Maven WAR 插件。 为了说明 Web 服务的操作，我们创建了一个集成测试。该测试首先生成 WAR 文件并启动嵌入式服务器，然后让客户端调用 Web 服务，验证后续响应并最终停止服务器。 以下插件需要包含在 Maven POM 文件中。有关更多详细信息，请查看此集成测试教程。 这是 Maven Surefire 插件： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;StudentTest.java\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 这个插件的最新版本可以在这里找到。 声明了一个带有integration id的配置文件部分以方便集成测试： \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;integration\u0026lt;/id\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; ... \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; Maven Cargo 插件包含在集成配置文件中： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.cargo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cargo-maven2-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;container\u0026gt; \u0026lt;containerId\u0026gt;jetty9x\u0026lt;/containerId\u0026gt; \u0026lt;type\u0026gt;embedded\u0026lt;/type\u0026gt; \u0026lt;/container\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;cargo.hostname\u0026gt;localhost\u0026lt;/cargo.hostname\u0026gt; \u0026lt;cargo.servlet.port\u0026gt;8080\u0026lt;/cargo.servlet.port\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;start-server\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;pre-integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;start\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;stop-server\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;post-integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;stop\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 请注意，为了清楚起见，仅包含cargo.hostname和*cargo.servlet.port配置属性。*这些配置属性可以省略而不会对应用程序产生任何影响，因为它们的值与默认值相同。该插件启动服务器，等待连接，最后停止服务器以释放系统资源。 这个链接允许我们查看最新版本的 Maven Cargo 插件。 Maven Surefire 插件在集成配置文件中再次声明，以覆盖其在主构建部分中的配置并执行上一节中描述的测试用例： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;test\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;none\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 现在整个过程可以通过命令运行：mvn -Pintegration clean install。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cxf_with_spring/","tags":["Apache CXF"],"title":"使用 Spring 的 Apache CXF 指南"},{"categories":["REST"],"contents":"1. 概述 本教程将Apache CXF介绍为符合 JAX-RS 标准的框架，该标准定义了 Java 生态系统对 REpresentational State Transfer (REST) 架构模式的支持。 具体来说，它逐步描述了如何构建和发布 RESTful Web 服务，以及如何编写单元测试来验证服务。 这是 Apache CXF 系列的第三篇；第一个侧重于将 CXF 用作完全兼容 JAX-WS 的实现。第二篇文章提供了如何将 CXF 与 Spring 一起使用的指南。 2. Maven依赖  第一个必需的依赖项是org.apache.cxf:cxf- rt -frontend- jaxrs。该工件提供 JAX-RS API 以及 CXF 实现： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-frontend-jaxrs\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在本教程中，我们使用 CXF 创建服务器端点来发布 Web 服务，而不是使用 servlet 容器。因此，需要在 Maven POM 文件中包含以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-transports-http-jetty\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最后，让我们添加 HttpClient 库以方便单元测试： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在这里您可以找到最新版本的cxf-rt-frontend-jaxrs依赖项。您可能还想参考此链接以获取org.apache.cxf:cxf-rt-transports-http-jetty工件的最新版本。最后，可以在这里找到最新版本的 httpclient。 3. 资源类和请求映射 让我们开始实现一个简单的例子；我们将使用两个资源课程和学生来设置我们的 REST API。 我们将从简单开始，然后逐步转向更复杂的示例。 3.1 资源 以下是Student资源类的定义： @XmlRootElement(name = \u0026#34;Student\u0026#34;) public class Student { private int id; private String name; // standard getters and setters  // standard equals and hashCode implementations  } 请注意，我们使用*@XmlRootElement*注释告诉 JAXB 这个类的实例应该被编组为 XML。 接下来是Course资源类的定义： @XmlRootElement(name = \u0026#34;Course\u0026#34;) public class Course { private int id; private String name; private List\u0026lt;Student\u0026gt; students = new ArrayList\u0026lt;\u0026gt;(); private Student findById(int id) { for (Student student : students) { if (student.getId() == id) { return student; } } return null; } // standard getters and setters  // standard equals and hasCode implementations  } 最后，让我们实现*CourseRepository——*它是根资源并作为 Web 服务资源的入口点： @Path(\u0026#34;course\u0026#34;) @Produces(\u0026#34;text/xml\u0026#34;) public class CourseRepository { private Map\u0026lt;Integer, Course\u0026gt; courses = new HashMap\u0026lt;\u0026gt;(); // request handling methods  private Course findById(int id) { for (Map.Entry\u0026lt;Integer, Course\u0026gt; course : courses.entrySet()) { if (course.getKey() == id) { return course.getValue(); } } return null; } } 注意带有@Path注释的映射。CourseRepository是这里的根资源，因此它被映射为处理以course开头的所有 URL 。 @Produces注解的值用于告诉服务器在将此类中的方法返回的对象发送给客户端之前将其转换为 XML 文档。我们在这里使用 JAXB 作为默认值，因为没有指定其他绑定机制。 3.2. 简单的数据设置 因为这是一个简单的示例实现，所以我们使用内存中的数据而不是成熟的持久性解决方案。 考虑到这一点，让我们实现一些简单的设置逻辑来将一些数据填充到系统中： { Student student1 = new Student(); Student student2 = new Student(); student1.setId(1); student1.setName(\u0026#34;Student A\u0026#34;); student2.setId(2); student2.setName(\u0026#34;Student B\u0026#34;); List\u0026lt;Student\u0026gt; course1Students = new ArrayList\u0026lt;\u0026gt;(); course1Students.add(student1); course1Students.add(student2); Course course1 = new Course(); Course course2 = new Course(); course1.setId(1); course1.setName(\u0026#34;REST with Spring\u0026#34;); course1.setStudents(course1Students); course2.setId(2); course2.setName(\u0026#34;Learn Spring Security\u0026#34;); courses.put(1, course1); courses.put(2, course2); } 此类中处理 HTTP 请求的方法将在下一小节中介绍。 3.3. API – 请求映射方法 现在，让我们来看看实际 REST API 的实现。 我们将开始在资源 POJO 中添加 API 操作——使用*@Path*注释。 重要的是要理解这与典型 Spring 项目中的方法有很大不同——API 操作将在控制器中定义，而不是在 POJO 本身上。 让我们从Course类中定义的映射方法开始： @GET @Path(\u0026#34;{studentId}\u0026#34;) public Student getStudent(@PathParam(\u0026#34;studentId\u0026#34;)int studentId) { return findById(studentId); } 简单地说，该方法在处理GET请求时被调用，由*@GET*注解表示。 注意到从 HTTP 请求映射studentId路径参数的简单语法。 然后我们简单地使用findById帮助器方法返回相应的Student实例。 以下方法通过将接收到的Student对象添加到学生列表来处理由*@POST注释指示的POST*请求： @POST @Path(\u0026#34;\u0026#34;) public Response createStudent(Student student) { for (Student element : students) { if (element.getId() == student.getId() { return Response.status(Response.Status.CONFLICT).build(); } } students.add(student); return Response.ok(student).build(); } 如果创建操作成功，则返回200 OK响应，如果具有提交id的对象已经存在，则返回409 Conflict 。 另请注意，我们可以跳过*@Path*注释，因为它的值是一个空字符串。 最后一个方法处理DELETE请求。它从学生列表中删除一个元素，其id是接收到的路径参数，并返回一个OK (200) 状态的响应。如果没有与指定id关联的元素，这意味着没有要删除的内容，则此方法返回Not Found (404) 状态的响应： @DELETE @Path(\u0026#34;{studentId}\u0026#34;) public Response deleteStudent(@PathParam(\u0026#34;studentId\u0026#34;) int studentId) { Student student = findById(studentId); if (student == null) { return Response.status(Response.Status.NOT_FOUND).build(); } students.remove(student); return Response.ok().build(); } 让我们继续请求CourseRepository类的映射方法。 以下getCourse方法返回Course对象，该对象是**课程映射中条目的值，其键是接收到的GET请求的courseId路径参数。在内部，该方法将路径参数分派给findById辅助方法以完成其工作。 @GET @Path(\u0026#34;courses/{courseId}\u0026#34;) public Course getCourse(@PathParam(\u0026#34;courseId\u0026#34;) int courseId) { return findById(courseId); } 以下方法更新课程地图的现有条目，其中接收到的PUT请求的正文是条目值，courseId参数是关联的键： @PUT @Path(\u0026#34;courses/{courseId}\u0026#34;) public Response updateCourse(@PathParam(\u0026#34;courseId\u0026#34;) int courseId, Course course) { Course existingCourse = findById(courseId); if (existingCourse == null) { return Response.status(Response.Status.NOT_FOUND).build(); } if (existingCourse.equals(course)) { return Response.notModified().build(); } courses.put(courseId, course); return Response.ok().build(); } 如果更新成功，则此updateCourse方法返回OK (200) 状态的响应，不更改任何内容，如果现有对象和上传的对象具有相同的字段值，则返回Not Modified (304) 响应。如果在课程地图中找不到具有给定ID的**课程实例，该方法将返回具有未找到(404) 状态的响应。 这个根资源类的第三种方法不直接处理任何 HTTP 请求。相反，它将请求委托给Course类，其中请求由匹配方法处理： @Path(\u0026#34;courses/{courseId}/students\u0026#34;) public Course pathToStudent(@PathParam(\u0026#34;courseId\u0026#34;) int courseId) { return findById(courseId); } 我们已经在Course类中展示了之前处理委托请求的方法。 4.服务器端点 本节重点介绍 CXF 服务器的构建，该服务器用于发布 RESTful Web 服务，其资源已在上一节中描述。第一步是实例化一个JAXRSServerFactoryBean对象并设置根资源类： JAXRSServerFactoryBean factoryBean = new JAXRSServerFactoryBean(); factoryBean.setResourceClasses(CourseRepository.class); 然后需要在工厂 bean 上设置资源提供者来管理根资源类的生命周期。我们使用默认的单例资源提供程序，它为每个请求返回相同的资源实例： factoryBean.setResourceProvider( new SingletonResourceProvider(new CourseRepository())); 我们还设置了一个地址来指示发布 Web 服务的 URL： factoryBean.setAddress(\u0026#34;http://localhost:8080/\u0026#34;); 现在可以使用factoryBean创建一个新**服务器，该服务器将开始侦听传入连接： Server server = factoryBean.create(); 本节上面的所有代码都应该包装在main方法中： public class RestfulServer { public static void main(String args[]) throws Exception { // code snippets shown above  } } 该main方法的调用在第 6 节中介绍。 5. 测试用例 本节介绍用于验证我们之前创建的 Web 服务的测试用例。这些测试在响应四种最常用方法的 HTTP 请求后验证服务的资源状态，即GET、POST、PUT和DELETE。 5.1。准备 首先，在测试类中声明了两个静态字段，命名为RestfulTest： private static String BASE_URL = \u0026#34;http://localhost:8080/\u0026#34;; private static CloseableHttpClient client; 在运行测试之前，我们创建一个客户端对象，用于与服务器通信并在之后销毁它： @BeforeClass public static void createClient() { client = HttpClients.createDefault(); } @AfterClass public static void closeClient() throws IOException { client.close(); } 客户端实例现在已准备好供测试用例使用。 5.2. 获取请求 在测试类中，我们定义了两种方法来向运行 Web 服务的服务器发送GET请求。 第一种方法是根据资源中的ID获取**Course实例： private Course getCourse(int courseOrder) throws IOException { URL url = new URL(BASE_URL + courseOrder); InputStream input = url.openStream(); Course course = JAXB.unmarshal(new InputStreamReader(input), Course.class); return course; } 第二种是在给定资源中课程和学生的id的情况下获取**Student实例： private Student getStudent(int courseOrder, int studentOrder) throws IOException { URL url = new URL(BASE_URL + courseOrder + \u0026#34;/students/\u0026#34; + studentOrder); InputStream input = url.openStream(); Student student = JAXB.unmarshal(new InputStreamReader(input), Student.class); return student; } 这些方法将 HTTP GET请求发送到服务资源，然后将 XML 响应解组到相应类的实例。两者都用于在执行POST、PUT和DELETE请求后验证服务资源状态。 5.3. POST请求 本小节介绍了POST请求的两个测试用例，说明了上传的Student实例导致冲突以及成功创建时Web 服务的操作。 在第一个测试中，我们使用了一个从conflict_student.xml文件中解组的**Student对象，该文件位于类路径中，内容如下： \u0026lt;Student\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student B\u0026lt;/name\u0026gt; \u0026lt;/Student\u0026gt; 这是将该内容转换为POST请求正文的方式： HttpPost httpPost = new HttpPost(BASE_URL + \u0026#34;1/students\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;conflict_student.xml\u0026#34;); httpPost.setEntity(new InputStreamEntity(resourceStream)); 设置Content-Type标头是为了告诉服务器请求的内容类型是 XML： httpPost.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); 由于上传的Student对象已经存在于第一个Course实例中，我们希望创建失败并返回一个带有Conflict (409) 状态的响应。以下代码片段验证了预期： HttpResponse response = client.execute(httpPost); assertEquals(409, response.getStatusLine().getStatusCode()); 在下一个测试中，我们从名为created_student.xml的文件中提取 HTTP 请求的主体，该文件也在类路径中。这是文件的内容： \u0026lt;Student\u0026gt; \u0026lt;id\u0026gt;3\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student C\u0026lt;/name\u0026gt; \u0026lt;/Student\u0026gt; 与前面的测试用例类似，我们构建并执行一个请求，然后验证是否成功创建了一个新实例： HttpPost httpPost = new HttpPost(BASE_URL + \u0026#34;2/students\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;created_student.xml\u0026#34;); httpPost.setEntity(new InputStreamEntity(resourceStream)); httpPost.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); HttpResponse response = client.execute(httpPost); assertEquals(200, response.getStatusLine().getStatusCode()); 我们可以确认 Web 服务资源的新状态： Student student = getStudent(2, 3); assertEquals(3, student.getId()); assertEquals(\u0026#34;Student C\u0026#34;, student.getName()); 这是对新Student对象请求的 XML 响应如下所示： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;Student\u0026gt; \u0026lt;id\u0026gt;3\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student C\u0026lt;/name\u0026gt; \u0026lt;/Student\u0026gt; 5.4. PUT请求 让我们从一个无效的更新请求开始，其中正在更新的Course对象不存在。以下是用于替换Web 服务资源中不存在的Course对象的实例内容： \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;3\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Apache CXF Support for RESTful\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 该内容存储在类路径上名为non_existent_course.xml的文件中。它被提取，然后通过以下代码用于填充PUT请求的主体： HttpPut httpPut = new HttpPut(BASE_URL + \u0026#34;3\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;non_existent_course.xml\u0026#34;); httpPut.setEntity(new InputStreamEntity(resourceStream)); 设置Content-Type标头是为了告诉服务器请求的内容类型是 XML： httpPut.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); 由于我们故意发送无效请求来更新不存在的对象，因此预计会收到*Not Found (404) 响应。*响应已验证： HttpResponse response = client.execute(httpPut); assertEquals(404, response.getStatusLine().getStatusCode()); 在PUT请求的第二个测试用例中，我们提交了一个具有相同字段值的Course对象。由于在这种情况下没有任何更改，我们希望返回未修改(304) 状态的响应。整个过程如图： HttpPut httpPut = new HttpPut(BASE_URL + \u0026#34;1\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;unchanged_course.xml\u0026#34;); httpPut.setEntity(new InputStreamEntity(resourceStream)); httpPut.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); HttpResponse response = client.execute(httpPut); assertEquals(304, response.getStatusLine().getStatusCode()); 其中未更改的课程.xml 是类路径上保存用于更新的信息的文件。这是它的内容： \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;1\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;REST with Spring\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 在PUT请求的最后一个演示中，我们执行了一个有效的更新。以下是changed_course.xml文件的内容，其内容用于更新 Web 服务资源中的Course实例： \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Apache CXF Support for RESTful\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 这是构建和执行请求的方式： HttpPut httpPut = new HttpPut(BASE_URL + \u0026#34;2\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;changed_course.xml\u0026#34;); httpPut.setEntity(new InputStreamEntity(resourceStream)); httpPut.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); 让我们验证对服务器的PUT请求并验证成功上传： HttpResponse response = client.execute(httpPut); assertEquals(200, response.getStatusLine().getStatusCode()); 让我们验证 Web 服务资源的新状态： Course course = getCourse(2); assertEquals(2, course.getId()); assertEquals(\u0026#34;Apache CXF Support for RESTful\u0026#34;, course.getName()); 以下代码片段显示了发送对先前上传的Course对象的 GET 请求时 XML 响应的内容： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Apache CXF Support for RESTful\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 5.5. 删除请求 首先，让我们尝试删除一个不存在的Student实例。操作应该会失败，并且会出现Not Found (404) 状态的相应响应： HttpDelete httpDelete = new HttpDelete(BASE_URL + \u0026#34;1/students/3\u0026#34;); HttpResponse response = client.execute(httpDelete); assertEquals(404, response.getStatusLine().getStatusCode()); 在DELETE请求的第二个测试用例中，我们创建、执行和验证请求： HttpDelete httpDelete = new HttpDelete(BASE_URL + \u0026#34;1/students/1\u0026#34;); HttpResponse response = client.execute(httpDelete); assertEquals(200, response.getStatusLine().getStatusCode()); 我们使用以下代码片段验证 Web 服务资源的新状态： Course course = getCourse(1); assertEquals(1, course.getStudents().size()); assertEquals(2, course.getStudents().get(0).getId()); assertEquals(\u0026#34;Student B\u0026#34;, course.getStudents().get(0).getName()); 接下来，我们列出在请求Web 服务资源中的第一个Course对象后收到的 XML 响应： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;1\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;REST with Spring\u0026lt;/name\u0026gt; \u0026lt;students\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student B\u0026lt;/name\u0026gt; \u0026lt;/students\u0026gt; \u0026lt;/Course\u0026gt; 很明显，第一个Student已成功移除。 6. 测试执行 第 4 节描述了如何在RestfulServer类的main方法中创建和销毁一个Server实例。 使服务器启动并运行的最后一步是调用该main方法。为了实现这一点，在 Maven POM 文件中包含并配置了 Exec Maven 插件： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.mojo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;exec-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0\u0026lt;version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt; com.codingman.cxf.jaxrs.implementation.RestfulServer \u0026lt;/mainClass\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 这个插件的最新版本可以通过这个链接找到。 在编译和打包本教程中说明的工件的过程中，Maven Surefire 插件会自动执行包含在名称以 Test 开头或结尾的类中的所有测试。如果是这种情况，则应将插件配置为排除这些测试： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/ServiceTest\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 使用上述配置，ServiceTest被排除在外，因为它是测试类的名称。您可以为该类选择任何名称，前提是其中包含的测试在服务器准备好连接之前不由 Maven Surefire 插件运行。 有关最新版本的 Maven Surefire 插件，请查看此处。 现在您可以执行exec:java目标来启动 RESTful Web 服务服务器，然后使用 IDE 运行上述测试。等效地，您可以通过在终端中执行命令mvn -Dtest=ServiceTest test来开始测试。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cxf_rest_api/","tags":["Apache CXF"],"title":"Apache CXF 对 RESTful Web 服务的支持"},{"categories":["Cloud","DevOps"],"contents":"1. 简介 Apache Curator是 Apache Zookeeper 的 Java 客户端，Apache Zookeeper是分布式应用程序的流行协调服务。 在本教程中，我们将介绍 Curator 提供的一些最相关的功能：  连接管理——管理连接和重试策略 异步——通过添加异步功能和使用 Java 8 lambda 来增强现有客户端 配置管理——对系统进行集中配置 强类型模型——使用类型模型 食谱——实现领导者选举、分布式锁或计数器  2. 先决条件 首先，建议快速了解一下Apache Zookeeper及其功能。 对于本教程，我们假设已经有一个独立的 Zookeeper 实例在127.0.0.1:2181上运行；如果您刚刚开始，这里有关于如何安装和运行它的说明。 首先，我们需要将curator-x-async依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-x-async\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.1\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本的 Apache Curator 4.XX 与 Zookeeper 3.5.X 存在硬依赖关系，目前仍处于测试阶段。 因此，在本文中，我们将使用当前最新的稳定版 Zookeeper 3.4.11。 所以我们需要排除 Zookeeper 依赖，并将Zookeeper 版本的依赖添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 有关兼容性的更多信息，请参阅此链接。 3. 连接管理 Apache Curator 的基本用例是连接到正在运行的 Apache Zookeeper 实例。 该工具提供了一个工厂来使用重试策略建立与 Zookeeper 的连接： int sleepMsBetweenRetries = 100; int maxRetries = 3; RetryPolicy retryPolicy = new RetryNTimes( maxRetries, sleepMsBetweenRetries); CuratorFramework client = CuratorFrameworkFactory .newClient(\u0026#34;127.0.0.1:2181\u0026#34;, retryPolicy); client.start(); assertThat(client.checkExists().forPath(\u0026#34;/\u0026#34;)).isNotNull(); 在这个快速示例中，我们将重试 3 次，并在重试之间等待 100 毫秒，以防出现连接问题。 使用CuratorFramework客户端连接到 Zookeeper后，我们现在可以浏览路径、获取/设置数据并与服务器进行交互。 4.异步 Curator Async 模块包装了上述CuratorFramework客户端，以使用CompletionStage Java 8 API提供非阻塞功能。 让我们看看前面的示例如何使用 Async 包装器： int sleepMsBetweenRetries = 100; int maxRetries = 3; RetryPolicy retryPolicy = new RetryNTimes(maxRetries, sleepMsBetweenRetries); CuratorFramework client = CuratorFrameworkFactory .newClient(\u0026#34;127.0.0.1:2181\u0026#34;, retryPolicy); client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); AtomicBoolean exists = new AtomicBoolean(false); async.checkExists() .forPath(\u0026#34;/\u0026#34;) .thenAcceptAsync(s -\u0026gt; exists.set(s != null)); await().until(() -\u0026gt; assertThat(exists.get()).isTrue()); 现在，*checkExists()操作在异步模式下工作，不会阻塞主线程。我们还可以使用thenAcceptAsync()*方法一个接一个地链接操作，该方法使用CompletionStage API。 5. 配置管理 在分布式环境中，最常见的挑战之一是管理许多应用程序之间的共享配置。我们可以使用 Zookeeper 作为数据存储来保存我们的配置。 让我们看一个使用 Apache Curator 获取和设置数据的示例： CuratorFramework client = newClient(); client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); String key = getKey(); String expected = \u0026#34;my_value\u0026#34;; client.create().forPath(key); async.setData() .forPath(key, expected.getBytes()); AtomicBoolean isEquals = new AtomicBoolean(); async.getData() .forPath(key) .thenAccept(data -\u0026gt; isEquals.set(new String(data).equals(expected))); await().until(() -\u0026gt; assertThat(isEquals.get()).isTrue()); 在这个例子中，我们创建节点路径，在 Zookeeper 中设置数据，然后我们检查它的值是否相同来恢复它。关键字段可以是像*/config/dev/my_key*这样的节点路径。 5.1 观察者 Zookeeper 中另一个有趣的特性是能够监视键或节点。它允许我们监听配置的变化并更新我们的应用程序，而无需重新部署. 让我们看看上面的例子在使用 watchers 时的样子： CuratorFramework client = newClient() client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); String key = getKey(); String expected = \u0026#34;my_value\u0026#34;; async.create().forPath(key); List\u0026lt;String\u0026gt; changes = new ArrayList\u0026lt;\u0026gt;(); async.watched() .getData() .forPath(key) .event() .thenAccept(watchedEvent -\u0026gt; { try { changes.add(new String(client.getData() .forPath(watchedEvent.getPath()))); } catch (Exception e) { // fail ...  }}); // Set data value for our key async.setData() .forPath(key, expected.getBytes()); await() .until(() -\u0026gt; assertThat(changes.size()).isEqualTo(1)); 我们配置观察者，设置数据，然后确认被观察事件被触发。我们可以一次观察一个节点或一组节点。 6. 强类型模型 Zookeeper 主要处理字节数组，所以我们需要对我们的数据进行序列化和反序列化。这使我们能够灵活地处理任何可序列化的实例，但它可能难以维护。 为了在这里提供帮助，Curator 添加了类型化模型的概念，它委托序列化/反序列化并允许我们直接使用我们的类型。让我们看看它是如何工作的。 首先，我们需要一个序列化器框架。Curator 建议使用 Jackson 实现，所以让我们将Jackson 依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.13.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在，让我们尝试持久化我们的自定义类HostConfig： public class HostConfig { private String hostname; private int port; // getters and setters } 我们需要提供从HostConfig类到路径的模型规范映射，并使用 Apache Curator 提供的建模框架包装器： ModelSpec\u0026lt;HostConfig\u0026gt; mySpec = ModelSpec.builder( ZPath.parseWithIds(\u0026#34;/config/dev\u0026#34;), JacksonModelSerializer.build(HostConfig.class)) .build(); CuratorFramework client = newClient(); client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); ModeledFramework\u0026lt;HostConfig\u0026gt; modeledClient = ModeledFramework.wrap(async, mySpec); modeledClient.set(new HostConfig(\u0026#34;host-name\u0026#34;, 8080)); modeledClient.read() .whenComplete((value, e) -\u0026gt; { if (e != null) { fail(\u0026#34;Cannot read host config\u0026#34;, e); } else { assertThat(value).isNotNull(); assertThat(value.getHostname()).isEqualTo(\u0026#34;host-name\u0026#34;); assertThat(value.getPort()).isEqualTo(8080); } }); 读取路径*/config/dev时的whenComplete()方法将返回 Zookeeper 中的HostConfig*实例。 7. recipes Zookeeper 提供此指南来实现高级解决方案或配方，例如领导者选举、分布式锁或共享计数器。 Apache Curator 为大多数这些配方提供了一个实现。要查看完整列表，请访问文档。 所有这些recipes都在一个单独的模块中可用： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 让我们直接进入并通过一些简单的例子开始理解这些。 7.1 领袖选举 在分布式环境中，我们可能需要一个主节点或领导节点来协调一项复杂的工作。 这是Curator中领导人选举配方的用法： CuratorFramework client = newClient(); client.start(); LeaderSelector leaderSelector = new LeaderSelector(client, \u0026#34;/mutex/select/leader/for/job/A\u0026#34;, new LeaderSelectorListener() { @Override public void stateChanged( CuratorFramework client, ConnectionState newState) { } @Override public void takeLeadership( CuratorFramework client) throws Exception { } }); // join the members group leaderSelector.start(); // wait until the job A is done among all members leaderSelector.close(); 当我们启动领导者选择器时，我们的节点会加入路径*/mutex/select/leader/for/job/A中的成员组。一旦我们的节点成为领导者，将调用takeLeadership*方法，我们作为领导者可以恢复工作。 7.2. 共享锁 共享锁配方是关于拥有一个完全分布式的锁： CuratorFramework client = newClient(); client.start(); InterProcessSemaphoreMutex sharedLock = new InterProcessSemaphoreMutex( client, \u0026#34;/mutex/process/A\u0026#34;); sharedLock.acquire(); // do process A  sharedLock.release(); 当我们获取锁时，Zookeeper 确保没有其他应用程序同时获取相同的锁。 7.3. 计数器 Counters 配方在所有客户端之间协调一个共享的Integer ： CuratorFramework client = newClient(); client.start(); SharedCount counter = new SharedCount(client, \u0026#34;/counters/A\u0026#34;, 0); counter.start(); counter.setCount(counter.getCount() + 1); assertThat(counter.getCount()).isEqualTo(1); 在此示例中，Zookeeper 将Integer值存储在路径*/counters/A中，如果尚未创建路径，则将该值初始化为0* 。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_curator/","tags":[],"title":"Apache Curator 简介"},{"categories":["Data"],"contents":"1. 简介 在本教程中，我们将 使用示例数据处理应用程序演示Apache Crunch 。我们将使用MapReduce框架运行这个应用程序。 我们将首先简要介绍一些 Apache Crunch 概念。然后我们将进入一个示例应用程序。在这个应用程序中，我们将进行文本处理：  首先，我们将从文本文件中读取行 稍后，我们将它们拆分为单词并删除一些常用单词 然后，我们将剩余的单词分组以获得唯一单词列表及其计数 最后，我们将此列表写入文本文件  2. 什么是MapReduce？ MapReduce 是一种分布式并行编程框架，用于在服务器集群上处理大量数据。Hadoop 和 Spark 等软件框架实现了 MapReduce。 **Crunch 提供了一个框架，用于在 Java 中编写、测试和运行 MapReduce 管道。**在这里，我们不直接编写 MapReduce 作业。相反，我们使用 Crunch API 定义数据管道（即执行输入、处理和输出步骤的操作）。Crunch Planner 将它们映射到 MapReduce 作业并在需要时执行它们。 **因此，每个 Crunch 数据管道都由Pipeline接口的一个实例进行协调。该接口还定义了通过Source实例将数据读入管道以及将数据从管道写入Target实例的方法。 我们有 3 个接口来表示数据：  PCollection – 不可变的分布式元素集合 PTable\u0026lt;K , V \u0026gt; – 一个不可变的、分布式的、无序的键和值的多映射 PGroupedTable\u0026lt;K , V \u0026gt; – K 类型键到可迭代 V的分布式排序映射，可仅迭代一次  ** DoFn是所有数据处理函数的基类**。它对应 于 MapReduce中的Mapper、 Reducer 和 Combiner类。我们将大部分开发时间用于编写和测试使用它的逻辑计算。 现在我们对 Crunch 更加熟悉了，让我们使用它来构建示例应用程序。 3. 建立一个 Crunch 项目 首先，让我们用 Maven 建立一个 Crunch 项目。我们可以通过两种方式做到这一点：  在现有项目的pom.xml文件中添加所需的依赖项 使用原型生成启动项目  让我们快速浏览一下这两种方法。 3.1 Maven 依赖项 为了将 Crunch 添加到现有项目，让我们在 pom.xml文件中添加所需的依赖项。 首先，让我们添加crunch-core库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.crunch\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;crunch-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，让我们添加hadoop-client库来与 Hadoop 通信。我们使用匹配Hadoop安装的版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.hadoop\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hadoop-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 我们可以查看 Maven Central 以获取最新版本的crunch-core和hadoop-client库。 3.2. Maven 原型 另一种方法是使用 Crunch 提供的 Maven 原型快速生成一个入门项目： mvn archetype:generate -Dfilter=org.apache.crunch:crunch-archetype 当上述命令提示时，我们提供 Crunch 版本和项目工件详细信息。 4. 紧缩管道设置 设置好项目后，我们需要创建一个Pipeline对象。 Crunch 有 3 个Pipeline实现：  MRPipeline – 在 Hadoop MapReduce 中执行 SparkPipeline – 作为一系列 Spark 管道执行 MemPipeline – 在客户端内存中执行，对单元测试很有用  通常，我们使用MemPipeline的实例进行开发和测试。稍后我们使用MRPipeline或SparkPipeline的实例进行实际执行。 如果我们需要一个内存管道，我们可以使用静态方法getInstance来获取MemPipeline实例： Pipeline pipeline = MemPipeline.getInstance(); 但是现在，让我们创建一个MRPipeline实例 来使用 Hadoop 执行应用程序*：* Pipeline pipeline = new MRPipeline(WordCount.class, getConf()); 5. 读取输入数据 创建管道对象后，我们要读取输入数据。 ** Pipeline接口提供了一种从文本文件读取输入的便捷方法**， 即 readTextFile(pathName)。 让我们调用这个方法来读取输入文本文件： PCollection\u0026lt;String\u0026gt; lines = pipeline.readTextFile(inputPath); 上面的代码将文本文件读取为String的集合。 下一步，让我们编写一个读取输入的测试用例： @Test public void givenPipeLine_whenTextFileRead_thenExpectedNumberOfRecordsRead() { Pipeline pipeline = MemPipeline.getInstance(); PCollection\u0026lt;String\u0026gt; lines = pipeline.readTextFile(INPUT_FILE_PATH); assertEquals(21, lines.asCollection() .getValue() .size()); } 在这个测试中，我们验证我们在读取文本文件时获得了预期的行数。 6. 数据处理步骤 读取输入数据后，我们需要对其进行处理。 Crunch API 包含许多 DoFn的子类来处理常见的数据处理场景：  FilterFn – 根据布尔条件过滤集合成员 MapFn – 将每个输入记录映射到一个输出记录 CombineFn – 将多个值组合成一个值 JoinFn – 执行连接，例如内连接、左外连接、右外连接和完全外连接  让我们通过使用这些类来实现以下数据处理逻辑：  将输入文件中的每一行拆分为单词 删除停用词 计算唯一的单词  6.1 将一行文本拆分为单词 首先，让我们创建Tokenizer类来将一行拆分为单词。 我们将扩展 DoFn 类。这个类有一个叫做process的抽象方法。此方法处理来自PCollection的输入记录并将输出发送到Emitter。 我们需要在这个方法中实现拆分逻辑： public class Tokenizer extends DoFn\u0026lt;String, String\u0026gt; { private static final Splitter SPLITTER = Splitter .onPattern(\u0026#34;\\\\s+\u0026#34;) .omitEmptyStrings(); @Override public void process(String line, Emitter\u0026lt;String\u0026gt; emitter) { for (String word : SPLITTER.split(line)) { emitter.emit(word); } } } 在上面的实现中，我们使用了Guava库中的Splitter类从一行中提取单词。 接下来，让我们为Tokenizer类编写一个单元测试 ： @RunWith(MockitoJUnitRunner.class) public class TokenizerUnitTest { @Mock private Emitter\u0026lt;String\u0026gt; emitter; @Test public void givenTokenizer_whenLineProcessed_thenOnlyExpectedWordsEmitted() { Tokenizer splitter = new Tokenizer(); splitter.process(\u0026#34; hello world \u0026#34;, emitter); verify(emitter).emit(\u0026#34;hello\u0026#34;); verify(emitter).emit(\u0026#34;world\u0026#34;); verifyNoMoreInteractions(emitter); } } 上面的测试验证是否返回了正确的单词。 最后，让我们使用这个类分割从输入文本文件中读取的行。 PCollection接口的parallelDo方法将给定的DoFn应用于所有元素并返回一个新的PCollection。** 让我们在 lines 集合上调用这个方法并传递一个Tokenizer的实例： PCollection\u0026lt;String\u0026gt; words = lines.parallelDo(new Tokenizer(), Writables.strings()); 结果，我们得到了输入文本文件中的单词列表。我们将在下一步中删除停用词。 6.2. 删除停用词 与上一步类似，让我们创建一个StopWordFilter类来过滤掉停用词。 但是，我们将扩展 FilterFn而不是DoFn。FilterFn有一个名为**accept的抽象方法。我们需要在这个方法中实现过滤逻辑： public class StopWordFilter extends FilterFn\u0026lt;String\u0026gt; { // English stop words, borrowed from Lucene.  private static final Set\u0026lt;String\u0026gt; STOP_WORDS = ImmutableSet .copyOf(new String[] { \u0026#34;a\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;are\u0026#34;, \u0026#34;as\u0026#34;, \u0026#34;at\u0026#34;, \u0026#34;be\u0026#34;, \u0026#34;but\u0026#34;, \u0026#34;by\u0026#34;, \u0026#34;for\u0026#34;, \u0026#34;if\u0026#34;, \u0026#34;in\u0026#34;, \u0026#34;into\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;it\u0026#34;, \u0026#34;no\u0026#34;, \u0026#34;not\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;on\u0026#34;, \u0026#34;or\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;such\u0026#34;, \u0026#34;t\u0026#34;, \u0026#34;that\u0026#34;, \u0026#34;the\u0026#34;, \u0026#34;their\u0026#34;, \u0026#34;then\u0026#34;, \u0026#34;there\u0026#34;, \u0026#34;these\u0026#34;, \u0026#34;they\u0026#34;, \u0026#34;this\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;was\u0026#34;, \u0026#34;will\u0026#34;, \u0026#34;with\u0026#34; }); @Override public boolean accept(String word) { return !STOP_WORDS.contains(word); } } 接下来，让我们编写StopWordFilter类的单元测试： public class StopWordFilterUnitTest { @Test public void givenFilter_whenStopWordPassed_thenFalseReturned() { FilterFn\u0026lt;String\u0026gt; filter = new StopWordFilter(); assertFalse(filter.accept(\u0026#34;the\u0026#34;)); assertFalse(filter.accept(\u0026#34;a\u0026#34;)); } @Test public void givenFilter_whenNonStopWordPassed_thenTrueReturned() { FilterFn\u0026lt;String\u0026gt; filter = new StopWordFilter(); assertTrue(filter.accept(\u0026#34;Hello\u0026#34;)); assertTrue(filter.accept(\u0026#34;World\u0026#34;)); } @Test public void givenWordCollection_whenFiltered_thenStopWordsRemoved() { PCollection\u0026lt;String\u0026gt; words = MemPipeline .collectionOf(\u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;sentence\u0026#34;); PCollection\u0026lt;String\u0026gt; noStopWords = words.filter(new StopWordFilter()); assertEquals(ImmutableList.of(\u0026#34;This\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;sentence\u0026#34;), Lists.newArrayList(noStopWords.materialize())); } } 此测试验证过滤逻辑是否正确执行。 最后，让我们使用StopWordFilter来过滤上一步生成的单词列表。 PCollection接口的filter方法将给定的FilterFn应用于所有元素并返回一个新的PCollection。 让我们在 words 集合上调用这个方法并传递一个StopWordFilter的实例： PCollection\u0026lt;String\u0026gt; noStopWords = words.filter(new StopWordFilter()); 结果，我们得到了过滤后的单词集合。 6.3. 计算唯一单词 在获得过滤后的单词集合后，我们要计算每个单词出现的频率。 PCollection接口有许多方法来执行常见的聚合：  min – 返回集合的最小元素 max – 返回集合的最大元素 length – 返回集合中元素的数量 count – 返回一个PTable，其中包含集合中每个唯一元素的计数  让我们使用count方法来获取唯一单词及其计数： // The count method applies a series of Crunch primitives and returns // a map of the unique words in the input PCollection to their counts. PTable\u0026lt;String, Long\u0026gt; counts = noStopWords.count(); 7. 指定输出 作为前面步骤的结果，我们有一个单词表和它们的计数。我们想将此结果写入文本文件。 Pipeline接口提供了方便****的 方法来编写输出： void write(PCollection\u0026lt;?\u0026gt; collection, Target target); void write(PCollection\u0026lt;?\u0026gt; collection, Target target, Target.WriteMode writeMode); \u0026lt;T\u0026gt; void writeTextFile(PCollection\u0026lt;T\u0026gt; collection, String pathName); 因此，让我们调用 writeTextFile方法： pipeline.writeTextFile(counts, outputPath); 8. 管理管道执行 到目前为止，所有步骤都刚刚定义了数据管道。未读取或处理任何输入。这是因为 Crunch 使用了惰性执行模型。 在 Pipeline 接口上调用控制作业计划和执行的方法之前，它不会运行 MapReduce 作业：  run - 准备一个执行计划来创建所需的输出，然后同步执行它 完成- 运行生成输出所需的任何剩余作业，然后清理创建的任何中间数据文件 runAsync - 类似于 run 方法，但以非阻塞方式执行  因此，让我们调用done方法将管道作为 MapReduce 作业执行： PipelineResult result = pipeline.done(); 上面的语句运行 MapReduce 作业以读取输入、处理它们并将结果写入输出目录。 9. 整合管道 到目前为止，我们已经开发并单元测试了读取输入数据、处理它并写入输出文件的逻辑。 接下来，让我们将它们放在一起构建整个数据管道： public int run(String[] args) throws Exception { String inputPath = args[0]; String outputPath = args[1]; // Create an object to coordinate pipeline creation and execution.  Pipeline pipeline = new MRPipeline(WordCount.class, getConf()); // Reference a given text file as a collection of Strings.  PCollection\u0026lt;String\u0026gt; lines = pipeline.readTextFile(inputPath); // Define a function that splits each line in a PCollection of Strings into  // a PCollection made up of the individual words in the file.  // The second argument sets the serialization format.  PCollection\u0026lt;String\u0026gt; words = lines.parallelDo(new Tokenizer(), Writables.strings()); // Take the collection of words and remove known stop words.  PCollection\u0026lt;String\u0026gt; noStopWords = words.filter(new StopWordFilter()); // The count method applies a series of Crunch primitives and returns  // a map of the unique words in the input PCollection to their counts.  PTable\u0026lt;String, Long\u0026gt; counts = noStopWords.count(); // Instruct the pipeline to write the resulting counts to a text file.  pipeline.writeTextFile(counts, outputPath); // Execute the pipeline as a MapReduce.  PipelineResult result = pipeline.done(); return result.succeeded() ? 0 : 1; } 10. Hadoop 启动配置 数据管道因此准备就绪。 但是，我们需要代码来启动它。因此，让我们编写启动应用程序的main方法： public class WordCount extends Configured implements Tool { public static void main(String[] args) throws Exception { ToolRunner.run(new Configuration(), new WordCount(), args); } ToolRunner.run 从命令行 解析 Hadoop 配置并执行 MapReduce 作业。 11. 运行应用程序 完整的应用程序现已准备就绪。让我们运行以下命令来构建它： mvn package 作为上述命令的结果，我们在目标目录中获得了打包的应用程序和一个特殊的作业 jar。 让我们使用这个作业 jar 在 Hadoop 上执行应用程序： hadoop jar target/crunch-1.0-SNAPSHOT-job.jar \u0026lt;input file path\u0026gt; \u0026lt;output directory\u0026gt; 应用程序读取输入文件并将结果写入输出文件。输出文件包含唯一单词及其计数，类似于以下内容： [Add,1] [Added,1] [Admiration,1] [Admitting,1] [Allowance,1] 除了 Hadoop，我们还可以在 IDE 中运行应用程序，作为独立应用程序或单元测试。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_crunch/","tags":[],"title":"Apache Crunch 指南"},{"categories":["Java Collections"],"contents":"1. 概述 在本文中，我们将探索 Apache Commons Collections 库的SetUtils API。简而言之，这些实用程序可用于对Java 中的Set数据结构执行某些操作。 2. 依赖安装 为了让我们在项目中使用SetUtils库，我们需要在项目的pom.xml文件中添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 或者，如果我们的项目是基于 Gradle 的，我们应该将依赖项添加到项目的build.gradle文件中。此外，我们需要将mavenCentral()添加到**build.gradle文件的存储库部分： compile \u0026#39;org.apache.commons:commons-collections4:4.1\u0026#39; 3. SetUtils SetUtils库的predicatedSet()方法允许定义要插入到集合中的所有元素应满足的条件。它接受一个源Set对象和一个谓词。 我们可以使用它来轻松验证Set的所有元素是否满足特定条件，这在开发第三方库/API 时会很方便。 如果任何元素的验证失败，将抛出IllegalArgumentException 。下面的代码段防止将 不以 \u0026lsquo;L\u0026rsquo; 开头的字符串添加到sourceSet或返回的验证集中： Set\u0026lt;String\u0026gt; validatingSet = SetUtils.predicatedSet(sourceSet, s -\u0026gt; s.startsWith(\u0026#34;L\u0026#34;)); 该库还具有predicatedSortedSet()和predicatedNavigableSet()分别用于处理SortedSet和NavigableSet。 4. 集合的并集、差集和交集 该库具有可以计算集合元素的并集、差集和交集的方法。 difference()方法接受两个Set对象并返回一个不可变的SetUtils 。**设置视图对象。返回的SetUtils。**SetView包含在 set a但不在 set b中的元素： Set\u0026lt;Integer\u0026gt; a = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 5)); Set\u0026lt;Integer\u0026gt; b = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2)); SetUtils.SetView\u0026lt;Integer\u0026gt; result = SetUtils.difference(a, b); assertTrue(result.size() == 1 \u0026amp;\u0026amp; result.contains(5)); 请注意，尝试在返回的SetUtils 上执行写操作，如add()或addAll() 。**SetView将抛出UnsupportedOperationException。 要修改返回的结果，我们需要调用返回的SetUtils的toSet()方法。**SetView获取一个可写的Set对象： Set\u0026lt;Integer\u0026gt; mutableSet = result.toSet(); SetUtils库的union方法完全符合它的意思——它返回集合a和b的所有元素。union方法还返回一个不可变的SetUtil.SetView对象： Set\u0026lt;Integer\u0026gt; expected = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 5)); SetUtils.SetView\u0026lt;Integer\u0026gt; union = SetUtils.union(a, b); assertTrue(SetUtils.isEqualSet(expected, union)); 注意assert 语句中使用的*isEqualSet()*****方法。**它是SetUtils库的一个方便的静态方法，可以有效地检查两个集合是否相等。 要获得集合的交集，即集合a和集合b中都存在的元素，我们将使用SetUtils。**交集（）方法。此方法还返回一个SetUtil.SetView对象： Set\u0026lt;Integer\u0026gt; expected = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2)); SetUtils.SetView\u0026lt;Integer\u0026gt; intersect = SetUtils.intersection(a, b); assertTrue(SetUtils.isEqualSet(expected, intersect)); 5. 转换集合元素 让我们看看另一个令人兴奋的方法*——SetUtils*。transformedSet（)。此方法接受一个Set对象和一个Transformer接口。在源集合的支持下，它使用*Transformer接口的**transform()*方法来转换集合的每个元素。 转换逻辑在*Transformer接口的**transform()*方法中定义，该方法应用于添加到集合中的每个元素。下面的代码片段将添加到集合中的每个元素乘以 2： Set\u0026lt;Integer\u0026gt; a = SetUtils.transformedSet(new HashSet\u0026lt;\u0026gt;(), e -\u0026gt; e * 2 ); a.add(2); assertEquals(a.toArray()[0], 4); *transformSet()*方法非常方便——它们甚至可以用来转换集合的元素——比如从字符串到整数。只要确保输出的类型是输入的子类型。 假设我们正在使用SortedSet或NavigableSet而不是HashSet，我们可以分别使用transformedSortedSet()或transformedNavigableSet()。 请注意，将一个新的HashSet实例传递给transformSet()方法。在将现有的非空Set传递给方法的情况下，不会转换预先存在的元素。 如果我们想要转换预先存在的元素（以及之后添加的元素），我们需要使用*org.apache.commons.collections4.set.TransformedSet的**transformSet()*方法： Set\u0026lt;Integer\u0026gt; source = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1)); Set\u0026lt;Integer\u0026gt; newSet = TransformedSet.transformedSet(source, e -\u0026gt; e * 2); assertEquals(newSet.toArray()[0], 2); assertEquals(source.toArray()[0], 2); 请注意，源集中的元素被转换，结果被复制到返回的newSet。 6. disjunction SetUtils库提供了一个静态方法，可用于查找集合析取。集合 a 和集合 b的析取是集合a和集合b唯一的所有元素。 让我们看看如何使用SetUtils库的*disjunction()*方法： Set\u0026lt;Integer\u0026gt; a = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 5)); Set\u0026lt;Integer\u0026gt; b = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 3)); SetUtils.SetView\u0026lt;Integer\u0026gt; result = SetUtils.disjunction(a, b); assertTrue( result.toSet().contains(5) \u0026amp;\u0026amp; result.toSet().contains(3)); 7. SetUtils库中的其他方法 SetUtils库中还有其他方法可以轻松处理集合数据：  我们可以使用synchronizedSet()或synchronizedSortedSet()来获得一个线程安全的Set。但是，如文档中所述，我们必须手动同步返回集的迭代器以避免非确定性行为 我们可以使用SetUtils.unmodifiableSet()来获取只读集。请注意，尝试将元素添加到返回的Set对象将引发UnsupportedOperationException 还有一个*SetUtils.emptySet()*方法，它返回一个类型安全、不可变的空集 SetUtils.emptyIfNull ()方法接受一个可为空的Set对象。如果提供的Set为空，则返回一个空的只读 S et；否则，它返回提供的Set SetUtils.orderedSet()将返回一个Set对象，该对象维护添加元素的顺序 *SetUtils.hashCodeForSet()*可以为一个集合生成一个哈希码——这样两个相同元素的集合将具有相同的哈希码 SetUtils.newIdentityHashSet()将返回一个使用==而不是equals()方法来匹配元素的HashSet 。 请在此处阅读其注意事项 \u0026quot;  ","permalink":"http://itcodingman.github.io/apache_commons_setutils/","tags":["Java Set"],"title":"Apache Commons Collections SetUtils"},{"categories":["Java Collections"],"contents":"1. 概述 Apache Commons Collections 库提供了补充 Java Collections Framework的有用类。 在本文中，我们将回顾接口OrderedMap，它扩展了java.util.Map。 2. Maven依赖 我们需要做的第一件事是在pom.xml中添加 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以在Maven 中央存储库中找到该库的最新版本。 3. OrderedMap属性 简单来说，一个实现了OrderedMap接口的地图：  保持其键集的顺序，尽管该集未排序 可以使用方法在两个方向上进行迭代：firstKey()和nextKey()，或lastKey()和previousKey() 可以用MapIterator遍历（也由库提供） 提供查找、更改、删除或替换元素的方法  **4. 使用OrderedMap ** 让我们在测试类中设置跑步者及其年龄的OrderedMap 。我们将使用LinkedMap——库中提供的OrderedMap实现之一。 首先，让我们设置跑步者和年龄的数组，我们将使用它们来加载地图并验证值的顺序： public class OrderMapUnitTest { private String[] names = {\u0026#34;Emily\u0026#34;, \u0026#34;Mathew\u0026#34;, \u0026#34;Rose\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;Anna\u0026#34;}; private Integer[] ages = {37, 28, 40, 36, 21}; private LinkedMap\u0026lt;String, Integer\u0026gt; runnersLinkedMap; //... } 现在，让我们初始化我们的地图： @Before public void createRunners() { this.runnersLinkedMap = new LinkedMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; RUNNERS_COUNT; i++) { runners.put(this.names[i], this.ages[i]); } } 4.1 前向迭代 让我们看看如何使用前向迭代器： @Test public void givenALinkedMap_whenIteratedForwards_thenPreservesOrder() { String name = this.runnersLinkedMap.firstKey(); int i = 0; while (name != null) { assertEquals(name, names[i]); name = this.runnersLinkedMap.nextKey(name); i++; } } 请注意，当我们到达最后一个键时，方法nextKey()将返回一个空值。 4.2. 向后迭代 现在让我们从最后一个键开始迭代： @Test public void givenALinkedMap_whenIteratedBackwards_thenPreservesOrder() { String name = this.runnersLinkedMap.lastKey(); int i = RUNNERS_COUNT - 1; while (name != null) { assertEquals(name, this.names[i]); name = this.runnersLinkedMap.previousKey(name); i--; } } **一旦我们到达第一个键，previousKey()方法将返回 null。 4.3. MapIterator示例 现在让我们使用mapIterator()方法来获取MapIterator，因为我们展示了它如何保留数组names和age中定义的跑步者的顺序： @Test public void givenALinkedMap_whenIteratedWithMapIterator_thenPreservesOrder() { OrderedMapIterator\u0026lt;String, Integer\u0026gt; runnersIterator = this.runnersLinkedMap.mapIterator(); int i = 0; while (runnersIterator.hasNext()) { runnersIterator.next(); assertEquals(runnersIterator.getKey(), this.names[i]); assertEquals(runnersIterator.getValue(), this.ages[i]); i++; } } 4.4. 移除元素 最后，让我们检查如何通过索引或对象删除元素： @Test public void givenALinkedMap_whenElementRemoved_thenSizeDecrease() { LinkedMap\u0026lt;String, Integer\u0026gt; lmap = (LinkedMap\u0026lt;String, Integer\u0026gt;) this.runnersLinkedMap; Integer johnAge = lmap.remove(\u0026#34;John\u0026#34;); assertEquals(johnAge, new Integer(36)); assertEquals(lmap.size(), RUNNERS_COUNT - 1); Integer emilyAge = lmap.remove(0); assertEquals(emilyAge, new Integer(37)); assertEquals(lmap.size(), RUNNERS_COUNT - 2); } 5. 提供的实现 目前，在库的 4.1 版本中，OrderedMap接口有两种实现*——ListOrderedMap和LinkedMap*。 ListOrderedMap使用java.util.List跟踪键集的顺序。它是OrderedMap的装饰器，可以使用静态方法ListOrderedMap.decorate(Map map)从任何**Map创建。 LinkedMap基于HashMap并通过允许双向迭代和OrderedMap接口的其他方法对其进行了改进。 两种实现还提供了OrderedMap接口之外的三个方法：  asList() – 获取List类型的列表（其中K是键的类型），保留映射的顺序 get(int index) – 获取位置index处的元素，而不是接口中提供的方法get(Object o) indexOf(Object o) – 获取对象o在有序映射中  我们可以将OrderedMap转换为LinkedMap以使用*asList()*方法： @Test public void givenALinkedMap_whenConvertedToList_thenMatchesKeySet() { LinkedMap\u0026lt;String, Integer\u0026gt; lmap = (LinkedMap\u0026lt;String, Integer\u0026gt;) this.runnersLinkedMap; List\u0026lt;String\u0026gt; listKeys = new ArrayList\u0026lt;\u0026gt;(); listKeys.addAll(this.runnersLinkedMap.keySet()); List\u0026lt;String\u0026gt; linkedMap = lmap.asList(); assertEquals(listKeys, linkedMap); } 然后我们可以检查LinkedMap实现中方法*indexOf(Object o)和get(int index)*的功能： @Test public void givenALinkedMap_whenSearchByIndexIsUsed_thenMatchesConstantArray() { LinkedMap\u0026lt;String, Integer\u0026gt; lmap = (LinkedMap\u0026lt;String, Integer\u0026gt;) this.runnersLinkedMap; for (int i = 0; i \u0026lt; RUNNERS_COUNT; i++) { String name = lmap.get(i); assertEquals(name, this.names[i]); assertEquals(lmap.indexOf(this.names[i]), i); } } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_ordered_map/","tags":["Java Map"],"title":"Apache Commons Collections OrderedMap"},{"categories":["Java Collections"],"contents":"1. 概述 在本快速教程中，我们将了解 Apache Commons Collections 库中提供的MultiValuedMap接口。 MultiValuedMap 提供了一个简单的 API，用于将每个键映射到 Java 中的值集合。*它是org.apache.commons.collections4.MultiMap*的继承者 *，*后者在 Commons Collection 4.1 中已被弃用。 2. Maven依赖 对于 Maven 项目，我们需要添加commons-collections4依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; **3. 将元素添加到MultiValuedMap ** 我们可以使用 put和putAll方法添加元素。 让我们从创建 MultiValuedMap的实例开始： MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); 接下来，让我们看看如何使用put方法一次添加一个元素 ： map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); 此外，让我们使用putAll方法添加一些元素，该方法在一次调用中将一个键映射到多个元素： map.putAll(\u0026#34;vehicles\u0026#34;, Arrays.asList(\u0026#34;car\u0026#34;, \u0026#34;bike\u0026#34;)); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;vehicles\u0026#34;)) .containsExactly(\u0026#34;car\u0026#34;, \u0026#34;bike\u0026#34;); 4. 从 MultiValuedMap中检索元素 MultiValuedMap提供检索键、值和键值映射的方法。让我们来看看其中的每一个。 4.1 获取键的所有值 要获取与键关联的所有值，我们可以使用get方法，该方法返回一个Collection： assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;fruits\u0026#34;)) .containsExactly(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;); 4.2. 获取所有键值映射 或者，我们可以使用 entries方法来获取 映射中包含的所有键值映射的集合： Collection\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = map.entries(); 4.3. 获取所有密钥 有两种方法可以检索 MultiValuedMap 中包含的所有键。 让我们使用keys方法来获取键的MultiSet视图： MultiSet\u0026lt;String\u0026gt; keys = map.keys(); assertThat(keys).contains(\u0026#34;fruits\u0026#34;, \u0026#34;vehicles\u0026#34;); 或者，我们可以使用keySet方法获取键的Set视图： Set\u0026lt;String\u0026gt; keys = map.keySet(); assertThat(keys).contains(\u0026#34;fruits\u0026#34;, \u0026#34;vehicles\u0026#34;); 4.4. 获取地图的所有值 最后，如果我们想要获取地图中包含的所有值的 Collection视图，我们可以使用values方法： Collection\u0026lt;String\u0026gt; values = map.values(); assertThat(values).contains(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;car\u0026#34;, \u0026#34;bike\u0026#34;); 5. 从 MultiValuedMap中移除元素 现在，让我们看看删除元素和键值映射的所有方法。 5.1 删除映射到键的所有元素 首先，让我们看看如何使用remove方法删除与指定键关联的所有值： Collection\u0026lt;String\u0026gt; removedValues = map.remove(\u0026#34;fruits\u0026#34;); assertThat(map.containsKey(\u0026#34;fruits\u0026#34;)).isFalse(); assertThat(removedValues).contains(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;); 此方法返回已删除值的 Collection视图。 5.2. 删除单个键值映射 现在，假设我们有一个映射到多个值的键，但我们只想删除一个映射值，留下其他值。我们可以使用 removeMapping方法轻松做到这一点： boolean isRemoved = map.removeMapping(\u0026#34;fruits\u0026#34;,\u0026#34;apple\u0026#34;); assertThat(map.containsMapping(\u0026#34;fruits\u0026#34;,\u0026#34;apple\u0026#34;)).isFalse(); 5.3. 删除所有键值映射 最后，我们可以使用 clear方法从地图中删除所有映射： map.clear(); assertThat(map.isEmpty()).isTrue(); 6. 检查MultiValuedMap中的元素 接下来，让我们看一下检查我们的地图中是否存在指定的键或值的各种方法。 6.1 检查密钥是否存在 要确定我们的地图是否包含指定键的映射，我们可以使用 containsKey方法： assertThat(map.containsKey(\u0026#34;vehicles\u0026#34;)).isTrue(); 6.2. 检查值是否存在 接下来，假设我们要检查映射中的至少一个键是否包含特定值的映射。我们可以使用 containsValue方法做到这一点： assertThat(map.containsValue(\u0026#34;orange\u0026#34;)).isTrue(); 6.3. 检查是否存在键值映射 同样，如果我们想检查一个映射是否包含特定键值对的映射，我们可以使用containsMapping 方法： assertThat(map.containsMapping(\u0026#34;fruits\u0026#34;,\u0026#34;orange\u0026#34;)).isTrue(); 6.4. 检查地图是否为空 要检查一个映射是否根本不包含任何键值映射，我们可以使用 isEmpty方法： assertThat(map.isEmpty()).isFalse; 6.5。检查地图的大小 最后，我们可以使用 size方法得到地图的总大小。当一个映射有多个值的键时，映射的总大小是所有键的所有值的计数： assertEquals(4, map.size()); 7. 实施 Apache Commons Collections Library 也提供了这个接口的多种实现。让我们来看看它们。 7.1 ArrayListValuedHashMap ArrayListValuedHashMap在内部 使用ArrayList 来存储与每个键关联的值，因此它允许重复的键值对： MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;fruits\u0026#34;)) .containsExactly(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;orange\u0026#34;); 现在，值得注意的是这个类不是线程安全的。因此，如果我们想从多个线程中使用这个映射，我们必须确保使用适当的同步。 7.2. HashSetValuedHashMap HashSetValuedHashMap 使用HashSet来 存储每个给定键的值。因此，它不允许重复的键值对。 让我们看一个简单的例子，我们添加了两次相同的键值映射： MultiValuedMap\u0026lt;String, String\u0026gt; map = new HashSetValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;fruits\u0026#34;)) .containsExactly(\u0026#34;apple\u0026#34;); 请注意，与我们之前使用 ArrayListValuedHashMap 的示例不同， HashSetValuedHashMap实现忽略了重复映射。 HashSetValuedHashMap 类也不 是线程安全的。 7.3. 不可修改的多值映射 UnmodifiableMultiValuedMap是一个装饰器类，当我们需要 MultiValuedMap的不可变实例时很有用 ——也就是说，它不应该允许进一步修改： @Test(expected = UnsupportedOperationException.class) public void givenUnmodifiableMultiValuedMap_whenInserting_thenThrowingException() { MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); MultiValuedMap\u0026lt;String, String\u0026gt; immutableMap = MultiMapUtils.unmodifiableMultiValuedMap(map); immutableMap.put(\u0026#34;fruits\u0026#34;, \u0026#34;banana\u0026#34;); // throws exception } 再次值得注意的是，修改最终put将导致UnsupportedOperationException。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_multi_valued_map/","tags":["Java Map"],"title":"Apache Commons MultiValuedMap 指南"},{"categories":["Java"],"contents":"1. 概述 我们经常需要使用数学工具，有时java.lang.Math根本不够用。幸运的是，Apache Commons 的目标是使用Apache Commons Math填补标准库的漏洞。 Apache Commons Math 是最大的 Java 数学函数和实用程序开源库。鉴于本文只是一个介绍，我们将仅概述该库并展示最引人注目的用例。 2. 从 Apache Commons Math 开始 2.1 Apache Commons Math 的用法 Apache Commons Math 由数学函数（例如erf）、表示数学概念的结构（如复数、多项式、向量等）以及我们可以应用于这些结构的算法（求根、优化、曲线拟合、计算几何图形的交叉点等）。 2.2. Maven 配置 如果您使用的是 Maven，只需添加此依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-math3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.3. 包装概述 Apache Commons Math 分为几个包：  ***org.apache.commons.math3.stat –***统计和统计测试 ***org.apache.commons.math3.distribution -***概率分布 ***org.apache.commons.math3.random –***随机数、字符串和数据生成 ***org.apache.commons.math3.analysis –***求根、积分、插值、多项式等。 ***org.apache.commons.math3.linear -***矩阵，求解线性系统 ***org.apache.commons.math3.geometry -***几何（欧几里得空间和二进制空间分区） ***org.apache.commons.math3.transform –***变换方法（快速傅里叶） ***org.apache.commons.math3.ode -***常微分方程积分 ***org.apache.commons.math3.fitting –***曲线拟合 ***org.apache.commons.math3.optim -***函数最大化或最小化 ***org.apache.commons.math3.genetics -***遗传算法 ***org.apache.commons.math3.ml -***机器学习（聚类和神经网络） ***org.apache.commons.math3.util –***扩展 java.lang.Math 的常用数学/统计函数 ***org.apache.commons.math3.special –***特殊函数（Gamma，Beta） ***org.apache.commons.math3.complex -***复数 ***org.apache.commons.math3.fraction -***有理数  3. 统计、概率和随机性 3.1 统计数据 org.apache.commons.math3.stat包提供了多种统计计算工具。例如，要计算均值、标准差等，我们可以使用DescriptiveStatistics： double[] values = new double[] {65, 51 , 16, 11 , 6519, 191 ,0 , 98, 19854, 1, 32}; DescriptiveStatistics descriptiveStatistics = new DescriptiveStatistics(); for (double v : values) { descriptiveStatistics.addValue(v); } double mean = descriptiveStatistics.getMean(); double median = descriptiveStatistics.getPercentile(50); double standardDeviation = descriptiveStatistics.getStandardDeviation(); 在这个包中，我们可以找到计算协方差、相关性或执行统计测试的工具（使用TestUtils）。 3.2. 概率和分布 在核心 Java 中，*Math.random()*可用于生成随机值，但这些值均匀分布在 0 和 1 之间。 有时，我们希望使用更复杂的分布产生随机值。为此，我们可以使用org.apache.commons.math3.distribution提供的框架。 以下是如何根据均值为 10、标准差为 3 的正态分布生成随机值： NormalDistribution normalDistribution = new NormalDistribution(10, 3); double randomValue = normalDistribution.sample(); 或者我们可以获得离散分布的值的概率P(X = x) ，或连续分布的累积概率**P(X \u0026lt;= x)。 4.分析 分析相关函数和算法可以在org.apache.commons.math3.analysis中找到。 4.1 求根 根是函数值为 0 的值。Commons-Math 包括几种求根算法的实现。 在这里，我们尝试找到v -\u0026gt; (v * v) – 2的根： UnivariateFunction function = v -\u0026gt; Math.pow(v, 2) - 2; UnivariateSolver solver = new BracketingNthOrderBrentSolver(1.0e-12, 1.0e-8, 5); double c = solver.solve(100, function, -10.0, 10.0, 0); 首先，我们从定义函数开始，然后定义求解器，并设置所需的精度。最后，我们调用solve() API。 寻根操作将使用多次迭代执行，因此需要在执行时间和准确性之间找到一个折衷方案。 4.2. 计算积分 集成几乎就像根查找一样工作： UnivariateFunction function = v -\u0026gt; v; UnivariateIntegrator integrator = new SimpsonIntegrator(1.0e-12, 1.0e-8, 1, 32); double i = integrator.integrate(100, function, 0, 10); 我们首先定义一个函数，在现有的可用集成解决方案中选择一个集成器，我们设置所需的精度，最后进行集成。 5. 线性代数 如果我们有一个 AX = B 形式的线性方程组，其中 A 是实数矩阵，B 是实数向量 – Commons Math 提供了表示矩阵和向量的结构，还提供了求解器来找到X 的值： RealMatrix a = new Array2DRowRealMatrix( new double[][] { { 2, 3, -2 }, { -1, 7, 6 }, { 4, -3, -5 } }, false); RealVector b = new ArrayRealVector(n ew double[] { 1, -2, 1 }, false); DecompositionSolver solver = new LUDecomposition(a).getSolver(); RealVector solution = solver.solve(b); 这个例子非常简单：我们从一个双精度数组定义一个矩阵a，从一个向量数组定义一个向量b。 然后，我们创建一个LUDecomposition，它为 AX = B 形式的方程提供求解器。顾名思义，LUDecomposition依赖于LU 分解，因此仅适用于方阵。 对于其他矩阵，存在不同的求解器，通常使用最小二乘法求解方程。 6.几何 包org.apache.commons.math3.geometry提供了几个表示几何对象的类和几个操作它们的工具。重要的是要注意，这个包分为不同的子包，关于我们想要使用的几何类型： 重要的是要注意，这个包分为不同的子包，关于我们想要使用的几何类型：  ***org.apache.commons.math3.geometry.euclidean.oned -***一维欧几里得几何 org.apache.commons.math3.geometry.euclidean.twod - 2D 欧几里得几何 org.apache.commons.math3.geometry.euclidean.threed - 3D 欧几里得几何 ***org.apache.commons.math3.geometry.spherical.oned -***一维球面几何 org.apache.commons.math3.geometry.spherical.twod - 2D 球面几何  最有用的类可能是Vector2D、Vector3D、Line和Segment。它们分别用于表示 2D 矢量（或点）、3D 矢量、线和线段。 使用上述类时，可以执行一些计算。例如，以下代码执行两条二维线的交点计算： Line l1 = new Line(new Vector2D(0, 0), new Vector2D(1, 1), 0); Line l2 = new Line(new Vector2D(0, 1), new Vector2D(1, 1.5), 0); Vector2D intersection = l1.intersection(l2); 使用这些结构来获取点到线的距离，或线到另一条线的最近点（在 3D 中）也是可行的。 7. 优化、遗传算法和机器学习 Commons-Math 还为与优化和机器学习相关的更复杂任务提供了一些工具和算法。 7.1 优化 优化通常包括最小化或最大化成本函数。优化算法可以在org.apache.commons.math3.optim和org.apache.commons.math3.optimimization中找到。它包括线性和非线性优化算法。 我们可以注意到optim和optimization包中有重复的类：优化包大部分已被弃用，并将在 Commons Math 4 中删除。 7.2. 遗传算法 遗传算法是一种元启发式算法：当确定性算法太慢时，它们是为问题找到可接受解决方案的解决方案。可以在此处找到遗传算法的概述。 org.apache.commons.math3.genetics包提供了一个使用遗传算法执行计算的框架。它包含可用于表示种群和染色体的结构，以及用于执行突变、交叉和选择操作的标准算法。 以下类提供了一个很好的起点：  *GeneticAlgorithm –*遗传算法框架 *人口-*代表人口的界面 *染色体——*代表染色体的界面  7.3. 机器学习 Commons-Math 中的机器学习分为两部分：聚类和神经网络。 聚类部分包括根据距离度量的相似性在向量上放置标签。提供的聚类算法基于 K-means 算法。 神经网络部分给出了表示网络（Network）和神经元（Neuron）的类。有人可能会注意到，与最常见的神经网络框架相比，提供的功能有限，但它对于要求不高的小型应用程序仍然有用。 8. 实用程序 8.1 快速数学 FastMath是一个位于org.apache.commons.math3.util中的静态类，其工作方式与**java.lang.Math完全相同。 它的目的是提供至少与我们在java.lang.Math中可以找到的功能相同的功能，但实现速度更快。因此，当程序严重依赖数学计算时，最好将对Math.sin()的调用（例如）替换为对FastMath.sin()的调用，以提高应用程序的性能。另一方面，请注意FastMath不如java.lang.Math 准确。 8.2. 常用和特殊功能 Commons-Math 提供了java.lang.Math中未实现的标准数学函数（如阶乘）。大多数这些函数都可以在包org.apache.commons.math3.special和org.apache.commons.math3.util中找到。 例如，如果我们想计算 10 的阶乘，我们可以简单地执行以下操作： long factorial = CombinatorialUtils.factorial(10); 与算术相关的函数（gcd、lcm等）可以在ArithmeticUtils中找到，与组合相关的函数可以在CombinatorialUtils中找到。其他一些特殊功能，例如erf，可以在org.apache.commons.math3.special中访问。 8.3. 分数和复数 也可以使用 commons-math 处理更复杂的类型：分数和复数。这些结构允许我们对这种数字执行特定的计算。 然后，我们可以计算两个分数的总和并将结果显示为分数的字符串表示形式（即以“a / b”的形式）： Fraction lhs = new Fraction(1, 3); Fraction rhs = new Fraction(2, 5); Fraction sum = lhs.add(rhs); String str = new FractionFormat().format(sum); 或者，我们可以快速计算复数的幂： Complex first = new Complex(1.0, 3.0); Complex second = new Complex(2.0, 5.0); Complex power = first.pow(second); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_math/","tags":["Math"],"title":"Apache Commons Math 简介"},{"categories":["Java Collections"],"contents":"1. 简介 MapUtils是 Apache Commons Collections 项目中可用的工具之一。 简单地说，它提供了实用方法和装饰器来处理java.util.Map和java.util.SortedMap实例。 2. 设置 让我们从添加依赖项开始： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 实用方法 3.1 从数组创建Map 现在，让我们设置用于创建Map的数组： public class MapUtilsTest { private String[][] color2DArray = new String[][] { {\u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;}, {\u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;}, {\u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34;} }; private String[] color1DArray = new String[] { \u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;, \u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;, \u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34; }; private Map\u0026lt;String, String\u0026gt; colorMap; //... } 让我们看看如何从二维数组创建Map： @Test public void whenCreateMapFrom2DArray_theMapIsCreated() { this.colorMap = MapUtils.putAll( new HashMap\u0026lt;\u0026gt;(), this.color2DArray); assertThat( this.colorMap, is(aMapWithSize(this.color2DArray.length))); assertThat(this.colorMap, hasEntry(\u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34;)); } 我们也可以使用一维数组。在这种情况下，数组被视为备用索引中的键和值： @Test public void whenCreateMapFrom1DArray_theMapIsCreated() { this.colorMap = MapUtils.putAll( new HashMap\u0026lt;\u0026gt;(), this.color1DArray); assertThat( this.colorMap, is(aMapWithSize(this.color1DArray.length / 2))); assertThat(this.colorMap, hasEntry(\u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34;)); } 3.2. 打印Map的内容 很多时候，在调试或调试日志中，我们想打印整个地图： @Test public void whenVerbosePrintMap_thenMustPrintFormattedMap() { MapUtils.verbosePrint(System.out, \u0026#34;Optional Label\u0026#34;, this.colorMap); } 结果： Optional Label = { RED = #FF0000 BLUE = #0000FF GREEN = #00FF00 } 我们还可以使用*debugPrint()*额外打印值的数据类型。 3.3. 获取Value MapUtils提供了一些方法，用于以null安全的方式从给定键的映射中提取值。 例如，getString()从Map中获取一个String。String值是通过toString()获得的。如果值为null或转换失败，我们可以选择指定要返回的默认值： @Test public void whenGetKeyNotPresent_thenMustReturnDefaultValue() { String defaultColorStr = \u0026#34;COLOR_NOT_FOUND\u0026#34;; String color = MapUtils .getString(this.colorMap, \u0026#34;BLACK\u0026#34;, defaultColorStr); assertEquals(color, defaultColorStr); } 请注意，这些方法是null安全的，即它们可以安全地处理null map 参数： @Test public void whenGetOnNullMap_thenMustReturnDefaultValue() { String defaultColorStr = \u0026#34;COLOR_NOT_FOUND\u0026#34;; String color = MapUtils.getString(null, \u0026#34;RED\u0026#34;, defaultColorStr); assertEquals(color, defaultColorStr); } 即使地图为null ，这里的颜色也会得到COLOR_NOT_FOUND的值。 3.4. 反转Map 我们还可以轻松地反转地图： @Test public void whenInvertMap_thenMustReturnInvertedMap() { Map\u0026lt;String, String\u0026gt; invColorMap = MapUtils.invertMap(this.colorMap); int size = invColorMap.size(); Assertions.assertThat(invColorMap) .hasSameSizeAs(colorMap) .containsKeys(this.colorMap.values().toArray(new String[] {})) .containsValues(this.colorMap.keySet().toArray(new String[] {})); } 这会将colorMap反转为： { #00FF00 = GREEN #FF0000 = RED #0000FF = BLUE } 如果源映射为多个键关联相同的值，则在反转后，其中一个值将随机成为键。 3.5. 空和空检查 如果Map为null或为空，isEmpty()方法返回true 。 safeAddToMap()方法防止向Map 添加空元素。 4. 装饰器 这些方法为地图添加了额外的功能。 在大多数情况下，最好不要存储对装饰 Map 的引用*。* 4.1 固定大小的Map *fixedSizeMap()*返回由给定地图支持的固定大小地图。元素可以更改，但不能添加或删除： @Test(expected = IllegalArgumentException.class) public void whenCreateFixedSizedMapAndAdd_thenMustThrowException() { Map\u0026lt;String, String\u0026gt; rgbMap = MapUtils .fixedSizeMap(MapUtils.putAll(new HashMap\u0026lt;\u0026gt;(), this.color1DArray)); rgbMap.put(\u0026#34;ORANGE\u0026#34;, \u0026#34;#FFA500\u0026#34;); } 4.2. 预测Map predicatedMap()方法返回一个Map确保所有持有的元素与提供的谓词匹配： @Test(expected = IllegalArgumentException.class) public void whenAddDuplicate_thenThrowException() { Map\u0026lt;String, String\u0026gt; uniqValuesMap = MapUtils.predicatedMap(this.colorMap, null, PredicateUtils.uniquePredicate()); uniqValuesMap.put(\u0026#34;NEW_RED\u0026#34;, \u0026#34;#FF0000\u0026#34;); } *在这里，我们使用PredicateUtils.uniquePredicate()为值指定谓词。任何将重复值插入此映射的尝试都将导致java.lang。*非法参数异常。 我们可以通过实现Predicate接口来实现自定义谓词。 4.3. lazyMap *lazyMap()*返回一个映射，其中值在请求时被初始化。 如果传递给此映射的Map.get(Object)方法的键在映射中不存在，则Transformer实例将用于创建将与请求的键关联的新对象： @Test public void whenCreateLazyMap_theMapIsCreated() { Map\u0026lt;Integer, String\u0026gt; intStrMap = MapUtils.lazyMap( new HashMap\u0026lt;\u0026gt;(), TransformerUtils.stringValueTransformer()); assertThat(intStrMap, is(anEmptyMap())); intStrMap.get(1); intStrMap.get(2); intStrMap.get(3); assertThat(intStrMap, is(aMapWithSize(3))); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_map_utils/","tags":["Java Map"],"title":"Apache Commons Collections MapUtils"},{"categories":["Java"],"contents":"1. 概述 创建 Apache Commons 项目的目的是为开发人员提供一组可以在日常代码中使用的通用库。 在本教程中，我们将探索 Commons IO 模块的一些关键实用程序类及其最著名的功能。 ** 2.Maven依赖** 要使用该库，让我们在pom.xml中包含以下 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 该库的最新版本可以在Maven Central中找到。 3. 实用程序类 简单地说，实用程序类提供了一组静态方法，可用于对文件执行常见任务。 **3.1 FileUtils ** 该类提供了对文件的不同操作，例如打开、读取、复制和移动。 让我们看看如何使用FileUtils读取或复制文件： File file = FileUtils.getFile(getClass().getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath()); File tempDir = FileUtils.getTempDirectory(); FileUtils.copyFileToDirectory(file, tempDir); File newTempFile = FileUtils.getFile(tempDir, file.getName()); String data = FileUtils.readFileToString(newTempFile, Charset.defaultCharset()); 3.2. FilenameUtils 此实用程序提供了一种与操作系统无关的方法来对文件名执行常用功能。让我们看看我们可以使用的一些不同的方法： String fullPath = FilenameUtils.getFullPath(path); String extension = FilenameUtils.getExtension(path); String baseName = FilenameUtils.getBaseName(path); 3.3. FileSystemUtils 我们可以使用FileSystemUtils来检查给定卷或驱动器上的可用空间： long freeSpace = FileSystemUtils.freeSpaceKb(\u0026#34;/\u0026#34;); 4.输入输出 这个包提供了几种处理输入和输出流的实现。 我们将专注于TeeInputStream和TeeOutputSteam。单词“ Tee ”（源自字母“ T ”）通常用于描述将单个输入拆分为两个不同的输出。 让我们看一个示例，该示例演示了如何将单个输入流写入两个不同的输出流： String str = \u0026#34;Hello World.\u0026#34;; ByteArrayInputStream inputStream = new ByteArrayInputStream(str.getBytes()); ByteArrayOutputStream outputStream1 = new ByteArrayOutputStream(); ByteArrayOutputStream outputStream2 = new ByteArrayOutputStream(); FilterOutputStream teeOutputStream = new TeeOutputStream(outputStream1, outputStream2); new TeeInputStream(inputStream, teeOutputStream, true) .read(new byte[str.length()]); assertEquals(str, String.valueOf(outputStream1)); assertEquals(str, String.valueOf(outputStream2)); 5. 过滤器  Commons IO 包含一个有用的文件过滤器列表。当开发人员想要从异构文件列表中缩小到特定的所需文件列表时，这些可以派上用场。 该库还支持对给定文件列表的AND和OR逻辑运算。因此，我们可以混合和匹配这些过滤器以获得所需的结果。 让我们看一个使用WildcardFileFilter和SuffixFileFilter检索名称中带有“ ple ”且后缀为“ txt ”的文件的示例。请注意，我们使用ANDFileFilter包装上述过滤器： @Test public void whenGetFilewith_ANDFileFilter_thenFind_sample_txt() throws IOException { String path = getClass().getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath(); File dir = FileUtils.getFile(FilenameUtils.getFullPath(path)); assertEquals(\u0026#34;sample.txt\u0026#34;, dir.list(new AndFileFilter( new WildcardFileFilter(\u0026#34;*ple*\u0026#34;, IOCase.INSENSITIVE), new SuffixFileFilter(\u0026#34;txt\u0026#34;)))[0]); } 6. Comparator  Comparator包提供了不同类型的文件比较。我们将在这里探讨两种不同的比较器。 6.1 PathFileComparator PathFileComparator类可用于以区分大小写、不区分大小写或系统相关的区分大小写的方式**按路径对文件列表或数组进行排序。**让我们看看如何使用此实用程序对资源目录中的文件路径进行排序： @Test public void whenSortDirWithPathFileComparator_thenFirstFile_aaatxt() throws IOException { PathFileComparator pathFileComparator = new PathFileComparator( IOCase.INSENSITIVE); String path = FilenameUtils.getFullPath(getClass() .getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath()); File dir = new File(path); File[] files = dir.listFiles(); pathFileComparator.sort(files); assertEquals(\u0026#34;aaa.txt\u0026#34;, files[0].getName()); } 请注意，我们使用了IOCase.INSENSITIVE配置。PathFileComparator还提供了许多具有不同区分大小写和反向排序选项的单例实例。 这些静态字段包括PATH_COMPARATOR、PATH_INSENSITIVE_COMPARATOR、PATH_INSENSITIVE_REVERSE、PATH_SYSTEM_COMPARATOR等等。 6.2. SizeFileComparator SizeFileComparator，顾名思义，是用来比较两个文件的大小（长度）的。如果第一个文件的大小小于第二个文件的大小，则返回一个负整数值。如果文件大小相等，则返回零，如果第一个文件的大小大于第二个文件的大小，则返回正值。 让我们编写一个单元测试来演示文件大小的比较： @Test public void whenSizeFileComparator_thenLargerFile_large() throws IOException { SizeFileComparator sizeFileComparator = new SizeFileComparator(); File largerFile = FileUtils.getFile(getClass().getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath()); File smallerFile = FileUtils.getFile(getClass().getClassLoader() .getResource(\u0026#34;sample.txt\u0026#34;) .getPath()); int i = sizeFileComparator.compare(largerFile, smallerFile); Assert.assertTrue(i \u0026gt; 0); } 7. 文件监视器 Commons IO 监视器包提供了跟踪文件或目录更改的能力。让我们看一个快速示例，说明如何将FileAlterationMonitor与**FileAlterationObserver和FileAlterationListener一起使用来监视文件或文件夹。 当FileAlterationMonitor启动时，我们将开始接收有关正在监视的目录上的文件更改的通知*：* FileAlterationObserver observer = new FileAlterationObserver(folder); FileAlterationMonitor monitor = new FileAlterationMonitor(5000); FileAlterationListener fal = new FileAlterationListenerAdaptor() { @Override public void onFileCreate(File file) { // on create action  } @Override public void onFileDelete(File file) { // on delete action  } }; observer.addListener(fal); monitor.addObserver(observer); monitor.start(); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_io/","tags":["Java IO"],"title":"Apache Commons IO"},{"categories":["Algorithms"],"contents":"1. 概述 在本教程中，我们将了解如何借助 Apache Commons Frequency类在直方图上呈现数据。 Frequency 类是本文探讨的 Apache Commons Math 库的一部分。 直方图是连接条形图，显示数据集中一系列数据的出现。它与条形图的不同之处在于它用于显示连续的定量变量的分布，而条形图用于显示分类数据。 2.项目依赖 在本文中，我们将使用具有以下依赖项的 Maven 项目： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-math3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.knowm.xchart\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xchart\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; commons-math3库包含 我们将用来确定数据集中变量出现的 *频率 类。*我们将使用 xchart 库在 GUI 中显示直方图 。 最新版本的commons-math3和xchart 可以在 Maven Central 上找到。 3. 计算变量的频率 在本教程中，我们将使用包含特定学校学生年龄的数据集。我们希望看到不同年龄组的频率并在直方图上观察它们的分布。 让我们用 List集合来表示数据集，并使用它来填充 Frequency类的实例： List\u0026lt;Integer\u0026gt; datasetList = Arrays.asList( 36, 25, 38, 46, 55, 68, 72, 55, 36, 38, 67, 45, 22, 48, 91, 46, 52, 61, 58, 55); Frequency frequency = new Frequency(); datasetList.forEach(d -\u0026gt; frequency.addValue(Double.parseDouble(d.toString()))); 现在我们已经填充了 Frequency类的实例，我们将获取 bin 中每个年龄的计数并将其相加，以便我们可以获得特定年龄组中年龄的总频率： datasetList.stream() .map(d -\u0026gt; Double.parseDouble(d.toString())) .distinct() .forEach(observation -\u0026gt; { long observationFrequency = frequency.getCount(observation); int upperBoundary = (observation \u0026gt; classWidth) ? Math.multiplyExact( (int) Math.ceil(observation / classWidth), classWidth) : classWidth; int lowerBoundary = (upperBoundary \u0026gt; classWidth) ? Math.subtractExact(upperBoundary, classWidth) : 0; String bin = lowerBoundary + \u0026#34;-\u0026#34; + upperBoundary; updateDistributionMap(lowerBoundary, bin, observationFrequency); }); 从上面的代码片段中，我们首先 使用 Frequency类的getCount()确定观察的 频率。该方法返回观察的发生总数*。* 使用当前观察，我们通过计算其相对于类宽度的上下边界（即 10 ）来动态确定它所属的组。 上下边界连接起来形成一个 bin， 使用updateDistributionMap()将其与**观察频率一起存储在distributionMap中。 如果 bin已经存在，我们更新频率，否则我们将其添加为键并将当前观察的频率设置为其值。请注意，我们会跟踪处理后的观察结果以避免重复。 频率类还具有确定数据集中变量的百分比和累积百分比的方法。 4. 绘制直方图 现在我们已经将原始数据集处理为年龄组及其各自频率的地图，我们可以使用 xchart库在直方图中显示数据： CategoryChart chart = new CategoryChartBuilder().width(800).height(600) .title(\u0026#34;Age Distribution\u0026#34;) .xAxisTitle(\u0026#34;Age Group\u0026#34;) .yAxisTitle(\u0026#34;Frequency\u0026#34;) .build(); chart.getStyler().setLegendPosition(Styler.LegendPosition.InsideNW); chart.getStyler().setAvailableSpaceFill(0.99); chart.getStyler().setOverlapped(true); List yData = new ArrayList(); yData.addAll(distributionMap.values()); List xData = Arrays.asList(distributionMap.keySet().toArray()); chart.addSeries(\u0026#34;age group\u0026#34;, xData, yData); new SwingWrapper\u0026lt;\u0026gt;(chart).displayChart(); 我们使用图表构建器创建了一个 CategoryChart实例，然后我们对其进行配置并使用 x 和 y 轴的数据填充它。 最后，我们使用SwingWrapper在 GUI 中显示图表 ： 从上面的直方图可以看出，80-90 岁的学生没有，而 50-60 岁的学生占主导地位。这很可能是博士生或博士后。 我们也可以说直方图具有正态分布。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_frequency/","tags":[],"title":"Apache Commons Frequency"},{"categories":["Persistence"],"contents":"1. 概述 Apache Commons DbUtils 是一个小型库，它使使用 JDBC 变得更加容易。 在本文中，我们将实施示例来展示其特性和功能。 2. 设置 2.1 Maven 依赖项 首先，我们需要将commons-dbutils和h2依赖添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-dbutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-dbutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.196\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 你可以在 Maven Central 上找到最新版本的commons-dbutils和h2 。 2.2. 测试数据库 有了我们的依赖关系，让我们创建一个脚本来创建我们将使用的表和记录： CREATETABLEemployee(idintNOTNULLPRIMARYKEYauto_increment,firstnamevarchar(255),lastnamevarchar(255),salarydouble,hireddatedate,);CREATETABLEemail(idintNOTNULLPRIMARYKEYauto_increment,employeeidint,addressvarchar(255));INSERTINTOemployee(firstname,lastname,salary,hireddate)VALUES(\u0026#39;John\u0026#39;,\u0026#39;Doe\u0026#39;,10000.10,to_date(\u0026#39;01-01-2001\u0026#39;,\u0026#39;dd-mm-yyyy\u0026#39;));//...INSERTINTOemail(employeeid,address)VALUES(1,\u0026#39;[[email protected]](cdn-cgi/l/email-protection)\u0026#39;);//...本文中的所有示例测试用例都将使用新创建的与 H2 内存数据库的连接： public class DbUtilsUnitTest { private Connection connection; @Before public void setupDB() throws Exception { Class.forName(\u0026#34;org.h2.Driver\u0026#34;); String db = \u0026#34;jdbc:h2:mem:;INIT=runscript from \u0026#39;classpath:/employees.sql\u0026#39;\u0026#34;; connection = DriverManager.getConnection(db); } @After public void closeBD() { DbUtils.closeQuietly(connection); } // ... } 2.3. POJO 最后，我们需要两个简单的类： public class Employee { private Integer id; private String firstName; private String lastName; private Double salary; private Date hiredDate; // standard constructors, getters, and setters } public class Email { private Integer id; private Integer employeeId; private String address; // standard constructors, getters, and setters } 3. 简介 DbUtils 库提供QueryRunner类作为大多数可用功能的主要入口点。 此类通过接收到数据库的连接、要执行的 SQL 语句以及为查询的占位符提供值的可选参数列表来工作。 正如我们稍后将看到的，一些方法还接收一个ResultSetHandler实现——它负责将ResultSet实例转换为我们的应用程序期望的对象。 \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; 当然，该库已经提供了几种处理最常见转换的实现，例如列表、映射和 JavaBean。 4. 查询数据 现在我们知道了基础知识，我们已经准备好查询我们的数据库了。 让我们从一个使用MapListHandler获取数据库中所有记录作为地图列表的快速示例开始： @Test public void givenResultHandler_whenExecutingQuery_thenExpectedList() throws SQLException { MapListHandler beanListHandler = new MapListHandler(); QueryRunner runner = new QueryRunner(); List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; list = runner.query(connection, \u0026#34;SELECT * FROM employee\u0026#34;, beanListHandler); assertEquals(list.size(), 5); assertEquals(list.get(0).get(\u0026#34;firstname\u0026#34;), \u0026#34;John\u0026#34;); assertEquals(list.get(4).get(\u0026#34;firstname\u0026#34;), \u0026#34;Christian\u0026#34;); } 接下来，这是一个使用BeanListHandler将结果转换为Employee实例的示例： @Test public void givenResultHandler_whenExecutingQuery_thenEmployeeList() throws SQLException { BeanListHandler\u0026lt;Employee\u0026gt; beanListHandler = new BeanListHandler\u0026lt;\u0026gt;(Employee.class); QueryRunner runner = new QueryRunner(); List\u0026lt;Employee\u0026gt; employeeList = runner.query(connection, \u0026#34;SELECT * FROM employee\u0026#34;, beanListHandler); assertEquals(employeeList.size(), 5); assertEquals(employeeList.get(0).getFirstName(), \u0026#34;John\u0026#34;); assertEquals(employeeList.get(4).getFirstName(), \u0026#34;Christian\u0026#34;); } 对于返回单个值的查询，我们可以使用ScalarHandler： @Test public void givenResultHandler_whenExecutingQuery_thenExpectedScalar() throws SQLException { ScalarHandler\u0026lt;Long\u0026gt; scalarHandler = new ScalarHandler\u0026lt;\u0026gt;(); QueryRunner runner = new QueryRunner(); String query = \u0026#34;SELECT COUNT(*) FROM employee\u0026#34;; long count = runner.query(connection, query, scalarHandler); assertEquals(count, 5); } 要了解所有ResultSerHandler实现，可以参考ResultSetHandler文档。 4.1 自定义处理程序 当我们需要更多地控制如何将结果转换为对象时，我们还可以创建一个自定义处理程序以传递给QueryRunner的方法。 这可以通过实现ResultSetHandler接口或扩展库提供的现有实现之一来完成。 让我们看看第二种方法的外观。首先，让我们在Employee类中添加另一个字段： public class Employee { private List\u0026lt;Email\u0026gt; emails; // ... } 现在，让我们创建一个扩展BeanListHandler类型并为每个员工设置电子邮件列表的类： public class EmployeeHandler extends BeanListHandler\u0026lt;Employee\u0026gt; { private Connection connection; public EmployeeHandler(Connection con) { super(Employee.class); this.connection = con; } @Override public List\u0026lt;Employee\u0026gt; handle(ResultSet rs) throws SQLException { List\u0026lt;Employee\u0026gt; employees = super.handle(rs); QueryRunner runner = new QueryRunner(); BeanListHandler\u0026lt;Email\u0026gt; handler = new BeanListHandler\u0026lt;\u0026gt;(Email.class); String query = \u0026#34;SELECT * FROM email WHERE employeeid = ?\u0026#34;; for (Employee employee : employees) { List\u0026lt;Email\u0026gt; emails = runner.query(connection, query, handler, employee.getId()); employee.setEmails(emails); } return employees; } } 请注意，我们期望构造函数中有一个Connection对象，以便我们可以执行查询以获取电子邮件。 最后，让我们测试一下我们的代码，看看是否一切都按预期工作： @Test public void givenResultHandler_whenExecutingQuery_thenEmailsSetted() throws SQLException { EmployeeHandler employeeHandler = new EmployeeHandler(connection); QueryRunner runner = new QueryRunner(); List\u0026lt;Employee\u0026gt; employees = runner.query(connection, \u0026#34;SELECT * FROM employee\u0026#34;, employeeHandler); assertEquals(employees.get(0).getEmails().size(), 2); assertEquals(employees.get(2).getEmails().size(), 3); } 4.2. 自定义行处理器 在我们的示例中，employee表的列名与Employee类的字段名匹配（匹配不区分大小写）。然而，情况并非总是如此——例如当列名使用下划线来分隔复合词时。 在这些情况下，我们可以利用RowProcessor接口及其实现将列名映射到我们类中的适当字段。 让我们看看这是什么样子。首先，让我们创建另一个表并在其中插入一些记录： CREATETABLEemployee_legacy(idintNOTNULLPRIMARYKEYauto_increment,first_namevarchar(255),last_namevarchar(255),salarydouble,hired_datedate,);INSERTINTOemployee_legacy(first_name,last_name,salary,hired_date)VALUES(\u0026#39;John\u0026#39;,\u0026#39;Doe\u0026#39;,10000.10,to_date(\u0026#39;01-01-2001\u0026#39;,\u0026#39;dd-mm-yyyy\u0026#39;));//...现在，让我们修改我们的EmployeeHandler类： public class EmployeeHandler extends BeanListHandler\u0026lt;Employee\u0026gt; { // ...  public EmployeeHandler(Connection con) { super(Employee.class, new BasicRowProcessor(new BeanProcessor(getColumnsToFieldsMap()))); // ...  } public static Map\u0026lt;String, String\u0026gt; getColumnsToFieldsMap() { Map\u0026lt;String, String\u0026gt; columnsToFieldsMap = new HashMap\u0026lt;\u0026gt;(); columnsToFieldsMap.put(\u0026#34;FIRST_NAME\u0026#34;, \u0026#34;firstName\u0026#34;); columnsToFieldsMap.put(\u0026#34;LAST_NAME\u0026#34;, \u0026#34;lastName\u0026#34;); columnsToFieldsMap.put(\u0026#34;HIRED_DATE\u0026#34;, \u0026#34;hiredDate\u0026#34;); return columnsToFieldsMap; } // ... } 请注意，我们正在使用BeanProcessor进行列到字段的实际映射，并且仅用于需要处理的那些。 最后，让我们测试一切是否正常： @Test public void givenResultHandler_whenExecutingQuery_thenAllPropertiesSetted() throws SQLException { EmployeeHandler employeeHandler = new EmployeeHandler(connection); QueryRunner runner = new QueryRunner(); String query = \u0026#34;SELECT * FROM employee_legacy\u0026#34;; List\u0026lt;Employee\u0026gt; employees = runner.query(connection, query, employeeHandler); assertEquals((int) employees.get(0).getId(), 1); assertEquals(employees.get(0).getFirstName(), \u0026#34;John\u0026#34;); } 5. 插入记录 QueryRunner类提供了两种在数据库中创建记录的方法*。* 第一个是使用*update()*方法并传递 SQL 语句和可选的替换参数列表。该方法返回插入的记录数： @Test public void whenInserting_thenInserted() throws SQLException { QueryRunner runner = new QueryRunner(); String insertSQL = \u0026#34;INSERT INTO employee (firstname,lastname,salary, hireddate) \u0026#34; + \u0026#34;VALUES (?, ?, ?, ?)\u0026#34;; int numRowsInserted = runner.update( connection, insertSQL, \u0026#34;Leia\u0026#34;, \u0026#34;Kane\u0026#34;, 60000.60, new Date()); assertEquals(numRowsInserted, 1); } 第二种是使用insert()方法，除了 SQL 语句和替换参数之外，还需要一个ResultSetHandler来转换生成的自动生成的键。返回值将是处理程序返回的内容： @Test public void givenHandler_whenInserting_thenExpectedId() throws SQLException { ScalarHandler\u0026lt;Integer\u0026gt; scalarHandler = new ScalarHandler\u0026lt;\u0026gt;(); QueryRunner runner = new QueryRunner(); String insertSQL = \u0026#34;INSERT INTO employee (firstname,lastname,salary, hireddate) \u0026#34; + \u0026#34;VALUES (?, ?, ?, ?)\u0026#34;; int newId = runner.insert( connection, insertSQL, scalarHandler, \u0026#34;Jenny\u0026#34;, \u0026#34;Medici\u0026#34;, 60000.60, new Date()); assertEquals(newId, 6); } 6. 更新和删除 QueryRunner类的*update()*方法也可用于修改和删除数据库中的记录。 它的用法是微不足道的。以下是如何更新员工工资的示例： @Test public void givenSalary_whenUpdating_thenUpdated() throws SQLException { double salary = 35000; QueryRunner runner = new QueryRunner(); String updateSQL = \u0026#34;UPDATE employee SET salary = salary * 1.1 WHERE salary \u0026lt;= ?\u0026#34;; int numRowsUpdated = runner.update(connection, updateSQL, salary); assertEquals(numRowsUpdated, 3); } 这是另一个删除具有给定 id 的员工的方法： @Test public void whenDeletingRecord_thenDeleted() throws SQLException { QueryRunner runner = new QueryRunner(); String deleteSQL = \u0026#34;DELETE FROM employee WHERE id = ?\u0026#34;; int numRowsDeleted = runner.update(connection, deleteSQL, 3); assertEquals(numRowsDeleted, 1); } 7. 异步操作 DbUtils 提供了AsyncQueryRunner类来异步执行操作。该类的方法与QueryRunner类的方法有对应关系，只是它们返回一个Future实例。 下面是一个获取数据库中所有员工的示例，最多等待 10 秒才能得到结果： @Test public void givenAsyncRunner_whenExecutingQuery_thenExpectedList() throws Exception { AsyncQueryRunner runner = new AsyncQueryRunner(Executors.newCachedThreadPool()); EmployeeHandler employeeHandler = new EmployeeHandler(connection); String query = \u0026#34;SELECT * FROM employee\u0026#34;; Future\u0026lt;List\u0026lt;Employee\u0026gt;\u0026gt; future = runner.query(connection, query, employeeHandler); List\u0026lt;Employee\u0026gt; employeeList = future.get(10, TimeUnit.SECONDS); assertEquals(employeeList.size(), 5); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_dbutils/","tags":[],"title":"Apache Commons DbUtils 指南"},{"categories":["Data"],"contents":"1. 概述 Apache Commons CSV 库具有许多用于创建和读取 CSV 文件的有用功能。 在这个快速教程中，我们将通过一个简单的例子来了解如何使用这个库。 2.Maven依赖 首先，我们将使用 Maven 导入该库的最新版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-csv\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查这个库的最新版本——去这里。 3. 读取 CSV 文件 考虑以下名为 book.csv 的 CSV 文件，其中包含一本书的属性： author,title Dan Simmons,Hyperion Douglas Adams,The Hitchhiker\u0026#39;s Guide to the Galaxy 让我们看看如何阅读它： Map\u0026lt;String, String\u0026gt; AUTHOR_BOOK_MAP = new HashMap\u0026lt;\u0026gt;() { { put(\u0026#34;Dan Simmons\u0026#34;, \u0026#34;Hyperion\u0026#34;); put(\u0026#34;Douglas Adams\u0026#34;, \u0026#34;The Hitchhiker\u0026#39;s Guide to the Galaxy\u0026#34;); } }); String[] HEADERS = { \u0026#34;author\u0026#34;, \u0026#34;title\u0026#34;}; @Test public void givenCSVFile_whenRead_thenContentsAsExpected() throws IOException { Reader in = new FileReader(\u0026#34;book.csv\u0026#34;); Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withHeader(HEADERS) .withFirstRecordAsHeader() .parse(in); for (CSVRecord record : records) { String author = record.get(\u0026#34;author\u0026#34;); String title = record.get(\u0026#34;title\u0026#34;); assertEquals(AUTHOR_BOOK_MAP.get(author), title); } } 我们在跳过第一行后读取 CSV 文件的记录，因为它是标题。 有不同类型的CSVFormat指定 CSV 文件的格式，您可以在下一段中看到一个示例。 4. 创建 CSV 文件 让我们看看如何创建与上面相同的 CSV 文件： public void createCSVFile() throws IOException { FileWriter out = new FileWriter(\u0026#34;book_new.csv\u0026#34;); try (CSVPrinter printer = new CSVPrinter(out, CSVFormat.DEFAULT .withHeader(HEADERS))) { AUTHOR_BOOK_MAP.forEach((author, title) -\u0026gt; { printer.printRecord(author, title); }); } } 将使用适当的标题创建新的 CSV 文件，因为我们已经在CSVFormat声明中指定了它们。 5. 标题和阅读栏 有不同的方法来读取和写入标头。同样，读取列值也有不同的方法。 让我们一一介绍： 5.1 按索引访问列 这是读取列值的最基本方法。当 CSV 文件的标题未知时，可以使用此方法： Reader in = new FileReader(\u0026#34;book.csv\u0026#34;); Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT.parse(in); for (CSVRecord record : records) { String columnOne = record.get(0); String columnTwo = record.get(1); } 5.2. 通过预定义的标题访问列 与通过索引访问相比，这是一种更直观的访问列的方式： Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withHeader(\u0026#34;author\u0026#34;, \u0026#34;title\u0026#34;).parse(in); for (CSVRecord record : records) { String author = record.get(\u0026#34;author\u0026#34;); String title = record.get(\u0026#34;title\u0026#34;); } 5.3. 使用枚举作为标题 使用字符串访问列值可能容易出错。使用 Enums 而不是 Strings 将使代码更加标准化和易于理解： enum BookHeaders { author, title } Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withHeader(BookHeaders.class).parse(in); for (CSVRecord record : records) { String author = record.get(BookHeaders.author); String title = record.get(BookHeaders.title); } 5.4. 跳过标题行 通常，CSV 文件在第一行包含标题。因此，在大多数情况下，跳过它并从第二行开始读取是安全的。 这将自动检测标题访问列值： Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withFirstRowAsHeader().parse(in); for (CSVRecord record : records) { String author = record.get(\u0026#34;author\u0026#34;); String title = record.get(\u0026#34;title\u0026#34;); } 5.5. 创建带有标题的文件 同样，我们可以创建一个 CSV 文件，其中第一行包含标题： FileWriter out = new FileWriter(\u0026#34;book_new.csv\u0026#34;); CSVPrinter printer = CSVFormat.DEFAULT .withHeader(\u0026#34;author\u0026#34;, \u0026#34;title\u0026#34;).print(out); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_csv/","tags":[],"title":"Apache Commons CSV 简介"},{"categories":["Guava","Java Collections"],"contents":"1. 概述 在本教程中，我们将比较两个基于 Java 的开源库：Apache Commons和Google Guava。这两个库都具有丰富的功能集，其中包含大量实用程序 API，主要位于集合和 I/O 领域。 为简洁起见，这里我们将仅描述集合框架中最常用的几个以及代码示例。我们还将看到它们之间差异的摘要。 2. 两个的简史 Google Guava 是 Google 的一个项目，主要由该组织的工程师开发，虽然现在已经开源。启动它的主要动机是将 JDK 1.5 中引入的泛型包含到 Java Collections Framework或JCF中，并增强其功能。 自成立以来，该库已扩展其功能，现在包括图形、函数式编程、范围对象、缓存和字符串操作。 Apache Commons 最初是作为 Jakarta 项目的一个补充核心 Java 集合 API 的项目，最终成为 Apache 软件基金会的一个项目。多年来，它已扩展到其他各个领域的大量可重用 Java 组件，包括（但不限于）成像、I/O、密码学、缓存、网络、验证和对象池。 由于这是一个开源项目，来自 Apache 社区的开发人员不断添加到该库以扩展其功能。但是，他们非常注意保持向后兼容性。 3. Maven依赖 要包含 Guava，我们需要将其依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;31.0.1-jre\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 它的最新版本信息可以在Maven上找到。 对于 Apache Commons，它有点不同。根据我们要使用的实用程序，我们必须添加那个特定的。例如，对于集合，我们需要添加： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在我们的代码示例中，我们将使用commons-collections4。 现在让我们进入有趣的部分吧！ 4. 双向Map 可以通过键和值访问的映射称为双向映射。JCF 没有此功能。 让我们看看我们的两种技术如何提供它们。在这两种情况下，我们都会以一周中的几天为例来获取给定日期的日期名称，反之亦然。 4.1 Guava 的BiMap Guava 提供了一个接口 - BiMap，作为双向地图。它可以使用其实现之一 EnumBiMap、EnumHashBiMap、HashBiMap或ImmutableBiMap来实例化。 这里我们使用HashBiMap： BiMap\u0026lt;Integer, String\u0026gt; daysOfWeek = HashBiMap.create(); 填充它类似于 Java 中的任何地图： daysOfWeek.put(1, \u0026#34;Monday\u0026#34;); daysOfWeek.put(2, \u0026#34;Tuesday\u0026#34;); daysOfWeek.put(3, \u0026#34;Wednesday\u0026#34;); daysOfWeek.put(4, \u0026#34;Thursday\u0026#34;); daysOfWeek.put(5, \u0026#34;Friday\u0026#34;); daysOfWeek.put(6, \u0026#34;Saturday\u0026#34;); daysOfWeek.put(7, \u0026#34;Sunday\u0026#34;); 这里有一些 JUnit 测试来证明这个概念： @Test public void givenBiMap_whenValue_thenKeyReturned() { assertEquals(Integer.valueOf(7), daysOfWeek.inverse().get(\u0026#34;Sunday\u0026#34;)); } @Test public void givenBiMap_whenKey_thenValueReturned() { assertEquals(\u0026#34;Tuesday\u0026#34;, daysOfWeek.get(2)); } 4.2. Apache 的BidiMap 同样，Apache 为我们提供了它的BidiMap接口： BidiMap\u0026lt;Integer, String\u0026gt; daysOfWeek = new TreeBidiMap\u0026lt;Integer, String\u0026gt;(); 这里我们使用TreeBidiMap。但是，还有其他实现，例如DualHashBidiMap和DualTreeBidiMap。 要填充它，我们可以像上面对 BiMap所做的那样放置值。 它的用法也很相似： @Test public void givenBidiMap_whenValue_thenKeyReturned() { assertEquals(Integer.valueOf(7), daysOfWeek.inverseBidiMap().get(\u0026#34;Sunday\u0026#34;)); } @Test public void givenBidiMap_whenKey_thenValueReturned() { assertEquals(\u0026#34;Tuesday\u0026#34;, daysOfWeek.get(2)); } 在一些简单的性能测试中，这个双向映射仅在插入方面落后于Guava 对应映射。获取键和值要快得多。 5. 将键映射到多个值 对于我们想要将多个键映射到不同值的用例，例如水果和蔬菜的购物车集合，这两个库为我们提供了独特的解决方案。 5.1 Guava 的MultiMap 首先，让我们看看如何实例化和初始化MultiMap： Multimap\u0026lt;String, String\u0026gt; groceryCart = ArrayListMultimap.create(); groceryCart.put(\u0026#34;Fruits\u0026#34;, \u0026#34;Apple\u0026#34;); groceryCart.put(\u0026#34;Fruits\u0026#34;, \u0026#34;Grapes\u0026#34;); groceryCart.put(\u0026#34;Fruits\u0026#34;, \u0026#34;Strawberries\u0026#34;); groceryCart.put(\u0026#34;Vegetables\u0026#34;, \u0026#34;Spinach\u0026#34;); groceryCart.put(\u0026#34;Vegetables\u0026#34;, \u0026#34;Cabbage\u0026#34;); 然后，我们将使用几个 JUnit 测试来查看它的实际效果： @Test public void givenMultiValuedMap_whenFruitsFetched_thenFruitsReturned() { List\u0026lt;String\u0026gt; fruits = Arrays.asList(\u0026#34;Apple\u0026#34;, \u0026#34;Grapes\u0026#34;, \u0026#34;Strawberries\u0026#34;); assertEquals(fruits, groceryCart.get(\u0026#34;Fruits\u0026#34;)); } @Test public void givenMultiValuedMap_whenVeggiesFetched_thenVeggiesReturned() { List\u0026lt;String\u0026gt; veggies = Arrays.asList(\u0026#34;Spinach\u0026#34;, \u0026#34;Cabbage\u0026#34;); assertEquals(veggies, groceryCart.get(\u0026#34;Vegetables\u0026#34;)); } 此外，MultiMap使我们能够从地图中删除给定条目或整组值： @Test public void givenMultiValuedMap_whenFuitsRemoved_thenVeggiesPreserved() { assertEquals(5, groceryCart.size()); groceryCart.remove(\u0026#34;Fruits\u0026#34;, \u0026#34;Apple\u0026#34;); assertEquals(4, groceryCart.size()); groceryCart.removeAll(\u0026#34;Fruits\u0026#34;); assertEquals(2, groceryCart.size()); } 如我们所见，这里我们首先从Fruits集中移除**Apple，然后移除整个Fruits集中。 5.2. Apache 的多值映射 同样，让我们​​从实例化MultiValuedMap开始： MultiValuedMap\u0026lt;String, String\u0026gt; groceryCart = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); 由于填充它与我们在上一节中看到的相同，让我们快速看一下用法： @Test public void givenMultiValuedMap_whenFruitsFetched_thenFruitsReturned() { List\u0026lt;String\u0026gt; fruits = Arrays.asList(\u0026#34;Apple\u0026#34;, \u0026#34;Grapes\u0026#34;, \u0026#34;Strawberries\u0026#34;); assertEquals(fruits, groceryCart.get(\u0026#34;Fruits\u0026#34;)); } @Test public void givenMultiValuedMap_whenVeggiesFetched_thenVeggiesReturned() { List\u0026lt;String\u0026gt; veggies = Arrays.asList(\u0026#34;Spinach\u0026#34;, \u0026#34;Cabbage\u0026#34;); assertEquals(veggies, groceryCart.get(\u0026#34;Vegetables\u0026#34;)); } 我们可以看到，它的用法也是一样的！ 但是，在这种情况下，我们无法灵活地删除单个条目，例如Apple from Fruits。 我们只能删除整组Fruits： @Test public void givenMultiValuedMap_whenFuitsRemoved_thenVeggiesPreserved() { assertEquals(5, groceryCart.size()); groceryCart.remove(\u0026#34;Fruits\u0026#34;); assertEquals(2, groceryCart.size()); } 6. 将多个键映射到一个值 在这里，我们将举例说明要映射到各个城市的纬度和经度： cityCoordinates.put(\u0026#34;40.7128° N\u0026#34;, \u0026#34;74.0060° W\u0026#34;, \u0026#34;New York\u0026#34;); cityCoordinates.put(\u0026#34;48.8566° N\u0026#34;, \u0026#34;2.3522° E\u0026#34;, \u0026#34;Paris\u0026#34;); cityCoordinates.put(\u0026#34;19.0760° N\u0026#34;, \u0026#34;72.8777° E\u0026#34;, \u0026#34;Mumbai\u0026#34;); 现在，我们将看看如何实现这一目标。 6.1 Guava的Table Guava 提供了满足上述用例的Table ： Table\u0026lt;String, String, String\u0026gt; cityCoordinates = HashBasedTable.create(); 以下是我们可以从中得出的一些用法： @Test public void givenCoordinatesTable_whenFetched_thenOK() { List expectedLongitudes = Arrays.asList(\u0026#34;74.0060° W\u0026#34;, \u0026#34;2.3522° E\u0026#34;, \u0026#34;72.8777° E\u0026#34;); assertArrayEquals(expectedLongitudes.toArray(), cityCoordinates.columnKeySet().toArray()); List expectedCities = Arrays.asList(\u0026#34;New York\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;Mumbai\u0026#34;); assertArrayEquals(expectedCities.toArray(), cityCoordinates.values().toArray()); assertTrue(cityCoordinates.rowKeySet().contains(\u0026#34;48.8566° N\u0026#34;)); } 如我们所见，我们可以获得行、列和值的Set视图。 Table还为我们提供了查询其行或列的能力。 让我们考虑一个电影表来证明这一点： Table\u0026lt;String, String, String\u0026gt; movies = HashBasedTable.create(); movies.put(\u0026#34;Tom Hanks\u0026#34;, \u0026#34;Meg Ryan\u0026#34;, \u0026#34;You\u0026#39;ve Got Mail\u0026#34;); movies.put(\u0026#34;Tom Hanks\u0026#34;, \u0026#34;Catherine Zeta-Jones\u0026#34;, \u0026#34;The Terminal\u0026#34;); movies.put(\u0026#34;Bradley Cooper\u0026#34;, \u0026#34;Lady Gaga\u0026#34;, \u0026#34;A Star is Born\u0026#34;); movies.put(\u0026#34;Keenu Reaves\u0026#34;, \u0026#34;Sandra Bullock\u0026#34;, \u0026#34;Speed\u0026#34;); movies.put(\u0026#34;Tom Hanks\u0026#34;, \u0026#34;Sandra Bullock\u0026#34;, \u0026#34;Extremely Loud \u0026amp; Incredibly Close\u0026#34;); 以下是我们可以在电影 表上进行的一些示例、不言自明的搜索： @Test public void givenMoviesTable_whenFetched_thenOK() { assertEquals(3, movies.row(\u0026#34;Tom Hanks\u0026#34;).size()); assertEquals(2, movies.column(\u0026#34;Sandra Bullock\u0026#34;).size()); assertEquals(\u0026#34;A Star is Born\u0026#34;, movies.get(\u0026#34;Bradley Cooper\u0026#34;, \u0026#34;Lady Gaga\u0026#34;)); assertTrue(movies.containsValue(\u0026#34;Speed\u0026#34;)); } 但是，Table限制我们只能将两个键映射到一个值。在 Guava 中，我们还没有将两个以上的键映射到单个值的替代方法。 6.2. Apache 的 MultiKeyMap 回到我们的cityCoordinates示例，下面是我们如何使用MultiKeyMap来操作它： @Test public void givenCoordinatesMultiKeyMap_whenQueried_thenOK() { MultiKeyMap\u0026lt;String, String\u0026gt; cityCoordinates = new MultiKeyMap\u0026lt;String, String\u0026gt;(); // populate with keys and values as shown previously  List expectedLongitudes = Arrays.asList(\u0026#34;72.8777° E\u0026#34;, \u0026#34;2.3522° E\u0026#34;, \u0026#34;74.0060° W\u0026#34;); List longitudes = new ArrayList\u0026lt;\u0026gt;(); cityCoordinates.forEach((key, value) -\u0026gt; { longitudes.add(key.getKey(1)); }); assertArrayEquals(expectedLongitudes.toArray(), longitudes.toArray()); List expectedCities = Arrays.asList(\u0026#34;Mumbai\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;New York\u0026#34;); List cities = new ArrayList\u0026lt;\u0026gt;(); cityCoordinates.forEach((key, value) -\u0026gt; { cities.add(value); }); assertArrayEquals(expectedCities.toArray(), cities.toArray()); } 正如我们从上面的代码片段中看到的那样，要获得与 Guava 的Table相同的断言，我们必须遍历MultiKeyMap。 然而，** MultiKeyMap也提供了将两个以上的键映射到一个值的可能性**。例如，它使我们能够将一周中的几天映射为工作日或周末： @Test public void givenDaysMultiKeyMap_whenFetched_thenOK() { days = new MultiKeyMap\u0026lt;String, String\u0026gt;(); days.put(\u0026#34;Monday\u0026#34;, \u0026#34;Tuesday\u0026#34;, \u0026#34;Wednesday\u0026#34;, \u0026#34;Thursday\u0026#34;, \u0026#34;Friday\u0026#34;, \u0026#34;Weekday\u0026#34;); days.put(\u0026#34;Saturday\u0026#34;, \u0026#34;Sunday\u0026#34;, \u0026#34;Weekend\u0026#34;); assertFalse(days.get(\u0026#34;Saturday\u0026#34;, \u0026#34;Sunday\u0026#34;).equals(\u0026#34;Weekday\u0026#34;)); } 7. Apache Commons Collections 与 Google Guava 根据其工程师的说法，Google Guava 的诞生是出于在库中使用泛型的需要，而 Apache Commons 没有提供。它还遵循 tee 的集合 API 要求。另一个主要优势是它正在积极开发中，新版本经常发布。 但是，在从集合中获取值时，Apache 在性能方面提供了优势。不过，就插入时间而言，番石榴仍然占据优势。 尽管我们只比较了代码示例中的集合 API，但与 Guava 相比，Apache Commons 作为一个整体提供了更大范围的功能。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_collections_vs_guava/","tags":[],"title":"Apache Commons Collections 与 Google Guava"},{"categories":["Java Collections"],"contents":"1. 概述 简而言之，Apache CollectionUtils为常见操作提供了实用方法，涵盖了广泛的用例，并有助于避免编写样板代码。该库针对较旧的 JVM 版本，因为目前 Java 8 的Stream API 提供了类似的功能。 2. Maven依赖 我们需要添加以下依赖项才能使用CollectionUtils： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到该库的最新版本。 3. 设置 让我们添加客户和地址类： public class Customer { private Integer id; private String name; private Address address; // standard getters and setters } public class Address { private String locality; private String city; // standard getters and setters } 我们还将保留以下Customer和List实例，以便测试我们的实现： Customer customer1 = new Customer(1, \u0026#34;Daniel\u0026#34;, \u0026#34;locality1\u0026#34;, \u0026#34;city1\u0026#34;); Customer customer2 = new Customer(2, \u0026#34;Fredrik\u0026#34;, \u0026#34;locality2\u0026#34;, \u0026#34;city2\u0026#34;); Customer customer3 = new Customer(3, \u0026#34;Kyle\u0026#34;, \u0026#34;locality3\u0026#34;, \u0026#34;city3\u0026#34;); Customer customer4 = new Customer(4, \u0026#34;Bob\u0026#34;, \u0026#34;locality4\u0026#34;, \u0026#34;city4\u0026#34;); Customer customer5 = new Customer(5, \u0026#34;Cat\u0026#34;, \u0026#34;locality5\u0026#34;, \u0026#34;city5\u0026#34;); Customer customer6 = new Customer(6, \u0026#34;John\u0026#34;, \u0026#34;locality6\u0026#34;, \u0026#34;city6\u0026#34;); List\u0026lt;Customer\u0026gt; list1 = Arrays.asList(customer1, customer2, customer3); List\u0026lt;Customer\u0026gt; list2 = Arrays.asList(customer4, customer5, customer6); List\u0026lt;Customer\u0026gt; list3 = Arrays.asList(customer1, customer2); List\u0026lt;Customer\u0026gt; linkedList1 = new LinkedList\u0026lt;\u0026gt;(list1); 4. CollectionUtils 让我们来看看Apache Commons CollectionUtils类中一些最常用的方法。 4.1 仅添加非空元素 我们可以使用CollectionUtils 的 addIgnoreNull方法仅将非空元素添加到提供的集合中。 这个方法的第一个参数是我们想要添加元素的集合，第二个参数是我们想要添加的元素： @Test public void givenList_whenAddIgnoreNull_thenNoNullAdded() { CollectionUtils.addIgnoreNull(list1, null); assertFalse(list1.contains(null)); } 请注意，null未添加到列表中。 4.2. 整理清单 **我们可以使用collat​​e方法来整理两个已经排序的列表。**此方法将我们要合并的两个列表作为参数并返回一个排序列表： @Test public void givenTwoSortedLists_whenCollated_thenSorted() { List\u0026lt;Customer\u0026gt; sortedList = CollectionUtils.collate(list1, list2); assertEquals(6, sortedList.size()); assertTrue(sortedList.get(0).getName().equals(\u0026#34;Bob\u0026#34;)); assertTrue(sortedList.get(2).getName().equals(\u0026#34;Daniel\u0026#34;)); } 4.3. 变换对象 我们可以使用transform方法将 A 类的对象转换为 B 类的不同对象。该方法将 A 类的对象列表和转换器作为参数。 此操作的结果是 B 类对象的列表： @Test public void givenListOfCustomers_whenTransformed_thenListOfAddress() { Collection\u0026lt;Address\u0026gt; addressCol = CollectionUtils.collect(list1, new Transformer\u0026lt;Customer, Address\u0026gt;() { public Address transform(Customer customer) { return customer.getAddress(); } }); List\u0026lt;Address\u0026gt; addressList = new ArrayList\u0026lt;\u0026gt;(addressCol); assertTrue(addressList.size() == 3); assertTrue(addressList.get(0).getLocality().equals(\u0026#34;locality1\u0026#34;)); } 4.4. 过滤对象 使用过滤器，我们可以从列表中删除不满足给定条件的对象***。*** 该方法将列表作为第一个参数，将Predicate作为第二个参数。 *filterInverse方法则相反。*当Predicate返回 true 时，它​​会从列表中删除对象。 如果修改了输入列表，即从列表中过滤出至少一个对象，则filter和filterInverse都返回true ： @Test public void givenCustomerList_WhenFiltered_thenCorrectSize() { boolean isModified = CollectionUtils.filter(linkedList1, new Predicate\u0026lt;Customer\u0026gt;() { public boolean evaluate(Customer customer) { return Arrays.asList(\u0026#34;Daniel\u0026#34;,\u0026#34;Kyle\u0026#34;).contains(customer.getName()); } }); assertTrue(linkedList1.size() == 2); } 如果我们希望返回结果列表而不是布尔标志，我们可以使用select和selectRejected 。 4.5. 检查非空 *当我们想要检查列表中是否至少有一个元素时，isNotEmpty方法非常方便。***另一种检查方法是： boolean isNotEmpty = (list != null \u0026amp;\u0026amp; list.size() \u0026gt; 0); 尽管上面的代码行相同，但CollectionUtils.isNotEmpty使我们的代码更干净： @Test public void givenNonEmptyList_whenCheckedIsNotEmpty_thenTrue() { assertTrue(CollectionUtils.isNotEmpty(list1)); } **isEmpty则相反。**它检查给定列表是否为空或列表中是否有零个元素： List\u0026lt;Customer\u0026gt; emptyList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Customer\u0026gt; nullList = null; assertTrue(CollectionUtils.isEmpty(nullList)); assertTrue(CollectionUtils.isEmpty(emptyList)); 4.6. 检查包含 我们可以使用isSubCollection来检查一个集合是否包含在另一个集合中。isSubCollection将两个集合作为参数，如果第一个集合是第二个集合的子集合，则返回true ： @Test public void givenCustomerListAndASubcollection_whenChecked_thenTrue() { assertTrue(CollectionUtils.isSubCollection(list3, list1)); } 如果一个对象在第一个集合中出现的次数小于或等于它在第二个集合中出现的次数，则一个集合是另一个集合的子集合。 4.7. 集合的交集 **我们可以使用CollectionUtils.intersection方法来获取两个集合的交集。**此方法接受两个集合并返回两个输入集合中共有的元素集合： @Test public void givenTwoLists_whenIntersected_thenCheckSize() { Collection\u0026lt;Customer\u0026gt; intersection = CollectionUtils.intersection(list1, list3); assertTrue(intersection.size() == 2); } 元素在结果集合中出现的次数是它在每个给定集合中出现的次数的最小值。 4.8. 减去集合 CollectionUtils.subtract将两个集合作为输入并返回一个集合，该集合包含第一个集合中存在但第二个集合中不存在的元素： @Test public void givenTwoLists_whenSubtracted_thenCheckElementNotPresentInA() { Collection\u0026lt;Customer\u0026gt; result = CollectionUtils.subtract(list1, list3); assertFalse(result.contains(customer1)); } 一个集合在结果中出现的次数是它在第一个集合中出现的次数减去它在第二个集合中出现的次数。 4.9. 集合合并 CollectionUtils.union合并两个集合并返回一个集合，该集合包含第一个或第二个集合中的所有元素。 @Test public void givenTwoLists_whenUnioned_thenCheckElementPresentInResult() { Collection\u0026lt;Customer\u0026gt; union = CollectionUtils.union(list1, list2); assertTrue(union.contains(customer1)); assertTrue(union.contains(customer4)); } 元素在结果集合中出现的次数是它在每个给定集合中出现的次数的最大值。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_collection_utils/","tags":[],"title":"Apache Commons CollectionUtils 指南"},{"categories":["Java"],"contents":"1. 简介 Apache Commons Chain是一个使用责任链模式的库——通常用于组织复杂的处理流程，其中多个接收者可以处理一个请求。 在这篇快速文章中，我们将通过一个表示从 ATM 取款的示例。 2. Maven依赖 首先，我们将使用 Maven 导入该库的最新版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-chain\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-chain\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查这个库的最新版本——去这里。 3. 示例链 ATM 将一个数字作为输入并将其传递给负责执行不同操作的处理程序。这些包括计算要分发的钞票数量，并向银行和客户发送有关交易的通知。 4. 链上下文 上下文表示应用程序的当前状态，存储有关事务的信息。 对于我们的 ATM 取款请求，我们需要的信息是：  提款总额 100面额纸币数量 50面额纸币数量 10面额纸币数量 剩余金额  此状态在一个类中定义： public class AtmRequestContext extends ContextBase { int totalAmountToBeWithdrawn; int noOfHundredsDispensed; int noOfFiftiesDispensed; int noOfTensDispensed; int amountLeftToBeWithdrawn; // standard setters \u0026amp; getters } 5. 命令 Command将Context作为输入并对其进行处理。 我们将把上面提到的每个步骤作为一个命令来实现： public class HundredDenominationDispenser implements Command { @Override public boolean execute(Context context) throws Exception { intamountLeftToBeWithdrawn = (int) context.get(\u0026#34;amountLeftToBeWithdrawn); if (amountLeftToBeWithdrawn \u0026gt;= 100) { context.put(\u0026#34;noOfHundredsDispensed\u0026#34;, amountLeftToBeWithdrawn / 100); context.put(\u0026#34;amountLeftToBeWithdrawn\u0026#34;, amountLeftToBeWithdrawn % 100); } return false; } } FiftyDenominationDispenser和TenDenominationDispenser的Command*类似。 6. 链条 Chain是按指定顺序执行的命令的集合。我们的Chain将由上述Command和最后的AuditFilter 组成： public class AtmWithdrawalChain extends ChainBase { public AtmWithdrawalChain() { super(); addCommand(new HundredDenominationDispenser()); addCommand(new FiftyDenominationDispenser()); addCommand(new TenDenominationDispenser()); addCommand(new AuditFilter()); } } 当Chain中的任何命令返回 true 时，它会强制Chain结束。 7. 过滤 过滤器也是一个命令，但具有在Chain执行后调用的postProcess方法。 我们的Filter将向客户和银行发送通知： public class AuditFilter implements Filter { @Override public boolean postprocess(Context context, Exception exception) { // send notification to bank and user  return false; } @Override public boolean execute(Context context) throws Exception { return false; } } 8. 链目录 它是具有逻辑名称的Chain和命令的集合。 在我们的例子中，我们的目录将包含AtmWithdrawalChain。 public class AtmCatalog extends CatalogBase { public AtmCatalog() { super(); addCommand(\u0026#34;atmWithdrawalChain\u0026#34;, new AtmWithdrawalChain()); } } 9. 使用链条 让我们看看我们如何使用上述Chain来处理提款请求。我们将首先创建一个Context，然后将其传递给Chain。Chain将处理Context。 我们将编写一个测试用例来演示我们的AtmWithdrawalChain： public class AtmChainTest { @Test public void givenInputsToContext_whenAppliedChain_thenExpectedContext() throws Exception { Context context = new AtmRequestContext(); context.put(\u0026#34;totalAmountToBeWithdrawn\u0026#34;, 460); context.put(\u0026#34;amountLeftToBeWithdrawn\u0026#34;, 460); Catalog catalog = new AtmCatalog(); Command atmWithdrawalChain = catalog.getCommand(\u0026#34;atmWithdrawalChain\u0026#34;); atmWithdrawalChain.execute(context); assertEquals(460, (int) context.get(\u0026#34;totalAmountToBeWithdrawn\u0026#34;)); assertEquals(0, (int) context.get(\u0026#34;amountLeftToBeWithdrawn\u0026#34;)); assertEquals(4, (int) context.get(\u0026#34;noOfHundredsDispensed\u0026#34;)); assertEquals(1, (int) context.get(\u0026#34;noOfFiftiesDispensed\u0026#34;)); assertEquals(1, (int) context.get(\u0026#34;noOfTensDispensed\u0026#34;)); } } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_chain/","tags":["Pattern"],"title":"Apache Commons Chain"},{"categories":["Data"],"contents":"1. 概述 Apache Commons BeansUtils 包含使用 Java bean 所需的所有工具。 简单地说，bean 是一个简单的 Java 类，包含字段、getter/setter 和无参数构造函数。 Java 提供反射和自省功能来识别 getter-setter 方法并动态调用它们。但是，这些 API 可能很难学习，并且可能需要开发人员编写样板代码来执行最简单的操作。 2. Maven依赖 这是在使用它之前需要在 POM 文件中包含的 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-beanutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-beanutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本可以在这里找到。 3. 创建一个 Java Bean 让我们使用典型的 getter 和 setter 方法创建两个 bean 类Course和Student 。 public class Course { private String name; private List\u0026lt;String\u0026gt; codes; private Map\u0026lt;String, Student\u0026gt; enrolledStudent = new HashMap\u0026lt;\u0026gt;(); // standard getters/setters } public class Student { private String name; // standard getters/setters } 我们有一个具有课程名称、课程代码和多个注册学生的课程类。注册学生由唯一的注册 ID 标识。课程类在Map对象中维护注册学生，其中注册 ID 是键，学生对象将是值。 4. 访问属性  Bean 的属性可以分为三类。 4.1 简单属性 单值属性也称为简单或标量。 它们的值可能是原始类型（例如 int、float）或复杂类型对象。BeanUtils 有一个PropertyUtils类，它允许我们修改 Java Bean 中的简单属性。 这是设置属性的示例代码： Course course = new Course(); String name = \u0026#34;Computer Science\u0026#34;; List\u0026lt;String\u0026gt; codes = Arrays.asList(\u0026#34;CS\u0026#34;, \u0026#34;CS01\u0026#34;); PropertyUtils.setSimpleProperty(course, \u0026#34;name\u0026#34;, name); PropertyUtils.setSimpleProperty(course, \u0026#34;codes\u0026#34;, codes); 4.2. 索引属性 索引属性有一个集合作为可以使用索引号单独访问的值。作为 JavaBean 的扩展，BeanUtils 也将java.util.List类型值视为索引。 我们可以使用PropertyUtils 的 setIndexedProperty方法修改索引属性的单个值。 这是修改索引属性的示例代码： PropertyUtils.setIndexedProperty(course, \u0026#34;codes[1]\u0026#34;, \u0026#34;CS02\u0026#34;); 4.3. 映射属性 任何以java.util.Map作为基础类型的属性都称为映射属性。BeanUtils 允许我们使用字符串值键更新映射中的单个值。 这是修改映射属性中的值的示例代码： Student student = new Student(); String studentName = \u0026#34;Joe\u0026#34;; student.setName(studentName); PropertyUtils.setMappedProperty(course, \u0026#34;enrolledStudent(ST-1)\u0026#34;, student); 5. 嵌套属性访问 如果一个属性值是一个对象并且我们需要访问该对象内部的一个属性值——那将是访问一个嵌套属性。PropertyUtils也允许我们访问和修改嵌套属性。 假设我们想通过Course对象访问Student类的 name 属性。我们可能会写： String name = course.getEnrolledStudent(\u0026#34;ST-1\u0026#34;).getName(); 我们可以使用getNestedProperty访问嵌套属性值，并使用 PropertyUtils 中的**setNestedProperty方法修改嵌套属性。这是代码： Student student = new Student(); String studentName = \u0026#34;Joe\u0026#34;; student.setName(studentName); String nameValue = (String) PropertyUtils.getNestedProperty( course, \u0026#34;enrolledStudent(ST-1).name\u0026#34;); 6. 复制Bean属性 将一个对象的属性复制到另一个对象对于开发人员来说通常是乏味且容易出错的。BeanUtils类提供了一个copyProperties方法，该方法将源对象的属性复制到**两个对象中属性名称相同的目标对象。 让我们创建另一个 bean 类，作为我们在上面创建的Course具有相同的属性，除了它不会有registeredStudent属性而是属性名称将是students。让我们将该类命名为CourseEntity。该类将如下所示： public class CourseEntity { private String name; private List\u0026lt;String\u0026gt; codes; private Map\u0026lt;String, Student\u0026gt; students = new HashMap\u0026lt;\u0026gt;(); // standard getters/setters } 现在我们将Course对象的属性复制到CourseEntity对象： Course course = new Course(); course.setName(\u0026#34;Computer Science\u0026#34;); course.setCodes(Arrays.asList(\u0026#34;CS\u0026#34;)); course.setEnrolledStudent(\u0026#34;ST-1\u0026#34;, new Student()); CourseEntity courseEntity = new CourseEntity(); BeanUtils.copyProperties(courseEntity, course); 请记住，这将仅复制具有相同名称的属性。因此，它不会复制Course类中的属性registeredStudent，因为 CourseEntity**类中没有同名的属性。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_beanutils/","tags":[],"title":"Apache Commons BeanUtils"},{"categories":["Java Collections"],"contents":"1. 简介 在这篇快速文章中，我们将重点介绍如何使用 Apache 的Bag集合。 2. Maven依赖 在开始之前，我们需要从Maven Central导入最新的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Bag与Collection 简而言之，Bag是一个允许存储多个项目及其重复次数的集合： public void whenAdded_thenCountIsKept() { Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;( Arrays.asList(1, 2, 3, 3, 3, 1, 4)); assertThat(2, equalTo(bag.getCount(1))); } 3.1 违反Collection合同 在阅读Bag的 API 文档时，我们可能会注意到某些方法被标记为违反标准 Java 的 Collection 契约。 例如，当我们使用 Java 集合中的add() API 时，即使项目已经在集合中，我们也会收到true ： Collection\u0026lt;Integer\u0026gt; collection = new ArrayList\u0026lt;\u0026gt;(); collection.add(1); assertThat(collection.add(1), is(true)); 当我们添加集合中已经可用的元素时，来自Bag实现的相同 API将返回false ： Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;(); bag.add(1); assertThat(bag.add(1), is(not(true))); 为了解决这些问题，Apache Collections 的库提供了一个名为CollectionBag 的装饰器。我们可以使用它来使我们的包集合符合 Java集合合约： public void whenBagAddAPILikeCollectionAPI_thenTrue() { Bag\u0026lt;Integer\u0026gt; bag = CollectionBag.collectionBag(new HashBag\u0026lt;\u0026gt;()); bag.add(1); assertThat(bag.add(1), is((true))); } 4. 包的实现 现在让我们在 Apache 的集合库中探索Bag接口的各种实现。 4.1 哈希包 我们可以添加一个元素并指示 API 该元素在我们的包集合中应具有的副本数： public void givenAdd_whenCountOfElementsDefined_thenCountAreAdded() { Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;(); bag.add(1, 5); // adding 1 five times  assertThat(5, equalTo(bag.getCount(1))); } 我们还可以从我们的包中删除特定数量的副本或元素的每个实例： public void givenMultipleCopies_whenRemove_allAreRemoved() { Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;( Arrays.asList(1, 2, 3, 3, 3, 1, 4)); bag.remove(3, 1); // remove one element, two still remain  assertThat(2, equalTo(bag.getCount(3))); bag.remove(1); // remove all  assertThat(0, equalTo(bag.getCount(1))); } 4.2. TreeBag TreeBag实现与任何其他树一样工作，另外还维护Bag**语义。 我们可以自然地使用TreeBag对整数数组进行排序，然后查询每个单独元素在集合中的实例数： public void givenTree_whenDuplicateElementsAdded_thenSort() { TreeBag\u0026lt;Integer\u0026gt; bag = new TreeBag\u0026lt;\u0026gt;(Arrays.asList(7, 5, 1, 7, 2, 3, 3, 3, 1, 4, 7)); assertThat(bag.first(), equalTo(1)); assertThat(bag.getCount(bag.first()), equalTo(2)); assertThat(bag.last(), equalTo(7)); assertThat(bag.getCount(bag.last()), equalTo(3)); } TreeBag实现了一个SortedBag接口，该接口的所有实现都可以使用装饰器CollectionSortedBag来遵守 Java Collections 契约： public void whenTreeAddAPILikeCollectionAPI_thenTrue() { SortedBag\u0026lt;Integer\u0026gt; bag = CollectionSortedBag.collectionSortedBag(new TreeBag\u0026lt;\u0026gt;()); bag.add(1); assertThat(bag.add(1), is((true))); } 4.3. SynchronizedSortedBag Bag的另一个广泛使用的实现是SynchronizedSortedBag。准确地说，这是一个SortedBag实现的同步装饰器。 我们可以将此装饰器与上一节中的TreeBag（SortedBag 的实现*）*一起使用，以同步对我们包的访问： public void givenSortedBag_whenDuplicateElementsAdded_thenSort() { SynchronizedSortedBag\u0026lt;Integer\u0026gt; bag = SynchronizedSortedBag .synchronizedSortedBag(new TreeBag\u0026lt;\u0026gt;( Arrays.asList(7, 5, 1, 7, 2, 3, 3, 3, 1, 4, 7))); assertThat(bag.first(), equalTo(1)); assertThat(bag.getCount(bag.first()), equalTo(2)); assertThat(bag.last(), equalTo(7)); assertThat(bag.getCount(bag.last()), equalTo(3)); } 我们可以使用 API 的组合——Collections.synchronizedSortedMap()和TreeMap——来模拟我们在这里使用SynchronizedSortedBag所做的事情。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_bag/","tags":[],"title":"Apache Commons Bag"},{"categories":["Persistence"],"contents":"1. 概述 之前，我们专注于如何开始使用 Apache Cayenne。 在本文中，我们将介绍如何使用 ORM 编写简单和高级查询。 2. 设置 该设置类似于上一篇文章中使用的设置。 **3.对象选择 ** 让我们从简单的开始，看看我们如何获取名字中包含“Paul”的所有作者： @Test public void whenContainsObjS_thenWeGetOneRecord() { List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.contains(\u0026#34;Paul\u0026#34;)) .select(context); assertEquals(authors.size(), 1); } 接下来，让我们看看如何在 Author\u0026rsquo;s name 列上应用不区分大小写的 LIKE 类型的查询： @Test void whenLikeObjS_thenWeGetTwoAuthors() { List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.likeIgnoreCase(\u0026#34;Paul%\u0026#34;)) .select(context); assertEquals(authors.size(), 2); } 接下来，*endsWith()*表达式将只返回一条记录，因为只有一位作者具有匹配的姓名： @Test void whenEndsWithObjS_thenWeGetOrderedAuthors() { List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.endsWith(\u0026#34;Sarra\u0026#34;)) .select(context); Author firstAuthor = authors.get(0); assertEquals(authors.size(), 1); assertEquals(firstAuthor.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 更复杂的是查询名称在列表中的作者： @Test void whenInObjS_thenWeGetAuthors() { List names = Arrays.asList( \u0026#34;Paul Xavier\u0026#34;, \u0026#34;pAuL Smith\u0026#34;, \u0026#34;Vicky Sarra\u0026#34;); List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.in(names)) .select(context); assertEquals(authors.size(), 3); } 第九个是相反的，这里只有“Vicky”会出现在结果中： @Test void whenNinObjS_thenWeGetAuthors() { List names = Arrays.asList( \u0026#34;Paul Xavier\u0026#34;, \u0026#34;pAuL Smith\u0026#34;); List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.nin(names)) .select(context); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 请注意，以下两个代码是相同的，因为它们都将创建具有相同参数的相同类型的表达式： Expression qualifier = ExpressionFactory .containsIgnoreCaseExp(Author.NAME.getName(), \u0026#34;Paul\u0026#34;); Author.NAME.containsIgnoreCase(\u0026#34;Paul\u0026#34;); 以下是*Expression* 和ExpressionFactory类中一些可用表达式的列表*：*  likeExp : 用于构建 LIKE 表达式 likeIgnoreCaseExp：用于构建 LIKE_IGNORE_CASE 表达式 containsExp : LIKE 查询的表达式，其模式匹配字符串中的任何位置 containsIgnoreCaseExp ：与**containsExp相同，但使用不区分大小写的方法 startsWithExp：模式应该匹配字符串的开头 startsWithIgnoreCaseExp：类似于startsWithExp但使用不区分大小写的方法 endsWithExp : 匹配字符串结尾的表达式 endsWithIgnoreCaseExp：使用不区分大小写的方法匹配字符串结尾的表达式 expTrue : 布尔真表达式 expFalse : 用于布尔假表达式 andExp：用于用and运算符链接两个表达式 orExp : 使用or运算符链接两个表达式  4. SelectQuery 它是用户应用程序中使用最广泛的查询类型。SelectQuery描述了一个简单而强大的 API，其行为类似于 SQL 语法，但仍然使用 Java 对象和方法，然后使用构建器模式来构造更复杂的表达式。 在这里，我们谈论的是一种表达式语言，其中我们使用Expression（用于构建表达式）又名限定符和Ordering（用于对结果排序）类构建查询，这些类接下来由 ORM 转换为原生 SQL。 为了看到这一点，我们汇总了一些测试，在实践中展示了如何构建一些表达式和对数据进行排序。 让我们应用一个 LIKE 查询来获取名称为“Paul”的作者**：** @Test void whenLikeSltQry_thenWeGetOneAuthor() { Expression qualifier = ExpressionFactory.likeExp(Author.NAME.getName(), \u0026#34;Paul%\u0026#34;); SelectQuery query = new SelectQuery(Author.class, qualifier); List\u0026lt;Author\u0026gt; authorsTwo = context.performQuery(query); assertEquals(authorsTwo.size(), 1); } 这意味着如果您不向查询 ( SelectQuery ) 提供任何表达式，则结果将是 Author 表的所有记录。 可以使用containsIgnoreCaseExp表达式执行类似的查询，以获取姓名中包含 Paul 的所有作者，无论字母的大小写如何： @Test void whenCtnsIgnorCaseSltQry_thenWeGetTwoAuthors() { Expression qualifier = ExpressionFactory .containsIgnoreCaseExp(Author.NAME.getName(), \u0026#34;Paul\u0026#34;); SelectQuery query = new SelectQuery(Author.class, qualifier); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); assertEquals(authors.size(), 2); } 类似地，让我们以不区分大小写的方式（containsIgnoreCaseExp ）获取名称包含“Paul”的作者，并以字母 h结尾的名称（endsWithExp ）： @Test void whenCtnsIgnorCaseEndsWSltQry_thenWeGetTwoAuthors() { Expression qualifier = ExpressionFactory .containsIgnoreCaseExp(Author.NAME.getName(), \u0026#34;Paul\u0026#34;) .andExp(ExpressionFactory .endsWithExp(Author.NAME.getName(), \u0026#34;h\u0026#34;)); SelectQuery query = new SelectQuery( Author.class, qualifier); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;pAuL Smith\u0026#34;); } 可以使用Ordering类执行升序： @Test void whenAscOrdering_thenWeGetOrderedAuthors() { SelectQuery query = new SelectQuery(Author.class); query.addOrdering(Author.NAME.asc()); List\u0026lt;Author\u0026gt; authors = query.select(context); Author firstAuthor = authors.get(0); assertEquals(authors.size(), 3); assertEquals(firstAuthor.getName(), \u0026#34;Paul Xavier\u0026#34;); } 这里不使用query.addOrdering(Author.NAME.asc())，我们也可以只使用SortOrder类来获取升序： query.addOrdering(Author.NAME.getName(), SortOrder.ASCENDING); 相对有降序排列： @Test void whenDescOrderingSltQry_thenWeGetOrderedAuthors() { SelectQuery query = new SelectQuery(Author.class); query.addOrdering(Author.NAME.desc()); List\u0026lt;Author\u0026gt; authors = query.select(context); Author firstAuthor = authors.get(0); assertEquals(authors.size(), 3); assertEquals(firstAuthor.getName(), \u0026#34;pAuL Smith\u0026#34;); } 正如我们在前面的示例中看到的 - 设置此排序的另一种方法是： query.addOrdering(Author.NAME.getName(), SortOrder.DESCENDING); **5. SQLTemplate ** SQLTemplate也是我们可以与 Cayenne 一起使用以不使用对象样式查询的一种替代方法。 使用SQLTemplate构建查询与使用某些参数编写本机 SQL 语句直接相关。让我们实现一些简单的例子。 以下是我们在每次测试后删除所有作者的方法： @After void deleteAllAuthors() { SQLTemplate deleteAuthors = new SQLTemplate( Author.class, \u0026#34;delete from author\u0026#34;); context.performGenericQuery(deleteAuthors); } 要查找所有记录的作者，我们只需要应用 SQL 查询select * from Author，我们将直接看到结果是正确的，因为我们恰好保存了三个作者： @Test void givenAuthors_whenFindAllSQLTmplt_thenWeGetThreeAuthors() { SQLTemplate select = new SQLTemplate( Author.class, \u0026#34;select * from Author\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(select); assertEquals(authors.size(), 3); } 接下来，让我们获取名为“Vicky Sarra”的作者： @Test void givenAuthors_whenFindByNameSQLTmplt_thenWeGetOneAuthor() { SQLTemplate select = new SQLTemplate( Author.class, \u0026#34;select * from Author where name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(select); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 6. EJBQL查询 接下来，让我们通过*EJBQLQuery 查询数据，*它是作为在 Cayenne 中采用 Java Persistence API 的实验的一部分而创建的。 在这里，查询以参数化的对象样式应用；让我们看一些实际的例子。 首先，所有已保存作者的搜索将如下所示： @Test void givenAuthors_whenFindAllEJBQL_thenWeGetThreeAuthors() { EJBQLQuery query = new EJBQLQuery(\u0026#34;select a FROM Author a\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); assertEquals(authors.size(), 3); } 让我们再次使用名称“Vicky Sarra”搜索作者，但现在使用EJBQLQuery： @Test void givenAuthors_whenFindByNameEJBQL_thenWeGetOneAuthor() { EJBQLQuery query = new EJBQLQuery( \u0026#34;select a FROM Author a WHERE a.name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 一个更好的例子是更新作者： @Test void whenUpdadingByNameEJBQL_thenWeGetTheUpdatedAuthor() { EJBQLQuery query = new EJBQLQuery( \u0026#34;UPDATE Author AS a SET a.name \u0026#34; + \u0026#34;= \u0026#39;Vicky Edison\u0026#39; WHERE a.name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;); QueryResponse queryResponse = context.performGenericQuery(query); EJBQLQuery queryUpdatedAuthor = new EJBQLQuery( \u0026#34;select a FROM Author a WHERE a.name = \u0026#39;Vicky Edison\u0026#39;\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(queryUpdatedAuthor); Author author = authors.get(0); assertNotNull(author); } 如果我们只想选择一列，我们应该使用这个查询*“select a.name FROM Author a”*。 7. SQLExec SQLExec也是从 Cayenne M4 版本引入的一个新的 Fluent 查询 API。 一个简单的插入看起来像这样： @Test void whenInsertingSQLExec_thenWeGetNewAuthor() { int inserted = SQLExec .query(\u0026#34;INSERT INTO Author (name) VALUES (\u0026#39;codingman\u0026#39;)\u0026#34;) .update(context); assertEquals(inserted, 1); } 接下来，我们可以根据作者的姓名更新作者： @Test void whenUpdatingSQLExec_thenItsUpdated() { int updated = SQLExec.query( \u0026#34;UPDATE Author SET name = \u0026#39;codingman\u0026#39; \u0026#34; + \u0026#34;WHERE name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;) .update(context); assertEquals(updated, 1); } 我们可以从文档中获得更多细节。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cayenne_query/","tags":[],"title":"Apache Cayenne 中的高级查询"},{"categories":["Persistence"],"contents":"1. 概述 Apache Cayenne是一个开源库，在 Apache 许可下分发，提供建模工具、对象关系映射（又名 ORM）等功能，用于本地持久性操作和远程服务。 在以下部分中，我们将了解如何使用 Apache Cayenne ORM 与 MySQL 数据库进行交互。 2. Maven依赖 首先，我们只需要添加以下依赖项，即可将 Apache Cayenne 和 MySQL 连接器与 JDBC 驱动程序一起访问我们的intro_cayenne数据库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cayenne\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cayenne-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.M5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.44\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 让我们配置 Cayenne 建模器插件，该插件将用于设计或设置我们的映射文件，该文件充当数据库模式和 Java 对象之间的桥梁： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cayenne.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-cayenne-modeler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.M5\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; 建议不要手动构建 XML 映射文件（很少制作），而是使用建模器，它是 Cayenne 发行版附带的一个非常高级的工具。 根据您的操作系统，可以从这个存档下载它，或者只使用作为 Maven 插件包含的跨平台版本 (JAR)。 Maven 中央存储库托管最新版本的Apache Cayenne、他的建模器和MySQL 连接器。 接下来，让我们使用mvn install构建我们的项目，并使用命令mvn cayenne-modeler:run 启动建模器 GUI，以获取此屏幕的输出： 3. 设置 要让 Apache Cayenne 查找正确的本地数据库，我们只需在资源目录中的文件cayenne-project.xml中使用正确的驱动程序、URL 和用户填充他的配置文件： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;domain project-version=\u0026#34;9\u0026#34;\u0026gt; \u0026lt;node name=\u0026#34;datanode\u0026#34; factory =\u0026#34;org.apache.cayenne.configuration.server.XMLPoolingDataSourceFactory\u0026#34; schema-update-strategy =\u0026#34;org.apache.cayenne.access.dbsync.CreateIfNoSchemaStrategy\u0026#34;\u0026gt; \u0026lt;data-source\u0026gt; \u0026lt;driver value=\u0026#34;com.mysql.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;url value =\u0026#34;jdbc:mysql://localhost:3306/intro_cayenne;create=true\u0026#34;/\u0026gt; \u0026lt;connectionPool min=\u0026#34;1\u0026#34; max=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;login userName=\u0026#34;root\u0026#34; password=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;/data-source\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/domain\u0026gt; 在这里我们可以看到：  本地数据库名为intro_cayenne 如果尚未创建，Cayenne 将为我们完成 我们将使用用户名root和密码root进行连接（根据在您的数据库管理系统中注册的用户进行更改）  在内部，它是XMLPoolingDataSourceFactory负责从与DataNodeDescriptor关联的 XML 资源加载 JDBC 连接信息。 请注意，这些参数与数据库管理系统和 JDBC 驱动程序相关，因为该库可以支持许多不同的数据库。 在此详细列表中，它们中的每一个都有一个可用的适配器。请注意，尚未提供 4.0 版的完整文档，因此我们在此处参考之前的版本。 4. 映射和数据库设计 4.1 造型 现在让我们单击*“打开项目”，导航到项目的资源文件夹并选择文件cayenne-project.xml，*建模器将显示以下内容： 在这里，我们可以选择从现有数据库创建映射结构 **或手动进行。**本文将处理使用建模器和现有数据库进入 Cayenne 并快速了解其工作原理的问题。 让我们看一下我们的intro_cayenne数据库，它在两个表之间具有一对多的关系，因为作者可以发布或拥有许多文章：  作者：id（PK）和姓名 文章：id (PK)、title、content和author_id(FK)  现在让我们转到“工具 \u0026gt; 重新设计数据库模式”，我们将自动填充所有映射配置。在提示屏幕上，只需填写cayenne-project.xml文件中可用的数据源配置，然后点击继续： 在下一个屏幕上，我们需要检查“使用 Java 原始类型”，如下所示： 我们还需要确保将com.codingman.apachecayenne.persistent作为 Java 包并保存；我们将看到 XML 配置文件已更新其defaultPackage属性以匹配 Java 包： 在每个ObjEntity 中，我们必须为子类指定包，如下图所示，然后再次单击*“保存”*图标： 现在在*“Tools \u0026gt; Generate Classes”菜单上，选择“ Standard Persistent Objects ”作为类型；并在“类”选项卡上检查所有类并点击“生成”*。 回到源码看看我们的持久化对象已经生成成功了，说说*_Article.java和_Author.java*。 请注意，所有这些配置都保存在文件datamap.map.xml中，该文件也位于资源文件夹中。 4.2. 映射结构 资源文件夹中生成的 XML 映射文件使用了一些与 Apache Cayenne 相关的唯一标签：  DataNode() – 数据库的模型，其内容连接到数据库所需的所有信息（数据库名称、驱动程序和用户凭据） DataMap() – 它是持久实体及其关系的容器 DbAttribute() – 表示数据库表中的列 DbEntity() - 单个数据库表或视图的模型，它可以有DbAttributes和关系 ObjEntity() ——单个持久化java类的模型；由对应于实体类属性的 ObjAttributes 和作为具有另一个实体类型的属性的 ObjRelationships 组成 Embeddable() – Java 类的模型，充当 ObjEntity 的属性，但对应于数据库中的多个列 Procedure() – 在数据库中注册存储过程 Query() - 查询的模型，用于在配置文件中映射查询，不要忘记我们也可以在代码中做到这一点  这是完整的细节。 5. Cayenne API 剩下的唯一步骤是使用 Cayenne API 使用生成的类来执行我们的数据库操作，因为我们知道将我们的持久类子类化只是以后用于自定义模型的最佳实践。 5.1 创建对象 在这里，我们只是保存了一个Author对象，稍后检查数据库中是否只有一条该类型的记录： @Test public void whenInsert_thenWeGetOneRecordInTheDatabase() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); long records = ObjectSelect.dataRowQuery(Author.class) .selectCount(context); assertEquals(1, records); } 5.2. 读取对象 保存Author后，我们只需通过特定属性的简单查询来选择它： @Test public void whenInsert_andQueryByFirstName_thenWeGetTheAuthor() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); assertEquals(\u0026#34;Paul\u0026#34;, expectedAuthor.getName()); } 5.3. 检索一个类的所有记录 我们将保存两个作者并检索作者对象的集合以检查是否只保存了这两个： @Test public void whenInsert_andQueryAll_thenWeGetTwoAuthors() { Author firstAuthor = context.newObject(Author.class); firstAuthor.setName(\u0026#34;Paul\u0026#34;); Author secondAuthor = context.newObject(Author.class); secondAuthor.setName(\u0026#34;Ludovic\u0026#34;); context.commitChanges(); List\u0026lt;Author\u0026gt; authors = ObjectSelect .query(Author.class) .select(context); assertEquals(2, authors.size()); } 5.4. 更新对象 更新过程也很简单，但我们需要先拥有所需的对象，然后再修改其属性并将其应用于数据库： @Test public void whenUpdating_thenWeGetAnUpatedeAuthor() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); expectedAuthor.setName(\u0026#34;Garcia\u0026#34;); context.commitChanges(); assertEquals(author.getName(), expectedAuthor.getName()); } 5.5. 附加对象 我们可以将一篇文章分配给作者： @Test public void whenAttachingToArticle_thenTheRelationIsMade() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); Article article = context.newObject(Article.class); article.setTitle(\u0026#34;My post title\u0026#34;); article.setContent(\u0026#34;The content\u0026#34;); article.setAuthor(author); context.commitChanges(); Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Smith\u0026#34;)) .selectOne(context); Article expectedArticle = (expectedAuthor.getArticles()).get(0); assertEquals(article.getTitle(), expectedArticle.getTitle()); } 5.6. 删除对象 删除保存的对象会将其从数据库中完全删除，此后我们将看到null作为查询的结果： @Test public void whenDeleting_thenWeLostHisDetails() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); Author savedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); if(savedAuthor != null) { context.deleteObjects(author); context.commitChanges(); } Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); assertNull(expectedAuthor); } 5.7. 删除班级的所有记录 也可以使用SQLTemplate删除表的所有记录，这里我们在每个测试方法之后执行此操作，以便在每个测试启动之前始终拥有一个 void 数据库*：* @After public void deleteAllRecords() { SQLTemplate deleteArticles = new SQLTemplate( Article.class, \u0026#34;delete from article\u0026#34;); SQLTemplate deleteAuthors = new SQLTemplate( Author.class, \u0026#34;delete from author\u0026#34;); context.performGenericQuery(deleteArticles); context.performGenericQuery(deleteAuthors); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cayenne_orm/","tags":[],"title":"Apache Cayenne ORM 简介"},{"categories":["Spring Boot"],"contents":"1. 概述 Apache Camel 的核心是一个集成引擎，简单地说，它可用于促进各种技术之间的交互。 这些服务和技术之间的桥梁被称为*路由。*路由在引擎（CamelContext）上实现，它们与所谓的“交换消息”进行通信。 2. Maven依赖 首先，我们需要包含 Spring Boot、Camel、带有 Swagger 和 JSON 的 Rest API 的依赖项： \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-servlet-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-jackson-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-swagger-java-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 可以在此处找到最新版本的 Apache Camel 依赖项。 3.主类 让我们首先创建一个 Spring Boot应用程序： @SpringBootApplication @ComponentScan(basePackages=\u0026#34;com.codingman.camel\u0026#34;) public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 4. Spring Boot 的 Camel 配置 现在让我们使用 Spring 配置我们的应用程序，从配置文件（属性）开始。 例如，让我们在src/main/resources的application.properties文件中为我们的应用程序配置一个日志： logging.config=classpath:logback.xml camel.springboot.name=MyCamel server.address=0.0.0.0 management.address=0.0.0.0 management.port=8081 endpoints.enabled = true endpoints.health.enabled = true 此示例显示了一个application.properties文件，该文件还设置了 Logback 配置的路径。通过将 IP 设置为“0.0.0.0”，我们完全限制了 Spring Boot 提供的 Web 服务器上的管理员和管理访问。此外，我们还启用了对我们的应用程序端点以及健康检查端点的所需网络访问。 另一个配置文件是application.yml。在其中，我们将添加一些属性来帮助我们将值注入我们的应用程序路由： server: port: 8080 camel: springboot: name: ServicesRest management: port: 8081 endpoints: enabled: false health: enabled: true quickstart: generateOrderPeriod: 10s processOrderPeriod: 30s 5. 设置 Camel Servlet 开始使用 Camel 的一种方法是将其注册为 servlet，以便它可以拦截 HTTP 请求并将它们重定向到我们的应用程序。 如前所述，盯着 Camel 的 2.18 及以下版本，我们可以利用我们的*application.yml——*通过为最终 URL 创建一个参数。稍后它将被注入到我们的 Java 代码中： codingman: api: path: \u0026#39;/camel\u0026#39; 回到我们的Application类，我们需要在上下文路径的根目录注册 Camel servlet，它将在应用程序启动时从 application.yml 中的引用**codingman.api.path注入： @Value(\u0026#34;${codingman.api.path}\u0026#34;) String contextPath; @Bean ServletRegistrationBean servletRegistrationBean() { ServletRegistrationBean servlet = new ServletRegistrationBean (new CamelHttpTransportServlet(), contextPath+\u0026#34;/*\u0026#34;); servlet.setName(\u0026#34;CamelServlet\u0026#34;); return servlet; } 从 Camel 的 2.19 版开始，此配置已被删除，因为CamelServlet默认设置为*“/camel”*。 6. 建立路线 让我们通过从 Camel 扩展RouteBuilder类开始创建路由，并将其设置为*@Component*以便组件扫描例程可以在 Web 服务器初始化期间找到它： @Component class RestApi extends RouteBuilder { @Override public void configure() { CamelContext context = new DefaultCamelContext(); restConfiguration()... rest(\u0026#34;/api/\u0026#34;)... from(\u0026#34;direct:remoteService\u0026#34;)... } } 在这个类中，我们重写了Camel 的*RouteBuilder类的**configure()*方法。 Camel 总是需要一个CamelContext实例——保存传入和传出消息的核心组件。 在这个简单的示例中，DefaultCamelContext就足够了，因为它只是将消息和路由绑定到其中，就像我们将要创建的 REST 服务一样。 **6.1 restConfiguration()路由 接下来，我们为计划在*restConfiguration()*方法中创建的端点创建一个 REST 声明： restConfiguration() .contextPath(contextPath) .port(serverPort) .enableCORS(true) .apiContextPath(\u0026#34;/api-doc\u0026#34;) .apiProperty(\u0026#34;api.title\u0026#34;, \u0026#34;Test REST API\u0026#34;) .apiProperty(\u0026#34;api.version\u0026#34;, \u0026#34;v1\u0026#34;) .apiContextRouteId(\u0026#34;doc-api\u0026#34;) .component(\u0026#34;servlet\u0026#34;) .bindingMode(RestBindingMode.json) 在这里，我们使用来自 YAML 文件的注入属性注册上下文路径。我们的应用程序的端口也应用了相同的逻辑。CORS 已启用，允许跨站点使用此 Web 服务。绑定模式允许并将参数转换为我们的 API。 接下来，我们将 Swagger 文档添加到我们之前设置的 URI、标题和版本中。当我们为 REST Web 服务创建方法/端点时，Swagger 文档将自动更新。 这个 Swagger 上下文本身就是一个 Camel 路由，在启动过程中我们可以在服务器日志中看到一些关于它的技术信息。我们的示例文档默认在http://localhost:8080/camel/api-doc 提供。 **6.2. rest()路由 现在，让我们从上面列出的*configure()方法中实现**rest()*方法调用： rest(\u0026#34;/api/\u0026#34;) .id(\u0026#34;api-route\u0026#34;) .consumes(\u0026#34;application/json\u0026#34;) .post(\u0026#34;/bean\u0026#34;) .bindingMode(RestBindingMode.json_xml) .type(MyBean.class) .to(\u0026#34;direct:remoteService\u0026#34;); 对于那些熟悉 API 的人来说，这种方法非常简单。id是CamelContext内部路由的标识。下一行定义 MIME 类型。这里定义了绑定模式，以表明我们可以在*restConfiguration()*上设置模式。 post()方法向API 添加一个操作，生成一个“ POST /bean ”端点，而MyBean（一个具有整数 id和字符串名称的常规 Java bean ）定义了预期的参数。 类似地，GET、PUT 和 DELETE 等 HTTP 操作也都以get()、put()、*delete()*的形式可用。 最后，*to()*方法创建了通往另一条路线的桥梁。在这里，它告诉 Camel 在其上下文/引擎中搜索我们将要创建的另一条路线——该路线由值/id “ *direct: \u0026hellip; ”命名和检测，与**from()*方法中定义的路线相匹配。 *6.3. 带有*transform()的from()路由 使用 Camel 时，路由接收参数，然后转换、转换和处理这些参数。之后，它将这些参数发送到另一个路由，该路由将结果转发到所需的输出（文件、数据库、SMTP 服务器或 REST API 响应）。 在本文中，我们只在我们要覆盖的*configure()方法中创建另一个路由。这将是我们最后一个to()*路线的目的地路线： from(\u0026#34;direct:remoteService\u0026#34;) .routeId(\u0026#34;direct-route\u0026#34;) .tracing() .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.id}\u0026#34;) .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.name}\u0026#34;) .transform().simple(\u0026#34;Hello ${in.body.name}\u0026#34;) .setHeader(Exchange.HTTP_RESPONSE_CODE, constant(200)); *from()方法遵循相同的原则，并且与rest()方法有许多相同的方法，除了它从 Camel 上下文消息中消费。这就是参数“ direct-route ”的原因，它创建了指向上述方法rest().to()*的链接。 许多其他转换是可用的，包括提取为 Java 原语（或对象）并将其发送到持久层。请注意，路由总是从传入消息中读取，因此链式路由将忽略传出消息。 我们的例子已经准备好了，我们可以试试：  运行提示命令：mvn spring-boot:run 使用标头参数向http://localhost:8080/camel/api/bean发出 POST 请求： Content-Type: application/json和有效负载*{“id”: 1,”name”: “World”}* 我们应该会收到 201 的返回码和响应：Hello, World  6.4. 简单的脚本语言 该示例使用*tracking()方法输出日志记录。请注意，我们使用了${}*占位符；这些是属于 Camel 的称为 SIMPLE 的脚本语言的一部分。它适用于通过路由交换的消息，例如消息中的正文。 在我们的示例中，我们使用 SIMPLE 将 Camel 消息正文中的 bean 属性输出到日志中。 我们也可以使用它来进行简单的转换，如*transform()*方法所示。 **6.5 from()路由与process() ** 让我们做一些更有意义的事情，比如调用一个服务层返回处理过的数据。SIMPLE 不适用于繁重的数据处理，因此让我们将*transform()替换为process()*方法： from(\u0026#34;direct:remoteService\u0026#34;) .routeId(\u0026#34;direct-route\u0026#34;) .tracing() .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.id}\u0026#34;) .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.name}\u0026#34;) .process(new Processor() { @Override public void process(Exchange exchange) throws Exception { MyBean bodyIn = (MyBean) exchange.getIn().getBody(); ExampleServices.example(bodyIn); exchange.getIn().setBody(bodyIn); } }) .setHeader(Exchange.HTTP_RESPONSE_CODE, constant(200)); 这允许我们将数据提取到一个 bean 中，与之前在type()方法中定义的相同，并在我们的ExampleServices层中处理它。 由于我们之前将bindingMode()设置为 JSON，因此响应已经是正确的 JSON 格式，基于我们的 POJO 生成。这意味着对于ExampleServices类： public class ExampleServices { public static void example(MyBean bodyIn) { bodyIn.setName( \u0026#34;Hello, \u0026#34; + bodyIn.getName() ); bodyIn.setId(bodyIn.getId() * 10); } } 现在，相同的 HTTP 请求返回响应代码 201 和正文：{“id”：10，“name”：“Hello, World”}。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_camel_spring_boot/","tags":["Apache Camel"],"title":"带有 Spring Boot 的 Apache Camel"},{"categories":["Data"],"contents":"1. 概述 Apache Camel是一个开源集成框架，旨在简化集成系统。 它允许最终用户使用相同的 API 集成各种系统，提供对多种协议和数据类型的支持，同时具有可扩展性并允许引入自定义协议。 2. Maven依赖 为了使用 Camel，我们需要先添加 Maven 依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.18.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 Camel 工件。 3. 领域特定语言 路由和路由引擎是 Camel 的核心部分。路由包含不同系统之间集成的流程和逻辑。 为了更轻松、更简洁地定义路由，Camel 为 Java 或 Groovy 等编程语言提供了几种不同的领域特定语言 (DSL)。另一方面，它还提供了使用 Spring DSL 在 XML 中定义路由。 使用 Java DSL 或 Spring DSL 主要是用户偏好，因为大多数功能都可用。 Java DSL 提供了更多 Spring DSL 不支持的特性。然而，Spring DSL 有时更有益，因为无需重新编译代码即可更改 XML。 4. 术语和架构 现在让我们讨论基本的 Camel 术语和架构。 首先，我们将在这里看一下 Camel 的核心概念：  消息包含正在传输到路由的数据。每条消息都有一个唯一的标识符，它由正文、标题和附件构成 Exchange是消息的容器，它是在消费者在路由过程中收到消息时创建的。Exchange 允许系统之间进行不同类型的交互——它可以定义单向消息或请求-响应消息 端点是系统可以接收或发送消息的通道。它可以引用 Web 服务 URI、队列 URI、文件、电子邮件地址等 组件充当端点工厂。简而言之，组件使用相同的方法和语法为不同的技术提供接口。Camel 已经在其 DSL 中为几乎所有可能的技术支持许多组件，但它也提供了编写自定义组件的能力 Processor是一个简单的 Java 接口，用于向路由添加自定义集成逻辑。它包含一个单一的流程方法，用于在消费者收到的消息上执行自定义业务逻辑  在高层次上，Camel 的架构很简单。CamelContext代表 Camel 运行时系统，它连接不同的概念，例如路由、组件或端点。 在此之下，处理器处理端点之间的路由和转换，而端点则集成不同的系统。 5. 定义路线 可以使用 Java DSL 或 Spring DSL 定义路由。 我们将通过定义一个路由来说明这两种样式，该路由使用一个文件夹中的文件并将它们移动到另一个文件夹，同时为每个文件名添加时间戳。 5.1 使用 Java DSL 进行路由 要使用 Java DSL 定义路由，我们首先需要创建一个DefaultCamelContext实例。之后，我们需要扩展RouteBuilder类并实现包含路由流的配置方法： private static final long DURATION_MILIS = 10000; private static final String SOURCE_FOLDER = \u0026#34;src/test/source-folder\u0026#34;; private static final String DESTINATION_FOLDER = \u0026#34;src/test/destination-folder\u0026#34;; @Test public void moveFolderContentJavaDSLTest() throws Exception { CamelContext camelContext = new DefaultCamelContext(); camelContext.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(\u0026#34;file://\u0026#34; + SOURCE_FOLDER + \u0026#34;?delete=true\u0026#34;).process( new FileProcessor()).to(\u0026#34;file://\u0026#34; + DESTINATION_FOLDER); } }); camelContext.start(); Thread.sleep(DURATION_MILIS); camelContext.stop(); } configure方法可以这样读取：从源文件夹读取文件，使用 FileProcessor 处理它们并将结果发送到目标文件夹。设置delete=true表示文件处理成功后将从源文件夹中删除。 为了启动 Camel，我们需要在CamelContext上调用**start方法。调用Thread.sleep是为了让 Camel 有时间将文件从一个文件夹移动到另一个文件夹。 FileProcessor实现Processor接口并包含单个进程方法，其中包含用于修改文件名的逻辑： public class FileProcessor implements Processor { public void process(Exchange exchange) throws Exception { String originalFileName = (String) exchange.getIn().getHeader( Exchange.FILE_NAME, String.class); Date date = new Date(); SimpleDateFormat dateFormat = new SimpleDateFormat( \u0026#34;yyyy-MM-dd HH-mm-ss\u0026#34;); String changedFileName = dateFormat.format(date) + originalFileName; exchange.getIn().setHeader(Exchange.FILE_NAME, changedFileName); } } 为了检索文件名，我们必须从交换中检索传入消息并访问其标题。与此类似，要修改文件名，我们必须更新消息头。 5.2. 使用 Spring DSL 进行路由 在使用 Spring DSL 定义路由时，我们使用 XML 文件来设置路由和处理器。这允许我们使用 Spring 无需代码即可配置路由，并最终为我们提供了完全控制反转的好处。 这已经在现有文章中介绍过，因此我们将重点关注使用 Spring DSL 和 Java DSL，这通常是定义路由的首选方式。 在这种安排中，CamelContext 是在 Spring XML 文件中使用 Camel 的自定义 XML 语法定义的，但没有像使用 XML 的“纯”Spring DSL 那样的路由定义： \u0026lt;bean id=\u0026#34;fileRouter\u0026#34; class=\u0026#34;com.codingman.camel.file.FileRouter\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;fileProcessor\u0026#34; class=\u0026#34;com.codingman.camel.file.FileProcessor\u0026#34; /\u0026gt; \u0026lt;camelContext xmlns=\u0026#34;http://camel.apache.org/schema/spring\u0026#34;\u0026gt; \u0026lt;routeBuilder ref=\u0026#34;fileRouter\u0026#34; /\u0026gt; \u0026lt;/camelContext\u0026gt; 通过这种方式，我们告诉 Camel 使用FileRouter类，该类包含我们在 Java DSL 中的路由定义： public class FileRouter extends RouteBuilder { private static final String SOURCE_FOLDER = \u0026#34;src/test/source-folder\u0026#34;; private static final String DESTINATION_FOLDER = \u0026#34;src/test/destination-folder\u0026#34;; @Override public void configure() throws Exception { from(\u0026#34;file://\u0026#34; + SOURCE_FOLDER + \u0026#34;?delete=true\u0026#34;).process( new FileProcessor()).to(\u0026#34;file://\u0026#34; + DESTINATION_FOLDER); } } 为了测试这一点，我们必须创建一个ClassPathXmlApplicationContext实例，它将在 Spring 中加载我们的CamelContext： @Test public void moveFolderContentSpringDSLTest() throws InterruptedException { ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;camel-context.xml\u0026#34;); Thread.sleep(DURATION_MILIS); applicationContext.close(); } 通过使用这种方法，我们获得了 Spring 提供的额外灵活性和好处，以及使用 Java DSL 实现 Java 语言的所有可能性。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_camel_intro/","tags":["Apache Camel"],"title":"Apache Camel 简介"},{"categories":["Jakarta EE"],"contents":"1. 简介 在本文中，我们将看看Apache BVal库对Java Bean Validation规范 ( JSR 349 )**的实现。 2. Maven依赖 为了使用Apache BVal，我们首先需要将以下依赖项添加到我们的pom.xml文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.bval\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bval-jsr\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.validation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;validation-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 自定义BVal约束可以在可选的bval-extras依赖项中找到： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.bval\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bval-extras\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本的bval-jsr、bval-extras和validation-api可以从 Maven Central 下载。 3. 应用约束 Apache BVal为**javax.validation包中定义的所有约束提供了实现。为了对 bean 的属性应用约束，我们可以在属性声明中添加约束注解。 让我们创建一个具有四个属性的User类，然后应用*@NotNull*、@Size和*@Min*注释： public class User { @NotNull private String email; private String password; @Size(min=1, max=20) private String name; @Min(18) private int age; // standard constructor, getters, setters } 4. 验证 Bean 要验证应用于User类的约束，我们需要获取一个ValidatorFactory实例和一个或多个Validator实例。 **4.1 获取ValidatorFactory ** Apache BVal文档建议获取此类的单个实例，因为工厂创建是一个要求很高的过程： ValidatorFactory validatorFactory = Validation.byProvider(ApacheValidationProvider.class) .configure().buildValidatorFactory(); **4.2. 获取Validator ** 接下来，我们需要从上面定义的validatorFactory中获取一个Validator实例： Validator validator = validatorFactory.getValidator(); 这是一个线程安全的实现，所以我们可以安全地重用已经创建的实例。 Validator类提供了三种确定 bean 有效性的方法：validate ()、validateProperty()和validateValue()。 这些方法中的每一个都返回一组ConstraintViolation对象，其中包含有关未遵守的约束的信息。 4.3. validate() API *validate()*方法检查整个 bean的有效性，这意味着它验证应用于作为参数传递的对象属性的所有约束。 让我们创建一个JUnit测试，我们在其中定义一个User对象并使用*validate()*方法来测试它的属性： @Test public void givenUser_whenValidate_thenValidationViolations() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;nameTooLong_______________\u0026#34;, 15); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validate(user); assertTrue(\u0026#34;no violations\u0026#34;, violations.size() \u0026gt; 0); } 4.4. validateProperty() API *validateProperty()*方法可用于验证 bean的单个属性。 \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; 让我们创建一个JUnit测试，我们将在其中定义一个年龄属性小于所需最小值 18的User对象，并验证验证此属性是否会导致一次违规： @Test public void givenInvalidAge_whenValidateProperty_thenConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;Ana\u0026#34;, 12); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; propertyViolations = validator.validateProperty(user, \u0026#34;age\u0026#34;); assertEquals(\u0026#34;size is not 1\u0026#34;, 1, propertyViolations.size()); } 4.5. validateValue() API *validateValue()*方法可用于在将某个值设置到 bean 之前检查某个值是否是 bean 属性的有效值。 让我们使用User对象创建一个JUnit测试，然后验证值20是否是**age属性的有效值： @Test public void givenValidAge_whenValidateValue_thenNoConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;Ana\u0026#34;, 18); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; valueViolations = validator.validateValue(User.class, \u0026#34;age\u0026#34;, 20); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, valueViolations.size()); } 4.6. 关闭ValidatorFactory 使用ValidatorFactory后，我们必须记得在最后关闭它： if (validatorFactory != null) { validatorFactory.close(); } 5. 非JSR约束 Apache BVal库还提供了一系列不属于JSR规范的约束，并提供了额外的更强大的验证功能。 bval -jsr包包含两个附加约束：@Email用于验证有效的电子邮件地址，@NotEmpty用于确保值不为空。 其余的自定义BVal约束在可选包bval-extras中提供。 此包包含**用于验证各种数字格式的约束，例如确保数字是有效国际银行帐号的@IBAN注释、验证有效标准书号的 @Isbn 注释和验证国际文章编号的@ EAN13注释. \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; 该库还提供注释以确保各种类型的信用卡号的有效性： @AmericanExpress、 @Diners 、@Discover、@Mastercard和*@Visa*。 您可以使用*@Domain和@InetAddress*注释来确定一个值是否包含有效的域或Internet 地址。 最后，该包包含*@Directory和@NotDirectory注释，用于**验证File*对象是否为目录**。 让我们在User类上定义额外的属性，并将一些非JSR注释应用到它们： public class User { @NotNull @Email private String email; @NotEmpty private String password; @Size(min=1, max=20) private String name; @Min(18) private int age; @Visa private String cardNumber = \u0026#34;\u0026#34;; @IBAN private String iban = \u0026#34;\u0026#34;; @InetAddress private String website = \u0026#34;\u0026#34;; @Directory private File mainDirectory = new File(\u0026#34;.\u0026#34;); // standard constructor, getters, setters } 可以以与JSR约束类似的方式测试约束： @Test public void whenValidateNonJSR_thenCorrect() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;Ana\u0026#34;, 20); user.setCardNumber(\u0026#34;1234\u0026#34;); user.setIban(\u0026#34;1234\u0026#34;); user.setWebsite(\u0026#34;10.0.2.50\u0026#34;); user.setMainDirectory(new File(\u0026#34;.\u0026#34;)); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validateProperty(user,\u0026#34;iban\u0026#34;); assertEquals(\u0026#34;size is not 1\u0026#34;, 1, violations.size()); violations = validator.validateProperty(user,\u0026#34;website\u0026#34;); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, violations.size()); violations = validator.validateProperty(user, \u0026#34;mainDirectory\u0026#34;); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, violations.size()); } 虽然这些额外的注解可以方便地满足潜在的验证需求，但使用不属于JSR规范的注解的一个缺点是，如果以后有必要，您不能轻易地切换到不同的JSR实现。 6. 自定义约束 为了定义我们自己的约束，我们首先需要按照标准语法创建一个注解。 让我们创建一个密码注释，它将定义用户密码必须满足的条件： \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; @Constraint(validatedBy = { PasswordValidator.class }) @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER }) @Retention(RetentionPolicy.RUNTIME) public @interface Password { String message() default \u0026#34;Invalid password\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; int length() default 6; int nonAlpha() default 1; } ** 密码值的实际验证是在一个实现ConstraintValidator接口**的类中完成的——在我们的例子中，是PasswordValidator类。此类重写isValid()方法并验证密码的长度是否小于length属性，以及是否包含少于nonAlpha属性中指定数量的非字母数字字符： public class PasswordValidator implements ConstraintValidator\u0026lt;Password, String\u0026gt; { private int length; private int nonAlpha; @Override public void initialize(Password password) { this.length = password.length(); this.nonAlpha = password.nonAlpha(); } @Override public boolean isValid(String value, ConstraintValidatorContext ctx) { if (value.length() \u0026lt; length) { return false; } int nonAlphaNr = 0; for (int i = 0; i \u0026lt; value.length(); i++) { if (!Character.isLetterOrDigit(value.charAt(i))) { nonAlphaNr++; } } if (nonAlphaNr \u0026lt; nonAlpha) { return false; } return true; } } 让我们将自定义约束应用于User类的密码属性： @Password(length = 8) private String password; 我们可以创建一个JUnit测试来验证无​​效的密码值是否会导致违反约束： @Test public void givenValidPassword_whenValidatePassword_thenNoConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;Ana\u0026#34;, 20); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validateProperty(user, \u0026#34;password\u0026#34;); assertEquals( \u0026#34;message incorrect\u0026#34;, \u0026#34;Invalid password\u0026#34;, violations.iterator().next().getMessage()); } 现在让我们创建一个JUnit测试，在其中我们验证一个有效的密码值： @Test public void givenValidPassword_whenValidatePassword_thenNoConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;password#\u0026#34;, \u0026#34;Ana\u0026#34;, 20); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validateProperty(user, \u0026#34;password\u0026#34;); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, violations.size()); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_bval/","tags":[],"title":"Apache BVal 简介"},{"categories":["Data"],"contents":" 概述   在本教程中，我们将介绍 Apache Beam 并探索其基本概念。 我们将首先展示使用 Apache Beam 的用例和好处，然后我们将介绍基本概念和术语。之后，我们将通过一个简单的示例来说明 Apache Beam 的所有重要方面。 什么是 Apache Beam？   **Apache Beam (Batch + strEAM) 是用于批处理和流式数据处理作业的统一编程模型。**它提供了一个软件开发工具包来定义和构建数据处理管道以及执行它们的运行器。 **Apache Beam 旨在提供可移植的编程层。**事实上，Beam Pipeline Runners 将数据处理管道转换为与用户选择的后端兼容的 API。目前，支持这些分布式处理后端：  Apache Apex Apache Flink Apache Gearpump (incubating) Apache Samza Apache Spark Google Cloud Dataflow Hazelcast Jet  为什么选择 Apache Beam？   **Apache Beam 融合了批处理和流式数据处理，而其他人通常通过单独的 API 来实现。**因此，很容易将流式流程更改为批处理流程，反之亦然，例如，随着需求的变化。 **Apache Beam 提高了可移植性和灵活性。**我们专注于我们的逻辑而不是潜在的细节。此外，我们可以随时更改数据处理后端。 有适用于 Apache Beam 的 Java、Python、Go 和 Scala SDK。事实上，团队中的每个人都可以使用他们选择的语言来使用它。 基本概念   使用 Apache Beam，我们可以构建工作流图（管道）并执行它们。编程模型中的关键概念是：  PCollection – 表示可以是固定批次或数据流的数据集 PTransform – 一种数据处理操作，采用一个或多个PCollection并输出零个或多个PCollection Pipeline – 表示PCollection 和PTransform的有向无环图，因此封装了整个数据处理作业 PipelineRunner –在指定的分布式处理后端执行Pipeline  简单来说，一个PipelineRunner执行一个Pipeline， 一个Pipeline由PCollection 和PTransform组成。 字数统计示例   现在我们已经了解了 Apache Beam 的基本概念，让我们设计和测试一个字数统计任务。 5.1 构建Beam管道 设计工作流图是每个 Apache Beam 作业的第一步。让我们定义一个字数统计任务的步骤：  从来源阅读文本。 将文本拆分为单词列表。 小写所有单词。 修剪标点符号。 过滤停用词。 计算每个唯一的单词。  为此，我们需要使用PCollection和PTransform抽象将上述步骤转换为单个管道。 5.2. 依赖项 在我们实现工作流图之前，我们应该将Apache Beam 的核心依赖添加到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.beam\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;beam-sdks-java-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${beam.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Beam Pipeline Runners 依靠分布式处理后端来执行任务。让我们添加DirectRunner作为运行时依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.beam\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;beam-runners-direct-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${beam.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 与其他 Pipeline Runners 不同，DirectRunner不需要任何额外的设置，这使其成为初学者的不错选择。 5.3. 执行 Apache Beam 利用 Map-Reduce 编程范式（与Java Streams相同）。事实上，在我们继续之前，有一个reduce()、filter()、count()、map()和flatMap()的基本概念是个好主意。 创建管道是我们要做的第一件事： PipelineOptions options = PipelineOptionsFactory.create(); Pipeline p = Pipeline.create(options); 现在我们应用我们的六步字数统计任务： PCollection\u0026lt;KV\u0026lt;String, Long\u0026gt;\u0026gt; wordCount = p .apply(\u0026#34;(1) Read all lines\u0026#34;, TextIO.read().from(inputFilePath)) .apply(\u0026#34;(2) Flatmap to a list of words\u0026#34;, FlatMapElements.into(TypeDescriptors.strings()) .via(line -\u0026gt; Arrays.asList(line.split(\u0026#34;\\\\s\u0026#34;)))) .apply(\u0026#34;(3) Lowercase all\u0026#34;, MapElements.into(TypeDescriptors.strings()) .via(word -\u0026gt; word.toLowerCase())) .apply(\u0026#34;(4) Trim punctuations\u0026#34;, MapElements.into(TypeDescriptors.strings()) .via(word -\u0026gt; trim(word))) .apply(\u0026#34;(5) Filter stopwords\u0026#34;, Filter.by(word -\u0026gt; !isStopWord(word))) .apply(\u0026#34;(6) Count words\u0026#34;, Count.perElement()); apply()的第一个（可选）参数是一个字符串，它只是为了提高代码的可读性。以下是上述代码中每个apply()的作用：  首先，我们使用TextIO 逐行读取输入文本文件。 用空格分割每一行，我们将它平面映射到一个单词列表。 字数不区分大小写，因此我们将所有单词小写。 早些时候，我们用空格分割行，最后得到像“word！”这样的词。和“单词？”，所以我们删除了标点符号。 “is”和“by”等停用词几乎在每个英文文本中都很常见，因此我们将它们删除。 最后，我们使用内置函数*Count.perElement()*计算唯一词。  如前所述，管道在分布式后端进行处理。不可能在内存中迭代PCollection，因为它分布在多个后端。相反，我们将结果写入外部数据库或文件。 首先，我们将PCollection转换为String。然后，我们使用TextIO来编写输出： wordCount.apply(MapElements.into(TypeDescriptors.strings()) .via(count -\u0026gt; count.getKey() + \u0026#34; --\u0026gt; \u0026#34; + count.getValue())) .apply(TextIO.write().to(outputFilePath)); 现在我们的Pipeline定义已经完成，我们可以运行和测试它。 5.4. 运行和测试 到目前为止，我们已经为字数统计任务定义了一个流水线。此时，让我们运行Pipeline： p.run().waitUntilFinish(); 在这行代码中，Apache Beam 会将我们的任务发送到多个DirectRunner实例。因此，最后将生成几个输出文件。它们将包含以下内容： ... apache --\u0026gt; 3 beam --\u0026gt; 5 rocks --\u0026gt; 2 ... 在 Apache Beam 中定义和运行分布式作业就像这样简单而富有表现力。为了比较，Apache Spark、Apache Flink和Hazelcast Jet上也提供了字数统计实现。 我们从这里走向何方？   我们成功地计算了输入文件中的每个单词，但我们还没有最常见单词的报告。当然，对PCollection进行排序是我们下一步要解决的好问题。 稍后，我们可以了解更多关于 Windowing、Triggers、Metrics 和更复杂的 Transforms 的知识。Apache Beam 文档提供了深入的信息和参考资料。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_beam/","tags":[],"title":"Apache Beam 简介"},{"categories":["Architecture"],"contents":" 概述   在分布式架构中，应用程序通常需要在它们之间交换数据。一方面，这可以通过彼此直接通信来完成。另一方面，为了达到高可用性和分区容错，以及在应用程序之间获得松耦合，消息传递是一个合适的解决方案。 因此，我们可以在多种产品之间进行选择。Apache 基金会提供了 ActiveMQ 和 Kafka，我们将在本文中对它们进行比较。 一般情况   2.1 Active MQ **Active MQ 是传统的消息代理之一，其目标是确保应用程序之间的数据交换以安全可靠的方式进行。**它处理少量数据，因此专门用于定义良好的消息格式和事务消息传递。 我们必须注意，除了这个“经典”版本之外，还有另一个版本：Active MQ Artemis。这个下一代代理基于 HornetQ，其代码于 2015 年由 RedHat 提供给 Apache 基金会。在Active MQ 网站上，据说：  一旦 Artemis 与“经典”代码库达到足够的功能对等水平，它将成为 ActiveMQ 的下一个主要版本。  因此，为了进行比较，我们需要考虑两个版本。*我们将使用术语“Active MQ”和“Artemis”*来区分它们。 2.2. Kafka 与 Active MQ 相比，**Kafka 是一个分布式系统，旨在处理大量数据。**我们可以将其用于传统消息传递以及：  网站活动跟踪 指标 日志聚合 流处理 事件溯源 提交日志  随着使用微服务构建的典型云架构的出现，这些要求变得非常重要。 2.3. JMS 的作用和消息传递的演变 Java 消息服务 (JMS) 是用于在 Java EE 应用程序中发送和接收消息的通用 API。它是消息传递系统早期发展的一部分，今天它仍然是一个标准。在 Jakarta EE 中，它被采用为Jakarta Messaging。因此，了解核心概念可能会有所帮助：   Java 原生但独立于供应商的 API   需要JCA 资源适配器来实现特定于供应商的通信协议   消息目标模型：  队列( P2P ) 确保消息排序和一次性消息处理，即使在多个消费者的情况下 主题（PubSub）作为发布-订阅模式的实现，这意味着多个消费者将在订阅主题期间接收消息    消息格式：  标头作为经纪人处理的标准化元信息（如优先级或到期日期） 消费者可用于消息处理的非标准化元信息的属性 包含有效负载的Body – JMS 声明了五种类型的消息，但这仅与使用 API 有关，与此比较无关    **然而，演变朝着一个开放和独立的方向发展——独立于消费者和生产者的平台，独立于消息代理的供应商。**有一些协议定义了自己的目标模型：  AMQP —— 独立于供应商的消息传递的二进制协议——使用通用节点 MQTT —— 嵌入式系统和物联网的轻量级二进制协议——使用主题 STOMP —— 一个简单的基于文本的协议，甚至允许从浏览器发送消息 – 使用通用目的地  **另一项发展是通过云架构的传播，根据“即发即弃”原则，将以前可靠的单个消息传输（“传统消息传递”）添加到处理大量数据中。**可以说，Active MQ 和 Kafka 的比较是对这两种方法的典型代表的比较。例如，Kafka 的替代品可能是NATS。 3.比较 在本节中，我们将比较 Active MQ 和 Kafka 在架构和开发方面最有趣的特性。 3.1 消息目标模型、协议和 API Active MQ 完全实现了Queues和Topics的 JMS 消息目的地模型，并将 AMQP、MQTT 和 STOMP 消息映射到它们。例如，STOMP 消息映射到Topic中的 JMS BytesMessage。此外，它还支持OpenWire，它允许跨语言访问 Active MQ。 Artemis 独立于标准 API 和协议定义了自己的消息目标模型，并且还需要将它们映射到此模型：   消息被发送到一个Address，它被赋予一个唯一的名称、一个Routing Type和零个或多个Queues。   路由类型确定消息如何从地址路由到绑定到该地址的队列。定义了两种类型：  ANYCAST：消息被路由到地址上的单个队列 MULTICAST：消息被路由到地址上的每个队列    Kafka 只定义了Topics，它由多个Partition（至少 1 个）和可以放置在不同 broker 上的 Replica*组成。*找到划分主题的最佳策略是一项挑战。我们必须注意：  一条消息被分配到一个分区中。 只有一个分区内的消息才能保证排序。 默认情况下，后续消息在主题的分区之间循环分发。 如果我们使用消息键，那么具有相同键的消息将落在同一个分区中。  Kafka 有自己的API。虽然也有JMS 的资源适配器，但我们应该知道这些概念并不完全兼容。官方不支持 AMQP、MQTT 和 STOMP，但有AMQP和MQTT的连接器。 3.2. 消息格式和处理 Active MQ 支持由标头、属性和正文组成的 JMS 标准消息格式（如上所述）。代理必须维护每条消息的传递状态，从而导致吞吐量降低。由于它受 JMS 支持，消费者可以从目标同步拉取消息，或者消息可以由代理异步推送。 Kafka 没有定义任何消息格式——这完全是生产者的责任。每条消息没有任何传递状态，只有每个消费者和分区的偏移量。**Offset是最后发送的消息的索引。这不仅更快，而且还允许通过重置偏移量来重新发送消息，而无需询问生产者。 3.3. Spring 和 CDI 集成 JMS 是 Java/Jakarta EE 标准，因此完全集成到 Java/Jakarta EE 应用程序中。因此，与 Active MQ 和 Artemis 的连接很容易由应用程序服务器管理。使用 Artemis，我们甚至可以使用嵌入式代理。对于 Kafka，托管连接仅在使用Resource Adapter for JMS或Eclipse MicroProfile Reactive时可用。 Spring 集成了JMS以及AMQP、MQTT和STOMP。还支持kafka。借助 Spring Boot，我们可以为Active MQ、Artemis和Kafka使用嵌入式代理。 Active MQ/Artemis 和 Kafka 用例   以下几点为我们指明了何时最好使用哪种产品。 4.1 Active MQ/Artemis 的用例  每天只处理少量消息 高水平的可靠性和事务性 即时数据转换，ETL 作业  4.2. Kafka的用例   处理大量数据  实时数据处理 应用程序活动跟踪 记录和监控    无需数据转换的消息传递（有可能，但并不容易）   没有传输保证的消息传递（有可能，但不容易）   Active MQ 和 Kafka 的区别      标准 活动 MQ 经典 活跃的 MQ 阿尔忒弥斯 卡夫卡     用例 传统消息传递（可靠、事务性） 分布式事件流    P2P 消息传递 尾巴 路由类型为 ANYCAST 的地址 –   PubSub 消息传递 话题 路由类型为 MULTICAST 的地址 话题   API / 协议 JMS，AMQP。MQTT、STOMP、OpenWire Kafka 客户端、AMQP 和 MQTT 连接器、JMS 资源适配器    拉式与推送式消息传递 基于推送 基于拉的    消息传递的责任 生产者必须确保消息被传递 消费者消费它应该消费的消息    交易支持 JMS, XA 自定义事务管理器    可扩展性 经纪人网络 集群 高度可扩展（分区和副本）   消费者越多…… …性能越慢 ……不减速    \u0026quot;       ","permalink":"http://itcodingman.github.io/apache_activemq_vs_kafka/","tags":["Kafka"],"title":"Apache ActiveMQ 与 Kafka"},{"categories":["DevOps","Gradle","Maven"],"contents":"1. 简介 在本文中，我们将探讨主导 JVM 生态系统的三个 Java 构建自动化工具——Ant、Maven 和 Gradle。 我们将介绍它们中的每一个，并探索 Java 构建自动化工具是如何演变的。 2. Apache Ant 一开始，Make是唯一一款超越本土解决方案的构建自动化工具。Make 自 1976 年以来一直存在，因此，它在 Java 早期用于构建 Java 应用程序。 但是，C 程序的许多约定并不适合 Java 生态系统，因此 Ant 及时取代了它作为更好的选择。 Apache Ant（“Another Neat Tool”）是一个 Java 库，用于自动化 Java 应用程序的构建过程。此外，Ant 可用于构建非 Java 应用程序。它最初是 Apache Tomcat 代码库的一部分，并于 2000 年作为独立项目发布。 在许多方面，Ant 与 Make 非常相似，而且它非常简单，因此任何人都可以在没有任何特定先决条件的情况下开始使用它。Ant 构建文件是用 XML 编写的，按照惯例，它们被称为build.xml。 构建过程的不同阶段称为“target”。 下面是一个带有HelloWorld主类的简单 Java 项目的build.xml文件示例： \u0026lt;project\u0026gt; \u0026lt;target name=\u0026#34;clean\u0026#34;\u0026gt; \u0026lt;delete dir=\u0026#34;classes\u0026#34; /\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;compile\u0026#34; depends=\u0026#34;clean\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;classes\u0026#34; /\u0026gt; \u0026lt;javac srcdir=\u0026#34;src\u0026#34; destdir=\u0026#34;classes\u0026#34; /\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;jar\u0026#34; depends=\u0026#34;compile\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;jar\u0026#34; /\u0026gt; \u0026lt;jar destfile=\u0026#34;jar/HelloWorld.jar\u0026#34; basedir=\u0026#34;classes\u0026#34;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name=\u0026#34;Main-Class\u0026#34; value=\u0026#34;antExample.HelloWorld\u0026#34; /\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;run\u0026#34; depends=\u0026#34;jar\u0026#34;\u0026gt; \u0026lt;java jar=\u0026#34;jar/HelloWorld.jar\u0026#34; fork=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt; 该构建文件定义了四个目标：clean、compile、jar和run。例如，我们可以通过运行来编译代码： ant compile 这将首先触发目标clean，这将删除“classes”目录。之后，目标compile将重新创建目录并将 src 文件夹编译到其中。 **Ant 的主要优点是它的灵活性。Ant 没有强加任何编码约定或项目结构。**因此，这意味着 Ant 需要开发人员自己编写所有命令，这有时会导致难以维护的巨大 XML 构建文件。 由于没有约定，只知道 Ant 并不意味着我们会很快理解任何 Ant 构建文件。习惯一个不熟悉的 Ant 文件可能需要一些时间，与其他较新的工具相比，这是一个劣势。 起初，Ant 没有对依赖管理的内置支持。然而，随着依赖管理在后来的几年中成为必须，Apache Ivy被开发为 Apache Ant 项目的子项目。它与 Apache Ant 集成，并且遵循相同的设计原则。 然而，最初的 Ant 限制是由于没有对依赖管理的内置支持以及在处理不可管理的 XML 构建文件时的挫败感，这导致了 Maven 的创建。 3. Apache Maven Apache Maven是一个依赖管理和构建自动化工具，主要用于 Java 应用程序。**Maven 继续像 Ant 一样使用 XML 文件，但以一种更易于管理的方式。**这里的游戏名称是约定优于配置。 Ant 提供了灵活性并要求一切从头开始编写，而Maven 依赖于约定并提供预定义的命令（目标）。 简而言之，Maven 允许我们专注于构建应该做什么，并为我们提供了框架来完成它。Maven 的另一个积极方面是它为依赖管理提供了内置支持。 Maven 的配置文件，包含构建和依赖管理指令，按照约定称为pom.xml。此外，Maven 还规定了严格的项目结构，而 Ant 也提供了灵活性。 下面是一个pom.xml文件示例，用于与之前的HelloWorld主类相同的简单 Java 项目： \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;codingman\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mavenExample\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;description\u0026gt;Maven example\u0026lt;/description\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.12\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 但是，现在项目结构也已经标准化，并且符合 Maven 约定： +---src | +---main | | +---java | | | \\---com | | | \\---codingman | | | \\---maven | | | HelloWorld.java | | | | | \\---resources | \\---test | +---java | \\---resources 与 Ant 相比，无需手动定义构建过程中的每个阶段。相反，我们可以简单地调用 Maven 的内置命令。 例如，我们可以通过运行来编译代码： mvn compile 正如官方页面所指出的，**Maven 的核心可以被认为是一个插件执行框架，因为所有工作都是由插件完成的。**Maven 支持范围广泛的可用插件，每个插件都可以额外配置。 可用的插件之一是 Apache Maven 依赖插件，它有一个复制依赖目标，它将我们的依赖复制到指定的目录。 为了展示这个插件，让我们在pom.xml文件中包含这个插件，并为我们的依赖项配置一个输出目录： \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-dependency-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;copy-dependencies\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;copy-dependencies\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;outputDirectory\u0026gt;target/dependencies \u0026lt;/outputDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 这个插件将在package阶段执行，所以如果我们运行： mvn package 我们将执行此插件并将依赖项复制到 target/dependencies 文件夹。 还有一篇关于如何使用不同的 Maven 插件创建可执行 JAR 的文章。此外，有关 Maven 的详细概述，请查看有关 Maven 的核心指南，其中探讨了 Maven 的一些关键特性。 Maven 变得非常流行，因为构建文件现在已经标准化，并且与 Ant 相比，维护构建文件所需的时间明显减少。然而，尽管比 Ant 文件更标准化，Maven 配置文件仍然趋于变得庞大和繁琐。 **Maven 的严格约定的代价是灵活性不如 Ant。**目标定制非常困难，因此与 Ant 相比，编写定制构建脚本要困难得多。 尽管 Maven 在使应用程序的构建过程更容易和更标准化方面做出了一些重大改进，但由于比 Ant 灵活得多，它仍然要付出代价。这导致了 Gradle 的创建，它结合了两全其美——Ant 的灵活性和 Maven 的特性。 4. Gradle Gradle是一个依赖管理和构建自动化工具，它建立在 Ant 和 Maven 的概念之上。 关于 Gradle，我们首先要注意的一点是它不使用 XML 文件，这与 Ant 或 Maven 不同。 随着时间的推移，开发人员对拥有和使用特定领域的语言越来越感兴趣——简单地说，这将允许他们使用为特定领域量身定制的语言来解决特定领域中的问题。 这被 Gradle 采用，它使用基于Groovy或Kotlin的 DSL 。**由于该语言是专门为解决特定领域问题而设计的，因此这导致了更小的配置文件和更少的混乱。**Gradle 的配置文件按照惯例在 Groovy 中称为build.gradle ，在 Kotlin中称为build.gradle.kts 。 请注意，Kotlin 在自动完成和错误检测方面提供了比 Groovy 更好的 IDE 支持。 下面是一个build.gradle文件的示例，用于与之前的**HelloWorld主类相同的简单 Java 项目： apply plugin: \u0026#39;java\u0026#39; repositories { mavenCentral() } jar { baseName = \u0026#39;gradleExample\u0026#39; version = \u0026#39;0.0.1-SNAPSHOT\u0026#39; } dependencies { testImplementation \u0026#39;junit:junit:4.12\u0026#39; } 我们可以通过运行来编译代码： gradle classes Gradle 的核心是有意提供很少的功能。**插件添加了所有有用的功能。**在我们的示例中，我们使用了java插件，它允许我们编译 Java 代码和其他有价值的功能。 **Gradle 将其构建步骤命名为“任务”，而不是 Ant 的“目标”或 Maven 的“阶段”。**在 Maven 中，我们使用了 Apache Maven Dependency Plugin，将依赖项复制到指定目录是一个特定的目标。使用 Gradle，我们可以使用任务来做同样的事情： task copyDependencies(type: Copy) { from configurations.compile into \u0026#39;dependencies\u0026#39; } 我们可以通过执行以下命令来运行此任务： gradle copyDependencies \u0026quot; ","permalink":"http://itcodingman.github.io/ant_maven_gradle/","tags":[],"title":"Ant vs Maven vs Gradle"},{"categories":["REST","Spring Data"],"contents":"1. 概述 在本教程中，我们将创建一个简单的 CRUD 应用程序示例，使用 AngularJS 作为前端，使用 Spring Data REST 作为后端。 2. 创建 REST 数据服务 为了创建对持久性的支持，我们将使用 Spring Data REST 规范，该规范将使我们能够对数据模型执行 CRUD 操作。 您可以在Spring Data REST 简介中找到有关如何设置 REST 端点的所有必要信息。在本文中，我们将重用我们为介绍教程设置的现有项目。 对于持久性，我们将使用内存数据库中的H2。 作为数据模型，上一篇文章定义了一个WebsiteUser类，具有id、name和email属性以及一个名为UserRepository的存储库接口。 定义此接口指示 Spring 创建对公开 REST 集合资源和项目资源的支持。现在让我们仔细看看我们稍后将从AngularJS调用的端点。 2.1 Collection资源 我们将在端点*/users*处获得所有用户的列表。可以使用 GET 方法调用此 URL，并将返回以下形式的 JSON 对象： { \u0026#34;_embedded\u0026#34; : { \u0026#34;users\u0026#34; : [ { \u0026#34;name\u0026#34; : \u0026#34;Bryan\u0026#34;, \u0026#34;age\u0026#34; : 20, \u0026#34;_links\u0026#34; : { \u0026#34;self\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; }, \u0026#34;User\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; } } }, ... ] } } 2.2. Item资源 可以通过使用不同的 HTTP 方法和请求有效负载访问*/users/{userID}形式的 URL 来操作单个WebsiteUser对象。* 为了检索WebsiteUser对象，我们可以使用GET 方法访问*/users/{userID} 。*这将返回以下形式的 JSON 对象： { \u0026#34;name\u0026#34; : \u0026#34;Bryan\u0026#34;, \u0026#34;email\u0026#34; : \u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;_links\u0026#34; : { \u0026#34;self\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; }, \u0026#34;User\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; } } } 要添加新的WebsiteUser，我们需要使用 POST 方法调用*/users* 。新的WebsiteUser记录的属性将作为 JSON 对象添加到请求正文中： \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; {name: \u0026#34;Bryan\u0026#34;, email: \u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;} 如果没有错误，此 URL 将返回状态代码 201 CREATED。 如果我们想更新WebsiteUser记录的属性，我们需要使用 PATCH 方法和包含新值的请求正文调用 URL /users/{UserID} ： {name: \u0026#34;Bryan\u0026#34;, email: \u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;} 要删除WebsiteUser记录，我们可以使用 DELETE 方法调用 URL */users/{UserID} 。*如果没有错误，则返回状态码 204 NO CONTENT。 2.3. MVC 配置 我们还将添加一个基本的 MVC 配置以在我们的应用程序中显示 html 文件： @Configuration @EnableWebMvc public class MvcConfig implements WebMvcConfigurer { public MvcConfig(){ super(); } @Override public void configureDefaultServletHandling( DefaultServletHandlerConfigurer configurer) { configurer.enable(); } @Bean WebServerFactoryCustomizer\u0026lt;ConfigurableServletWebServerFactory\u0026gt; enableDefaultServlet() { return (factory) -\u0026gt; factory.setRegisterDefaultServlet(true); } } 2.4. 允许跨域请求 如果我们想将AngularJS前端应用程序与 REST API 分开部署——那么我们需要启用跨域请求。 \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; Spring Data REST 从版本 1.5.0.RELEASE 开始添加了对此的支持。要允许来自不同域的请求，您只需将*@CrossOrigin*注释添加到存储库： @CrossOrigin @RepositoryRestResource(collectionResourceRel = \u0026#34;users\u0026#34;, path = \u0026#34;users\u0026#34;) public interface UserRepository extends CrudRepository\u0026lt;WebsiteUser, Long\u0026gt; {} 因此，在来自 REST 端点的每个响应中，都会添加一个Access-Control-Allow-Origin标头。 3. 创建 AngularJS 客户端 为了创建我们的 CRUD 应用程序的前端，我们将使用*AngularJS——*一个众所周知的 JavaScript 框架，它简化了前端应用程序的创建。 为了使用AngularJS，我们首先需要在我们的 html 页面中包含angular.min.js文件，该文件将被称为users.html： \u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/angularjs/1.5.6/angular.min.js\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 接下来，我们需要创建一个 Angular 模块、控制器和服务，它们将调用 REST 端点并显示返回的数据。 这些将被放置在一个名为app.js的 JavaScript 文件中，该文件也需要包含在users.html页面中： \u0026lt;script src=\u0026#34;view/app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 3.1 Angular服务 首先，让我们创建一个名为UserCRUDService的 Angular 服务，它将利用注入的AngularJS $http服务来调用服务器。每个调用都将放在一个单独的方法中。 让我们看一下使用*/users/{userID}*端点定义通过 id 检索用户的方法： app.service(\u0026#39;UserCRUDService\u0026#39;, [ \u0026#39;$http\u0026#39;, function($http) { this.getUser = function getUser(userId) { return $http({ method : \u0026#39;GET\u0026#39;, url : \u0026#39;users/\u0026#39; + userId }); } } ]); 接下来，让我们定义addUser方法，该方法向**/users URL 发出POST 请求，并在data属性中发送用户值： this.addUser = function addUser(name, email) { return $http({ method : \u0026#39;POST\u0026#39;, url : \u0026#39;users\u0026#39;, data : { name : name, email: email } }); } updateUser方法与上面的方法类似，不同之处在于它将有一个id参数并发出 PATCH 请求： this.updateUser = function updateUser(id, name, email) { return $http({ method : \u0026#39;PATCH\u0026#39;, url : \u0026#39;users/\u0026#39; + id, data : { name : name, email: email } }); } 删除WebsiteUser记录的方法会发出 DELETE 请求： this.deleteUser = function deleteUser(id) { return $http({ method : \u0026#39;DELETE\u0026#39;, url : \u0026#39;users/\u0026#39; + id }) } 最后，让我们看一下检索整个用户列表的方法： this.getAllUsers = function getAllUsers() { return $http({ method : \u0026#39;GET\u0026#39;, url : \u0026#39;users\u0026#39; }); } 所有这些服务方法都将由AngularJS控制器调用。 3.2. Angular控制器 我们将创建一个UserCRUDCtrl AngularJS控制器，该控制器将注入一个UserCRUDService并使用服务方法从服务器获取响应，处理成功和错误情况，并设置包含响应数据的*$scope*变量以在 HTML 页面中显示它. 我们看一下调用getUser(userId)服务函数的getUser( )函数，定义了成功和错误的两个回调方法。如果服务器请求成功，则将响应保存在用户变量中；否则，将处理错误消息： app.controller(\u0026#39;UserCRUDCtrl\u0026#39;, [\u0026#39;$scope\u0026#39;,\u0026#39;UserCRUDService\u0026#39;, function ($scope,UserCRUDService) { $scope.getUser = function () { var id = $scope.user.id; UserCRUDService.getUser($scope.user.id) .then(function success(response) { $scope.user = response.data; $scope.user.id = id; $scope.message=\u0026#39;\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error (response) { $scope.message = \u0026#39;\u0026#39;; if (response.status === 404){ $scope.errorMessage = \u0026#39;User not found!\u0026#39;; } else { $scope.errorMessage = \u0026#34;Error getting user!\u0026#34;; } }); }; }]); *addUser()*函数将调用相应的服务函数并处理响应： $scope.addUser = function () { if ($scope.user != null \u0026amp;\u0026amp; $scope.user.name) { UserCRUDService.addUser($scope.user.name, $scope.user.email) .then (function success(response){ $scope.message = \u0026#39;User added!\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error(response){ $scope.errorMessage = \u0026#39;Error adding user!\u0026#39;; $scope.message = \u0026#39;\u0026#39;; }); } else { $scope.errorMessage = \u0026#39;Please enter a name!\u0026#39;; $scope.message = \u0026#39;\u0026#39;; } } *updateUser()和deleteUser()*函数与上面的函数类似： $scope.updateUser = function () { UserCRUDService.updateUser($scope.user.id, $scope.user.name, $scope.user.email) .then(function success(response) { $scope.message = \u0026#39;User data updated!\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error(response) { $scope.errorMessage = \u0026#39;Error updating user!\u0026#39;; $scope.message = \u0026#39;\u0026#39;; }); } $scope.deleteUser = function () { UserCRUDService.deleteUser($scope.user.id) .then (function success(response) { $scope.message = \u0026#39;User deleted!\u0026#39;; $scope.User = null; $scope.errorMessage=\u0026#39;\u0026#39;; }, function error(response) { $scope.errorMessage = \u0026#39;Error deleting user!\u0026#39;; $scope.message=\u0026#39;\u0026#39;; }); } 最后，让我们定义检索用户列表并将其存储在users变量中的函数： $scope.getAllUsers = function () { UserCRUDService.getAllUsers() .then(function success(response) { $scope.users = response.data._embedded.users; $scope.message=\u0026#39;\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error (response) { $scope.message=\u0026#39;\u0026#39;; $scope.errorMessage = \u0026#39;Error getting users!\u0026#39;; }); } 3.3. 网页 users.html页面将使用上一节中定义的控制器函数和存储的变量*。* 首先，为了使用 Angular 模块，我们需要设置ng-app属性： \u0026lt;html ng-app=\u0026#34;app\u0026#34;\u0026gt; 然后，为了避免每次使用控制器的函数时都输入UserCRUDCtrl.getUser()，我们可以将 HTML 元素包装在一个带有ng-controller属性集的div中： \u0026lt;div ng-controller=\u0026#34;UserCRUDCtrl\u0026#34;\u0026gt; 让我们创建一个表单来输入和显示我们想要操作的WebiteUser对象的值。其中每一个都有一个ng-model属性集，它将它绑定到属性的值： \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td width=\u0026#34;100\u0026#34;\u0026gt;ID:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;id\u0026#34; ng-model=\u0026#34;user.id\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td width=\u0026#34;100\u0026#34;\u0026gt;Name:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;name\u0026#34; ng-model=\u0026#34;user.name\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td width=\u0026#34;100\u0026#34;\u0026gt;Age:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;age\u0026#34; ng-model=\u0026#34;user.email\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; 例如，将id输入绑定到user.id变量意味着每当输入的值发生更改时，都会在user.id变量中设置该值，反之亦然。 接下来，让我们使用ng-click属性来定义将触发调用定义的每个 CRUD 控制器函数的链接： \u0026lt;a ng-click=\u0026#34;getUser(user.id)\u0026#34;\u0026gt;Get User\u0026lt;/a\u0026gt; \u0026lt;a ng-click=\u0026#34;updateUser(user.id,user.name,user.email)\u0026#34;\u0026gt;Update User\u0026lt;/a\u0026gt; \u0026lt;a ng-click=\u0026#34;addUser(user.name,user.email)\u0026#34;\u0026gt;Add User\u0026lt;/a\u0026gt; \u0026lt;a ng-click=\u0026#34;deleteUser(user.id)\u0026#34;\u0026gt;Delete User\u0026lt;/a\u0026gt; 最后，让我们按名称完整显示用户列表： \u0026lt;a ng-click=\u0026#34;getAllUsers()\u0026#34;\u0026gt;Get all Users\u0026lt;/a\u0026gt;\u0026lt;br/\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;div ng-repeat=\u0026#34;usr in users\u0026#34;\u0026gt; {{usr.name}} {{usr.email}} \u0026quot; ","permalink":"http://itcodingman.github.io/angularjs_crud_with_spring_data_rest/","tags":["Spring Data REST"],"title":"带有 Spring Data REST 的 AngularJS CRUD 应用程序"},{"categories":["REST"],"contents":"1. 概述 在这个快速教程中，我们将学习如何从一个简单的 AngularJS 前端使用 RESTful API。 我们将在表格中显示数据，创建资源，更新它，最后删除它。 2. REST API 首先，让我们快速浏览一下我们的简单 API——使用分页公开Feed资源：  分页 - GET /api/myFeeds?page={page}\u0026amp;size={size}\u0026amp;sortDir={dir}\u0026amp;sort={propertyName}* 创建 - POST /api/myFeeds* 更新 – PUT /api/myFeeds/{id}* 删除 - DELETE/api/myFeeds/{id}*  这里的一个快速说明是分页使用以下 4 个参数：  page : 请求页面的索引 size : 每页最大记录数 sort : 用于排序的属性名称 sortDir : 排序方向  以下是Feed资源的示例： { \u0026#34;id\u0026#34;:1, \u0026#34;name\u0026#34;:\u0026#34;codingman feed\u0026#34;, \u0026#34;url\u0026#34;:\u0026#34;/feed\u0026#34; } 3. Feeds页面 现在，让我们看看我们的Feeds页面： \u0026lt;script src=\u0026#34;http://ajax.googleapis.com/ajax/libs/angularjs/1.3.14/angular.min.js\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://ajax.googleapis.com/ajax/libs/angularjs/1.3.14/angular-resource.min.js\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script th:src=\u0026#34;@{/resources/ng-table.min.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script th:src=\u0026#34;@{/resources/mainCtrl.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; ng-click=\u0026#34;addNewFeed()\u0026#34;\u0026gt;Add New RSS Feed\u0026lt;/a\u0026gt; \u0026lt;table ng-table=\u0026#34;tableParams\u0026#34;\u0026gt; \u0026lt;tr ng-repeat=\u0026#34;row in $data track by row.id\u0026#34;\u0026gt; \u0026lt;td data-title=\u0026#34;\u0026#39;Name\u0026#39;\u0026#34; sortable=\u0026#34;\u0026#39;name\u0026#39;\u0026#34;\u0026gt;{{row.name}}\u0026lt;/td\u0026gt; \u0026lt;td data-title=\u0026#34;\u0026#39;Feed URL\u0026#39;\u0026#34; sortable=\u0026#34;\u0026#39;url\u0026#39;\u0026#34;\u0026gt;{{row.url}}\u0026lt;/td\u0026gt; \u0026lt;td data-title=\u0026#34;\u0026#39;Actions\u0026#39;\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; ng-click=\u0026#34;editFeed(row) \u0026#34;\u0026gt;Edit\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; ng-click=\u0026#34;confirmDelete(row.id) \u0026#34;\u0026gt;Delete\u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 请注意，我们使用ng-table来显示数据——更多内容将在以下部分中介绍。 4. Angular控制器 接下来，让我们看看我们的 AngularJS 控制器： var app = angular.module(\u0026#39;myApp\u0026#39;, [\u0026#34;ngTable\u0026#34;, \u0026#34;ngResource\u0026#34;]); app.controller(\u0026#39;mainCtrl\u0026#39;, function($scope, NgTableParams, $resource) { ... }); 注意：  我们注入了ngTable模块以使用它在用户友好的表格中显示我们的数据并处理分页/排序操作 我们还注入了 ngResource模块来使用它来访问我们的 REST API 资源  5. AngularJS 数据表 现在让我们快速浏览一下ng-table模块——这是配置： $scope.feed = $resource(\u0026#34;api/myFeeds/:feedId\u0026#34;,{feedId:\u0026#39;@id\u0026#39;}); $scope.tableParams = new NgTableParams({}, { getData: function(params) { var queryParams = { page:params.page() - 1, size:params.count() }; var sortingProp = Object.keys(params.sorting()); if(sortingProp.length == 1){ queryParams[\u0026#34;sort\u0026#34;] = sortingProp[0]; queryParams[\u0026#34;sortDir\u0026#34;] = params.sorting()[sortingProp[0]]; } return $scope.feed.query(queryParams, function(data, headers) { var totalRecords = headers(\u0026#34;PAGING_INFO\u0026#34;).split(\u0026#34;,\u0026#34;)[0].split(\u0026#34;=\u0026#34;)[1]; params.total(totalRecords); return data; }).$promise; } }); API 需要某种分页样式，因此我们需要在表格中自定义它以匹配它。我们使用ng-module中的参数并在这里创建我们自己的queryParams。 关于分页的一些附加说明：  *params.page()*从 1 开始，所以我们还需要确保它在与 API 通信时变为零索引 params.sorting()返回一个对象 - 例如{“name”: “asc”}，因此我们需要将键和值分隔为两个不同的参数 - sort，sortDir 我们从响应的 HTTP 标头中提取总元素数  6. 更多操作 最后，我们可以使用*ngResource*模块执行很多操作—— $resource确实涵盖了可用操作方面的完整 HTTP 语义。我们还可以定义我们的自定义功能。 我们在上一节中使用query来获取提要列表。请注意，get和query都执行GET——但query用于处理数组响应。 6.1 添加新Feed 为了添加新的提要，我们将使用*$resource方法save*- 如下： $scope.feed = {name:\u0026#34;New feed\u0026#34;, url: \u0026#34;http://www.example.com/feed\u0026#34;}; $scope.createFeed = function(){ $scope.feeds.save($scope.feed, function(){ $scope.tableParams.reload(); }); } 6.2. 更新Feed 我们可以使用我们自己的自定义方法和*$resource* - 如下： $scope.feeds = $resource(\u0026#34;api/myFeeds/:feedId\u0026#34;,{feedId:\u0026#39;@id\u0026#39;},{ \u0026#39;update\u0026#39;: { method:\u0026#39;PUT\u0026#39; } }); $scope.updateFeed = function(){ $scope.feeds.update($scope.feed, function(){ $scope.tableParams.reload(); }); } 请注意我们如何配置自己的更新方法来发送PUT请求。 6.3. 删除Feed 最后，我们可以使用delete方法删除一个Feed： $scope.confirmDelete = function(id){ $scope.feeds.delete({feedId:id}, function(){ $scope.tableParams.reload(); }); } 7. AngularJs 对话框 现在，让我们看看如何使用*ngDialog*模块来显示用于添加/更新我们的提要的简单表单。 这是我们的模板，我们可以在单独的 HTML 页面或同一页面中定义它： \u0026lt;script type=\u0026#34;text/ng-template\u0026#34; id=\u0026#34;templateId\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ngdialog-message\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{feed.name}}\u0026lt;/h2\u0026gt; \u0026lt;input ng-model=\u0026#34;feed.name\u0026#34;/\u0026gt; \u0026lt;input ng-model=\u0026#34;feed.url\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;ngdialog-buttons mt\u0026#34;\u0026gt; \u0026lt;button ng-click=\u0026#34;save()\u0026#34;\u0026gt;Save\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/script\u0026gt; 然后我们将打开我们的对话框来添加/编辑一个提要： $scope.addNewFeed = function(){ $scope.feed = {name:\u0026#34;New Feed\u0026#34;, url: \u0026#34;\u0026#34;}; ngDialog.open({ template: \u0026#39;templateId\u0026#39;, scope: $scope}); } $scope.editFeed = function(row){ $scope.feed.id = row.id; $scope.feed.name = row.name; $scope.feed.url = row.url; ngDialog.open({ template: \u0026#39;templateId\u0026#39;, scope: $scope}); } $scope.save = function(){ ngDialog.close(\u0026#39;ngdialog1\u0026#39;); if(! $scope.feed.id){ $scope.createFeed(); } else{ $scope.updateFeed(); } } 注意：  *$scope.save()*在用户点击对话框中的保存按钮时被调用 $scope.addNewFeed()在用户单击提要页面中的添加新Feed按钮时被调用——它初始化一个新提要对象（没有id） 当用户想要编辑 Feeds 表中的特定行时调用*$scope.editFeed()*  8. 错误处理 最后，让我们看看如何使用 AngularJS 处理响应错误消息。 为了全局处理服务器错误响应——而不是每个请求——我们将向*$httpProvider*注册一个拦截器： app.config([\u0026#39;$httpProvider\u0026#39;, function ($httpProvider) { $httpProvider.interceptors.push(function ($q,$rootScope) { return { \u0026#39;responseError\u0026#39;: function (responseError) { $rootScope.message = responseError.data.message; return $q.reject(responseError); } }; }); }]); 这是我们在 HTML 中的消息表示： \u0026lt;div ng-show=\u0026#34;message\u0026#34; class=\u0026#34;alert alert-danger\u0026#34;\u0026gt; {{message}} \u0026lt;/div\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/angular_js_rest_api/","tags":[],"title":"用于 REST API 的简单 AngularJS 前端"},{"categories":["Sorting"],"contents":"1. 简介 在本教程中，我们将研究快速排序算法并了解它是如何工作的。 快速排序是一种分而治之的算法。这意味着每次迭代的工作原理是将输入分成两部分，然后对它们进行排序，然后再将它们组合在一起 它最初由 Tony Hoare 开发并于 1961 年发布，它仍然是可用的更有效的通用排序算法之一。 2. 算法要求 使用快速排序算法的唯一真正要求是比较两个元素的定义明确的操作。我们可以确定任何元素是否严格小于另一个元素。这种比较的确切性质并不重要，只要它是一致的。请注意，不需要直接相等比较，只需要小于比较。 对于许多类型，这是一个不可否认的比较。例如，数字隐含地定义了如何执行此操作。其他类型不太明显，但我们仍然可以根据排序的要求来定义它。例如，在对字符串进行排序时，我们需要确定字符大小写是否重要或 Unicode 字符如何工作。 3. 二叉树排序 二叉树排序是一种算法，我们在其中构建由我们正在排序的元素组成的平衡二叉树。一旦我们有了这个，我们就可以从这棵树中构建结果。 这个想法是选择一个枢轴作为树上的节点，然后 根据它们是否小于枢轴元素，将所有元素分配给节点的左分支或 *右分支。*然后我们可以递归地对这些分支进行排序，直到我们有一个完全排序的树。 3.1 示例 例如，要对数字列表“3 7 8 5 2 1 9 5 4”进行排序，我们的第一遍将如下所示： Input: 3 7 8 5 2 1 9 5 4 Pivot = 3 Left = 2 1 Right = 7 8 5 9 5 4 这给了我们原始输入的两个分区。** Left列表中的所有内容都严格小于 Pivot，而其他所有内容都在Right列表中**。 接下来，我们使用相同的算法对这两个列表进行排序： Input: 2 1 Pivot = 2 Left = 1 Right = Empty Input: 7 8 5 9 5 4 Pivot = 7 Left = 5 5 4 Right = 8 9 当我们从第一遍对左侧分区进行排序时，我们最终得到了两个长度为 one 或更少的列表。然后这些已经排序——因为不可能有一个未排序的大小为 1 的列表。这意味着我们可以在这里停下来，而是专注于正确分区的剩余部分。 此时，我们有以下结构： / [1] 2 / \\ [] 3 \\ / [5 5 4] 7 \\ [8 9] 我们可以看到我们已经接近排序列表了。我们还有两个分区要排序，然后我们就完成了： 1 / 2 4 / / 3 5 \\ / \\ 7 5 \\ 8 \\ 9 这在算法的 5 遍中对列表进行了排序，适用于越来越小的子列表。但是，内存需求相对较高，必须额外分配 17 个元素的内存来对原始列表中的 9 个元素进行排序。 4. 快速排序的总体思路 快速排序算法在概念上类似于二叉树排序。它不是在我们需要排序的每个步骤中构建子列表，而是在原始列表中完成所有工作。 它的工作原理是围绕选定的枢轴动态交换列表中的元素，然后递归地将子列表排序到该枢轴的任一侧。这使得它的空间效率显着提高，这对于大型列表可能很重要。 快速排序取决于两个关键因素——选择主元和 划分元素的机制。 这个算法的关键是 配分函数，我们很快就会讲到。这将返回输入数组的索引，使得该索引下方的每个元素排序为小于该索引处的元素，并且该索引处的元素排序为小于其上方的所有元素。 这样做将涉及交换数组中的一些元素，以使它们成为该索引的适当一侧。 一旦我们完成了这个分区，我们就将算法应用到这个索引两侧的两个分区上。当我们的分区每个只包含一个元素时，这最终完成，此时输入数组现在已排序。 因此，我们可以将快速排序算法总结为三个步骤：   选择一个元素作为枢轴   通过将较小的元素移动到枢轴的左侧并将较大的元素移动到其右侧来划分问题集   在每个分区上重复上述步骤   快速排序示例    这里我们有一个包含十个未排序值的数组，我们将使用 Quicksort 对其进行排序： **我们要采取的第一步是从这个数组中选择一个元素作为我们的枢轴。**我们可以用不同的方式选择一个主元，但对于这个例子，我们总是选择数组的最右边的元素，即数字 5。 现在我们已经确定了 5 作为我们的枢轴，让我们根据我们的枢轴对数组进行分区，将大于 5 的数字放在右侧，将小于 5 的数字放在左侧。在这一点上，我们并不真正担心对数字进行排序，只是我们已经将它们移动到关于枢轴的正确位置。 在此过程中，我们将数组围绕枢轴 5 划分为两部分： 让我们取最左边的分区（索引 0 - 1）并重复这些步骤。我们将选择数字 2 作为我们的支点并相应地重新排列，这为我们提供了以下信息： 接下来，我们取最右边的分区（索引 3 - 9）并将 10 作为我们的枢轴；任何大于 10 的数字都将移至其右侧，小于 10 的数字将移至其左侧： 正如我们通过定位每个选定的枢轴所看到的那样，我们正在慢慢接近排序数组！如果我们继续在索引 5 到 9 的剩余分区上重复这些步骤，我们将最终达到我们的数组从最小到最大排序的点。 下图显示了所有步骤，最终为我们提供了一个排序数组： 正如我们所看到的，这些步骤可能会根据我们选择枢轴元素的方式而有所不同。因此，让我们开始讨论选择支点的主要方法。 快速排序实现   快速排序算法有多种实现。这些实现在选择枢轴元素的方式方面彼此不同。让我们讨论分区方法。 6.1 Lomuto 分区 Lomuto 分区归功于 Nico Lomuto。这通过迭代输入数组来工作，交换严格小于预先选择的枢轴元素的元素。它们出现在数组的较早位置，但在滑动目标索引上。 然后，这个滑动目标索引就是我们将返回的新分区索引，以供更大算法的下一次递归使用。 这是为了确保我们的滑动目标索引的位置使得数组中它之前的所有元素都小于这个元素，并且这个元素小于数组中它之后的所有元素。 让我们用伪代码来看看这个： fun quicksort(input : T[], low : int, high : int) if (low \u0026lt; high) p := partition(input, low, high) quicksort(input, low, p - 1) quicksort(input, p + 1, high) fun partition(input: T[], low: int, high: int) : int pivot := input[high] partitionIndex := low loop j from low to (high - 1) if (input[j] \u0026lt; pivot) then swap(input[partitionIndex], input[j]) partitionIndex := partitionIndex + 1 swap(input[partitionIndex], input[high] return partitionIndex 作为一个工作示例，我们可以从之前对数组进行分区： Sorting input: 3,7,8,5,2,1,9,5,4 from 0 to 8 Pivot: 4 Partition Index: 0 When j == 0 =\u0026gt; input[0] == 3 =\u0026gt; Swap 3 for 3 =\u0026gt; input := 3,7,8,5,2,1,9,5,4, partitionIndex := 1 When j == 1 =\u0026gt; input[1] == 7 =\u0026gt; No Change When j == 2 =\u0026gt; input[2] == 8 =\u0026gt; No Change When j == 3 =\u0026gt; input[3] == 5 =\u0026gt; No Change When j == 4 =\u0026gt; input[4] == 7 =\u0026gt; Swap 7 for 2 =\u0026gt; input := 3,2,8,5,7,1,9,5,4, partitionIndex := 2 When j == 5 =\u0026gt; input[5] == 8 =\u0026gt; Swap 8 for 1 =\u0026gt; input := 3,2,1,5,7,8,9,5,4, partitionIndex := 3 When j == 6 =\u0026gt; input[6] == 9 =\u0026gt; No Change When j == 7 =\u0026gt; input[7] == 5 =\u0026gt; No Change After Loop =\u0026gt; Swap 4 for 5 =\u0026gt; input := 3,2,1,4,7,8,9,5,5, partitionIndex := 3 通过这个我们可以看到，我们已经执行了 3 次交换，并确定了索引“3”的新分区点。这些交换之后的数组使得元素 0、1 和 2 都小于元素 3，并且元素 3 小于元素 4、5、6、7 和 8。 完成此操作后，将递归更大的算法，这样我们将从 0 到 2 对子数组进行排序，从 4 到 8 对子数组进行排序。例如，对从 0 到 2 的子数组重复此操作，我们会这样做： Sorting input: 3,2,1,4,7,8,9,5,5 from 0 to 2 Pivot: 1 Partition Index: 0 When j == 0 =\u0026gt; input[0] == 3 =\u0026gt; No Change When j == 1 =\u0026gt; input[1] == 2 =\u0026gt; No Change After Loop =\u0026gt; Swap 1 for 3 =\u0026gt; input := 1,2,3,4,7,8,9,5,5, partitionIndex := 0 请注意，我们仍在传递整个输入数组以供算法使用，但因为我们有低和高索引，我们实际上只关注我们关心的位。这是一种效率，意味着我们不需要复制整个数组或其中的部分。 在整个算法中，对整个数组进行排序，我们执行了 12 次不同的交换以获得结果。 6.2. 霍尔分区 Hoare 分区是由 Tony Hoare 在 Quicksort 算法最初发布时提出的。它不是从低到高跨数组工作，而是从两端一次向中心迭代。这意味着我们有更多的迭代，更多的比较，但更少的交换。 这可能很重要，因为通常比较内存值比交换它们便宜。 在伪代码中： fun quicksort(input : T[], low : int, high : int) if (low \u0026lt; high) p := partition(input, low, high) quicksort(input, low, p) // Note that this is different than when using Lomuto quicksort(input, p + 1, high) fun partition(input : T[], low: int, high: int) : int pivotPoint := floor((high + low) / 2) pivot := input[pivotPoint] high++ low-- loop while True low++ loop while (input[low] \u0026lt; pivot) high-- loop while (input[high] \u0026gt; pivot) if (low \u0026gt;= high) return high swap(input[low], input[high]) 作为一个工作示例，我们可以从之前对数组进行分区： Sorting input: 3,7,8,5,2,1,9,5,4 from 0 to 8 Pivot: 2 Loop #1 Iterate low =\u0026gt; input[0] == 3 =\u0026gt; Stop, low == 0 Iterate high =\u0026gt; input[8] == 4 =\u0026gt; high := 7 Iterate high =\u0026gt; input[7] == 5 =\u0026gt; high := 6 Iterate high =\u0026gt; input[6] == 9 =\u0026gt; high := 5 Iterate high =\u0026gt; input[5] == 1 =\u0026gt; Stop, high == 5 Swap 1 for 3 =\u0026gt; input := 1,7,8,5,2,3,9,5,4 Low := 1 High := 4 Loop #2 Iterate low =\u0026gt; input[1] == 7 =\u0026gt; Stop, low == 1 Iterate high =\u0026gt; input[4] == 2 =\u0026gt; Stop, high == 4 Swap 2 for 7 =\u0026gt; input := 1,2,8,5,7,3,9,5,4 Low := 2 High := 3 Loop #3 Iterate low =\u0026gt; input[2] == 8 =\u0026gt; Stop, low == 2 Iterate high =\u0026gt; input[3] == 5 =\u0026gt; high := 2 Iterate high =\u0026gt; input[2] == 8 =\u0026gt; high := 1 Iterate high =\u0026gt; input[1] == 2 =\u0026gt; Stop, high == 1 Return 1 从表面上看，这看起来是一个更复杂的算法，正在做更多的工作。但是，总体而言，它的工作成本较低。整个算法只需要 8 次交换而不是 Lomuto 分区方案所需的 12 次即可达到相同的结果。 7. 算法调整 根据具体要求，我们可以对正常算法进行一些调整。这些并不适合每种情况，因此我们应该仅在适当的时候使用它们，但它们可以对结果产生重大影响。 7.1 枢轴选择 选择要围绕的元素对算法的效率具有重要意义。上面，我们选择了一个固定元素。如果列表真正按随机顺序打乱，这很有效，但列表越有序，效率就越低。 如果我们要对列表 1, 2, 3, 4, 5, 6, 7, 8, 9进行排序，那么 Hoare 分区方案以零交换进行排序，但 Lomuto 方案需要 44。同样，列表 *9, 8, 7、6、5、4、3、2、1 需要与 Hoare 交换 4次，*与 Lomuto 交换 24 次。 在 Hoare 分区方案中，这已经很不错了，但是 Lomuto 方案可以改进很多。通过改变我们选择枢轴的方式，通过使用三个固定点的中值，我们可以获得显着的改进。 这种调整简称为三中位数： mid := (low + high) / 2 if (input[mid] \u0026lt; input[low]) swap(input[mid], input[low]) if (input[high] \u0026lt; input[low]) swap(input[high], input[low]) if (input[mid] \u0026lt; input[high]) swap(input[mid], input[high]) 我们将其应用于算法的每一次通过。这需要三个固定点并确保它们以相反的顺序预先排序。 这似乎不寻常，但影响不言而喻。使用它对列表 1、2、3、4、5、6、7、8、9进行排序现在需要 16 次交换，而之前需要 44 次。这减少了 64% 的工作量。但是，列表 9, 8, 7, 6, 5, 4, 3, 2, 1只下降到 19 次交换，而不是之前的 24 次，列表 3, 7, 8, 5, 2, 1, 9 , 5, 4从之前的 12 上升到 18。 7.2. 重复元素 当有大量直接相等的元素时，快速排序会受到轻微影响。它仍然会尝试对所有这些进行排序，并且可能会做很多不必要的工作。 我们可以做的一个调整是在分割阶段检测这些相等的元素，并在它们的任一侧返回边界，而不仅仅是一个点。然后，我们可以将一整段相等的元素视为已经排序，并只处理两边的元素。 让我们用伪代码来看看： fun quicksort(input : T[], low : int, high : int) if (low \u0026lt; high) (left, right) := partition(input, low, high) quicksort(input, low, left - 1) quicksort(input, right + 1, high) 每次分区方案返回一个主元时，它都会返回所有具有相同值的相邻元素的下索引和上索引。这可以快速删除列表的较大部分，而无需处理它们。 为了实现这一点，我们需要能够比较元素的相等和小于。然而，这通常是更容易实现的比较。 8. 算法性能 快速排序算法通常被认为是非常有效的。平均而言，它具有O(n log(n))对任意输入进行排序的性能。 原始的 Lomuto 分区方案将降级为O(n)列表已经排序并且我们选择最终元素作为枢轴的情况。正如我们所见，当我们为枢轴选择实施三中位数时，这种情况会有所改善，事实上，这会将我们带回到O(n log(n)) 相反，Hoare 分区方案可能会导致更多的比较，因为它递归low-\u0026gt;p而不是low-\u0026gt;p-1. 这意味着递归进行更多比较，即使它导致更少的交换。 \u0026quot; ","permalink":"http://itcodingman.github.io/algorithm_quicksort/","tags":[],"title":"快速排序算法概述"},{"categories":["Reactive","Spring"],"contents":"1. 简介 在本文中，我们将专注于将 Akka 与 Spring 框架集成——以允许将基于 Spring 的服务注入 Akka actor。 在阅读本文之前，建议先了解 Akka 的基础知识。 2. As中的依赖注入 Akka是一个基于 Actor 并发模型的强大应用框架。该框架是用 Scala 编写的，这当然也使其在基于 Java 的应用程序中完全可用。因此**，我们经常希望将 Akka 与现有的基于 Spring 的应用程序集成，**或者简单地使用 Spring 将 bean 连接到 actor。 Spring/Akka 集成的问题在于 Spring 中 bean 的管理和 Akka 中 Actor 的管理之间的差异：Actor 具有不同于典型 Spring bean 生命周期的特定生命周期。 此外，actor 被拆分为一个 actor 本身（这是一个内部实现细节，不能由 Spring 管理）和一个 actor 引用，它可以被客户端代码访问，以及在不同的 Akka 运行时之间可序列化和可移植。 幸运的是，Akka 提供了一种机制，即Akka 扩展，这使得使用外部依赖注入框架变得相当容易。 3. Maven依赖 为了在我们的 Spring 项目中演示 Akka 的使用，我们需要一个最基本的 Spring 依赖项——spring- context库和akka-actor库。库版本可以提取到pom的**部分： \u0026lt;properties\u0026gt; \u0026lt;spring.version\u0026gt;4.3.1.RELEASE\u0026lt;/spring.version\u0026gt; \u0026lt;akka.version\u0026gt;2.4.8\u0026lt;/akka.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${akka.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 确保检查 Maven Central 以获取最新版本的spring-context和akka-actor依赖项。 请注意，akka-actor依赖项的名称中有一个*_2.11*后缀，这表示此版本的 Akka 框架是针对 Scala 版本 2.11 构建的。相应版本的 Scala 库将传递地包含在您的构建中。 4. 将 Spring Beans 注入 Akka Actors 让我们创建一个简单的 Spring/Akka 应用程序，该应用程序由一个参与者组成，该参与者可以通过向这个人发出问候来回答这个人的名字。问候的逻辑将被提取到一个单独的服务中。我们希望将此服务自动连接到一个参与者实例。Spring 集成将帮助我们完成这项任务。 4.1 定义演员和服务 为了演示将服务注入到 actor 中，我们将创建一个简单的类GreetingActor，定义为无类型的 actor（扩展 Akka 的UntypedActor基类）。每个 Akka Actor 的主要方法是onReceive方法，它接收消息并根据某些指定的逻辑对其进行处理。 在我们的例子中，GreetingActor实现检查消息是否是预定义的Greet类型，然后从**Greet实例中获取人名，然后使用GreetingService接收此人的问候语，并使用接收到的问候语字符串回答发件人。如果消息属于其他未知类型，则将其传递给参与者预定义的未处理方法。 我们来看一下： @Component @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public class GreetingActor extends UntypedActor { private GreetingService greetingService; // constructor  @Override public void onReceive(Object message) throws Throwable { if (message instanceof Greet) { String name = ((Greet) message).getName(); getSender().tell(greetingService.greet(name), getSelf()); } else { unhandled(message); } } public static class Greet { private String name; // standard constructors/getters  } } 注意Greet消息类型被定义为这个actor内部的一个静态内部类，这被认为是一个很好的实践。接受的消息类型应尽可能靠近参与者定义，以避免混淆该参与者可以处理哪些消息类型。 还要注意 Spring 注释@Component和@Scope——**它们将类定义为具有原型范围的 Spring 管理的 bean。 范围非常重要，因为每个 bean 检索请求都应该产生一个新创建的实例，因为这种行为与 Akka 的 actor 生命周期相匹配。如果您在其他范围内实现此 bean，则在 Akka 中重新启动 actor 的典型情况很可能无法正常运行。 最后，请注意我们不必显式地*@Autowire* GreetingService实例——这是可能的，因为 Spring 4.3 的新特性称为隐式构造函数注入。 GreeterService的实现非常简单，请注意我们通过向其添加*@Component注释将其定义为 Spring 管理的 bean（具有默认的单例*范围）： @Component public class GreetingService { public String greet(String name) { return \u0026#34;Hello, \u0026#34; + name; } } 4.2. 通过 Akka 扩展添加 Spring 支持 将 Spring 与 Akka 集成的最简单方法是通过 Akka 扩展。 **扩展是每个参与者系统创建的单例实例。**它由一个实现标记接口Extension的扩展类本身和一个通常继承AbstractExtensionId的扩展 id 类组成。 由于这两个类是紧密耦合的，因此实现嵌套在 ExtensionId 类中的Extension类是有意义的： public class SpringExtension extends AbstractExtensionId\u0026lt;SpringExtension.SpringExt\u0026gt; { public static final SpringExtension SPRING_EXTENSION_PROVIDER = new SpringExtension(); @Override public SpringExt createExtension(ExtendedActorSystem system) { return new SpringExt(); } public static class SpringExt implements Extension { private volatile ApplicationContext applicationContext; public void initialize(ApplicationContext applicationContext) { this.applicationContext = applicationContext; } public Props props(String actorBeanName) { return Props.create( SpringActorProducer.class, applicationContext, actorBeanName); } } } 首先——SpringExtension从AbstractExtensionId类中实现了一个createExtension方法——它负责创建扩展实例，即SpringExt对象。 SpringExtension类也有一个静态字段SPRING_EXTENSION_PROVIDER ，它包含对其唯一实例的引用。添加一个私有构造函数来明确声明SpringExtention应该是一个单例类通常是有意义的，但为了清楚起见，我们将省略它。 其次，静态内部类SpringExt就是扩展本身。由于Extension只是一个标记接口，我们可以按照我们认为合适的方式定义这个类的内容。 在我们的例子中，我们需要initialize方法来保存一个 Spring ApplicationContext实例——这个方法在每个扩展初始化时只会被调用一次。 我们还需要props方法来创建Props对象。Props实例是一个演员的蓝图，在我们的例子中，Props.create方法接收一个SpringActorProducer类和该类的构造函数参数。这些是这个类的构造函数将被调用的参数。 每次我们需要 Spring 管理的 Actor 引用时，都会执行props方法。 第三个也是最后一个难题是SpringActorProducer类。它实现了 Akka 的IndirectActorProducer接口，该接口允许通过实现producer和actorClass方法来覆盖 actor 的实例化过程。 你可能已经猜到了，它不会直接实例化，而是总是从 Spring 的ApplicationContext中检索一个actor实例。由于我们已将 actor设为原型作用域的 bean，因此每次调用 producer方法都将返回该 actor 的一个新实例： public class SpringActorProducer implements IndirectActorProducer { private ApplicationContext applicationContext; private String beanActorName; public SpringActorProducer(ApplicationContext applicationContext, String beanActorName) { this.applicationContext = applicationContext; this.beanActorName = beanActorName; } @Override public Actor produce() { return (Actor) applicationContext.getBean(beanActorName); } @Override public Class\u0026lt;? extends Actor\u0026gt; actorClass() { return (Class\u0026lt;? extends Actor\u0026gt;) applicationContext .getType(beanActorName); } } 4.3. 把它们放在一起 剩下要做的就是创建一个 Spring 配置类（标有*@Configuration注释），它将告诉 Spring 扫描当前包以及所有嵌套包（这是由@ComponentScan*注释确保的）并创建一个 Spring 容器. 我们只需要添加一个额外的 bean—— ActorSystem实例——并在这个**ActorSystem上初始化 Spring 扩展： @Configuration @ComponentScan public class AppConfiguration { @Autowired private ApplicationContext applicationContext; @Bean public ActorSystem actorSystem() { ActorSystem system = ActorSystem.create(\u0026#34;akka-spring-demo\u0026#34;); SPRING_EXTENSION_PROVIDER.get(system) .initialize(applicationContext); return system; } } 4.4. 检索Spring的 Actor 为了测试一切正常，我们可以将ActorSystem实例注入我们的代码（一些 Spring 管理的应用程序代码或基于 Spring 的测试），使用我们的扩展为一个演员创建一个Props对象，检索一个演员的引用通过Props对象并尝试向某人打招呼： ActorRef greeter = system.actorOf(SPRING_EXTENSION_PROVIDER.get(system) .props(\u0026#34;greetingActor\u0026#34;), \u0026#34;greeter\u0026#34;); FiniteDuration duration = FiniteDuration.create(1, TimeUnit.SECONDS); Timeout timeout = Timeout.durationToTimeout(duration); Future\u0026lt;Object\u0026gt; result = ask(greeter, new Greet(\u0026#34;John\u0026#34;), timeout); Assert.assertEquals(\u0026#34;Hello, John\u0026#34;, Await.result(result, duration)); 这里我们使用典型的akka.pattern.Patterns.ask模式，它返回一个 Scala 的Future实例。一旦计算完成，Future将使用我们在**GreetingActor.onMessasge方法中返回的值解析。 我们可以通过将 Scala 的Await.result方法应用于Future来等待结果，或者，更优选地，使用异步模式构建整个应用程序。 \u0026quot; ","permalink":"http://itcodingman.github.io/akka_with_spring/","tags":["Akka"],"title":"用 Akka 介绍 Spring"},{"categories":["Data","Reactive"],"contents":"1. 概述 在本文中，我们将研究建立在 Akka actor 框架之上的akka-streams库，它遵循响应式流宣言。Akka Streams API 允许我们从独立的步骤轻松组合数据转换流。 此外，所有处理都是以反应式、非阻塞和异步的方式完成的。 2.Maven依赖 首先，我们需要将akka-stream 和akka-stream-testkit库添加到我们的pom.xml 中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-stream_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-stream-testkit_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Streams API 要使用 Akka Streams，我们需要了解核心 API 概念：  Source —— akka-stream库中处理的入口点——我们可以从多个源创建这个类的实例；例如，如果我们想从单个StringSourcesingle()从IterableItemCreateSource Flow – 主要处理构建块– 每个Flow实例都有一个输入和一个输出值 Materializer——如果我们希望我们的Flow有一些副作用，比如记录或保存结果，我们可以使用它；最常见的是，我们将NotUsed别名作为Materializer传递，以表示我们的Flow不应该有任何副作用 Sink 操作——当我们构建一个Streams 时，它不会执行，直到我们在其上注册一个Sink 操作——它是一个终端操作，会触发整个Streams  4.在 Akka Streams 中创建Flow 让我们从构建一个简单的示例开始，我们将在其中展示如何**创建和组合多个Flow——**以处理整数流并从流中计算整数对的平均移动窗口。 我们将解析一个以分号分隔的整数字符串作为输入，以创建示例的akka-stream 源。 4.1 使用stream解析输入 首先，让我们创建一个DataImporter类，它将采用 ActorSystem 的一个实例*，我们稍后将使用它来创建我们的Flow*： public class DataImporter { private ActorSystem actorSystem; // standard constructors, getters... } 接下来，让我们创建一个parseLine方法，该方法将从我们的分隔输入字符串生成一个整数列表。请记住，我们在这里使用 Java Stream API 仅用于解析： private List\u0026lt;Integer\u0026gt; parseLine(String line) { String[] fields = line.split(\u0026#34;;\u0026#34;); return Arrays.stream(fields) .map(Integer::parseInt) .collect(Collectors.toList()); } 我们的初始Flow会将parseLine应用于我们的输入，以创建一个输入类型为String且输出类型为Integer的Flow： private Flow\u0026lt;String, Integer, NotUsed\u0026gt; parseContent() { return Flow.of(String.class) .mapConcat(this::parseLine); } 当我们调用parseLine()方法时，编译器知道该 lambda 函数的参数将是一个字符串——与我们的Flow*的输入类型相同。 请注意，我们使用的是mapConcat()方法——等效于 Java 8 flatMap()方法——因为我们希望将parseLine()返回的整数列表扁平化为整数流，以便我们处理中的后续步骤不需要处理List。 4.2 使用Streams执行计算 至此，我们有了解析整数的流程。现在，我们需要实现将所有输入元素组合成对并计算这些对的平均值的逻辑。 现在，我们将创建一个*Integer流并使用grouped()*方法对**它们进行分组。 接下来，我们要计算平均值。 由于我们对处理这些平均值的顺序不感兴趣，因此我们可以使用*mapAsyncUnordered()*方法使用多个线程并行计算平均值，并将线程数作为参数传递给该方法。 将作为 lambda 传递给Flow的操作需要返回CompletableFuture，因为该操作将在单独的线程中异步计算： private Flow\u0026lt;Integer, Double, NotUsed\u0026gt; computeAverage() { return Flow.of(Integer.class) .grouped(2) .mapAsyncUnordered(8, integers -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; integers.stream() .mapToDouble(v -\u0026gt; v) .average() .orElse(-1.0))); } 我们正在计算八个并行线程的平均值。请注意，我们使用 Java 8 Stream API 来计算平均值。 4.3. 将多个Flow组合成一个Flow Flow API 是一个流畅的抽象，它允许我们组合多个Flow实例来实现我们的最终处理目标。我们可以有细粒度的流程，例如，一个正在解析*JSON，*另一个正在做一些转换，另一个正在收集一些统计信息。 这样的粒度将帮助我们创建更多可测试的代码，因为我们可以独立地测试每个处理步骤。 我们在上面创建了两个可以相互独立工作的流程。现在，我们想将它们组合在一起。 首先，我们要解析我们的输入String，接下来，我们要计算元素流的平均值。 *我们可以使用via()*方法来组合我们的流程： Flow\u0026lt;String, Double, NotUsed\u0026gt; calculateAverage() { return Flow.of(String.class) .via(parseContent()) .via(computeAverage()); } 我们创建了一个输入类型为String的**Flow和两个其他流。parseContent ()**流接受一个字符串输入并返回一个整数作为输出。computeAverage() 流采用该Integer并计算返回Double作为输出类型的平均值。 5. 向流中添加Sink 正如我们所提到的，到目前为止，整个Flow还没有执行，因为它是惰性的。**要开始执行Flow，我们需要定义一个Sink。例如，Sink操作可以将数据保存到数据库中，或将结果发送到某些外部 Web 服务。 假设我们有一个带有以下save()方法的**AverageRepository类，它将结果写入我们的数据库： CompletionStage\u0026lt;Double\u0026gt; save(Double average) { return CompletableFuture.supplyAsync(() -\u0026gt; { // write to database  return average; }); } 现在，我们要创建一个使用此方法保存Flow处理结果的Sink操作。要创建我们的Sink，我们首先需要**创建一个Flow，它将我们的处理结果作为输入类型**。接下来，我们要将所有结果保存到数据库中。 同样，我们不关心元素的顺序，因此我们可以使用*mapAsyncUnordered()方法并行执行save()*操作。 要从Flow中创建Sink，我们需要使用Sink.ignore()作为第一个参数和Keep.right()作为第二个参数调用toMat() ，因为我们想要返回处理的状态： private Sink\u0026lt;Double, CompletionStage\u0026lt;Done\u0026gt;\u0026gt; storeAverages() { return Flow.of(Double.class) .mapAsyncUnordered(4, averageRepository::save) .toMat(Sink.ignore(), Keep.right()); } 6. 定义流量来源 我们需要做的最后一件事是*从输入String创建一个Source。我们可以使用*via()方法将calculateAverage()流应用到这个源。 然后，要将Sink添加到处理中，我们需要调用runWith()方法并传递我们刚刚创建的storeAverages() Sink： CompletionStage\u0026lt;Done\u0026gt; calculateAverageForContent(String content) { return Source.single(content) .via(calculateAverage()) .runWith(storeAverages(), ActorMaterializer.create(actorSystem)) .whenComplete((d, e) -\u0026gt; { if (d != null) { System.out.println(\u0026#34;Import finished \u0026#34;); } else { e.printStackTrace(); } }); } 请注意，当处理完成时，我们正在添加*whenComplete()*回调，我们可以在其中根据处理的结果执行一些操作。 7. 测试Akka 流 我们可以使用akka-stream-testkit 测试我们的处理。 测试处理的实际逻辑的最佳方法是测试所有Flow逻辑并使用TestSink触发计算并对结果进行断言。 在我们的测试中，我们正在创建我们想要测试的Flow ，接下来，我们将从测试输入内容创建一个Source ： @Test public void givenStreamOfIntegers_whenCalculateAverageOfPairs_thenShouldReturnProperResults() { // given  Flow\u0026lt;String, Double, NotUsed\u0026gt; tested = new DataImporter(actorSystem).calculateAverage(); String input = \u0026#34;1;9;11;0\u0026#34;; // when  Source\u0026lt;Double, NotUsed\u0026gt; flow = Source.single(input).via(tested); // then  flow .runWith(TestSink.probe(actorSystem), ActorMaterializer.create(actorSystem)) .request(4) .expectNextUnordered(5d, 5.5); } 我们正在检查我们是否期望四个输入参数，并且两个平均值的结果可以以任何顺序到达，因为我们的处理是以异步和并行方式完成的。 \u0026quot; ","permalink":"http://itcodingman.github.io/akka_streams/","tags":["Akka"],"title":"Akka Streams 指南"},{"categories":["Java"],"contents":" 概述   当我们希望我们的 Web 客户端与我们的服务器保持对话时，WebSockets 可能是一个有用的解决方案。WebSockets 保持持久的全双工连接。这使我们能够在服务器和客户端之间发送双向消息。 在本教程中，我们将学习如何在Play Framework中将 WebSockets 与Akka一起使用。 设置   让我们设置一个简单的聊天应用程序。用户将向服务器发送消息，服务器将响应来自JSONPlaceholder的消息。 2.1 设置 Play 框架应用程序 我们将使用 Play 框架构建这个应用程序。 让我们按照Introduction to Play in Java 中的说明设置和运行一个简单的 Play Framework 应用程序。 2.2. 添加必要的 JavaScript 文件 此外，我们还需要使用 JavaScript 来编写客户端脚本。这将使我们能够接收从服务器推送的新消息。我们将为此使用jQuery库。 让我们将 jQuery 添加到app/views/ index.scala.html文件的底部： \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.4.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 2.3. 设置 Akka 最后，我们将使用 Akka 来处理服务器端的 WebSocket 连接。 让我们导航到build.sbt文件并添加依赖项。 我们需要添加 *as-actor*和 *as-testkit*依赖项： libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-actor\u0026#34; % akkaVersion libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-testkit\u0026#34; % akkaVersion 我们需要这些能够使用和测试 Akka 框架代码。 接下来，我们将使用 Akka 流。所以让我们添加*akka-stream*依赖项： libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-stream\u0026#34; % akkaVersion 最后，我们需要从 Akka actor 调用一个 rest 端点。为此，我们需要 *akka-http*依赖项。当我们这样做时，端点将返回我们必须反序列化的 JSON 数据，因此我们还需要添加akka-http-jackson依赖项： libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http-jackson\u0026#34; % akkaHttpVersion libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http\u0026#34; % akkaHttpVersion 现在我们都准备好了。让我们看看如何让 WebSockets 工作！ 使用 Akka Actor 处理 WebSocket   **Play 的 WebSocket 处理机制是围绕 Akka 流构建的。**WebSocket 被建模为流。因此，传入的 WebSocket 消息被馈送到流中，流产生的消息被发送到客户端。 要使用 Actor 处理 WebSocket，我们需要将ActorRef转换为流的 Play 实用程序ActorFlow。这主要需要一些Java代码，稍加配置。 3.1 WebSocket 控制器方法 首先，我们需要一个Materializer实例。Materializer 是流执行引擎的工厂。 我们需要将ActorSystem和Materializer注入控制器app/controllers/HomeController.java： private ActorSystem actorSystem; private Materializer materializer; @Inject public HomeController( ActorSystem actorSystem, Materializer materializer) { this.actorSystem = actorSystem; this.materializer = materializer; } 现在让我们添加一个套接字控制器方法： public WebSocket socket() { return WebSocket.Json .acceptOrResult(this::createActorFlow); } 这里我们调用函数acceptOrResult，它接受请求头并返回一个future。返回的未来是处理 WebSocket 消息的流。 相反，我们可以拒绝请求并返回拒绝结果。 现在，让我们创建流程： private CompletionStage\u0026lt;F.Either\u0026lt;Result, Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt;\u0026gt;\u0026gt; createActorFlow(Http.RequestHeader request) { return CompletableFuture.completedFuture( F.Either.Right(createFlowForActor())); } Play Framework 中的 F类定义了一组函数式编程风格的助手。在这种情况下，我们使用F.Either.Right来接受连接并返回流。 假设我们想在客户端未通过身份验证时拒绝连接。 为此，我们可以检查会话中是否设置了用户名。如果不是，我们拒绝与 HTTP 403 Forbidden 的连接： private CompletionStage\u0026lt;F.Either\u0026lt;Result, Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt;\u0026gt;\u0026gt; createActorFlow2(Http.RequestHeader request) { return CompletableFuture.completedFuture( request.session() .getOptional(\u0026#34;username\u0026#34;) .map(username -\u0026gt; F.Either.\u0026lt;Result, Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt;\u0026gt;Right( createFlowForActor())) .orElseGet(() -\u0026gt; F.Either.Left(forbidden()))); } 我们使用F.Either.Left 来拒绝连接，就像我们使用F.Either.Right提供流一样。 最后，我们将流程链接到将处理消息的参与者： private Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt; createFlowForActor() { return ActorFlow.actorRef(out -\u0026gt; Messenger.props(out), actorSystem, materializer); } ActorFlow.actorRef创建了一个由 Messenger actor处理的流。 3.2. routes文件 现在，让我们在conf/routes中添加控制器方法的路由定义： GET / controllers.HomeController.index(request: Request) GET /chat controllers.HomeController.socket GET /chat/with/streams controllers.HomeController.akkaStreamsSocket GET /assets/*file controllers.Assets.versioned(path=\u0026#34;/public\u0026#34;, file: Asset) 这些路由定义将传入的 HTTP 请求映射到控制器操作方法，如Routing in Play Applications in Java 中所述。 3.3. Actor 实现 Actor 类最重要的部分是 createReceive方法，它决定了 Actor 可以处理哪些消息： @Override public Receive createReceive() { return receiveBuilder() .match(JsonNode.class, this::onSendMessage) .matchAny(o -\u0026gt; log.error(\u0026#34;Received unknown message: {}\u0026#34;, o.getClass())) .build(); } Actor 会将与JsonNode类 匹配的所有消息转发到onSendMessage处理程序方法： private void onSendMessage(JsonNode jsonNode) { RequestDTO requestDTO = MessageConverter.jsonNodeToRequest(jsonNode); String message = requestDTO.getMessage().toLowerCase(); //..  processMessage(requestDTO); } 然后处理程序将使用processMessage方法响应每条消息： private void processMessage(RequestDTO requestDTO) { CompletionStage\u0026lt;HttpResponse\u0026gt; responseFuture = getRandomMessage(); responseFuture.thenCompose(this::consumeHttpResponse) .thenAccept(messageDTO -\u0026gt; out.tell(MessageConverter.messageToJsonNode(messageDTO), getSelf())); } 3.4. 使用 Akka HTTP 使用 Rest API 我们将向JSONPlaceholder Posts的虚拟消息生成器发送 HTTP 请求。当响应到达时，我们通过写出将响应发送给客户端。 让我们有一个使用随机帖子 ID 调用端点的方法： private CompletionStage\u0026lt;HttpResponse\u0026gt; getRandomMessage() { int postId = ThreadLocalRandom.current().nextInt(0, 100); return Http.get(getContext().getSystem()) .singleRequest(HttpRequest.create( \u0026#34;https://jsonplaceholder.typicode.com/posts/\u0026#34; + postId)); } 我们还在处理通过调用服务获得的HttpResponse以获得 JSON 响应： private CompletionStage\u0026lt;MessageDTO\u0026gt; consumeHttpResponse( HttpResponse httpResponse) { Materializer materializer = Materializer.matFromSystem(getContext().getSystem()); return Jackson.unmarshaller(MessageDTO.class) .unmarshal(httpResponse.entity(), materializer) .thenApply(messageDTO -\u0026gt; { log.info(\u0026#34;Received message: {}\u0026#34;, messageDTO); discardEntity(httpResponse, materializer); return messageDTO; }); } MessageConverter类是用于在 JsonNode和 DTO之间进行转换的 实用程序： public static MessageDTO jsonNodeToMessage(JsonNode jsonNode) { ObjectMapper mapper = new ObjectMapper(); return mapper.convertValue(jsonNode, MessageDTO.class); } 接下来，我们需要丢弃实体。如果实体对我们没有任何用途，则discardEntityBytes便捷方法的目的是轻松丢弃实体。 让我们看看如何丢弃字节： private void discardEntity( HttpResponse httpResponse, Materializer materializer) { HttpMessage.DiscardedEntity discarded = httpResponse.discardEntityBytes(materializer); discarded.completionStage() .whenComplete((done, ex) -\u0026gt; log.info(\u0026#34;Entity discarded completely!\u0026#34;)); } 现在已经完成了 WebSocket 的处理，让我们看看如何使用 HTML5 WebSockets 设置客户端。 设置 WebSocket 客户端   对于我们的客户，让我们构建一个简单的基于 Web 的聊天应用程序。 4.1 控制器动作 我们需要定义一个呈现索引页面的控制器动作。我们将把它放在控制器类app.controllers.HomeController 中： public Result index(Http.Request request) { String url = routes.HomeController.socket() .webSocketURL(request); return ok(views.html.index.render(url)); } 4.2. 模板页面 现在，让我们转到app/views/ndex.scala.html页面并为接收到的消息添加一个容器和一个用于捕获新消息的表单： \u0026lt;div id=\u0026#34;messageContent\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;F \u0026lt;form\u0026gt; \u0026lt;textarea id=\u0026#34;messageInput\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;button id=\u0026#34;sendButton\u0026#34;\u0026gt;Send\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 我们还需要通过在app/views/index.scala.html页面顶部声明此参数来传递 WebSocket 控制器操作的 URL： @(url: String) 4.3. JavaScript 中的 WebSocket 事件处理程序 现在，我们可以添加 JavaScript 来处理 WebSocket 事件。为简单起见，我们将在app/views/index.scala.html页面的底部添加 JavaScript 函数。 让我们声明事件处理程序： var webSocket; var messageInput; function init() { initWebSocket(); } function initWebSocket() { webSocket = new WebSocket(\u0026#34;@url\u0026#34;); webSocket.onopen = onOpen; webSocket.onclose = onClose; webSocket.onmessage = onMessage; webSocket.onerror = onError; } 让我们自己添加处理程序： function onOpen(evt) { writeToScreen(\u0026#34;CONNECTED\u0026#34;); } function onClose(evt) { writeToScreen(\u0026#34;DISCONNECTED\u0026#34;); } function onError(evt) { writeToScreen(\u0026#34;ERROR: \u0026#34; + JSON.stringify(evt)); } function onMessage(evt) { var receivedData = JSON.parse(evt.data); appendMessageToView(\u0026#34;Server\u0026#34;, receivedData.body); } 然后，为了呈现输出，我们将使用函数appendMessageToView和writeToScreen： function appendMessageToView(title, message) { $(\u0026#34;#messageContent\u0026#34;).append(\u0026#34;\u0026lt;p\u0026gt;\u0026#34; + title + \u0026#34;: \u0026#34; + message + \u0026#34;\u0026lt;/p\u0026gt;\u0026#34;); } function writeToScreen(message) { console.log(\u0026#34;New message: \u0026#34;, message); } 4.4. 运行和测试应用程序 我们已准备好测试应用程序，让我们运行它： cd websockets sbt run 随着应用程序的运行，我们可以通过访问*http://localhost:9000*与服务器聊天： 每次我们输入消息并点击 发送时，服务器都会立即响应来自 JSON 占位符服务的一些lorem ipsum 。 使用 Akka Streams 直接处理 WebSockets   如果我们正在处理来自源的事件流并将其发送到客户端，那么我们可以围绕 Akka 流进行建模。 让我们看看如何在服务器每两秒发送一次消息的示例中使用 Akka 流。 我们将从HomeController中的 WebSocket 操作开始： public WebSocket akkaStreamsSocket() { return WebSocket.Json.accept(request -\u0026gt; { Sink\u0026lt;JsonNode, ?\u0026gt; in = Sink.foreach(System.out::println); MessageDTO messageDTO = new MessageDTO(\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;Title\u0026#34;, \u0026#34;Test Body\u0026#34;); Source\u0026lt;JsonNode, ?\u0026gt; out = Source.tick( Duration.ofSeconds(2), Duration.ofSeconds(2), MessageConverter.messageToJsonNode(messageDTO) ); return Flow.fromSinkAndSource(in, out); }); } Source# tick方法采用三个参数。第一个是处理第一个滴答之前的初始延迟，第二个是连续滴答之间的间隔。我们在上面的代码片段中将这两个值都设置为两秒。第三个参数是应在每次报价时返回的对象。 要查看此操作，我们需要修改index操作中的 URL 并使其指向akkaStreamsSocket端点： String url = routes.HomeController.akkaStreamsSocket().webSocketURL(request); 现在刷新页面，我们将每两秒看到一个新条目： 终止 Actor   在某些时候，我们需要通过用户请求或超时来关闭聊天。 6.1 处理 Actor 终止 我们如何检测 WebSocket 何时关闭？ 当处理 WebSocket 的 actor 终止时，Play 将自动关闭 WebSocket。所以我们可以通过实现Actor#postStop方法来处理这种情况： @Override public void postStop() throws Exception { log.info(\u0026#34;Messenger actor stopped at {}\u0026#34;, OffsetDateTime.now() .format(DateTimeFormatter.ISO_OFFSET_DATE_TIME)); } 6.2. 手动终止 Actor 此外，如果我们必须停止演员，我们可以向演员发送PoisonPill。在我们的示例应用程序中，我们应该能够处理“停止”请求。 让我们看看如何在 onSendMessage方法中做到这一点： private void onSendMessage(JsonNode jsonNode) { RequestDTO requestDTO = MessageConverter.jsonNodeToRequest(jsonNode); String message = requestDTO.getMessage().toLowerCase(); if(\u0026#34;stop\u0026#34;.equals(message)) { MessageDTO messageDTO = createMessageDTO(\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;Stop\u0026#34;, \u0026#34;Stopping actor\u0026#34;); out.tell(MessageConverter.messageToJsonNode(messageDTO), getSelf()); self().tell(PoisonPill.getInstance(), getSelf()); } else { log.info(\u0026#34;Actor received. {}\u0026#34;, requestDTO); processMessage(requestDTO); } } 当我们收到一条消息时，我们会检查它是否是一个停止请求。如果是，我们发送 PoisonPill。否则，我们处理请求。 配置选项   我们可以根据如何处理 WebSocket 来配置几个选项。让我们看几个。 7.1 WebSocket 帧长度 WebSocket 通信涉及数据帧的交换。 WebSocket 帧长度是可配置的。我们可以根据应用要求调整帧长度。 **配置较短的帧长度可能有助于减少使用长数据帧的拒绝服务攻击。**我们可以通过在 application.conf 中指定最大长度来更改应用程序的帧长度： play.server.websocket.frame.maxLength = 64k 我们还可以通过将最大长度指定为命令行参数来设置此配置选项： sbt -Dwebsocket.frame.maxLength=64k run 7.2. 连接空闲超时 默认情况下，我们用来处理 WebSocket 的actor在一分钟后终止。**这是因为运行我们的应用程序的 Play 服务器的默认空闲超时时间为 60 秒。**这意味着所有在 60 秒内未收到请求的连接都会自动关闭。 我们可以通过配置选项来改变它。让我们转到我们的application.conf并将服务器更改为没有空闲超时： play.server.http.idleTimeout = \u0026#34;infinite\u0026#34; 或者我们可以将选项作为命令行参数传入： sbt -Dhttp.idleTimeout=infinite run 我们也可以通过 在 build.sbt中指定**devSettings来配置它。 build.sbt中指定的配置选项仅在开发中使用，它们将在生产中被忽略： PlayKeys.devSettings += \u0026#34;play.server.http.idleTimeout\u0026#34; -\u0026gt; \u0026#34;infinite\u0026#34; 如果我们重新运行应用程序，actor 不会终止。 我们可以将值更改为秒： PlayKeys.devSettings += \u0026#34;play.server.http.idleTimeout\u0026#34; -\u0026gt; \u0026#34;120 s\u0026#34; 我们可以在 Play Framework 文档中找到有关可用配置选项的更多信息。 \u0026quot; ","permalink":"http://itcodingman.github.io/akka_play_websockets/","tags":["Akka","Play","WebSockets"],"title":"带有 Play 框架和 Akka 的 WebSockets"},{"categories":["Reactive"],"contents":" 概述   在本教程中，借助 Akka 的Actor和Stream模型，我们将学习如何设置 Akka 以创建提供基本 CRUD 操作的 HTTP API。 2.Maven依赖 首先，让我们看一下开始使用 Akka HTTP 所需的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-http_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;10.0.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-stream_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-http-jackson_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;10.0.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-http-testkit_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;10.0.11\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 当然，我们可以在Maven Central上找到这些 Akka 库的最新版本。 创建一个Actor   例如，我们将构建一个允许我们管理用户资源的 HTTP API。API 将支持两种操作：  创建新用户 加载现有用户  在我们提供 HTTP API 之前，我们需要实现一个提供我们需要的操作的 actor： class UserActor extends AbstractActor { private UserService userService = new UserService(); static Props props() { return Props.create(UserActor.class); } @Override public Receive createReceive() { return receiveBuilder() .match(CreateUserMessage.class, handleCreateUser()) .match(GetUserMessage.class, handleGetUser()) .build(); } private FI.UnitApply\u0026lt;CreateUserMessage\u0026gt; handleCreateUser() { return createUserMessage -\u0026gt; { userService.createUser(createUserMessage.getUser()); sender() .tell(new ActionPerformed( String.format(\u0026#34;User %s created.\u0026#34;, createUserMessage.getUser().getName())), getSelf()); }; } private FI.UnitApply\u0026lt;GetUserMessage\u0026gt; handleGetUser() { return getUserMessage -\u0026gt; { sender().tell(userService.getUser(getUserMessage.getUserId()), getSelf()); }; } } 基本上，我们正在扩展AbstractActor类并实现它的*createReceive()*方法。 在*createReceive()*中，我们将传入消息类型映射到处理相应类型消息的方法。 消息类型是简单的可序列化容器类，其中包含一些描述特定操作的字段。GetUserMessage并具有单个字段userId 来标识要加载的用户。CreateUserMessage包含一个User对象，其中包含我们创建新用户所需的用户数据。 稍后，我们将看到如何将传入的 HTTP 请求转换为这些消息。 最终，我们将所有消息委托给一个UserService实例，该实例提供了管理持久用户对象所需的业务逻辑。 另外，请注意 *props()方法。**虽然props()方法对于扩展*AbstractActor不是必需的，但稍后在创建ActorSystem时会派上用场 。 有关演员的更深入讨论，请查看我们对 Akka Actors 的介绍。 定义 HTTP 路由   有了一个为我们做实际工作的参与者，我们剩下要做的就是提供一个 HTTP API，将传入的 HTTP 请求委托给我们的参与者。 Akka 使用路由的概念来描述 HTTP API。对于每个操作，我们都需要一条路线。 为了创建一个 HTTP 服务器，我们扩展了框架类HttpApp并实现了routes方法： class UserServer extends HttpApp { private final ActorRef userActor; Timeout timeout = new Timeout(Duration.create(5, TimeUnit.SECONDS)); UserServer(ActorRef userActor) { this.userActor = userActor; } @Override public Route routes() { return path(\u0026#34;users\u0026#34;, this::postUser) .orElse(path(segment(\u0026#34;users\u0026#34;).slash(longSegment()), id -\u0026gt; route(getUser(id)))); } private Route getUser(Long id) { return get(() -\u0026gt; { CompletionStage\u0026lt;Optional\u0026lt;User\u0026gt;\u0026gt; user = PatternsCS.ask(userActor, new GetUserMessage(id), timeout) .thenApply(obj -\u0026gt; (Optional\u0026lt;User\u0026gt;) obj); return onSuccess(() -\u0026gt; user, performed -\u0026gt; { if (performed.isPresent()) return complete(StatusCodes.OK, performed.get(), Jackson.marshaller()); else return complete(StatusCodes.NOT_FOUND); }); }); } private Route postUser() { return route(post(() -\u0026gt; entity(Jackson.unmarshaller(User.class), user -\u0026gt; { CompletionStage\u0026lt;ActionPerformed\u0026gt; userCreated = PatternsCS.ask(userActor, new CreateUserMessage(user), timeout) .thenApply(obj -\u0026gt; (ActionPerformed) obj); return onSuccess(() -\u0026gt; userCreated, performed -\u0026gt; { return complete(StatusCodes.CREATED, performed, Jackson.marshaller()); }); }))); } } 现在，这里有相当多的样板，但请注意，我们遵循与之前映射操作相同的模式**，这次是路由。**让我们分解一下。 在getUser()中，我们只需将传入的用户 ID 包装在GetUserMessage类型的消息中，然后将该消息转发给我们的userActor。 一旦参与者处理完消息，就会调用onSuccess处理程序，在该处理程序中，我们通过发送具有特定 HTTP 状态和特定 JSON 正文的响应来*完成HTTP 请求。*我们使用Jackson marshaller 将 actor 给出的答案序列化为 JSON 字符串。 在postUser()中，我们做的事情有点不同，因为我们期望 HTTP 请求中有一个 JSON 正文。我们使用entity()方法将传入的 JSON 主体映射到User对象中，然后将其包装到CreateUserMessage中并将其传递给我们的actor。同样，我们使用 Jackson 在 Java 和 JSON 之间进行映射，反之亦然。 由于HttpApp期望我们提供单个*Route对象，因此我们在routes方法中将两个路由合并为一个。**在这里，我们使用path*指令最终提供我们的 API 应该可用的 URL 路径。 我们将postUser()提供的路由绑定到路径 /users。如果传入的请求不是 POST 请求，Akka 将自动进入orElse分支并期望路径为*/users/*并且 HTTP 方法为 GET。 如果 HTTP 方法是 GET，请求将被转发到getUser() 路由。如果用户不存在，Akka 将返回 HTTP 状态 404（未找到）。如果方法既不是 POST 也不是 GET，Akka 将返回 HTTP 状态 405（不允许方法）。 有关如何使用 Akka 定义 HTTP 路由的更多信息，请查看Akka 文档。 启动服务器   一旦我们像上面那样创建了一个HttpApp实现，我们可以用几行代码启动我们的 HTTP 服务器： public static void main(String[] args) throws Exception { ActorSystem system = ActorSystem.create(\u0026#34;userServer\u0026#34;); ActorRef userActor = system.actorOf(UserActor.props(), \u0026#34;userActor\u0026#34;); UserServer server = new UserServer(userActor); server.startServer(\u0026#34;localhost\u0026#34;, 8080, system); } 我们只需创建一个具有UserActor类型的单个 Actor 的*ActorSystem并在localhost*上启动服务器。** \u0026quot; ","permalink":"http://itcodingman.github.io/akka_http/","tags":["Akka"],"title":"Akka HTTP 简介"},{"categories":["Reactive"],"contents":"1. 简介 Akka是一个开源库，可通过利用 Actor 模型帮助使用 Java 或 Scala 轻松开发并发和分布式应用程序。 在本教程中，我们将介绍基本功能，例如定义参与者、他们如何通信以及我们如何杀死他们。在最后的笔记中，我们还将记录使用 Akka 时的一些最佳实践。 2. Actor模型 Actor 模型对计算机科学界来说并不陌生。它由 Carl Eddie Hewitt 于 1973 年首次引入，作为处理并发计算的理论模型。 当软件行业开始意识到实现并发和分布式应用程序的陷阱时，它开始显示出它的实际适用性。 **一个actor代表一个独立的计算单元。**一些重要的特征是：  Actor 封装了它的状态和部分应用程序逻辑 参与者仅通过异步消息进行交互，从不通过直接方法调用 每个参与者都有一个唯一的地址和一个邮箱，其他参与者可以在其中传递消息 Actor 将按顺序处理邮箱中的所有消息（邮箱的默认实现是 FIFO 队列） 演员系统以树状层次结构组织 演员可以创建其他演员，可以向任何其他演员发送消息并停止自己或已创建任何演员  2.1 优点 开发并发应用程序很困难，因为我们需要处理同步、锁和共享内存。通过使用 Akka Actor，我们可以轻松编写异步代码，而无需锁和同步。 使用消息而不是方法调用的优点之一是发送者线程在向另一个参与者发送消息时不会阻塞以等待返回值。接收参与者将通过向发送者发送回复消息来响应结果。 使用消息的另一大好处是我们不必担心多线程环境中的同步问题。这是因为所有消息都是按顺序处理的。 Akka actor 模型的另一个优点是错误处理。通过在层次结构中组织参与者，每个参与者都可以将失败通知其父级，因此它可以采取相应的行动。父actor可以决定停止或重新启动子actor。 3. 设置 为了利用 Akka actor，我们需要从Maven Central添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. 创建一个Actor 如前所述，参与者是在层次系统中定义的。共享一个公共配置的所有参与者都将由一个ActorSystem 定义。 现在，我们将简单地定义一个具有默认配置和自定义名称的ActorSystem ： ActorSystem system = ActorSystem.create(\u0026#34;test-system\u0026#34;); 即使我们还没有创建任何演员，系统已经包含 3 个主要演员：  具有地址“/”的根监护actor，其名称表示actor系统层次结构的根 具有地址“/user”的用户监护人actor。这将是我们定义的所有actor的父级 具有地址“/system”的系统守护者actor。这将是 Akka 系统内部定义的所有参与者的父级  任何 Akka Actor 都将扩展AbstractActor抽象类并实现*createReceive()*方法来处理来自其他 Actor 的传入消息： public class MyActor extends AbstractActor { public Receive createReceive() { return receiveBuilder().build(); } } **这是我们可以创建的最基本的actor。**它可以接收来自其他参与者的消息并将丢弃它们，因为在*ReceiveBuilder 中没有定义匹配的消息模式。*我们将在本文后面讨论消息模式匹配。 现在我们已经创建了我们的第一个actor，我们应该将它包含在ActorSystem中： ActorRef readingActorRef = system.actorOf(Props.create(MyActor.class), \u0026#34;my-actor\u0026#34;); 4.1 actor配置 ** Props类包含actor配置。**我们可以配置诸如调度程序、邮箱或部署配置之类的东西。此类是不可变的，因此是线程安全的，因此可以在创建新参与者时共享它。 强烈推荐并认为最佳实践是在 actor 对象中定义工厂方法来处理Props对象的创建。 举例来说，让我们定义一个将进行一些文本处理的actor。Actor 将收到一个String对象，它将在该对象上进行处理： public class ReadingActor extends AbstractActor { private String text; public static Props props(String text) { return Props.create(ReadingActor.class, text); } // ... } 现在，要创建这种类型的actor的实例，我们只需使用props()工厂方法将String参数传递给构造函数： ActorRef readingActorRef = system.actorOf( ReadingActor.props(TEXT), \u0026#34;readingActor\u0026#34;); 现在我们知道了如何定义一个actor，让我们看看它们是如何在actor系统中进行通信的。 5. Actor消息 为了相互交互，参与者可以发送和接收来自系统中任何其他参与者的消息。这些消息可以是任何类型的对象，条件是它是不可变的。 **在 Actor 类中定义消息是最佳实践。**这有助于编写易于理解的代码，并且知道参与者可以处理哪些消息。 5.1 发送消息 在 Akka Actor 系统内部，消息使用以下方法发送：  tell（） ask（） forward（）  **当我们想要发送消息但不期望响应时，我们可以使用*tell()*方法。**从性能的角度来看，这是最有效的方法： readingActorRef.tell(new ReadingActor.ReadLines(), ActorRef.noSender()); 第一个参数代表我们发送给actor地址readingActorRef的消息。 第二个参数指定发件人是谁。当接收消息的参与者需要向发送者以外的参与者（例如发送参与者的父节点）发送响应时，这很有用。 通常，我们可以将第二个参数设置为null或ActorRef.noSender()，因为我们不期望回复。*当我们需要一个演员的回应时，我们可以使用*ask()方法： CompletableFuture\u0026lt;Object\u0026gt; future = ask(wordCounterActorRef, new WordCounterActor.CountWords(line), 1000).toCompletableFuture(); 当请求参与者响应时，会返回一个CompletionStage对象，因此处理保持非阻塞状态。 我们必须注意的一个非常重要的事实是在将响应的参与者内部进行错误处理。要返回一个包含异常的Future对象，我们必须向发送者 actor 发送一条Status.Failure消息。 当参与者在处理消息时抛出异常并且*ask()*调用将超时并且在日志中不会看到对异常的引用时，这不会自动完成： @Override public Receive createReceive() { return receiveBuilder() .match(CountWords.class, r -\u0026gt; { try { int numberOfWords = countWordsFromLine(r.line); getSender().tell(numberOfWords, getSelf()); } catch (Exception ex) { getSender().tell( new akka.actor.Status.Failure(ex), getSelf()); throw ex; } }).build(); } 我们还有类似于*tell()的forward()*方法。不同之处在于发送消息时保留了消息的原始发送者，因此转发消息的actor仅充当中间actor： printerActorRef.forward( new PrinterActor.PrintFinalResult(totalNumberOfWords), getContext()); 5.2. 接收消息 *每个参与者都将实现*createReceive()方法，该方法处理所有传入消息。*receiveBuilder()*就像一个 switch 语句，试图将接收到的消息与定义的消息类型匹配： public Receive createReceive() { return receiveBuilder().matchEquals(\u0026#34;printit\u0026#34;, p -\u0026gt; { System.out.println(\u0026#34;The address of this actor is: \u0026#34; + getSelf()); }).build(); } 收到消息后，会将消息放入 FIFO 队列，因此消息按顺序处理。 6. 杀死Actor 当我们使用完一个 actor 后，我们可以通过从ActorRefFactory接口调用***stop()***方法来停止它： system.stop(myActorRef); 我们可以使用这个方法来终止任何子actor或actor本身。重要的是要注意停止是异步完成的，并且当前消息处理将在actor终止之前完成。演员邮箱将不再接受传入的消息。 通过停止父actor，我们还将向所有由它生成的子actor发送终止信号。 当我们不再需要actor系统时，我们可以终止它以释放所有资源并防止任何内存泄漏： Future\u0026lt;Terminated\u0026gt; terminateResponse = system.terminate(); 这将停止系统监护参与者，因此此 Akka 系统中定义的所有参与者。 我们还可以向我们想要杀死的任何参与者发送PoisonPill消息： myActorRef.tell(PoisonPill.getInstance(), ActorRef.noSender()); PoisonPill消息将像任何其他消息一样被Actor 接收并放入队列中。Actor 将处理所有消息，直到到达PoisonPill one。只有这样，参与者才会开始终止过程。 另一个用于杀死演员的特殊消息是Kill消息。与PoisonPill 不同， actor在处理此消息时会抛出ActorKilledException ： myActorRef.tell(Kill.getInstance(), ActorRef.noSender()); \u0026quot; ","permalink":"http://itcodingman.github.io/akka_actors_java/","tags":["Akka"],"title":"Java 中的 Akka Actor 简介"},{"categories":["Programming"],"contents":" 简介   在本文中，我们将介绍 Java Ahead of Time (AOT) 编译器，该编译器在JEP-295中进行了描述，并在 Java 9 中作为实验性特性添加。 首先，我们将了解 AOT 是什么，其次，我们将看一个简单的示例。第三，我们将看到 AOT 的一些限制，最后，我们将讨论一些可能的用例。 什么是提前编译？   AOT 编译是提高 Java 程序性能，尤其是 JVM 启动时间的一种方法。JVM 执行 Java 字节码并将经常执行的代码编译为本机代码。这称为即时 (JIT) 编译。JVM 根据执行期间收集的分析信息决定要 JIT 编译哪些代码。 虽然这种技术使 JVM 能够生成高度优化的代码并提高峰值性能，但启动时间可能不是最佳的，因为执行的代码尚未 JIT 编译。AOT 旨在改善这个所谓的预热期。用于 AOT 的编译器是 Graal。 在本文中，我们不会详细介绍 JIT 和 Graal。请参阅我们的其他文章，了解Java 9 和 10 的性能改进概述 ，以及 对 Graal JIT 编译器的深入了解。 例子   对于这个例子，我们将使用一个非常简单的类，编译它，然后看看如何使用生成的库。 3.1 AOT 编译 让我们快速浏览一下我们的示例类： public class JaotCompilation { public static void main(String[] argv) { System.out.println(message()); } public static String message() { return \u0026#34;The JAOT compiler says \u0026#39;Hello\u0026#39;\u0026#34;; } } 在我们可以使用 AOT 编译器之前，我们需要使用 Java 编译器编译该类： javac JaotCompilation.java 然后我们将生成的 JaotCompilation.class传递 给 AOT 编译器，它与标准 Java 编译器位于同一目录中： jaotc --output jaotCompilation.so JaotCompilation.class 这会在当前目录中生成库 jaotCompilation.so 。 3.2. 运行程序 然后我们可以执行程序： java -XX:AOTLibrary=./jaotCompilation.so JaotCompilation 参数*-XX:AOTLibrary* 接受库的相对或完整路径。或者，我们可以将库复制到 Java 主目录中的lib文件夹中，并且只传递库的名称。 3.3. 验证库是否被调用和使用 通过添加-XX:+PrintAOT作为 JVM 参数，我们可以看到该库确实已加载： java -XX:+PrintAOT -XX:AOTLibrary=./jaotCompilation.so JaotCompilation 输出将如下所示： 77 1 loaded ./jaotCompilation.so aot library 但是，这仅告诉我们库已加载，而不是实际使用。通过传递参数*-verbose*，我们可以看到库中的方法确实被调用了： java -XX:AOTLibrary=./jaotCompilation.so -verbose -XX:+PrintAOT JaotCompilation 输出将包含以下行： 11 1 loaded ./jaotCompilation.so aot library 116 1 aot[ 1] jaotc.JaotCompilation.\u0026lt;init\u0026gt;()V 116 2 aot[ 1] jaotc.JaotCompilation.message()Ljava/lang/String; 116 3 aot[ 1] jaotc.JaotCompilation.main([Ljava/lang/String;)V The JAOT compiler says \u0026#39;Hello\u0026#39; AOT 编译库包含一个类指纹，它必须与.class*文件的指纹匹配。* 让我们更改JaotCompilation.java类中的代码以返回不同的消息： public static String message() { return \u0026#34;The JAOT compiler says \u0026#39;Good morning\u0026#39;\u0026#34;; } 如果我们在没有 AOT 编译修改后的类的情况下执行程序： java -XX:AOTLibrary=./jaotCompilation.so -verbose -XX:+PrintAOT JaotCompilation 然后输出将仅包含： 11 1 loaded ./jaotCompilation.so aot library The JAOT compiler says \u0026#39;Good morning\u0026#39; **我们可以看到库中的方法不会被调用，因为类的字节码已经改变。**这背后的想法是，无论是否加载了 AOT 编译库，程序总是会产生相同的结果。 更多 AOT 和 JVM 参数   4.1 Java 模块的 AOT 编译 也可以 AOT 编译模块： jaotc --output javaBase.so --module java.base 生成的库javaBase.so大小约为 320 MB，加载需要一些时间。可以通过选择要 AOT 编译的包和类来减小大小。 我们将在下面介绍如何做到这一点，但是，我们不会深入研究所有细节。 4.2. 使用编译命令进行选择性编译 **为了防止 Java 模块的 AOT 编译库变得太大，我们可以添加编译命令来限制 AOT 编译的范围。**这些命令需要在一个文本文件中——在我们的示例中，我们将使用文件 complileCommands.txt： compileOnly java.lang.* 然后，我们将其添加到编译命令中： jaotc --output javaBaseLang.so --module java.base --compile-commands compileCommands.txt 生成的库将仅包含java.lang 包中的 AOT 编译类。 为了获得真正的性能改进，我们需要找出在 JVM 预热期间调用了哪些类。 这可以通过添加几个 JVM 参数来实现： java -XX:+UnlockDiagnosticVMOptions -XX:+LogTouchedMethods -XX:+PrintTouchedMethodsAtExit JaotCompilation 在本文中，我们不会深入研究这种技术。 4.3. 单个类的 AOT 编译 我们可以使用参数–class-name编译单个类： jaotc --output javaBaseString.so --class-name java.lang.String 生成的库将仅包含类String。 4.4. 为分层编译 默认情况下，将始终使用 AOT 编译的代码，并且库中包含的类不会发生 JIT 编译。如果我们想在库中包含分析信息，我们可以添加参数 compile-for-tiered： jaotc --output jaotCompilation.so --compile-for-tiered JaotCompilation.class 库中的预编译代码将一直使用，直到字节码符合 JIT 编译条件。 AOT 编译的可能用例   AOT 的一个用例是短运行程序，它在任何 JIT 编译发生之前完成执行。 另一个用例是嵌入式环境，其中 JIT 是不可能的。 此时，我们还需要注意的是，AOT编译库只能从具有相同字节码的Java类中加载，因此无法通过JNI加载。 AOT 和亚马逊 Lambda   AOT 编译代码的一个可能用例是短寿命的 lambda 函数，其中短启动时间很重要。在本节中，我们将了解如何在 AWS Lambda 上运行 AOT 编译的 Java 代码。 **使用 AWS Lambda 进行 AOT 编译需要在与 AWS 上使用的操作系统兼容的操作系统上构建库。**在撰写本文时，这是Amazon Linux 2。 此外，Java 版本需要匹配。AWS 提供了Amazon Corretto Java 11 JVM。为了有一个环境来编译我们的库，我们将在 Docker 中安装Amazon Linux 2和Amazon Corretto 。 我们不会讨论使用 Docker 和 AWS Lambda 的所有细节，而只会概述最重要的步骤。有关如何使用 Docker 的更多信息，请参阅此处的官方文档。 有关使用 Java 创建 Lambda 函数的更多详细信息，您可以查看我们的文章AWS Lambda With Java。 6.1 我们的开发环境的配置 首先，我们需要为Amazon Linux 2拉取 Docker 映像并安装Amazon Corretto： # download Amazon Linux  docker pull amazonlinux # inside the Docker container, install Amazon Corretto yum install java-11-amazon-corretto # some additional libraries needed for jaotc yum install binutils.x86_64 6.2. 编译类和库 在我们的 Docker 容器中，我们执行以下命令： # create folder aot mkdir aot cd aot mkdir jaotc cd jaotc 文件夹的名称只是一个示例，当然可以是任何其他名称。 package jaotc; public class JaotCompilation { public static int message(int input) { return input * 2; } } 下一步是编译类和库： javac JaotCompilation.java cd .. jaotc -J-XX:+UseSerialGC --output jaotCompilation.so jaotc/JaotCompilation.class 在这里，使用与 AWS 上相同的垃圾收集器很重要。如果我们的库无法在 AWS Lambda 上加载，我们可能希望使用以下命令检查实际使用的垃圾收集器： java -XX:+PrintCommandLineFlags -version 现在，我们可以创建一个包含我们的库和类文件的 zip 文件： zip -r jaot.zip jaotCompilation.so jaotc/ 6.3. 配置 AWS Lambda 最后一步是登录 AWS Lamda 控制台，上传 zip 文件并使用以下参数配置 Lambda：  运行时：Java 11 处理程序：jaotc.JaotCompilation::message  此外，我们需要创建一个名为 JAVA_TOOL_OPTIONS 的环境变量并将其值设置为： -XX:+UnlockExperimentalVMOptions -XX:+PrintAOT -XX:AOTLibrary=./jaotCompilation.so 这个变量允许我们将参数传递给 JVM。 最后一步是为我们的 Lambda 配置输入。默认是 JSON 输入，不能传递给我们的函数，因此我们需要将其设置为包含整数的字符串，例如“1”。 最后，我们可以执行我们的 Lambda 函数，并且应该在日志中看到我们的 AOT 编译库已加载： 57 1 loaded ./jaotCompilation.so aot library \u0026quot; ","permalink":"http://itcodingman.github.io/ahead_of_time_compilation/","tags":[],"title":"提前编译 (AoT)"},{"categories":["XML"],"contents":"1. 概述 本教程介绍了Aegis数据绑定，这是一个可以在 Java 对象和 XML 模式描述的 XML 文档之间映射的子系统。Aegis 允许对映射过程进行详细控制，同时将编程工作量降至最低。 Aegis 是Apache CXF的一部分，但不限于仅在此框架内使用。相反，这种数据绑定机制可以在任何地方使用，因此在本教程中，我们将重点关注它作为独立子系统的使用。 2. Maven依赖 激活 Aegis 数据绑定所需的唯一依赖项是： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-databinding-aegis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到此工件的最新版本。 3. 类型定义 本节介绍用于说明 Aegis 的三种类型的定义。 3.1。课程 这是我们示例中最简单的类，定义为： public class Course { private int id; private String name; private String instructor; private Date enrolmentDate; // standard getters and setters } 3.2. CourseRepo CourseRepo是我们模型中的顶级类型。我们将它定义为一个接口而不是一个类，以演示编组 Java 接口是多么容易，这在没有自定义适配器的 JAXB 中是不可能的： public interface CourseRepo { String getGreeting(); void setGreeting(String greeting); Map\u0026lt;Integer, Course\u0026gt; getCourses(); void setCourses(Map\u0026lt;Integer, Course\u0026gt; courses); void addCourse(Course course); } 请注意，我们使用返回类型Map声明getCourses方法。这是为了表达 Aegis 相对于 JAXB 的另一个优势。后者无法在没有自定义适配器的情况下编组地图，而前者可以。 3.3. CourseRepoImpl 此类提供CourseRepo接口的实现： public class CourseRepoImpl implements CourseRepo { private String greeting; private Map\u0026lt;Integer, Course\u0026gt; courses = new HashMap\u0026lt;\u0026gt;(); // standard getters and setters  @Override public void addCourse(Course course) { courses.put(course.getId(), course); } } 4. 自定义数据绑定 为了使自定义生效，XML 映射文件必须存在于类路径中。要求将这些文件放在一个目录中，该目录的结构对应于相关 Java 类型的包层次结构。 例如，如果一个完全限定的名称类名为package.ClassName，则其关联的映射文件必须位于类路径上的package/ClassName子目录中。映射文件的名称必须与附加了*.aegis.xml*后缀的关联 Java 类型相同。 4.1 CourseRepo映射 CourseRepo接口属于com.codingman.cxf.aegis包，所以其对应的映射文件命名为CourseRepo.aegis.xml，放到classpath的com/codingman/cxf/aegis目录下。 在CourseRepo映射文件中，我们更改与**CourseRepo接口关联的 XML 元素的名称和命名空间，以及它的greeting属性的样式： \u0026lt;mappings xmlns:ns=\u0026#34;http://courserepo.codingman.com\u0026#34;\u0026gt; \u0026lt;mapping name=\u0026#34;ns:Codingman\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;greeting\u0026#34; style=\u0026#34;attribute\u0026#34;/\u0026gt; \u0026lt;/mapping\u0026gt; \u0026lt;/mappings\u0026gt; 4.2. Course映射 与CourseRepo类型类似， Course类的映射文件名为Course.aegis.xml，也位于com/codingman/cxf/aegis目录下。 在这个映射文件中，我们指示 Aegis 在编组时忽略Course类的instructor属性，以便其值在从输出 XML 文档重新创建的对象中不可用： \u0026lt;mappings\u0026gt; \u0026lt;mapping\u0026gt; \u0026lt;property name=\u0026#34;instructor\u0026#34; ignore=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/mapping\u0026gt; \u0026lt;/mappings\u0026gt; Aegis 的主页是我们可以找到更多自定义选项的地方。 5. 测试 本节是设置和执行测试用例的分步指南，说明 Aegis 数据绑定的使用。 为了方便测试过程，我们在测试类中声明了两个字段： public class CodingmanTest { private AegisContext context; private String fileName = \u0026#34;codingman.xml\u0026#34;; // other methods } 这些字段已在此处定义以供此类的其他方法使用。 5.1 AegisContext初始化 首先，必须创建一个AegisContext对象： context = new AegisContext(); 然后配置并初始化该AegisContext实例。以下是我们为上下文设置根类的方法： Set\u0026lt;Type\u0026gt; rootClasses = new HashSet\u0026lt;Type\u0026gt;(); rootClasses.add(CourseRepo.class); context.setRootClasses(rootClasses); Aegis 为Set对象中的每个类型创建一个 XML 映射元素。在本教程中，我们仅将 CourseRepo设置为根类型。 现在，让我们为上下文设置实现映射，以指定CourseRepo接口的代理类： Map\u0026lt;Class\u0026lt;?\u0026gt;, String\u0026gt; beanImplementationMap = new HashMap\u0026lt;\u0026gt;(); beanImplementationMap.put(CourseRepoImpl.class, \u0026#34;CourseRepo\u0026#34;); context.setBeanImplementationMap(beanImplementationMap); Aegis 上下文的最后一个配置是告诉它在相应的 XML 文档中设置xsi:type 属性。此属性携带相关 Java 对象的实际类型名称，除非被映射文件覆盖： context.setWriteXsiTypes(true); 我们的AegisContext实例现在可以初始化了： context.initialize(); 为了保持代码干净，我们将本小节中的所有代码片段收集到一个辅助方法中： private void initializeContext() { // ... } 5.2. 简单的数据设置 由于本教程的简单性，我们直接在内存中生成示例数据，而不是依赖于持久解决方案。让我们使用以下设置逻辑填充课程存储库： private CourseRepoImpl initCourseRepo() { Course restCourse = new Course(); restCourse.setId(1); restCourse.setName(\u0026#34;REST with Spring\u0026#34;); restCourse.setInstructor(\u0026#34;Eugen\u0026#34;); restCourse.setEnrolmentDate(new Date(1234567890000L)); Course securityCourse = new Course(); securityCourse.setId(2); securityCourse.setName(\u0026#34;Learn Spring Security\u0026#34;); securityCourse.setInstructor(\u0026#34;Eugen\u0026#34;); securityCourse.setEnrolmentDate(new Date(1456789000000L)); CourseRepoImpl courseRepo = new CourseRepoImpl(); courseRepo.setGreeting(\u0026#34;Welcome to Beldung!\u0026#34;); courseRepo.addCourse(restCourse); courseRepo.addCourse(securityCourse); return courseRepo; } 5.3. 绑定 Java 对象和 XML 元素 将 Java 对象编组为 XML 元素需要采取的步骤通过以下辅助方法进行说明： private void marshalCourseRepo(CourseRepo courseRepo) throws Exception { AegisWriter\u0026lt;XMLStreamWriter\u0026gt; writer = context.createXMLStreamWriter(); AegisType aegisType = context.getTypeMapping().getType(CourseRepo.class); XMLStreamWriter xmlWriter = XMLOutputFactory.newInstance() .createXMLStreamWriter(new FileOutputStream(fileName)); writer.write(courseRepo, new QName(\u0026#34;http://aegis.cxf.codingman.com\u0026#34;, \u0026#34;codingman\u0026#34;), false, xmlWriter, aegisType); xmlWriter.close(); } 正如我们所见，AegisWriter和AegisType对象必须从AegisContext实例中创建。然后AegisWriter对象将给定的 Java 实例编组到指定的输出。 在这种情况下，这是一个XMLStreamWriter对象，它与以文件系统中**fileName类级字段的值命名的文件相关联。 以下方法将 XML 文档解组为给定类型的 Java 对象： private CourseRepo unmarshalCourseRepo() throws Exception { AegisReader\u0026lt;XMLStreamReader\u0026gt; reader = context.createXMLStreamReader(); XMLStreamReader xmlReader = XMLInputFactory.newInstance() .createXMLStreamReader(new FileInputStream(fileName)); CourseRepo courseRepo = (CourseRepo) reader.read( xmlReader, context.getTypeMapping().getType(CourseRepo.class)); xmlReader.close(); return courseRepo; } 在这里，从AegisContext实例生成一个**AegisReader对象。然后，AegisReader对象根据提供的输入创建一个 Java 对象。在此示例中，该输入是一个XMLStreamReader对象，该对象由我们在上面描述的**marshalCourseRepo方法中生成的文件支持。 5.4. 测试 现在，是时候将前面小节中定义的所有辅助方法组合成一个测试方法了： @Test public void whenMarshalingAndUnmarshalingCourseRepo_thenCorrect() throws Exception { initializeContext(); CourseRepo inputRepo = initCourseRepo(); marshalCourseRepo(inputRepo); CourseRepo outputRepo = unmarshalCourseRepo(); Course restCourse = outputRepo.getCourses().get(1); Course securityCourse = outputRepo.getCourses().get(2); // JUnit assertions } 我们首先创建一个CourseRepo实例，然后将其编组为 XML 文档，最后解组该文档以重新创建原始对象。让我们验证重新创建的对象是否符合我们的预期： assertEquals(\u0026#34;Welcome to Beldung!\u0026#34;, outputRepo.getGreeting()); assertEquals(\u0026#34;REST with Spring\u0026#34;, restCourse.getName()); assertEquals(new Date(1234567890000L), restCourse.getEnrolmentDate()); assertNull(restCourse.getInstructor()); assertEquals(\u0026#34;Learn Spring Security\u0026#34;, securityCourse.getName()); assertEquals(new Date(1456789000000L), securityCourse.getEnrolmentDate()); assertNull(securityCourse.getInstructor()); 很明显，除了讲师属性之外，所有其他属性的值都已恢复，包括值类型为Date的**enrolmentDate属性。这正是我们所期望的，因为我们已指示 Aegis在编组Course对象时忽略讲师属性。 5.5. 输出 XML 文档 为了使 Aegis 映射文件的效果更加明确，我们在下面展示了没有自定义的 XML 文档： \u0026lt;ns1:codingman xmlns:ns1=\u0026#34;http://aegis.cxf.codingman.com\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;ns1:CourseRepo\u0026#34;\u0026gt; \u0026lt;ns1:courses\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;1\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2009-02-14T06:31:30+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;1\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:instructor\u0026gt;Eugen\u0026lt;/ns1:instructor\u0026gt; \u0026lt;ns1:name\u0026gt;REST with Spring\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;2\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2016-03-01T06:36:40+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;2\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:instructor\u0026gt;Eugen\u0026lt;/ns1:instructor\u0026gt; \u0026lt;ns1:name\u0026gt;Learn Spring Security\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;/ns1:courses\u0026gt; \u0026lt;ns1:greeting\u0026gt;Welcome to Beldung!\u0026lt;/ns1:greeting\u0026gt; \u0026lt;/ns1:codingman\u0026gt; 将此与 Aegis 自定义映射运行时的情况进行比较： \u0026lt;ns1:codingman xmlns:ns1=\u0026#34;http://aegis.cxf.codingman.com\u0026#34; xmlns:ns=\u0026#34;http://courserepo.codingman.com\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;ns:Codingman\u0026#34; greeting=\u0026#34;Welcome to Beldung!\u0026#34;\u0026gt; \u0026lt;ns:courses\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;1\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2009-02-14T06:31:30+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;1\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:name\u0026gt;REST with Spring\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;2\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2016-03-01T06:36:40+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;2\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:name\u0026gt;Learn Spring Security\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;/ns:courses\u0026gt; \u0026lt;/ns1:codingman\u0026gt; 运行本节中定义的测试后，您可以在项目主目录中的codingman.xml中找到这个 XML 结构。 您会看到CourseRepo对象对应的 XML 元素的type属性和命名空间会根据我们在CourseRepo.aegis.xml文件中设置的内容发生变化。greeting属性也转化为一个属性，Course对象的instructor属性如预期般消失了。 值得注意的是，默认情况下，Aegis 将基本 Java 类型转换为最匹配的模式类型，例如从Date对象转换为xsd:dateTime 元素，如本教程所示。但是，我们可以通过在相应的映射文件中设置配置来更改该特定绑定。 如果您想了解更多信息，请导航至Aegis 主页。 \u0026quot; ","permalink":"http://itcodingman.github.io/aegis_data_binding_in_apache_cxf/","tags":["Apache CXF"],"title":"Apache CXF Aegis 数据绑定简介"},{"categories":["Java"],"contents":" 概述   启动服务通常很容易。但是，有时我们需要制定一个优雅地关闭一个的计划。 在本教程中，我们将了解 JVM 应用程序可以终止的不同方式。然后，我们将使用 Java API 来管理 JVM 关闭挂钩。请 参阅本文以了解有关在 Java 应用程序中关闭 JVM 的更多信息。 2.JVM关闭 JVM 可以通过两种不同的方式关闭：  受控过程 突然的方式  在以下任一情况下，受控进程会关闭 JVM：  最后一个非守护线程终止。例如，当主线程退出时，JVM 开始其关闭进程 从操作系统发送中断信号。例如，通过按 Ctrl + C 或注销操作系统 从 Java 代码调用 System.exit()  虽然我们都在努力实现优雅的关闭，但有时 JVM 可能会以突然和意外的方式关闭。JVM 在以下情况下突然关闭：  从操作系统发送终止信号。例如，通过发出 kill -9 \u0026lt;jvm_pid\u0026gt; 从 Java 代码调用 Runtime.getRuntime().halt() 主机操作系统意外死机，例如电源故障或操作系统崩溃  关闭挂钩   JVM 允许注册函数在其完成关闭之前运行。这些功能通常是释放资源或其他类似内务任务的好地方。在 JVM 术语中，这些函数称为 s shutdown hooks。 关闭挂钩基本上是已初始化但未启动的线程。当 JVM 开始其关闭过程时，它将以未指定的顺序启动所有已注册的钩子。运行所有挂钩后，JVM 将停止。 3.1。添加挂钩 为了添加关闭钩子，我们可以使用 *Runtime.getRuntime().addShutdownHook()*方法： Thread printingHook = new Thread(() -\u0026gt; System.out.println(\u0026#34;In the middle of a shutdown\u0026#34;)); Runtime.getRuntime().addShutdownHook(printingHook); 在这里，我们只是在 JVM 自行关闭之前将一些内容打印到标准输出。如果我们像下面这样关闭 JVM： \u0026gt; System.exit(129); In the middle of a shutdown 然后我们将看到钩子实际上将消息打印到标准输出。 JVM 负责启动钩子线程。因此，如果给定的钩子已经启动，Java 将抛出异常： Thread longRunningHook = new Thread(() -\u0026gt; { try { Thread.sleep(300); } catch (InterruptedException ignored) {} }); longRunningHook.start(); assertThatThrownBy(() -\u0026gt; Runtime.getRuntime().addShutdownHook(longRunningHook)) .isInstanceOf(IllegalArgumentException.class) .hasMessage(\u0026#34;Hook already running\u0026#34;); 显然，我们也不能多次注册一个钩子： Thread unfortunateHook = new Thread(() -\u0026gt; {}); Runtime.getRuntime().addShutdownHook(unfortunateHook); assertThatThrownBy(() -\u0026gt; Runtime.getRuntime().addShutdownHook(unfortunateHook)) .isInstanceOf(IllegalArgumentException.class) .hasMessage(\u0026#34;Hook previously registered\u0026#34;); 3.2. 拆除挂钩 Java 提供了一个双重 删除方法来在注册后删除特定的关闭挂钩： Thread willNotRun = new Thread(() -\u0026gt; System.out.println(\u0026#34;Won\u0026#39;t run!\u0026#34;)); Runtime.getRuntime().addShutdownHook(willNotRun); assertThat(Runtime.getRuntime().removeShutdownHook(willNotRun)).isTrue(); 当成功删除关闭挂钩时，removeShutdownHook()方法返回 true 。 3.3. 注意事项 **JVM 仅在正常终止的情况下运行关闭挂钩。**因此，当外力突然杀死 JVM 进程时，JVM 将没有机会执行关闭挂钩。此外，从 Java 代码中停止 JVM 也会产生相同的效果： Thread haltedHook = new Thread(() -\u0026gt; System.out.println(\u0026#34;Halted abruptly\u0026#34;)); Runtime.getRuntime().addShutdownHook(haltedHook); Runtime.getRuntime().halt(129); halt方法强制终止当前运行的 JVM 。因此，注册的关闭钩子将没有机会执行。 \u0026quot; ","permalink":"http://itcodingman.github.io/adding_shutdown_hooks_for_jvm_applications/","tags":["JVM"],"title":"为 JVM 应用程序添加关闭挂钩"},{"categories":["Spring Security"],"contents":"1. 概述 Activiti 是一个开源 BPM（业务流程管理）系统。有关介绍，请查看我们的 Java Activiti 指南。 Activiti 和 Spring 框架都提供了自己的身份管理。但是，在集成了这两个项目的应用程序中，我们可能希望将两者组合成一个用户管理流程。 在下文中，我们将探索实现这一目标的两种可能性：一种是通过为 Spring Security 提供 Activiti 支持的用户服务，另一种是通过将 Spring Security 用户源插入到 Activiti 身份管理中。 2. Maven依赖 要在 Spring Boot 项目中设置 Activiti，请查看我们之前的文章。除了*activiti-spring-boot-starter-basic，*我们还需要activiti-spring-boot-starter-security依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.activiti\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activiti-spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 使用 Activiti 进行身份管理 对于这个场景，Activiti 启动器提供了一个 Spring Boot 自动配置类，它使用HTTP 基本身份验证保护所有 REST 端点。 自动配置还创建了IdentityServiceUserDetailsService类的UserDetailsService bean。 该类实现了 Spring 接口UserDetailsService并覆盖了*loadUserByUsername()*方法。此方法检索具有给定id的 Activiti User对象，并使用它来创建 Spring UserDetails对象。 此外，Activiti Group对象对应于一个 Spring 用户角色。 这意味着当我们登录 Spring Security 应用程序时，我们将使用 Activiti 凭据。 3.1 设置 Activiti 用户 首先，让我们使用IdentityService在主*@SpringBootApplication类中定义的InitializingBean*中创建一个用户： @Bean InitializingBean usersAndGroupsInitializer(IdentityService identityService) { return new InitializingBean() { public void afterPropertiesSet() throws Exception { User user = identityService.newUser(\u0026#34;activiti_user\u0026#34;); user.setPassword(\u0026#34;pass\u0026#34;); identityService.saveUser(user); Group group = identityService.newGroup(\u0026#34;user\u0026#34;); group.setName(\u0026#34;ROLE_USER\u0026#34;); group.setType(\u0026#34;USER\u0026#34;); identityService.saveGroup(group); identityService.createMembership(user.getId(), group.getId()); } }; } 您会注意到，由于 Spring Security 将使用它，因此Group对象名称必须采用“ROLE_X”形式。 3.2. Spring 安全配置 如果我们想使用不同的安全配置而不是 HTTP Basic 身份验证，首先我们必须排除自动配置： @SpringBootApplication( exclude = org.activiti.spring.boot.SecurityAutoConfiguration.class) public class ActivitiSpringSecurityApplication { // ... } 然后，我们可以提供我们自己的 Spring Security 配置类，它使用*IdentityServiceUserDetailsService 从 Activiti 数据源中检索用户： @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private IdentityService identityService; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService()); } @Bean public UserDetailsService userDetailsService() { return new IdentityServiceUserDetailsService( this.identityService); } // spring security configuration } 4. 使用 Spring Security 进行身份管理 如果我们已经使用 Spring Security 设置了用户管理，并且我们想将 Activiti 添加到我们的应用程序中，那么我们需要自定义 Activiti 的身份管理。 为此，我们必须扩展两个主要类：UserEntityManagerImpl和GroupEntityManagerImpl，它们处理用户和组。 让我们更详细地看一下其中的每一个。 **4.1 扩展UserEntityManagerImpl ** 让我们创建自己的类来扩展UserEntityManagerImpl类： public class SpringSecurityUserManager extends UserEntityManagerImpl { private JdbcUserDetailsManager userManager; public SpringSecurityUserManager( ProcessEngineConfigurationImpl processEngineConfiguration, UserDataManager userDataManager, JdbcUserDetailsManager userManager) { super(processEngineConfiguration, userDataManager); this.userManager = userManager; } // ... } 此类需要上述形式的构造函数，以及 Spring Security 用户管理器。在我们的例子中，我们使用了数据库支持的UserDetailsManager。 我们要覆盖的主要方法是那些处理用户检索的方法：findById()、 findUserByQueryCriteria()和findGroupsByUser()。 findById()方法使用JdbcUserDetailsManager查找UserDetails对象并将其转换为User对象： @Override public UserEntity findById(String userId) { UserDetails userDetails = userManager.loadUserByUsername(userId); if (userDetails != null) { UserEntityImpl user = new UserEntityImpl(); user.setId(userId); return user; } return null; } 接下来，findGroupsByUser()方法查找用户的所有 Spring Security 权限并返回Group对象列表： public List\u0026lt;Group\u0026gt; findGroupsByUser(String userId) { UserDetails userDetails = userManager.loadUserByUsername(userId); if (userDetails != null) { return userDetails.getAuthorities().stream() .map(a -\u0026gt; { Group g = new GroupEntityImpl(); g.setId(a.getAuthority()); return g; }) .collect(Collectors.toList()); } return null; } findUserByQueryCriteria()方法基于具有多个属性的UserQueryImpl对象，我们将从中提取组 id 和用户 id，因为它们在 Spring Security 中具有对应关系： @Override public List\u0026lt;User\u0026gt; findUserByQueryCriteria( UserQueryImpl query, Page page) { // ... } 此方法遵循与上述类似的原则，通过从UserDetails对象创建User对象。 同样，我们有*findUserCountByQueryCriteria()*方法： public long findUserCountByQueryCriteria( UserQueryImpl query) { return findUserByQueryCriteria(query, null).size(); } *checkPassword()*方法应该总是返回 true，因为密码验证不是由 Activiti 完成的： @Override public Boolean checkPassword(String userId, String password) { return true; } 对于其他方法，例如那些处理更新用户的方法，我们只会抛出一个异常，因为这是由 Spring Security 处理的： public User createNewUser(String userId) { throw new UnsupportedOperationException(\u0026#34;This operation is not supported!\u0026#34;); } 4.2. 扩展GroupEntityManagerImpl SpringSecurityGroupManager类似于用户管理器类，除了它处理用户组的事实： public class SpringSecurityGroupManager extends GroupEntityManagerImpl { private JdbcUserDetailsManager userManager; public SpringSecurityGroupManager(ProcessEngineConfigurationImpl processEngineConfiguration, GroupDataManager groupDataManager) { super(processEngineConfiguration, groupDataManager); } // ... } 这里*要覆盖的主要方法是*findGroupsByUser()方法： @Override public List\u0026lt;Group\u0026gt; findGroupsByUser(String userId) { UserDetails userDetails = userManager.loadUserByUsername(userId); if (userDetails != null) { return userDetails.getAuthorities().stream() .map(a -\u0026gt; { Group g = new GroupEntityImpl(); g.setId(a.getAuthority()); return g; }) .collect(Collectors.toList()); } return null; } 该方法检索 Spring Security 用户的权限并将其转换为Group对象列表。 基于此，我们还可以重写*findGroupByQueryCriteria()和findGroupByQueryCriteriaCount()*方法： @Override public List\u0026lt;Group\u0026gt; findGroupByQueryCriteria(GroupQueryImpl query, Page page) { if (query.getUserId() != null) { return findGroupsByUser(query.getUserId()); } return null; } @Override public long findGroupCountByQueryCriteria(GroupQueryImpl query) { return findGroupByQueryCriteria(query, null).size(); } 可以覆盖更新组的其他方法以引发异常： public Group createNewGroup(String groupId) { throw new UnsupportedOperationException(\u0026#34;This operation is not supported!\u0026#34;); } 4.3. 流程引擎配置 在定义了两个身份管理器类之后，我们需要将它们连接到配置中。 spring 启动器为我们自动配置SpringProcessEngineConfiguration。要修改它，我们可以使用InitializingBean： @Autowired private SpringProcessEngineConfiguration processEngineConfiguration; @Autowired private JdbcUserDetailsManager userManager; @Bean InitializingBean processEngineInitializer() { return new InitializingBean() { public void afterPropertiesSet() throws Exception { processEngineConfiguration.setUserEntityManager( new SpringSecurityUserManager(processEngineConfiguration, new MybatisUserDataManager(processEngineConfiguration), userManager)); processEngineConfiguration.setGroupEntityManager( new SpringSecurityGroupManager(processEngineConfiguration, new MybatisGroupDataManager(processEngineConfiguration))); } }; } 在这里，现有的processEngineConfiguration被修改为使用我们的自定义身份管理器。 如果我们想在Activiti中设置当前用户，可以使用方法： identityService.setAuthenticatedUserId(userId); 请记住，这会设置一个ThreadLocal属性，因此每个线程的值都不同。 \u0026quot; ","permalink":"http://itcodingman.github.io/activiti_spring_security/","tags":["Activiti"],"title":"带有 Spring Security 的 Activiti"},{"categories":["Java","Programming"],"contents":"1. 概述 在我们之前的Activiti with Java介绍文章中，我们看到了ProcessEngine的重要性，并通过框架提供的默认静态 API 创建了一个。 除了默认设置之外，还有其他创建ProcessEngine的方法——我们将在这里探讨。 2. 获取ProcessEngine实例 有两种获取ProcessEngine实例的方法：  使用ProcessEngines类 以编程方式，通过ProcessEngineConfiguration  让我们仔细看看这两种方法的示例。 3. 使用ProcessEngines类获取ProcessEngine 通常，ProcessEngine是使用名为activiti.cfg.xml的 XML 文件配置的，默认创建过程也将使用该文件。 这是此配置的外观的快速示例： \u0026lt;beans xmlns=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;processEngineConfiguration\u0026#34; class= \u0026#34;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34; vasentence you have mentioned and also changed thelue=\u0026#34;jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcDriver\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcUsername\u0026#34; value=\u0026#34;root\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcPassword\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseSchemaUpdate\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 注意这里是如何配置引擎的持久性方面的。 现在，我们可以获得ProcessEngine： ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); **4. 使用ProcessEngineConfiguration获取ProcessEngine ** 超越获取引擎的默认路径——有两种创建ProcessEngineConfiguration的方法：  使用 XML 配置 使用 Java 配置  让我们从 XML 配置开始。 如第 2.1 节所述。– 我们可以以编程方式定义ProcessEngineConfiguration ，并使用该实例构建ProcessEngine ： @Test public void givenXMLConfig_whenCreateDefaultConfiguration_thenGotProcessEngine() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createProcessEngineConfigurationFromResourceDefault(); ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;root\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } createProcessEngineConfigurationFromResourceDefault()方法也会查找activiti.cfg.xml文件，现在我们只需要调用buildProcessEngine() API。 在这种情况下，它查找的默认 bean 名称是processEngineConfiguration。如果我们想更改配置文件名或 bean 名称，我们可以使用其他可用的方法来创建ProcessEngineConfiguration。 让我们看几个例子。 首先，我们将更改配置文件名并要求 API 使用我们的自定义文件： @Test public void givenDifferentNameXMLConfig_whenGetProcessEngineConfig_thenGotResult() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createProcessEngineConfigurationFromResource( \u0026#34;my.activiti.cfg.xml\u0026#34;); ProcessEngine processEngine = processEngineConfiguration .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;codingman\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 现在，让我们也更改 bean 名称： @Test public void givenDifferentBeanNameInXMLConfig_whenGetProcessEngineConfig_thenGotResult() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createProcessEngineConfigurationFromResource( \u0026#34;my.activiti.cfg.xml\u0026#34;, \u0026#34;myProcessEngineConfiguration\u0026#34;); ProcessEngine processEngine = processEngineConfiguration .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;codingman\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 当然，既然配置需要不同的名称，我们需要更改文件名（和 bean 名称）以匹配 - 在运行测试之前。 创建引擎的其他可用选项是createProcessEngineConfigurationFromInputStream(InputStream inputStream)、 createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName)。 如果我们不想使用 XML 配置，我们也可以仅使用 Java 配置进行设置。 我们将使用四个不同的类；每一个都代表不同的环境：  org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration – ProcessEngine以独立的方式使用，由数据库支持 *org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration –*默认情况下，使用 H2 内存数据库。数据库在引擎启动和关闭时创建和删除——因此，这种配置风格可用于测试 *org.activiti.spring.SpringProcessEngineConfiguration –*在 Spring 环境中使用 *org.activiti.engine.impl.cfg.JtaProcessEngineConfiguration –*引擎以独立模式运行，带有 JTA 事务  让我们看几个例子。 这是一个用于创建独立流程引擎配置的 JUnit 测试： @Test public void givenNoXMLConfig_whenCreateProcessEngineConfig_thenCreated() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createStandaloneProcessEngineConfiguration(); ProcessEngine processEngine = processEngineConfiguration .setDatabaseSchemaUpdate(ProcessEngineConfiguration .DB_SCHEMA_UPDATE_TRUE) .setJdbcUrl(\u0026#34;jdbc:h2:mem:my-own-db;DB_CLOSE_DELAY=1000\u0026#34;) .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;sa\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 同样，我们将编写一个 JUnit 测试用例，用于使用内存数据库创建独立流程引擎配置： @Test public void givenNoXMLConfig_whenCreateInMemProcessEngineConfig_thenCreated() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createStandaloneInMemProcessEngineConfiguration(); ProcessEngine processEngine = processEngineConfiguration .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;sa\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 5. 数据库设置 默认情况下，Activiti API 将使用 H2 内存数据库，数据库名称为“activiti”，用户名为“sa”。 如果我们需要使用任何其他数据库，我们必须明确设置——使用两个主要属性。 databaseType – 有效值为h2、mysql、oracle、postgres、mssql、db2。这也可以从数据库配置中找出，但如果自动检测失败，这将很有用。 *databaseSchemaUpdate –*此属性允许我们定义引擎启动或关闭时数据库发生的情况。它可以有以下三个值：  false（默认）– 此选项根据库验证数据库模式的版本。如果它们不匹配，引擎将抛出异常 true – 构建流程引擎配置时，将对数据库执行检查。数据库将相应地创建/更新 create-drop “ - ” - 这将在创建流程引擎时创建数据库模式，并在流程引擎关闭时将其删除。  我们可以将 DB 配置定义为 JDBC 属性： \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34; value=\u0026#34;jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcDriver\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcUsername\u0026#34; value=\u0026#34;sa\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcPassword\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseType\u0026#34; value=\u0026#34;mysql\u0026#34; /\u0026gt; 或者，如果我们使用DataSource： \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.apache.commons.dbcp.BasicDataSource\u0026#34; \u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;com.mysql.jdbc.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/activiti\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;activiti\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;activiti\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;defaultAutoCommit\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseType\u0026#34; value=\u0026#34;mysql\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/activiti_process_engine/","tags":["Activiti"],"title":"Activiti 中的 ProcessEngine 配置"},{"categories":["Java","Programming"],"contents":"1. 概述 在我们之前的文章（基于Java和Spring 的 Activiti API）中，我们看到了如何以编程方式管理进程。如果我们想设置一个演示，连同 Activiti 的 UI，我们有两个 web 应用程序可以让我们在几分钟内完成。 ** activiti-app提供了一个用户界面，用户可以通过它执行任何身份管理和任务管理相关的操作**，创建用户和组。 类似地，** activiti-rest是一个 webapp，它提供 REST API 用于对进程、任务、进程**等执行任何操作。 在本文中，我们将研究如何使用这些 web 应用程序，以及它们提供的功能。 2. 下载 我们可以从Activiti 网站本身下载两个 webapp 的战争文件。 对于 v6.0.0，我们只需下载activiti-6.0.0.zip并解压，war文件可以在activiti-6.0.0/wars目录中找到。 3. 激活 Kickstart 应用程序 我们需要一个有效的Java 运行时和一个Apache Tomcat安装来部署应用程序。任何 Web 容器都可以工作，但 Activiti 主要在 Tomcat 上进行测试。 现在，我们只需要在 Tomcat 上部署war并使用http://localhost:8080/activiti-app访问它。 主页应如下所示： Activiti 3.1 数据库 默认情况下，它使用 H2 内存数据库。如果我们想更改数据库配置，我们可以查看代码并修改activiti-app.properties文件。 完成此操作后，我们需要重新生成 war 文件，这可以通过运行start.sh脚本来完成。这将构建activiti-app以及所需的依赖项。 3.2. 启动应用程序 当我们单击 Kickstart 应用程序时，我们会获得使用流程的选项。我们可以创建/导入进程并从这里运行它们。 让我们创建一个小进程，它有一个User Task，它接收来自用户的消息。进入 Kickstart 应用程序后，要创建流程，请选择流程选项卡，然后单击创建流程： 应用活动创建新模型 流程编辑器将打开，我们可以在其中拖放开始事件、各种类型的任务和结束事件的各种符号来定义流程。 当我们将User Task添加到我们的流程中时，我们需要将其分配给某人。我们可以通过单击此任务选项中的分配并选择受让人来完成。 为简单起见，让我们将任务分配给流程发起者： activiti 应用分配任务 我们还希望此User Task从用户那里获得输入消息。为此，我们需要将带有单个文本字段的表单与此任务相关联。 选择User Task并选择Referenced Form。目前，没有与任务关联的表单，因此单击New Form，并添加所需的详细信息： 活动创建表格 在此之后，它将带我们到表单部分，我们可以在表单中拖放我们想要的各种字段，并为它们设置标签： 活动创建表格 2 请注意，我们勾选了必填项，这意味着如果不输入消息，**用户任务将无法完成。 完成后，我们将保存它并转到“应用程序”选项卡。为了能够运行我们创建的流程，我们需要创建一个 Process App。 在 Process App 中，我们可以添加一个或多个Process Definitions。完成此操作后，我们需要发布此应用程序，以便其他用户可以使用流程： 活动应用发布应用 3.3. 任务应用 在任务应用程序中，有两个选项卡：任务——用于当前运行的任务，进程——用于当前运行的进程。 单击“进程”选项卡中的“启动进程”后，我们将获得可以运行的可用进程列表。从这个列表中，我们将选择我们的进程并单击开始按钮： activiti 应用启动过程 我们的流程只包含一个任务，它是一个用户任务。因此，该进程正在等待用户完成此任务。当我们点击进程正在等待的任务时，我们可以看到我们创建的表单： activiti 给用户输入 如果我们点击Show Diagram，它不仅会显示流程图，还会突出显示已完成的任务和待处理的任务。在我们的例子中，用户任务仍处于未决状态，突出显示： activiti 应用流程图 要完成这个任务，我们可以点击完成按钮n。如前所述，我们需要输入消息，因为我们保持它是强制性的。因此，输入消息后，我们就可以完成任务了。 3.4. 身份管理应用 除了管理流程外，我们还有一个身份管理应用程序，它允许我们添加用户和组。我们还可以为用户定义角色。 4. REST活动 Activiti 为 Activiti Engine 提供了一个 REST API，可以通过将activiti-rest.war文件部署到像 Apache Tomcat 这样的 servlet 容器来安装它。 默认情况下，Activiti Engine 将连接到内存中的 H2 数据库。就像我们在activiti-app中看到的那样，在这里我们可以更改WEB-INF/classes文件夹中db.properties文件中的数据库设置并重新创建 war 文件。 随着应用程序启动并运行，我们可以将这个基本 URL 用于所有请求： http://localhost:8080/activiti-rest/service/ 默认情况下，所有 REST 资源都需要一个有效的 Activiti 用户进行身份验证。每个 REST 调用都应使用基本 HTTP 访问身份验证。 4.1 创建和运行进程 要创建流程，首先，我们需要流程的 BPMN 文件。我们可以创建文件，如我们之前基于Activiti with Java的文章中所述，也可以从 Kickstart App 的 Process 部分下载。 我们需要发出一个 POST 请求以及contentType: multipart/form-data，我们将在其中为我们的新流程上传 BPMN 文件： POST repository/deployments 当我们通过为我们创建的流程传递 BPMN 文件来进行此调用时，它将给出以下输出： { \u0026#34;id\u0026#34;: \u0026#34;40\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;user_msg.bpmn20.xml\u0026#34;, \u0026#34;deploymentTime\u0026#34;: \u0026#34;2017-10-04T17:28:07.963+05:30\u0026#34;, \u0026#34;category\u0026#34;: null, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/repository/deployments/40\u0026#34;, \u0026#34;tenantId\u0026#34;: \u0026#34;\u0026#34; } 现在，如果我们获得所有流程定义，我们可以看到我们列出的流程定义： GET repository/process-definitions 接下来，我们可以使用我们在 BPMN 文件中提到的processKey运行此流程： POST /runtime/process-instances 使用此请求正文： { \u0026#34;processDefinitionKey\u0026#34;:\u0026#34;user_msg\u0026#34; } 响应将是： { \u0026#34;id\u0026#34;: \u0026#34;44\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/runtime/process-instances/44\u0026#34;, \u0026#34;businessKey\u0026#34;: null, \u0026#34;suspended\u0026#34;: false, \u0026#34;ended\u0026#34;: false, \u0026#34;processDefinitionId\u0026#34;: \u0026#34;user_msg:1:43\u0026#34;, \u0026#34;processDefinitionUrl\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/repository/process-definitions/user_msg:1:43\u0026#34;, \u0026#34;processDefinitionKey\u0026#34;: \u0026#34;user_msg\u0026#34;, //other details... } 我们可以使用上一个响应返回的流程实例的id来查看我们正在运行的流程的图表： GET runtime/process-instances/44/diagram 如前所述，该过程正在等待用户任务完成，因此在图中突出显示： 活动休息图 4.2. 完成任务 现在让我们看看我们的待处理任务： GET runtime/tasks 响应将包含待处理任务的列表。目前，只有一项任务——我们的用户任务： { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;49\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/runtime/tasks/49\u0026#34;, \u0026#34;owner\u0026#34;: null, \u0026#34;assignee\u0026#34;: \u0026#34;$INITIATOR\u0026#34;, \u0026#34;delegationState\u0026#34;: null, \u0026#34;name\u0026#34;: \u0026#34;User Input Message\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;User Task to take user input\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2017-10-04T17:33:07.205+05:30\u0026#34;, \u0026#34;dueDate\u0026#34;: null, // other details... } } 最后，让我们使用任务id 49完成这个任务： POST runtime/tasks/49 这是一个 POST 请求，我们需要发送指示我们想要对任务执行什么操作的*操作字段。*我们可以“解决”、“完成”或“删除”一项任务。此外，我们可以传递任务所需的变量数组来完成。 在我们的例子中，我们必须传递一个字段“消息”，它是用户消息文本字段。所以我们的请求正文是： { \u0026#34;action\u0026#34;: \u0026#34;complete\u0026#34;, \u0026#34;variables\u0026#34;: [{ \u0026#34;name\u0026#34;: \u0026#34;message\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;This is a User Input Message\u0026#34; }] } \u0026quot; ","permalink":"http://itcodingman.github.io/activiti_kickstart_and_rest_apps/","tags":["Activiti"],"title":"Activiti Kickstart App 和 Activiti Rest Webapp"},{"categories":["Java","REST"],"contents":"1. 概述 在本文中，我们将说明Activeweb——来自 JavaLite 的全栈 Web 框架——提供开发动态 Web 应用程序或 REST-ful Web 服务所需的一切。 2. 基本概念与原则 Activeweb 利用“约定优于配置”——这意味着它是可配置的，但具有合理的默认值并且不需要额外的配置。我们只需要遵循一些预定义的约定，例如以某种预定义的格式命名类、方法和字段。 它还通过重新编译并将源重新加载到正在运行的容器（默认为 Jetty）中来简化开发。 对于依赖管理，它使用 Google Guice 作为 DI 框架；要了解有关 Guice 的更多信息，请在此处查看我们的指南。 Maven 设置   首先，让我们先添加必要的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activeweb\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.15\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本可以在这里找到。 此外，为了测试应用程序，我们需要activeweb-testing依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activeweb-testing\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.15\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 在这里查看最新版本。 4. 应用结构 正如我们所讨论的，应用程序结构需要遵循一定的约定；这是典型的 MVC 应用程序的样子： 我们可以看到，controllers、service、config、models应该位于app包中各自的子包中。 视图应位于WEB-INF/views目录中，每个视图都有基于控制器名称的自己的子目录。例如app.controllers.ArticleController应该有一个*article/*子目录，其中包含该控制器的所有视图文件。 部署描述符或web.xml通常应包含*和相应的。由于框架是一个 servlet 过滤器，所以有一个过滤器配置，而不是*配置： ... \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;dispatcher\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.javalite.activeweb.RequestDispatcher\u0026lt;/filter-class\u0026gt; ... \u0026lt;/filter\u0026gt; ... 我们还需要一个*root_controller来定义应用程序的默认控制器——类似于home*控制器： ... \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;root_controller\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;home\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; ... 5. 控制器 控制器是 ActiveWeb 应用程序的主要组件；并且，如前所述，所有控制器都应位于app.controllers包内： public class ArticleController extends AppController { // ... } 请注意，控制器正在扩展org.javalite.activeweb.AppController。 5.1 控制器 URL 映射 控制器会根据约定自动映射到 URL。例如，ArticleController将被映射到： http://host:port/contextroot/article 现在，这会将它们映射到控制器中的默认操作。动作只不过是控制器内部的方法。将默认方法命名为index()： public class ArticleController extends AppController { // ...  public void index() { render(\u0026#34;articles\u0026#34;); } // ... } 对于其他方法或操作，请将方法名称附加到 URL： public class ArticleController extends AppController { // ...  public void search() { render(\u0026#34;search\u0026#34;); } } 网址： http://host:port/contextroot/article/search 我们甚至可以有基于 HTTP 方法的控制器动作。只需使用*@POST、@PUT、@DELETE、@GET、@HEAD 中的任何一个来注释该方法。*如果我们不注释一个动作，它默认被认为是一个 GET。 5.2. 控制器 URL 解析 该框架使用控制器名称和子包名称来生成控制器 URL。例如app.controllers.ArticleController.java的 URL： http://host:port/contextroot/article 如果控制器位于子包中，则 URL 简单地变为： http://host:port/contextroot/codingman/article 对于包含多个单词的控制器名称（例如app.controllers.PublishedArticleController.java），URL 将使用下划线分隔： http://host:port/contextroot/published_article 5.3. 检索请求参数 在控制器内部，我们可以使用AppController 类的*param()或params()*方法访问请求参数。第一个方法接受一个字符串参数——要检索的参数的名称： public void search() { String keyword = param(\u0026#34;key\u0026#34;); view(\u0026#34;search\u0026#34;,articleService.search(keyword)); } 如果需要，我们可以使用后者来获取所有参数： public void search() { Map\u0026lt;String, String[]\u0026gt; criterion = params(); // ... } 6. 意见 在 ActiveWeb 术语中，视图通常称为模板。这主要是因为它使用 Apache FreeMarker模板引擎而不是 JSP。您可以在我们的指南中阅读有关 FreeMarker的更多信息，请点击此处。 将模板放在WEB-INF/views目录中。每个控制器都应该有一个按其名称命名的子目录，其中包含它所需的所有模板。 6.1 控制器视图映射 当一个控制器被点击时，默认的动作index()被执行并且框架将选择WEB-INF/views/article/ index.ftl模板作为该控制器的视图目录。同样，对于任何其他操作，将根据操作名称选择视图。 这并不总是我们想要的。有时我们可能希望根据内部业务逻辑返回一些视图。在这种情况下，我们可以使用父类org.javalite.activeweb.AppController类的*render()*方法来控制进程： public void index() { render(\u0026#34;articles\u0026#34;); } 请注意，自定义视图的位置也应该在该控制器的同一视图目录中。如果不是这种情况，则在模板名称前面加上模板所在的目录名称，并将其传递给*render()*方法： render(\u0026#34;/common/error\u0026#34;); 6.3. 数据视图 为了向视图发送数据，org.javalite.activeweb.AppController提供了*view()*方法： view(\u0026#34;articles\u0026#34;, articleService.getArticles()); 这需要两个参数。首先，用于访问模板中对象的对象名称，其次是包含数据的对象。 我们还可以使用*assign()*方法将数据传递给视图。*view() 和assign()*方法之间绝对没有区别——我们可以选择其中任何一种： assign(\u0026#34;article\u0026#34;, articleService.search(keyword)); 让我们映射模板中的数据： \u0026lt;@content for=\u0026#34;title\u0026#34;\u0026gt;Articles\u0026lt;/@content\u0026gt; ... \u0026lt;#list articles as article\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;${article.title}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${article.author}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${article.words}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${article.date}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/#list\u0026gt; \u0026lt;/table\u0026gt; 7. 管理依赖 为了管理对象和实例，ActiveWeb 使用 Google Guice 作为依赖管理框架。 假设我们的应用程序中需要一个服务类；这会将业务逻辑与控制器分开。 我们先创建一个服务接口： public interface ArticleService { List\u0026lt;Article\u0026gt; getArticles(); Article search(String keyword); } 和实施： public class ArticleServiceImpl implements ArticleService { public List\u0026lt;Article\u0026gt; getArticles() { return fetchArticles(); } public Article search(String keyword) { Article ar = new Article(); ar.set(\u0026#34;title\u0026#34;, \u0026#34;Article with \u0026#34;+keyword); ar.set(\u0026#34;author\u0026#34;, \u0026#34;codingman\u0026#34;); ar.set(\u0026#34;words\u0026#34;, \u0026#34;1250\u0026#34;); ar.setDate(\u0026#34;date\u0026#34;, Instant.now()); return ar; } } 现在，让我们将此服务绑定为 Guice 模块： public class ArticleServiceModule extends AbstractModule { @Override protected void configure() { bind(ArticleService.class).to(ArticleServiceImpl.class) .asEagerSingleton(); } } 最后，在应用程序上下文中注册它并根据需要将其注入控制器： public class AppBootstrap extends Bootstrap { public void init(AppContext context) { } public Injector getInjector() { return Guice.createInjector(new ArticleServiceModule()); } } 请注意，此配置类名称必须是AppBootstrap，并且它应该位于app.config包中。 最后，这是我们将其注入控制器的方法： @Inject private ArticleService articleService; 8. 测试 ActiveWeb 应用程序的单元测试是使用 JavaLite 的JSpec库编写的。 我们将使用 JSpec 中的org.javalite.activeweb.ControllerSpec类来测试我们的控制器，我们将按照类似的约定命名测试类： public class ArticleControllerSpec extends ControllerSpec { // ... } 请注意，该名称类似于它正在测试的控制器，末尾带有“Spec”。 这是测试用例： @Test public void whenReturnedArticlesThenCorrect() { request().get(\u0026#34;index\u0026#34;); a(responseContent()) .shouldContain(\u0026#34;\u0026lt;td\u0026gt;Introduction to Mule\u0026lt;/td\u0026gt;\u0026#34;); } 请注意，*request()方法模拟了对控制器的调用，而相应的 HTTP 方法get()*将操作名称作为参数。 我们还可以使用*params()*方法将参数传递给控制器： @Test public void givenKeywordWhenFoundArticleThenCorrect() { request().param(\u0026#34;key\u0026#34;, \u0026#34;Java\u0026#34;).get(\u0026#34;search\u0026#34;); a(responseContent()) .shouldContain(\u0026#34;\u0026lt;td\u0026gt;Article with Java\u0026lt;/td\u0026gt;\u0026#34;); } 要传递多个参数，我们也可以使用这个流畅的 API 链接方法。 部署应用程序   可以将应用程序部署在任何 servlet 容器中，例如 Tomcat、WildFly 或 Jetty。当然，部署和测试最简单的方法是使用 Maven Jetty 插件： ... \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetty-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.4.8.v20171121\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;reload\u0026gt;manual\u0026lt;/reload\u0026gt; \u0026lt;scanIntervalSeconds\u0026gt;10000\u0026lt;/scanIntervalSeconds\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; ... 最新版本的插件在这里。 现在，终于 - 我们可以启动它了： mvn jetty:run \u0026quot; ","permalink":"http://itcodingman.github.io/activeweb/","tags":[],"title":"ActiveWeb 简介"},{"categories":["Persistence"],"contents":" 简介   ActiveJDBC 是一个轻量级的 ORM，它遵循ActiveRecord的核心思想，它是 Ruby on Rails 的主要 ORM。 它侧重于**通过删除典型持久性管理器的额外层来简化与数据库的交互，**并侧重于 SQL 的使用，而不是创建新的查询语言。 此外，它通过DBSpec类为数据库交互提供了自己的编写单元测试的方式。 让我们看看这个库与其他流行的 Java ORM 有何不同以及如何使用它。 ActiveJDBC 与其他 ORM   与大多数其他 Java ORM 相比，ActiveJDBC 有明显的不同。它从数据库中推断出 DB 模式参数，从而无需将实体映射到基础表。 没有会话，没有持久性管理器，不需要学习新的查询语言，没有 getter/setter。库本身在大小和依赖数量方面很轻。 该实现鼓励使用在执行测试后由框架清理的测试数据库，从而降低维护测试数据库的成本。 但是，每当我们创建或更新模型时，都需要一些额外的检测步骤。我们将在接下来的部分讨论这个问题。 设计原则    从数据库推断元数据 基于约定的配置 没有会话，没有“附加，重新附加” 轻量级模型，简单 POJO 无代理 避免Anemic域模型 不需要 DAO 和 DTO  设置java包   使用 MySQL 数据库的典型 Maven 设置包括： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activejdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.34\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在 Maven 中央存储库中找到最新版本的activejdbc和mysql 连接器工件。 Instrumentation是简化的代价，在处理 ActiveJDBC 项目时需要。 有一个仪器插件需要在项目中配置： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activejdbc-instrumentation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.13\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;process-classes\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;instrument\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 最新的activejdbc-instrumentation插件也可以在 Maven Central 中找到。 现在，我们可以通过执行以下两个命令之一来处理检测： mvn process-classes mvn activejdbc-instrumentation:instrument 使用 ActiveJDBC   5.1 模型 我们可以只用一行代码创建一个简单的模型——它涉及扩展Model类。 该库使用反射来实现名词的复数和单数形式的转换。这可以使用*@Table*注释覆盖。 让我们看看一个简单的模型是什么样子的： import org.javalite.activejdbc.Model; public class Employee extends Model {} 5.2 连接到数据库 提供了两个类——Base和DB——来连接数据库。 连接数据库的最简单方法是： Base.open(\u0026#34;com.mysql.jdbc.Driver\u0026#34;, \u0026#34;jdbc:mysql://host/organization\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;xxxxx\u0026#34;); 当模型在运行时，它们利用在当前线程中找到的连接。在任何 DB 操作之前，此连接由Base或DB类放在本地线程上。 上述方法允许使用更简洁的 API，无需像其他 Java ORM 中那样使用 DB Session 或 Persistence 管理器。 让我们看看如何使用DB类连接到数据库： new DB(\u0026#34;default\u0026#34;).open( \u0026#34;com.mysql.jdbc.Driver\u0026#34;, \u0026#34;jdbc:mysql://localhost/dbname\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;XXXXXX\u0026#34;); 如果我们看看Base和DB用于连接数据库的不同之处，它有助于我们得出结论，如果在单个数据库上操作应该使用Base ，而DB应该与多个数据库一起使用。 5.3. 插入记录 向数据库中添加记录非常简单。如前所述，不需要 setter 和 getter： Employee e = new Employee(); e.set(\u0026#34;first_name\u0026#34;, \u0026#34;Hugo\u0026#34;); e.set(\u0026#34;last_name\u0026#34;, \u0026#34;Choi\u0026#34;); e.saveIt(); 或者，我们可以通过这种方式添加相同的记录： Employee employee = new Employee(\u0026#34;Hugo\u0026#34;,\u0026#34;Choi\u0026#34;); employee.saveIt(); 甚至，流利地： new Employee() .set(\u0026#34;first_name\u0026#34;, \u0026#34;Hugo\u0026#34;, \u0026#34;last_name\u0026#34;, \u0026#34;Choi\u0026#34;) .saveIt(); 5.4. 更新记录 下面的代码片段显示了如何更新记录： Employee employee = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); employee .set(\u0026#34;last_name\u0026#34;,\u0026#34;Choi\u0026#34;) .saveIt(); 5.5. 删除记录 Employee e = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); e.delete(); 如果需要删除所有记录： Employee.deleteAll(); 如果我们想从级联到子表的主表中删除一条记录，请使用deleteCascade： Employee employee = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;,\u0026#34;Hugo\u0026#34;); employee.deleteCascade(); 5.6. 获取记录 让我们从数据库中获取一条记录： Employee e = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); 如果我们想获取多条记录，我们可以使用where方法： List\u0026lt;Employee\u0026gt; employees = Employee.where(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); 6.交易支持 在 Java ORM 中，存在显式连接或管理器对象（JPA 中的 EntityManager、Hibernate 中的 SessionManager 等）。ActiveJDBC 中没有这样的东西。 调用*Base.open()打开一个连接，将其附加到当前线程，因此所有模型的所有后续方法都重用此连接。调用Base.close()*关闭连接并将其从当前线程中删除。 为了管理事务，有几个方便的调用： 开始交易： Base.openTransaction(); 提交事务： Base.commitTransaction(); 回滚事务： Base.rollbackTransaction(); 支持的数据库   最新版本支持 SQLServer、MySQL、Oracle、PostgreSQL、H2、SQLite3、DB2 等数据库。 \u0026quot; ","permalink":"http://itcodingman.github.io/active_jdbc/","tags":[],"title":"ActiveJDBC 简介"},{"categories":["Java"],"contents":"1. 概述 术语套接字编程是指编写跨多台计算机执行的程序，其中设备都使用网络相互连接。 我们可以使用两种通信协议进行套接字编程：用户数据报协议（UDP）和传输控制协议（TCP）。 两者的主要区别在于 UDP 是无连接的，这意味着客户端和服务器之间没有会话，而 TCP 是面向连接的，这意味着必须首先在客户端和服务器之间建立独占连接才能进行通信. 本教程介绍TCP/IP网络上的套接字编程，并演示如何用 Java 编写客户端/服务器应用程序。UDP 不是主流协议，因此可能不会经常遇到。 2. 项目设置 Java 提供了一组类和接口来处理客户端和服务器之间的低级通信细节。 这些大部分都包含在java.net包中，因此我们需要进行以下导入： import java.net.*; 我们还需要java.io包，它为我们提供了在通信时写入和读取的输入和输出流： import java.io.*; 为简单起见，我们将在同一台计算机上运行我们的客户端和服务器程序。如果我们要在不同的联网计算机上执行它们，唯一会改变的是 IP 地址。在这种情况下，我们将在127.0.0.1上使用localhost。 3. 简单例子 让我们用涉及客户端和服务器的最基本示例来动手。这将是一个双向通信应用程序，客户端向服务器打招呼，服务器响应。 我们将使用以下代码在名为GreetServer.java的类中创建服务器应用程序。 我们将包括main方法和全局变量，以提醒我们如何在本文中运行所有服务器。对于本文中的其余示例，我们将省略这种重复代码： public class GreetServer { private ServerSocket serverSocket; private Socket clientSocket; private PrintWriter out; private BufferedReader in; public void start(int port) { serverSocket = new ServerSocket(port); clientSocket = serverSocket.accept(); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); String greeting = in.readLine(); if (\u0026#34;hello server\u0026#34;.equals(greeting)) { out.println(\u0026#34;hello client\u0026#34;); } else { out.println(\u0026#34;unrecognised greeting\u0026#34;); } } public void stop() { in.close(); out.close(); clientSocket.close(); serverSocket.close(); } public static void main(String[] args) { GreetServer server=new GreetServer(); server.start(6666); } } 我们还将使用以下代码创建一个名为GreetClient.java的客户端： public class GreetClient { private Socket clientSocket; private PrintWriter out; private BufferedReader in; public void startConnection(String ip, int port) { clientSocket = new Socket(ip, port); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); } public String sendMessage(String msg) { out.println(msg); String resp = in.readLine(); return resp; } public void stopConnection() { in.close(); out.close(); clientSocket.close(); } } **现在让我们启动服务器。**在我们的 IDE 中，我们只需将其作为 Java 应用程序运行即可。 然后我们将使用单元测试向服务器发送问候语，确认服务器发送问候语作为响应： @Test public void givenGreetingClient_whenServerRespondsWhenStarted_thenCorrect() { GreetClient client = new GreetClient(); client.startConnection(\u0026#34;127.0.0.1\u0026#34;, 6666); String response = client.sendMessage(\u0026#34;hello server\u0026#34;); assertEquals(\u0026#34;hello client\u0026#34;, response); } 这个例子让我们对本文后面的内容有所了解。因此，我们可能还没有完全理解这里发生了什么。 在接下来的部分中，我们将使用这个简单的示例来剖析套接字通信，并深入研究更复杂的示例。 4. 套接字如何工作 我们将使用上面的示例来逐步介绍本节的不同部分。 根据定义，套接字是网络上不同计算机上运行的两个程序之间双向通信链路的一个端点。套接字绑定到端口号，以便传输层可以识别数据要发送到的应用程序。 4.1 服务器 通常，服务器在网络上的特定计算机上运行，并且有一个绑定到特定端口号的套接字。在我们的例子中，我们将使用与客户端相同的计算机，并在端口6666上启动服务器： ServerSocket serverSocket = new ServerSocket(6666); 服务器只是等待，侦听套接字以供客户端发出连接请求。这发生在下一步中： Socket clientSocket = serverSocket.accept(); 当服务器代码遇到accept方法时，它会阻塞，直到客户端向它发出连接请求。 如果一切顺利，服务器接受连接。接受后，服务器会获得一个新的套接字clientSocket，绑定到相同的本地端口6666，并将其远程端点设置为客户端的地址和端口。 此时，新的Socket对象将服务器与客户端直接连接。然后，我们可以访问输出和输入流，分别向客户端写入和接收消息： PrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); BufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); 现在，服务器能够与客户端无休止地交换消息，直到套接字与其流一起关闭。 但是，在我们的示例中，服务器只能在关闭连接之前发送问候响应。这意味着如果我们再次运行测试，服务器将拒绝连接。 为了保持通信的连续性，我们必须在while循环内从输入流中读取数据，并且仅在客户端发送终止请求时退出。我们将在下一节中看到这一点。 对于每个新客户端，服务器都需要一个由接受调用返回的新套接字。我们使用serverSocket继续监听连接请求，同时倾向于连接客户端的需求。在我们的第一个示例中，我们还没有允许这样做。 4.2 客户端 客户端必须知道服务器正在运行的机器的主机名或 IP，以及服务器正在侦听的端口号。 为了发出连接请求，客户端尝试在服务器的机器和端口上与服务器会合： Socket clientSocket = new Socket(\u0026#34;127.0.0.1\u0026#34;, 6666); 客户端还需要向服务器标识自己，因此它绑定到系统分配的本地端口号，它将在此连接期间使用。我们自己不处理这个。 上面的构造函数只在服务器接受连接时创建一个新的套接字；否则，我们会得到一个连接被拒绝的异常。创建成功后，我们就可以从中获取输入输出流，与服务器进行通信： PrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); BufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); 客户端的输入流连接到服务器的输出流，就像服务器的输入流连接到客户端的输出流一样。 5. 持续沟通 我们当前的服务器阻塞，直到客户端连接到它，然后再次阻塞以收听来自客户端的消息。在单个消息之后，它会关闭连接，因为我们还没有处理连续性。 因此，它仅对 ping 请求有用。但是想象一下我们想要实现一个聊天服务器；肯定需要服务器和客户端之间的持续来回通信。 我们必须创建一个 while 循环来持续观察服务器的输入流以获取传入消息。 因此，让我们创建一个名为EchoServer.java 的新服务器，其唯一目的是回显从客户端接收到的任何消息： public class EchoServer { public void start(int port) { serverSocket = new ServerSocket(port); clientSocket = serverSocket.accept(); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); String inputLine; while ((inputLine = in.readLine()) != null) { if (\u0026#34;.\u0026#34;.equals(inputLine)) { out.println(\u0026#34;good bye\u0026#34;); break; } out.println(inputLine); } } 请注意，我们添加了一个终止条件，当我们收到一个句点字符时，while 循环退出。 我们将使用 main 方法启动EchoServer，就像我们对GreetServer所做的那样。这一次，我们在另一个端口上启动它，例如*4444，*以避免混淆。 EchoClient类似于GreetClient ，因此我们可以复制代码。为了清楚起见，我们将它们分开。 在一个不同的测试类中，我们将创建一个测试来显示多个对EchoServer的请求将在服务器关闭套接字的情况下得到处理。只要我们从同一个客户端发送请求，情况就是如此。 与多个客户打交道是另一种情况，我们将在下一节中看到。 现在让我们创建一个设置方法来启动与服务器的连接： @Before public void setup() { client = new EchoClient(); client.startConnection(\u0026#34;127.0.0.1\u0026#34;, 4444); } 我们还将创建一个tearDown方法来释放我们所有的资源。这是我们使用网络资源的每种情况的最佳实践： @After public void tearDown() { client.stopConnection(); } 然后我们将使用一些请求来测试我们的 echo 服务器： @Test public void givenClient_whenServerEchosMessage_thenCorrect() { String resp1 = client.sendMessage(\u0026#34;hello\u0026#34;); String resp2 = client.sendMessage(\u0026#34;world\u0026#34;); String resp3 = client.sendMessage(\u0026#34;!\u0026#34;); String resp4 = client.sendMessage(\u0026#34;.\u0026#34;); assertEquals(\u0026#34;hello\u0026#34;, resp1); assertEquals(\u0026#34;world\u0026#34;, resp2); assertEquals(\u0026#34;!\u0026#34;, resp3); assertEquals(\u0026#34;good bye\u0026#34;, resp4); } 这是对初始示例的改进，在初始示例中，我们只在服务器关闭我们的连接之前通信一次。现在我们发送一个终止信号来告诉服务器我们什么时候完成了会话。 6. 多客户端服务器 尽管前面的示例比第一个示例有所改进，但它仍然不是一个很好的解决方案。服务器必须能够同时为许多客户端和许多请求提供服务。 处理多个客户端是我们将在本节中介绍的内容。 我们将在这里看到的另一个特性是，同一个客户端可以断开连接并再次重新连接，而不会出现连接被拒绝异常或服务器上的连接重置。我们以前无法做到这一点。 这意味着我们的服务器将在来自多个客户端的多个请求中更加健壮和有弹性。 为此，我们将为每个新客户端创建一个新套接字，并为该客户端在不同线程上的请求提供服务。同时服务的客户端数量将等于运行的线程数。 主线程在侦听新连接时将运行一个 while 循环。 现在让我们看看它的实际效果。我们将创建另一个名为EchoMultiServer.java的服务器。在其中，我们将创建一个处理程序线程类来管理每个客户端在其套接字上的通信： public class EchoMultiServer { private ServerSocket serverSocket; public void start(int port) { serverSocket = new ServerSocket(port); while (true) new EchoClientHandler(serverSocket.accept()).start(); } public void stop() { serverSocket.close(); } private static class EchoClientHandler extends Thread { private Socket clientSocket; private PrintWriter out; private BufferedReader in; public EchoClientHandler(Socket socket) { this.clientSocket = socket; } public void run() { out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader( new InputStreamReader(clientSocket.getInputStream())); String inputLine; while ((inputLine = in.readLine()) != null) { if (\u0026#34;.\u0026#34;.equals(inputLine)) { out.println(\u0026#34;bye\u0026#34;); break; } out.println(inputLine); } in.close(); out.close(); clientSocket.close(); } } 请注意，我们现在在while循环中调用了accept 。每次执行while循环时，它都会阻塞accept调用，直到有新的客户端连接。然后为该客户端创建处理程序线程EchoClientHandler。 线程内部发生的事情与EchoServer相同，我们只处理一个客户端。EchoMultiServer将此工作委托给EchoClientHandler，以便它可以在while循环中继续侦听更多客户端。 我们仍将使用EchoClient来测试服务器。这一次，我们将创建多个客户端，每个客户端从服务器发送和接收多条消息。 让我们使用端口5555上的 main 方法启动我们的服务器。 为清楚起见，我们仍将测试放在一个新套件中： @Test public void givenClient1_whenServerResponds_thenCorrect() { EchoClient client1 = new EchoClient(); client1.startConnection(\u0026#34;127.0.0.1\u0026#34;, 5555); String msg1 = client1.sendMessage(\u0026#34;hello\u0026#34;); String msg2 = client1.sendMessage(\u0026#34;world\u0026#34;); String terminate = client1.sendMessage(\u0026#34;.\u0026#34;); assertEquals(msg1, \u0026#34;hello\u0026#34;); assertEquals(msg2, \u0026#34;world\u0026#34;); assertEquals(terminate, \u0026#34;bye\u0026#34;); } @Test public void givenClient2_whenServerResponds_thenCorrect() { EchoClient client2 = new EchoClient(); client2.startConnection(\u0026#34;127.0.0.1\u0026#34;, 5555); String msg1 = client2.sendMessage(\u0026#34;hello\u0026#34;); String msg2 = client2.sendMessage(\u0026#34;world\u0026#34;); String terminate = client2.sendMessage(\u0026#34;.\u0026#34;); assertEquals(msg1, \u0026#34;hello\u0026#34;); assertEquals(msg2, \u0026#34;world\u0026#34;); assertEquals(terminate, \u0026#34;bye\u0026#34;); } 我们可以根据需要创建尽可能多的这些测试用例，每个都生成一个新客户端，服务器将为它们提供服务。 \u0026quot; ","permalink":"http://itcodingman.github.io/a_guide_to_java_sockets/","tags":["Java IO"],"title":"Java 套接字指南"},{"categories":["Java"],"contents":" 概述   在本教程中，我们将了解 Java 枚举是什么，它们解决了哪些问题，以及如何在实践中使用它们的一些设计模式。 **Java 5 首次引入了enum关键字。**它表示一种特殊类型的类，它总是扩展java.lang.Enum类。有关使用的官方文档，我们可以前往文档。 以这种方式定义的常量使代码更具可读性，允许编译时检查，预先记录接受值的列表，并避免由于传入无效值而导致的意外行为。 这是一个定义披萨订单状态的快速简单的枚举示例；订单状态可以是ORDERED、READY或DELIVERED： public enum PizzaStatus { ORDERED, READY, DELIVERED; } 此外，枚举带有许多有用的方法，如果我们使用传统的公共静态最终常量，我们将需要编写这些方法。 2. 自定义枚举方法 现在我们对枚举是什么以及如何使用它们有了基本的了解，我们将通过在枚举上定义一些额外的 API 方法，将前面的示例提升到一个新的水平： public class Pizza { private PizzaStatus status; public enum PizzaStatus { ORDERED, READY, DELIVERED; } public boolean isDeliverable() { if (getStatus() == PizzaStatus.READY) { return true; } return false; } // Methods that set and get the status variable. } 3. 使用“==”运算符比较枚举类型 由于枚举类型确保 JVM 中仅存在一个常量实例，因此我们可以安全地使用“==”运算符来比较两个变量，就像我们在上面的示例中所做的那样。此外，“==”运算符提供编译时和运行时安全性。 首先，我们将在以下代码段中查看**运行时安全性，其中我们将使用“==”运算符来比较状态。**任何一个值都可以为 空，我们不会得到 NullPointerException。相反，如果我们使用 equals 方法，我们会得到一个NullPointerException： if(testPz.getStatus().equals(Pizza.PizzaStatus.DELIVERED)); if(testPz.getStatus() == Pizza.PizzaStatus.DELIVERED); 至于编译时安全性，让我们看一个示例，我们将通过使用equals方法进行比较来确定不同类型的枚举是否相等。这是因为 enum 和getStatus方法的值恰好是相同的；但是，从逻辑上讲，比较应该是错误的。我们通过使用“==”运算符来避免这个问题。 编译器会将比较标记为不兼容错误： if(testPz.getStatus().equals(TestColor.GREEN)); if(testPz.getStatus() == TestColor.GREEN); 4. 在 Switch 语句中使用枚举类型 我们也可以在switch语句中使用枚举类型： public int getDeliveryTimeInDays() { switch (status) { case ORDERED: return 5; case READY: return 2; case DELIVERED: return 0; } return 0; } 5. 枚举中的字段、方法和构造函数 我们可以在枚举类型中定义构造函数、方法和字段，这使得它们非常强大。 接下来，让我们通过实现从披萨订单的一个阶段到另一个阶段的转换来扩展上面的示例。我们将看到如何摆脱之前使用的if和switch语句： public class Pizza { private PizzaStatus status; public enum PizzaStatus { ORDERED (5){ @Override public boolean isOrdered() { return true; } }, READY (2){ @Override public boolean isReady() { return true; } }, DELIVERED (0){ @Override public boolean isDelivered() { return true; } }; private int timeToDelivery; public boolean isOrdered() {return false;} public boolean isReady() {return false;} public boolean isDelivered(){return false;} public int getTimeToDelivery() { return timeToDelivery; } PizzaStatus (int timeToDelivery) { this.timeToDelivery = timeToDelivery; } } public boolean isDeliverable() { return this.status.isReady(); } public void printTimeToDeliver() { System.out.println(\u0026#34;Time to delivery is \u0026#34; + this.getStatus().getTimeToDelivery()); } // Methods that set and get the status variable. } 下面的测试片段演示了它是如何工作的： @Test public void givenPizaOrder_whenReady_thenDeliverable() { Pizza testPz = new Pizza(); testPz.setStatus(Pizza.PizzaStatus.READY); assertTrue(testPz.isDeliverable()); } EnumSet和EnumMap   6.1 EnumSet EnumSet是一个专门的Set实现，旨在与Enum类型一起使用。 与HashSet相比，由于使用了内部位向量表示，它是一组特定枚举常量的非常有效和紧凑的表示。它还为传统的基于int的“位标志”提供了一种类型安全的替代方案，使我们能够编写更易读和更易于维护的简洁代码。 EnumSet是一个抽象类，它有两个实现，RegularEnumSet和JumboEnumSet，其中一个是根据实例化时枚举中常量的数量来选择的。 因此，在大多数情况下（如子集、添加、删除和批量操作，如containsAll和removeAll），只要我们想使用枚举常量集合，最好使用这个集合，如果我们使用*Enum.values()*只想遍历所有可能的常量。 在下面的代码片段中，我们可以看到如何使用EnumSet创建常量子集： public class Pizza { private static EnumSet\u0026lt;PizzaStatus\u0026gt; undeliveredPizzaStatuses = EnumSet.of(PizzaStatus.ORDERED, PizzaStatus.READY); private PizzaStatus status; public enum PizzaStatus { ... } public boolean isDeliverable() { return this.status.isReady(); } public void printTimeToDeliver() { System.out.println(\u0026#34;Time to delivery is \u0026#34; + this.getStatus().getTimeToDelivery() + \u0026#34; days\u0026#34;); } public static List\u0026lt;Pizza\u0026gt; getAllUndeliveredPizzas(List\u0026lt;Pizza\u0026gt; input) { return input.stream().filter( (s) -\u0026gt; undeliveredPizzaStatuses.contains(s.getStatus())) .collect(Collectors.toList()); } public void deliver() { if (isDeliverable()) { PizzaDeliverySystemConfiguration.getInstance().getDeliveryStrategy() .deliver(this); this.setStatus(PizzaStatus.DELIVERED); } } // Methods that set and get the status variable. } 执行以下测试演示了Set接口的EnumSet实现的强大功能： @Test public void givenPizaOrders_whenRetrievingUnDeliveredPzs_thenCorrectlyRetrieved() { List\u0026lt;Pizza\u0026gt; pzList = new ArrayList\u0026lt;\u0026gt;(); Pizza pz1 = new Pizza(); pz1.setStatus(Pizza.PizzaStatus.DELIVERED); Pizza pz2 = new Pizza(); pz2.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz3 = new Pizza(); pz3.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz4 = new Pizza(); pz4.setStatus(Pizza.PizzaStatus.READY); pzList.add(pz1); pzList.add(pz2); pzList.add(pz3); pzList.add(pz4); List\u0026lt;Pizza\u0026gt; undeliveredPzs = Pizza.getAllUndeliveredPizzas(pzList); assertTrue(undeliveredPzs.size() == 3); } 6.2. EnumMap EnumMap是一种专门的Map实现，旨在与枚举常量一起用作键。与其对应的HashMap 相比，它是一种高效且紧凑的实现，内部表示为数组： EnumMap\u0026lt;Pizza.PizzaStatus, Pizza\u0026gt; map; 让我们看一个如何在实践中使用它的示例： public static EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; groupPizzaByStatus(List\u0026lt;Pizza\u0026gt; pizzaList) { EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; pzByStatus = new EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt;(PizzaStatus.class); for (Pizza pz : pizzaList) { PizzaStatus status = pz.getStatus(); if (pzByStatus.containsKey(status)) { pzByStatus.get(status).add(pz); } else { List\u0026lt;Pizza\u0026gt; newPzList = new ArrayList\u0026lt;Pizza\u0026gt;(); newPzList.add(pz); pzByStatus.put(status, newPzList); } } return pzByStatus; } 执行以下测试演示了Map接口的EnumMap实现的强大功能： @Test public void givenPizaOrders_whenGroupByStatusCalled_thenCorrectlyGrouped() { List\u0026lt;Pizza\u0026gt; pzList = new ArrayList\u0026lt;\u0026gt;(); Pizza pz1 = new Pizza(); pz1.setStatus(Pizza.PizzaStatus.DELIVERED); Pizza pz2 = new Pizza(); pz2.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz3 = new Pizza(); pz3.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz4 = new Pizza(); pz4.setStatus(Pizza.PizzaStatus.READY); pzList.add(pz1); pzList.add(pz2); pzList.add(pz3); pzList.add(pz4); EnumMap\u0026lt;Pizza.PizzaStatus,List\u0026lt;Pizza\u0026gt;\u0026gt; map = Pizza.groupPizzaByStatus(pzList); assertTrue(map.get(Pizza.PizzaStatus.DELIVERED).size() == 1); assertTrue(map.get(Pizza.PizzaStatus.ORDERED).size() == 2); assertTrue(map.get(Pizza.PizzaStatus.READY).size() == 1); } 使用枚举实现设计模式   7.1 单例模式 通常，使用单例模式实现一个类是非常重要的。枚举提供了一种实现单例的快速简便的方法。 此外，由于 enum 类在底层实现了Serializable接口，因此该类被 JVM 保证为单例。这与传统实现不同，在传统实现中，我们必须确保在反序列化期间不会创建新实例。 在下面的代码片段中，我们看到了如何实现单例模式： public enum PizzaDeliverySystemConfiguration { INSTANCE; PizzaDeliverySystemConfiguration() { // Initialization configuration which involves  // overriding defaults like delivery strategy  } private PizzaDeliveryStrategy deliveryStrategy = PizzaDeliveryStrategy.NORMAL; public static PizzaDeliverySystemConfiguration getInstance() { return INSTANCE; } public PizzaDeliveryStrategy getDeliveryStrategy() { return deliveryStrategy; } } 7.2 策略模式 传统上，策略模式是通过具有由不同类实现的接口来编写的。 添加新策略意味着添加新的实现类。使用枚举，我们可以用更少的努力来实现这一点，并且添加一个新的实现意味着简单地定义另一个具有一些实现的实例。 下面的代码片段展示了如何实现策略模式： public enum PizzaDeliveryStrategy { EXPRESS { @Override public void deliver(Pizza pz) { System.out.println(\u0026#34;Pizza will be delivered in express mode\u0026#34;); } }, NORMAL { @Override public void deliver(Pizza pz) { System.out.println(\u0026#34;Pizza will be delivered in normal mode\u0026#34;); } }; public abstract void deliver(Pizza pz); } 然后我们在Pizza类中添加以下方法： public void deliver() { if (isDeliverable()) { PizzaDeliverySystemConfiguration.getInstance().getDeliveryStrategy() .deliver(this); this.setStatus(PizzaStatus.DELIVERED); } } @Test public void givenPizaOrder_whenDelivered_thenPizzaGetsDeliveredAndStatusChanges() { Pizza pz = new Pizza(); pz.setStatus(Pizza.PizzaStatus.READY); pz.deliver(); assertTrue(pz.getStatus() == Pizza.PizzaStatus.DELIVERED); } Java 8 和枚举   我们可以在 Java 8 中重写Pizza类，看看getAllUndeliveredPizzas()和groupPizzaByStatus()方法如何通过使用 lambda 和Stream API 变得如此简洁： public static List\u0026lt;Pizza\u0026gt; getAllUndeliveredPizzas(List\u0026lt;Pizza\u0026gt; input) { return input.stream().filter( (s) -\u0026gt; !deliveredPizzaStatuses.contains(s.getStatus())) .collect(Collectors.toList()); } public static EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; groupPizzaByStatus(List\u0026lt;Pizza\u0026gt; pzList) { EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; map = pzList.stream().collect( Collectors.groupingBy(Pizza::getStatus, () -\u0026gt; new EnumMap\u0026lt;\u0026gt;(PizzaStatus.class), Collectors.toList())); return map; } Enum 的 JSON 表示   使用 Jackson 库，可以将枚举类型的 JSON 表示为 POJO。在下面的代码片段中，我们将看到如何使用 Jackson 注释： @JsonFormat(shape = JsonFormat.Shape.OBJECT) public enum PizzaStatus { ORDERED (5){ @Override public boolean isOrdered() { return true; } }, READY (2){ @Override public boolean isReady() { return true; } }, DELIVERED (0){ @Override public boolean isDelivered() { return true; } }; private int timeToDelivery; public boolean isOrdered() {return false;} public boolean isReady() {return false;} public boolean isDelivered(){return false;} @JsonProperty(\u0026#34;timeToDelivery\u0026#34;) public int getTimeToDelivery() { return timeToDelivery; } private PizzaStatus (int timeToDelivery) { this.timeToDelivery = timeToDelivery; } } 我们可以使用Pizza和PizzaStatus如下： Pizza pz = new Pizza(); pz.setStatus(Pizza.PizzaStatus.READY); System.out.println(Pizza.getJsonString(pz)); 这将生成Pizza状态的以下 JSON 表示： { \u0026#34;status\u0026#34; : { \u0026#34;timeToDelivery\u0026#34; : 2, \u0026#34;ready\u0026#34; : true, \u0026#34;ordered\u0026#34; : false, \u0026#34;delivered\u0026#34; : false }, \u0026#34;deliverable\u0026#34; : true } 有关枚举类型的 JSON 序列化/反序列化（包括自定义）的更多信息，我们可以参考Jackson – Serialize Enums as JSON Objects。 \u0026quot; ","permalink":"http://itcodingman.github.io/a_guide_to_java_enums/","tags":["Core Java"],"title":"Java 枚举指南"},{"categories":["Algorithms","Java"],"contents":"1. 简介 **最近，我们研究了解决游戏 2048 的算法。**我们从理论的角度讨论了这个问题，而不是背后的任何真实代码。 **在这里，我们将用 Java 编写一个实现。**这将扮演人类和计算机玩家的角色，展示如何玩出更优化的游戏。 2. 初始设置 我们需要的第一件事是一个设置，我们可以在其中玩游戏并查看进展情况。 这将为我们提供玩游戏所需的所有构造，并完全实现计算机播放器——无论如何它只会放置随机图块。这为我们提供了实现“人类”玩家玩游戏的空间。 2.1 游戏板 首先，我们需要一个游戏板。这是一个可以放置数字单元格。 为了让一些事情更容易处理，让我们从一个简单的单元格位置表示开始。这实际上只是一对坐标的包装： public class Cell { private final int x; private final int y; // constructor, getters, and toString } 我们现在可以编写一个类来表示网格本身。这会将值存储在一个简单的二维数组中，但允许我们通过上面的Cell类访问它们： public class Board { private final int[][] board; private final int score; public Board(int size) { this.board = new int[size][]; this.score = 0; for (int x = 0; x \u0026lt; size; ++x) { this.board[x] = new int[size]; for (int y = 0; y \u0026lt; size; ++y) { board[x][y] = 0; } } } public int getSize() { return board.length; } public int getScore() { return score; } public int getCell(Cell cell) { return board[cell.getX()][cell.getY()]; } public boolean isEmpty(Cell cell) { return getCell(cell) == 0; } public List\u0026lt;Cell\u0026gt; emptyCells() { List\u0026lt;Cell\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (int x = 0; x \u0026lt; board.length; ++x) { for (int y = 0; y \u0026lt; board[x].length; ++y) { Cell cell = new Cell(x, y); if (isEmpty(cell)) { result.add(cell); } } } return result; } } **这是一个代表棋盘的不可变类，让我们查询它以找出当前状态。**它还跟踪当前的分数，我们稍后会谈到。 2.2 电脑选手和放置图块 现在我们有了一个游戏板，我们希望能够玩它。我们想要的第一件事是电脑选手，因为这是一个纯粹的随机选手，以后会完全按照需要。 电脑玩家只不过是在一个单元格中放置了一个棋子，所以我们需要一些方法来在我们的棋盘上实现这一点。我们希望保持它是不可变的，因此放置一个图块将在新状态下生成一个全新的棋盘。 首先，我们需要一个构造函数来获取实际的棋盘状态，而不是我们之前构造一个空白棋盘的构造函数： private Board(int[][] board, int score) { this.score = score; this.board = new int[board.length][]; for (int x = 0; x \u0026lt; board.length; ++x) { this.board[x] = Arrays.copyOf(board[x], board[x].length); } } 这是私有的，因此它只能被同一类中的其他方法使用。这有助于我们封装游戏板。 **接下来，我们将添加一个放置图块的方法。**这将返回一个与当前板相同的全新板，只是它在给定单元格中具有给定编号： public Board placeTile(Cell cell, int number) { if (!isEmpty(cell)) { throw new IllegalArgumentException(\u0026#34;That cell is not empty\u0026#34;); } Board result = new Board(this.board, this.score); result.board[cell.getX()][cell.getY()] = number; return result; } 最后，**我们将编写一个代表计算机选手的新类。**这将有一个方法可以获取当前板并返回新板： public class Computer { private final SecureRandom rng = new SecureRandom(); public Board makeMove(Board input) { List\u0026lt;Cell\u0026gt; emptyCells = input.emptyCells(); double numberToPlace = rng.nextDouble(); int indexToPlace = rng.nextInt(emptyCells.size()); Cell cellToPlace = emptyCells.get(indexToPlace); return input.placeTile(cellToPlace, numberToPlace \u0026gt;= 0.9 ? 4 : 2); } } **这会从板上获取每个空单元格的列表，随机选择一个，然后将一个数字放入其中。**我们将随机决定在 10% 的情况下将“4”放入单元格，在其他 90% 的情况下放入“2”。 2.2 一个“人类”玩家和移动图块 接下来我们需要的是一个“人类”玩家。**这不是最终目标，而是一个纯粹随机的玩家，每次移动时都会选择一个随机方向来移动图块。**然后，这将成为我们可以建立最佳玩家的地方。 首先，我们需要定义可以进行的可能移动的枚举： public enum Move { UP, DOWN, LEFT, RIGHT } **接下来，我们需要增加Board类以支持通过在这些方向之一上移动图块来进行移动。**为了降低这里的复杂性，我们想要旋转棋盘，这样我们总是在同一个方向移动瓷砖。 这意味着我们需要一种转置和反转板的方法： private static int[][] transpose(int[][] input) { int[][] result = new int[input.length][]; for (int x = 0; x \u0026lt; input.length; ++x) { result[x] = new int[input[0].length]; for (int y = 0; y \u0026lt; input[0].length; ++y) { result[x][y] = input[y][x]; } } return result; } private static int[][] reverse(int[][] input) { int[][] result = new int[input.length][]; for (int x = 0; x \u0026lt; input.length; ++x) { result[x] = new int[input[0].length]; for (int y = 0; y \u0026lt; input[0].length; ++y) { result[x][y] = input[x][input.length - y - 1]; } } return result; } 转置板将交换所有行和列，使得顶部边缘变为左侧边缘。反转板只是镜像它，使左边缘变成右边缘。 接下来，我们向Board添加一个方法，以在给定方向上移动，并以新的状态返回一个新的Board。 我们首先制作Board状态的副本，然后我们可以使用它： public Board move(Move move) { int newScore = 0; // Clone the board  int[][] tiles = new int[this.board.length][]; for (int x = 0; x \u0026lt; this.board.length; ++x) { tiles[x] = Arrays.copyOf(this.board[x], this.board[x].length); } 接下来，我们操纵我们的副本，以便我们总是向上移动瓷砖： if (move == Move.LEFT || move == Move.RIGHT) { tiles = transpose(tiles); } if (move == Move.DOWN || move == Move.RIGHT) { tiles = reverse(tiles); } 我们还需要另一组图块——这次是我们将构建最终结果的图块——以及一个用于跟踪此次移动获得的新分数的跟踪器： int[][] result = new int[tiles.length][]; int newScore = 0; 现在我们已经准备好开始移动图块了，并且我们已经操纵了一些东西，以便我们始终朝着同一个方向工作，我们可以开始了。 **我们可以独立于其他列移动每一列。**我们只需要遍历列并重复，从构建我们正在移动的图块的另一个副本开始。 这次我们将它们构建到LinkedList中，因为我们希望能够轻松地从中弹出值。我们也只添加具有数字的实际图块并跳过空图块。 这实现了我们的平移，但还没有实现图块的合并： for (int x = 0; x \u0026lt; tiles.length; ++x) { LinkedList\u0026lt;Integer\u0026gt; thisRow = new LinkedList\u0026lt;\u0026gt;(); for (int y = 0; y \u0026lt; tiles[0].length; ++y) { if (tiles[x][y] \u0026gt; 0) { thisRow.add(tiles[x][y]); } } 接下来，我们需要合并图块。我们需要与上述分开执行此操作；否则，我们可能会多次合并同一个图块。 这是通过从上面构建另一个图块的LinkedList来实现的，但这次我们合并： LinkedList\u0026lt;Integer\u0026gt; newRow = new LinkedList\u0026lt;\u0026gt;(); while (thisRow.size() \u0026gt;= 2) { int first = thisRow.pop(); int second = thisRow.peek(); if (second == first) { int newNumber = first * 2; newRow.add(newNumber); newScore += newNumber; thisRow.pop(); } else { newRow.add(first); } } newRow.addAll(thisRow); 在这里，我们还计算了这一举动的新分数。这是由于合并而创建的图块的总和。 我们现在可以将其构建到结果数组中。一旦我们用完列表中的图块，其余部分将填充值“0”以表示它们是空白的： result[x] = new int[tiles[0].length]; for (int y = 0; y \u0026lt; tiles[0].length; ++y) { if (newRow.isEmpty()) { result[x][y] = 0; } else { result[x][y] = newRow.pop(); } } } 一旦我们完成了图块的移动，我们需要再次将它们操作回正确的旋转。这与我们之前所做的完全相反： if (move == Move.DOWN || move == Move.RIGHT) { result = reverse(result); } if (move == Move.LEFT || move == Move.RIGHT) { result = transpose(result); } 最后，我们可以用这组新的图块和新计算的分数构建并返回一个新的棋盘： return new Board(result, this.score + newScore); } **我们现在可以编写随机的“人类”玩家。**这只不过是生成一个随机移动并调用上述方法来移动： public class Human { private SecureRandom rng = new SecureRandom(); public Board makeMove(Board input) { Move move = Move.values()[rng.nextInt(4)]; return input.move(move); } } 2.3. 玩游戏 **我们有足够的组件来玩这个游戏，虽然不是很成功。**但是，很快我们将改进Human类的游戏方式，这将使我们能够轻松地看到差异。 首先，我们需要一种打印游戏板的方法。 对于这个例子，我们只是要打印到控制台，所以System.out.print已经足够好了。对于一个真正的游戏，我们想要做更好的图形： private static void printBoard(Board board) { StringBuilder topLines = new StringBuilder(); StringBuilder midLines = new StringBuilder(); for (int x = 0; x \u0026lt; board.getSize(); ++x) { topLines.append(\u0026#34;+--------\u0026#34;); midLines.append(\u0026#34;| \u0026#34;); } topLines.append(\u0026#34;+\u0026#34;); midLines.append(\u0026#34;|\u0026#34;); for (int y = 0; y \u0026lt; board.getSize(); ++y) { System.out.println(topLines); System.out.println(midLines); for (int x = 0; x \u0026lt; board.getSize(); ++x) { Cell cell = new Cell(x, y); System.out.print(\u0026#34;|\u0026#34;); if (board.isEmpty(cell)) { System.out.print(\u0026#34; \u0026#34;); } else { StringBuilder output = new StringBuilder(Integer.toString(board.getCell(cell))); while (output.length() \u0026lt; 8) { output.append(\u0026#34; \u0026#34;); if (output.length() \u0026lt; 8) { output.insert(0, \u0026#34; \u0026#34;); } } System.out.print(output); } } System.out.println(\u0026#34;|\u0026#34;); System.out.println(midLines); } System.out.println(topLines); System.out.println(\u0026#34;Score: \u0026#34; + board.getScore()); } 我们差不多准备好了。我们只需要进行设置。 这意味着创建棋盘、两名玩家，并让计算机进行两个初始动作——即在棋盘上放置两个随机数： Board board = new Board(4); Computer computer = new Computer(); Human human = new Human(); for (int i = 0; i \u0026lt; 2; ++i) { board = computer.makeMove(board); } 现在我们有了实际的游戏循环。这将是人类和计算机玩家轮流进行的重复，只有在没有空单元格时才停止： printBoard(board); do { System.out.println(\u0026#34;Human move\u0026#34;); System.out.println(\u0026#34;==========\u0026#34;); board = human.makeMove(board); printBoard(board); System.out.println(\u0026#34;Computer move\u0026#34;); System.out.println(\u0026#34;=============\u0026#34;); board = computer.makeMove(board); printBoard(board); } while (!board.emptyCells().isEmpty()); System.out.println(\u0026#34;Final Score: \u0026#34; + board.getScore()); 此时，如果我们要运行该程序，我们会看到正在玩 2048 的随机游戏。 3. 实现 2048 玩家 一旦我们有了玩游戏的基础，我们就可以开始实现“人类”玩家并玩更好的游戏，而不仅仅是选择随机方向。 3.1 模拟动作 我们在这里实现的算法是基于Expectimax算法的。因此，算法的核心是模拟每一个可能的动作，为每一个动作分配一个分数，然后选择一个做得最好的动作。 我们将大量使用Java 8 Streams来帮助构建此代码，原因我们稍后会看到。 我们将从在Human类中*重写 makeMove()*方法开始： public Board makeMove(Board input) { return Arrays.stream(Move.values()) .map(input::move) .max(Comparator.comparingInt(board -\u0026gt; generateScore(board, 0))) .orElse(input); } 对于我们可以移动的每一个可能的方向，我们生成新的棋盘，然后开始评分算法——通过这个棋盘，深度为 0。然后我们选择得分最高的棋步。 然后，我们的*generateScore()*方法模拟每一个可能的计算机移动——也就是说，将“2”或“4”放入每个空单元格——然后看看接下来会发生什么： private int generateScore(Board board, int depth) { if (depth \u0026gt;= 3) { return calculateFinalScore(board); } return board.emptyCells().stream() .flatMap(cell -\u0026gt; Stream.of(new Pair\u0026lt;\u0026gt;(cell, 2), new Pair\u0026lt;\u0026gt;(cell, 4))) .mapToInt(move -\u0026gt; { Board newBoard = board.placeTile(move.getFirst(), move.getSecond()); int boardScore = calculateScore(newBoard, depth + 1); return (int) (boardScore * (move.getSecond() == 2 ? 0.9 : 0.1)); }) .sum(); } 如果我们达到了我们的深度限制，那么我们将立即停下来计算这个板有多好的最终分数；否则，我们继续我们的模拟。 然后，我们的*calculateScore()*方法是我们模拟的延续，运行等式的人类移动方面。 *这与上面的makeMove()*方法非常相似，但我们返回的是正在进行的分数而不是实际的棋盘： private int calculateScore(Board board, int depth) { return Arrays.stream(Move.values()) .map(board::move) .mapToInt(newBoard -\u0026gt; generateScore(newBoard, depth)) .max() .orElse(0); } 3.2 计分决赛板 我们现在处于可以模拟人类和计算机玩家来回移动的情况，当我们模拟足够多时停止。我们需要能够为每个模拟分支中的最终板生成一个分数，以便我们可以看到哪个分支是我们想要追求的分支。 我们的评分是多个因素的组合，我们将把每个因素应用到板上的每一行和每一列。这些都加在一起，然后返回总数。 因此，我们需要生成要评分的行和列列表： List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; rowsToScore = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; board.getSize(); ++i) { List\u0026lt;Integer\u0026gt; row = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; col = new ArrayList\u0026lt;\u0026gt;(); for (int j = 0; j \u0026lt; board.getSize(); ++j) { row.add(board.getCell(new Cell(i, j))); col.add(board.getCell(new Cell(j, i))); } rowsToScore.add(row); rowsToScore.add(col); } 然后我们取出我们建立的列表，对每个列表进行评分，然后将分数相加。这是我们即将填写的占位符： return rowsToScore.stream() .mapToInt(row -\u0026gt; { int score = 0; return score; }) .sum(); 最后，我们实际上需要生成我们的分数。这进入了上面的 lambda，并且是几个不同的因素都有助于：  每行的固定分数 行中每个数字的总和 行中可能的每个合并 行中的每个空单元格 行的单调性。这表示该行按数字升序排列的数量。  在计算分数之前，我们需要构建一些额外的数据。 首先，我们想要一个删除了空白单元格的数字列表： List\u0026lt;Integer\u0026gt; preMerged = row.stream() .filter(value -\u0026gt; value != 0) .collect(Collectors.toList()); 然后我们可以从这个新列表中进行一些计数，给出具有相同数字的相邻单元格的数量，数字严格递增，数字严格递减： int numMerges = 0; int monotonicityLeft = 0; int monotonicityRight = 0; for (int i = 0; i \u0026lt; preMerged.size() - 1; ++i) { Integer first = preMerged.get(i); Integer second = preMerged.get(i + 1); if (first.equals(second)) { ++numMerges; } else if (first \u0026gt; second) { monotonicityLeft += first - second; } else { monotonicityRight += second - first; } } 现在我们可以计算这一行的分数： int score = 1000; score += 250 * row.stream().filter(value -\u0026gt; value == 0).count(); score += 750 * numMerges; score -= 10 * row.stream().mapToInt(value -\u0026gt; value).sum(); score -= 50 * Math.min(monotonicityLeft, monotonicityRight); return score; 这里选择的数字是比较随意的。不同的数字将对游戏的表现产生影响，在我们的游戏方式中优先考虑不同的因素。 4. 算法改进 **到目前为止，我们所拥有的东西是有效的，我们可以看到它玩得很好，但是速度很慢。**每个人的移动大约需要 1 分钟。我们可以做得比这更好。 4.1 并行处理 **我们可以做的显而易见的事情是并行工作。**这是使用 Java Streams 的巨大好处——我们可以通过向每个流添加单个语句来并行工作。 仅此更改就可以将我们的每次移动时间缩短到 20 秒左右。 4.2 修剪不可游戏的分支 **接下来我们可以做的就是修剪掉所有无法游戏的分支。**也就是说，任何时候人类移动都会导致棋盘不变。几乎可以肯定，这些分支会导致更糟糕的结果——它们有效地让计算机自由移动——但它们花费了我们处理它们的时间。 为此，我们需要在Board上实现一个 equals 方法，以便我们可以比较它们： @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } Board board1 = (Board) o; return Arrays.deepEquals(board, board1.board); } 然后，我们可以向我们的流管道添加一些过滤器，以停止处理任何未更改的内容。 return Arrays.stream(Move.values()) .parallel() .map(board::move) .filter(moved -\u0026gt; !moved.equals(board)) ........ 这对游戏的早期部分影响很小——当填充的单元格很少时，可以修剪的动作也很少。然而，后来，这开始产生更大的影响，将移动时间减少到只有几秒钟。 \u0026quot; ","permalink":"http://itcodingman.github.io/2048_java_solver/","tags":[],"title":"用 Java 解决 2048 游戏"},{"categories":["Processes"],"contents":" 概述   在使用 Linux 命令行界面时，通常会将程序的输出重定向为另一个程序的输入。 在本教程中，我们将研究在 Linux 中使用管道和命名管道。 什么是管道？   管道是基于 Unix 的系统中的一种重要机制，它允许我们将数据从一个进程传递到另一个进程，而无需在磁盘上存储任何内容。 在 Linux 中，我们有两种类型的管道：管道（也称为匿名或未命名管道）和 FIFO（也称为命名管道）。 管道   管道通过将命令串在一起使用，由管道字符分隔，\u0026rsquo; | \u0026lsquo;。这通常被称为管道，每个 shell 都定义了它的行为。 shell 在后台运行的单独进程中执行每个命令，从最左边的命令开始。 然后，左侧命令的标准输出连接到右侧命令的标准输入。这提供了流的单向性。 这种机制一直持续到管道中的所有进程都完成为止。 像 Bash 和 Zsh 这样的 shell 使用标记“ |\u0026amp; ”来指代管道，将左侧命令的标准输出和标准错误与右侧命令的标准输入连接起来。 假设我们想使用netstat命令查看使用 localhost 正在运行的进程并使用grep实用程序进行过滤： $ netstat -tlpn | grep 127.0.0.1 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN - 在这个示例输出中，我们在netstat中看到了脚本的 stdout 和 stderr，而不管过滤器如何。 现在，让我们将 stderr 合并到 stdout 并将其传递给grep的标准输入： $ netstat -tlpn |\u0026amp; grep 127.0.0.1 tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN - 我们已经将警告信息隐藏起来了。 3.1。Bash 中的管道 Bash 有一个名为PIPESTATUS的变量，其中包含最近执行的管道中进程的退出状态列表： $ exit 1 | exit 2 | exit 3 | exit 4 | exit 5 $ echo ${PIPESTATUS[@]} 1 2 3 4 5 整个管道执行的返回状态将取决于pipefail变量的状态。 如果设置了此变量，则管道的返回状态将是最右边的非零状态命令的退出状态，或者如果所有命令成功退出，则将为零： $ set -o pipefail $ exit 1 | exit 2 | exit 3| exit 4 | exit 0 $ echo $? 4 禁用 pipefail选项后，管道的返回状态将是最后一个命令的退出状态： $ set +o pipefail $ exit 1 | exit 2 | exit 3| exit 4 | exit 0 $ echo $? 0 Bash 也有lastpipe选项，它指示 shell 在当前环境的前台执行最后一个命令。 3.2. Zsh 中的管道 Zsh 对管道的控制与 Bash 类似，但有一些区别。例如，Zsh 有 pipestatus命令，它类似于 Bash 中的 PIPESTATUS 变量。 此外，Zsh 在单独的进程中执行每个管道中的命令，除了最后一个命令，它在当前 shell 环境中执行。 命名管道   FIFO，也称为命名管道，是一种类似于管道但在文件系统上具有名称的特殊文件。多个进程可以像任何普通文件一样访问这个特殊文件进行读写。 因此，该名称仅作为需要在文件系统中使用名称的进程的参考点。 FIFO 具有与任何其他文件相同的特性。例如，它具有所有权、权限和元数据。 FIFO 的另一个重要特性是它提供双向通信。 在 Linux 中，我们可以使用命令mknod（使用字母“p”表示 FIFO 类型）和mkfifo创建一个 FIFO ： $ mkfifo pipe1 $ mknod pipe2 p $ ls -l prw-r--r-- 1 cuau cuau 0 Oct 7 21:17 pipe1 prw-r--r-- 1 cuau cuau 0 Oct 7 21:17 pipe2 在这里，我们可以看到我们的 FIFO 的文件类型用字母“p”表示。 这种机制允许我们使用我们的 shell 创建更复杂的应用程序。 命名管道和匿名管道可以一起使用。让我们创建一个结合 FIFO 和管道的反向 shell。 我们将使用nc实用程序创建一个客户端/服务器应用程序，其中“服务器”端将提供其 shell，“客户端”端将能够访问它。 首先，让我们安装netcat-openbsd包。我们可以使用以下命令将它安装在任何 Ubuntu/Debian 系统上： $ sudo apt install netcat-openbsd 接下来，让我们创建一个名为fifo_reverse的 FIFO，输入mkfifo fifo_reverse。 然后，让我们使用两个不同的用户登录，每个用户都充当“客户端”（比如“user1”）和“服务器”（比如“user2”）。让我们在 user2 shell 上运行这个管道： user2_prompt$ bash -i \u0026lt; fifo_reverse |\u0026amp; nc -l 127.0.0.1 1234 \u0026gt; fifo_reverse 在这个单行程序中，shell 读取我们的 FIFO 的内容并将其传递给交互式 Bash shell。 接下来，交互式 shell 的 stdout 和 stderr 都将传递给nc命令，该命令将在地址 127.0.0.1 的端口 1234 上进行侦听。 最后，当“客户端”成功建立连接时，nc会将接收到的内容写入我们的 FIFO，交互式 shell 将能够执行接收到的内容。 现在，使用 user1 shell，让我们输入： user1_prompt$ nc 127.0.0.1 1234 user2_prompt$ 我们已经获得了 user2 提示，但使用了结合匿名和命名管道的 user1 shell。 临时命名管道   一些 shell 具有称为进程替换的功能，它将命令列表的输入或输出连接到 FIFO。然后这些命令将使用此 FIFO 的名称。 这种机制在 Bash 和 Zsh 中的表示法是*\u0026lt;(command list)将列表的结果传递给实际命令的标准输入，或\u0026gt;(command list)*将实际命令的标准输出传递给标准输入的名单。 让我们使用我们所看到的将多个命令的输出传递给wc命令： $ wc -l \\  \u0026lt;(find / -mindepth 1 -maxdepth 1 -type d) \\  \u0026lt;(find /opt -mindepth 1 -maxdepth 1 -type d) 20 /proc/self/fd/11 2 /proc/self/fd/12 22 total 在此示例输出中，我们使用 find命令获取*/和/opt*目录中的目录数。 何时使用命名管道或匿名管道？   使用匿名管道而不是命名管道取决于我们正在寻找的特性。其中一些可以是持久性、双向通信、具有文件名、创建过滤器和限制访问权限等。 例如，如果我们想多次过滤命令的输出，使用匿名管道似乎是最合适的选择。我们还要记住，当我们使用匿名管道时，我们使用的 shell 将发挥核心作用。 另一方面，如果我们需要一个文件名并且我们不想将数据存储在磁盘上，我们正在寻找的是一个 FIFO。如果我们只需要一个名称作为参考，其内容直接来自另一个进程。 另外，让我们考虑一下，虽然匿名管道可能看起来像管道类型的管道，但 FIFO 可以创建更复杂的图表。 \u0026quot; ","permalink":"http://itcodingman.github.io/anonymous_named_pipes/","tags":["netstat"],"title":"Linux 中的匿名和命名管道"},{"categories":["Administration"],"contents":"1. 概述 在本文中，我们将介绍 Linux 系统的环境变量，以及如果我们要创建新的或修改现有的，我们需要了解哪些规则。本文将重点介绍环境变量的语法。 2.环境变量 要开始我们的讨论，最好先看一下 Linux 系统上的环境变量。为此，我们可以键入printenv命令来查看它们： $ printenv SHELL=/bin/bash SESSION_MANAGER=local/username-VirtualBox:@/tmp/.ICE-unix/1644,unix/username-VirtualBox:/tmp/.ICE-unix/1644 QT_ACCESSIBILITY=1 COLORTERM=truecolor ... PATH=/home/username/anaconda3/bin:/home/username/anaconda3/condabin:/home/username/.local/bin:... GDMSESSION=ubuntu DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus _=/usr/bin/printenv 上面的输出显示了我们当前机器登录会话的环境变量列表。**在这里，我们可以很容易地找到NAME=VALUE的模式。**因此，我们需要注意不要在命名环境变量时使用等号（ “ = ” ）字符。 3. 环境变量定义 从 IEEE 和 The Open Group 发布的 The Open Group Base Specifications （AKA POSIX 法规）第 8 章文档中，我们可以找到环境变量构成的一般定义。除了使用等号（“ = ”）字符外，还有一些关于可用字符的一般规定。 3.1 使用便携式字符 为了确保我们的程序适用于所有机器，我们需要使用Open Group Base Specifications 第 6 章中定义的Portable Character Set中的字符 （NUL除外）。这些字符由POSIX.1-2017定义，并且在已正确安装的 Linux 系统中始终可用。 只允许使用此字符集中的大写字母、小写字母和下划线。 3.2. 注意案例 系统环境变量由大写字母、数字和下划线（“ _ ”）组成。然而我们仍然可以用小写字母定义环境变量。此外，字母表壳代表不同的含义，因此我们不想将表壳折叠在一起。 按照惯例，小写字母仅供应用程序使用。 3.3. 不要以数字开头 **某些应用程序无法处理以数字开头的环境变量。**如果我们以这种方式定义这些变量，可能会出现意外的行为。 POSIX 文档和我们都不建议在任何地方创建以此类数字开头的环境变量。 3.4. 变量名冲突 下表显示了我们需要避免冲突的变量，其中大部分是系统定义的，并且有一些特殊用途。 关键字表在这里：            ARFLAGS IFS MAILPATH PS1   CC LANG MAILRC PS2   CDPATH LC_ALL MAKEFLAGS PS3   CFLAGS LC_COLLATE MAKESHELL PS4   CHARSET LC_CTYPE MANPATH PWD   COLUMNS LC_MESSAGES MBOX RANDOM   DATEMSK LC_MONETARY MORE SECONDS   DEAD LC_NUMERIC MSGVERB SHELL   \u0026gt;EDITOR LC_TIME NLSPATH TERM   ENV LDFLAGS NPROC TERMCAP   EXINIT LEX OLDPWD TERMINFO   FC LFLAGS OPTARG TMPDIR   FCEDIT LINENO OPTERR TZ   FFLAGS LINES OPTIND USER   GET LISTER PAGER VISUAL   GFLAGS LOGNAME PATH YACC   HISTFILE LPDEST PPID YFLAGS   HISTORY MAIL PRINTER    HISTSIZE MAILCHECK PROCLANG    HOME MAILER PROJECTDIR     系统非常频繁地调用这些变量。因此，与它们发生冲突可能会导致严重错误。 \u0026quot; ","permalink":"http://itcodingman.github.io/allowed_characters_variable_names/","tags":["printenv"],"title":"Linux 环境变量名称中允许的字符"},{"categories":["Administration"],"contents":" 概述   在本文中，我们将讨论如何在 Linux 上查找所有串行设备而无需打开它们。这将显示系统拥有的设备，这在诊断或设置新设备时很有用。 问题陈述   */dev/*目录包含任何给定系统的每个设备的文件。对于串行设备，我们将仅限于那些同时支持波特率和 RTS/CTS 流控制的设备，它代表 RS-232 电信标准下的 Request-to-Send/Clear-to-Send。 我们不想打开设备，因为这可能需要一段时间并可能返回错误。尝试打开设备时，会执行连接尝试。当系统的驱动程序想要连接设备时，通过蓝牙提供的串行设备会发生这种行为的一个示例。 解决方案   通过查看不同的文件并使用多种工具，我们将介绍上述问题的四种解决方案。 3.1 */sys/class/*目录 */sys/class/目录下的文件系统提供有关连接到系统的设备的信息。在其中，*目录/sys/class/tty显示了串行设备、虚拟终端和伪终端，**具有特定串行设备组的子目录。 例如，让我们获取串行 USB 设备： $ ls /sys/class/tty/ttyUSB* /sys/class/tty/ttyUSB0 /sys/class/tty/ttyUSB1 如果我们访问其中一台设备的目录之一，我们会看到不同的文件： $ ls /sys/class/tty/ttyUSB0/ dev device power subsystem uevent **声明我们正在处理串行设备（而不是终端）的文件是device/driver **。因此，我们只能检查那些具有这些目录树的设备： $ ls /sys/class/tty/*/device/driver /sys/class/tty/ttyS0/device/driver /sys/class/tty/ttyS1/device/driver /sys/class/tty/ttyUSB0/device/driver /sys/class/tty/ttyUSB1/device/driver 一种幼稚且错误的方法是仅遍历*/dev/ttyS* 目录，因为我们也可以通过其他接口访问串行设备。使用 USB 到 RS-232 适配器，串行设备位于/dev/ttyUSB* *下，如示例中所示。类似地，其他命名空间可能包含其他串行设备。 3.2. dmesg工具 使用**dmesg工具，我们可以在屏幕上显示内核日志，其中存储了连接到系统的设备的驱动程序产生的所有信息**。我们必须从dmesg（我们感兴趣的串行设备）中搜索整个消息缓冲区： $ dmesg | grep tty 我们可能需要以超级用户权限执行前面的命令。 3.3. HAL 软件 硬件抽象层 ( HAL ) 是一种已被*udev*弃用的工具。但是，该工具仍然可以在 2008 年之前的较旧 Linux 版本上找到，这些版本也是最常见的具有旧串行接口标准的版本。 我们可以从所有可用的端口中获取那些能够进行串行传输的端口： $ hal-find-by-capability --capability serial 这将返回唯一设备标识符的列表。我们可以将 UDI值插入： $ hal-get-property --udi UDI --key serial.device 如果我们想探索所有串行设备，我们可以将这两个命令与一个for循环结合起来： $ for device in $(hal-find-by-capability --capability serial) ; do hal-get-property --udi \u0026#34;${device}\u0026#34; --key serial.device done 3.4. */dev/serial/*目录 如果我们处理较新的 Linux 内核，HAL 工具将不再可用。但是，我们可以利用udev（只要我们安装了早于 2.5. 的版本）。 *在/dev/serial/*目录中，有一个所有可用串行端口的列表。*它们是指向适当的/dev/*文件的符号链接。我们找到两组串口： $ ls /dev/serial/ by-id/ by-path/ 这两组是指同一个串口，但根据端口的不同信息进行组织。让我们看看每个人的样子： $ ls -l /dev/serial/by-id/ total 0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 tty-WM_Gmbh._Serial_Controller-port0 -\u0026gt; ../../ttyS0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 tty-WM_Gmbh._Serial_Controller-port1 -\u0026gt; ../../ttyS1 lrwxrwxrwx 1 root root 13 2015-07-20 04:03 usb-PTechnology_Inc._USB-Serial_Controller-if00-port0 -\u0026gt; ../../ttyUSB0 lrwxrwxrwx 1 root root 13 2015-07-20 04:04 usb-PTechnology_Inc._USB-Serial_Controller-if00-port1 -\u0026gt; ../../ttyUSB1 对于路径组，我们有： $ ls -l /dev/serial/by-path/ total 0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 pci-0000:00:0a.0-tty-1:1:1.0-port0 -\u0026gt; ../../ttyS0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 pci-0000:00:0a.0-tty-1:1:1.0-port1 -\u0026gt; ../../ttyS1 lrwxrwxrwx 1 root root 13 2015-07-20 04:03pci-0000:00:0b.0-usb-0:3:1.0-port0-\u0026gt; ../../ttyUSB0 lrwxrwxrwx 1 root root 13 2015-07-20 04:04 pci-0000:00:0b.0-usb-0:3:1.1-port1 -\u0026gt; ../../ttyUSB1 当系统中没有串行端口时，文件系统中不存在/dev/serial/目录。 \u0026quot; ","permalink":"http://itcodingman.github.io/all_serial_devices/","tags":[],"title":"无需打开即可在 Linux 上查找所有串行设备"},{"categories":["Scripting"],"contents":" 概述   Shell 程序通常实现命令别名功能，即当命令的别名存在时，Shell 替换命令的第一个单词。当命令冗长或频繁使用时，这可以方便地节省一些键盘敲击。 当别名共享相同名称时，别名可能会隐藏现有命令。在这种情况下，我们需要依靠变通方法来消除命令的歧义。 在本教程中，我们将快速介绍使用别名的一些非常基本的用法，然后我们将研究几种不同的方法来运行被别名遮蔽的命令。 别名   2.1 命令别名 **最常见的别名形式是命令别名，它是命令中第一个单词的文本替换。**让我们创建一些虚拟目录和文件并隐藏ls命令： $ { mkdir -p a b c; touch e f g; } $ alias ls=\u0026#39;echo foobar\u0026#39; $ ls # foobar 我们可以使用一个简单的别名命令列出 shell 会话中的别名： $ alias # alias ls=\u0026#39;echo foobar\u0026#39; 2.2. 全局别名 在 zsh shell 中，我们还可以使用另一种形式的别名，称为全局别名，以替换输入中任何位置的文本： $ alias -g t=\u0026#39;foobar\u0026#39; $ echo t # foobar 避免别名替换   有时我们希望 shell 在解释命令时忽略别名。我们可以使用几种不同的方法来解决阻碍别名的问题。 接下来，让我们看看如何使用这些不同的技术来解决我们在前面部分中配置的ls别名。 3.1 删除别名 **一个简单的unalias ls将从我们的 shell 会话中删除ls别名，**我们将能够调用先前隐藏的命令： $ unalias ls $ ls # a b c e f g 虽然是一种简单的解决方法，但这种方法的缺点是我们将丢失 shell 会话中的别名。 3.2. 报价 **另一种技术是通过“引用”命令从命令中删除特殊含义。**只要字符串中的任何字符被引用，命令就会被视为引用。让我们看看引用命令的三种不同方式。 首先，我们可以使用转义字符（\\）来保留命令的字面意思： $ \\ls # a b c e f g 另一种选择是使用单引号 ('...') 来引用命令： $ \u0026#39;ls\u0026#39; # a b c e f g 我们可以使用双引号（”...”）来引用命令： $ \u0026#34;ls\u0026#34; # a b c e f g 引用是一个较少讨论的 shell 概念，有几点需要指出。我们应该知道，没有必要引用整个命令，以便 shell 将命令视为已引用。以下引用变体同样“引用” ls命令： $ l\\s # a b c e f g $ l\u0026#39;s\u0026#39; # a b c e f g $ l\u0026#34;s\u0026#34; # a b c e f g 我们还应该注意不要将别名与 shell 函数混淆，因为 shell 函数是常规命令，因此引用它们不会有任何效果： $ function foobar () { echo helloworld; } $ foo\\bar # helloworld 3.3. command（内置） 自命名的内置command可用于将命令的解释范围缩小到仅在***$PATH*****或 shell 内置目录中找到的可执行文件。**让我们看看如何使用命令忽略ls别名： $ command ls # a b c e f g 3.4. 绝对路径 当别名隐藏可执行文件时，一个简单的解决方案是简单地将可执行文件的完整路径名指定为 command。我们可以使用一些工具在$PATH目录中找到可执行文件： 我们可以使用which在我们的*$PATH中搜索与提供的文件名匹配的可执行文件。如果找不到可执行文件，那么它将*以退出代码 1 终止。让我们看看实际情况： $ which ls # /usr/bin/ls $ which foobar $ echo $? # 1 我们还可以使用type内置命令来了解 shell 如何解释命令： $ type -a ls # ls is aliased to `ls --color=auto\u0026#39; # ls is /usr/bin/ls # ls is /bin/ls \u0026quot; ","permalink":"http://itcodingman.github.io/alias_run_shadowed_command/","tags":["alias"],"title":"运行受别名影响的命令"},{"categories":["File Permissions","Files","Security"],"contents":" 概述   在 Linux 中，我们知道文件可以具有读、写和执行(rwx)权限标志。 除了这些标准权限外，还有三个特殊权限可用。 在本教程中，让我们看一下特殊类型的权限，并学习如何使用 Linux 命令设置和删除这些标志。 setuid   **通常，当一个进程在类 Unix 操作系统中启动时，它会以启动它的用户的有效用户 ID 和组 ID 以及相应的权限运行。**但是，如果我们对可执行文件设置特殊权限，则可以更改此行为。 setuid表示“设置用户 ID”。如果我们在一个可执行文件上设置setuid位，该文件总是以文件所有者的权限运行，无论是谁启动它。 setuid位仅在设置在可执行文件上时才有意义。如果我们在非可执行文件或目录上设置setuid位，则没有实际意义。 passwd命令是一个带有这个特殊位集的示例： $ ls -l /bin/passwd -rwsr-xr-x 1 root root 63624 Dec 15 21:06 /bin/passwd 我们注意到所有者的执行权限是小写的“s”而不是通常的“x”。这个“s”表示文件设置了setuid位。passwd命令将始终以 root权限运行，无论是谁启动它，因为文件的所有者是root。 我们可以使用chmod命令来设置文件的 setuid位： chmod u+s FILE 只有文件的所有者或root用户才能设置setuid位。 让我们看一个在文件上设置setuid位的示例： $ ls -l file -rwxr-xr-x 1 kent kent 0 Feb 2 12:22 file $ chmod u+s file $ ls -l file -rwsr-xr-x 1 kent kent 0 Feb 2 12:22 file 或者，我们也可以通过在模式前面加上“4”来使用八进制表示法设置setuid位： $ chmod 4755 file -rwsr-xr-x 1 kent kent 0 Feb 2 12:22 file 要删除setuid位，我们将我们传递给 chmod 命令： $ chmod u-s file $ ls -l file -rwxr-xr-x 1 kent kent 0 Feb 2 12:22 file setgid位   3.1 文件上的setgid位 setgid是“set group id”的缩写。如果我们在可执行文件上设置setgid位，那么无论谁启动该文件，它都会以所属组的权限运行。 定位**命令是设置了setgid位的文件示例： $ ls -l /usr/bin/locate -rwxr-sr-x 1 root locate 43048 Nov 13 18:09 /usr/bin/locate 与 setuid位类似，我们注意到ls*输出中有一个小写的“s” ，除了它在组部分而不是所有者部分中。 我们可以通过将g+s传递给chmod命令来设置文件的setgid位： $ ls -l file2 -rwxr-xr-x 1 kent kent 0 Feb 2 22:35 file2 $ chmod g+s file2 $ ls -l file2 -rwxr-sr-x 1 kent kent 0 Feb 2 22:35 file2 或者，我们可以通过在模式前面加上“2”来使用八进制表示法设置setgid位： chmod 2755 file2 如果我们想删除文件上的setgid位，我们将 gs传递给 chmod命令： $ chmod g-s file2 $ ls -l file2 -rwxr-xr-x 1 kent kent 0 Feb 2 22:35 file2 3.2. 目录上的setgid位 **如果我们在一个目录上设置setgid位，则该目录中所有新创建的文件和子目录都将继承该目录的组。**但是，现有文件和目录不会应用组更改。 让我们看一个例子来阐明这种行为。 首先，我们准备一个包含两个文件的parent目录： $ ls -ld parent drwxrwxrwx 2 root kent 4096 Feb 3 00:33 parent/ $ ls -l parent total 2 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest1 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest2 parent 由用户root和组kent拥有。它包含两个文件，组来宾拥有这两个文件。 接下来，让我们 使用chmod在parent上设置setgid位： root# chmod g+s parent root# ls -ld parent drwxrwsrwx 2 root kent 4096 Feb 3 00:33 parent/ 现在，我们将使用root在parent目录下创建一个新文件和一个子目录： root# touch parent/new_file_by_root root# mkdir parent/new_dir_by_root 然后，我们将检查parent下所有文件和子目录的组所有者： root# ls -l parent total 4 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest1 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest2 drwxr-sr-x 2 root kent 4096 Feb 3 00:54 new_dir_by_root/ -rw-r--r-- 1 root kent 0 Feb 3 00:54 new_file_by_root 在上面的输出中，我们看到在parent上设置setuid位后，两个现有文件没有改变。 但是，新创建的文件和子目录由kent而不是 root拥有，即使是root创建了它们。这是因为parent设置了setgid位，并且它下新创建的文件和目录继承了parent的组。 sticky位   4.1 sticky位 粘性位是保护目录中的文件。如果我们在一个目录上设置sticky位，那么这个目录下的文件只能通过以下方式之一删除：  文件的所有者 目录的所有者 根用户  换言之，此特殊权限可防止用户在公共目录中删除其他用户的文件。 /tmp目录是一个典型的真实世界sticky位示例： $ ls -ld /tmp drwxrwxrwt 24 root root 980 Feb 3 21:41 /tmp/ 由于“其他”权限部分中的“w”，我们知道任何用户都可以创建和删除*/tmp*目录下的任何文件。 但是如果我们仔细阅读上面的ls输出，我们会发现“other”部分中的执行权限位是小写的“t”，而不是通常的“x”。 这个小写字母*“t”表示 /tmp目录设置了粘性位。使用粘性位，任何用户仍然可以在/tmp* 下创建文件。但是，用户只能删除自己拥有的文件。 4.2. 目录上的sticky bit 要在目录上设置sticky bit，我们仍然可以使用 带有模式*+t的chmod*命令： chmod +t DIRECTORY 或者，我们也可以在目录模式前加上“1”来设置sticky bit： chmod 1777 DIRECTORY 我们还可以使用-t**从目录中删除sticky bit： chmod -t DIRECTORY 和往常一样，让我们看一个例子来了解sticky bit如何保护目录下的文件以及如何设置和删除目录上的sticky bit。 让我们从准备一个名为public的公共目录开始，并允许所有用户写入它： $ ls -ld public drwxrwxrwx 2 root root 40 Feb 3 22:22 public/ 接下来，我们将在不同用户的public下创建一些文件： $ ls -l -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file1_by_guest -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file2_by_guest -rw-r--r-- 1 kent kent 0 Feb 3 22:28 file_by_kent 到目前为止，我们还没有在任何地方设置sticky bit。让我们看看用户kent是否可以删除guest拥有的文件： kent$ rm file1_by_guest rm: remove write-protected regular empty file \u0026#39;file1_by_guest\u0026#39;? y kent$ ls -l -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file2_by_guest -rw-r--r-- 1 kent kent 0 Feb 3 22:28 file_by_kent 因此，没有sticky bit，我们可以删除其他用户拥有的文件。 现在，让我们设置sticky bit，看看是否有任何变化： root# chmod +t public root# ls -ld public drwxrwxrwt 2 root root 80 Feb 3 22:33 public/ root# su kent kent$ rm file2_by_guest rm: remove write-protected regular empty file \u0026#39;file2_by_guest\u0026#39;? y rm: cannot remove \u0026#39;file2_by_guest\u0026#39;: Operation not permitted kent$ ls -l -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file2_by_guest -rw-r--r-- 1 kent kent 0 Feb 3 22:28 file_by_kent 设置sticky bit后*，* public下的文件 只能被文件所有者删除。 安全   setuid位在各种应用程序中可能非常方便。但是，当我们设置这些特殊权限时，我们必须谨慎，因为它会产生安全问题。 例如，典型用户可以通过执行将UID设置 为root的程序来获得超级用户权限。 5.1 权限提升 **我们监控系统是否有任何可疑的setuid位使用以获得超级用户权限是一个很好的做法。**我们可以使用find命令找到所有由root拥有并带有setuid位的文件： root# find / -user root -perm -4000 -exec ls -ldb {} \\; ... -rwsr-xr-x 1 root root 30744 Dec 12 22:11 /usr/lib/virtualbox/VBoxNetAdpCtl -rwsr-xr-x 1 root root 161720 Dec 12 22:11 /usr/lib/virtualbox/VBoxNetDHCP -rwsr-xr-x 1 root root 71728 Dec 15 21:06 /usr/bin/chage -rwsr-xr-x 1 root root 145176 Jan 1 13:17 /usr/bin/sudo -rwsr-sr-x 1 root root 38664 Nov 13 18:49 /usr/bin/unix_chkpwd -rwsr-xr-x 1 root root 12360 Dec 15 2013 /usr/bin/sflock ... 5.2. setuid和解释的可执行文件 解释的可执行文件通常是一个可执行文件，它通过shebang声明解释器。例如，以“ #!/bin/bash ”开头的 Bash 文件或以“ #!/usr/bin/env python ”开头的可执行 Python 源文件。 出于安全原因， Linux 忽略所有解释的可执行文件上的 setuid位。如果我们希望我们的 shell 脚本拥有setuid权限，我们可以使用sudo命令获得脚本文件所有者的权限。 \u0026quot; ","permalink":"http://itcodingman.github.io/advanced_file_permissions/","tags":["chmod"],"title":"Linux 中的高级文件权限"},{"categories":["File Editing","Files"],"contents":" 概述   我们有时需要快速更改文件，最好是从命令行本身。在文件的每一行末尾添加一个字符串就是这样一种更改。 在本教程中，我们将研究使用sed、awk、echo和perl 执行此操作的多种方法。 问题陈述   在本文中，我们将使用以下名为test.txt的示例文件： $ cat test.txt Python Java JavaScript PHP 我们将看到如何添加字符串“是一种很棒的编程语言”。使用不同的方法到我们的test.txt文件中每一行的末尾。 3.使用sed sed（流编辑器）是 Linux 中一个强大的内置实用程序。我们可以使用它来执行文件的查找和替换、搜索、插入和删除等功能。 我们可以使用sed来编辑文件，甚至无需打开它们，这使得它可以轻松快捷地执行不同的文件功能。 让我们在测试文件上运行sed命令： $ sed -i s/$/ is a great programming language./ test.txt Python is a great programming language. Java is a great programming language. JavaScript is a great programming language. PHP is a great programming language. 让我们分解此命令以了解更多信息：  -i：指示sed就地编辑文件 s : 用于替换 / : 用于基于正则表达式的替换 $ : 匹配行尾的正则表达式 ” is a great\u0026hellip;”：表示我们要添加的字符串  但是我们的结果只打印在标准输出上。要保存更改，我们需要修改我们的命令： $ sed -i s/$/ is a great programming language./ test.txt \u0026gt; test_sed.txt 这会将我们的更改保存到test_sed.txt文件中。 4.使用awk awk是包含在 Unix 和大多数 Unix 变体中的脚本语言。它的开发者名字是 Aho、Weinberger 和 Kernighan 的缩写，他们于 1977 年建造了它。 awk使我们能够以语句的形式编写小程序，这些语句定义要在文件的每一行中搜索的文本模式，并在找到匹配项后执行操作。 让我们输入以下命令来添加我们的字符串： $ awk \u0026#39;{print $0, \u0026#34; is a great programming language.\u0026#34;}\u0026#39; test.txt Python is a great programming language. Java is a great programming language. JavaScript is a great programming language. PHP is a great programming language. 让我们理解命令：  print：用于从输入文件中输出选定的数据。 $0：用于匹配整行的正则表达式。 ” is a great\u0026hellip;”：表示我们要在每行末尾添加的字符串。  此命令将结果输出到标准输出 (STDOUT)。 让我们修改它以将我们的更改保存到另一个文件： $ awk \u0026#39;{print $0, \u0026#34; is a great programming language.\u0026#34;}\u0026#39; test.txt \u0026gt; test_awk.txt 5.使用回声 众所周知，*echo*命令将文本写入标准输出（STDOUT）。 虽然echo命令的行为因 shell 而略有不同，但我们将在此处介绍 bash 内置版本。 让我们结合*cat命令并运行echo：* $ cat test.txt | while read line; do echo ${line}$\u0026#34; is a great programming language.\u0026#34;; done Python is a great programming language. Java is a great programming language. JavaScript is a great programming language. PHP is a great programming language. 和以前一样，让我们分解一下：  cat：我们首先使用cat来读取我们的文件。 | pipe：我们用它来将cat与一个附加命令结合起来。 while\u0026hellip;do：我们使用 while 循环遍历文件中的每一行。 done：一旦完成，我们就使用它来终止我们的函数。  但是，我们的结果只打印到标准输出 (STDOUT)，以保存我们的更改。 让我们将更改保存到一个名为test_echo.txt的新文件中： $ cat test.txt | while read line; do echo ${line}$\u0026#34; is a great programming language.\u0026#34; \u0026gt;\u0026gt; test_echo.txt; done 6.使用perl perl (Practical Extraction and Report Language)是一种**最初为扫描任意文本文件、从中提取信息并根据输入数据生成报告而优化的语言。**它结合了sed、awk和sh的一些特性，使我们能够更轻松、更熟悉地快速解决常见问题。 让我们运行perl命令： $ perl -pi -e \u0026#39;s/$/\\ is a great programming language./\u0026#39; test.txt 让我们仔细看看以了解更多信息：  *-pi：*我们使用这个标签来打印和保存我们的更改。 -e：我们使用这个标签，以便我们可以从终端执行perl代码，而不是创建一个文件。 s/$/：代表一个正则表达式，它以我们文件中每一行的结尾为目标。  上面的命令没有显示标准输出的结果。但是，我们可以对输入文件本身使用cat命令来查看更改。由于perl直接对输入文件进行更改，因此我们不需要创建新文件。 \u0026quot; ","permalink":"http://itcodingman.github.io/add_string_line_end/","tags":["awk","echo","file","perl","sed"],"title":"如何在 Linux 中的文件中的每一行之后添加一个字符串"},{"categories":["Scripting"],"contents":" 概述   我们可以想象需要在变量中插入换行符的情况。例如，对于任何需要文本格式的任务，生成要运行的命令列表。 出于这个原因，在本教程中，我们将举例说明如何在 bash 中将换行符插入到变量中。 2.显示已经格式化的文本 首先，我们想简要介绍一下用换行符显示文本的可能性。 假设我们有带有换行符的文本。鉴于让我们尝试使用*echo*： $ text=\u0026#34;first \\nsecond \\nthird\u0026#34; $ echo $text first \\nsecond \\nthird 正如我们所见，\\ n序列未被识别为新行。 2.1 echo -e命令 为了能够识别特殊字符序列，例如换行符*\\n*，我们可以使用带有特殊选项*-e的echo*： $ text=\u0026#34;first \\nsecond \\nthird\u0026#34; $ echo -e $text first second third 这一次我们已经实现了我们想要的，并且单词换行了。 2.2. printf命令 使用printf我们可以完成与使用echo -e相同的结果： $ text=\u0026#34;first \\nsecond \\nthird\u0026#34; $ printf %b $text first second third 2.3. 带有换行符的文本 让我们考虑一下当我们有一个带有换行符的文本时的情况： $ text=\u0026#34;first second third\u0026#34; $ echo \u0026#34;$text\u0026#34; first second third 正如我们所看到的，当我们处理包含插入换行符的文本时，我们也可以根据需要显示文本。但是，让我们注意我们必须用括号包裹变量，否则它不会显示带有新行的文本。 2.4. 外壳参数扩展 此外，我们可以通过参数扩展来操作文本。 为此，我们需要在所有出现的*\\n之前添加**$*运算符： $ text=\u0026#34;first \u0026#34;$\u0026#39;\\n\u0026#39;\u0026#34;second \u0026#34;$\u0026#39;\\n\u0026#39;\u0026#34;third\u0026#34; $ echo \u0026#34;$text\u0026#34; first second third 3.自动在文本中添加换行符 在上一节中，我们展示了如何显示和格式化文本以打印新行。但是，在实际示例中，具有预处理文本并根据指定规则添加换行符的能力可能非常有用。因此，我们准备了一些如何在文本中设置新行的示例。 3.1 顺序添加换行符 假设我们想在文本中插入换行符而不是空格，我们之前用作示例。因此，我们可以例如遍历每个世界并插入我们在上一节中已经知道的特殊序列字符之一： $ text=\u0026#34;first second third\u0026#34; $ for word in $text $ do $ p+=\u0026#34;$word\u0026#34;$\u0026#39;\\n\u0026#39; $ done $ echo \u0026#34;$p\u0026#34; first second third 正如我们所见，它很好用！ 3.2. 添加换行符而不是所选字符 但是如果我们想添加一个换行符而不是“;”呢？或除空格以外的任何其他字符？出于这个原因，我们必须稍微修改一下我们之前的脚本： $ text=\u0026#34;first ; second ; third\u0026#34; $ IFS=\u0026#34;;\u0026#34; $ for word in $text; do \u0026gt; p+=\u0026#34;$word\u0026#34;$\u0026#39;\\n\u0026#39; \u0026gt; done $ echo \u0026#34;$p\u0026#34; first second third 完美的！所以现在我们知道如何在变量中存储换行符，也知道如何操作任何文本或命令序列来在我们想要的任何地方插入换行符。 3.3. 使用*tr*命令 我们可以使用更方便的东西，而不是遍历文本中的所有单词。因此，对于我们的目的而言， *tr*将是一个完美的选择： $ text=\u0026#34;first second third\u0026#34; $ echo $text | tr \u0026#34; \u0026#34; \u0026#34;\\n\u0026#34; first second third 结果与我们使用循环时的结果相同，但这次我们将所有内容放在一行中。 将文件中的文本分配给变量   现在假设我们想使用存储在文件中的文本。出于这个原因，使用先前提供的命令没有任何障碍。但是，在处理文件中的文本时，我们首先想到的是sed命令。 4.1 使用sed命令 当然，结合echo的sed命令也可以用于我们使用分配给变量的文本的示例。但是为了使其优雅而不需要编写多于一行的代码，我们使用sed准备了示例： $ cat text.txt one two three four five six $ text=$(sed \u0026#39;s/ /\\n/g\u0026#39; text.txt) $ echo $text one two three four five six 很棒，只需要一行代码，我们就可以从文件中读取文本，插入换行符而不是空格（当然我们可以将任何字符交换到换行符），并将其分配给一个变量。 4.2. awk命令 我们认为拥有更多选择总是更好。考虑到这一点，我们想再举一个在变量中插入换行符的例子： $ cat text.txt one two three four five six $ text=$(awk \u0026#39;{gsub(/ /,\u0026#34;\\n\u0026#34;)}1\u0026#39; text.txt) $ echo $text one two three four five six 它的工作与sed几乎相同，但awk有很多附加功能，这可能对我们非常有用。 \u0026quot; ","permalink":"http://itcodingman.github.io/add_newline_variable_bash/","tags":["awk","printf","sed","tr"],"title":"在 Bash 的变量中插入换行符"},{"categories":["Scripting"],"contents":" 概述   在本教程中，我们将学习如何在 Bash shell 中将一列数字相加。我们将仔细研究一些可用于此目的的 Bash 实用程序。我们还将对所提供解决方案的性能进行基准测试。 设置   首先，让我们设置我们将在大部分教程中使用的输入文件： $ for i in `seq 1000000`; do echo $(($RANDOM%100)); done \u0026gt;numbers.csv 在这里，我们正在生成一个文件numbers.csv，其中包含 1-100 范围内的一百万个随机数。我们使用seq命令运行一个for循环，使用RANDOM内置变量生成 1,000,000 个数字。 在接下来的部分中，我们还将查看使用time命令提供的解决方案的本地速度，以了解每个命令的执行方式。 3.使用awk工具 让我们从*awk*命令开始计算列中数字的总和： $ awk \u0026#39;{Total=Total+$1} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; numbers.csv Total is: 49471228 现在，让我们看看使用time命令的执行时间： $ time awk \u0026#39;{Total=Total+$1} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; numbers.csv Total is: 49471228 real 0m0.228s user 0m0.141s sys 0m0.047s 它非常快！我们可以在 0.228 秒内计算出一百万个数字的总和。事实上，awk是 Bash 中用于文件处理的最强大的工具之一。 3.1 当文件包含多列时 到目前为止，我们知道一种使用awk将列中的数字相加的方法。让我们看看我们在一个文件中有多个列并且我们只对计算特定列的总和感兴趣的情况： $ cat prices.csv Books,40 Bag,70 Dress,80 Box,10 此处，文件prices.csv包含两列。现在，让我们计算第二列中元素的总和： $ awk -F \u0026#34;,\u0026#34; \u0026#39;{Total=Total+$2} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; prices.csv Total is: 200 3.2. 当文件包含标题行时 有时，文本或 CSV 文件也包含标题行。该标题行通常包含列名，以提高可读性。让我们修改我们的prices.csv并添加一个标题行： $ cat prices.csv Item,Value Books,40 Bag,70 Dress,80 Box,10 当文件包含标题行时，我们希望在文本处理发生之前消除此标题行。有几种方法可以实现这一点。在这种情况下，我们将使用awk工具来忽略标题行。所以，让我们继续修改我们的命令来计算列总和： $ awk -F \u0026#34;,\u0026#34; \u0026#39;NR!=1{Total=Total+$2} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; prices.csv Total is: 200 在接下来的部分中，我们将检查一些其他方法来将列中的数字相加，并评估awk解决方案相对于这些方法的执行情况。 使用 Bash 循环进行迭代   awk是一个很棒的工具，但是，我们也可以使用循环来遍历列值。 4.1 使用expr命令 让我们运行一个实验并检查expr 命令在for循环中计算总和的有效性： $ time (sum=0;for number in `cat numbers.csv`; do sum=`expr $sum + $number`; done; echo \u0026#34;Total is: $sum\u0026#34;) Total is: 49471228 real 212m48.418s user 7m19.375s sys 145m48.203s **处理速度非常慢。使用expr命令，添加一百万个数字需要 3.5 多个小时。**值得注意的是，expr实用程序是 Bash 早期的遗留物，我们应该只在我们的脚本需要与遗留（POSIX 之前）实现互操作的情况下使用它。 4.2. 使用算术展开 由于使用expr命令没有多大帮助，让我们尝试另一种使用算术扩展的方法： $ time (sum=0;for number in `cat numbers.csv`; do sum=$((sum+number)); done; echo \u0026#34;Total is: $sum\u0026#34;) Total is: 49471228 real 0m1.961s user 0m1.813s sys 0m0.125s 在这里，我们使用算术展开式计算总和，形式为$((..))。与expr命令相反，使用算术扩展，我们能够在两秒内添加一百万个数字。**算术扩展允许我们执行简单的整数算术。但是，它不适用于浮点数。因此，对于浮点运算，我们必须使用bc命令。我们将在下一节检查bc命令的实现。 使用bc命令添加值   bc命令对单行表达式执行计算。因此，我们需要将这些数字组合成一行，并由加法运算符分隔。然后我们将表达式传递给bc以计算总数。让我们来看看实现这一点的几种方法。 5.1 使用paste命令 首先，**让我们看一下将数据集的前 10 个数字排列在一行中的paste**命令，它们之间使用加号 (+) 运算符： $ cat numbers.csv| head -10 | paste -sd+ - 2+44+6+15+23+0+15+88+82+1 选项*-s*确保 paste 将所有数字连接在一行中。我们还指定了 d+ 选项以在加入条目时添加“+”字符作为分隔符。 有了这个，我们准备将这个序列作为标准输入提供给bc命令： $ time echo \u0026#34;Total is: $(cat numbers.csv | paste -sd+ - | bc)\u0026#34; Total is: 49471228 real 0m0.244s user 0m0.203s sys 0m0.063s 值得注意的是，性能优于我们使用 Bash 循环观察到的性能（约 2 秒）。此外，它接近但无法击败awk命令的性能（0.228 秒）。 5.2. 使用tr命令 与粘贴命令类似，让我们再次使用tr命令生成一个序列： $ cat numbers.csv | head -10 |tr \u0026#34;\\n\u0026#34; \u0026#34;+\u0026#34; 2+44+6+15+23+0+15+88+82+1+ 在这里，我们将每个换行符*(\u0026rsquo;\\n\u0026rsquo;)转换为加号(\u0026rsquo;+\u0026rsquo;)字符。但是，请注意序列末尾的额外“+” 。作为一种解决方法，我们可以在最后添加一个额外的零来解决这个问题，然后再将它传递给bc*命令： $ cat numbers.csv | head -10 |tr \u0026#34;\\n\u0026#34; \u0026#34;+\u0026#34; ; echo \u0026#34;0\u0026#34; 2+44+6+15+23+0+15+88+82+1+0 现在，让我们将输出重定向到bc命令： $ time ((cat numbers.csv | tr \u0026#34;\\n\u0026#34; \u0026#34;+\u0026#34; ; echo \u0026#34;0\u0026#34;) | bc) 49471228 real 0m0.217s user 0m0.203s sys 0m0.031s tr和bc命令的组合执行速度比awk解决方案快。** 5.3. 使用sed命令 最后，我们将使用sed命令生成序列： $ cat numbers.csv | head -10 | sed -z \u0026#39;s#\\n#+#g\u0026#39; 2+44+6+15+23+0+15+88+82+1+ 同样，我们使用sed命令的搜索和替换选项将换行符*(\u0026rsquo;\\n\u0026rsquo;)替换为加号(\u0026rsquo;+\u0026rsquo;)*字符。此外，我们在末尾打印零来处理额外的加号运算符，类似于上一节： $ time ((cat numbers.csv | sed -z \u0026#39;s#\\n#+#g\u0026#39; ; echo \u0026#34;0\u0026#34;) | bc) 49471228 real 0m0.343s user 0m0.281s sys 0m0.109s 在这里，使用*-z选项会更改sed命令的换行符的含义。它将不再将\\n视为行尾，而是将空字符解释为行尾。实际上，我们可以用加号(\u0026rsquo;+\u0026rsquo;)字符替换换行符(\u0026rsquo;\\n\u0026rsquo;)*。 请注意，与tr和paste选项相比，用sed替换字符很慢。 在我们结束之前，我们应该知道，对于包含单个数字列的文件，非*awk替代方案可能运行得更快。*但是在许多现实世界的场景中，文件将包含多个列，并且在实际计算发生之前要去除一些附加信息（有点类似于我们在第 3.1 节中的讨论）。 在这种情况下，awk应该是首选工具，因为非awk替代方案的所有速度优势将被在计算其元素之和之前预处理文件以提取单个列所花费的时间所消耗。 \u0026quot; ","permalink":"http://itcodingman.github.io/add_column_of_numbers/","tags":["awk","expr","paste","sed","tr"],"title":"如何在 Bash 中添加一列数字"},{"categories":["Files"],"contents":" 简介   在本教程中，我们将了解如何使用两种常见的 Linux 文件系统工具获取给定文件的绝对目录。 2.先决条件 不幸的是，目前没有一个命令可以获取文件的绝对目录。相反，我们必须将操作分成两部分，使用一个命令的输出作为另一个命令的输入。 2.1 readlink 要获取文件的完整路径，我们使用readlink命令。readlink打印符号链接的绝对路径，但作为副作用，它还打印相对路径的绝对路径。 例如，假设我们有以下目录结构： / └── home/ └── example/ ├── foo/ | └── file.txt └── link -\u0026gt; foo/ 我们使用*-f标志来规范化相对路径或符号链接的路径。因此，如果我们将目录更改为/home/example/*，我们可以执行以下任何命令： readlink -f foo/file.txt readlink -f link/file.txt readlink -f ./foo/file.txt readlink -f ../example/foo/file.txt 这些命令将输出： /home/example/foo/file.txt 对于第一个命令，readlink将*foo/的相对路径解析为/home/example/foo/*的绝对路径。 在第二种情况下，readlink将*link/*的符号链接解析为相同的绝对路径。 对于最后两个命令，readlink将相对路径规范化并解析为与前面示例相同的绝对路径。 请注意，-f标志要求除了提供的路径中的最后一个组件（在我们的例子中为file.txt）之外的所有组件都必须存在。如果路径不存在，则不返回任何输出。例如，执行readlink -f bar/file.txt将不会产生任何输出，因为bar/目录不存在。相反，执行readlink -f foo/other.txt将返回*/home/example/foo/other.txt*，因为除了最终组件之外的所有组件都存在。 相反，如果我们不关心提供的路径中是否存在任何组件，我们可以使用*-m标志。同样，如果我们希望提供的路径中的所有组件都存在，我们可以使用-e标志。* 2.2 dirname 第二个先决条件是dirname命令，它打印包含提供的路径的目录。 如果我们提供一个目录，dirname会输出包含该目录的路径。例如，我们可以执行： dirname /home/example/foo/ 这将产生： /home/example 请注意，dirname会打印绝对目录，因为我们提供了绝对路径。如果我们将目录更改为*/home/并执行dirname example/foo/，dirname将输出example*。通常，如果提供了相对路径，则dirname将输出一个相对目录，如果提供了绝对路径，则dirname将输出一个绝对目录。 提供文件时，dirname输出包含该文件的路径。例如，我们可以执行： dirname foo/file.txt 这将产生： foo 3.文件的绝对目录 要获取文件的绝对目录，我们结合使用readlink和dirname命令。我们可以通过以下两种方式之一来做到这一点。 3.1 xargs 首先，我们可以使用xargs命令，它将输入转换为所提供命令的参数。通过将readlink的输出传送到xargs并将命令dirname作为参数提供给xargs，我们可以获得这个所需的绝对目录： readlink -f foo/file.txt | xargs dirname 这导致： /home/example/foo 3.2 命令替换 类似地，我们可以使用命令替换- $(command) - 在子 shell 中执行命令，并且该命令的输出替换它的调用。因此，我们可以执行以下操作： dirname $(readlink -f foo/file.txt) 此命令导致： /home/example/foo 等效地，我们也可以执行以下命令，并且输出将保持不变： dirname `readlink -f foo/file.txt` 请注意，命令替换适用于 bash，但不一定适用于其他 shell。 \u0026quot; ","permalink":"http://itcodingman.github.io/absolute_directory_of_file/","tags":["dirname","readlink"],"title":"在 Linux 中获取文件的绝对目录"},{"categories":["Processes","Scripting"],"contents":" 概述   使用Bash 脚本，我们拥有了一个强大的工具。Bash 脚本是连续运行多个命令的好方法。在编写脚本的时候，我们要提醒自己，如果一个命令失败了，后面的所有命令仍然会执行。在本文中，我们将学习如何通过添加一些保护措施来防止这种情况。本文示例中使用的命令已经在 Bash 中进行了测试。它们也应该在其他 POSIX 兼容的 shell 中工作。 2.问题 首先，让我们看一下 bash 脚本在默认情况下是如何处理错误的。假设我们有一个简单的脚本hello.sh打印单词 \u0026lsquo;hello\u0026rsquo; 和 \u0026lsquo;world\u0026rsquo;： #!/bin/bash echo hello echo world 运行它会给出预期的结果： $ ./hello.sh hello world 现在让我们添加一个保证失败的语句： #!/bin/bash echo hello cat non-existing-file echo world 执行时，此脚本将打印错误。然而，执行并没有停止，\u0026lsquo;world\u0026rsquo; 仍然被打印出来： $ ./hello.sh hello cat: non-existing-file: No such file or directory world 此外，我们的脚本的退出代码为零，表明一切正常： $ echo $? 0 3.第一个错误退出 假设我们想让我们的脚本在发生第一个错误时以非零退出代码终止。因此，我们必须在脚本开头使用set更改 shell 的默认行为： #!/bin/bash set -e echo hello cat non-existing-file echo world 在第一行使用 set -e，我们告诉 Bash 在第一个错误时停止执行： $ ./hello.sh hello cat: non-existing-file: No such file or directory 此外，返回的退出代码等于失败命令的退出代码： $ echo $? 1 使用pipefail   不幸的是，此解决方案不适用于包含管道语句的脚本。例如，让我们将前两个命令连接在一起，从失败的命令开始： #!/bin/bash set -e cat non-existing-file | echo hello echo world 尽管我们使用 了set -e，但输出是： $ ./hello.sh hello cat: non-existing-file: No such file or directory world 为了处理这种情况，让我们在第一行的set 命令中添加*-o pipefail* 作为附加选项 ： #!/bin/bash set -eo pipefail cat non-existing-file | echo hello echo world 因此我们告诉 Bash，当管道中发生错误时，它应该停止并返回最右边失败的命令的退出代码： $ ./hello.sh hello cat: non-existing-file: No such file or directory 这会产生与我们之前看到的相同的非零退出代码： $ echo $? 1 \u0026quot; ","permalink":"http://itcodingman.github.io/aborting_shell_script/","tags":[],"title":"如果任何命令失败则中止 Shell 脚本"},{"categories":["Administration","Installation"],"contents":" 概述   想象一个程序员想要设计和编写三个不同的程序。他认为这三个程序共享几个可以被程序重用的通用功能。为了让他的生活更轻松，他需要将这些功能收集到一个名为library的实体中。 通常，库是为其他程序员或程序重用而编写的数据和函数的集合。在 Linux 上，存档库以.a扩展名结尾，共享对象库以.so 扩展名**结尾。 在本文中，我们将了解程序如何在 Linux 下运行以及归档和共享对象库的用途。除此之外，我们还将看到一些关于如何为程序构建库的示例。我们将使用GNU C 编译器 和GNU ar实用程序。 2.Linux下程序如何运行 大多数 Linux 用户可能都遇到过*/lib和/usr/lib*目录。这些是我们存储 安装在我们的 Linux 机器上**的程序使用的所有常用功能的目录。**作为约定，库名称以“lib”开头，扩展名决定了库的类型：  .a — 代表“存档” .so — 代表“共享对象”  一个程序可能依赖于多个共享对象。因此，手动安装共享对象可能很麻烦。为了解决这个问题，我们需要一个包管理器——一个在安装实际程序之前计算和确定依赖关系的工具。 当我们运行程序时，它会在*/usr/lib* 和*/share*目录中查找所需的依赖项。但是，如果缺少所需的依赖项，程序将无法启动。 3.程序库 程序库由执行常见任务所需的相关数据和子程序组成。例如，多个程序可能需要使用复数来计算结果。提供此功能的库的一个很好的例子是GNU C 库，它在链接阶段由gcc编译器链接到我们的程序中。 3.1 静态库 传统的静态库是一种在编译时与程序链接的库。因此，库的目标代码包含在可执行程序的目标代码中。最终，如果我们有多个程序链接到一个静态库，那么每个生成的程序二进制文件都将包含引用库的目标代码。因此，这将导致更大的可执行文件。 静态库通常以*.a扩展名结尾——例如glibc.a*。 3.2 共享库 为了解决较大的可执行二进制文件的问题，程序员改用共享库。共享库也称为动态库。这些共享库在运行时由操作系统上可用的动态链接器链接。 共享库通常以*.so扩展名结尾——例如libboost.5.6.so*。与静态库不同，引用共享库的程序不会在其生成的可执行文件中包含共享库对象代码。因此，我们得到更小的可执行文件。 同样，当我们有多个程序引用同一个共享库时，该库将有一个可供程序同时重用的单一副本。这是由操作系统安全管理的，它是现代计算的基础。我们看一下*/usr/lib/xorg*目录： $ ls -halF /usr/bin/xorg -rwxr-xr-x 1 root root 95K Apr 13 20:12 libexa.so* -rwxr-xr-x 1 root root 23K Apr 13 20:12 libfbdevhw.so* -rwxr-xr-x 1 root root 111K Apr 13 20:12 libfb.so* -rwxr-xr-x 1 root root 213K Apr 13 20:12 libglamoregl.so* -rwxr-xr-x 1 root root 143K Apr 13 20:12 libint10.so* -rwxr-xr-x 1 root root 15K Apr 13 20:12 libshadowfb.so* -rwxr-xr-x 1 root root 39K Apr 13 20:12 libshadow.so* 正如我们所见，Xorg依赖于列出的共享库。反过来，这些库也可以被dwm等其他程序使用。 构建*.a*或静态库   为了使这个说明起作用，我们需要gcc来编译我们的源代码。假设我们有一堆C编程源文件——我们需要将源文件编译成目标代码。我们可以通过发出带有*-Wall选项的gcc*命令来实现： $ gcc -Wall -c *.c 我们需要确保我们位于源目录的根目录。-Wall选项告诉编译器打印它遇到的所有警告。*.c参数中的星号告诉编译器编译所有**.c源文件。发出上述命令后，编译器会将*.c文件编译为相应的目标文件。因此，我们获得了 构建库所需的所有必需的*.o*文件。 接下来，我们将使用GNU Binutils中包含的ar实用程序从目标代码创建一个库文件： $ ar -cvq libfile.a *.o -c选项抑制错误， -v 选项用于详细输出， -q选项用于快速将指定文件附加到存档。如果存档不存在，则会创建一个新存档。当ar命令执行成功时，我们应该得到一个静态库文件libfile.a。让我们看看libfile.a文件中包含的内容： $ ar -t libfile.a 这将列出归档到libfile.a中的所有目标文件。稍后，当我们想在我们的程序中包含该库时，我们可以简单地在编译命令中引用该库： $ gcc -o MyProgram *.o -L path/to/libdir -lfile.a -L选项用于指定库目录。 注意命令中的库文件名。我们 用*-l替换了lib*前缀。MyProgram可执行文件将包含 libfile.a库的目标代码。 构建*.so*或共享库   使用gcc可以轻松构建共享库。和之前一样，我们首先需要将源文件编译成对应的目标文件： $ gcc -Wall -c *.c 编译代码后，我们需要将目标代码文件提供给我们的下一个命令以创建共享库： $ gcc -shared -o libfile.so *.o -shared选项向编译器指定我们正在构建一个共享库。 成功编译后，我们将构建一个共享库，我们可以将其安装在我们的系统上，以便所有程序在运行时都可以使用它。 \u0026quot; ","permalink":"http://itcodingman.github.io/a_so_extension_files/","tags":["gcc"],"title":"什么是 .a 和 .so 文件？"},{"categories":["Spring MVC"],"contents":"1. 概述 本教程将讨论配置 Spring Transactions 的正确方法、如何使用*@Transactional*注解以及常见的陷阱。 有关核心持久性配置的更深入讨论，请查看Spring with JPA 教程。 基本上，有两种不同的方式来配置事务、注解和AOP，每一种方式都有自己的优势。我们将在这里讨论更常见的注释配置。 2. 配置事务 Spring 3.1 引入了**@EnableTransactionManagement注解**，我们可以在*@Configuration*类中使用它来启用事务支持： @Configuration @EnableTransactionManagement public class PersistenceJPAConfig{ @Bean public LocalContainerEntityManagerFactoryBean entityManagerFactoryBean(){ //...  } @Bean public PlatformTransactionManager transactionManager(){ JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory( entityManagerFactoryBean().getObject() ); return transactionManager; } } 但是，如果我们使用的是 Spring Boot 项目并且类路径上有 spring-data-* 或 spring-tx 依赖项，则默认情况下将启用事务管理。 3. 使用 XML 配置事务 对于 3.1 之前的版本，或者如果 Java 不是一个选项，这里是使用注释驱动和命名空间支持的 XML 配置： \u0026lt;bean id=\u0026#34;txManager\u0026#34; class=\u0026#34;org.springframework.orm.jpa.JpaTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;entityManagerFactory\u0026#34; ref=\u0026#34;myEmf\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;tx:annotation-driven transaction-manager=\u0026#34;txManager\u0026#34; /\u0026gt; 4. @Transactional注解 配置事务后，我们现在可以在类或方法级别使用*@Transactional注解 bean：* @Service @Transactional public class FooService { //... } 注解还支持进一步的配置：  交易的传播类型 事务的隔离级别 事务包装的操作的超时 一个readOnly 标志——提示持久性提供者事务应该是只读的 事务的回滚规则  请注意，默认情况下，回滚仅发生在运行时，未经检查的异常。检查的异常不会触发事务的回滚。当然，我们可以使用rollbackFor和noRollbackFor注释参数来配置这种行为。 5. 潜在的陷阱 5.1 交易和代理 在高层次上， Spring 为所有使用**@Transactional**注释的类创建代理，无论是在类上还是在任何方法上。代理允许框架在运行方法之前和之后注入事务逻辑，主要用于启动和提交事务。 需要记住的重要一点是，如果事务 bean 正在实现一个接口，那么默认情况下代理将是一个 Java 动态代理。这意味着只有通过代理传入的外部方法调用才会被拦截。**任何自调用都不会启动任何事务，*即使该方法具有@Transactional*注释。 使用代理的另一个注意事项是**只有公共方法才应该使用@Transactional 进行注释。**任何其他可见性的方法将简单地忽略注释，因为它们没有被代理。 5.2 更改隔离级别 courseDao.createWithRuntimeException(course); 我们还可以更改事务隔离级别： @Transactional(isolation = Isolation.SERIALIZABLE) 请注意，这实际上已在 Spring 4.1中引入；如果我们在 Spring 4.1之前运行上面的示例，它将导致：  org.springframework.transaction.InvalidIsolationLevelException：标准 JPA 不支持自定义隔离级别 -为您的 JPA 实现使用特殊的JpaDialect  5.3 只读事务 readOnly标志通常会产生混淆，尤其是在使用 JPA 时。来自 Javadoc：  这只是作为实际事务子系统的提示；它不一定会导致写访问尝试失败。无法解释只读提示的事务管理器在请求只读事务时不会抛出异常。  事实是，当设置了readOnly标志时，我们不能确定不会发生插入或更新。此行为取决于驱动，而 JPA 与驱动无关。 了解readOnly标志仅在事务内部相关也很重要。如果操作发生在事务上下文之外，则简单地忽略该标志。一个简单的示例将调用一个带有以下注释的方法： @Transactional( propagation = Propagation.SUPPORTS,readOnly = true ) 在非事务性上下文中，不会创建事务并且readOnly标志将被忽略。 5.4 事务记录 了解事务相关问题的一个有用方法是微调事务包中的日志记录。Spring中的相关包是“ org.springframework.transaction”，需要配置一个TRACE的日志级别。 5.5 事务回滚 @Transactional注解是指定方法上事务的语义的元数据。我们有两种回滚事务的方法：声明式和编程式。 在声明式方法中，我们使用 @Transactional对方法进行注解。@Transactional注解使用属性rollbackFor或rollbackForClassName来回滚事务，并使用属性noRollbackFor或noRollbackForClassName来避免对列出的异常进行回滚。 声明式方法中的默认回滚行为将在运行时异常时回滚。 让我们看一个使用声明性方法回滚事务以处理运行时异常或错误的简单示例： @Transactional public void createCourseDeclarativeWithRuntimeException(Course course) { courseDao.create(course); throw new DataIntegrityViolationException(\u0026#34;Throwing exception for demoing Rollback!!!\u0026#34;); } 接下来，我们将使用声明性方法为列出的检查异常回滚事务。我们示例中的回滚是在SQLException上： @Transactional(rollbackFor = { SQLException.class }) public void createCourseDeclarativeWithCheckedException(Course course) throws SQLException { courseDao.create(course); throw new SQLException(\u0026#34;Throwing exception for demoing rollback\u0026#34;); } 让我们看一下在声明性方法中对属性noRollbackFor的简单使用，以防止所列异常的事务回滚： @Transactional(noRollbackFor = { SQLException.class }) public void createCourseDeclarativeWithNoRollBack(Course course) throws SQLException { courseDao.create(course); throw new SQLException(\u0026#34;Throwing exception for demoing rollback\u0026#34;); } 在编程方法中，我们使用TransactionAspectSupport回滚事务： public void createCourseDefaultRatingProgramatic(Course course) { try { courseDao.create(course); } catch (Exception e) { TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); } } 声明性回滚策略应该优于程序化回滚策略。 \u0026quot; ","permalink":"http://itcodingman.github.io/transaction_configuration_with_jpa_and_spring/","tags":["Spring MVC Basics","Thymeleaf"],"title":"Spring 和 JPA 的事务配置"},{"categories":["Spring Data"],"contents":"1. 概述 Thymeleaf是一个 Java 模板引擎，用于处理和创建 HTML、XML、JavaScript、CSS 和文本。 在本教程中，我们将讨论如何在 Spring MVC 应用程序的视图层中使用 Thymeleaf以及一些基本用例。 该库具有极强的可扩展性，其自然的模板功能确保我们可以在没有后端的情况下制作模板原型。与其他流行的模板引擎（例如 JSP）相比，这使得开发速度非常快。 2. 将 Thymeleaf 与 Spring 集成 首先，让我们看看与 Spring 集成所需的配置。集成需要thymeleaf -spring库。 我们将以下依赖项添加到我们的 Maven POM 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.11.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf-spring5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.11.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，对于 Spring 4 项目，我们必须使用thymeleaf-spring4库而不是thymeleaf-spring5。 SpringTemplateEngine类执行所有配置步骤。 我们可以在 Java 配置文件中将这个类配置为 bean： @Bean @Description(\u0026#34;Thymeleaf Template Resolver\u0026#34;) public ServletContextTemplateResolver templateResolver() { ServletContextTemplateResolver templateResolver = new ServletContextTemplateResolver(); templateResolver.setPrefix(\u0026#34;/WEB-INF/views/\u0026#34;); templateResolver.setSuffix(\u0026#34;.html\u0026#34;); templateResolver.setTemplateMode(\u0026#34;HTML5\u0026#34;); return templateResolver; } @Bean @Description(\u0026#34;Thymeleaf Template Engine\u0026#34;) public SpringTemplateEngine templateEngine() { SpringTemplateEngine templateEngine = new SpringTemplateEngine(); templateEngine.setTemplateResolver(templateResolver()); templateEngine.setTemplateEngineMessageSource(messageSource()); return templateEngine; } templateResolver bean 属性prefix和suffix分别指示webapp目录中视图页面的位置及其文件扩展名。 Spring MVC 中的ViewResolver接口将控制器返回的视图名称映射到实际的视图对象。ThymeleafViewResolver实现ViewResolver接口，它用于确定要呈现哪些 Thymeleaf 视图，给定视图名称。 集成的最后一步是将ThymeleafViewResolver添加为 bean： @Bean @Description(\u0026#34;Thymeleaf View Resolver\u0026#34;) public ThymeleafViewResolver viewResolver() { ThymeleafViewResolver viewResolver = new ThymeleafViewResolver(); viewResolver.setTemplateEngine(templateEngine()); viewResolver.setOrder(1); return viewResolver; } 3. Spring Boot 中的 Thymeleaf Spring Boot通过添加spring-boot-starter-thymeleaf依赖项为Thymeleaf提供自动配置： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 无需显式配置。默认情况下，HTML 文件应放置在resources/templates 位置。 4. 显示来自消息源（属性文件）的值 我们可以使用th:text=\u0026quot;#{key}\u0026quot; 标签属性来显示属性文件中的值。 为此，我们需要将属性文件配置为messageSource bean： @Bean @Description(\u0026#34;Spring Message Resolver\u0026#34;) public ResourceBundleMessageSource messageSource() { ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); messageSource.setBasename(\u0026#34;messages\u0026#34;); return messageSource; } 这是 Thymeleaf HTML 代码，用于显示与键welcome.message关联的值： \u0026lt;span th:text=\u0026#34;#{welcome.message}\u0026#34; /\u0026gt; 5. 显示模型属性 5.1 简单属性 我们可以使用th:text=\u0026quot;${attributename}\u0026quot; 标签属性来显示模型属性的值。 让我们在控制器类中添加一个名为serverTime的模型属性： model.addAttribute(\u0026#34;serverTime\u0026#34;, dateFormat.format(new Date())); 这是显示serverTime属性值的 HTML 代码： Current time is \u0026lt;span th:text=\u0026#34;${serverTime}\u0026#34; /\u0026gt; 5.2 集合属性 如果模型属性是对象的集合，我们可以使用th:each 标签属性对其进行迭代。 让我们定义一个包含两个字段id 和name的Student*模型类： public class Student implements Serializable { private Integer id; private String name; // standard getters and setters } 现在我们将在控制器类中添加一个学生列表作为模型属性： List\u0026lt;Student\u0026gt; students = new ArrayList\u0026lt;Student\u0026gt;(); // logic to build student data model.addAttribute(\u0026#34;students\u0026#34;, students); 最后，我们可以使用 Thymeleaf 模板代码遍历学生列表并显示所有字段值： \u0026lt;tbody\u0026gt; \u0026lt;tr th:each=\u0026#34;student: ${students}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${student.id}\u0026#34; /\u0026gt; \u0026lt;td th:text=\u0026#34;${student.name}\u0026#34; /\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; 6. 条件语句 6.1 if和unless 如果满足条件，我们使用th:if=\u0026quot;${condition}\u0026quot; 属性来显示视图的一部分。如果条件不满足，我们使用th:unless=\u0026quot;${condition}\u0026quot; 属性来显示视图的一部分。 让我们在Student模型中添加一个gender字段： public class Student implements Serializable { private Integer id; private String name; private Character gender; // standard getters and setters } 假设该字段有两个可能的值（M 或 F）来指示学生的性别。 如果我们希望显示单词“Male”或“Female”而不是单个字符，我们可以使用以下 Thymeleaf 代码： \u0026lt;td\u0026gt; \u0026lt;span th:if=\u0026#34;${student.gender} == \u0026#39;M\u0026#39;\u0026#34; th:text=\u0026#34;Male\u0026#34; /\u0026gt; \u0026lt;span th:unless=\u0026#34;${student.gender} == \u0026#39;M\u0026#39;\u0026#34; th:text=\u0026#34;Female\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; 6.2 switch和case 我们使用th:switch和th:case 属性来使用 switch 语句结构有条件地显示内容。 让我们使用th:switch和th:case 属性重写前面的代码： \u0026lt;td th:switch=\u0026#34;${student.gender}\u0026#34;\u0026gt; \u0026lt;span th:case=\u0026#34;\u0026#39;M\u0026#39;\u0026#34; th:text=\u0026#34;Male\u0026#34; /\u0026gt; \u0026lt;span th:case=\u0026#34;\u0026#39;F\u0026#39;\u0026#34; th:text=\u0026#34;Female\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; 7. 处理用户输入 我们可以使用th:action=\u0026quot;@{url}\u0026quot; 和 th:object=\u0026quot;${object}\u0026quot; 属性来处理表单输入。我们使用th:action 提供表单操作 URL，使用th:object 指定提交的表单数据将绑定到的对象。 使用th:field=\u0026quot;*{name}\u0026quot; 属性映射各个字段，其中name是对象的匹配属性。 对于Student类，我们可以创建一个输入表单： \u0026lt;form action=\u0026#34;#\u0026#34; th:action=\u0026#34;@{/saveStudent}\u0026#34; th:object=\u0026#34;${student}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;table border=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;label th:text=\u0026#34;#{msg.id}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;number\u0026#34; th:field=\u0026#34;*{id}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;label th:text=\u0026#34;#{msg.name}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; th:field=\u0026#34;*{name}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; 在上面的代码中，/saveStudent是表单操作 URL，student是保存提交的表单数据的对象。 StudentController类处理表单提交： @Controller public class StudentController { @RequestMapping(value = \u0026#34;/saveStudent\u0026#34;, method = RequestMethod.POST) public String saveStudent(@ModelAttribute Student student, BindingResult errors, Model model) { // logic to process input data  } } @RequestMapping注解将控制器方法映射到表单中提供的 URL。带注释的方法saveStudent()对提交的表单执行所需的处理。最后，@ModelAttribute注释将表单字段绑定到学生对象。 8. 显示验证错误 我们可以使用*#fields.hasErrors()函数来检查一个字段是否有任何验证错误。我们使用#fields.errors()*函数来显示特定字段的错误。字段名称是这两个函数的输入参数。 让我们看一下用于迭代并显示表单中每个字段的错误的 HTML 代码： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;id\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;name\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 上述函数不接受字段名称，而是接受通配符*或常量all来表示所有字段。我们使用th:each 属性来迭代每个字段可能存在的多个错误。 这是之前使用通配符*重写的 HTML 代码： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;*\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 在这里我们使用常量all： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;all\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 同样，我们可以使用全局常量在 Spring 中显示全局错误。 这是显示全局错误的 HTML 代码： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;global\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 此外，我们可以使用th:errors属性来显示错误消息。 之前在表单中显示错误的代码可以使用th:errors属性重写： \u0026lt;ul\u0026gt; \u0026lt;li th:errors=\u0026#34;*{id}\u0026#34; /\u0026gt; \u0026lt;li th:errors=\u0026#34;*{name}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 9. 使用转换 我们使用双括号语法*{{}}来格式化数据以供显示。这利用了为上下文文件的conversionService* bean 中的该类型字段配置的格式化程序。 让我们看看如何格式化Student类中的 name 字段： \u0026lt;tr th:each=\u0026#34;student: ${students}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${{student.name}}\u0026#34; /\u0026gt; \u0026lt;/tr\u0026gt; 上面的代码使用NameFormatter类，通过覆盖*WebMvcConfigurer接口的**addFormatters()*方法进行配置。 为此，我们的*@Configuration类覆盖了WebMvcConfigurerAdapter*类： @Configuration public class WebMVCConfig extends WebMvcConfigurerAdapter { // ...  @Override @Description(\u0026#34;Custom Conversion Service\u0026#34;) public void addFormatters(FormatterRegistry registry) { registry.addFormatter(new NameFormatter()); } } NameFormatter类实现了 Spring Formatter接口。 我们还可以使用*#conversions实用程序来转换对象以进行显示。实用程序函数的语法是#conversions.convert(Object, Class)，其中Object被转换为Class*类型。 以下是如何在删除小数部分的情况下显示学生对象百分比字段： \u0026lt;tr th:each=\u0026#34;student: ${students}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${#conversions.convert(student.percentage, \u0026#39;Integer\u0026#39;)}\u0026#34; /\u0026gt; \u0026lt;/tr\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/thymeleaf_in_spring_mvc/","tags":["JPA"],"title":"在 Spring 中使用 Thymeleaf"},{"categories":["Spring Persistence"],"contents":"1. 概述 本教程将重点**介绍将 Spring Data JPA 引入 Spring 项目，**并全面配置持久层。有关使用基于 Java 的配置和项目的基本 Maven pom 设置 Spring 上下文的分步介绍，请参阅本文。 2. Spring Data Generated DAO – 不再有 DAO 实现 正如我们在之前的文章中所讨论的，DAO 层通常由许多可以而且应该被简化的样板代码组成。这种简化的优点有很多：减少了我们需要定义和维护的工件数量、数据访问模式的一致性以及配置的一致性。 Spring Data 将这种简化更进一步，使得完全删除 DAO 实现成为可能。DAO 的接口现在是我们需要明确定义的唯一工件。 为了开始利用 JPA 的 Spring Data 编程模型，DAO 接口需要扩展 JPA 特定的Repository接口JpaRepository。这将使 Spring Data 能够找到这个接口并自动为其创建一个实现。 通过扩展接口，我们获得了标准 DAO 中可用的标准数据访问最相关的 CRUD 方法。 3. 自定义访问方法和查询 如前所述，通过实现Repository接口之一，DAO 将已经定义和实现了一些基本的 CRUD 方法（和查询）。 为了定义更具体的访问方法，Spring JPA 支持很多选项：  只需在接口中定义一个新方法 使用*@Query*注释提供实际的JPQL 查询 在 Spring Data 中使用更高级的Specification 和 Querydsl 支持 通过 JPA 命名查询定义自定义查询  第三个选项Specifications and Querydsl support 与 JPA Criteria 类似，但使用了更灵活方便的 API。这使得整个操作更具可读性和可重用性。当处理大量固定查询时，此 API 的优势将变得更加明显，因为我们可以通过较少数量的可重用块更简洁地表达这些。 最后一个选项的缺点是它要么涉及 XML，要么给域类增加了查询负担。 3.1 自动自定义查询 当 Spring Data 创建一个新的Repository实现时，它会分析接口定义的所有方法，并尝试从方法名称自动生成查询。虽然这有一些限制，但它是一种非常强大且优雅的方式，可以轻松定义新的自定义访问方法。 让我们看一个例子。如果实体有一个名称字段（以及 Java Bean 标准的getName和setName方法），**我们将在 DAO 接口中定义findByName方法。**这将自动生成正确的查询： public interface IFooDAO extends JpaRepository\u0026lt;Foo, Long\u0026gt; { Foo findByName(String name); } 这是一个比较简单的例子。查询创建机制支持更大的关键字集。 如果解析器无法将属性与域对象字段匹配，我们将看到以下异常： java.lang.IllegalArgumentException: No property nam found for type class com.baeldung.spring.data.persistence.model.Foo 3.2 手动自定义查询 现在让我们看一下我们将通过*@Query*注释定义的自定义查询： @Query(\u0026#34;SELECT f FROM Foo f WHERE LOWER(f.name) = LOWER(:name)\u0026#34;) Foo retrieveByName(@Param(\u0026#34;name\u0026#34;) String name); 要对查询的创建进行更细粒度的控制，例如使用命名参数或修改现有查询，参考是一个很好的起点。 4. 交易配置 Spring 管理的 DAO 的实际实现确实是隐藏的，因为我们不直接使用它。但是，它是一个足够简单的实现，即SimpleJpaRepository，它使用 annotations 定义事务语义。 更明确地说，这在类级别使用只读*@Transactional*注释，然后为非只读方法覆盖该注释。其余的事务语义是默认的，但是这些可以很容易地被每个方法手动覆盖。 4.1 异常翻译 现在的问题变成了：由于 Spring Data JPA 不依赖于旧的 ORM 模板（JpaTemplate、HibernateTemplate），并且自 Spring 5 以来它们已被删除，我们是否仍将 JPA 异常转换为 Spring 的DataAccessException层次结构？ 答案是，当然，我们是。通过在 DAO 上使用@Repository仍然可以启用异常翻译。此注解使 Spring bean 后处理器能够通知所有*@Repository* bean 以及在容器中找到的所有PersistenceExceptionTranslator实例，并像以前一样提供异常翻译。 让我们通过集成测试来验证异常翻译： @Test(expected = DataIntegrityViolationException.class) public void givenFooHasNoName_whenInvalidEntityIsCreated_thenDataException() { service.create(new Foo()); } 请记住，**异常翻译是通过代理完成的。**为了让 Spring 能够围绕 DAO 类创建代理，这些代理不能被声明为final。 5. Spring Data JPA 存储库配置 要激活 Spring JPA 存储库支持，我们可以使用*@EnableJpaRepositories*注释并指定包含 DAO 接口的包： @EnableJpaRepositories(basePackages = \u0026#34;com.codingman.spring.data.persistence.repository\u0026#34;) public class PersistenceConfig { ... } 我们可以对 XML 配置做同样的事情： \u0026lt;jpa:repositories base-package=\u0026#34;com.codingman.spring.data.persistence.repository\u0026#34; /\u0026gt; 6. Java 或 XML 配置 我们已经在之前的文章中详细讨论了如何在 Spring 中配置 JPA 。Spring Data 还利用了 Spring 对 JPA @PersistenceContext注释的支持。它使用它将EntityManager连接到负责创建实际 DAO 实现JpaRepositoryFactoryBean的 Spring 工厂 bean 。 除了已经讨论过的配置，如果我们使用 XML，我们还需要包含 Spring Data XML 配置： @Configuration @EnableTransactionManagement @ImportResource(\u0026#34;classpath*:*springDataConfig.xml\u0026#34;) public class PersistenceJPAConfig { ... } 7. Maven依赖 除了 JPA 的 Maven 配置之外，就像在之前的文章中一样，我们将添加spring -data-jpa依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 8. 使用 Spring Boot 我们还可以使用Spring Boot Starter Data JPA依赖项，它会自动为我们配置DataSource。 我们需要确保我们要使用的数据库存在于类路径中。在我们的示例中，我们添加了 H2 内存数据库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.200\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 结果，只需执行这些依赖项，我们的应用程序就可以启动并运行，我们可以将其用于其他数据库操作。 标准 Spring 应用程序的显式配置现在包含在 Spring Boot 自动配置中。 当然，我们可以通过添加我们自定义的显式配置来修改自动配置。 Spring Boot 提供了一种使用application.properties文件中的属性的简单方法。让我们看一个更改连接 URL 和凭据的示例： spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1 spring.datasource.username=sa spring.datasource.password=sa 9. Spring Data JPA 的有用工具 所有主要的 Java IDE 都支持 Spring Data JPA。让我们看看 Eclipse 和 IntelliJ IDEA 有哪些有用的工具。 **如果你使用 Eclipse 作为你的 IDE，你可以安装Dali Java Persistence Tools插件。**这提供了 JPA 实体的 ER 图、用于初始化模式的 DDL 生成以及基本的逆向工程功能。此外，您还可以使用 Eclipse Spring Tool Suite (STS)。它将有助于验证 Spring Data JPA 存储库中的查询方法名称。 如果您使用 IntelliJ IDEA，有两个选项。 IntelliJ IDEA Ultimate 支持 ER 图、用于测试 JPQL 语句的 JPA 控制台和有价值的检查。但是，这些功能在 Community Edition 中不可用。 **为了提高 IntelliJ 的生产力，您可以安装JPA Buddy插件，**它提供了许多功能，包括生成 JPA 实体、Spring Data JPA 存储库、DTO、初始化 DDL 脚本、Flyway 版本化迁移、Liquibase 更改日志等。此外，JPA Buddy 提供逆向工程的高级工具。 最后，JPA Buddy 插件适用于社区版和终极版。 \u0026quot; ","permalink":"http://itcodingman.github.io/the_persistence_layer_with_spring_data_jpa/","tags":["JPA"],"title":"Spring Data JPA 简介"},{"categories":["Spring"],"contents":"1. 概述 本教程展示了如何使用 Hibernate 作为持久性提供者来使用JPA 设置 Spring 。 有关使用基于 Java 的配置和项目的基本 Maven pom 设置 Spring 上下文的分步介绍，请参阅本文。 我们将从在 Spring Boot 项目中设置 JPA 开始。然后，如果我们有一个标准的 Spring 项目，我们将研究我们需要的完整配置。 2. Spring Boot 中的 JPA Spring Boot 项目旨在使创建 Spring 应用程序更快、更容易。这是通过对各种 Spring 功能使用启动器和自动配置来完成的，其中包括 JPA。 2.1 Maven 依赖项 要在 Spring Boot 应用程序中启用 JPA，我们需要*[spring-boot-starter](https://search.maven.org/classic/#search|ga|1|a%3A\u0026quot;spring-boot-starter\u0026quot; AND g%3A\u0026quot;org.springframework.boot\u0026quot;)和spring-boot-starter-data-jpa*依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-boot-starter包含 Spring JPA的必要自动配置。此外，spring-boot-starter-jpa项目引用了所有必要的依赖项，例如hibernate-core。 2.2 配置 Spring Boot 将Hibernate配置为默认的 JPA 提供程序，因此不再需要定义entityManagerFactory bean，除非我们想要自定义它。 **Spring Boot 还可以根据我们使用的数据库自动配置dataSource bean。**对于H2、HSQLDB 和Apache Derby类型的内存数据库，如果类路径上存在相应的数据库依赖项，则 Boot 会自动配置DataSource 。 例如，如果我们想在 Spring Boot JPA 应用程序中使用内存中的H2数据库，我们只需要在pom.xml文件中添加[h2](https://search.maven.org/classic/#search|ga|1|a%3A\u0026quot;h2\u0026quot; AND g%3A\u0026quot;com.h2database\u0026quot;)依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.200\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这样，我们不需要定义dataSource bean，但如果我们想自定义它，我们可以。 如果我们想将 JPA 与MySQL数据库一起使用，我们需要mysql-connector-java依赖项。我们还需要定义DataSource配置。 我们可以在*@Configuration*类中或使用标准 Spring Boot 属性来执行此操作。 Java 配置看起来与标准 Spring 项目中的配置相同： @Bean public DataSource dataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); dataSource.setUsername(\u0026#34;user\u0026#34;); dataSource.setPassword(\u0026#34;pass\u0026#34;); dataSource.setUrl( \u0026#34;jdbc:mysql://localhost:3306/myDb?createDatabaseIfNotExist=true\u0026#34;); return dataSource; } 要使用属性文件配置数据源，我们必须设置以spring.datasource为前缀的属性： spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.username=user spring.datasource.password=pass spring.datasource.url= jdbc:mysql://localhost:3306/myDb?createDatabaseIfNotExist=true Spring Boot 会根据这些属性自动配置一个数据源。 同样在 Spring Boot 1 中，默认连接池为Tomcat，但在 Spring Boot 2 中已更改为HikariCP。 正如我们所见，如果我们使用 Spring Boot，基本的 JPA 配置相当简单。 但是，**如果我们有一个标准的 Spring 项目，我们需要更明确的配置，使用 Java 或 XML。**这就是我们将在接下来的部分中关注的内容。 3. 非引导项目中使用 Java 的 JPA Spring 配置 要在 Spring 项目中使用 JPA，我们需要设置EntityManager。 这是配置的主要部分，我们可以通过 Spring 工厂 bean 来完成。这可以是更简单的LocalEntityManagerFactoryBean或更灵活的LocalContainerEntityManagerFactoryBean。 让我们看看如何使用后一个选项： @Configuration @EnableTransactionManagement public class PersistenceJPAConfig{ @Bean public LocalContainerEntityManagerFactoryBean entityManagerFactory() { LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(dataSource()); em.setPackagesToScan(new String[] { \u0026#34;com.baeldung.persistence.model\u0026#34; }); JpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); em.setJpaVendorAdapter(vendorAdapter); em.setJpaProperties(additionalProperties()); return em; } // ...  } 我们还需要显式定义我们上面使用的*DataSource* bean ： @Bean public DataSource dataSource(){ DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:mysql://localhost:3306/spring_jpa\u0026#34;); dataSource.setUsername( \u0026#34;tutorialuser\u0026#34; ); dataSource.setPassword( \u0026#34;tutorialmy5ql\u0026#34; ); return dataSource; } 配置的最后一部分是附加的 Hibernate 属性以及TransactionManager和exceptionTranslation bean： @Bean public PlatformTransactionManager transactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory(entityManagerFactory().getObject()); return transactionManager; } @Bean public PersistenceExceptionTranslationPostProcessor exceptionTranslation(){ return new PersistenceExceptionTranslationPostProcessor(); } Properties additionalProperties() { Properties properties = new Properties(); properties.setProperty(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;, \u0026#34;create-drop\u0026#34;); properties.setProperty(\u0026#34;hibernate.dialect\u0026#34;, \u0026#34;org.hibernate.dialect.MySQL5Dialect\u0026#34;); return properties; } 4. JPA Spring 配置 XML 接下来，让我们看一下使用 XML 的相同 Spring 配置： \u0026lt;bean id=\u0026#34;myEmf\u0026#34; class=\u0026#34;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;com.codingman.persistence.model\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jpaVendorAdapter\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter\u0026#34; /\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;jpaProperties\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.hbm2ddl.auto\u0026#34;\u0026gt;create-drop\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.dialect\u0026#34;\u0026gt;org.hibernate.dialect.MySQL5Dialect\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/spring_jpa\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;tutorialuser\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;tutorialmy5ql\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.orm.jpa.JpaTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;entityManagerFactory\u0026#34; ref=\u0026#34;myEmf\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;tx:annotation-driven /\u0026gt; \u0026lt;bean id=\u0026#34;persistenceExceptionTranslationPostProcessor\u0026#34; class= \u0026#34;org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\u0026#34; /\u0026gt; XML 和新的基于 Java 的配置之间存在相对较小的差异。也就是说，在 XML 中，对另一个 bean 的引用可以指向该 bean 或该 bean 的 bean 工厂。 但在 Java 中，由于类型不同，编译器不允许这样做，因此首先从其 bean 工厂中检索EntityManagerFactory ，然后将其传递给事务管理器： transactionManager.setEntityManagerFactory(entityManagerFactory().getObject()); 5. 完全无 XML 通常，JPA 通过META-INF/persistence.xml文件定义一个持久化单元。从 Spring 3.1 开始，persistence.xml不再需要。LocalContainerEntityManagerFactoryBean现在支持packagesToScan属性，其中可以指定要扫描*@Entity*类的包。 该文件是我们需要删除的最后一段 XML。我们现在可以在没有 XML 的情况下完全设置 JPA。 我们通常会在persistence.xml文件中指定 JPA 属性。 或者，我们可以将属性直接添加到实体管理器工厂 bean： factoryBean.setJpaProperties(this.additionalProperties()); 附带说明一下，如果 Hibernate 是持久性提供程序，那么这也是指定 Hibernate 特定属性的方法。 6. Maven 配置 除了 Spring Core 和持久性依赖项（在Spring with Maven 教程中有详细介绍）之外，我们还需要在项目中定义 JPA 和 Hibernate 以及 MySQL 连接器： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.17.Final\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.19\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，此处包含 MySQL 依赖项作为示例。我们需要一个驱动程序来配置数据源，但是任何支持 Hibernate 的数据库都可以。 \u0026quot; ","permalink":"http://itcodingman.github.io/the_persistence_layer_with_spring_and_jpa/","tags":["Spring Core Basics","Spring DI"],"title":"使用 Spring 的 JPA 指南"},{"categories":["Maven","Spring"],"contents":"1. 简介 在这个基础教程中，我们将学习如何使用 Spring Framework 进行简单的基于 XML 的 bean 配置。 2. 概述 让我们首先在pom.xml中添加 Spring 的库依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在[此处](https://search.maven.org/classic/#search|ga|1|g%3A\u0026quot;org.springframework\u0026quot; AND a%3A\u0026quot;spring-context\u0026quot;)找到最新版本的 Spring 依赖项。 3. 依赖注入——概述 依赖注入是一种技术，其中对象的依赖关系由外部容器提供。 假设我们有一个依赖于实际处理业务逻辑的服务的应用程序类： public class IndexApp { private IService service; // standard constructors/getters/setters } 现在假设IService是一个接口： public interface IService { public String serve(); } 这个接口可以有多种实现。 让我们快速看一下一种可能的实现： public class IndexService implements IService { @Override public String serve() { return \u0026#34;Hello World\u0026#34;; } } 在这里，IndexApp是一个高级组件，它依赖于名为IService的低级组件。 从本质上讲，我们将IndexApp与IService的特定实现分离，该实现可能会因各种因素而异。 4. 依赖注入——在行动 让我们看看如何注入依赖项。 4.1 使用属性 让我们看看如何使用基于 XML 的配置将依赖项连接在一起： \u0026lt;bean id=\u0026#34;indexService\u0026#34; class=\u0026#34;com.codingman.di.IndexService\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34; \u0026gt; \u0026lt;property name=\u0026#34;service\u0026#34; ref=\u0026#34;indexService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 可以看出，我们正在创建一个IndexService实例并为其分配一个id。默认情况下，bean是单例的。此外，我们正在创建一个IndexApp实例。 在这个 bean 中，我们使用 setter 方法注入另一个bean。 4.2 使用构造函数 我们可以使用构造函数注入依赖项，而不是通过 setter 方法注入 bean： \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34;\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;indexService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 4.3 使用静态工厂 我们还可以注入工厂返回的 bean。让我们创建一个简单的工厂，它根据提供的数字返回IService的实例： public class StaticServiceFactory { public static IService getNumber(int number) { // ...  } } 现在让我们看看如何使用上面的实现通过基于 XML 的配置将 bean 注入IndexApp ： \u0026lt;bean id=\u0026#34;messageService\u0026#34; class=\u0026#34;com.codingman.di.StaticServiceFactory\u0026#34; factory-method=\u0026#34;getService\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;service\u0026#34; ref=\u0026#34;messageService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 在上面的示例中，我们使用工厂方法调用静态**getService方法来创建一个 id为messageService的 bean ，我们将其注入IndexApp。 4.4 使用工厂方法 让我们考虑一个实例工厂，它根据提供的数字返回一个*IService实例。*这一次，方法不是静态的： public class InstanceServiceFactory { public IService getNumber(int number) { // ...  } } 现在让我们看看如何使用上述实现通过 XML 配置将 bean 注入IndexApp ： \u0026lt;bean id=\u0026#34;indexServiceFactory\u0026#34; class=\u0026#34;com.codingman.di.InstanceServiceFactory\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;messageService\u0026#34; class=\u0026#34;com.codingman.di.InstanceServiceFactory\u0026#34; factory-method=\u0026#34;getService\u0026#34; factory-bean=\u0026#34;indexServiceFactory\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;service\u0026#34; ref=\u0026#34;messageService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 在上面的示例中，我们使用工厂方法在InstanceServiceFactory 实例上调用getService方法，以创建一个 id 为messageService的 bean ，我们将其注入IndexApp。 5. 测试 这就是我们可以访问配置的 bean 的方式： @Test public void whenGetBeans_returnsBean() { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;...\u0026#34;); IndexApp indexApp = applicationContext.getBean(\u0026#34;indexApp\u0026#34;, IndexApp.class); assertNotNull(indexApp); } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_xml_injection/","tags":[],"title":"Spring 中基于 XML 的注入"},{"categories":["Spring"],"contents":"1. 概述 本教程说明了如何通过 Maven 设置Spring 依赖项。最新的 Spring 版本可以在 Maven Central上找到。 2. Maven 的基本 Spring 依赖 Spring 被设计成高度模块化的——使用 Spring 的一部分不应该也不需要另一部分。例如，基本的 Spring Context 可以没有 Persistence 或 MVC Spring 库。 让我们从一个基本的Maven 设置开始，它只使用spring-context依赖： \u0026lt;properties\u0026gt; \u0026lt;org.springframework.version\u0026gt;5.2.8.RELEASE\u0026lt;/org.springframework.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 这个依赖**——spring-context——定义了实际的 Spring Injection Container，并且有少量的依赖：spring-core、spring-expression、spring-aop和spring-beans。这些通过支持一些核心 Spring 技术**来增强容器：核心 Spring 实用程序、Spring 表达式语言(SpEL)、面向方面的编程支持和JavaBeans 机制。 请注意，我们在运行时范围内定义依赖项——这将确保在任何 Spring 特定 API 上都没有编译时依赖项。对于更高级的用例，可能会从一些选定的 Spring 依赖项中删除运行时范围，但对于更简单的项目，无需针对 Spring 进行编译以充分利用框架。 另请注意，JDK 8 是 Spring 5.2 所需的最低 Java 版本。它还支持 JDK 11 作为当前的 LTS 分支和 JDK 13 作为最新的 OpenJDK 版本。 3. Maven 的 Spring 持久性 现在让我们看看持久性 Spring 依赖项——主要是spring-orm： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-orm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这附带了 Hibernate 和 JPA 支持——例如HibernateTemplate和JpaTemplate——以及一些额外的与持久性相关的依赖项：spring-jdbc和spring-tx。 JDBC 数据访问库定义了Spring JDBC 支持以及JdbcTemplate，而spring-tx代表了极其灵活的事务管理抽象。 4. 使用 Maven 的 Spring MVC 要使用 Spring Web 和 Servlet 支持，除了上面的核心依赖项之外，还需要在pom中包含两个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-web依赖项包含用于 Servlet 和 Portlet 环境的常见 Web 特定实用程序，而spring -webmvc启用了对 Servlet 环境的 MVC 支持。 由于spring-webmvc具有spring-web作为依赖项，因此在使用spring-webmvc时不需要显式定义spring-web。 从 Spring 5.0 开始，对于响应式堆栈 Web 框架的支持，我们可以添加Spring WebFlux的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webflux\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5. Maven 的 Spring 安全性 安全性 Maven 依赖项在Spring Security with Maven文章中进行了深入讨论。 6. 使用 Maven 进行Spring测试 Spring Test Framework 可以通过以下依赖项包含在项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 使用 Spring 5，我们也可以执行并发测试执行。 7. 使用里程碑 Spring 的发布版本托管在 Maven Central 上。但是，如果项目需要使用里程碑版本，则需要在 pom 中添加自定义 Spring 存储库： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.springframework.maven.milestone\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Framework Maven Milestone Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/milestone/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 一旦定义了这个存储库，项目就可以定义依赖项，例如： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0-M1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 8. 使用快照 与里程碑类似，快照托管在自定义存储库中： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.springframework.maven.snapshot\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Framework Maven Snapshot Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/snapshot/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 在 pom.xml 中启用 SNAPSHOT 存储库后，可以引用以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.3.BUILD-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 以及对于 5.x： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/spring_with_maven/","tags":["Spring Core Basics"],"title":"Spring 和 Maven"},{"categories":["Spring"],"contents":"1. 概述 在本文中，我们将介绍Spring作为最流行的 Java 框架之一的主要价值主张。 更重要的是，我们将尝试了解 Spring 成为我们选择框架的原因。Spring 及其组成部分的详细信息已在我们之前的教程中广泛介绍。因此，我们将跳过介绍性的“如何”部分，而主要关注“为什么”。 2. 为什么使用任何框架？ 在我们开始特别讨论 Spring 之前，让我们首先了解为什么我们首先需要使用任何框架。 像 Java 这样的通用编程语言能够支持各种各样的应用程序。更不用说 Java 每天都在积极地工作和改进。 此外，在这方面有无数的开源和专有库支持 Java。 那么我们到底为什么需要一个框架呢？老实说，使用框架来完成任务并不是绝对必要的。但是，出于以下几个原因，通常建议使用其中一种：  帮助我们专注于核心任务而不是与其相关的样板 以设计模式的形式汇集多年的智慧 帮助我们遵守行业和监管标准 降低应用程序的总拥有成本  我们只是在这里触及了表面，我们必须说这些好处是难以忽视的。但这不可能都是积极的，所以有什么问题：  迫使我们以特定的方式编写应用程序 绑定到特定版本的语言和库 增加应用程序的资源占用  坦率地说，软件开发中没有灵丹妙药，框架当然也不例外。因此，应该从上下文中驱动选择哪个框架或不选择哪个框架。 希望在本文结束时，我们能够更好地做出关于 Java 中的 Spring 的决定。 3. Spring生态系统简介 在我们开始对 Spring Framework 进行定性评估之前，让我们仔细看看 Spring 生态系统是什么样的。 **Spring 出现在 2003 年的某个地方，**当时 Java 企业版正在快速发展，开发企业应用程序令人兴奋但仍然乏味！ Spring 最初是作为Java 的控制反转 (IoC) 容器。我们仍然主要将 Spring 与它联系起来，事实上，它构成了框架的核心以及在它之上开发的其他项目。 3.1 Spring框架 Spring 框架分为模块，这使得在任何应用程序中都可以很容易地挑选和选择部分：  核心：提供核心功能，如 DI（依赖注入）、国际化、验证和 AOP（面向方面的编程） 数据访问：支持通过 JTA（Java Transaction API）、JPA（Java Persistence API）和 JDBC（Java 数据库连接）进行数据访问 Web：同时支持 Servlet API ( Spring MVC ) 和最近的 Reactive API ( Spring WebFlux )，另外还支持 WebSockets、STOMP 和 WebClient 集成：支持通过 JMS（Java 消息服务）、JMX（Java 管理扩展）和 RMI（远程方法调用）集成到 Enterprise Java 测试：通过模拟对象、测试装置、上下文管理和缓存对单元和集成测试提供广泛支持  3.2 Spring项目 但是，让 Spring 更有价值的是一个强大的生态系统，多年来围绕它发展并继续积极发展。这些都是在 Spring 框架之上开发的Spring 项目。 虽然 Spring 项目的列表很长，而且还在不断变化，但有几个值得一提：  Boot：为我们提供了一套高度自以为是但可扩展的模板，几乎可以在短时间内创建各种基于 Spring 的项目。它使得使用嵌入式 Tomcat 或类似容器创建独立的 Spring 应用程序变得非常容易。 云：提供支持以轻松开发一些常见的分布式系统模式，如服务发现、断路器和 API 网关。它可以帮助我们减少在本地、远程甚至托管平台上部署此类样板模式的工作量。 安全性：提供强大的机制，以高度可定制的方式为基于 Spring 的项目开发身份验证和授权。通过最少的声明性支持，我们可以防止会话固定、点击劫持和跨站点请求伪造等常见攻击。 移动：提供检测设备并相应地调整应用程序行为的功能。此外，支持设备感知视图管理以获得最佳用户体验、站点偏好管理和站点切换器。 Batch：提供轻量级框架，用于为数据归档等企业系统开发批处理应用程序。对调度、重新启动、跳过、收集指标和日志记录具有直观的支持。此外，支持通过优化和分区扩展大容量作业。  不用说，这是对 Spring 所提供的内容的相当抽象的介绍。但它为我们提供了足够的关于 Spring 的组织和广度的基础来进一步讨论。 4. Spring 示例 习惯上添加一个 hello-world 程序来了解任何新技术。 让我们看看Spring 如何让编写一个不仅仅是 hello-world 的程序变得轻而易举。我们将创建一个应用程序，它将 CRUD 操作公开为 REST API，用于由内存数据库支持的域实体（如 Employee）。更重要的是，我们将使用基本身份验证保护我们的突变端点。最后，没有好的、旧的单元测试，任何应用程序都不可能真正完整。 4.1 项目设置 我们将使用Spring Initializr设置我们的 Spring Boot 项目，这是一个方便的在线工具，可以使用正确的依赖项引导项目。我们将添加 Web、JPA、H2 和 Security 作为项目依赖项，以正确设置 Maven 配置。 有关引导的更多详细信息，请参阅我们之前的一篇文章。 4.2 领域模型和持久性 要做的事情很少，我们已经准备好定义我们的领域模型和持久性。 让我们首先将Employee定义为一个简单的 JPA 实体： @Entity public class Employee { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; @NotNull private String firstName; @NotNull private String lastName; // Standard constructor, getters and setters } 请注意我们在实体定义中包含的自动生成的 ID。 现在我们必须为我们的实体定义一个 JPA 存储库。这是 Spring 让它变得非常简单的地方： public interface EmployeeRepository extends CrudRepository\u0026lt;Employee, Long\u0026gt; { List\u0026lt;Employee\u0026gt; findAll(); } 我们所要做的就是定义一个这样的接口，Spring JPA 将为我们提供一个包含默认和自定义操作的实现。相当整洁！在我们的其他文章中查找有关使用 Spring Data JPA的更多详细信息。 4.3 控制器 现在我们必须定义一个 Web 控制器来路由和处理我们的传入请求： @RestController public class EmployeeController { @Autowired private EmployeeRepository repository; @GetMapping(\u0026#34;/employees\u0026#34;) public List\u0026lt;Employee\u0026gt; getEmployees() { return repository.findAll(); } // Other CRUD endpoints handlers } 实际上，我们所要做的就是注释类并定义路由元信息以及每个处理程序方法。 我们之前的文章详细介绍了使用Spring REST 控制器。 4.4 安全 所以我们现在已经定义了一切，但是如何保护诸如创建或删除员工之类的操作呢？我们不希望未经身份验证的访问这些端点！ Spring Security 在这方面确实大放异彩： @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/employees\u0026#34;, \u0026#34;/employees/**\u0026#34;) .permitAll() .anyRequest() .authenticated() .and() .httpBasic(); } // other necessary beans and definitions } 这里有更多细节需要注意理解，但最重要的一点是我们只允许不受限制的 GET 操作的声明方式。 4.5 测试 现在我们已经完成了所有工作，但是等等，我们如何测试呢？ 让我们看看 Spring 是否可以轻松地为 REST 控制器编写单元测试： @RunWith(SpringRunner.class) @SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT) @AutoConfigureMockMvc public class EmployeeControllerTests { @Autowired private MockMvc mvc; @Test @WithMockUser() public void givenNoEmployee_whenCreateEmployee_thenEmployeeCreated() throws Exception { mvc.perform(post(\u0026#34;/employees\u0026#34;).content( new ObjectMapper().writeValueAsString(new Employee(\u0026#34;First\u0026#34;, \u0026#34;Last\u0026#34;)) .with(csrf())) .contentType(MediaType.APPLICATION_JSON) .accept(MediaType.APPLICATION_JSON)) .andExpect(MockMvcResultMatchers.status() .isCreated()) .andExpect(jsonPath(\u0026#34;$.firstName\u0026#34;, is(\u0026#34;First\u0026#34;))) .andExpect(jsonPath(\u0026#34;$.lastName\u0026#34;, is(\u0026#34;Last\u0026#34;))); } // other tests as necessary } 正如我们所见，Spring 为我们提供了编写简单单元和集成测试所需的基础设施，否则这些测试依赖于 Spring 上下文进行初始化和配置。 4.6 运行应用程序 最后，我们如何运行这个应用程序？这是 Spring Boot 的另一个有趣的方面。尽管我们可以将其打包为常规应用程序并传统上部署在 Servlet 容器上。 但是这哪有什么好玩的！Spring Boot 带有一个嵌入式 Tomcat 服务器： @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 这是一个作为引导程序的一部分预先创建的类，具有使用嵌入式服务器启动此应用程序的所有必要细节。 此外，这是高度可定制的。 5. Spring 的替代品 虽然选择使用框架相对容易，但在框架之间进行选择通常会因我们的选择而令人生畏。但为此，我们必须至少对 Spring 必须提供的功能有哪些替代方案有一个粗略的了解。 正如我们之前所讨论的，Spring 框架及其项目为企业开发人员提供了广泛的选择。如果我们对当代 Java 框架进行快速评估，它们甚至还没有接近 Spring 为我们提供的生态系统。 但是，对于特定领域，它们确实形成了一个令人信服的论据来选择替代方案：  Guice：为 Java 应用程序提供强大的 IoC 容器 Play：非常适合作为具有响应式支持的 Web 框架 Hibernate : 已建立的支持 JPA 的数据访问框架  除了这些之外，还有一些最近添加的内容提供了比特定域更广泛的支持，但仍然没有涵盖 Spring 必须提供的所有内容：  Micronaut：针对云原生微服务量身定制的基于 JVM 的框架 Quarkus：一个新时代的 Java 堆栈，承诺提供更快的启动时间和更小的占用空间  显然，完全迭代列表既没有必要也不可行，但我们确实在这里得到了大致的想法。 6. 那么，为什么选择Spring？ 最后，我们已经构建了所有必需的上下文来解决我们的中心问题，为什么是 Spring？我们了解框架可以帮助我们开发复杂的企业应用程序的方式。 此外，我们确实了解针对特定问题的选择，例如 Web、数据访问、框架集成，尤其是 Java。 现在，春天在所有这些中闪耀在哪里？让我们探索一下。 6.1 可用性 任何框架流行的关键方面之一是开发人员使用它的难易程度。Spring 通过多个配置选项和 Convention over Configuration 使开发人员能够非常轻松地开始并准确地配置他们需要的东西。 像Spring Boot 这样的项目使得引导一个复杂的 Spring 项目几乎是微不足道的。更不用说，它有优秀的文档和教程来帮助任何人上手。 6.2 模块化 Spring 受欢迎的另一个关键方面是其高度模块化的特性。我们可以选择使用整个 Spring 框架或仅使用必要的模块。此外，我们可以根据需要选择包含一个或多个 Spring 项目。 更重要的是，我们还可以选择使用其他框架，如 Hibernate 或 Struts！ 6.3 一致性 尽管 Spring不支持所有 Jakarta EE 规范，但它支持其所有技术，并且经常在必要时改进对标准规范的支持。例如，Spring 支持基于 JPA 的存储库，因此可以轻松切换提供程序。 此外，Spring 支持Spring Web Reactive 下的Reactive Stream和Spring HATEOAS 下的 HATEOAS 等行业规范。 6.4 可测试性 采用任何框架很大程度上还取决于测试构建在它之上的应用程序的难易程度。Spring 的核心是倡导并支持测试驱动开发(TDD)。 Spring 应用程序主要由 POJO 组成，这自然使单元测试相对简单得多。但是，Spring 确实为 MVC 等单元测试变得复杂的场景提供了 Mock Objects。 6.5 成熟 Spring 在创新、采用和标准化方面有着悠久的历史。多年来，它已经足够成熟，成为大型企业应用程序开发中面临的最常见问题的默认解决方案。 更令人兴奋的是它的开发和维护有多积极。每天都在开发对新语言功能和企业集成解决方案的支持。 6.6 社区支持 最后但同样重要的是，任何框架甚至库都通过创新在行业中生存下来，没有比社区更好的创新场所了。Spring 是由 Pivotal Software 领导的开源项目，并得到了一个由组织和个人开发人员组成的大型联盟的支持。 这意味着它仍然是上下文相关的，而且往往是未来主义的，这一点从它旗下的项目数量就可以看出。 7. 不使用 Spring 的原因 有各种各样的应用程序可以从不同级别的 Spring 使用中受益，并且随着 Spring 的增长而变化。 但是，我们必须了解 Spring 与任何其他框架一样有助于管理应用程序开发的复杂性。它可以帮助我们避免常见的陷阱，并随着时间的推移保持应用程序的可维护性。 这是以额外的资源占用和学习曲线为代价的，尽管这可能很小。如果真的有一个足够简单且不会变得复杂的应用程序，那么完全不使用任何框架可能会受益更多！ \u0026quot; ","permalink":"http://itcodingman.github.io/spring_why_to_choose/","tags":["Spring Core Basics"],"title":"为什么选择 Spring 作为您的 Java 框架？"},{"categories":["Spring"],"contents":"1. 概述 Spring 的*@Value*注解提供了一种将属性值注入组件的便捷方式。为可能不存在属性的情况提供合理的默认值也非常有用。 这就是我们将在本教程中关注的内容——如何为*@Value* Spring 注解指定默认值。 有关*@Value*的更详细的快速指南，请参阅此处的文章。 2. 字符串默认值 让我们看一下为String属性设置默认值的基本语法： @Value(\u0026#34;${some.key:my default value}\u0026#34;) private String stringWithDefaultValue; 如果some.key无法解析，stringWithDefaultValue**将设置为我的 default value 的默认值。 同样，我们可以设置一个长度为零的字符串作为默认值： @Value(\u0026#34;${some.key:})\u0026#34; private String stringWithBlankDefaultValue; 3. 基本类型 要为boolean和int等基本类型设置默认值，我们使用文字值： @Value(\u0026#34;${some.key:true}\u0026#34;) private boolean booleanWithDefaultValue; @Value(\u0026#34;${some.key:42}\u0026#34;) private int intWithDefaultValue; 如果我们愿意，我们可以通过将类型更改为Boolean和Integer来使用原始包装器。 4. 数组 我们还可以将逗号分隔的值列表注入数组： @Value(\u0026#34;${some.key:one,two,three}\u0026#34;) private String[] stringArrayWithDefaults; @Value(\u0026#34;${some.key:1,2,3}\u0026#34;) private int[] intArrayWithDefaults; 在上面的第一个示例中，值one、two 和three作为默认值注入到stringArrayWithDefaults中。 在第二个示例中，值1、2 和3作为默认值注入到intArrayWithDefaults中。 5. 使用 SpEL 我们还可以使用 Spring 表达式语言 (SpEL) 来指定表达式和默认值。 在下面的示例中，我们希望将 some.system.key设置为系统属性，如果未设置，我们希望使用我的默认系统属性值 作为默认值： @Value(\u0026#34;#{systemProperties[\u0026#39;some.key\u0026#39;] ?: \u0026#39;my default system property value\u0026#39;}\u0026#34;) private String spelWithDefaultValue; \u0026quot; ","permalink":"http://itcodingman.github.io/spring_value_defaults/","tags":["Spring Annotations","Spring Core Basics"],"title":"使用带有默认值的 Spring @Value"},{"categories":["Maven","Spring Security"],"contents":"1.概述 在这个快速教程中，我们将看一下*@Value* 注释。 此注解可用于将值注入 Spring 管理的 bean 中的字段，并且可以在字段或构造函数/方法参数级别应用。 2. 设置应用程序 为了描述这个注解的不同用途，我们需要配置一个简单的 Spring 应用程序配置类。 自然，我们需要一个属性文件来定义我们想要使用*@Value*注释注入的值。因此，我们首先需要在我们的配置类中定义一个@PropertySource——使用属性文件名。 让我们定义属性文件： value.from.file=Value got from the file priority=high listOfValues=A,B,C 3. 使用示例 作为一个基本且几乎无用的示例，我们只能将注释中的“字符串值”注入字段： @Value(\u0026#34;string value\u0026#34;) private String stringValue; 使用*@PropertySource注释允许我们使用带有@Value*注释的属性文件中的值。 在以下示例中，我们从 分配给该字段的文件中获取 Value： @Value(\u0026#34;${value.from.file}\u0026#34;) private String valueFromFile; 我们还可以使用相同的语法从系统属性中设置值。 假设我们已经定义了一个名为systemValue的系统属性： @Value(\u0026#34;${systemValue}\u0026#34;) private String systemValue; 可以为可能未定义的属性提供默认值。在这里， 将注入一些默认值： @Value(\u0026#34;${unknown.param:some default}\u0026#34;) private String someDefault; 如果相同的属性被定义为系统属性并在属性文件中，则系统属性将被应用。 假设我们将属性优先级定义为系统属性，其值为System 属性，并在属性文件中定义为其他内容。该值将是系统属性： @Value(\u0026#34;${priority}\u0026#34;) private String prioritySystemProperty; 有时，我们需要注入一堆值。将它们定义为属性文件中单个属性的逗号分隔值或系统属性并注入数组会很方便。 在第一节中，我们在属性文件的listOfValues中定义了逗号分隔的值，因此数组值将是*[“A”, “B”, “C”]：* @Value(\u0026#34;${listOfValues}\u0026#34;) private String[] valuesArray; 4. SpEL 的高级示例 我们还可以使用 SpEL 表达式来获取值。 如果我们有一个名为priority的系统属性，那么它的值将应用于该字段： @Value(\u0026#34;#{systemProperties[\u0026#39;priority\u0026#39;]}\u0026#34;) private String spelValue; 如果我们没有定义系统属性，那么将分配空值。 为了防止这种情况，我们可以在 SpEL 表达式中提供一个默认值。如果未定义系统属性，我们将获得该字段的一些默认值： @Value(\u0026#34;#{systemProperties[\u0026#39;unknown\u0026#39;] ?: \u0026#39;some default\u0026#39;}\u0026#34;) private String spelSomeDefault; 此外，我们可以使用来自其他 bean 的字段值。假设我们有一个名为someBean的 bean ，其字段someValue等于10。然后，10将分配给该字段： @Value(\u0026#34;#{someBean.someValue}\u0026#34;) private Integer someBeanValue; 我们可以操作属性来获取值列表，这里是字符串值 A、B 和 C 的列表： @Value(\u0026#34;#{\u0026#39;${listOfValues}\u0026#39;.split(\u0026#39;,\u0026#39;)}\u0026#34;) private List\u0026lt;String\u0026gt; valuesList; 5. 将*@Value与Map*一起使用 我们还可以使用*@Value注解来注入Map*属性。 首先，我们需要在属性文件的*{key: \u0026lsquo;value\u0026rsquo; }*表单中定义属性： valuesMap={key1: \u0026#39;1\u0026#39;, key2: \u0026#39;2\u0026#39;, key3: \u0026#39;3\u0026#39;} 请注意，Map中的值必须用单引号引起来。 现在我们可以将属性文件中的这个值作为Map注入： @Value(\u0026#34;#{${valuesMap}}\u0026#34;) private Map\u0026lt;String, Integer\u0026gt; valuesMap; 如果我们需要在Map中获取特定键的值，我们所要做的就是在表达式中添加键的名称： @Value(\u0026#34;#{${valuesMap}.key1}\u0026#34;) private Integer valuesMapKey1; 如果我们不确定Map是否包含某个键，我们应该选择一个更安全的表达式，它不会抛出异常，而是在找不到键时将值设置为null ： @Value(\u0026#34;#{${valuesMap}[\u0026#39;unknownKey\u0026#39;]}\u0026#34;) private Integer unknownMapKey; 我们还可以为可能不存在的属性或键设置默认值： @Value(\u0026#34;#{${unknownMap : {key1: \u0026#39;1\u0026#39;, key2: \u0026#39;2\u0026#39;}}}\u0026#34;) private Map\u0026lt;String, Integer\u0026gt; unknownMap; @Value(\u0026#34;#{${valuesMap}[\u0026#39;unknownKey\u0026#39;] ?: 5}\u0026#34;) private Integer unknownMapKeyWithDefaultValue; 映射条目也可以在注入之前进行过滤。 假设我们只需要获取值大于 1 的条目： @Value(\u0026#34;#{${valuesMap}.?[value\u0026gt;\u0026#39;1\u0026#39;]}\u0026#34;) private Map\u0026lt;String, Integer\u0026gt; valuesMapFiltered; 我们还可以使用*@Value*注解注入所有当前系统属性： @Value(\u0026#34;#{systemProperties}\u0026#34;) private Map\u0026lt;String, String\u0026gt; systemPropertiesMap; 6. 将*@Value*与构造函数注入一起使用 当我们使用*@Value*注解时，我们并不局限于字段注入。我们也可以将它与构造函数注入一起使用。 让我们在实践中看看： @Component @PropertySource(\u0026#34;classpath:values.properties\u0026#34;) public class PriorityProvider { private String priority; @Autowired public PriorityProvider(@Value(\u0026#34;${priority:normal}\u0026#34;) String priority) { this.priority = priority; } // standard getter } 在上面的示例中，我们将优先级直接注入到PriorityProvider的构造函数中。 请注意，我们还提供默认值以防找不到该属性。 7. 使用*@Value*和 Setter 注入 类似于构造函数注入，我们也可以使用@Value*和setter注入。* 让我们来看看： @Component @PropertySource(\u0026#34;classpath:values.properties\u0026#34;) public class CollectionProvider { private List\u0026lt;String\u0026gt; values = new ArrayList\u0026lt;\u0026gt;(); @Autowired public void setValues(@Value(\u0026#34;#{\u0026#39;${listOfValues}\u0026#39;.split(\u0026#39;,\u0026#39;)}\u0026#34;) List\u0026lt;String\u0026gt; values) { this.values.addAll(values); } // standard getter } 我们使用 SpEL 表达式将值列表注入到setValues方法中。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_value_annotation/","tags":["Spring Security Basics"],"title":"Spring @Value 快速指南"},{"categories":["Spring MVC"],"contents":"1. 概述 在本文中，我们将解释如何**使用 Maven 设置 Spring Security，**并介绍使用 Spring Security 依赖项的特定用例。您可以在 Maven Central 上找到最新的 Spring Security 版本。 这是上一篇 Spring with Maven 文章的后续，因此对于非安全 Spring 依赖项，这是开始的地方。 2. 使用 Maven 的 Spring Security 2.1 Spring Security核心 核心 Spring Security 支持 - spring-security-core - 包含身份验证和访问控制功能。所有使用 Spring Security 的项目都必须包含此依赖项。 此外，spring-security-core支持独立（非 Web）应用程序、方法级安全性和 JDBC： \u0026lt;properties\u0026gt; \u0026lt;spring-security.version\u0026gt;5.3.4.RELEASE\u0026lt;/spring-security.version\u0026gt; \u0026lt;spring.version\u0026gt;5.2.8.RELEASE\u0026lt;/spring.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-security.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，Spring 和 Spring Security 的发布计划不同，因此版本号之间并不总是 1:1 匹配。 如果您使用的是旧版本的 Spring – 同样重要的是要了解一个事实，即**Spring Security 4.1.x 不依赖于 Spring 4.1.x 版本！**例如，当Spring Security 4.1.0发布时，Spring 核心框架已经是 4.2.x，因此包含该版本作为其编译依赖项。计划是在未来的版本中更紧密地调整这些依赖关系——有关更多详细信息，请参阅此 JIRA——但就目前而言，这具有实际意义，我们将在接下来研究。 2.2 Spring Security 要为 Spring Security 添加Web 支持，我们需要spring-security-web依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-security.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这包含过滤器和相关的 Web 安全基础设施，可在 Servlet 环境中启用 URL 访问控制。 2.3 Spring Security 和旧的 Spring Core 依赖问题 这种新的依赖关系也表现出Maven 依赖关系图的问题。如上所述，Spring Security jars 不依赖于最新的 Spring core jars（而是依赖于之前的版本）。这可能会导致这些较旧的依赖项出现在类路径之上，而不是较新的 5.x Spring 工件。 要理解为什么会发生这种情况，我们需要看看Maven 如何解决冲突。在版本冲突的情况下，Maven 将选择最接近树根的 jar。例如，spring-core由spring-orm（5.0.0 .RELEASE版本）和spring-security-core（5.0.2.RELEASE版本）定义。所以在这两种情况下，spring-jdbc都定义在我们项目的根 pom 的深度为 1 处。因此，在我们自己的 pom.xml 中定义spring-orm和spring-security-core的顺序实际上很重要。第一个将优先，所以我们最终可能会在类路径中使用任一版本。 为了解决这个问题，我们必须在我们自己的 pom 中显式定义一些 Spring 依赖，而不是依赖隐式的 Maven 依赖解析机制。这样做会将特定依赖项置于我们的 pom 深度 0（因为它在 pom 本身中定义），因此它将优先。以下所有内容都属于同一类别，并且都需要直接明确定义，或者对于多模块项目，在父项的dependencyManagement元素中进行明确定义： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-beans\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-tx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-expression\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.4 spring-security-config和其他 要使用丰富的 Spring Security XML 命名空间和注释，我们需要spring-security-config依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-security.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最后，LDAP、ACL、CAS、OAuth 和 OpenID 支持在 Spring Security 中都有自己的依赖项：spring-security-ldap、spring-security-acl、spring-security-cas、spring-security-oauth和spring-security-openid。 3. 使用 Spring Boot 使用 Spring Boot 时，spring-boot-starter-security启动器将自动包含所有依赖项，例如spring-security-core、spring-security-web和spring-security-config等： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 由于 Spring Boot 将自动为我们管理所有依赖项，这也将摆脱前面提到的 Spring 安全性和旧的核心依赖项问题。 4. 使用快照和里程碑 Spring Security里程碑和快照在 Spring 提供的自定义 Maven 存储库中可用。有关如何配置这些的更多详细信息，请参阅如何使用快照和里程碑。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_security_with_maven/","tags":["Spring MVC Basics"],"title":"使用 Maven 的 Spring 安全性"},{"categories":["Spring MVC"],"contents":"1. 简介 在这个快速教程中，我们简要概述了 Spring @RequestBody和*@ResponseBody*注释。 2. @RequestBody 简单地说，@RequestBody注释将HttpRequest主体映射到传输或域对象，从而将入站HttpRequest主体自动反序列化到 Java 对象上。 首先，我们来看一个 Spring 控制器方法： @PostMapping(\u0026#34;/request\u0026#34;) public ResponseEntity postController( @RequestBody LoginForm loginForm) { exampleService.fakeAuthenticate(loginForm); return ResponseEntity.ok(HttpStatus.OK); } 假设指定了适当的类型，Spring 会自动将 JSON 反序列化为 Java 类型。 默认情况下，我们使用@RequestBody*注解注解的类型必须对应于从我们的客户端控制器发送的 JSON：* public class LoginForm { private String username; private String password; // ... } 在这里，我们用来表示HttpRequest主体的对象映射到我们的LoginForm对象。 让我们使用 CURL 进行测试： curl -i \\ -H \u0026#34;Accept: application/json\u0026#34; \\ -H \u0026#34;Content-Type:application/json\u0026#34; \\ -X POST --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;ann\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;}\u0026#39; \u0026#34;https://localhost:8080/.../request\u0026#34; 这就是使用*@RequestBody*注解的 Spring REST API 和 Angular 客户端所需要的全部内容。 3. @ResponseBody @ResponseBody注解告诉控制器返回的对象自动序列化为 JSON 并传回HttpResponse对象。 假设我们有一个自定义的Response对象： public class ResponseTransfer { private String text; // standard getters/setters } 接下来，可以实现关联的控制器： @Controller @RequestMapping(\u0026#34;/post\u0026#34;) public class ExamplePostController { @Autowired ExampleService exampleService; @PostMapping(\u0026#34;/response\u0026#34;) @ResponseBody public ResponseTransfer postResponseController( @RequestBody LoginForm loginForm) { return new ResponseTransfer(\u0026#34;Thanks For Posting!!!\u0026#34;); } } 在我们浏览器的开发者控制台中或者使用 Postman 之类的工具，我们可以看到如下响应： {\u0026#34;text\u0026#34;:\u0026#34;Thanks For Posting!!!\u0026#34;} *请记住，我们不需要使用 @ResponseBody 注解来注解@RestController-*注解的控制器，**因为 Spring 默认会这样做。 3.1 设置内容类型 当我们使用*@ResponseBody*注解时，我们仍然能够显式地设置我们的方法返回的内容类型。 为此，我们可以使用@RequestMapping的produces属性。**请注意，@PostMapping、@GetMapping等注释定义了该参数的别名。 现在让我们添加一个发送 JSON 响应的新端点： @PostMapping(value = \u0026#34;/content\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) @ResponseBody public ResponseTransfer postResponseJsonContent( @RequestBody LoginForm loginForm) { return new ResponseTransfer(\u0026#34;JSON Content!\u0026#34;); } 在示例中，我们使用了MediaType.APPLICATION_JSON_VALUE常量。或者，我们可以直接使用application/json。 接下来，让我们实现一个新方法，映射到相同的*/content*路径，但返回 XML 内容： @PostMapping(value = \u0026#34;/content\u0026#34;, produces = MediaType.APPLICATION_XML_VALUE) @ResponseBody public ResponseTransfer postResponseXmlContent( @RequestBody LoginForm loginForm) { return new ResponseTransfer(\u0026#34;XML Content!\u0026#34;); } 现在，根据请求标头中发送的Accept参数的值，我们将得到不同的响应。 让我们看看它的实际效果： curl -i \\  -H \u0026#34;Accept: application/json\u0026#34; \\  -H \u0026#34;Content-Type:application/json\u0026#34; \\  -X POST --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;ann\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;}\u0026#39; \u0026#34;https://localhost:8080/.../content\u0026#34; CURL 命令返回 JSON 响应： HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 20 Feb 2020 19:43:06 GMT {\u0026#34;text\u0026#34;:\u0026#34;JSON Content!\u0026#34;} 现在，让我们更改Accept参数： curl -i \\ -H \u0026#34;Accept: application/xml\u0026#34; \\ -H \u0026#34;Content-Type:application/json\u0026#34; \\ -X POST --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;ann\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;}\u0026#39; \u0026#34;https://localhost:8080/.../content\u0026#34; 正如预期的那样，这次我们得到了一个 XML 内容： HTTP/1.1 200 Content-Type: application/xml Transfer-Encoding: chunked Date: Thu, 20 Feb 2020 19:43:19 GMT \u0026lt;ResponseTransfer\u0026gt;\u0026lt;text\u0026gt;XML Content!\u0026lt;/text\u0026gt;\u0026lt;/ResponseTransfer\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/spring_request_response_body/","tags":["Spring Annotations","Spring Core Basics","Spring MVC Basics"],"title":"Spring 的 @RequestBody 和 @ResponseBody 注解"},{"categories":["Spring"],"contents":"1. 概述 在这个快速教程中，我们将探索 Spring 的*@RequestParam*注解及其属性。 简单来说，我们可以使用@RequestParam*从请求中提取查询参数、表单参数，甚至是文件。* 2. 一个简单的映射 假设我们有一个端点*/api/foos*接受一个名为 id的查询参数： @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam String id) { return \u0026#34;ID: \u0026#34; + id; } 在此示例中，我们使用*@RequestParam来提取id*查询参数。 一个简单的 GET 请求会调用getFoos： http://localhost:8080/spring-mvc-basics/api/foos?id=abc ---- ID: abc 接下来，让我们看一下注解的属性：name、 value、required和defaultValue。 3. 指定请求参数名称 在前面的例子中，变量名和参数名都是一样的。 **不过，有时我们希望这些有所不同。**或者，如果我们不使用 Spring Boot，我们可能需要进行特殊的编译时配置，否则参数名称实际上不会出现在字节码中。 幸运的是，我们可以使用name属性配置*@RequestParam*名称： @PostMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String addFoo(@RequestParam(name = \u0026#34;id\u0026#34;) String fooId, @RequestParam String name) { return \u0026#34;ID: \u0026#34; + fooId + \u0026#34; Name: \u0026#34; + name; } 我们也可以使用 @RequestParam(value = \u0026ldquo;id\u0026rdquo;)或只是@RequestParam(\u0026ldquo;id\u0026rdquo;)。 4. 可选请求参数 默认情况下需要使用*@RequestParam*注释的方法参数 。 这意味着如果请求中不存在参数，我们将收到错误： GET /api/foos HTTP/1.1 ----- 400 Bad Request Required String parameter \u0026#39;id\u0026#39; is not present 不过，我们可以使用required 属性将@RequestParam*配置为可选的：* @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam(required = false) String id) { return \u0026#34;ID: \u0026#34; + id; } 在这种情况下，两者： http://localhost:8080/spring-mvc-basics/api/foos?id=abc ---- ID: abc 和 http://localhost:8080/spring-mvc-basics/api/foos ---- ID: null 将正确调用该方法。 未指定参数时，方法参数绑定为null。 4.1 使用 Java 8 Optional 或者，我们可以将参数包装在 *Optional*中： @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam Optional\u0026lt;String\u0026gt; id){ return \u0026#34;ID: \u0026#34; + id.orElseGet(() -\u0026gt; \u0026#34;not provided\u0026#34;); } 在这种情况下，我们不需要指定required属性。 如果未提供请求参数，将使用默认值： http://localhost:8080/spring-mvc-basics/api/foos ---- ID: not provided 5. 请求参数的默认值 我们还可以 使用defaultValue属性为*@RequestParam设置默认值：* @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam(defaultValue = \u0026#34;test\u0026#34;) String id) { return \u0026#34;ID: \u0026#34; + id; } 这就像required=false， 因为用户不再需要提供参数： http://localhost:8080/spring-mvc-basics/api/foos ---- ID: test 虽然，我们仍然可以提供它： http://localhost:8080/spring-mvc-basics/api/foos?id=abc ---- ID: abc 请注意，当我们设置 defaultValue 属性时， required确实设置为false。 6. 映射所有参数 我们也可以有多个参数，而无需定义它们的名称或数量，只需使用Map： @PostMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String updateFoos(@RequestParam Map\u0026lt;String,String\u0026gt; allParams) { return \u0026#34;Parameters are \u0026#34; + allParams.entrySet(); } 然后将反映发送的任何参数： curl -X POST -F \u0026#39;name=abc\u0026#39; -F \u0026#39;id=123\u0026#39; http://localhost:8080/spring-mvc-basics/api/foos ----- Parameters are {[name=abc], [id=123]} 7. 映射多值参数 单个*@RequestParam*可以有多个值： @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam List\u0026lt;String\u0026gt; id) { return \u0026#34;IDs are \u0026#34; + id; } Spring MVC 将映射一个逗号分隔的 id 参数： http://localhost:8080/spring-mvc-basics/api/foos?id=1,2,3 ---- IDs are [1,2,3] 或单独的id参数列表： http://localhost:8080/spring-mvc-basics/api/foos?id=1\u0026amp;id=2 ---- IDs are [1,2] \u0026quot; ","permalink":"http://itcodingman.github.io/spring_request_param/","tags":["Spring Annotations","Spring Core Basics"],"title":"Spring @RequestParam 注解"},{"categories":["REST","Spring MVC"],"contents":"1. 概述 在本教程中，我们将关注Spring MVC 中的主要注解之一：@RequestMapping。 简单来说，注解就是用来将 web 请求映射到 Spring Controller 方法上的。 2. @RequestMapping基础 让我们从一个简单的示例开始：使用一些基本标准将 HTTP 请求映射到方法。 2.1 @RequestMapping — 按路径 @RequestMapping(value = \u0026#34;/ex/foos\u0026#34;, method = RequestMethod.GET) @ResponseBody public String getFoosBySimplePath() { return \u0026#34;Get some Foos\u0026#34;; } 要使用简单的curl命令测试此映射，请运行： curl -i http://localhost:8080/spring-rest/ex/foos 2.2. @RequestMapping — HTTP 方法 HTTP方法参数**没有默认值。**因此，如果我们不指定值，它将映射到任何 HTTP 请求。 这是一个简单的示例，与上一个类似，但这次映射到 HTTP POST 请求： @RequestMapping(value = \u0026#34;/ex/foos\u0026#34;, method = POST) @ResponseBody public String postFoos() { return \u0026#34;Post some Foos\u0026#34;; } 通过curl命令测试 POST： curl -i -X POST http://localhost:8080/spring-rest/ex/foos 3. RequestMapping和 HTTP 标头 3.1 @RequestMapping带有headers属性 通过为请求指定标头，可以进一步缩小映射范围： @RequestMapping(value = \u0026#34;/ex/foos\u0026#34;, headers = \u0026#34;key=val\u0026#34;, method = GET) @ResponseBody public String getFoosWithHeader() { return \u0026#34;Get some Foos with Header\u0026#34;; } 为了测试操作，我们将使用curl标头支持： curl -i -H \u0026#34;key:val\u0026#34; http://localhost:8080/spring-rest/ex/foos 甚至通过*@RequestMapping的headers*属性设置多个标头： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, headers = { \u0026#34;key1=val1\u0026#34;, \u0026#34;key2=val2\u0026#34; }, method = GET) @ResponseBody public String getFoosWithHeaders() { return \u0026#34;Get some Foos with Header\u0026#34;; } 我们可以使用以下命令进行测试： curl -i -H \u0026#34;key1:val1\u0026#34; -H \u0026#34;key2:val2\u0026#34; http://localhost:8080/spring-rest/ex/foos 请注意，对于curl语法，冒号分隔标头键和标头值，与 HTTP 规范中相同，而在 Spring 中，使用等号。 3.2 @RequestMapping消费和生产 由控制器方法生成的映射媒体类型值得特别注意。 我们可以通过上面介绍的*@RequestMapping* headers属性根据其Accept标头映射请求： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, method = GET, headers = \u0026#34;Accept=application/json\u0026#34;) @ResponseBody public String getFoosAsJsonFromBrowser() { return \u0026#34;Get some Foos with Header Old\u0026#34;; } 这种定义Accept标头的方式的匹配是灵活的——它使用 contains 而不是 equals，所以像下面这样的请求仍然可以正确映射： curl -H \u0026#34;Accept:application/json,text/html\u0026#34; http://localhost:8080/spring-rest/ex/foos 从 Spring 3.1 开始，@RequestMapping注解现在具有生产和消费属性，专门用于此目的： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, method = RequestMethod.GET, produces = \u0026#34;application/json\u0026#34; ) @ResponseBody public String getFoosAsJsonFromREST() { return \u0026#34;Get some Foos with Header New\u0026#34;; } 此外，从 Spring 3.1 开始，带有headers属性的旧映射类型将自动转换为新的生产机制，因此结果将是相同的。 这是通过curl以相同的方式使用的： curl -H \u0026#34;Accept:application/json\u0026#34; http://localhost:8080/spring-rest/ex/foos 此外，produces 还支持多个值： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, method = GET, produces = { \u0026#34;application/json\u0026#34;, \u0026#34;application/xml\u0026#34; } ) 请记住，这些（指定Accept标头的新旧方法）基本上是相同的映射，因此 Spring 不允许它们一起使用。 激活这两种方法将导致： Caused by: java.lang.IllegalStateException: Ambiguous mapping found. Cannot map \u0026#39;fooController\u0026#39; bean method java.lang.String org.baeldung.spring.web.controller .FooController.getFoosAsJsonFromREST() to { [/ex/foos], methods=[GET],params=[],headers=[], consumes=[],produces=[application/json],custom=[] }: There is already \u0026#39;fooController\u0026#39; bean method java.lang.String org.baeldung.spring.web.controller .FooController.getFoosAsJsonFromBrowser() mapped. 关于新生产和消费机制的最后一点说明，其行为与大多数其他注释不同：在类型级别指定时，方法级别注释不会补充而是覆盖类型级别信息。 当然，如果您想深入了解如何使用 Spring 构建 REST API，请查看新的 REST with Spring 课程。 ** 4. 带路径变量的 RequestMapping** 映射 URI 的一部分可以通过*@PathVariable*注释绑定到变量。 4.1 单个@PathVariable 带有单个路径变量的简单示例： @RequestMapping(value = \u0026#34;/ex/foos/{id}\u0026#34;, method = GET) @ResponseBody public String getFoosBySimplePathWithPathVariable( @PathVariable(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Get a specific Foo with id=\u0026#34; + id; } 这可以用curl测试： curl http://localhost:8080/spring-rest/ex/foos/1 如果方法参数的名称与路径变量的名称完全匹配，则可以使用不带值的@PathVariable来简化： @RequestMapping(value = \u0026#34;/ex/foos/{id}\u0026#34;, method = GET) @ResponseBody public String getFoosBySimplePathWithPathVariable( @PathVariable String id) { return \u0026#34;Get a specific Foo with id=\u0026#34; + id; } 请注意，@PathVariable受益于自动类型转换，因此我们也可以将id声明为： @PathVariable long id 4.2 多个@PathVariable 更复杂的 URI 可能需要将 URI 的多个部分映射到多个值： @RequestMapping(value = \u0026#34;/ex/foos/{fooid}/bar/{barid}\u0026#34;, method = GET) @ResponseBody public String getFoosBySimplePathWithPathVariables (@PathVariable long fooid, @PathVariable long barid) { return \u0026#34;Get a specific Bar with id=\u0026#34; + barid + \u0026#34; from a Foo with id=\u0026#34; + fooid; } 这很容易用curl以相同的方式进行测试： curl http://localhost:8080/spring-rest/ex/foos/1/bar/2 4.3 @PathVariable与正则表达式 映射*@PathVariable*时也可以使用正则表达式。 例如，我们将映射限制为只接受id的数值： @RequestMapping(value = \u0026#34;/ex/bars/{numericId:[\\\\d]+}\u0026#34;, method = GET) @ResponseBody public String getBarsBySimplePathWithPathVariable( @PathVariable long numericId) { return \u0026#34;Get a specific Bar with id=\u0026#34; + numericId; } 这意味着以下 URI 将匹配： http://localhost:8080/spring-rest/ex/bars/1 但这不会： http://localhost:8080/spring-rest/ex/bars/abc 5. 请求参数的RequestMapping @RequestMapping 允许使用@RequestParam注释轻松映射 URL 参数。 我们现在将请求映射到 URI： http://localhost:8080/spring-rest/ex/bars?id=100 @RequestMapping(value = \u0026#34;/ex/bars\u0026#34;, method = GET) @ResponseBody public String getBarBySimplePathWithRequestParam( @RequestParam(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Get a specific Bar with id=\u0026#34; + id; } 然后，我们使用控制器方法签名中的*@RequestParam(\u0026ldquo;id\u0026rdquo;)注释来提取id*参数的值。 要发送带有id参数的请求，我们将使用curl中的参数支持： curl -i -d id=100 http://localhost:8080/spring-rest/ex/bars 在这个例子中，参数是直接绑定的，没有先声明。 对于更高级的场景，@RequestMapping可以选择将参数定义为缩小请求映射的另一种方式： @RequestMapping(value = \u0026#34;/ex/bars\u0026#34;, params = \u0026#34;id\u0026#34;, method = GET) @ResponseBody public String getBarBySimplePathWithExplicitRequestParam( @RequestParam(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Get a specific Bar with id=\u0026#34; + id; } 允许更灵活的映射。可以设置多个参数值，而不是必须使用所有参数值： @RequestMapping( value = \u0026#34;/ex/bars\u0026#34;, params = { \u0026#34;id\u0026#34;, \u0026#34;second\u0026#34; }, method = GET) @ResponseBody public String getBarBySimplePathWithExplicitRequestParams( @RequestParam(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Narrow Get a specific Bar with id=\u0026#34; + id; } 当然，还有对 URI 的请求，例如： http://localhost:8080/spring-rest/ex/bars?id=100\u0026amp;second=something 将始终映射到最佳匹配——这是更窄的匹配，它定义了id和第二个参数。 6. RequestMapping角落案例 6.1 @RequestMapping — 映射到同一个控制器方法的多个路径 尽管单个*@RequestMapping*路径值通常用于单个控制器方法（只是一种好的做法，而不是硬性规定），但在某些情况下可能需要将多个请求映射到同一个方法。 在这种情况下，@RequestMapping的value属性确实接受多个映射，而不仅仅是一个： @RequestMapping( value = { \u0026#34;/ex/advanced/bars\u0026#34;, \u0026#34;/ex/advanced/foos\u0026#34; }, method = GET) @ResponseBody public String getFoosOrBarsByPath() { return \u0026#34;Advanced - Get some Foos or Bars\u0026#34;; } 现在这两个curl命令都应该使用相同的方法： curl -i http://localhost:8080/spring-rest/ex/advanced/foos curl -i http://localhost:8080/spring-rest/ex/advanced/bars 6.2 @RequestMapping — 对同一个控制器方法的多个 HTTP 请求方法 使用不同 HTTP 动词的多个请求可以映射到同一个控制器方法： @RequestMapping( value = \u0026#34;/ex/foos/multiple\u0026#34;, method = { RequestMethod.PUT, RequestMethod.POST } ) @ResponseBody public String putAndPostFoos() { return \u0026#34;Advanced - PUT and POST within single method\u0026#34;; } 使用curl，这两个现在都将使用相同的方法： curl -i -X POST http://localhost:8080/spring-rest/ex/foos/multiple curl -i -X PUT http://localhost:8080/spring-rest/ex/foos/multiple 6.3 @RequestMapping — 所有请求的后备 要使用特定 HTTP 方法为所有请求实现简单的回退，例如，对于 GET： @RequestMapping(value = \u0026#34;*\u0026#34;, method = RequestMethod.GET) @ResponseBody public String getFallback() { return \u0026#34;Fallback for GET Requests\u0026#34;; } 甚至对于所有请求： @RequestMapping( value = \u0026#34;*\u0026#34;, method = { RequestMethod.GET, RequestMethod.POST ... }) @ResponseBody public String allFallback() { return \u0026#34;Fallback for All Requests\u0026#34;; } 6.4 模棱两可的映射错误 当 Spring 评估两个或多个请求映射对于不同的控制器方法相同时，会发生不明确的映射错误。当请求映射具有相同的 HTTP 方法、URL、参数、标头和媒体类型时，它是相同的。 例如，这是一个模棱两可的映射： @GetMapping(value = \u0026#34;foos/duplicate\u0026#34; ) public String duplicate() { return \u0026#34;Duplicate\u0026#34;; } @GetMapping(value = \u0026#34;foos/duplicate\u0026#34; ) public String duplicateEx() { return \u0026#34;Duplicate\u0026#34;; } 抛出的异常通常确实包含以下错误消息： Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map \u0026#39;fooMappingExamplesController\u0026#39; method public java.lang.String com.codingman.web.controller.FooMappingExamplesController.duplicateEx() to {[/ex/foos/duplicate],methods=[GET]}: There is already \u0026#39;fooMappingExamplesController\u0026#39; bean method public java.lang.String com.codingman.web.controller.FooMappingExamplesController.duplicate() mapped. 仔细阅读错误消息会发现 Spring 无法映射方法 *com.codingman.web.controller.FooMappingExamplesController.duplicateEx()，*因为它与已映射的 com.codingman.web.controller的映射存在冲突.FooMappingExamplesController.duplicate()。 下面的代码片段不会导致不明确的映射错误，因为两种方法都返回不同的内容类型： @GetMapping(value = \u0026#34;foos/duplicate\u0026#34;, produces = MediaType.APPLICATION_XML_VALUE) public String duplicateXml() { return \u0026#34;\u0026lt;message\u0026gt;Duplicate\u0026lt;/message\u0026gt;\u0026#34;; } @GetMapping(value = \u0026#34;foos/duplicate\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) public String duplicateJson() { return \u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Duplicate\\\u0026#34;}\u0026#34;; } 这种区分允许我们的控制器根据请求中提供的Accepts标头返回正确的数据表示 。 解决此问题的另一种方法是更新分配给所涉及的两种方法中的任何一种的 URL。 7. 新的请求映射快捷方式 Spring Framework 4.3 引入了一些新的HTTP 映射注解，全部基于*@RequestMapping*：  @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping  这些新的注释可以提高可读性并减少代码的冗长。 让我们通过创建一个支持 CRUD 操作的 RESTful API 来看看这些新注释的实际应用： @GetMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; getBazz(@PathVariable String id){ return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(id, \u0026#34;Bazz\u0026#34;+id), HttpStatus.OK); } @PostMapping public ResponseEntity\u0026lt;?\u0026gt; newBazz(@RequestParam(\u0026#34;name\u0026#34;) String name){ return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(\u0026#34;5\u0026#34;, name), HttpStatus.OK); } @PutMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; updateBazz( @PathVariable String id, @RequestParam(\u0026#34;name\u0026#34;) String name) { return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(id, name), HttpStatus.OK); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; deleteBazz(@PathVariable String id){ return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(id), HttpStatus.OK); } 可以在这里找到对这些的深入了解。 8. Spring 配置 考虑到我们的FooController定义在以下包中，Spring MVC 配置非常简单： package com.codingman.controller; @Controller public class FooController { ... } 我们只需要一个*@Configuration*类来启用完整的 MVC 支持并为控制器配置类路径扫描： @Configuration @EnableWebMvc @ComponentScan({ \u0026#34;com.codingman.controller\u0026#34; }) public class MvcConfig { // } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_requestmapping/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring请求映射"},{"categories":["Spring"],"contents":"1.概述 在本教程中，我们将探讨**@Qualifier注解**可以帮助我们解决哪些问题，以及如何使用它。 2. Autowire 需要消歧义 @Autowired注解是一种在 Spring 中显式注入依赖项的好方法。尽管它很有用，但在某些用例中，仅此注解不足以让 Spring 了解要注入哪个 bean。 默认情况下，Spring 按类型解析自动装配的条目。 如果容器中有多个相同类型的 bean 可用，框架将抛出 NoUniqueBeanDefinitionException，表明有多个 bean 可用于自动装配。 让我们想象这样一种情况，其中 Spring 存在两个可能的候选对象，以便在给定实例中作为 bean 协作者注入： @Component(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter implements Formatter { public String format() { return \u0026#34;foo\u0026#34;; } } @Component(\u0026#34;barFormatter\u0026#34;) public class BarFormatter implements Formatter { public String format() { return \u0026#34;bar\u0026#34;; } } @Component public class FooService { @Autowired private Formatter formatter; } 如果我们尝试将FooService加载到我们的上下文中，Spring 框架将抛出* NoUniqueBeanDefinitionException*。这是因为Spring 不知道要注入哪个 bean。为了避免这个问题，有几种解决方案；@Qualifier注释就是其中之一。 3. @Qualifier注解 通过使用*@Qualifier*注解，我们可以消除需要注入哪个 bean 的问题。 让我们重新回顾之前的示例，看看我们如何通过包含*@Qualifier*注释来指示我们要使用哪个 bean 来解决问题： public class FooService { @Autowired @Qualifier(\u0026#34;fooFormatter\u0026#34;) private Formatter formatter; } 通过包含*@Qualifier注解，以及我们要使用的具体实现的名称，在这个例子中Foo*，我们可以避免当 Spring 找到多个相同类型的 bean 时产生歧义。 我们需要考虑到要使用的限定符名称是*@Component*注解中声明的名称。 请注意，我们也可以在Formatter实现类上使用*@Qualifier注释，而不是在它们的@Component*注释中指定名称，以获得相同的效果： @Component @Qualifier(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter implements Formatter { //... } @Component @Qualifier(\u0026#34;barFormatter\u0026#34;) public class BarFormatter implements Formatter { //... } 4. @Qualifier与*@Primary* 还有另一个名为@Primary的注解 ，当依赖注入存在歧义时，我们可以使用它来决定注入哪个 bean。 **当存在多个相同类型的 bean 时，*此注释定义了一个首选项。除非另有说明，否则将使用与@Primary*注释关联的 bean 。 让我们看一个例子： @Configuration public class Config { @Bean public Employee johnEmployee() { return new Employee(\u0026#34;Ann\u0026#34;); } @Bean @Primary public Employee tonyEmployee() { return new Employee(\u0026#34;Bob\u0026#34;); } } 在此示例中，两种方法都返回相同的Employee类型。Spring 将注入的 bean 是方法tonyEmployee返回的 bean 。这是因为它包含*@Primary*注释。当我们要指定默认注入某种类型的 bean时，此注解很有用。 如果我们在某个注入点需要另一个 bean，我们需要特别指出它。我们可以通过*@Qualifier注解做到这一点。例如，我们可以通过使用@Qualifier注释来指定我们想要使用johnEmployee*方法返回的 bean。 值得注意的是，*如果@Qualifier和@Primary注释都存在，那么@Qualifier注释将具有优先权。**基本上，@Primary定义了一个默认值，而@Qualifier*非常具体。 让我们看一下使用*@Primary*注解的另一种方式，这次使用初始示例： @Component @Primary public class FooFormatter implements Formatter { //... } @Component public class BarFormatter implements Formatter { //... } **在这种情况下，@Primary注释被放置在实现类之一中，**并将消除场景的歧义。 5. @Qualifier与按名称自动装配 自动装配时在多个 bean 之间做出决定的另一种方法是使用要注入的字段的名称。这是默认设置，以防 Spring 没有其他提示。让我们看一些基于我们最初示例的代码： public class FooService { @Autowired private Formatter fooFormatter; } 在这种情况下，Spring 将确定要注入的 bean 是FooFormatter的，因为字段名称与我们在*@Component*注释中为该 bean使用的值匹配。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_qualifier_annotation/","tags":["Spring Core Basics"],"title":"Spring @Qualifier 注解"},{"categories":["Spring MVC"],"contents":"1. 概述 在本教程中，我们将重点介绍 Spring 中的 Profiles。 配置文件是框架的核心特性——允许我们将 bean 映射到不同的配置文件——例如dev、test和prod。 然后，我们可以在不同的环境中激活不同的配置文件以仅引导我们需要的 bean。 2. 在 Bean 上使用@Profile 让我们从简单的开始，看看我们如何让一个 bean 属于一个特定的配置文件。我们使用@Profile*注释——我们将 bean 映射到那个特定的配置文件*；注释仅采用一个（或多个）配置文件的名称。 考虑一个基本场景：我们有一个 bean，它应该只在开发期间处于活动状态，而不是在生产中部署。 我们使用开发配置文件注释该 bean ，它只会在开发期间出现在容器中。在生产中，开发人员根本不会处于活动状态： @Component @Profile(\u0026#34;dev\u0026#34;) public class DevDatasourceConfig 作为一个快速的旁注，配置文件名称也可以使用 NOT 运算符作为前缀，例如*!dev*，以将它们从配置文件中排除。 在示例中，仅当dev 配置文件未激活时才会激活组件： @Component @Profile(\u0026#34;!dev\u0026#34;) public class DevDatasourceConfig 3. 在 XML 中声明配置文件 配置文件也可以在 XML 中配置。\u0026lt; beans\u0026gt;标签有一个profile属性，它采用逗号分隔的适用配置文件的值： \u0026lt;beans profile=\u0026#34;dev\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;devDatasourceConfig\u0026#34; class=\u0026#34;org.codingman.profiles.DevDatasourceConfig\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 4.设置配置文件 下一步是激活和设置配置文件，以便在容器中注册相应的 bean。 这可以通过多种方式完成，我们将在以下部分中进行探讨。 4.1 通过WebApplicationInitializer接口以编程方式 在 Web 应用程序中，WebApplicationInitializer可用于以编程方式配置ServletContext。 它也是以编程方式设置我们的活动配置文件的非常方便的位置： @Configuration public class MyWebApplicationInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletContext) throws ServletException { servletContext.setInitParameter( \u0026#34;spring.profiles.active\u0026#34;, \u0026#34;dev\u0026#34;); } } 4.2 通过ConfigurableEnvironment以编程方式 我们还可以直接在环境中设置配置文件： @Autowired private ConfigurableEnvironment env; ... env.setActiveProfiles(\u0026#34;someProfile\u0026#34;); 4.3 web.xml中的上下文参数 同样，我们可以使用上下文参数在 Web 应用程序的web.xml文件中定义活动配置文件： \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/app-config.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;spring.profiles.active\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;dev\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; 4.4 JVM 系统参数 配置文件名称也可以通过 JVM 系统参数传入。这些配置文件将在应用程序启动期间激活： -Dspring.profiles.active=dev 4.5 环境变量 在 Unix 环境中，配置文件也可以通过环境变量激活： export spring_profiles_active=dev 4.6 Maven 简介 Spring 配置文件也可以通过 Maven 配置文件激活，通过指定spring.profiles.active 配置属性。 在每个 Maven 配置文件中，我们可以设置一个spring.profiles.active属性： \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;dev\u0026lt;/id\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;spring.profiles.active\u0026gt;dev\u0026lt;/spring.profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;prod\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;spring.profiles.active\u0026gt;prod\u0026lt;/spring.profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; 它的值将用于替换 application.properties 中的@spring.profiles.active@ 占位符：** spring.profiles.active=@spring.profiles.active@ 现在我们需要在pom.xml中启用资源过滤： \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; ... \u0026lt;/build\u0026gt; 并附加一个*-P*参数来切换将应用哪个 Maven 配置文件： mvn clean package -Pprod 此命令将为prod配置文件打包应用程序。它还 在此应用程序运行时应用spring.profiles.active 值prod 。 4.7. 测试中的@ActiveProfile 测试可以很容易地使用*@ActiveProfile*注释指定哪些配置文件处于活动状态以启用特定配置文件： @ActiveProfiles(\u0026#34;dev\u0026#34;) 到目前为止，我们已经研究了多种激活配置文件的方法。现在让我们看看哪个优先级高于另一个，如果我们使用多个优先级会发生什么，从最高到最低优先级：  web.xml中的上下文参数 WebApplicationInitializer JVM 系统参数 环境变量 Maven 简介  5. 默认配置文件 任何未指定配置文件的 bean 都属于默认 配置文件。 Spring 还提供了一种在没有其他配置文件处于活动状态时设置默认配置文件的方法——通过使用spring.profiles.default 属性。 6. 获取活跃的Profile Spring 的活动配置文件驱动*@Profile*注释的行为以启用/禁用 bean。但是，我们也可能希望以编程方式访问活动配置文件列表。 我们有两种方法可以做到这一点，使用Environment或spring.active.profile。 6.1 使用Environment 我们可以通过注入Environment对象来访问活动配置文件： public class ProfileManager { @Autowired private Environment environment; public void getActiveProfiles() { for (String profileName : environment.getActiveProfiles()) { System.out.println(\u0026#34;Currently active profile - \u0026#34; + profileName); } } } 6.2 使用spring.active.profile 或者，我们可以通过注入属性 spring.profiles.active来访问配置文件： @Value(\u0026#34;${spring.profiles.active}\u0026#34;) private String activeProfile; 在这里，我们的activeProfile 变量**将包含当前活动的配置文件的名称，**如果有多个，它将包含用逗号分隔的名称。 但是，我们应该**考虑如果根本没有活动配置文件会发生什么。**使用我们上面的代码，缺少活动配置文件会阻止创建应用程序上下文。由于缺少用于注入变量的占位符，这将导致IllegalArgumentException 。 为了避免这种情况，我们可以定义一个默认值： @Value(\u0026#34;${spring.profiles.active:}\u0026#34;) private String activeProfile; 现在，如果没有激活的配置文件，我们的activeProfile将只包含一个空字符串。 如果我们想像前面的例子一样访问它们的列表，我们可以通过拆分activeProfile变量来实现： public class ProfileManager { @Value(\u0026#34;${spring.profiles.active:}\u0026#34;) private String activeProfiles; public String getActiveProfiles() { for (String profileName : activeProfiles.split(\u0026#34;,\u0026#34;)) { System.out.println(\u0026#34;Currently active profile - \u0026#34; + profileName); } } } 7. 示例：使用配置文件分离数据源配置 既然基础知识已经结束，让我们看一个真实的例子。 考虑一个场景，我们必须为开发和生产环境维护数据源配置。 让我们创建一个需要由两个数据源实现实现的通用接口DatasourceConfig ： public interface DatasourceConfig { public void setup(); } 下面是开发环境的配置： @Component @Profile(\u0026#34;dev\u0026#34;) public class DevDatasourceConfig implements DatasourceConfig { @Override public void setup() { System.out.println(\u0026#34;Setting up datasource for DEV environment. \u0026#34;); } } 以及生产环境的配置： @Component @Profile(\u0026#34;production\u0026#34;) public class ProductionDatasourceConfig implements DatasourceConfig { @Override public void setup() { System.out.println(\u0026#34;Setting up datasource for PRODUCTION environment. \u0026#34;); } } 现在让我们创建一个测试并注入我们的 DatasourceConfig 接口；根据活动配置文件，Spring 将注入DevDatasourceConfig或ProductionDatasourceConfig bean： public class SpringProfilesWithMavenPropertiesIntegrationTest { @Autowired DatasourceConfig datasourceConfig; public void setupDatasource() { datasourceConfig.setup(); } } 当dev 配置文件处于活动状态时，Spring 注入DevDatasourceConfig对象，然后调用*setup()*方法时，输出如下： Setting up datasource for DEV environment. 8. Spring Boot 中的配置文件 Spring Boot 支持到目前为止列出的所有配置文件配置，并具有一些附加功能。 8.1 激活或设置配置文件 第 4 节中介绍的初始化参数spring.profiles.active也可以设置为 Spring Boot 中的属性，以定义当前活动的配置文件。这是 Spring Boot 将自动获取的标准属性： spring.profiles.active=dev 但是，从 Spring Boot 2.4 开始，此属性不能与spring.config.activate.on-profile结合使用，因为这可能会引发ConfigDataException （ 即InvalidConfigDataPropertyException或InactiveConfigDataAccessException ）。 要以编程方式设置配置文件，我们还可以使用SpringApplication类： SpringApplication.setAdditionalProfiles(\u0026#34;dev\u0026#34;); 要在 Spring Boot 中使用 Maven 设置配置文件，我们可以 在pom.xm l中**的 spring-boot-maven-plugin下指定配置文件名称： \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt;dev\u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; ... \u0026lt;/plugins\u0026gt; 并执行 Spring Boot 特定的 Maven 目标： mvn spring-boot:run 8.2 配置文件特定的属性文件 但是，Spring Boot 带来的最重要的配置文件相关功能是**配置文件特定的属性文件。**这些必须以application-{profile}.properties格式命名。 Spring Boot 将自动为所有配置文件加载application.properties文件中的属性，并且仅为指定配置文件加载特定于配置文件的*.properties文件中的属性。* 例如，我们可以使用名为application-dev.properties和application-production.properties的两个文件为dev和production配置文件配置不同的数据源： 在application-production.properties文件中，我们可以设置一个MySql数据源： spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/db spring.datasource.username=root spring.datasource.password=root 然后我们可以在application-dev.properties文件中为dev配置文件配置相同的属性，以使用内存H2数据库： spring.datasource.driver-class-name=org.h2.Driver spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1 spring.datasource.username=sa spring.datasource.password=sa 这样，我们就可以轻松地为不同的环境提供不同的配置。 在 Spring Boot 2.4 之前，可以从特定于配置文件的文档中激活配置文件。但情况已不再如此；对于更高版本， 在这些情况下，框架将再次抛出InvalidConfigDataPropertyException或 InactiveConfigDataAccessException 。 8.3 多文档文件 为了进一步简化为不同环境定义属性，我们甚至可以将所有属性合并到同一个文件中，并使用分隔符来指示配置文件。 从 2.4 版本开始，除了之前支持的YAML之外，Spring Boot 还扩展了对属性文件的多文档文件的支持。所以现在，我们可以在同一个application.properties中指定dev和production属性： my.prop=used-always-in-all-profiles #--- spring.config.activate.on-profile=dev spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/db spring.datasource.username=root spring.datasource.password=root #--- spring.config.activate.on-profile=production spring.datasource.driver-class-name=org.h2.Driver spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1 spring.datasource.username=sa spring.datasource.password=sa 此文件由 Spring Boot 按从上到下的顺序读取。也就是说，如果某个属性，比如my.prop，在上述示例的末尾再次出现，则将考虑最后的值。 8.4 配置文件组 Boot 2.4 中添加的另一个功能是配置文件组。顾名思义，它允许我们将相似的配置文件组合在一起。 让我们考虑一个用例，其中我们有多个用于生产环境的配置文件。比如说，一个用于数据库的proddb和一个用于生产环境中调度程序的prodquartz 。* 要通过我们的application.properties文件一次性启用这些配置文件，我们可以指定： spring.profiles.group.production=proddb,prodquartz 因此，激活production配置文件也将激活proddb和prodquartz。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_profiles/","tags":["Spring MVC Basics"],"title":"Spring 中的 Profiles"},{"categories":["Spring MVC"],"contents":"1. 概述 所有 MVC 框架都提供了一种处理视图的方法。 Spring 通过视图解析器做到这一点，这使您能够在浏览器中呈现模型，而无需将实现绑定到特定的视图技术。 ViewResolver将视图名称映射到实际视图。 Spring 框架附带了很多视图解析器，例如InternalResourceViewResolver、BeanNameViewResolver和其他一些。 这是一个简单的教程，展示了如何设置最常见的视图解析器以及如何在同一配置中使用多个ViewResolver。 2. Spring Web 配置 让我们从 web 配置开始；我们将使用*@EnableWebMvc*、@Configuration和*@ComponentScan*对其进行注释： @EnableWebMvc @Configuration @ComponentScan(\u0026#34;com.codingman.web\u0026#34;) public class WebConfig implements WebMvcConfigurer { // All web configuration will go here } 在这里，我们将在配置中设置我们的视图解析器。 3. 添加一个InternalResourceViewResolver 这个ViewResolver允许我们为视图名称设置前缀或后缀等属性，以生成最终的视图页面 URL： @Bean public ViewResolver internalResourceViewResolver() { InternalResourceViewResolver bean = new InternalResourceViewResolver(); bean.setViewClass(JstlView.class); bean.setPrefix(\u0026#34;/WEB-INF/view/\u0026#34;); bean.setSuffix(\u0026#34;.jsp\u0026#34;); return bean; } 为了示例的 简单性，我们不需要控制器来处理请求。 我们只需要一个简单的jsp页面，放在配置中定义的*/WEB-INF/view*文件夹中： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is the body of the sample view\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 4. 添加一个BeanNameViewResolver 这是 ViewResovler 的实现，它将视图名称解释为当前应用程序上下文中的 bean 名称。每个此类View都可以定义为 XML 或 Java 配置中的 bean。 首先，我们将BeanNameViewResolver添加到之前的配置中： @Bean public BeanNameViewResolver beanNameViewResolver(){ return new BeanNameViewResolver(); } 一旦定义了 ViewResolver，我们需要定义View类型的 beans，以便DispatcherServlet可以执行它来呈现视图： @Bean public View sample() { return new JstlView(\u0026#34;/WEB-INF/view/sample.jsp\u0026#34;); } 这是控制器类中相应的处理程序方法： @GetMapping(\u0026#34;/sample\u0026#34;) public String showForm() { return \u0026#34;sample\u0026#34;; } 从控制器方法中，视图名称作为“ *sample”*返回，这意味着来自此处理程序方法的视图解析为带有/WEB-INF/view/sample.jspURL 的 JstlView 类。 5. 链接ViewResolver并定义订单优先级 Spring MVC 还支持多个视图解析器。 这允许您在某些情况下覆盖特定视图。我们可以通过在配置中添加多个解析器来简单地链接视图解析器。 完成后，我们需要为这些解析器定义一个顺序。order属性用于定义链中调用的顺序。order 属性（最大订单号）越高，视图解析器在链中的位置就越晚。 要定义顺序，我们可以将以下代码行添加到我们的视图解析器的配置中： bean.setOrder(0); 请注意顺序优先级，因为InternalResourceViewResolver应该具有更高的顺序 - 因为它旨在表示非常明确的映射。如果其他解析器具有更高的顺序，则可能永远不会调用InternalResourceViewResolver 。 6. 使用 Spring Boot 使用 Spring Boot 时，WebMvcAutoConfiguration 会在我们的应用程序上下文中自动配置InternalResourceViewResolver 和BeanNameViewResolver bean 。 此外，为模板引擎添加相应的启动器会消除我们必须执行的大部分手动配置。 例如，通过将spring-boot-starter-thymeleaf依赖添加到我们的 pom.xml 中，Thymeleaf 被启用，并且不需要额外的配置： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot-starter-thymeleaf.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 此启动器依赖项在我们的应用程序上下文中使用名称thymeleafViewResolver配置ThymeleafViewResolver* bean。我们可以通过提供一个同名的 bean 来覆盖自动配置的 ThymeleafViewResolver。 Thymeleaf 视图解析器通过用前缀和后缀包围视图名称来工作。prefix 和 suffix 的默认值分别是 \u0026lsquo;classpath:/templates/\u0026rsquo; 和 \u0026lsquo;.html\u0026rsquo;。 spring.thymeleaf.prefixSpring Boot 还提供了一个选项来分别通过设置和spring.thymeleaf.suffix属性来改变前缀和后缀的默认值。 同样，我们有groovy-templates、freemarker和mustache模板引擎的启动器依赖项，我们可以使用它们来使用 Spring Boot 自动配置相应的视图解析器。 DispatcherServlet使用它在应用程序上下文中找到的所有视图解析器，并尝试每一个，直到得到结果，因此如果我们计划添加自己的视图解析器，这些视图解析器的顺序变得非常重要。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_view_resolver_tutorial/","tags":["Spring MVC Basics"],"title":"Spring MVC 中的 ViewResolver 指南"},{"categories":["Spring MVC"],"contents":"1. 概述 这是一个简单的Spring MVC 教程，展示了如何使用基于 Java 的配置以及 XML 配置来设置 Spring MVC 项目。 Spring MVC 项目的 Maven 依赖项在Spring MVC 依赖项文章中有详细描述。 2. 什么是Spring MVC？ 顾名思义，**它是 Spring 框架的一个模块，处理 Model-View-Controller 或 MVC 模式。**它结合了 MVC 模式的所有优点和 Spring 的便利性。 Spring使用其DispatcherServlet以前端控制器模式实现 MVC 。 简而言之，DispatcherServlet充当主控制器，将请求路由到其预期目的地。模型只不过是我们应用程序的数据，视图由各种模板引擎中的任何一个表示。 稍后我们将在示例中查看 JSP。 3. Spring MVC 使用 Java 配置 要通过 Java 配置类启用 Spring MVC 支持，我们只需添加*@EnableWebMvc*注解： @EnableWebMvc @Configuration public class WebConfig { /// ... } 这将为 MVC 项目设置我们所需的基本支持，例如注册控制器和映射、类型转换器、验证支持、消息转换器和异常处理。 如果我们想自定义这个配置，我们需要实现WebMvcConfigurer接口： @EnableWebMvc @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(\u0026#34;/\u0026#34;).setViewName(\u0026#34;index\u0026#34;); } @Bean public ViewResolver viewResolver() { InternalResourceViewResolver bean = new InternalResourceViewResolver(); bean.setViewClass(JstlView.class); bean.setPrefix(\u0026#34;/WEB-INF/view/\u0026#34;); bean.setSuffix(\u0026#34;.jsp\u0026#34;); return bean; } } 在这个例子中，我们注册了一个ViewResolver bean，它将从*/WEB-INF/view目录返回.jsp*视图。 这里非常重要的是，我们可以注册视图控制器， 使用ViewControllerRegistry在 URL 和视图名称之间创建直接映射。这样，两者之间就不需要任何控制器了。 如果我们还想定义和扫描控制器类，我们可以在包含控制器的包中添加*@ComponentScan注释：* @EnableWebMvc @Configuration @ComponentScan(basePackages = { \u0026#34;com.baeldung.web.controller\u0026#34; }) public class WebConfig implements WebMvcConfigurer { // ... } 要引导加载此配置的应用程序，我们还需要一个初始化程序类： public class MainWebAppInitializer implements WebApplicationInitializer { @Override public void onStartup(final ServletContext sc) throws ServletException { AnnotationConfigWebApplicationContext root = new AnnotationConfigWebApplicationContext(); root.scan(\u0026#34;com.codingman\u0026#34;); sc.addListener(new ContextLoaderListener(root)); ServletRegistration.Dynamic appServlet = sc.addServlet(\u0026#34;mvc\u0026#34;, new DispatcherServlet(new GenericWebApplicationContext())); appServlet.setLoadOnStartup(1); appServlet.addMapping(\u0026#34;/\u0026#34;); } } 请注意，对于 Spring 5 之前的版本，我们必须使用WebMvcConfigurerAdapter类而不是接口。 4. Spring MVC 使用 XML 配置 除了上面的 Java 配置，我们还可以使用纯 XML 配置： \u0026lt;context:component-scan base-package=\u0026#34;com.codingman.web.controller\u0026#34; /\u0026gt; \u0026lt;mvc:annotation-driven /\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/view/\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.jsp\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name=\u0026#34;index\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 如果我们想使用纯 XML 配置，我们还需要添加一个web.xml文件来引导应用程序。有关此方法的更多详细信息，请查看我们之前的文章。 5. 控制器和视图 让我们看一个基本控制器的示例： @Controller public class SampleController { @GetMapping(\u0026#34;/sample\u0026#34;) public String showForm() { return \u0026#34;sample\u0026#34;; } } 而对应的JSP资源就是sample.jsp文件： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is the body of the sample view\u0026lt;/h1\u0026gt;\t\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 基于 JSP 的视图文件位于项目的 / WEB-INF文件夹下，因此它们只能由 Spring 基础架构访问，而不能通过直接 URL 访问。 6. 带引导的 Spring MVC Spring Boot 是对 Spring 平台的一个补充，它使得上手和创建独立的生产级应用程序变得非常容易。Boot并不是为了取代 Spring，而是为了让使用它变得更快、更容易。 6.1 Spring Boot 启动器 新框架提供了方便的启动依赖项，这些依赖项描述符可以为特定功能引入所有必要的技术。 它们的优点是我们不再需要为每个依赖项指定一个版本，而是允许启动器为我们管理依赖项。 最快的入门方法是添加spring-boot-starter-parentpom.xml： \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 这将负责依赖管理。 6.2 Spring Boot 入口点 使用Spring Boot构建的每个应用程序只需要定义主入口点。 这通常是一个带有main方法的 Java 类，用*@SpringBootApplication*注解： @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 此注解添加了以下其他注解：  @Configuration将类标记为 bean 定义的来源。 @EnableAutoConfiguration告诉框架根据类路径上的依赖项自动添加 bean。 @ComponentScan扫描与Application类或以下相同包中的其他配置和 bean 。  使用 Spring Boot，我们可以使用 Thymeleaf 或 JSP 设置前端，而无需使用第 3 节中定义的 ViewResolver。通过向我们的 pom.xml 添加spring-boot-starter-thymeleaf依赖项，Thymeleaf 被启用，并且不需要额外的配置。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_tutorial/","tags":["Spring MVC Basics"],"title":"Spring MVC 教程"},{"categories":["Spring MVC"],"contents":"1. 概述 在本文中，我们将了解Spring MVC 提供的核心org.springframework.ui.Model、org.springframework.ui.ModelMap和org.springframework.web.servlet.ModelAndView的使用。 2. Maven依赖 让我们从pom.xml文件中的spring-context依赖项开始： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 spring-context 依赖项。 对于ModelAndView，需要spring-web依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 spring-web 依赖项。 而且，如果我们使用 Thymeleaf 作为我们的视图，我们应该将此依赖项添加到 pom.xml： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf-spring5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.11.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在[这里](https://search.maven.org/search?q=a:thymeleaf-spring5 AND g:org.thymeleaf)找到最新版本的 Thymeleaf 依赖项。 3. Model 让我们从这里最基本的概念开始——Model。 简单地说，Model可以提供用于渲染视图的属性。 要为视图提供可用数据，我们只需将此数据添加到其Model对象中。此外，具有属性的地图可以与Model实例合并： @GetMapping(\u0026#34;/showViewPage\u0026#34;) public String passParametersWithModel(Model model) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;spring\u0026#34;, \u0026#34;mvc\u0026#34;); model.addAttribute(\u0026#34;message\u0026#34;, \u0026#34;Baeldung\u0026#34;); model.mergeAttributes(map); return \u0026#34;viewPage\u0026#34;; } 4. ModelMap 就像上面的Model接口一样，ModelMap也用于传递值来渲染视图。 ModelMap的优势在于它使我们能够传递值的集合并将这些值视为在Map中： @GetMapping(\u0026#34;/printViewPage\u0026#34;) public String passParametersWithModelMap(ModelMap map) { map.addAttribute(\u0026#34;welcomeMessage\u0026#34;, \u0026#34;welcome\u0026#34;); map.addAttribute(\u0026#34;message\u0026#34;, \u0026#34;Baeldung\u0026#34;); return \u0026#34;viewPage\u0026#34;; } 5. ModelAndView 将值传递给视图的最终接口是ModelAndView。 这个接口允许我们一次返回传递 Spring MVC 所需的所有信息： @GetMapping(\u0026#34;/goToViewPage\u0026#34;) public ModelAndView passParametersWithModelAndView() { ModelAndView modelAndView = new ModelAndView(\u0026#34;viewPage\u0026#34;); modelAndView.addObject(\u0026#34;message\u0026#34;, \u0026#34;Baeldung\u0026#34;); return modelAndView; } 6. View 我们放置在这些模型中的所有数据都被一个视图使用——通常是一个模板化的视图来呈现网页。 如果我们有一个 Thymeleaf 模板文件，我们的控制器方法将其作为他们的视图。可以从 thymeleaf HTML 代码中访问通过模型传递的参数： \u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div th:text=\u0026#34;${message}\u0026#34;\u0026gt;Web Application. \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 此处传递的参数通过语法*${message}*使用，称为占位符。Thymeleaf 模板引擎将用通过模型传递的同名属性的实际值替换此占位符。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_model_model_map_model_view/","tags":["Spring MVC Basics"],"title":"Spring MVC 中的 Model、ModelMap 和 ModelAndView"},{"categories":["Spring MVC"],"contents":"1. 概述 在本文中，我们将讨论 Spring 表单和与控制器的数据绑定。此外，我们将看看Spring MVC中的主要注释之一，即*@ModelAttribute*。 当然，Spring MVC 是一个复杂的主题，您需要了解很多东西才能充分发挥它的潜力，所以一定要在这里更深入地研究这个框架。 2. 模型 首先——让我们定义一个简单的实体，我们将显示并绑定到表单： public class Employee { private String name; private long id; private String contactNumber; // standard getters and setters } 这将是我们的表单支持对象。 3. View 接下来——让我们定义实际的表单，当然还有包含它的 HTML 文件。我们将使用一个创建/注册新员工的页面： \u0026lt;%@ taglib prefix=\u0026#34;form\u0026#34; uri=\u0026#34;http://www.springframework.org/tags/form\u0026#34;%\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Welcome, Enter The Employee Details\u0026lt;/h3\u0026gt; \u0026lt;form:form method=\u0026#34;POST\u0026#34; action=\u0026#34;/spring-mvc-xml/addEmployee\u0026#34; modelAttribute=\u0026#34;employee\u0026#34;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:label path=\u0026#34;name\u0026#34;\u0026gt;Name\u0026lt;/form:label\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:input path=\u0026#34;name\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:label path=\u0026#34;id\u0026#34;\u0026gt;Id\u0026lt;/form:label\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:input path=\u0026#34;id\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:label path=\u0026#34;contactNumber\u0026#34;\u0026gt; Contact Number\u0026lt;/form:label\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:input path=\u0026#34;contactNumber\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form:form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 首先——请注意，我们在 JSP 页面中包含了一个标签库——form标签库——以帮助定义我们的表单。 Next – *form:form*标签在这里扮演着重要的角色；它与常规的 HTLM 标记非常相似，但modelAttribute属性是指定支持此表单的模型对象名称的键： \u0026lt;form:form method=\u0026#34;POST\u0026#34; action=\u0026#34;/SpringMVCFormExample/addEmployee\u0026#34; modelAttribute=\u0026#34;employee\u0026#34;\u0026gt; 这将对应于稍后在控制器中的*@ModelAttribute* 。 接下来 – 每个输入字段都使用 Spring Form taglib 中的另一个有用标签 – form: prefix。这些字段中的每一个都指定了一个路径属性——这必须对应于模型属性的 getter/setter（在本例中为 Employee 类）。加载页面时，输入字段由 Spring 填充，它调用绑定到输入字段的每个字段的 getter。提交表单时，会调用 setter 将表单的值保存到对象中。 最后——当表单提交时，控制器中的 POST 处理程序被调用，表单自动绑定到我们传入的员工参数。 4. Controller 现在，让我们看看将处理后端的Controller： @Controller public class EmployeeController { @RequestMapping(value = \u0026#34;/employee\u0026#34;, method = RequestMethod.GET) public ModelAndView showForm() { return new ModelAndView(\u0026#34;employeeHome\u0026#34;, \u0026#34;employee\u0026#34;, new Employee()); } @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit(@Valid @ModelAttribute(\u0026#34;employee\u0026#34;)Employee employee, BindingResult result, ModelMap model) { if (result.hasErrors()) { return \u0026#34;error\u0026#34;; } model.addAttribute(\u0026#34;name\u0026#34;, employee.getName()); model.addAttribute(\u0026#34;contactNumber\u0026#34;, employee.getContactNumber()); model.addAttribute(\u0026#34;id\u0026#34;, employee.getId()); return \u0026#34;employeeView\u0026#34;; } } 控制器定义了两个简单的操作——GET 用于在表单中显示数据，POST 用于创建操作，通过表单的提交。 还要注意，如果没有将名为“employee”的对象添加到模型中，当我们尝试访问 JSP 时，Spring 会报错，因为 JSP 将被设置为将表单绑定到“employee”模型属性： java.lang.IllegalStateException: Neither BindingResult nor plain target object for bean name \u0026#39;employee\u0026#39; available as request attribute at o.s.w.s.s.BindStatus.\u0026lt;init\u0026gt;(BindStatus.java:141) 要访问我们的表单支持对象，我们需要通过*@ModelAttribute*注释注入它。 方法参数上的一个\u0026lt;em\u0026gt;@ModelAttribute \u0026lt;/em\u0026gt;表示将从模型中检索该参数。如果模型中不存在，则参数将首先实例化，然后添加到模型中。 5. 处理绑定错误 默认情况下，Spring MVC 在请求绑定过程中发生错误时会抛出异常。这通常不是我们想要的，相反，我们应该将这些错误呈现给用户。我们将通过向控制器方法添加一个作为参数来使用BindingResult ： public String submit( @Valid @ModelAttribute(\u0026#34;employee\u0026#34;) Employee employee, BindingResult result, ModelMap model) BindingResult参数需要放置在我们的表单支持对象之后——这是方法参数的顺序很重要的罕见情况之一。否则，我们将遇到以下异常： java.lang.IllegalStateException: Errors/BindingResult argument declared without preceding model attribute. Check your handler method signature! 现在——不再抛出异常；相反，错误将在传递给submit方法的BindingResult上注册。此时，我们可以通过多种方式处理这些错误——例如，可以取消操作： @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit(@Valid @ModelAttribute(\u0026#34;employee\u0026#34;)Employee employee, BindingResult result, ModelMap model) { if (result.hasErrors()) { return \u0026#34;error\u0026#34;; } //Do Something  return \u0026#34;employeeView\u0026#34;; } 请注意，如果结果包含错误，我们如何将另一个视图返回给用户，以便正确显示这些错误。让我们看一下那个视图*——error.jsp*： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Please enter the correct details\u0026lt;/h3\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026#34;employee\u0026#34;\u0026gt;Retry\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 6. 显示员工 最后，除了创建一个新员工之外，我们还可以简单地显示一个——这是它的快速查看代码： \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;Submitted Employee Information\u0026lt;/h2\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Name :\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${name}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;ID :\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${id}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Contact Number :\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${contactNumber}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; JSP 页面只是使用 EL 表达式来显示模型中 Employee 对象的属性值。 7. 测试应用程序 可以部署简单的应用程序（例如在 Tomcat 服务器中）并在本地访问： http://localhost:8080/spring-mvc-xml/employee 这是包含主表单的视图——在提交操作之前： Spring MVC 表单示例——提交 提交后显示数据： Spring MVC 表单示例 – 查看 就是这样——一个使用 Spring MVC 的简单表单的工作示例，带有验证。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_form_tutorial/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring MVC 中的表单入门"},{"categories":["Spring MVC"],"contents":"1. 概述 在本教程中，我们将探索org.springframework.web.bind.annotation包中的 Spring Web 注释。 2. @RequestMapping 简单地说，@RequestMapping 标记了*@Controller*类内部的请求处理方法；可以使用以下方式进行配置：  路径或其别名、名称和*值：*方法映射到哪个 URL *方法：*兼容的 HTTP 方法 *params：*根据 HTTP 参数的存在、不存在或值过滤请求 *标头：*根据 HTTP 标头的存在、不存在或值过滤请求 *消费：*该方法可以在 HTTP 请求正文中消费哪些媒体类型 *产生：*该方法可以在 HTTP 响应正文中产生哪些媒体类型  这是一个简单的示例： @Controller class VehicleController { @RequestMapping(value = \u0026#34;/vehicles/home\u0026#34;, method = RequestMethod.GET) String home() { return \u0026#34;home\u0026#34;; } } 如果我们在类级别应用此注解，我们可以为@Controller类中的所有处理程序方法提供默认设置。唯一的例外是Spring不会用方法级别设置覆盖但附加两个路径部分的 URL。 例如，下面的配置和上面的效果是一样的： @Controller @RequestMapping(value = \u0026#34;/vehicles\u0026#34;, method = RequestMethod.GET) class VehicleController { @RequestMapping(\u0026#34;/home\u0026#34;) String home() { return \u0026#34;home\u0026#34;; } } 此外，@GetMapping、@PostMapping、@PutMapping、 @DeleteMapping和*@PatchMapping是@RequestMapping*的不同变体， HTTP 方法已分别设置为 GET、POST、PUT、DELETE 和 PATCH。 这些从 Spring 4.3 版本开始可用。 3. @RequestBody 让我们继续看@RequestBody——它将HTTP 请求的主体映射到一个对象： @PostMapping(\u0026#34;/save\u0026#34;) void saveVehicle(@RequestBody Vehicle vehicle) { // ... } 反序列化是自动的，取决于请求的内容类型。 4. @PathVariable 接下来，让我们谈谈*@PathVariable*。 此注释指示方法参数绑定到 URI 模板变量。我们可以使用*@RequestMapping注释指定 URI 模板，并使用@PathVariable*将方法参数绑定到模板部分之一。 我们可以使用名称或其别名、Value参数来实现这一点： @RequestMapping(\u0026#34;/{id}\u0026#34;) Vehicle getVehicle(@PathVariable(\u0026#34;id\u0026#34;) long id) { // ... } 如果模板中部分的名称与方法参数的名称匹配，我们不必在注解中指定： @RequestMapping(\u0026#34;/{id}\u0026#34;) Vehicle getVehicle(@PathVariable long id) { // ... } 此外，我们可以通过将required的参数设置为false来将路径变量标记为可选： @RequestMapping(\u0026#34;/{id}\u0026#34;) Vehicle getVehicle(@PathVariable(required = false) long id) { // ... } 5. @RequestParam 我们使用*@RequestParam*来访问 HTTP 请求参数： @RequestMapping Vehicle getVehicleByParam(@RequestParam(\u0026#34;id\u0026#34;) long id) { // ... } 它具有与*@PathVariable*注释相同的配置选项。 除了这些设置之外，当 Spring 在请求中发现没有值或空值时，我们可以使用*@RequestParam指定注入值。为此，我们必须设置defaultValue*参数。 提供默认值隐式地将required设置为false： @RequestMapping(\u0026#34;/buy\u0026#34;) Car buyCar(@RequestParam(defaultValue = \u0026#34;5\u0026#34;) int seatCount) { // ... } 除了参数，我们还可以访问其他 HTTP 请求部分：cookies 和 headers。我们可以分别使用注解*@CookieValue和@RequestHeader*来访问它们。 我们可以像@RequestParam一样配置它们。 6. 响应处理注解 在接下来的部分中，我们将看到在 Spring MVC 中操作 HTTP 响应的最常见的注解。 6.1 @ResponseBody 如果我们使用@ResponseBody标记请求处理程序方法，Spring 将方法的结果视为响应本身： @ResponseBody @RequestMapping(\u0026#34;/hello\u0026#34;) String hello() { return \u0026#34;Hello World!\u0026#34;; } 如果我们用这个注解来注解一个*@Controller*类，所有的请求处理方法都会使用它。 6.2 @ExceptionHandler 有了这个注解，我们可以声明一个自定义的错误处理方法。当请求处理程序方法抛出任何指定的异常时，Spring 调用此方法。 捕获的异常可以作为参数传递给方法： @ExceptionHandler(IllegalArgumentException.class) void onIllegalArgumentException(IllegalArgumentException exception) { // ... } 6.3 @ResponseStatus 如果我们使用此注释注释请求处理程序方法，我们可以指定**响应的所需 HTTP 状态。**我们可以使用code参数或它的别名value参数来声明状态代码。 此外，我们可以使用reason参数提供原因。 我们也可以将它与*@ExceptionHandler*一起使用： @ExceptionHandler(IllegalArgumentException.class) @ResponseStatus(HttpStatus.BAD_REQUEST) void onIllegalArgumentException(IllegalArgumentException exception) { // ... } 有关 HTTP 响应状态的更多信息，请访问本文。 7. 其他网页注解 一些注释不直接管理 HTTP 请求或响应。在接下来的部分中，我们将介绍最常见的部分。 7.1 @Controller 我们可以使用@Controller定义一个 Spring MVC 控制器。有关更多信息，请访问我们关于 Spring Bean Annotations 的文章。 7.2. @RestController @RestController结合了*@Controller和@ResponseBody*。 因此，以下声明是等价的： @Controller @ResponseBody class VehicleRestController { // ... } @RestController class VehicleRestController { // ... } 7.3 @ModelAttribute 使用这个注解，我们可以通过提供模型键来访问已经存在于MVC @Controller模型中的元素： @PostMapping(\u0026#34;/assemble\u0026#34;) void assembleVehicle(@ModelAttribute(\u0026#34;vehicle\u0026#34;) Vehicle vehicleInModel) { // ... } 与*@PathVariable和@RequestParam*一样，如果参数具有相同的名称，我们不必指定模型键： @PostMapping(\u0026#34;/assemble\u0026#34;) void assembleVehicle(@ModelAttribute Vehicle vehicle) { // ... } 此外，@ModelAttribute还有一个用途：如果我们用它来注解一个方法，Spring 会自动将该方法的返回值添加到模型中： @ModelAttribute(\u0026#34;vehicle\u0026#34;) Vehicle getVehicle() { // ... } 和以前一样，我们不必指定模型键，Spring 默认使用方法的名称： @ModelAttribute Vehicle vehicle() { // ... } 在 Spring 调用请求处理程序方法之前，它会调用类中所有*@ModelAttribute*注释的方法。 有关*@ModelAttribute*的更多信息，请参阅本文。 7.4 @CrossOrigin @CrossOrigin 为带注释的请求处理程序方法启用跨域通信： @CrossOrigin @RequestMapping(\u0026#34;/hello\u0026#34;) String hello() { return \u0026#34;Hello World!\u0026#34;; } 如果我们用它标记一个类，它适用于其中的所有请求处理程序方法。 我们可以使用此注释的参数微调 CORS 行为。 有关更多详细信息，请访问本文。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_annotations/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring Web 注释"},{"categories":["Maven","Spring"],"contents":"1. 概述 最重要的Spring MVC注释之一是@ModelAttribute注释。 @ModelAttribute是一个注解，它将方法参数或方法返回值绑定到命名模型属性，然后将其公开给 Web 视图。 在本教程中，我们将通过一个通用概念（公司员工提交的表单）来演示此注释的可用性和功能。 2. 深入了解@ModelAttribute 正如介绍性段落所揭示的，我们可以将*@ModelAttribute*用作方法参数或在方法级别使用。 2.1 在方法级别 当我们在方法级别使用注解时，它表明方法的目的是添加一个或多个模型属性。此类方法支持与@RequestMapping方法相同的参数类型，但它们不能直接映射到请求。 让我们看一个简单的例子来了解它是如何工作的： @ModelAttribute public void addAttributes(Model model) { model.addAttribute(\u0026#34;msg\u0026#34;, \u0026#34;Welcome to the Netherlands!\u0026#34;); } 在上面的例子中，我们看到了一个方法，它为控制器类中定义的所有Model添加了一个名为msg的属性。 当然，我们将在本文后面看到这一点。 一般来说，Spring MVC 在调用任何请求处理程序方法之前总是会先调用该方法。基本上，**@ModelAttribute方法在调用带有@RequestMapping注释的控制器方法之前被调用。**这是因为必须在控制器方法内部开始任何处理之前创建模型对象。 将相应的类注释为@ControllerAdvice也很重要。因此，我们可以在Model中添加将被标识为全局的值。这实际上意味着对于每个请求，响应中的每个方法都存在一个默认值。 2.2 作为方法论据 当我们使用注解作为方法参数时，它表示从模型中检索参数。当注释不存在时，它应该首先被实例化，然后添加到模型中。一旦出现在模型中，参数字段应该从具有匹配名称的所有请求参数中填充。 在以下代码片段中，我们将使用提交到addEmployee端点的表单中的数据填充员工模型属性。Spring MVC 在调用提交方法之前在后台执行此操作： @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit(@ModelAttribute(\u0026#34;employee\u0026#34;) Employee employee) { // Code that uses the employee object  return \u0026#34;employeeView\u0026#34;; } 在本文后面，我们将看到一个完整的示例，说明如何使用Employee对象来填充employeeView模板。 它将表单数据与 bean 绑定。使用@RequestMapping注释的控制器可以具有使用*@ModelAttribute*注释的自定义类参数。 在 Spring MVC 中，我们将其称为数据绑定，这是一种通用机制，可以让我们不必单独解析每个表单字段。 3. 表格示例 在本节中，我们将查看概述部分中概述的示例，这是一个非常基本的表单，提示用户（特别是公司员工）输入一些个人信息（特别是name和ID）。*在提交完成并且没有任何错误之后，用户希望看到之前提交的数据显示在另一个屏幕上。 3.1 View 让我们首先创建一个带有 id 和 name 字段的简单表单： \u0026lt;form:form method=\u0026#34;POST\u0026#34; action=\u0026#34;/spring-mvc-basics/addEmployee\u0026#34; modelAttribute=\u0026#34;employee\u0026#34;\u0026gt; \u0026lt;form:label path=\u0026#34;name\u0026#34;\u0026gt;Name\u0026lt;/form:label\u0026gt; \u0026lt;form:input path=\u0026#34;name\u0026#34; /\u0026gt; \u0026lt;form:label path=\u0026#34;id\u0026#34;\u0026gt;Id\u0026lt;/form:label\u0026gt; \u0026lt;form:input path=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34; /\u0026gt; \u0026lt;/form:form\u0026gt; 3.2 控制器 这是控制器类，我们将在其中实现上述视图的逻辑： @Controller @ControllerAdvice public class EmployeeController { private Map\u0026lt;Long, Employee\u0026gt; employeeMap = new HashMap\u0026lt;\u0026gt;(); @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit( @ModelAttribute(\u0026#34;employee\u0026#34;) Employee employee, BindingResult result, ModelMap model) { if (result.hasErrors()) { return \u0026#34;error\u0026#34;; } model.addAttribute(\u0026#34;name\u0026#34;, employee.getName()); model.addAttribute(\u0026#34;id\u0026#34;, employee.getId()); employeeMap.put(employee.getId(), employee); return \u0026#34;employeeView\u0026#34;; } @ModelAttribute public void addAttributes(Model model) { model.addAttribute(\u0026#34;msg\u0026#34;, \u0026#34;Welcome to the Netherlands!\u0026#34;); } } 在submit()方法中，我们有一个绑定到View的Employee对象。我们可以像这样简单地将表单字段映射到对象模型。在该方法中，我们从表单中获取值并将它们设置为ModelMap。 最后，我们返回employeeView，这意味着我们将各自的 JSP 文件称为View代表。 此外，还有一个addAttributes()方法。其目的是在模型中添加将被全局识别的值。也就是说，对每个控制器方法的每个请求都将返回一个默认值作为响应。我们还必须将特定类注释为*@ControllerAdvice。* 3.3 模型 如前所述，模型对象非常简单，包含“前端”属性所需的所有内容。现在让我们看一个例子： @XmlRootElement public class Employee { private long id; private String name; public Employee(long id, String name) { this.id = id; this.name = name; } // standard getters and setters removed } 3.4 ControllerAdvice @ControllerAdvice协助控制器，特别是适用于所有*@RequestMapping方法的@ModelAttribute方法。当然，我们的addAttributes()方法将是第一个运行的，在其余的@RequestMapping*方法之前。 记住这一点，在submit()和addAttributes()都运行之后，我们可以在从Controller类返回的View中引用它们，方法是在美元化的花括号中提及它们的给定名称，例如*${name}*。 3.5 结果视图 现在让我们打印我们从表单中收到的内容： \u0026lt;h3\u0026gt;${msg}\u0026lt;/h3\u0026gt; Name : ${name} ID : ${id} \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_and_the_modelattribute_annotation/","tags":[],"title":"Spring MVC 和 @ModelAttribute 注解"},{"categories":["Spring Persistence"],"contents":"1. 概述 本文将展示在项目中使用 Spring 工件时要使用的 Maven 存储库 - 请参阅Spring wiki上存储库的完整列表。以前的 SpringSource 工件管理基础设施是maven.springframework.org - 现在已被弃用，取而代之的是更强大的repo.spring.io。 2. Maven 发布 所有 GA/Release 工件都发布到 Maven Central，因此如果只需要发布，则无需在pom中添加任何新的 repo 。但是，如果由于某种原因 Central 不可用，也有一个可用于 Spring 版本的自定义、可浏览的 Maven 存储库： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.spring.release\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring GA Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/release\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; Spring 工件版本控制规则在项目 wiki 上进行了说明。 里程碑和快照不会直接发布到 Maven Central，因此它们有自己特定的存储库。 3. Maven 里程碑和候选版本 对于里程碑和 RC，需要将以下 repo 添加到pom中： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.spring.milestone\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Milestone Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/milestone\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 已经定义了一个这个存储库，项目可以开始使用 Spring里程碑依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.0.RC3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. Maven 快照 与里程碑类似，Spring 快照托管在自定义存储库中： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.spring.snapshot\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Snapshot Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/snapshot\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 在 pom 中启用存储库后，项目可以开始使用 Spring 快照： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.5.BUILD-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 乃至： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.0.BUILD-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在还可以浏览快照存储库。 5. Spring OSGI 的 Maven 存储库 OSGI 兼容的 Spring 工件在 SpringSource Enterprise Bundle Repository中维护- 简而言之，EBR。这些存储库包含整个 Spring Framework 的有效 OSGI 包和库，以及这些库的完整依赖项集。对于捆绑： \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.bundles.release\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - SpringSource Bundle Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/bundles/release\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.bundles.external\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - External Bundle Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/bundles/external\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; 对于 OSGI 兼容库： \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.libraries.release\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - SpringSource Library Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/libraries/release\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.libraries.external\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - External Library Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/libraries/external\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; 注意：SpringSource EBR 现在是只读的，不再发布 Spring Framework 3.2.x 版本。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_maven_repository/","tags":["JDBC","SQL"],"title":"Spring Maven 存储库"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将介绍 Spring JDBC 模块的实际用例。 Spring JDBC 中的所有类都分为四个独立的包：  core — JDBC 的核心功能。该包下的一些重要类包括JdbcTemplate、 SimpleJdbcInsert、 SimpleJdbcCall和NamedParameterJdbcTemplate。 datasource — 用于访问数据源的实用程序类。它还具有用于在 Jakarta EE 容器之外测试 JDBC 代码的各种数据源实现。 object — 以面向对象的方式访问数据库。它允许运行查询并将结果作为业务对象返回。它还映射业务对象的列和属性之间的查询结果。 support — 支持核心和对象包下的类，例如，提供SQLException转换功能  2. 配置 让我们从数据源的一些简单配置开始。 我们将使用 MySQL 数据库： @Configuration @ComponentScan(\u0026#34;com.codingman.jdbc\u0026#34;) public class SpringJdbcConfig { @Bean public DataSource mysqlDataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:mysql://localhost:3306/springjdbc\u0026#34;); dataSource.setUsername(\u0026#34;user\u0026#34;); dataSource.setPassword(\u0026#34;password\u0026#34;); return dataSource; } } 或者，我们也可以充分利用嵌入式数据库进行开发或测试。 这是一个创建 H2 嵌入式数据库实例并使用简单 SQL 脚本预填充它的快速配置： @Bean public DataSource dataSource() { return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.H2) .addScript(\u0026#34;classpath:jdbc/schema.sql\u0026#34;) .addScript(\u0026#34;classpath:jdbc/test-data.sql\u0026#34;).build(); } 最后，同样可以使用 XML 配置数据源来完成： \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.apache.commons.dbcp.BasicDataSource\u0026#34; destroy-method=\u0026#34;close\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;com.mysql.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/springjdbc\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;user\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;password\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 3. JdbcTemplate和运行查询 3.1 基本查询 JDBC 模板是主要的 API，我们将通过它访问我们感兴趣的大部分功能：  创建和关闭连接 运行语句和存储过程调用 遍历ResultSet并返回结果  首先，我们从一个简单的例子开始，看看JdbcTemplate能做什么： int result = jdbcTemplate.queryForObject( \u0026#34;SELECT COUNT(*) FROM EMPLOYEE\u0026#34;, Integer.class); 这是一个简单的插入： public int addEmplyee(int id) { return jdbcTemplate.update( \u0026#34;INSERT INTO EMPLOYEE VALUES (?, ?, ?, ?)\u0026#34;, id, \u0026#34;Ann\u0026#34;, \u0026#34;Green\u0026#34;, \u0026#34;USA\u0026#34;); } *注意使用?*提供参数的标准语法 特点。 接下来，让我们看一下这种语法的替代方法。 3.2 带有命名参数的查询 为了获得对命名参数的支持，我们将使用框架提供的另一个 JDBC 模板 — NamedParameterJdbcTemplate。 此外，它包装了JbdcTemplate并使用 ? 提供了传统语法的替代方案。指定参数。 在幕后，它将命名参数替换为 JDBC ? 占位符并委托给包装的JDCTemplate以运行查询： SqlParameterSource namedParameters = new MapSqlParameterSource().addValue(\u0026#34;id\u0026#34;, 1); return namedParameterJdbcTemplate.queryForObject( \u0026#34;SELECT FIRST_NAME FROM EMPLOYEE WHERE ID = :id\u0026#34;, namedParameters, String.class); 请注意我们如何使用MapSqlParameterSource为命名参数提供值。 让我们看看使用 bean 的属性来确定命名参数： Employee employee = new Employee(); employee.setFirstName(\u0026#34;James\u0026#34;); String SELECT_BY_ID = \u0026#34;SELECT COUNT(*) FROM EMPLOYEE WHERE FIRST_NAME = :firstName\u0026#34;; SqlParameterSource namedParameters = new BeanPropertySqlParameterSource(employee); return namedParameterJdbcTemplate.queryForObject( SELECT_BY_ID, namedParameters, Integer.class); 请注意我们现在如何使用BeanPropertySqlParameterSource实现，而不是像以前那样手动指定命名参数。 3.3 将查询结果映射到 Java 对象 另一个非常有用的特性是能够通过实现RowMapper接口将查询结果映射到 Java 对象。 例如，对于查询返回的每一行，Spring 使用行映射器来填充 java bean： public class EmployeeRowMapper implements RowMapper\u0026lt;Employee\u0026gt; { @Override public Employee mapRow(ResultSet rs, int rowNum) throws SQLException { Employee employee = new Employee(); employee.setId(rs.getInt(\u0026#34;ID\u0026#34;)); employee.setFirstName(rs.getString(\u0026#34;FIRST_NAME\u0026#34;)); employee.setLastName(rs.getString(\u0026#34;LAST_NAME\u0026#34;)); employee.setAddress(rs.getString(\u0026#34;ADDRESS\u0026#34;)); return employee; } } 随后，我们现在可以将行映射器传递给查询 API 并获得完全填充的 Java 对象： String query = \u0026#34;SELECT * FROM EMPLOYEE WHERE ID = ?\u0026#34;; Employee employee = jdbcTemplate.queryForObject( query, new Object[] { id }, new EmployeeRowMapper()); 4. 异常翻译 Spring 自带开箱即用的数据异常层次结构——以DataAccessException作为根异常——并将所有底层原始异常转换为它。 因此，我们通过不处理低级持久性异常来保持理智。我们还受益于 Spring 将低级异常包装在DataAccessException或其子类之一中。 这也使异常处理机制独立于我们正在使用的底层数据库。 除了默认的SQLErrorCodeSQLExceptionTranslator之外，我们还可以提供自己的SQLExceptionTranslator实现。 下面是一个自定义实现的快速示例——在存在重复键违规时自定义错误消息，这在使用 H2 时会导致错误代码 23505 ： public class CustomSQLErrorCodeTranslator extends SQLErrorCodeSQLExceptionTranslator { @Override protected DataAccessException customTranslate(String task, String sql, SQLException sqlException) { if (sqlException.getErrorCode() == 23505) { return new DuplicateKeyException( \u0026#34;Custom Exception translator - Integrity constraint violation.\u0026#34;, sqlException); } return null; } } 要使用这个自定义异常转换器，我们需要通过调用setExceptionTranslator()方法将其传递给JdbcTemplate ： CustomSQLErrorCodeTranslator customSQLErrorCodeTranslator = new CustomSQLErrorCodeTranslator(); jdbcTemplate.setExceptionTranslator(customSQLErrorCodeTranslator); 5. 使用 SimpleJdbc 类的 JDBC 操作 SimpleJdbc类提供了一种简单的方法来配置和运行 SQL 语句。这些类使用数据库元数据来构建基本查询。因此，SimpleJdbcInsert和SimpleJdbcCall类提供了一种更简单的方法来运行插入和存储过程调用。 5.1 SimpleJdbcInsert 让我们看一下以最少的配置运行简单的插入语句。 INSERT 语句是根据SimpleJdbcInsert的配置生成的。我们只需要提供表名、列名和值。 首先，让我们创建一个 SimpleJdbcInsert： SimpleJdbcInsert simpleJdbcInsert = new SimpleJdbcInsert(dataSource).withTableName(\u0026#34;EMPLOYEE\u0026#34;); 接下来，让我们提供列名称和值，然后运行操作： public int addEmplyee(Employee emp) { Map\u0026lt;String, Object\u0026gt; parameters = new HashMap\u0026lt;String, Object\u0026gt;(); parameters.put(\u0026#34;ID\u0026#34;, emp.getId()); parameters.put(\u0026#34;FIRST_NAME\u0026#34;, emp.getFirstName()); parameters.put(\u0026#34;LAST_NAME\u0026#34;, emp.getLastName()); parameters.put(\u0026#34;ADDRESS\u0026#34;, emp.getAddress()); return simpleJdbcInsert.execute(parameters); } 此外，我们可以使用executeAndReturnKey() API 来允许数据库生成主键。我们还需要配置实际的自动生成列： SimpleJdbcInsert simpleJdbcInsert = new SimpleJdbcInsert(dataSource) .withTableName(\u0026#34;EMPLOYEE\u0026#34;) .usingGeneratedKeyColumns(\u0026#34;ID\u0026#34;); Number id = simpleJdbcInsert.executeAndReturnKey(parameters); System.out.println(\u0026#34;Generated id - \u0026#34; + id.longValue()); 最后，我们还可以使用BeanPropertySqlParameterSource和MapSqlParameterSource传入这些数据。 5.2 使用SimpleJdbcCall 的存储过程 让我们也看看正在运行的存储过程。 我们将使用SimpleJdbcCall抽象： SimpleJdbcCall simpleJdbcCall = new SimpleJdbcCall(dataSource) .withProcedureName(\u0026#34;READ_EMPLOYEE\u0026#34;); public Employee getEmployeeUsingSimpleJdbcCall(int id) { SqlParameterSource in = new MapSqlParameterSource().addValue(\u0026#34;in_id\u0026#34;, id); Map\u0026lt;String, Object\u0026gt; out = simpleJdbcCall.execute(in); Employee emp = new Employee(); emp.setFirstName((String) out.get(\u0026#34;FIRST_NAME\u0026#34;)); emp.setLastName((String) out.get(\u0026#34;LAST_NAME\u0026#34;)); return emp; } 6. 批量操作 另一个简单的用例是将多个操作批处理在一起。 6.1 使用JdbcTemplate 的基本批处理操作 使用JdbcTemplate，可以通过batchUpdate() API运行批处理操作。 这里有趣的部分是简洁但非常有用的BatchPreparedStatementSetter实现： public int[] batchUpdateUsingJdbcTemplate(List\u0026lt;Employee\u0026gt; employees) { return jdbcTemplate.batchUpdate(\u0026#34;INSERT INTO EMPLOYEE VALUES (?, ?, ?, ?)\u0026#34;, new BatchPreparedStatementSetter() { @Override public void setValues(PreparedStatement ps, int i) throws SQLException { ps.setInt(1, employees.get(i).getId()); ps.setString(2, employees.get(i).getFirstName()); ps.setString(3, employees.get(i).getLastName()); ps.setString(4, employees.get(i).getAddress(); } @Override public int getBatchSize() { return 50; } }); } 6.2 使用NamedParameterJdbcTemplate 进行批量操作 我们还可以选择使用NamedParameterJdbcTemplate – batchUpdate() API 进行批处理操作。 此 API 比上一个 API 更简单。因此，不需要实现任何额外的接口来设置参数，因为它有一个内部准备好的语句设置器来设置参数值。 相反，参数值可以作为SqlParameterSource数组传递给*batchUpdate()*方法。 SqlParameterSource[] batch = SqlParameterSourceUtils.createBatch(employees.toArray()); int[] updateCounts = namedParameterJdbcTemplate.batchUpdate( \u0026#34;INSERT INTO EMPLOYEE VALUES (:id, :firstName, :lastName, :address)\u0026#34;, batch); return updateCounts; 7. Spring JDBC 与 Spring Boot Spring Boot 提供了一个启动器spring-boot-starter-jdbc用于将 JDBC 与关系数据库一起使用。 与每个 Spring Boot 启动器一样，这个启动器可以帮助我们快速启动和运行我们的应用程序。 7.1 Maven 依赖 我们需要 spring-boot-starter-jdbc依赖项作为主要依赖项。我们还需要我们将使用的数据库的依赖项。在我们的例子中，这是MySQL： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 7.2 配置 Spring Boot 会自动为我们配置数据源。我们只需要在properties文件中提供属性： spring.datasource.url=jdbc:mysql://localhost:3306/springjdbc spring.datasource.username=user spring.datasource.password=password 就是这样。只需执行这些配置，我们的应用程序就可以启动并运行。我们现在可以将它用于其他数据库操作。 我们在上一节中看到的标准 Spring 应用程序的显式配置现在包含在 Spring Boot 自动配置中。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_jdbc_jdbctemplate/","tags":["Spring Core Basics","Spring DI"],"title":"Spring JDBC"},{"categories":["Spring Data"],"contents":"1. 简介 在本教程中，我们将介绍*BeanFactory.getBean()*方法的不同变体。 简单地说，正如该方法的名称所暗示的，它负责从 Spring 容器中检索一个 bean 实例。 2. Spring Beans 设置 首先，让我们定义一些用于测试的 Spring bean。我们可以通过多种方式为 Spring 容器提供 bean 定义，但在我们的示例中，我们将使用基于注解的 Java 配置： @Configuration class AnnotationConfig { @Bean(name = {\u0026#34;tiger\u0026#34;, \u0026#34;kitty\u0026#34;}) @Scope(value = \u0026#34;prototype\u0026#34;) Tiger getTiger(String name) { return new Tiger(name); } @Bean(name = \u0026#34;lion\u0026#34;) Lion getLion() { return new Lion(\u0026#34;demo lion name\u0026#34;); } interface Animal {} } 我们已经创建了两个 bean。Lion具有默认的单例范围。Tiger被明确设置为原型范围。此外，请注意，我们为每个 bean 定义了名称，我们将在进一步的请求中使用这些名称。 3. getBean() API BeanFactory提供了五种不同的*getBean()*方法签名，我们将在下面的小节中进行研究。 3.1 按名称检索 Bean 让我们看看如何使用名称检索Lion bean 实例： Object lion = context.getBean(\u0026#34;lion\u0026#34;); assertEquals(Lion.class, lion.getClass()); 在这个变体中，我们提供了一个名称，作为回报，如果具有给定名称的 bean 存在于应用程序上下文中，我们将获得一个*Object 类的实例。*否则，如果 bean 查找失败，此实现和所有其他实现都会抛出NoSuchBeanDefinitionException 。 主要缺点是在检索 bean 后，我们必须将其转换为所需的类型。如果返回的 bean 的类型与我们预期的不同，这可能会产生另一个异常。 假设我们尝试使用名称lion来获得Tiger。 当我们将结果转换为Tiger时，它会抛出ClassCastException： assertThrows(ClassCastException.class, () -\u0026gt; { Tiger tiger = (Tiger) context.getBean(\u0026#34;lion\u0026#34;); }); 3.2 按名称和类型检索 Bean 在这里，我们需要指定请求的 bean 的名称和类型： Lion lion = context.getBean(\u0026#34;lion\u0026#34;, Lion.class); 与前一种方法相比，这种方法更安全，因为我们可以立即获得有关类型不匹配的信息： assertThrows(BeanNotOfRequiredTypeException.class, () -\u0026gt; context.getBean(\u0026#34;lion\u0026#34;, Tiger.class)); } 3.3. 按类型检索 Bean 使用*getBean()*的第三个变体， 只指定 bean 类型就足够了： Lion lion = context.getBean(Lion.class); 在这种情况下，我们需要特别注意潜在的模棱两可的结果： assertThrows(NoUniqueBeanDefinitionException.class, () -\u0026gt; context.getBean(Animal.class)); } 在上面的示例中，由于Lion和Tiger都实现了Animal接口，因此仅指定类型不足以明确确定结果。因此，我们得到一个NoUniqueBeanDefinitionException。 3.4 使用构造函数参数按名称检索 Bean 除了bean名称，我们还可以传递构造函数参数： Tiger tiger = (Tiger) context.getBean(\u0026#34;tiger\u0026#34;, \u0026#34;Siberian\u0026#34;); 这个方法有点不同，因为它只适用于具有原型作用域的 bean。 在单例的情况下，我们将得到一个*BeanDefinitionStoreException。* 因为原型 bean 每次从应用程序容器请求时都会返回一个新创建的实例，所以我们可以在调用 getBean()时即时提供构造函数参数： Tiger tiger = (Tiger) context.getBean(\u0026#34;tiger\u0026#34;, \u0026#34;aaa\u0026#34;); Tiger secondTiger = (Tiger) context.getBean(\u0026#34;tiger\u0026#34;, \u0026#34;bbb\u0026#34;); assertEquals(\u0026#34;aaa\u0026#34;, tiger.getName()); assertEquals(\u0026#34;bbb\u0026#34;, secondTiger.getName()); 正如我们所见，根据我们在请求 bean 时指定的第二个参数，每个Tiger都会获得不同的名称。 3.5 使用构造函数参数按类型检索 Bean 这个方法类似于最后一个，但我们需要传递类型而不是名称作为第一个参数： Tiger tiger = context.getBean(Tiger.class, \u0026#34;ccc\u0026#34;); assertEquals(\u0026#34;ccc\u0026#34;, tiger.getName()); 与使用构造函数参数按名称检索 bean 类似，此方法仅适用于具有原型作用域的 bean。 4. 使用注意事项 尽管在BeanFactory接口中定义，getBean()方法最常通过ApplicationContext 访问。通常，*我们不想在程序中直接使用*getBean()方法。 bean 应该由容器管理。如果我们想使用其中之一，我们应该依赖依赖注入而不是直接调用ApplicationContext.getBean()。这样，我们就可以避免将应用程序逻辑与框架相关的细节混在一起。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_getbean/","tags":["JPA"],"title":"了解 Spring 中的 getBean()"},{"categories":["NoSQL","Spring Data"],"contents":"1. 概述 在本教程中，我们将为具有多个数据库的 Spring Data JPA 系统实现一个简单的 Spring 配置。 2. 实体 首先，让我们创建两个简单的实体，每个实体都存在于一个单独的数据库中。 这是第一个用户 实体： package com.codingman.multipledb.model.user; @Entity @Table(schema = \u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue(strategy = GenerationType.AUTO) private int id; private String name; @Column(unique = true, nullable = false) private String email; private int age; } 这是第二个实体Product： package com.codingman.multipledb.model.product; @Entity @Table(schema = \u0026#34;products\u0026#34;) public class Product { @Id private int id; private String name; private double price; } 我们可以看到这**两个实体也被放置在独立的包中。**当我们进入配置时，这将很重要。 3. JPA 存储库 接下来，让我们看一下我们的两个 JPA 存储库UserRepository： package com.codingman.multipledb.dao.user; public interface UserRepository extends JpaRepository\u0026lt;User, Integer\u0026gt; { } 和ProductRepository： package com.codingman.multipledb.dao.product; public interface ProductRepository extends JpaRepository\u0026lt;Product, Integer\u0026gt; { } 再次注意我们如何在不同的包中创建这两个存储库。 4. 用Java配置JPA 现在我们将了解实际的 Spring 配置。我们将首先设置两个配置类——一个用于User，另一个用于Product。 在每个配置类中，我们需要为User定义以下接口：  数据源 实体管理器工厂（用户实体管理器） 事务管理器（用户事务管理器）  让我们从查看用户配置开始： @Configuration @PropertySource({ \u0026#34;classpath:persistence-multiple-db.properties\u0026#34; }) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.user\u0026#34;, entityManagerFactoryRef = \u0026#34;userEntityManager\u0026#34;, transactionManagerRef = \u0026#34;userTransactionManager\u0026#34; ) public class PersistenceUserConfiguration { @Autowired private Environment env; @Bean @Primary public LocalContainerEntityManagerFactoryBean userEntityManager() { LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(userDataSource()); em.setPackagesToScan( new String[] { \u0026#34;com.codingman.multipledb.model.user\u0026#34; }); HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); em.setJpaVendorAdapter(vendorAdapter); HashMap\u0026lt;String, Object\u0026gt; properties = new HashMap\u0026lt;\u0026gt;(); properties.put(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;, env.getProperty(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;)); properties.put(\u0026#34;hibernate.dialect\u0026#34;, env.getProperty(\u0026#34;hibernate.dialect\u0026#34;)); em.setJpaPropertyMap(properties); return em; } @Primary @Bean public DataSource userDataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName( env.getProperty(\u0026#34;jdbc.driverClassName\u0026#34;)); dataSource.setUrl(env.getProperty(\u0026#34;user.jdbc.url\u0026#34;)); dataSource.setUsername(env.getProperty(\u0026#34;jdbc.user\u0026#34;)); dataSource.setPassword(env.getProperty(\u0026#34;jdbc.pass\u0026#34;)); return dataSource; } @Primary @Bean public PlatformTransactionManager userTransactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory( userEntityManager().getObject()); return transactionManager; } } 请注意我们如何通过使用 @Primary 注释 bean 定义来使用userTransactionManager作为我们的Primary *TransactionManager*。每当我们要隐式或显式地注入事务管理器而不指定哪个名称时，这都会很有帮助。 接下来，让我们讨论PersistenceProductConfiguration，我们在其中定义了类似的 bean： @Configuration @PropertySource({ \u0026#34;classpath:persistence-multiple-db.properties\u0026#34; }) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.product\u0026#34;, entityManagerFactoryRef = \u0026#34;productEntityManager\u0026#34;, transactionManagerRef = \u0026#34;productTransactionManager\u0026#34; ) public class PersistenceProductConfiguration { @Autowired private Environment env; @Bean public LocalContainerEntityManagerFactoryBean productEntityManager() { LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(productDataSource()); em.setPackagesToScan( new String[] { \u0026#34;com.codingman.multipledb.model.product\u0026#34; }); HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); em.setJpaVendorAdapter(vendorAdapter); HashMap\u0026lt;String, Object\u0026gt; properties = new HashMap\u0026lt;\u0026gt;(); properties.put(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;, env.getProperty(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;)); properties.put(\u0026#34;hibernate.dialect\u0026#34;, env.getProperty(\u0026#34;hibernate.dialect\u0026#34;)); em.setJpaPropertyMap(properties); return em; } @Bean public DataSource productDataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName( env.getProperty(\u0026#34;jdbc.driverClassName\u0026#34;)); dataSource.setUrl(env.getProperty(\u0026#34;product.jdbc.url\u0026#34;)); dataSource.setUsername(env.getProperty(\u0026#34;jdbc.user\u0026#34;)); dataSource.setPassword(env.getProperty(\u0026#34;jdbc.pass\u0026#34;)); return dataSource; } @Bean public PlatformTransactionManager productTransactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory( productEntityManager().getObject()); return transactionManager; } } 5. 简单测试 最后，让我们测试一下我们的配置。 为此，我们将创建每个实体的实例并确保它已创建： @RunWith(SpringRunner.class) @SpringBootTest @EnableTransactionManagement public class JpaMultipleDBIntegrationTest { @Autowired private UserRepository userRepository; @Autowired private ProductRepository productRepository; @Test @Transactional(\u0026#34;userTransactionManager\u0026#34;) public void whenCreatingUser_thenCreated() { User user = new User(); user.setName(\u0026#34;Ann\u0026#34;); user.setEmail(\u0026#34;Ann@163.com\u0026#34;); user.setAge(205); user = userRepository.save(user); assertNotNull(userRepository.findOne(user.getId())); } @Test @Transactional(\u0026#34;userTransactionManager\u0026#34;) public void whenCreatingUsersWithSameEmail_thenRollback() { User user1 = new User(); user1.setName(\u0026#34;Ann\u0026#34;); user1.setEmail(\u0026#34;Ann@163.com\u0026#34;); user1.setAge(25); user1 = userRepository.save(user1); assertNotNull(userRepository.findOne(user1.getId())); User user2 = new User(); user2.setName(\u0026#34;Bob\u0026#34;); user2.setEmail(\u0026#34;Ann@163.com\u0026#34;); user2.setAge(28); try { user2 = userRepository.save(user2); } catch (DataIntegrityViolationException e) { } assertNull(userRepository.findOne(user2.getId())); } @Test @Transactional(\u0026#34;productTransactionManager\u0026#34;) public void whenCreatingProduct_thenCreated() { Product product = new Product(); product.setName(\u0026#34;Book\u0026#34;); product.setId(2); product.setPrice(20); product = productRepository.save(product); assertNotNull(productRepository.findOne(product.getId())); } } 6. Spring Boot 中的多个数据库 Spring Boot 可以简化上面的配置。 默认情况下，Spring Boot 将使用前缀为spring.datasource.的配置属性实例化其默认DataSource： spring.datasource.jdbcUrl = [url] spring.datasource.username = [username] spring.datasource.password = [password] 我们现在想继续使用相同的方式来配置第二个DataSource，但使用不同的属性命名空间： spring.second-datasource.jdbcUrl = [url] spring.second-datasource.username = [username] spring.second-datasource.password = [password] 因为我们希望 Spring Boot 自动配置能够获取这些不同的属性（并实例化两个不同的DataSources），所以我们将定义两个类似于前面部分的配置类： @Configuration @PropertySource({\u0026#34;classpath:persistence-multiple-db-boot.properties\u0026#34;}) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.user\u0026#34;, entityManagerFactoryRef = \u0026#34;userEntityManager\u0026#34;, transactionManagerRef = \u0026#34;userTransactionManager\u0026#34;) public class PersistenceUserAutoConfiguration { @Primary @Bean @ConfigurationProperties(prefix=\u0026#34;spring.datasource\u0026#34;) public DataSource userDataSource() { return DataSourceBuilder.create().build(); } // userEntityManager bean  // userTransactionManager bean } @Configuration @PropertySource({\u0026#34;classpath:persistence-multiple-db-boot.properties\u0026#34;}) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.product\u0026#34;, entityManagerFactoryRef = \u0026#34;productEntityManager\u0026#34;, transactionManagerRef = \u0026#34;productTransactionManager\u0026#34;) public class PersistenceProductAutoConfiguration { @Bean @ConfigurationProperties(prefix=\u0026#34;spring.second-datasource\u0026#34;) public DataSource productDataSource() { return DataSourceBuilder.create().build(); } // productEntityManager bean  // productTransactionManager bean } 现在我们已经根据 Boot 自动配置约定在persistence-multiple-db-boot.properties中定义了数据源属性。 有趣的部分是使用@ConfigurationProperties注释数据源 bean 创建方法。我们只需要指定相应的配置前缀。在这个方法中，我们使用了一个DataSourceBuilder，Spring Boot 会自动处理剩下的事情。 但是如何将配置的属性注入到DataSource配置中呢？ 在DataSourceBuilder上调用*build()方法时，它会调用其私有的bind()*方法： public T build() { Class\u0026lt;? extends DataSource\u0026gt; type = getType(); DataSource result = BeanUtils.instantiateClass(type); maybeGetDriverClassName(); bind(result); return (T) result; } 这个私有方法执行了很多自动配置魔法，将解析的配置绑定到实际的DataSource实例： private void bind(DataSource result) { ConfigurationPropertySource source = new MapConfigurationPropertySource(this.properties); ConfigurationPropertyNameAliases aliases = new ConfigurationPropertyNameAliases(); aliases.addAliases(\u0026#34;url\u0026#34;, \u0026#34;jdbc-url\u0026#34;); aliases.addAliases(\u0026#34;username\u0026#34;, \u0026#34;user\u0026#34;); Binder binder = new Binder(source.withAliases(aliases)); binder.bind(ConfigurationPropertyName.EMPTY, Bindable.ofInstance(result)); } 尽管我们自己不必接触任何这些代码，但了解 Spring Boot 自动配置背后发生的事情仍然很有用。 除此之外，事务管理器和实体管理器 bean 配置与标准 Spring 应用程序相同。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_data_jpa_multiple_databases/","tags":["Cassandra"],"title":"Spring JPA – 多个数据库"},{"categories":["Spring Persistence"],"contents":"1. 概述 本文是使用 Spring Data 使用 Cassandra 的实用介绍。 我们将从基础开始，通过配置和编码，最终构建一个完整的 Spring Data Cassandra 模块。 2. Maven依赖 让我们首先使用 Maven在pom.xml中定义依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.datastax.cassandra\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-driver-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.9\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Cassandra的配置 我们将在整个过程中使用 Java 配置风格来配置 Cassandra 集成。 3.1 主要配置（Spring） 我们将为此使用 Java 配置风格。让我们从主要的配置类开始——当然是通过类级别的*@Configuration*注解驱动的： @Configuration public class CassandraConfig extends AbstractCassandraConfiguration { @Override protected String getKeyspaceName() { return \u0026#34;testKeySpace\u0026#34;; } @Bean public CassandraClusterFactoryBean cluster() { CassandraClusterFactoryBean cluster = new CassandraClusterFactoryBean(); cluster.setContactPoints(\u0026#34;127.0.0.1\u0026#34;); cluster.setPort(9142); return cluster; } @Bean public CassandraMappingContext cassandraMapping() throws ClassNotFoundException { return new BasicCassandraMappingContext(); } } 注意带有默认实现的新 bean - *BasicCassandraMappingContext 。*这是在它们的对象和它们的持久格式之间映射持久实体所必需的。 并且由于默认实现足够强大，我们可以直接使用它。 3.2 主要配置（Spring Boot） 让我们通过application.properties进行 Cassandra 配置： spring.data.cassandra.keyspace-name=testKeySpace spring.data.cassandra.port=9142 spring.data.cassandra.contact-points=127.0.0.1 我们完成了！这就是我们在使用 Spring Boot 时所需要的。 3.3 Cassandra 连接属性 我们必须配置三个强制设置来设置 Cassandra 客户端的连接。 我们必须设置 Cassandra 服务器作为联系点运行的主机名*。端口*只是服务器中请求的侦听端口。KeyspaceName是定义节点上数据复制的命名空间，它基于 Cassandra 相关概念。 4. CassandraRepository 我们将使用CassandraRepository作为数据访问层。这遵循 Spring Data repository 抽象，该抽象专注于抽象出跨不同持久性机制实现数据访问层所需的代码。 4.1 创建CassandraRepository 让我们创建要在配置中使用的CassandraRepository： @Repository public interface BookRepository extends CassandraRepository\u0026lt;Book\u0026gt; { // } 4.2 CassandraRepository的配置 现在，我们可以扩展第 3.1 节中的配置，在 CassandraConfig 中添加*@EnableCassandraRepositories*类级别注释来标记我们在第 4.1 节中创建的 Cassandra Repository： @Configuration @EnableCassandraRepositories( basePackages = \u0026#34;com.codingman.spring.data.cassandra.repository\u0026#34;) public class CassandraConfig extends AbstractCassandraConfiguration { // } 5. 实体 让我们快速看一下实体——我们将要使用的模型类。该类被注释并定义了嵌入模式下元数据 Cassandra 数据表创建的附加参数。 使用*@Table*注解，bean 直接映射到 Cassandra 数据表。此外，每个属性都被定义为一种主键或简单列： @Table public class Book { @PrimaryKeyColumn( name = \u0026#34;isbn\u0026#34;, ordinal = 2, type = PrimaryKeyType.CLUSTERED, ordering = Ordering.DESCENDING) private UUID id; @PrimaryKeyColumn( name = \u0026#34;title\u0026#34;, ordinal = 0, type = PrimaryKeyType.PARTITIONED) private String title; @PrimaryKeyColumn( name = \u0026#34;publisher\u0026#34;, ordinal = 1, type = PrimaryKeyType.PARTITIONED) private String publisher; @Column private Set\u0026lt;String\u0026gt; tags = new HashSet\u0026lt;\u0026gt;(); // standard getters and setters } 6. 使用嵌入式服务器进行测试 6.1 Maven 依赖项 如果要在嵌入式模式下运行 Cassandra（无需手动安装单独的 Cassandra 服务器），则需要将cassandra-unit相关依赖项添加到pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.cassandraunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-unit-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.9.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.cassandraunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-unit\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.cassandraunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-unit-shaded\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.9.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hectorclient\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hector-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0-0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以使用嵌入式 Cassandra 服务器来测试此应用程序。主要优点是您不想显式安装 Cassandra。 这个嵌入式服务器也与 Spring JUnit 测试兼容。在这里，我们可以使用*@RunWith注解与嵌入式服务器一起设置SpringJUnit4ClassRunner 。*因此，无需运行外部 Cassandra 服务即可实现完整的测试套件。 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = CassandraConfig.class) public class BookRepositoryIntegrationTest { // } 6.2 启动和停止服务器 如果您正在运行外部 Cassandra 服务器，则可以忽略此部分。 我们必须为整个测试套件启动一次服务器，因此服务器启动方法用*@BeforeClass*注释标记： @BeforeClass public static void startCassandraEmbedded() { EmbeddedCassandraServerHelper.startEmbeddedCassandra(); Cluster cluster = Cluster.builder() .addContactPoints(\u0026#34;127.0.0.1\u0026#34;).withPort(9142).build(); Session session = cluster.connect(); } 接下来，我们必须确保在测试套件执行完成后服务器停止： @AfterClass public static void stopCassandraEmbedded() { EmbeddedCassandraServerHelper.cleanEmbeddedCassandra(); } 6.3 清洁数据表 最好在每次测试执行之前删除并创建数据表，以避免由于早期测试执行中的操纵数据而导致意外结果。 现在我们可以在服务器启动时创建数据表： @Before public void createTable() { adminTemplate.createTable( true, CqlIdentifier.cqlId(DATA_TABLE_NAME), Book.class, new HashMap\u0026lt;String, Object\u0026gt;()); } 并在每个测试用例执行后丢弃： @After public void dropTable() { adminTemplate.dropTable(CqlIdentifier.cqlId(DATA_TABLE_NAME)); } 7. 使用CassandraRepository 进行数据访问 我们可以直接使用上面创建的BookRepository来持久化、操作和获取 Cassandra 数据库中的数据。 7.1 保存一本新书 我们可以将一本新书保存到我们的书店： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); 然后我们可以检查数据库中插入的书的可用性： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;); assertEquals(javaBook.getId(), books.iterator().next().getId()); 7.2 更新现有书籍 Lat 从插入一本新书开始： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); 让我们按标题获取这本书： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;); 那我们改一下书名： javaBook.setTitle(\u0026#34;Demo Book 2\u0026#34;); bookRepository.save(ImmutableSet.of(javaBook)); 最后让我们检查一下数据库中的标题是否更新： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 2\u0026#34;, \u0026#34;ABC Company\u0026#34;); assertEquals( javaBook.getTitle(), updateBooks.iterator().next().getTitle()); 7.3 删除现有书籍 插入一本新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); 然后删除新输入的书： bookRepository.delete(javaBook); 现在我们可以检查删除： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;); assertNotEquals(javaBook.getId(), books.iterator().next().getId()); 这将导致从代码中抛出 NoSuchElementException 以确保该书已被删除。 7.4 查找所有书籍 先插入一本新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); Book dPatternBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 2\u0026#34;,\u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); bookRepository.save(ImmutableSet.of(dPatternBook)); 查找所有书籍： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findAll(); 然后我们可以检查数据库中可用书籍的数量： int bookCount = 0; for (Book book : books) bookCount++; assertEquals(bookCount, 2); \u0026quot; ","permalink":"http://itcodingman.github.io/spring_data_cassandra_tutorial/","tags":["JPA"],"title":"Spring Data Cassandra简介"},{"categories":["NoSQL","Spring Data"],"contents":"1. 概述 这是 Spring Data Cassandra 文章系列的第二篇。在本文中，我们将主要关注数据访问层中的CassandraTemplate和 CQL 查询。您可以在该系列的第一篇文章中阅读有关 Spring Data Cassandra 的更多信息。 Cassandra Query Language (CQL) 是 Cassandra 数据库的查询语言，CqlTemplate是 Spring Data Cassandra 中的低级数据访问模板——它方便地公开与数据操作相关的操作以执行 CQL 语句。 CassandraTemplate构建在低级CqlTemplate 之上，并提供了一种简单的方法来查询域对象并将对象映射到 Cassandra 中的持久数据结构。 让我们从配置开始，然后深入研究使用这两个模板的示例。 2. CassandraTemplate配置 CassandraTemplate在 Spring 上下文中可用，因为我们的主要 Cassandra Spring 配置正在扩展 AbstractCassandraConfiguration： @Configuration @EnableCassandraRepositories(basePackages = \u0026#34;com.codingman.spring.data.cassandra.repository\u0026#34;) public class CassandraConfig extends AbstractCassandraConfiguration { ... } 然后我们可以在模板中进行简单的连接——或者通过它的确切类型，CassandraTemplate，或者作为更通用的接口CassandraOperations： @Autowired private CassandraOperations cassandraTemplate; 3. 使用CassandraTemplate进行数据访问 让我们使用上面在数据访问层模块中定义的CassandraTemplate来处理数据持久化。 3.1 保存一本新书 我们可以将一本新书保存到我们的书店： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); 然后我们可以检查数据库中插入的书的可用性： Select select = QueryBuilder.select().from(\u0026#34;book\u0026#34;) .where(QueryBuilder.eq(\u0026#34;title\u0026#34;, \u0026#34;Spring Demo Book\u0026#34;)) .and(QueryBuilder.eq(\u0026#34;publisher\u0026#34;, \u0026#34;ABC Company\u0026#34;)); Book retrievedBook = cassandraTemplate.selectOne(select, Book.class); 我们在这里使用Select QueryBuilder，映射到 cassandraTemplate 中的selectOne ( )。我们将在 CQL 查询部分更深入地讨论QueryBuilder。 3.2 保存多本书 我们可以使用列表一次将多本书保存到我们的书店： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); Book dPatternBook = new Book( UUIDs.timeBased(), \u0026#34;Java Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); List\u0026lt;Book\u0026gt; bookList = new ArrayList\u0026lt;Book\u0026gt;(); bookList.add(javaBook); bookList.add(dPatternBook); cassandraTemplate.insert(bookList); 3.3 更新现有书籍 Lat 从插入一本新书开始： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); 我们来取书： Select select = QueryBuilder.select().from(\u0026#34;book\u0026#34;); Book retrievedBook = cassandraTemplate.selectOne(select, Book.class); 然后让我们为检索到的书添加一些额外的标签： retrievedBook.setTags(ImmutableSet.of(\u0026#34;Java\u0026#34;, \u0026#34;Programming\u0026#34;)); cassandraTemplate.update(retrievedBook); 3.4 删除插入的书 让我们插入一本新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); 然后删除这本书： cassandraTemplate.delete(javaBook); 3.5 删除所有书籍 现在让我们插入一些新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); Book dPatternBook = new Book( UUIDs.timeBased(), \u0026#34;Java Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); cassandraTemplate.insert(dPatternBook); 然后删除所有书籍： cassandraTemplate.deleteAll(Book.class); 4. 使用 CQL 查询的数据访问 始终可以使用 CQL 查询在数据访问层中进行数据操作。CQL 查询处理由CqlTemplate类执行，允许我们根据需要执行自定义查询。 但是，由于CassandraTemplate类是CqlTemplate的扩展，我们可以直接使用它来执行这些查询。 让我们看看我们可以使用 CQL 查询来操作数据的不同方法。 4.1。使用QueryBuilder QueryBuilder可用于为数据库中的数据操作构建查询。几乎所有标准操作都可以使用开箱即用的构建块构建： Insert insertQueryBuider = QueryBuilder.insertInto(\u0026#34;book\u0026#34;) .value(\u0026#34;isbn\u0026#34;, UUIDs.timeBased()) .value(\u0026#34;title\u0026#34;, \u0026#34;Spring Demo Book\u0026#34;) .value(\u0026#34;publisher\u0026#34;, \u0026#34;ABC Company\u0026#34;) .value(\u0026#34;tags\u0026#34;, ImmutableSet.of(\u0026#34;Software\u0026#34;)); cassandraTemplate.execute(insertQueryBuider); 如果您仔细查看代码片段，您可能会注意到使用了execute()方法而不是相关的操作类型（插入、删除等）。这是因为查询的类型是由QueryBuilder 的输出定义的。 4.2 使用PreparedStatements 尽管PreparedStatements可用于任何情况，但通常建议将此机制用于多个插入以进行高速摄取。 PreparedStatement只准备一次，有助于确保高性能： UUID uuid = UUIDs.timeBased(); String insertPreparedCql = \u0026#34;insert into book (isbn, title, publisher, tags) values (?, ?, ?, ?)\u0026#34;; List\u0026lt;Object\u0026gt; singleBookArgsList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;List\u0026lt;?\u0026gt;\u0026gt; bookList = new ArrayList\u0026lt;\u0026gt;(); singleBookArgsList.add(uuid); singleBookArgsList.add(\u0026#34;Spring Demo Book\u0026#34;); singleBookArgsList.add(\u0026#34;ABC Company\u0026#34;); singleBookArgsList.add(ImmutableSet.of(\u0026#34;Software\u0026#34;)); bookList.add(singleBookArgsList); cassandraTemplate.ingest(insertPreparedCql, bookList); 4.3 使用 CQL 语句 我们可以直接使用CQL语句查询数据，如下： UUID uuid = UUIDs.timeBased(); String insertCql = \u0026#34;insert into book (isbn, title, publisher, tags) values (\u0026#34; + uuid + \u0026#34;, \u0026#39;Spring Demo Book\u0026#39;, \u0026#39;ABC Company\u0026#39;, {\u0026#39;Software\u0026#39;})\u0026#34;; cassandraTemplate.execute(insertCql); \u0026quot; ","permalink":"http://itcodingman.github.io/spring_data_cassandratemplate_cqltemplate/","tags":["Cassandra"],"title":"使用 Spring Data 中的 CassandraTemplate"},{"categories":["Spring"],"contents":"1. 概述 本文将展示如何使用 Spring 和 JPA 实现 DAO。有关核心 JPA 配置，请参阅有关 JPA with Spring 的文章。 2. 不再有 Spring 模板 从 Spring 3.1 开始，已弃用JpaTemplate和相应的JpaDaoSupport 以支持使用本机 Java Persistence API。 此外，这两个类仅与 JPA 1 相关（来自JpaTemplate javadoc）：  请注意，此类没有升级到 JPA 2.0，也永远不会升级。  因此，现在最好的做法是直接使用 Java Persistence API而不是JpaTemplate。 2.1 没有模板的异常翻译 JpaTemplate的职责之一是异常转换——将低级异常转换为更高级别的通用 Spring 异常。 如果没有模板，异常翻译仍然可以为所有使用 @Repository 注释的 DAO启用并完全正常运行。Spring 使用 bean 后处理器实现这一点，该后处理器将使用容器中找到的所有PersistenceExceptionTranslator通知所有**@Repository bean 。 同样重要的是要注意异常转换机制使用代理——为了让 Spring 能够围绕 DAO 类创建代理，这些代理不能被声明为final。 3. DAO 首先，我们将为所有 DAO 实现基础层——一个使用泛型并设计为可扩展的抽象类： public abstract class AbstractJpaDAO\u0026lt;T extends Serializable\u0026gt; { private Class\u0026lt;T\u0026gt; clazz; @PersistenceContext EntityManager entityManager; public final void setClazz(Class\u0026lt;T\u0026gt; clazzToSet){ this.clazz = clazzToSet; } public T findOne( long id ){ return entityManager.find(clazz, id); } public List\u0026lt;T\u0026gt; findAll(){ return entityManager.createQuery(\u0026#34;from \u0026#34; + clazz.getName()) .getResultList(); } public void create(T entity){ entityManager.persist(entity); } public T update(T entity){ return entityManager.merge(entity); } public void delete(T entity){ entityManager.remove(entity); } public void deleteById(long entityId){ T entity = findOne(entityId); delete(entity); } } 这里主要有趣的方面是EntityManager的注入方式——使用标准的*@PersistenceContext注释。在后台，这是由PersistenceAnnotationBeanPostProcessor*处理的——它处理注释，从包含中检索 JPA 实体管理器并注入它。 持久化后处理器要么通过在配置中定义显式创建，要么通过在命名空间配置中定义context:annotation-config或context:component-scan自动创建。 另外，请注意实体Class在构造函数中传递以用于通用操作： @Repository public class FooDAO extends AbstractJPADAO\u0026lt; Foo \u0026gt; implements IFooDAO{ public FooDAO(){ setClazz(Foo.class ); } } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_dao_jpa/","tags":["Spring Annotations","Spring Core Basics","Spring DI"],"title":"JPA 和 Spring 的 DAO"},{"categories":["REST","Spring MVC"],"contents":"1. 概述 我们可以使用org.springframework.beans.factory.annotation 和 org.springframework.context.annotation包中的注释来利用 Spring DI 引擎的功能。 我们经常将这些称为“Spring 核心注释”，我们将在本教程中回顾它们。 2. DI 相关注解 2.1 @Autowired 我们可以使用*@Autowired*来标记 Spring 将要解析和注入的依赖项。我们可以将此注解与构造函数、setter 或字段注入一起使用。 构造函数注入： class Car { Engine engine; @Autowired Car(Engine engine) { this.engine = engine; } } setter注入： class Car { Engine engine; @Autowired void setEngine(Engine engine) { this.engine = engine; } } 现场注入： class Car { @Autowired Engine engine; } @Autowired有一个名为required的boolean参数，默认值为true。当找不到合适的 bean 进行连接时，它会调整 Spring 的行为。当true时，抛出异常，否则，什么都没有连接。 请注意，如果我们使用构造函数注入，则所有构造函数参数都是必需的。 从 4.3 版开始，除非我们声明至少两个构造函数，否则我们不需要显式使用*@Autowired注释构造函数。* 有关更多详细信息，请访问我们关于@Autowired和构造函数注入的文章。 2.2 @Bean @Bean标记了一个实例化 Spring bean 的工厂方法： @Bean Engine engine() { return new Engine(); } 当需要返回类型的新实例时，Spring 会调用这些方法。 生成的 bean 与工厂方法具有相同的名称。如果我们想以不同的方式命名它，我们可以使用这个注解的name或value参数（参数value是参数name的别名）： @Bean(\u0026#34;engine\u0026#34;) Engine getEngine() { return new Engine(); } 请注意，所有使用*@Bean注释的方法都必须在@Configuration*类中。 2.3 @Qualifier 我们使用*@Qualifier和@Autowired*来提供我们想要在模棱两可的情况下使用的bean id 或bean 名称。 例如，以下两个 bean 实现了相同的接口： class Bike implements Vehicle {} class Car implements Vehicle {} 如果 Spring 需要注入一个Vehicle bean，它最终会得到多个匹配的定义。在这种情况下，我们可以使用@Qualifier注释显式地提供 bean 的名称。 使用构造函数注入： @Autowired Biker(@Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle) { this.vehicle = vehicle; } 使用 setter 注入： @Autowired void setVehicle(@Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle) { this.vehicle = vehicle; } 或者： @Autowired @Qualifier(\u0026#34;bike\u0026#34;) void setVehicle(Vehicle vehicle) { this.vehicle = vehicle; } 使用字段注入： @Autowired @Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle; 更详细的描述，请阅读这篇文章。 2.4 @Required @Required在 setter 方法上标记我们希望通过 XML 填充的依赖项： @Required void setColor(String color) { this.color = color; } \u0026lt;bean class=\u0026#34;com.codingman.annotations.Bike\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;color\u0026#34; value=\u0026#34;green\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 否则，将抛出BeanInitializationException 。 2.5 @Value 我们可以使用@Value将属性值注入到 bean 中。它与构造函数、设置器和字段注入兼容。 构造函数注入： Engine(@Value(\u0026#34;8\u0026#34;) int cylinderCount) { this.cylinderCount = cylinderCount; } setter注入： @Autowired void setCylinderCount(@Value(\u0026#34;8\u0026#34;) int cylinderCount) { this.cylinderCount = cylinderCount; } 或者： @Value(\u0026#34;8\u0026#34;) void setCylinderCount(int cylinderCount) { this.cylinderCount = cylinderCount; } 现场注入： @Value(\u0026#34;8\u0026#34;) int cylinderCount; 当然，注入静态值是没有用的。因此，我们可以在*@Value中使用占位符字符串来连接外部源中定义的**值，例如，在.properties或.yaml*文件中。 让我们假设以下*.properties*文件： engine.fuelType=petrol 我们可以使用以下内容注入engine.fuelType的值： @Value(\u0026#34;${engine.fuelType}\u0026#34;) String fuelType; 即使在 SpEL 中，我们也可以使用*@Value*。更多高级示例可以在我们关于*@Value*的文章中找到。 2.6 @DependsOn 我们可以使用这个注解让Spring在被注解的bean之前初始化其他bean。通常，这种行为是自动的，基于 bean 之间的显式依赖关系。 我们只有在依赖是隐式的时候才需要这个注解，例如 JDBC 驱动加载或者静态变量初始化。 我们可以在依赖类上使用*@DependsOn来指定依赖bean 的名称。注释的value*参数需要一个包含依赖 bean 名称的数组： @DependsOn(\u0026#34;engine\u0026#34;) class Car implements Vehicle {} 或者，如果我们使用*@Bean注解定义 bean，则工厂方法应该使用@DependsOn*进行注解： @Bean @DependsOn(\u0026#34;fuel\u0026#34;) Engine engine() { return new Engine(); } 2.7 @Lazy 当我们想要懒惰地初始化我们的bean时，我们使用@Lazy默认情况下，Spring 在应用程序上下文的启动/引导时急切地创建所有单例 bean。 但是，在某些情况下，我们需要在请求时创建 bean，而不是在应用程序启动时。 这个注解的行为会根据我们准确放置的位置而有所不同。我们可以装上：  一个*@Bean*注释的 bean 工厂方法，用于延迟方法调用（因此创建 bean） 一个*@Configuration类和所有包含的@Bean*方法都会受到影响 一个*@Component类，它不是一个@Configuration*类，这个bean 将被延迟初始化 @Autowired构造函数、设置器或字段，用于延迟加载依赖项本身（通过代理）  此注释有一个名为value的参数，默认值为true。覆盖默认行为很有用。 例如，当全局设置为惰性时，将 bean 标记为预加载，或者在标有*@Lazy的**@Configuration类中配置特定的@Bean*方法以预加载： @Configuration @Lazy class VehicleFactoryConfig { @Bean @Lazy(false) Engine engine() { return new Engine(); } } 如需进一步阅读，请访问本文。 2.8 @Lookup 使用*@Lookup*注释的方法告诉 Spring 在我们调用它时返回该方法的返回类型的实例。 有关注释的详细信息可以在本文中找到。 2.9 @Primary 有时我们需要定义多个相同类型的bean。在这些情况下，注入将不成功，因为 Spring 不知道我们需要哪个 bean。 我们已经看到了处理这种情况的一个选项：用*@Qualifier*标记所有连接点并指定所需bean 的名称。 然而，大多数时候我们需要一个特定的 bean 而很少需要其他的。我们可以使用*@Primary来简化这种情况：如果我们用@Primary*标记最常用的bean，它将在不合格的注入点上被选中： @Component @Primary class Car implements Vehicle {} @Component class Bike implements Vehicle {} @Component class Driver { @Autowired Vehicle vehicle; } @Component class Biker { @Autowired @Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle; } 在前面的示例中，汽车是主要车辆。因此，在Driver类中，Spring 注入了一个Car bean。当然，在Biker bean 中，字段vehicle的值将是Bike对象，因为它是合格的。 2.10 @Scope 我们使用*@Scope来定义@Component类或@Bean定义的范围。它可以是单例、原型、请求、会话、globalSession*或一些自定义范围。 例如： @Component @Scope(\u0026#34;prototype\u0026#34;) class Engine {} 3. 上下文配置注解 我们可以使用本节中描述的注释来配置应用程序上下文。 3.1 @Profile 如果我们希望 Spring仅在特定配置文件处于活动状态时使用*@Component类或@Bean方法，我们可以用@Profile标记它。我们可以使用注解的value*参数配置配置文件的名称： @Component @Profile(\u0026#34;sportDay\u0026#34;) class Bike implements Vehicle {} 您可以在本文中阅读有关配置文件的更多信息。 3.2. @Import 我们可以使用特定的*@Configuration类而无需使用此注解**进行组件扫描。*我们可以为这些类提供@Import的value参数： @Import(VehiclePartSupplier.class) class VehicleFactoryConfig {} 3.3 @ImportResource 我们可以使用此注解**导入 XML 配置。**我们可以使用位置参数指定 XML 文件位置，或者使用它的别名，Value参数： @Configuration @ImportResource(\u0026#34;classpath:/annotations.xml\u0026#34;) class VehicleFactoryConfig {} 3.4 @PropertySource 使用此注解，我们可以为应用程序设置定义属性文件： @Configuration @PropertySource(\u0026#34;classpath:/annotations.properties\u0026#34;) class VehicleFactoryConfig {} @PropertySource利用 Java 8 重复注释功能，这意味着我们可以多次使用它标记一个类： @Configuration @PropertySource(\u0026#34;classpath:/annotations.properties\u0026#34;) @PropertySource(\u0026#34;classpath:/vehicle-factory.properties\u0026#34;) class VehicleFactoryConfig {} 3.5. @PropertySources 我们可以使用这个注解来指定多个*@PropertySource*配置： @Configuration @PropertySources({ @PropertySource(\u0026#34;classpath:/annotations.properties\u0026#34;), @PropertySource(\u0026#34;classpath:/vehicle-factory.properties\u0026#34;) }) class VehicleFactoryConfig {} 请注意，从 Java 8 开始，我们可以通过上述重复注释功能实现相同的功能。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_core_annotations/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring 核心注解"},{"categories":["Spring"],"contents":"1. 概述 在这个简短的教程中，我们将讨论Spring MVC 中*@Controller和@RestController*注解之间的区别。 我们可以将第一个注解用于传统的 Spring 控制器，它已经成为框架的一部分很长时间了。 Spring 4.0 引入了*@RestController注解，以简化 RESTful Web 服务的创建。*这是一个方便的注解，结合了@Controller和*@ResponseBody* *，它消除了使用@ResponseBody*注解对控制器类的每个请求处理方法进行注解的需要。 2. Spring MVC @Controller 我们可以使用*@Controller*注解来注解经典控制器。这只是 @Component类的一个特化，它允许我们通过类路径扫描自动检测实现类。 我们通常将 @Controller与*@RequestMapping*注解结合使用，用于请求处理方法。 让我们看一个 Spring MVC 控制器的快速示例： @Controller @RequestMapping(\u0026#34;books\u0026#34;) public class SimpleBookController { @GetMapping(\u0026#34;/{id}\u0026#34;, produces = \u0026#34;application/json\u0026#34;) public @ResponseBody Book getBook(@PathVariable int id) { return findBookById(id); } private Book findBookById(int id) { // ...  } } 我们用@ResponseBody注释了请求处理方法。此注释支持将返回对象自动序列化到HttpResponse中。 3. Spring MVC @RestController @RestController是控制器的专用版本。它包括*@Controller和@ResponseBody*注释，因此简化了控制器的实现： @RestController @RequestMapping(\u0026#34;books-rest\u0026#34;) public class SimpleBookRestController { @GetMapping(\u0026#34;/{id}\u0026#34;, produces = \u0026#34;application/json\u0026#34;) public Book getBook(@PathVariable int id) { return findBookById(id); } private Book findBookById(int id) { // ...  } } 控制器使用@RestController注解进行注解；因此，不需要@ResponseBody。** 控制器类的每个请求处理方法都会自动将返回对象序列化为HttpResponse。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_controller_vs_restcontroller/","tags":["Spring Annotations","Spring Core Basics","Spring DI"],"title":"Spring @Controller 和 @RestController 注解"},{"categories":["Spring Boot"],"contents":"1. 简介 在本快速教程中，我们将了解Spring Framework 中*@Component*、@Repository和*@Service*注释之间的区别。 2. Spring注解 在大多数典型应用程序中，我们有不同的层，如数据访问、表示、服务、业务等。 此外，在每一层中，我们都有各种 bean。为了自动检测这些 bean，Spring 使用类路径扫描注解。 然后它在ApplicationContext中注册每个 bean 。 以下是其中一些注释的快速概述：  @Component是任何 Spring 管理的组件的通用构造型。 @Service在服务层注释类。 @Repository在持久层注释类，它将充当数据库存储库。  我们已经有一篇关于这些注释的扩展文章，所以我们将重点放在它们之间的区别上。 3. 有什么不同？ **这些刻板印象之间的主要区别在于它们用于不同的分类。**当我们注释一个类进行自动检测时，我们应该使用各自的原型。 现在让我们更详细地了解它们。 3.1 @Component 我们可以在整个应用程序中使用 @Component 将 bean 标记为 Spring 的托管组件。Spring 只会使用*@Component获取和注册bean，一般不会查找@Service* 和 @Repository。 它们在ApplicationContext中注册，因为它们使用*@Component*注释： @Component public @interface Service { } @Component public @interface Repository { } @Service 和 @Repository是*@Component*的特例。它们在技术上是相同的，但我们将它们用于不同的目的。 3.2 @Repository @Repository的工作是捕获特定于持久性的异常并将它们作为Spring的统一未检查异常之一重新抛出。 为此，Spring 提供了PersistenceExceptionTranslationPostProcessor，我们需要将其添加到我们的应用程序上下文中（如果我们使用 Spring Boot，则已经包括在内）： \u0026lt;bean class= \u0026#34;org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\u0026#34;/\u0026gt; 这个 bean 后处理器为任何使用 @Repository 注释的 bean 添加了一个顾问。 3.3 @Service 我们用@Service 标记bean 以表明它们持有业务逻辑。该注解除了用于服务层外，没有其他特殊用途。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_component_repository_service/","tags":[],"title":"Spring 中的 @Component 与 @Repository 和 @Service"},{"categories":["Spring"],"contents":"1. 概述 Spring Boot Web 应用程序默认包含一个预配置的嵌入式 Web 服务器。但是，在某些情况下，我们希望修改默认配置以满足自定义要求。 在本教程中，我们将了解如何在 Spring Boot 2.x 应用程序的application.properties文件中为请求标头设置和使用max-http-header-size属性。 2. Max-HTTP-Header-Size Spring Boot 支持Tomcat、Undertow和Jetty作为嵌入式服务器。通常，我们在 Spring Boot 应用程序中的application.properties文件或application.yaml文件中编写服务器配置。 大多数 Web 服务器都有自己的 HTTP 请求标头大小限制。HTTP 标头值受服务器实现的限制。在 Spring Boot 应用程序中，最大 HTTP 标头大小是使用server.max-http-header-size配置的。 Tomcat 和 Jetty 的实际默认值为 8kB，Undertow 的默认值为 1MB。 要修改最大 HTTP 标头大小，我们将属性添加到application.properties文件中： server.max-http-header-size=20000 对于application.yaml格式也是如此： server:max-http-header-size:20000从 Spring Boot 2.1 开始，我们现在将使用DataSize可解析值： server.max-http-header-size=10KB 3.请求头太大 假设在总 HTTP 标头大小大于max-http-header-size值的情况下发送请求。服务器以“400 Bad request”错误拒绝该请求。在下一个示例中，我们将在日志文件中看到此错误。 让我们创建一个控制器，它有一个名为 token 的标头属性： @RestController @RequestMapping(value = \u0026#34;/request-header-test\u0026#34;) public class MaxHttpHeaderSizeController { @GetMapping public boolean testMaxHTTPHeaderSize(@RequestHeader(value = \u0026#34;token\u0026#34;) String token) { return true; } } 接下来，让我们在application.properties文件中添加一些属性： ## Server connections configuration\rserver.tomcat.threads.max=200\rserver.connection-timeout=5s\rserver.max-http-header-size=8KB\rserver.tomcat.max-swallow-size=2MB\rserver.tomcat.max-http-post-size=2MB 当我们在令牌中传递一个大小大于 8kb的字符串值时，我们将得到 400 错误，如下所示： 在日志中，我们看到以下错误： 19:41:50.757 [http-nio-8080-exec-7] INFO o.a.coyote.http11.Http11Processor - Error parsing HTTP request header Note: further occurrences of HTTP request parsing errors will be logged at DEBUG level. java.lang.IllegalArgumentException: Request header is too large ... 4.解决方案 我们可以根据需要在application.properties文件中增加max-http-header-size属性的值。 在上面的程序中，我们可以将它的值从默认的 8kb 升级到 40KB，这样就可以解决问题了。 server.max-http-header-size=40KB 现在，服务器将处理请求并返回 200 响应，如下所示： 因此，每当标头大小超过服务器列出的默认值时，我们将看到服务器返回 400-Bad Request 并显示错误“请求标头太大”。如上例所示，我们必须覆盖应用程序配置文件中的max-http-header-size值以匹配请求标头长度。 通常，当使用的令牌由于加密而非常长时，请求标头可能会变得太大。\u0026quot; ","permalink":"http://itcodingman.github.io/spring_boot_max_http_header_size/","tags":["Spring Core Basics","Spring DI"],"title":"Spring Boot 2 中的 Max-HTTP-Header-Size"},{"categories":["Spring"],"contents":"1. 概述 在这个快速教程中，我们将了解 Spring 框架中不同类型的 bean 作用域。bean 的范围定义了该 bean 在我们使用它的上下文中的生命周期和可见性。最新版本的 Spring 框架定义了 6 种作用域：  单身人士 原型 要求 会议 应用 网络套接字  最后提到的四个范围，request、session、application和websocket，仅在 web 感知应用程序中可用。 2. 单例范围 当我们使用单例范围定义 bean 时，容器会创建该 bean 的单个实例；对该 bean 名称的所有请求都将返回相同的对象，该对象被缓存。对对象的任何修改都将反映在对 bean 的所有引用中。如果未指定其他范围，则此范围是默认值。 让我们创建一个Person实体来举例说明作用域的概念： public class Person { private String name; // standard constructor, getters and setters } 之后，我们使用*@Scope注释定义具有单例*范围的 bean： @Bean @Scope(\u0026#34;singleton\u0026#34;) public Person personSingleton() { return new Person(); } 我们还可以通过以下方式使用常量而不是String值： @Scope(value = ConfigurableBeanFactory.SCOPE_SINGLETON) 现在我们可以继续编写一个测试，表明引用同一个 bean 的两个对象将具有相同的值，即使它们中只有一个改变了它们的状态，因为它们都引用了同一个 bean 实例： private static final String NAME = \u0026#34;John Smith\u0026#34;; @Test public void givenSingletonScope_whenSetName_thenEqualNames() { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;scopes.xml\u0026#34;); Person personSingletonA = (Person) applicationContext.getBean(\u0026#34;personSingleton\u0026#34;); Person personSingletonB = (Person) applicationContext.getBean(\u0026#34;personSingleton\u0026#34;); personSingletonA.setName(NAME); Assert.assertEquals(NAME, personSingletonB.getName()); ((AbstractApplicationContext) applicationContext).close(); } 此示例中的scopes.xml文件应包含所用 bean 的 xml 定义： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;personSingleton\u0026#34; class=\u0026#34;com.codingman.scopes.Person\u0026#34; scope=\u0026#34;singleton\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 3.原型范围 每次从容器请求时，具有原型作用域的 bean都会返回不同的实例。它是通过将值prototype设置为 bean 定义中的*@Scope*注解来定义的： @Bean @Scope(\u0026#34;prototype\u0026#34;) public Person personPrototype() { return new Person(); } 我们也可以像在单例作用域中那样使用常量： @Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE) 我们现在将编写一个与之前类似的测试，显示两个对象在 原型 范围内请求相同的 bean 名称。它们将具有不同的状态，因为它们不再引用同一个 bean 实例： private static final String NAME = \u0026#34;John Smith\u0026#34;; private static final String NAME_OTHER = \u0026#34;Anna Jones\u0026#34;; @Test public void givenPrototypeScope_whenSetNames_thenDifferentNames() { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;scopes.xml\u0026#34;); Person personPrototypeA = (Person) applicationContext.getBean(\u0026#34;personPrototype\u0026#34;); Person personPrototypeB = (Person) applicationContext.getBean(\u0026#34;personPrototype\u0026#34;); personPrototypeA.setName(NAME); personPrototypeB.setName(NAME_OTHER); Assert.assertEquals(NAME, personPrototypeA.getName()); Assert.assertEquals(NAME_OTHER, personPrototypeB.getName()); ((AbstractApplicationContext) applicationContext).close(); } scopes.xml文件类似于上一节中介绍的文件，同时为具有原型作用域的 bean 添加xml定义： \u0026lt;bean id=\u0026#34;personPrototype\u0026#34; class=\u0026#34;com.codingman.scopes.Person\u0026#34; scope=\u0026#34;prototype\u0026#34;/\u0026gt; 4. Web 感知范围 如前所述，有四个附加范围仅在 Web 感知应用程序上下文中可用。我们在实践中较少使用这些。 请求范围为单个 HTTP 请求创建一个 bean 实例，而 s会话范围为一个 HTTP 会话创建一个 bean 实例。 应用程序范围为ServletContext的生命周期创建 bean 实例，而websocket范围为特定的WebSocket会话创建它。 让我们创建一个用于实例化 bean 的类： public class HelloMessageGenerator { private String message; // standard getter and setter } 4.1。请求范围 我们可以使用*@Scope注释定义具有请求*范围的 bean： @Bean @Scope(value = WebApplicationContext.SCOPE_REQUEST, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator requestScopedBean() { return new HelloMessageGenerator(); } proxyMode属性是必要的*，*因为在 Web 应用程序上下文的实例化时刻，没有活动请求。Spring 创建一个代理作为依赖注入，并在请求中需要它时实例化目标 bean。 我们还可以使用*@RequestScope*组合注释作为上述定义的快捷方式： @Bean @RequestScope public HelloMessageGenerator requestScopedBean() { return new HelloMessageGenerator(); } 接下来，我们可以定义一个控制器，该控制器具有对requestScopedBean的注入引用。我们需要访问同一个请求两次以测试 Web 特定范围。 如果我们在每次运行请求时都显示该消息，我们可以看到该值被重置为**null，即使它后来在方法中被更改。这是因为每个请求都返回了不同的 bean 实例。 @Controller public class ScopesController { @Resource(name = \u0026#34;requestScopedBean\u0026#34;) HelloMessageGenerator requestScopedBean; @RequestMapping(\u0026#34;/scopes/request\u0026#34;) public String getRequestScopeMessage(final Model model) { model.addAttribute(\u0026#34;previousMessage\u0026#34;, requestScopedBean.getMessage()); requestScopedBean.setMessage(\u0026#34;Good morning!\u0026#34;); model.addAttribute(\u0026#34;currentMessage\u0026#34;, requestScopedBean.getMessage()); return \u0026#34;scopesExample\u0026#34;; } } 4.2. 会话范围 我们可以用类似的方式定义具有会话范围的 bean： @Bean @Scope(value = WebApplicationContext.SCOPE_SESSION, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator sessionScopedBean() { return new HelloMessageGenerator(); } 还有一个专用的组合注释，我们可以使用它来简化 bean 定义： @Bean @SessionScope public HelloMessageGenerator sessionScopedBean() { return new HelloMessageGenerator(); } 接下来我们定义一个引用sessionScopedBean的控制器。同样，我们需要运行两个请求以显示消息字段的值对于会话是相同的。 在这种情况下，当第一次发出请求时，值消息为*空。*但是，一旦更改，该值将保留给后续请求，因为为整个会话返回相同的 bean 实例。 @Controller public class ScopesController { @Resource(name = \u0026#34;sessionScopedBean\u0026#34;) HelloMessageGenerator sessionScopedBean; @RequestMapping(\u0026#34;/scopes/session\u0026#34;) public String getSessionScopeMessage(final Model model) { model.addAttribute(\u0026#34;previousMessage\u0026#34;, sessionScopedBean.getMessage()); sessionScopedBean.setMessage(\u0026#34;Good afternoon!\u0026#34;); model.addAttribute(\u0026#34;currentMessage\u0026#34;, sessionScopedBean.getMessage()); return \u0026#34;scopesExample\u0026#34;; } } 4.3. 适用范围 应用程序范围为ServletContext的生命周期创建 bean 实例。 这类似于单例范围，但在 bean 的范围方面有一个非常重要的区别。 当 bean 是应用程序作用域时，bean 的同一个实例在同一个**ServletContext中运行的多个基于 servlet 的应用程序之间共享，而单例作用域 bean 的作用域仅限于单个应用程序上下文。 让我们创建具有应用程序范围的 bean ： @Bean @Scope( value = WebApplicationContext.SCOPE_APPLICATION, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator applicationScopedBean() { return new HelloMessageGenerator(); } 类似于请求和会话范围，我们可以使用更短的版本： @Bean @ApplicationScope public HelloMessageGenerator applicationScopedBean() { return new HelloMessageGenerator(); } 现在让我们创建一个引用这个 bean 的控制器： @Controller public class ScopesController { @Resource(name = \u0026#34;applicationScopedBean\u0026#34;) HelloMessageGenerator applicationScopedBean; @RequestMapping(\u0026#34;/scopes/application\u0026#34;) public String getApplicationScopeMessage(final Model model) { model.addAttribute(\u0026#34;previousMessage\u0026#34;, applicationScopedBean.getMessage()); applicationScopedBean.setMessage(\u0026#34;Good afternoon!\u0026#34;); model.addAttribute(\u0026#34;currentMessage\u0026#34;, applicationScopedBean.getMessage()); return \u0026#34;scopesExample\u0026#34;; } } 在这种情况下，一旦在applicationScopedBean中设置，值消息将保留给所有后续请求、会话，甚至对于将访问此 bean 的不同 servlet 应用程序，只要它在相同的ServletContext 中运行。 4.4. WebSocket 范围 最后，让我们使用websocket范围创建 bean ： @Bean @Scope(scopeName = \u0026#34;websocket\u0026#34;, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator websocketScopedBean() { return new HelloMessageGenerator(); } 首次访问时，WebSocket范围的 bean 存储在WebSocket会话属性中。每当在整个WebSocket会话期间访问该 bean 时，都会返回该 bean 的相同实例。 我们也可以说它表现出单例行为，但仅限于WebSocket**会话。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_bean_scopes/","tags":["Spring Annotations","Spring Core Basics"],"title":"Spring Bean 范围快速指南"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将讨论用于定义不同类型bean的最常见的 Spring bean 注释。 有几种方法可以在 Spring 容器中配置 bean。首先，我们可以使用 XML 配置声明它们。我们还可以在配置类中使用*@Bean*注解来声明 bean。 最后，我们可以使用org.springframework.stereotype包中的注释之一标记该类，并将其余部分留给组件扫描。 2. 组件扫描 如果启用了组件扫描，Spring可以自动扫描包中的bean。 @ComponentScan配置要扫描哪些包以查找具有注释配置的类。我们可以使用basePackages或value参数之一直接指定基本包名称（value是basePackages的别名）： @Configuration @ComponentScan(basePackages = \u0026#34;com.codingman.annotations\u0026#34;) class VehicleFactoryConfig {} 此外，我们可以使用basePackageClasses参数指向基础包中的类： @Configuration @ComponentScan(basePackageClasses = VehicleFactoryConfig.class) class VehicleFactoryConfig {} 这两个参数都是数组，因此我们可以为每个参数提供多个包。 如果未指定参数，则扫描从存在*@ComponentScan*注释类的同一包中进行。 @ComponentScan利用了 Java 8 的重复注解特性，这意味着我们可以用它多次标记一个类： @Configuration @ComponentScan(basePackages = \u0026#34;com.codingman.annotations\u0026#34;) @ComponentScan(basePackageClasses = VehicleFactoryConfig.class) class VehicleFactoryConfig {} 或者，我们可以使用*@ComponentScans指定多个@ComponentScan*配置： @Configuration @ComponentScans({ @ComponentScan(basePackages = \u0026#34;com.codingman.annotations\u0026#34;), @ComponentScan(basePackageClasses = VehicleFactoryConfig.class) }) class VehicleFactoryConfig {} 使用XML 配置时，配置组件扫描同样简单： \u0026lt;context:component-scan base-package=\u0026#34;com.codingman\u0026#34; /\u0026gt; 3. @Component @Component是一个类级别的注解。在组件扫描期间，Spring Framework 会自动检测带有@Component的类： @Component class CarUtility { // ... } 默认情况下，此类的 bean 实例与具有小写首字母的类名称具有相同的名称。此外，我们可以使用此注解的可选value参数指定不同的名称。 由于*@Repository*、@Service、@Configuration和*@Controller都是@Component*的元注释，它们共享相同的 bean 命名行为。Spring 还会在组件扫描过程中自动拾取它们。 4. @Repository DAO 或 Repository 类通常代表应用程序中的数据库访问层，应使用*@Repository 进行注释：* @Repository class VehicleRepository { // ... } 使用此注释的一个优点是它启用了自动持久性异常转换。当使用持久性框架（例如 Hibernate）时，在带有*@Repository注释的类中抛出的本机异常将自动转换为 Spring 的DataAccessExeption*的子类。 要启用异常翻译，我们需要声明我们自己的PersistenceExceptionTranslationPostProcessor bean： @Bean public PersistenceExceptionTranslationPostProcessor exceptionTranslation() { return new PersistenceExceptionTranslationPostProcessor(); } 请注意，在大多数情况下，Spring 会自动执行上述步骤。 或者通过 XML 配置： \u0026lt;bean class= \u0026#34;org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\u0026#34;/\u0026gt; 5. @Service 应用程序的业务逻辑通常驻留在服务层中，因此我们将使用*@Service*来指示一个类属于该层： @Service public class VehicleService { // ... } 6. @Controller @Controller是一个类级别的注解，它告诉 Spring Framework 这个类作为Spring MVC 中的一个控制器： @Controller public class VehicleController { // ... } 7. @Configuration Configuration类包含使用*@Bean*注解的bean 定义方法： @Configuration class VehicleFactoryConfig { @Bean Engine engine() { return new Engine(); } } 8. 原型注解和AOP 当我们使用Spring原型注解时，很容易创建一个指向所有具有特定原型的类的切入点。 例如，假设我们想从 DAO 层测量方法的执行时间。我们将利用*@Repository*原型创建以下方面（使用AspectJ 注释）： @Aspect @Component public class PerformanceAspect { @Pointcut(\u0026#34;within(@org.springframework.stereotype.Repository *)\u0026#34;) public void repositoryClassMethods() {}; @Around(\u0026#34;repositoryClassMethods()\u0026#34;) public Object measureMethodExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable { long start = System.nanoTime(); Object returnValue = joinPoint.proceed(); long end = System.nanoTime(); String methodName = joinPoint.getSignature().getName(); System.out.println( \u0026#34;Execution of \u0026#34; + methodName + \u0026#34; took \u0026#34; + TimeUnit.NANOSECONDS.toMillis(end - start) + \u0026#34; ms\u0026#34;); return returnValue; } } 在此示例中，我们创建了一个切入点，该切入点匹配使用*@Repository注释的类中的所有方法。然后我们使用@Around*通知来定位那个切入点，并确定被拦截方法调用的执行时间。 此外，使用这种方法，我们可以将日志记录、性能管理、审计和其他行为添加到每个应用程序层。\u0026quot; ","permalink":"http://itcodingman.github.io/spring_bean_annotations/","tags":["Spring Core Basics"],"title":"Spring Bean 注解"},{"categories":["Spring"],"contents":"1. 概述 Bean 是 Spring Framework 的一个关键概念。因此，理解这个概念对于掌握框架并以有效的方式使用它至关重要。 不幸的是，**对于 Spring bean 究竟是什么这个简单问题，并没有明确的答案。**一些解释太低了以至于错过了大局，而另一些解释太模糊了。 本教程将尝试阐明该主题，从官方文档中的描述开始。 2. bean定义 这是Spring Framework 文档中 bean 的定义 ： 在 Spring 中，构成应用程序主干并由 Spring IoC 容器管理的对象称为 bean。bean 是由 Spring IoC 容器实例化、组装和管理的对象。 这个定义简洁明了，**但没有详细说明一个重要元素：Spring IoC 容器。**让我们仔细看看它是什么以及它带来的好处。 3. 控制反转 简单地说，控制反转(IoC) 是**一个对象定义其依赖关系而不创建它们的过程。**该对象将构建此类依赖项的工作委托给 IoC 容器。 在深入研究 IoC 之前，让我们先声明几个域类。 3.1 领域类 假设我们有一个类声明： public class Company { private Address address; public Company(Address address) { this.address = address; } // getter, setter and other properties } 这个类需要一个 Address类型的协作者： public class Address { private String street; private int number; public Address(String street, int number) { this.street = street; this.number = number; } // getters and setters } 3.2 传统方法 通常，我们使用类的构造函数创建对象： Address address = new Address(\u0026#34;High Street\u0026#34;, 1000); Company company = new Company(address); 这种方法没有任何问题，但是以更好的方式管理依赖关系不是很好吗？ 想象一个有几十个甚至几百个类的应用程序。有时我们希望在整个应用程序中共享一个类的单个实例，有时我们需要为每个用例提供一个单独的对象，等等。 管理如此多的对象简直就是一场噩梦。这就是控制反转来拯救的地方。 对象可以从 IoC 容器中检索其依赖项，而不是自己构建依赖项。我们需要做的就是为容器提供适当的配置元数据。 3.3 Bean配置 首先，让我们用*@Component注解来装饰Company类：* @Component public class Company { // this body is the same as before } 这是一个向 IoC 容器提供 bean 元数据的配置类： @Configuration @ComponentScan(basePackageClasses = Company.class) public class Config { @Bean public Address getAddress() { return new Address(\u0026#34;High Street\u0026#34;, 1000); } } 配置类产生一个 Address类型的 bean 。它还带有*@ComponentScan注释，它指示容器在包含Company*类的包中查找 bean。 当 Spring IoC 容器构造这些类型的对象时，所有对象都称为 Spring bean，因为它们由 IoC 容器管理。 3.4 IoC 由于我们在配置类中定义了 bean，我们需要AnnotationConfigApplicationContext类的实例来构建容器： ApplicationContext context = new AnnotationConfigApplicationContext(Config.class); 快速测试验证我们的 bean 的存在和属性值： Company company = context.getBean(\u0026#34;company\u0026#34;, Company.class); assertEquals(\u0026#34;High Street\u0026#34;, company.getAddress().getStreet()); assertEquals(1000, company.getAddress().getNumber()); 结果证明 IoC 容器已经正确地创建和初始化了 bean。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_bean/","tags":["Spring Core Basics","Spring DI"],"title":"什么是 Spring Bean"},{"categories":["Spring"],"contents":"1. 概述 从 Spring 2.5 开始，该框架引入了注解驱动的依赖注入。此功能的主要注释是*@Autowired* 。 它允许 Spring 解析协作 bean 并将其注入到我们的 bean 中。 在本教程中，我们将首先了解如何启用自动装配以及自动装配 bean 的 各种 方法。之后，我们将讨论使用**@Qualifier注解解决 bean 冲突**，以及潜在的异常情况。 2. 启用*@Autowired*注解 Spring 框架支持自动依赖注入。换句话说，通过在 Spring 配置文件中声明所有 bean 依赖项，Spring 容器可以自动装配协作 bean 之间的关系。这称为Spring bean 自动装配。 要在我们的应用程序中使用基于 Java 的配置，让我们启用注解驱动注入 来加载我们的 Spring 配置： @Configuration @ComponentScan(\u0026#34;com.codingman.autowire.sample\u0026#34;) public class AppConfig {} 或者，注解主要用于激活 Spring XML 文件中的依赖注入注解。 此外，Spring Boot 引入了@SpringBootApplication注解。此单个注释等效于使用*@Configuration*、@EnableAutoConfiguration和 @ComponentScan。 让我们在应用程序的主类中使用这个注解： @SpringBootApplication class VehicleFactoryApplication { public static void main(String[] args) { SpringApplication.run(VehicleFactoryApplication.class, args); } } 因此，当我们运行这个 Spring Boot 应用程序时，它会自动扫描当前包及其子包中的组件。因此它将在 Spring 的应用程序上下文中注册它们，并允许我们使用*@Autowired*注入 bean 。 3. 使用*@Autowired* 启用注解注入后，我们可以对属性、设置器和构造器使用自动装配。 3.1 @Autowired属性 让我们看看如何使用*@Autowired*注释属性。这消除了对 getter 和 setter 的需要。 首先，让我们定义一个fooFormatter bean： @Component(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter { public String format() { return \u0026#34;foo\u0026#34;; } } 然后，我们将在字段定义上使用*@Autowired将此 bean 注入FooService bean：* @Component public class FooService { @Autowired private FooFormatter fooFormatter; } 因此，Spring在创建FooService时会注入fooFormatter。 3.2. 设置器上的@Autowired 现在让我们尝试在 setter 方法上添加*@Autowired注解。* 在以下示例中，在创建FooService时使用FooFormatter的实例调用 setter 方法： public class FooService { private FooFormatter fooFormatter; @Autowired public void setFooFormatter(FooFormatter fooFormatter) { this.fooFormatter = fooFormatter; } } 3.3. @Autowired在构造函数上 最后，让我们在构造函数上使用*@Autowired*。 我们将看到Spring 将 FooFormatter 的实例作为FooService**构造函数的参数注入： public class FooService { private FooFormatter fooFormatter; @Autowired public FooService(FooFormatter fooFormatter) { this.fooFormatter = fooFormatter; } } 4. @Autowired和可选依赖 构建 bean 时，@Autowired依赖项应该可用。否则，如果 Spring 无法解析 bean 进行布线，它将抛出异常。 因此，它会阻止 Spring 容器成功启动，但以下形式除外： Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.autowire.sample.FooDAO] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} 为了解决这个问题，我们需要声明一个所需类型的 bean： public class FooService { @Autowired(required = false) private FooDAO dataAccessor; } 5. Autowire歧义 默认情况下，Spring 按类型解析*@Autowired*条目。如果容器中有多个相同类型的 bean 可用，框架将抛出一个致命异常。 为了解决这个冲突，我们需要明确地告诉 Spring 我们要注入哪个bean。 5.1 @Qualifier自动装配 例如，让我们看看如何使用@Qualifier注解来指示所需的 bean。 首先，我们将定义 2 个Formatter类型的 bean ： @Component(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter implements Formatter { public String format() { return \u0026#34;foo\u0026#34;; } } @Component(\u0026#34;barFormatter\u0026#34;) public class BarFormatter implements Formatter { public String format() { return \u0026#34;bar\u0026#34;; } } 现在让我们尝试将Formatter bean 注入FooService类： public class FooService { @Autowired private Formatter formatter; } 在我们的示例中，有两个可用于 Spring 容器的Formatter的具体实现。因此， Spring 在构造FooService时会抛出NoUniqueBeanDefinitionException异常： Caused by: org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type [com.autowire.sample.Formatter] is defined: expected single matching bean but found 2: barFormatter,fooFormatter 我们可以通过使用@Qualifier注解缩小实现范围来避免这种情况： public class FooService { @Autowired @Qualifier(\u0026#34;fooFormatter\u0026#34;) private Formatter formatter; } 当有多个相同类型的 bean 时，最好使用@Qualifier来避免歧义。 请注意，@Qualifier 注释的值与我们的FooFormatter实现的*@Component*注释中声明的名称匹配。 5.2 通过自定义限定符自动装配 Spring 还允许我们创建自己的自定义@Qualifier注释。为此，我们应该提供带有定义的*@Qualifier*注释： @Qualifier @Target({ ElementType.FIELD, ElementType.METHOD, ElementType.TYPE, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) public @interface FormatterType { String value(); } 然后我们可以在各种实现中使用FormatterType 来指定自定义值： @FormatterType(\u0026#34;Foo\u0026#34;) @Component public class FooFormatter implements Formatter { public String format() { return \u0026#34;foo\u0026#34;; } } @FormatterType(\u0026#34;Bar\u0026#34;) @Component public class BarFormatter implements Formatter { public String format() { return \u0026#34;bar\u0026#34;; } } 最后，我们的自定义 Qualifier 注解已准备好用于自动装配： @Component public class FooService { @Autowired @FormatterType(\u0026#34;Foo\u0026#34;) private Formatter formatter; } @Target元注释中指定的值限制了应用限定符的位置，在我们的示例中是字段、方法、类型和参数。 5.3. 按名称自动装配 **Spring 使用 bean 的名称作为默认限定符值。**它将检查容器并查找具有确切名称的 bean 作为属性来自动装配它。 因此，在我们的示例中，Spring 将fooFormatter属性名称与FooFormatter实现相匹配。因此，它在构造FooService时注入了该特定实现： public class FooService { @Autowired private Formatter fooFormatter; } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_autowired/","tags":["Spring DI","Spring Core Basics"],"title":"Spring @Autowired 指南"},{"categories":["Spring"],"contents":"1. 概述 在本 Spring Framework 教程中，我们将演示如何使用与依赖注入相关的注解，即*@Resource*、@Inject和*@Autowired*注解。这些注解为类提供了一种声明性的方式来解决依赖关系： @Autowired ArbitraryClass arbObject; 与直接实例化它们相反（命令式）： ArbitraryClass arbObject = new ArbitraryClass(); 三个注解中有两个属于 Java 扩展包：javax.annotation.Resource和javax.inject.Inject。@Autowired注解属于org.springframework.beans.factory.annotation包。 这些注解中的每一个都可以通过字段注入或 setter 注入来解决依赖关系。我们将使用一个简化但实用的示例来演示三个注释之间的区别，基于每个注释所采用的执行路径。 示例将重点介绍如何在集成测试期间使用三个注入注解。测试所需的依赖可以是任意文件或任意类。 2. @Resource注解 @Resource注释是JSR-250注释集合的一部分，并与 Jakarta EE 一起打包。此注解具有以下执行路径，按优先级列出：  按名称匹配 按类型匹配 按限定词匹配  这些执行路径适用于 setter 和 field 注入。 2.1 现场注入 我们可以通过使用@Resource注释来注释实例变量来通过字段注入来解决依赖关系。 2.1.1 按名称匹配 我们将使用以下集成测试来演示按名称匹配字段注入： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceNameType.class) public class FieldResourceInjectionIntegrationTest { @Resource(name=\u0026#34;namedFile\u0026#34;) private File defaultFile; @Test public void givenResourceAnnotation_WhenOnField_ThenDependencyValid(){ assertNotNull(defaultFile); assertEquals(\u0026#34;namedFile.txt\u0026#34;, defaultFile.getName()); } } 让我们看一下代码。在FieldResourceInjectionTest集成测试中，在第 7 行，我们通过将 bean 名称作为属性值传递给*@Resource*注释来按名称解析依赖项： @Resource(name=\u0026#34;namedFile\u0026#34;) private File defaultFile; 此配置将使用按名称匹配执行路径解析依赖关系。我们必须在ApplicationContextTestResourceNameType应用程序上下文中定义 bean namedFile 。 注意 bean id 和对应的引用属性值必须匹配： @Configuration public class ApplicationContextTestResourceNameType { @Bean(name=\u0026#34;namedFile\u0026#34;) public File namedFile() { File namedFile = new File(\u0026#34;namedFile.txt\u0026#34;); return namedFile; } } 如果我们未能在应用程序上下文中定义 bean，它将导致org.springframework.beans.factory.NoSuchBeanDefinitionException被抛出。我们可以通过更改ApplicationContextTestResourceNameType应用程序上下文中传递给**@Bean注解的属性值，或者更改FieldResourceInjectionTest集成测试中传递给*@Resource*注解的属性值来证明这一点。 2.1.2 按类型匹配 为了演示按类型匹配的执行路径，我们只删除FieldResourceInjectionTest集成测试第 7 行的属性值： @Resource private File defaultFile; 然后我们再次运行测试。 测试仍然会通过，因为如果*@Resource*注释没有接收到 bean 名称作为属性值，Spring 框架将继续进行下一级优先级，按类型匹配，以尝试解决依赖关系。 2.1.3 按限定词匹配 为了演示 match-by-qualifier 执行路径，将修改集成测试场景，以便在ApplicationContextTestResourceQualifier应用程序上下文中定义两个 bean： @Configuration public class ApplicationContextTestResourceQualifier { @Bean(name=\u0026#34;defaultFile\u0026#34;) public File defaultFile() { File defaultFile = new File(\u0026#34;defaultFile.txt\u0026#34;); return defaultFile; } @Bean(name=\u0026#34;namedFile\u0026#34;) public File namedFile() { File namedFile = new File(\u0026#34;namedFile.txt\u0026#34;); return namedFile; } } 我们将使用QualifierResourceInjectionTest集成测试来演示逐个匹配的依赖关系解析。在这种情况下，需要将特定的 bean 依赖注入到每个引用变量中： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceQualifier.class) public class QualifierResourceInjectionIntegrationTest { @Resource private File dependency1; @Resource private File dependency2; @Test public void givenResourceAnnotation_WhenField_ThenDependency1Valid(){ assertNotNull(dependency1); assertEquals(\u0026#34;defaultFile.txt\u0026#34;, dependency1.getName()); } @Test public void givenResourceQualifier_WhenField_ThenDependency2Valid(){ assertNotNull(dependency2); assertEquals(\u0026#34;namedFile.txt\u0026#34;, dependency2.getName()); } } 当我们运行集成测试时，会抛出org.springframework.beans.factory.NoUniqueBeanDefinitionException 。**这会发生，因为应用程序上下文将找到两个类型为File的 bean 定义，并且不知道哪个 bean 应该解决依赖关系。 要解决这个问题，我们需要参考QualifierResourceInjectionTest集成测试的第 7 行到第 10 行： @Resource private File dependency1; @Resource private File dependency2; 我们必须添加以下代码行： @Qualifier(\u0026#34;defaultFile\u0026#34;) @Qualifier(\u0026#34;namedFile\u0026#34;) 使代码块如下所示： @Resource @Qualifier(\u0026#34;defaultFile\u0026#34;) private File dependency1; @Resource @Qualifier(\u0026#34;namedFile\u0026#34;) private File dependency2; 当我们再次运行集成测试时，它应该会通过。我们的测试表明，即使我们在应用程序上下文中定义了多个 bean，我们也可以使用*@Qualifier*注释通过允许我们将特定的依赖项注入到一个类中来消除任何混淆。 2.2 Setter注入 在字段上注入依赖项时所采用的执行路径也适用于基于 setter 的注入。 2.2.1 按名称匹配 唯一的区别是MethodResourceInjectionTest集成测试有一个 setter 方法： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceNameType.class) public class MethodResourceInjectionIntegrationTest { private File defaultFile; @Resource(name=\u0026#34;namedFile\u0026#34;) protected void setDefaultFile(File defaultFile) { this.defaultFile = defaultFile; } @Test public void givenResourceAnnotation_WhenSetter_ThenDependencyValid(){ assertNotNull(defaultFile); assertEquals(\u0026#34;namedFile.txt\u0026#34;, defaultFile.getName()); } } 我们通过注解引用变量的相应 setter 方法，通过 setter 注入来解决依赖关系。然后我们将bean依赖的名称作为属性值传递给*@Resource*注解： private File defaultFile; @Resource(name=\u0026#34;namedFile\u0026#34;) protected void setDefaultFile(File defaultFile) { this.defaultFile = defaultFile; } 在本例中，我们将重用namedFile bean 依赖项。bean 名称和相应的属性值必须匹配。 当我们运行集成测试时，它将通过。 为了让我们验证按名称匹配执行路径是否解决了依赖关系，我们需要将传递给*@Resource注解的属性值更改为我们选择的值并再次运行测试。这一次，测试将失败并出现NoSuchBeanDefinitionException*。 2.2.2 按类型匹配 为了演示基于 setter、按类型匹配的执行，我们将使用MethodByTypeResourceTest集成测试： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceNameType.class) public class MethodByTypeResourceIntegrationTest { private File defaultFile; @Resource protected void setDefaultFile(File defaultFile) { this.defaultFile = defaultFile; } @Test public void givenResourceAnnotation_WhenSetter_ThenValidDependency(){ assertNotNull(defaultFile); assertEquals(\u0026#34;namedFile.txt\u0026#34;, defaultFile.getName()); } } 当我们运行这个测试时，它会通过。 为了让我们验证按类型匹配的执行路径是否解决了File依赖关系，我们需要将defaultFile变量的类类型更改为另一个类类型，如String。然后我们可以再次执行MethodByTypeResourceTest集成测试，这次会抛出NoSuchBeanDefinitionException 。 该异常验证是否确实使用了按类型匹配来解决文件依赖关系。NoSuchBeanDefinitionException确认引用变量名称不需要与 bean 名称匹配。相反，依赖解析取决于 bean 的类类型与引用变量的类类型匹配。 2.2.3 按限定词匹配 我们将使用MethodByQualifierResourceTest集成测试来演示 match-by-qualifier 执行路径： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceQualifier.class) public class MethodByQualifierResourceIntegrationTest { private File arbDependency; private File anotherArbDependency; @Test public void givenResourceQualifier_WhenSetter_ThenValidDependencies(){ assertNotNull(arbDependency); assertEquals(\u0026#34;namedFile.txt\u0026#34;, arbDependency.getName()); assertNotNull(anotherArbDependency); assertEquals(\u0026#34;defaultFile.txt\u0026#34;, anotherArbDependency.getName()); } @Resource @Qualifier(\u0026#34;namedFile\u0026#34;) public void setArbDependency(File arbDependency) { this.arbDependency = arbDependency; } @Resource @Qualifier(\u0026#34;defaultFile\u0026#34;) public void setAnotherArbDependency(File anotherArbDependency) { this.anotherArbDependency = anotherArbDependency; } } 我们的测试表明，即使我们在应用程序上下文中定义了特定类型的多个 bean 实现，我们也可以使用*@Qualifier注释和@Resource*注释来解决依赖关系。 类似于基于字段的依赖注入，如果我们在一个应用上下文中定义多个bean，我们必须使用 @Qualifier 注解来指定使用哪个bean来解析依赖，否则会抛出NoUniqueBeanDefinitionException 。 3. @Inject注解 @Inject注解属于JSR-330注解集合。此注解具有以下执行路径，按优先级列出：  按类型匹配 按预选赛匹配 按名称匹配  这些执行路径适用于 setter 和 field 注入。为了让我们访问*@Inject注解，我们必须将javax.inject*库声明为 Gradle 或 Maven 依赖项。 对于 Gradle： testCompile group: \u0026#39;javax.inject\u0026#39;, name: \u0026#39;javax.inject\u0026#39;, version: \u0026#39;1\u0026#39; 对于 Maven： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.inject\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.inject\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.1 现场注入 3.1.1 按类型匹配 我们将修改集成测试示例以使用另一种类型的依赖项，即ArbitraryDependency类。ArbitraryDependency类依赖仅作为一个简单的依赖，并没有进一步的意义： @Component public class ArbitraryDependency { private final String label = \u0026#34;Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 这是有问题的FieldInjectTest集成测试： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestInjectType.class) public class FieldInjectIntegrationTest { @Inject private ArbitraryDependency fieldInjectDependency; @Test public void givenInjectAnnotation_WhenOnField_ThenValidDependency(){ assertNotNull(fieldInjectDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, fieldInjectDependency.toString()); } } 与*@Resource注解首先按名称解析依赖关系不同，@* Inject注解的默认行为是按类型解析依赖关系。 这意味着即使类引用变量名称与 bean 名称不同，依赖关系仍然会被解析，前提是 bean 是在应用程序上下文中定义的。请注意以下测试中引用变量名称的方式： @Inject private ArbitraryDependency fieldInjectDependency; 与应用程序上下文中配置的 bean 名称不同： @Bean public ArbitraryDependency injectDependency() { ArbitraryDependency injectDependency = new ArbitraryDependency(); return injectDependency; } 当我们执行测试时，我们能够解决依赖关系。 3.1.2 按限定词匹配 如果一个特定的类类型有多个实现，并且某个类需要一个特定的 bean，该怎么办？让我们修改集成测试示例，使其需要另一个依赖项。 在此示例中，我们将ArbitraryDependency类（在按类型匹配示例中使用）进行子类化，以创建AnotherArbitraryDependency类： public class AnotherArbitraryDependency extends ArbitraryDependency { private final String label = \u0026#34;Another Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 每个测试用例的目标是确保我们将每个依赖项正确地注入每个引用变量中： @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; 我们可以使用FieldQualifierInjectTest集成测试来演示限定符匹配： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestInjectQualifier.class) public class FieldQualifierInjectIntegrationTest { @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; @Test public void givenInjectQualifier_WhenOnField_ThenDefaultFileValid(){ assertNotNull(defaultDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, defaultDependency.toString()); } @Test public void givenInjectQualifier_WhenOnField_ThenNamedFileValid(){ assertNotNull(defaultDependency); assertEquals(\u0026#34;Another Arbitrary Dependency\u0026#34;, namedDependency.toString()); } } 如果我们在应用程序上下文中有多个特定类的实现，并且FieldQualifierInjectTest集成测试尝试以下面列出的方式注入依赖项，则会抛出NoUniqueBeanDefinitionException ： @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; 抛出这个异常是 Spring 框架指出某个类有多个实现的方式，它对使用哪一个感到困惑。为了阐明混淆，我们可以转到FieldQualifierInjectTest集成测试的第 7 行和第 10 行： @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; 我们可以将所需的 bean 名称传递给*@Qualifier注释，我们将其与@Inject*注释一起使用。这就是代码块现在的样子： @Inject @Qualifier(\u0026#34;defaultFile\u0026#34;) private ArbitraryDependency defaultDependency; @Inject @Qualifier(\u0026#34;namedFile\u0026#34;) private ArbitraryDependency namedDependency; @Qualifier注解在接收 bean 名称时要求严格匹配。我们必须确保将 bean 名称正确传递给Qualifier，否则将抛出*NoUniqueBeanDefinitionException 。*如果我们再次运行测试，它应该会通过。 3.1.3 按名称匹配 用于演示按名称匹配的FieldByNameInjectTest集成测试类似于按类型匹配执行路径。唯一的区别是现在我们需要一个特定的 bean，而不是一个特定的类型。在此示例中，我们再次对ArbitraryDependency类进行子类化以生成YetAnotherArbitraryDependency类： public class YetAnotherArbitraryDependency extends ArbitraryDependency { private final String label = \u0026#34;Yet Another Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 为了演示按名称匹配的执行路径，我们将使用以下集成测试： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestInjectName.class) public class FieldByNameInjectIntegrationTest { @Inject @Named(\u0026#34;yetAnotherFieldInjectDependency\u0026#34;) private ArbitraryDependency yetAnotherFieldInjectDependency; @Test public void givenInjectQualifier_WhenSetOnField_ThenDependencyValid(){ assertNotNull(yetAnotherFieldInjectDependency); assertEquals(\u0026#34;Yet Another Arbitrary Dependency\u0026#34;, yetAnotherFieldInjectDependency.toString()); } } 我们列出应用程序上下文： @Configuration public class ApplicationContextTestInjectName { @Bean public ArbitraryDependency yetAnotherFieldInjectDependency() { ArbitraryDependency yetAnotherFieldInjectDependency = new YetAnotherArbitraryDependency(); return yetAnotherFieldInjectDependency; } } 如果我们运行集成测试，它将通过。 为了验证我们是否通过按名称匹配执行路径注入了依赖项，我们需要将传入*@Named注释的值**yetAnotherFieldInjectDependency更改为我们选择的另一个名称。当我们再次运行测试时，会抛出NoSuchBeanDefinitionException 。* 3.2 Setter注入 @Inject注解的基于设置器的注入类似于用于基于*@Resource*设置器的注入的方法。我们不是注释引用变量，而是注释相应的 setter 方法。基于字段的依赖注入所遵循的执行路径也适用于基于 setter 的注入。 4. @Autowired注解 @Autowired注解的行为类似于*@Inject注解。唯一的区别是@Autowired*注解是 Spring 框架的一部分。此注解与@Inject注解具有相同的执行路径，按优先顺序列出：  按类型匹配 按限定词匹配 按名称匹配  这些执行路径适用于 setter 和 field 注入。 4.1 现场注入 4.1.1 按类型匹配 用于演示*@Autowired按类型匹配执行路径的集成测试示例将类似于用于演示@Inject按类型匹配执行路径的测试。我们使用以下FieldAutowiredTest集成测试来演示使用@Autowired*注释的按类型匹配： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestAutowiredType.class) public class FieldAutowiredIntegrationTest { @Autowired private ArbitraryDependency fieldDependency; @Test public void givenAutowired_WhenSetOnField_ThenDependencyResolved() { assertNotNull(fieldDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, fieldDependency.toString()); } } 我们列出了此集成测试的应用程序上下文： @Configuration public class ApplicationContextTestAutowiredType { @Bean public ArbitraryDependency autowiredFieldDependency() { ArbitraryDependency autowiredFieldDependency = new ArbitraryDependency(); return autowiredFieldDependency; } } 我们使用此集成测试来证明按类型匹配优先于其他执行路径。注意FieldAutowiredTest集成测试第 8 行的引用变量名称： @Autowired private ArbitraryDependency fieldDependency; 这与应用程序上下文中的 bean 名称不同： @Bean public ArbitraryDependency autowiredFieldDependency() { ArbitraryDependency autowiredFieldDependency = new ArbitraryDependency(); return autowiredFieldDependency; } 当我们运行测试时，它应该通过了。 为了确认依赖确实是使用 match-by-type 执行路径解决的，我们需要更改fieldDependency引用变量的类型并再次运行集成测试。这一次，FieldAutowiredTest集成测试将失败，并引发NoSuchBeanDefinitionException。这验证了我们使用了按类型匹配来解决依赖关系。 4.1.2 按限定词匹配 如果我们遇到在应用程序上下文中定义了多个 bean 实现的情况怎么办： @Configuration public class ApplicationContextTestAutowiredQualifier { @Bean public ArbitraryDependency autowiredFieldDependency() { ArbitraryDependency autowiredFieldDependency = new ArbitraryDependency(); return autowiredFieldDependency; } @Bean public ArbitraryDependency anotherAutowiredFieldDependency() { ArbitraryDependency anotherAutowiredFieldDependency = new AnotherArbitraryDependency(); return anotherAutowiredFieldDependency; } } 如果我们执行以下FieldQualifierAutowiredTest集成测试，将抛出NoUniqueBeanDefinitionException ： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestAutowiredQualifier.class) public class FieldQualifierAutowiredIntegrationTest { @Autowired private ArbitraryDependency fieldDependency1; @Autowired private ArbitraryDependency fieldDependency2; @Test public void givenAutowiredQualifier_WhenOnField_ThenDep1Valid(){ assertNotNull(fieldDependency1); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, fieldDependency1.toString()); } @Test public void givenAutowiredQualifier_WhenOnField_ThenDep2Valid(){ assertNotNull(fieldDependency2); assertEquals(\u0026#34;Another Arbitrary Dependency\u0026#34;, fieldDependency2.toString()); } } 异常是由于应用程序上下文中定义的两个 bean 引起的歧义。Spring 框架不知道哪个 bean 依赖项应该自动装配到哪个引用变量。我们可以通过在FieldQualifierAutowiredTest集成测试的第 7 行和第 10 行添加*@Qualifier*注释来解决此问题： @Autowired private FieldDependency fieldDependency1; @Autowired private FieldDependency fieldDependency2; 使代码块如下所示： @Autowired @Qualifier(\u0026#34;autowiredFieldDependency\u0026#34;) private FieldDependency fieldDependency1; @Autowired @Qualifier(\u0026#34;anotherAutowiredFieldDependency\u0026#34;) private FieldDependency fieldDependency2; 当我们再次运行测试时，它将通过。 4.1.3 按名称匹配 我们将使用相同的集成测试场景来演示使用@Autowired注释注入字段依赖项的按名称匹配执行路径。当按名称自动装配依赖项时，@ComponentScan注释必须与应用程序上下文ApplicationContextTestAutowiredName一起使用： @Configuration @ComponentScan(basePackages={\u0026#34;com.codingman.dependency\u0026#34;}) public class ApplicationContextTestAutowiredName { } 我们使用*@ComponentScan注解在包中搜索已使用@Component 注解进行注解的Java类*。例如，在应用程序上下文中，将扫描com.codingman.dependency包以查找已使用*@Component注释进行注释的类。在这种情况下，Spring 框架必须检测带有@Component注解的ArbitraryDependency*类： @Component(value=\u0026#34;autowiredFieldDependency\u0026#34;) public class ArbitraryDependency { private final String label = \u0026#34;Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 传递到*@Component注释的属性值autowiredFieldDependency告诉 Spring 框架ArbitraryDependency类是一个名为autowiredFieldDependency的组件。为了让@Autowired注解通过名称解析依赖，组件名称必须与FieldAutowiredNameTest*集成测试中定义的字段名称相对应；请参考第8行： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestAutowiredName.class) public class FieldAutowiredNameIntegrationTest { @Autowired private ArbitraryDependency autowiredFieldDependency; @Test public void givenAutowiredAnnotation_WhenOnField_ThenDepValid(){ assertNotNull(autowiredFieldDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, autowiredFieldDependency.toString()); } } 当我们运行FieldAutowiredNameTest集成测试时，它将通过。 但是我们怎么知道*@Autowired注解确实调用了按名称匹配的执行路径呢？我们可以将引用变量autowiredFieldDependency*的名称更改为我们选择的另一个名称，然后再次运行测试。 这一次，测试将失败并抛出NoUniqueBeanDefinitionException。类似的检查是将*@Component属性值autowiredFieldDependency更改为我们选择的另一个值并再次运行测试。NoUniqueBeanDefinitionException也会*被抛出。 这个异常证明如果我们使用不正确的 bean 名称，将找不到有效的 bean。这就是我们知道调用了按名称匹配执行路径的方式。 4.2. Setter注入 @Autowired注解的基于设置器的注入类似于为基于*@Resource*设置器的注入演示的方法。我们不是用@Inject注解来注解引用变量，而是注解对应的setter。基于字段的依赖注入所遵循的执行路径也适用于基于 setter 的注入。 5. 应用这些注释 这就提出了应该使用哪种注释以及在什么情况下使用的问题。这些问题的答案取决于相关应用程序面临的设计场景，以及开发人员希望如何利用基于每个注释的默认执行路径的多态性。 5.1 通过多态性在应用程序范围内使用单例 如果设计是这样的应用程序行为基于接口或抽象类的实现，并且这些行为在整个应用程序中使用，那么我们可以使用*@Inject或@Autowired*注解。 这种方法的好处是，当我们升级应用程序或应用补丁来修复错误时，可以将类换出，而对整体应用程序行为的负面影响最小。在这种情况下，主要的默认执行路径是按类型匹配。 5.2 通过多态进行细粒度的应用程序行为配置 如果设计使得应用程序具有复杂的行为，每个行为都基于不同的接口/抽象类，并且这些实现中的每一个的使用因应用程序而异，那么我们可以使用*@Resource*注解。在这种情况下，主要的默认执行路径是按名称匹配。 5.3 依赖注入应该由 Jakarta EE 平台单独处理 如果 Jakarta EE 平台而不是 Spring 注入所有依赖项的设计要求，那么选择是在*@Resource注释和@Inject*注释之间进行选择。我们应该根据需要哪个默认执行路径来缩小两个注释之间的最终决定。 5.4 依赖注入应该由 Spring 框架单独处理 如果要求所有依赖项都由 Spring 框架处理，则唯一的选择是*@Autowired*注释。 5.5 讨论总结 下表总结了我们的讨论。    场景 @Resource @Inject @Autowired     通过多态性在应用程序范围内使用单例 ✗ ✔ ✔   通过多态进行细粒度的应用程序行为配置 ✔ ✗ ✗   依赖注入由 Jakarta EE 平台单独处理 ✔ ✔ ✗   依赖注入由 Spring Framework 单独处理 ✗ ✗ ✔   \u0026quot;       ","permalink":"http://itcodingman.github.io/spring_annotations_resource_inject_autowire/","tags":["Spring DI","Spring Core Basics"],"title":"Spring 中的注解：@Autowired、@Resource 和 @Inject"},{"categories":["Spring Security"],"contents":"1、概述 在本教程中，我们将使用 OAuth2 保护 REST API，并从一个简单的 Angular 客户端使用它。 我们要构建的应用程序将包含三个独立的模块：  授权服务器 资源服务器 UI 授权码：使用授权码流程的前端应用程序  **我们将在 Spring Security 5 中使用 OAuth 堆栈。**如果您想使用 Spring Security OAuth legacy stack，请查看之前的这篇文章：Spring REST API + OAuth2 + Angular（使用 Spring Security OAuth Legacy Stack）。 2. OAuth2授权服务器（AS） 简单地说，授权服务器是一个发布授权令牌的应用程序。 以前，Spring Security OAuth 堆栈提供了将授权服务器设置为 Spring 应用程序的可能性。但该项目已被弃用，主要是因为 OAuth 是一个开放标准，拥有许多成熟的供应商，例如 Okta、Keycloak 和 ForgeRock，仅举几例。 其中，我们将使用Keycloak。它是由 Red Hat 管理的开源身份和访问管理服务器，由 JBoss 用 Java 开发。它不仅支持 OAuth2，还支持其他标准协议，例如 OpenID Connect 和 SAML。 对于本教程，我们将在 Spring Boot 应用程序中设置嵌入式 Keycloak 服务器。 3. 资源服务器（RS） 现在让我们讨论资源服务器；这本质上是 REST API，我们最终希望能够使用它。 3.1 Maven 配置 我们的资源服务器的 pom 与之前的授权服务器 pom 非常相似，没有 Keycloak 部分，并具有额外的spring-boot-starter-oauth2-resource-server依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-oauth2-resource-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 3.2 安全配置 由于我们使用的是 Spring Boot，因此我们可以使用 Boot 属性定义所需的最低配置。 我们将在application.yml文件中执行此操作： server: port: 8081 servlet: context-path: /resource-server spring: security: oauth2: resourceserver: jwt: issuer-uri: http://localhost:8083/auth/realms/codingman jwk-set-uri: http://localhost:8083/auth/realms/codingman/protocol/openid-connect/certs 在这里，我们指定我们将使用 JWT 令牌进行授权。 jwk *-set-uri*属性指向包含公钥的 URI，以便我们的资源服务器可以验证令牌的完整性。 issuer-uri属性表示验证令牌颁发者（即授权服务器）的附加安全措施。但是，添加此属性还要求授权服务器应该在我们启动资源服务器应用程序之前运行。 接下来，让我们为 API 设置安全配置以保护端点： @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors() .and() .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/user/info\u0026#34;, \u0026#34;/api/foos/**\u0026#34;) .hasAuthority(\u0026#34;SCOPE_read\u0026#34;) .antMatchers(HttpMethod.POST, \u0026#34;/api/foos\u0026#34;) .hasAuthority(\u0026#34;SCOPE_write\u0026#34;) .anyRequest() .authenticated() .and() .oauth2ResourceServer() .jwt(); } } 正如我们所见，对于我们的 GET 方法，我们只允许具有读取范围的请求。对于 POST 方法，请求者除了read之外还需要有写权限。但是，对于任何其他端点，该请求应该只通过任何用户进行身份验证。 此外，**oauth2ResourceServer *()***方法指定这是一个资源服务器，带有*jwt()*格式的令牌。 这里要注意的另一点是使用方法*cors()*来允许请求上的 Access-Control 标头。这一点尤其重要，因为我们正在处理一个 Angular 客户端，并且我们的请求将来自另一个源 URL。 3.4 模型和存储库 接下来，让我们为我们的模型Foo定义一个javax.persistence.Entity： @Entity public class Foo { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; // constructor, getters and setters } 然后我们需要一个Foo的存储库。我们将使用 Spring 的PagingAndSortingRepository： public interface IFooRepository extends PagingAndSortingRepository\u0026lt;Foo, Long\u0026gt; { } 3.4 服务与实施 之后，我们将为我们的 API 定义并实现一个简单的服务： public interface IFooService { Optional\u0026lt;Foo\u0026gt; findById(Long id); Foo save(Foo foo); Iterable\u0026lt;Foo\u0026gt; findAll(); } @Service public class FooServiceImpl implements IFooService { private IFooRepository fooRepository; public FooServiceImpl(IFooRepository fooRepository) { this.fooRepository = fooRepository; } @Override public Optional\u0026lt;Foo\u0026gt; findById(Long id) { return fooRepository.findById(id); } @Override public Foo save(Foo foo) { return fooRepository.save(foo); } @Override public Iterable\u0026lt;Foo\u0026gt; findAll() { return fooRepository.findAll(); } } 3.5 示例控制器 现在让我们实现一个简单的控制器，通过 DTO公开我们的Foo资源： @RestController @RequestMapping(value = \u0026#34;/api/foos\u0026#34;) public class FooController { private IFooService fooService; public FooController(IFooService fooService) { this.fooService = fooService; } @CrossOrigin(origins = \u0026#34;http://localhost:8089\u0026#34;) @GetMapping(value = \u0026#34;/{id}\u0026#34;) public FooDto findOne(@PathVariable Long id) { Foo entity = fooService.findById(id) .orElseThrow(() -\u0026gt; new ResponseStatusException(HttpStatus.NOT_FOUND)); return convertToDto(entity); } @GetMapping public Collection\u0026lt;FooDto\u0026gt; findAll() { Iterable\u0026lt;Foo\u0026gt; foos = this.fooService.findAll(); List\u0026lt;FooDto\u0026gt; fooDtos = new ArrayList\u0026lt;\u0026gt;(); foos.forEach(p -\u0026gt; fooDtos.add(convertToDto(p))); return fooDtos; } protected FooDto convertToDto(Foo entity) { FooDto dto = new FooDto(entity.getId(), entity.getName()); return dto; } } 注意上面@CrossOrigin的使用；这是控制器级别的配置，我们需要允许来自我们的 Angular 应用程序的 CORS 在指定的 URL 上运行。 这是我们的FooDto： public class FooDto { private long id; private String name; } 4. 前端——设置 现在，我们将研究一个简单的客户端 Angular 前端实现，它将访问我们的 REST API。 我们将首先使用Angular CLI来生成和管理我们的前端模块。 首先，我们安装node 和 npm，因为 Angular CLI 是一个 npm 工具。 然后我们需要使用frontend-maven-plugin来使用 Maven 构建我们的 Angular 项目： \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.github.eirslett\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;frontend-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;nodeVersion\u0026gt;v6.10.2\u0026lt;/nodeVersion\u0026gt; \u0026lt;npmVersion\u0026gt;3.10.10\u0026lt;/npmVersion\u0026gt; \u0026lt;workingDirectory\u0026gt;src/main/resources\u0026lt;/workingDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;install node and npm\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;install-node-and-npm\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;npm install\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;npm\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;npm run build\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;npm\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;arguments\u0026gt;run build\u0026lt;/arguments\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 最后，使用 Angular CLI 生成一个新模块： ng new oauthApp 在下一节中，我们将讨论 Angular 应用程序逻辑。 5. 使用 Angular 的授权代码流程 我们将在此处使用 OAuth2 授权代码流程。 我们的用例：客户端应用程序从授权服务器请求代码并显示登录页面。**一旦用户提供了他们的有效凭证并提交，授权服务器就会给我们代码。**然后前端客户端使用它来获取访问令牌。 5.1 HomeComponent 让我们从我们的主要组件HomeComponent开始，所有动作都从这里开始： @Component({ selector: \u0026#39;home-header\u0026#39;, providers: [AppService], template: `\u0026lt;div class=\u0026#34;container\u0026#34; \u0026gt; \u0026lt;button *ngIf=\u0026#34;!isLoggedIn\u0026#34; class=\u0026#34;btn btn-primary\u0026#34; (click)=\u0026#34;login()\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt; Login\u0026lt;/button\u0026gt; \u0026lt;div *ngIf=\u0026#34;isLoggedIn\u0026#34; class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;span\u0026gt;Welcome !!\u0026lt;/span\u0026gt; \u0026lt;a class=\u0026#34;btn btn-default pull-right\u0026#34;(click)=\u0026#34;logout()\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Logout\u0026lt;/a\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;foo-details\u0026gt;\u0026lt;/foo-details\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;` }) export class HomeComponent { public isLoggedIn = false; constructor(private _service: AppService) { } ngOnInit() { this.isLoggedIn = this._service.checkCredentials(); let i = window.location.href.indexOf(\u0026#39;code\u0026#39;); if(!this.isLoggedIn \u0026amp;\u0026amp; i != -1) { this._service.retrieveToken(window.location.href.substring(i + 5)); } } login() { window.location.href = \u0026#39;http://localhost:8083/auth/realms/codingman/protocol/openid-connect/auth? response_type=code\u0026amp;scope=openid%20write%20read\u0026amp;client_id=\u0026#39; + this._service.clientId + \u0026#39;\u0026amp;redirect_uri=\u0026#39;+ this._service.redirectUri; } logout() { this._service.logout(); } } 一开始，当用户没有登录时，只出现登录按钮。单击此按钮后，用户将导航到 AS 的授权 URL，他们在其中键入用户名和密码。成功登录后，用户将使用授权代码重定向回来，然后我们使用此代码检索访问令牌。 5.2 AppService 现在让我们看看*AppService——位于app.service.ts——*它包含服务器交互的逻辑：  retrieveToken()：使用授权码获取访问令牌 saveToken()：使用 ng2-cookies 库将我们的访问令牌保存在 cookie 中 getResource()：使用其 ID 从服务器获取 Foo 对象 checkCredentials() : 检查用户是否登录 logout()：删除访问令牌cookie并注销用户  export class Foo { constructor(public id: number, public name: string) { } } @Injectable() export class AppService { public clientId = \u0026#39;newClient\u0026#39;; public redirectUri = \u0026#39;http://localhost:8089/\u0026#39;; constructor(private _http: HttpClient) { } retrieveToken(code) { let params = new URLSearchParams(); params.append(\u0026#39;grant_type\u0026#39;,\u0026#39;authorization_code\u0026#39;); params.append(\u0026#39;client_id\u0026#39;, this.clientId); params.append(\u0026#39;client_secret\u0026#39;, \u0026#39;newClientSecret\u0026#39;); params.append(\u0026#39;redirect_uri\u0026#39;, this.redirectUri); params.append(\u0026#39;code\u0026#39;,code); let headers = new HttpHeaders({\u0026#39;Content-type\u0026#39;: \u0026#39;application/x-www-form-urlencoded; charset=utf-8\u0026#39;}); this._http.post(\u0026#39;http://localhost:8083/auth/realms/codingman/protocol/openid-connect/token\u0026#39;, params.toString(), { headers: headers }) .subscribe( data =\u0026gt; this.saveToken(data), err =\u0026gt; alert(\u0026#39;Invalid Credentials\u0026#39;)); } saveToken(token) { var expireDate = new Date().getTime() + (1000 * token.expires_in); Cookie.set(\u0026#34;access_token\u0026#34;, token.access_token, expireDate); console.log(\u0026#39;Obtained Access token\u0026#39;); window.location.href = \u0026#39;http://localhost:8089\u0026#39;; } getResource(resourceUrl) : Observable\u0026lt;any\u0026gt; { var headers = new HttpHeaders({ \u0026#39;Content-type\u0026#39;: \u0026#39;application/x-www-form-urlencoded; charset=utf-8\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;CD \u0026#39;+Cookie.get(\u0026#39;access_token\u0026#39;)}); return this._http.get(resourceUrl, { headers: headers }) .catch((error:any) =\u0026gt; Observable.throw(error.json().error || \u0026#39;Server error\u0026#39;)); } checkCredentials() { return Cookie.check(\u0026#39;access_token\u0026#39;); } logout() { Cookie.delete(\u0026#39;access_token\u0026#39;); window.location.reload(); } } 在retrieveToken方法中，我们使用我们的客户端凭据和基本身份验证将POST发送到*/openid-connect/token*端点以获取访问令牌。参数以 URL 编码格式发送。获得访问令牌后，我们将其存储在 cookie 中。 cookie 存储在这里尤为重要，因为我们仅将 cookie 用于存储目的，而不是直接驱动身份验证过程。这有助于防止跨站点请求伪造 (CSRF) 攻击和漏洞。 5.3. Foo 组件 最后，我们的FooComponent来显示我们的 Foo 详细信息： @Component({ selector: \u0026#39;foo-details\u0026#39;, providers: [AppService], template: `\u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;col-sm-12\u0026#34;\u0026gt;Foo Details\u0026lt;/h1\u0026gt; \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;col-sm-3\u0026#34;\u0026gt;ID\u0026lt;/label\u0026gt; \u0026lt;span\u0026gt;{{foo.id}}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;col-sm-3\u0026#34;\u0026gt;Name\u0026lt;/label\u0026gt; \u0026lt;span\u0026gt;{{foo.name}}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;btn btn-primary\u0026#34; (click)=\u0026#34;getFoo()\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt;New Foo\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;` }) export class FooComponent { public foo = new Foo(1,\u0026#39;sample foo\u0026#39;); private foosUrl = \u0026#39;http://localhost:8081/resource-server/api/foos/\u0026#39;; constructor(private _service:AppService) {} getFoo() { this._service.getResource(this.foosUrl+this.foo.id) .subscribe( data =\u0026gt; this.foo = data, error =\u0026gt; this.foo.name = \u0026#39;Error\u0026#39;); } } 5.4 AppComponent 我们简单的AppComponent作为根组件： @Component({ selector: \u0026#39;app-root\u0026#39;, template: `\u0026lt;nav class=\u0026#34;navbar navbar-default\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container-fluid\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;navbar-header\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;navbar-brand\u0026#34; href=\u0026#34;/\u0026#34;\u0026gt;Spring Security Oauth - Authorization Code\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;router-outlet\u0026gt;\u0026lt;/router-outlet\u0026gt;` }) export class AppComponent { } 还有我们包装所有组件、服务和路由的AppModule ： @NgModule({ declarations: [ AppComponent, HomeComponent, FooComponent ], imports: [ BrowserModule, HttpClientModule, RouterModule.forRoot([ { path: \u0026#39;\u0026#39;, component: HomeComponent, pathMatch: \u0026#39;full\u0026#39; }], {onSameUrlNavigation: \u0026#39;reload\u0026#39;}) ], providers: [], bootstrap: [AppComponent] }) export class AppModule { } 5.5 运行前端  要运行我们的任何前端模块，我们需要先构建应用程序：  mvn clean install 然后我们需要导航到我们的 Angular 应用目录：  cd src/main/resources 最后，我们将启动我们的应用程序：  npm start 服务器将默认在端口 4200 上启动；要更改任何模块的端口，请更改： \u0026#34;start\u0026#34;: \u0026#34;ng serve\u0026#34; 在*package.json 中；*例如，要使其在端口 8089 上运行，请添加： \u0026#34;start\u0026#34;: \u0026#34;ng serve --port 8089\u0026#34; \u0026quot; ","permalink":"http://itcodingman.github.io/securing_a_restful_web_service_with_spring_security/","tags":["OAuth New Stack"],"title":"Spring REST API + OAuth2 + Angular"},{"categories":["REST","Spring"],"contents":"1. 概述 本教程将重点介绍使用 Spring MVC 和 Spring Data 在 REST API 中实现分页。 2. 页面作为资源与页面作为表示 在 RESTful 架构的上下文中设计分页时的第一个问题是，是否将页面视为实际资源或只是资源的表示。 将页面本身视为资源会带来许多问题，例如不再能够在调用之间唯一标识资源。这一点，再加上在持久层中，页面不是一个适当的实体，而是一个在必要时构建的持有者，这使得选择变得简单；页面是表示的一部分。 REST 上下文中分页设计的下一个问题是在哪里包含分页信息：  在 URI 路径中：/foo/page/1 URI 查询：/foo?page=1  请记住，页面不是 Resource，因此无法在 URI 中对页面信息进行编码。 我们将使用标准方法通过在 URI 查询中编码分页信息来解决这个问题。 3. 控制器 现在进行实施用于分页的 Spring MVC 控制器很简单： @GetMapping(params = { \u0026#34;page\u0026#34;, \u0026#34;size\u0026#34; }) public List\u0026lt;Foo\u0026gt; findPaginated(@RequestParam(\u0026#34;page\u0026#34;) int page, @RequestParam(\u0026#34;size\u0026#34;) int size, UriComponentsBuilder uriBuilder, HttpServletResponse response) { Page\u0026lt;Foo\u0026gt; resultPage = service.findPaginated(page, size); if (page \u0026gt; resultPage.getTotalPages()) { throw new MyResourceNotFoundException(); } eventPublisher.publishEvent(new PaginatedResultsRetrievedEvent\u0026lt;Foo\u0026gt;( Foo.class, uriBuilder, response, page, resultPage.getTotalPages(), size)); return resultPage.getContent(); } 在此示例中，我们 通过@RequestParam在 Controller 方法中注入两个查询参数size和page。 或者，我们可以使用Pageable对象，它自动映射page、 size和sort参数。此外，PagingAndSortingRepository实体提供了开箱即用的方法，支持使用Pageable作为参数。 我们还注入了 Http Response 和UriComponentsBuilder来帮助实现可发现性，我们通过自定义事件将其解耦。如果这不是 API 的目标，我们可以简单地删除自定义事件。 最后，注意本文的重点只是REST和web层；要深入了解分页的数据访问部分，我们可以查看这篇关于使用 Spring Data 进行分页的文章。 4. REST 分页的可发现性 在分页范围内，满足REST 的 HATEOAS 约束意味着 API 的客户端能够根据导航中的当前页面发现下一页和上一页。为此，我们将使用Link HTTP 标头，以及“下一个”、 “上一个”、“第一个”和“最后一个”链接关系类型。 在 REST 中，可发现性是一个横切关注点，不仅适用于特定操作，还适用于操作类型。例如，每次创建资源时，客户端应该可以发现该资源的 URI。由于此要求与 ANY Resource 的创建相关，因此我们将单独处理它。 正如我们在上一篇文章中讨论的那样，我们将使用事件来解耦这些关注点，重点是 REST 服务的可发现性。在分页的情况下，事件PaginatedResultsRetrievedEvent在控制器层中触发。然后，我们将使用此事件的自定义侦听器实现可发现性。 简而言之，监听器将检查导航是否允许下一页、 上一页、 第一页 和 最后一页。如果是这样，它会将相关的 URI 作为“链接”HTTP Header 添加到响应中。 现在让我们一步一步来。从控制器传递的UriComponentsBuilder仅包含基本 URL（主机、端口和上下文路径）。因此，我们必须添加其余部分： void addLinkHeaderOnPagedResourceRetrieval( UriComponentsBuilder uriBuilder, HttpServletResponse response, Class clazz, int page, int totalPages, int size ){ String resourceName = clazz.getSimpleName().toString().toLowerCase(); uriBuilder.path( \u0026#34;/admin/\u0026#34; + resourceName ); // ...  } 接下来，我们将使用StringJoiner 连接每个链接。我们将使用uriBuilder来生成 URI。让我们看看我们如何处理到下一页的链接： StringJoiner linkHeader = new StringJoiner(\u0026#34;, \u0026#34;); if (hasNextPage(page, totalPages)){ String uriForNextPage = constructNextPageUri(uriBuilder, page, size); linkHeader.add(createLinkHeader(uriForNextPage, \u0026#34;next\u0026#34;)); } 我们看一下 constructNextPageUri方法的逻辑： String constructNextPageUri(UriComponentsBuilder uriBuilder, int page, int size) { return uriBuilder.replaceQueryParam(PAGE, page + 1) .replaceQueryParam(\u0026#34;size\u0026#34;, size) .build() .encode() .toUriString(); } 我们将对我们想要包含的其余 URI 进行类似的处理。 最后，我们将输出添加为响应标头： response.addHeader(\u0026#34;Link\u0026#34;, linkHeader.toString()); 请注意，为简洁起见，仅包含部分代码示例。 5. 分页 分页和可发现性的主要逻辑都包含在小型、集中的集成测试中。与上一篇文章一样，我们将使用 REST-assured 库来使用 REST 服务并验证结果。 这些是分页集成测试的一些示例： @Test public void whenResourcesAreRetrievedPaged_then200IsReceived(){ Response response = RestAssured.get(paths.getFooURL() + \u0026#34;?page=0\u0026amp;size=2\u0026#34;); assertThat(response.getStatusCode(), is(200)); } @Test public void whenPageOfResourcesAreRetrievedOutOfBounds_then404IsReceived(){ String url = getFooURL() + \u0026#34;?page=\u0026#34; + randomNumeric(5) + \u0026#34;\u0026amp;size=2\u0026#34;; Response response = RestAssured.get.get(url); assertThat(response.getStatusCode(), is(404)); } @Test public void givenResourcesExist_whenFirstPageIsRetrieved_thenPageContainsResources(){ createResource(); Response response = RestAssured.get(paths.getFooURL() + \u0026#34;?page=0\u0026amp;size=2\u0026#34;); assertFalse(response.body().as(List.class).isEmpty()); } 6. 分页可发现性 测试分页是否可以被客户发现是相对简单的，尽管有很多内容需要覆盖。 测试将关注当前页面在导航中的位置，以及应该从每个位置发现的不同 URI： @Test public void whenFirstPageOfResourcesAreRetrieved_thenSecondPageIsNext(){ Response response = RestAssured.get(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;); String uriToNextPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;next\u0026#34;); assertEquals(getFooURL()+\u0026#34;?page=1\u0026amp;size=2\u0026#34;, uriToNextPage); } @Test public void whenFirstPageOfResourcesAreRetrieved_thenNoPreviousPage(){ Response response = RestAssured.get(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;); String uriToPrevPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;prev\u0026#34;); assertNull(uriToPrevPage ); } @Test public void whenSecondPageOfResourcesAreRetrieved_thenFirstPageIsPrevious(){ Response response = RestAssured.get(getFooURL()+\u0026#34;?page=1\u0026amp;size=2\u0026#34;); String uriToPrevPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;prev\u0026#34;); assertEquals(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;, uriToPrevPage); } @Test public void whenLastPageOfResourcesIsRetrieved_thenNoNextPageIsDiscoverable(){ Response first = RestAssured.get(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;); String uriToLastPage = extractURIByRel(first.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;last\u0026#34;); Response response = RestAssured.get(uriToLastPage); String uriToNextPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;next\u0026#34;); assertNull(uriToNextPage); } 7. 获取所有资源 在分页和可发现性的同一主题上，必须做出选择，是允许客户端一次检索系统中的所有资源，还是客户端必须分页请求它们。 如果确定客户端无法通过单个请求检索所有资源，并且需要分页，那么有几个选项可用于响应以获取请求。一种选择是返回 404 ( Not Found ) 并使用Link标头使第一页可发现：  链接=http://localhost:8080/rest/api/admin/foo?page=0\u0026size=2; rel=”first”, http://localhost:8080/rest/api/admin/foo?page=103\u0026size=2; rel=“last”  另一种选择是将重定向 303 （请参阅其他）返回到第一页。更保守的方法是简单地为 GET 请求返回 405（不允许的方法）给客户端。 8. 带有Range HTTP 标头的 REST 分页 实现分页的一种相对不同的方式是使用HTTP Range标头、 Range、Content-Range、If-Range、Accept-Ranges和HTTP 状态代码、 206（部分内容）、413（请求实体太大）和416（请求的范围不可满足）。 这种方法的一种观点是，HTTP Range 扩展不用于分页，它们应该由服务器管理，而不是由应用程序管理。基于 HTTP Range 标头扩展实现分页在技术上是可行的，尽管不像本文中讨论的实现那样普遍。 9. Spring Data REST 分页 在 Spring Data 中，如果我们需要从完整的数据集中返回一些结果，我们可以使用任何Pageable存储库方法，因为它总是返回一个Page。将根据页码、页面大小和排序方向返回结果。 Spring Data REST自动识别page, size, sort等URL 参数。 要使用任何存储库的分页方法，我们需要扩展PagingAndSortingRepository： public interface SubjectRepository extends PagingAndSortingRepository\u0026lt;Subject, Long\u0026gt;{} 如果我们调用 http://localhost:8080/subjects， Spring 会自动通过 API添加page, size, sort参数建议： \u0026#34;_links\u0026#34; : { \u0026#34;self\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/subjects{?page,size,sort}\u0026#34;, \u0026#34;templated\u0026#34; : true } } 默认情况下，页面大小为 20，但我们可以通过调用类似http://localhost:8080/subjects?page=10 的方法来更改它。 如果我们想在我们自己的自定义存储库 API 中实现分页，我们需要传递一个额外的Pageable参数并确保 API 返回一个Page： @RestResource(path = \u0026#34;nameContains\u0026#34;) public Page\u0026lt;Subject\u0026gt; findByNameContaining(@Param(\u0026#34;name\u0026#34;) String name, Pageable p); 每当我们添加自定义 API 时，都会将/search端点添加到生成的链接中。因此，如果我们调用 http://localhost:8080/subjects/search，我们将看到一个支持分页的端点： \u0026#34;findByNameContaining\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/subjects/search/nameContains{?name,page,size,sort}\u0026#34;, \u0026#34;templated\u0026#34; : true } 所有实现 PagingAndSortingRepository的 API都会返回一个Page。如果我们需要从Page返回结果列表， Page的getContent() API提供了作为 Spring Data REST API 结果获取的记录列表。 10. 将List转换为Page 假设我们有一个Pageable对象作为输入，但是我们需要检索的信息包含在一个列表而不是PagingAndSortingRepository中。在这些情况下，我们可能需要将List转换为Page。 例如，假设我们有一个SOAP服务的结果列表： List\u0026lt;Foo\u0026gt; list = getListOfFooFromSoapService(); 我们需要访问发送给我们的Pageable对象指定的特定位置的列表。所以让我们定义开始索引： int start = (int) pageable.getOffset(); 和结束索引： int end = (int) ((start + pageable.getPageSize()) \u0026gt; fooList.size() ? fooList.size() : (start + pageable.getPageSize())); 有了这两个，我们可以创建一个Page来获取它们之间的元素列表： Page\u0026lt;Foo\u0026gt; page = new PageImpl\u0026lt;Foo\u0026gt;(fooList.subList(start, end), pageable, fooList.size()); 而已！我们现在可以将page作为有效结果返回。 请注意，如果我们还想支持排序，我们需要在子列表之前对列表进行排序。 \u0026quot; ","permalink":"http://itcodingman.github.io/rest_api_pagination_in_spring/","tags":["Pagination"],"title":"Spring中的REST分页"},{"categories":["Spring","Spring Boot"],"contents":"1. 概述 本教程将展示如何通过Java配置和*@PropertySource*在 Spring 中设置和使用属性。 我们还将看到属性在 Spring Boot 中是如何工作的。 2. 通过注解注册一个属性文件 Spring 3.1 还引入了新的*@PropertySource*注解作为向环境添加属性源的便捷机制。 我们可以将此注解与*@Configuration*注解结合使用： @Configuration @PropertySource(\u0026#34;classpath:foo.properties\u0026#34;) public class PropertiesWithJavaConfig { //... } 注册新属性文件的另一种非常有用的方法是使用占位符，它允许我们在运行时动态选择正确的文件： @PropertySource({ \u0026#34;classpath:persistence-${envTarget:mysql}.properties\u0026#34; }) ... 2.1。定义多个属性位置 根据Java 8 约定， @PropertySource注释是可重复的。因此，如果我们使用 Java 8 或更高版本，我们可以使用这个注解来定义多个属性位置： @PropertySource(\u0026#34;classpath:foo.properties\u0026#34;) @PropertySource(\u0026#34;classpath:bar.properties\u0026#34;) public class PropertiesWithJavaConfig { //... } 当然，*我们也可以使用@PropertySources注解，指定一个@PropertySource*数组。**这适用于任何受支持的 Java 版本，而不仅仅是 Java 8 或更高版本： @PropertySources({ @PropertySource(\u0026#34;classpath:foo.properties\u0026#34;), @PropertySource(\u0026#34;classpath:bar.properties\u0026#34;) }) public class PropertiesWithJavaConfig { //... } 在任何一种情况下，值得注意的是，如果发生属性名称冲突，最后读取的源优先。 3. 使用/注入属性 **使用@Value注释**注入属性很简单： @Value( \u0026#34;${jdbc.url}\u0026#34; ) private String jdbcUrl; 我们还可以为属性指定一个默认值： @Value( \u0026#34;${jdbc.url:aDefaultUrl}\u0026#34; ) private String jdbcUrl; Spring 3.1 中添加的新PropertySourcesPlaceholderConfigurer在 bean 定义属性值和*@Value*注释中解析 ${…} 占位符。 最后，我们可以使用Environment API 获取属性的值 ： @Autowired private Environment env; ... dataSource.setUrl(env.getProperty(\u0026#34;jdbc.url\u0026#34;)); 4. Spring Boot 的属性 在我们进入更高级的属性配置选项之前，让我们花一些时间来看看 Spring Boot 中的新属性支持。 一般来说，与标准 Spring 相比，这种新的支持涉及更少的配置，这当然是 Boot 的主要目标之一。 4.1 application.properties：默认属性文件 Boot 将其典型的约定优于配置方法应用于属性文件。这意味着我们可以简单地将application.properties文件放在我们的src/main/resources 目录中，它会被自动检测到。然后我们可以像往常一样从中注入任何加载的属性。 因此，通过使用此默认文件，我们不必显式注册PropertySource ，甚至不必提供属性文件的路径。 如果需要，我们还可以使用环境属性在运行时配置不同的文件： java -jar app.jar --spring.config.location=classpath:/another-location.properties 从Spring Boot 2.3开始，我们还可以为配置文件指定通配符位置。 例如，我们可以将 spring.config.location 属性设置为 config/*/： java -jar app.jar --spring.config.location=config/*/ 这样，Spring Boot 将在我们的 jar 文件之外查找与config/*/ 目录模式匹配的配置文件。当我们有多个配置属性来源时，这会派上用场。 从2.4.0版本开始，Spring Boot 支持使用多文档属性文件，类似于YAML的设计： baeldung.customProperty=defaultValue #--- baeldung.customProperty=overriddenValue 请注意，对于属性文件，三破折号表示法前面有一个注释字符 ( # )。 4.2. 环境特定的属性文件 如果我们需要针对不同的环境，Boot 中有一个内置机制。 我们可以简单的在src/main/resources目录下定义一个application-environment.properties文件，然后设置一个相同环境名的Spring profile。 例如，如果我们定义一个“暂存”环境，这意味着我们必须定义一个暂存配置文件，然后定义application-staging.properties。 此 env 文件将被加载，**并将优先于默认属性文件。**注意还是会加载默认文件，只是当发生属性冲突时，环境特定的属性文件优先。 4.3. 测试特定的属性文件 当我们的应用程序正在测试时，我们可能还需要使用不同的属性值。 Spring Boot 通过在测试运行期间查看我们的src/test/resources 目录来为我们处理这个问题。同样，默认属性仍然可以正常注入，但如果发生冲突，默认属性将被这些属性覆盖。 4.4. @TestPropertySource注解 如果我们需要对测试属性进行更精细的控制，那么我们可以使用*@TestPropertySource*注释。 这允许我们为特定的测试上下文设置测试属性，优先于默认属性源： @RunWith(SpringRunner.class) @TestPropertySource(\u0026#34;/foo.properties\u0026#34;) public class FilePropertyInjectionUnitTest { @Value(\u0026#34;${foo}\u0026#34;) private String foo; @Test public void whenFilePropertyProvided_thenProperlyInjected() { assertThat(foo).isEqualTo(\u0026#34;bar\u0026#34;); } } 如果我们不想使用文件，我们可以直接指定名称和值： @RunWith(SpringRunner.class) @TestPropertySource(properties = {\u0026#34;foo=bar\u0026#34;}) public class PropertyInjectionUnitTest { @Value(\u0026#34;${foo}\u0026#34;) private String foo; @Test public void whenPropertyProvided_thenProperlyInjected() { assertThat(foo).isEqualTo(\u0026#34;bar\u0026#34;); } } 我们也可以使用@SpringBootTest注解的properties参数来实现类似的效果： @RunWith(SpringRunner.class) @SpringBootTest( properties = {\u0026#34;foo=bar\u0026#34;}, classes = SpringBootPropertiesTestApplication.class) public class SpringBootPropertyInjectionIntegrationTest { @Value(\u0026#34;${foo}\u0026#34;) private String foo; @Test public void whenSpringBootPropertyProvided_thenProperlyInjected() { assertThat(foo).isEqualTo(\u0026#34;bar\u0026#34;); } } 4.5. 分层属性 如果我们有组合在一起的属性，我们可以使用*@ConfigurationProperties*注释，它将这些属性层次结构映射到 Java 对象图中。 让我们使用一些用于配置数据库连接的属性： database.url=jdbc:postgresql:/localhost:5432/instance database.username=foo database.password=bar 然后让我们使用注解将它们映射到数据库对象： @ConfigurationProperties(prefix = \u0026#34;database\u0026#34;) public class Database { String url; String username; String password; // standard getters and setters } Spring Boot 再次应用它的约定而不是配置方法，在属性名称及其对应字段之间自动映射。我们需要提供的只是属性前缀。 如果您想深入了解配置属性，请查看我们的深度文章。 4.6 替代方案：YAML 文件 Spring 还支持 YAML 文件。 所有相同的命名规则都适用于特定于测试的、特定于环境的和默认属性文件。唯一的区别是文件扩展名和对我们类路径上的SnakeYAML库的依赖。 YAML 特别适合分层属性存储；以下属性文件： database.url=jdbc:postgresql:/localhost:5432/instance database.username=foo database.password=bar secret: foo 与以下 YAML 文件同义： database: url: jdbc:postgresql:/localhost:5432/instance username: foo password: bar secret: foo 还值得一提的是 YAML 文件不支持*@PropertySource*注解，所以如果我们需要使用这个注解，它会限制我们使用属性文件。 另一个值得注意的点是，在 2.4.0 版本中，Spring Boot 改变了从多文档 YAML 文件加载属性的方式。以前，它们的添加顺序基于配置文件激活顺序。然而，在新版本中，框架遵循我们之前为*.properties*文件指出的相同排序规则；在文件中声明较低的属性将简单地覆盖那些较高的属性。 此外，在此版本中，无法再从特定于配置文件的文档中激活配置文件，从而使结果更加清晰和可预测。 4.7 导入其他配置文件 在 2.4.0 版本之前，Spring Boot 允许使用spring.config.location和 spring.config.additional-location 属性包含其他配置文件，但它们有一定的限制。例如，必须在启动应用程序之前定义它们（作为环境或系统属性，或使用命令行参数），因为它们在流程的早期使用。 在上述版本中，**我们可以使用application.properties或application.yml文件中的spring.config.import属性来轻松包含其他文件。**这个属性支持一些有趣的特性：  添加多个文件或目录 可以从类路径或外部目录加载文件 指示如果找不到文件或者它是否是可选文件，则启动过程是否应该失败 导入无扩展名文件  让我们看一个有效的例子： spring.config.import=classpath:additional-application.properties, classpath:additional-application[.yml], optional:file:./external.properties, classpath:additional-application-properties/ 注意：为了清楚起见，我们在这里使用换行符格式化了这个属性。 Spring 会将导入视为紧接在导入声明下方插入的新文档。 4.8 命令行参数的属性 除了使用文件，我们还可以直接在命令行中传递属性： java -jar app.jar --property=\u0026#34;value\u0026#34; 我们也可以通过系统属性来做到这一点，这些属性在*-jar*命令之前而不是之后提供： java -Dproperty.name=\u0026#34;value\u0026#34; -jar app.jar 4.9 来自环境变量的属性 Spring Boot 还将检测环境变量，将它们视为属性： export name=value java -jar app.jar 4.10 属性值的随机化 如果我们不想要确定性属性值，我们可以使用*RandomValuePropertySource* 来随机化属性值： random.number=${random.int} random.long=${random.long} random.uuid=${random.uuid} 4.11 其他类型的财产来源 Spring Boot 支持多种属性源，实现了经过深思熟虑的排序以允许明智的覆盖。值得参考官方文档，这超出了本文的范围。 5. 使用原始 Bean 进行配置 — PropertySourcesPlaceholderConfigurer 除了将属性获取到 Spring 中的便捷方法外，我们还可以手动定义和注册属性配置 bean。 使用PropertySourcesPlaceholderConfigurer可以让我们完全控制配置，但缺点是更冗长且大多数时候是不必要的。 让我们看看如何使用 Java 配置定义这个 bean： @Bean public static PropertySourcesPlaceholderConfigurer properties(){ PropertySourcesPlaceholderConfigurer pspc = new PropertySourcesPlaceholderConfigurer(); Resource[] resources = new ClassPathResource[ ] { new ClassPathResource( \u0026#34;foo.properties\u0026#34; ) }; pspc.setLocations( resources ); pspc.setIgnoreUnresolvablePlaceholders( true ); return pspc; } 6. 父子上下文中的属性 这个问题一次又一次地出现：当我们的Web 应用程序有父上下文和子上下文时会发生什么？父上下文可能有一些共同的核心功能和 bean，然后是一个（或多个）子上下文，可能包含特定于 servlet 的 bean。 在这种情况下，定义属性文件并将它们包含在这些上下文中的最佳方法是什么？以及如何最好地从 Spring 中检索这些属性？ 我们将给出一个简单的细分。 如果文件是在父上下文中定义的：   @Value在子上下文中工作：是   @Value在父上下文中工作：是   子上下文中的environment.getProperty：是   父上下文中的environment.getProperty：是   如果文件在子上下文中定义：   @Value在子上下文中工作：是   @Value在父上下文中工作：否   子上下文中的environment.getProperty：是   父上下文中的environment.getProperty：否 \u0026quot;   ","permalink":"http://itcodingman.github.io/properties_with_spring/","tags":["Spring Core Basics"],"title":"Spring 和 Spring Boot 的属性"},{"categories":["Spring"],"contents":"1. 配置必须是特定于环境的 配置必须是特定于环境的——这是不争的事实。如果不是这种情况，那么它就不是配置，我们只会在代码中硬编码值。 对于 Spring 应用程序，您可以使用多种解决方案——从简单的解决方案一直到超级灵活、高度复杂的替代方案。 一个更常见和直接的解决方案是灵活使用属性文件和Spring 提供的属性支持。 作为概念证明，出于本文的目的，我们将了解一种特定类型的属性——数据库配置。将一种类型的数据库配置用于生产，另一种用于测试，另一种用于开发环境是非常有意义的。 2.每个环境的.properties文件 让我们开始我们的概念证明——通过定义我们想要定位的环境：  开发 分期 生产  接下来 – 让我们创建 3 个属性文件 – 每个环境一个：  persistence-dev.properties persistence-staging.properties persistence-production.properties  在典型的 Maven 应用程序中，它们可以驻留在src/main/resources中，但是无论它们在哪里，它们都需要在部署应用程序时在类路径中可用。 将所有属性文件置于版本控制之下，使配置更加透明和可重复。这与将配置放在磁盘上的某个地方并简单地将 Spring 指向它们不同。 3. Spring 配置 在 Spring 中，我们将根据环境包含正确的文件： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\u0026#34;\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath*:*persistence-${envTarget}.properties\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 当然，Java 配置也可以做到这一点： @PropertySource({ \u0026#34;classpath:persistence-${envTarget:dev}.properties\u0026#34; }) 这种方法允许灵活地拥有多个*.properties*文件以用于特定的、集中的目的。例如——在我们的例子中，Spring持久性配置导入持久性属性——这非常有意义。安全配置将导入与安全相关的属性等。 4. 在每个环境中设置属性 最终的、可部署的war将包含所有属性文件——例如持久性，persistence-*.properties的三个文件。由于文件实际上命名不同，因此不必担心意外包含错误的文件。我们将设置envTarget变量，从而从多个现有文件中选择我们想要的实例。 envTarget变量可以在操作系统/环境中设置或作为 JVM 命令行的参数*：* -DenvTarget=dev 5. 测试和 Maven 对于需要启用持久性的集成测试——我们只需在 pom.xml 中设置envTarget属性： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;systemPropertyVariables\u0026gt; \u0026lt;envTarget\u0026gt;h2_test\u0026lt;/envTarget\u0026gt; \u0026lt;/systemPropertyVariables\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 对应的persistence-h2_test.properties文件可以放在src/test/resources中，这样它就只会用于测试，而不是在运行时不必要地包含和部署在 war 中。 6. 更进一步 如果需要，有几种方法可以在此解决方案中增加额外的灵活性。 一种这样的方法是对属性文件的名称使用更复杂的编码，不仅指定要使用它们的环境，还指定更多信息（例如持久性提供程序）。例如，我们可能会使用以下类型的属性：persistence-h2.properties、persistence-mysql.properties ，或者更具体的：persistence-dev_h2.properties、persistence-staging_mysql.properties、persistence-production_amazonRDS.properties。 这种命名约定的优势——它只是一个约定，因为整体方法没有任何变化——只是透明。现在仅通过查看名称就可以更清楚地了解配置的作用：  persistence-dev_h2.properties：开发环境的持久性提供程序是一个轻量级的内存 H2 数据库 persistence-staging_mysql.properties：暂存环境的持久性提供程序是一个 MySQL 实例 persistence-production_amazon_rds.propertie：生产环境的持久性提供程序是 Amazon RDS \u0026quot;  ","permalink":"http://itcodingman.github.io/project_configuration_with_spring/","tags":["Spring Core Basics"],"title":"使用 Spring 进行项目配置"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将介绍 IoC（控制反转）和 DI（依赖注入）的概念，并了解它们在 Spring 框架中是如何实现的。 2. 什么是控制反转？ 控制反转是软件工程中的一项原则，它将对象或程序部分的控制转移到容器或框架中。我们最常在面向对象编程的上下文中使用它。 与我们的自定义代码调用库的传统编程相比，IoC 使框架能够控制程序的流程并调用我们的自定义代码。为了实现这一点，框架使用内置附加行为的抽象。如果我们想添加自己的行为，我们需要扩展框架的类或插入我们自己的类。 这种架构的优点是：  将任务的执行与其实现分离 更容易在不同的实现之间切换 程序的更大模块化 通过隔离组件或模拟其依赖关系并允许组件通过合约进行通信，从而更轻松地测试程序  我们可以通过各种机制来实现控制反转，例如：策略设计模式、服务定位器模式、工厂模式和依赖注入（DI）。 接下来我们将研究 DI。 3. 什么是依赖注入？ 依赖注入是我们可以用来实现 IoC 的一种模式，其中被反转的控制是设置对象的依赖关系。 将对象与其他对象连接起来，或将对象“注入”到其他对象中，是由汇编程序完成的，而不是由对象本身完成的。 以下是我们如何在传统编程中创建对象依赖项： public class Store { private Item item; public Store() { item = new ItemImpl1(); } } 在上面的示例中，我们需要在Store类本身中实例化Item接口的实现。 通过使用 DI，我们可以重写示例，而无需指定我们想要的Item的实现： public class Store { private Item item; public Store(Item item) { this.item = item; } } 在接下来的部分中，我们将了解如何通过元数据提供Item的实现。 IoC 和 DI 都是简单的概念，但它们对我们构建系统的方式有着深远的影响，因此它们非常值得充分理解。 4. Spring IoC 容器 IoC 容器是实现 IoC 的框架的共同特征。 在 Spring 框架中，接口 ApplicationContext代表 IoC 容器。Spring 容器负责实例化、配置和组装称为bean的对象，以及管理它们的生命周期。 Spring 框架提供了ApplicationContext接口的几种实现：ClassPathXmlApplicationContext和FileSystemXmlApplicationContext用于独立应用程序，WebApplicationContext用于 Web 应用程序。 为了组装 bean，容器使用配置元数据，它可以是 XML 配置或注解的形式。 这是手动实例化容器的一种方法： ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;applicationContext.xml\u0026#34;); 要在上面的示例中设置项目属性，我们可以使用元数据。然后容器将读取此元数据并在运行时使用它来组装 bean。 Spring 中的依赖注入可以通过构造函数、setter 或字段来完成。 5. 基于构造函数的依赖注入 在基于构造函数的依赖注入的情况下，容器将调用带有参数的构造函数，每个参数代表我们要设置的依赖项。 Spring 主要按类型解析每个参数，然后是属性名称，以及用于消歧的索引。让我们使用注解查看 bean 的配置及其依赖项： @Configuration public class AppConfig { @Bean public Item item1() { return new ItemImpl1(); } @Bean public Store store() { return new Store(item1()); } } @Configuration注解表明该类是 bean 定义的来源。我们还可以将它添加到多个配置类中。 我们在方法上使用*@Bean*注解来定义一个 bean。如果我们不指定自定义名称，那么 bean 名称将默认为方法名称。 对于具有默认单例范围的 bean，Spring 首先检查 bean 的缓存实例是否已经存在，如果不存在则只创建一个新实例。如果我们使用原型作用域，容器会为每个方法调用返回一个新的 bean 实例。 创建 bean 配置的另一种方法是通过 XML 配置： \u0026lt;bean id=\u0026#34;item1\u0026#34; class=\u0026#34;com.codingman.store.ItemImpl1\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34;\u0026gt; \u0026lt;constructor-arg type=\u0026#34;ItemImpl1\u0026#34; index=\u0026#34;0\u0026#34; name=\u0026#34;item\u0026#34; ref=\u0026#34;item1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 6. 基于 Setter 的依赖注入 对于基于 setter 的 DI，容器会在调用无参数构造函数或无参数静态工厂方法实例化 bean 后调用我们类的 setter 方法。让我们使用注解创建这个配置： @Bean public Store store() { Store store = new Store(); store.setItem(item1()); return store; } 我们还可以将 XML 用于相同的 bean 配置： \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;item\u0026#34; ref=\u0026#34;item1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 我们可以为同一个 bean 组合基于构造函数和基于 setter 的注入类型。Spring 文档建议对强制依赖项使用基于构造函数的注入，对可选依赖项使用基于 setter 的注入。 7. 基于字段的依赖注入 对于基于字段的 DI，我们可以通过使用*@Autowired*注释标记依赖项来注入依赖项： public class Store { @Autowired private Item item; } 在构造Store对象时，如果没有构造函数或 setter 方法来注入Item bean，容器将使用反射将Item注入Store。 我们也可以使用XML 配置来实现这一点。 这种方法可能看起来更简单、更干净，但我们不建议使用它，因为它有一些缺点，例如：  该方法使用反射来注入依赖项，这比基于构造函数或基于 setter 的注入成本更高。 使用这种方法继续添加多个依赖项真的很容易。如果我们使用构造函数注入，具有多个参数会让我们认为该类做了不止一件事，这可能违反单一职责原则。  更多关于*@Autowired*注解的信息可以在Wiring In Spring文章中找到。 8. 自动装配依赖 Wiring允许 Spring 容器通过检查已定义的 bean 来自动解决协作 bean 之间的依赖关系。 使用 XML 配置自动装配 bean 有四种模式：  no：默认值——这意味着 bean 不使用自动装配，我们必须显式命名依赖项。 byName：自动装配是基于属性的名称完成的，因此 Spring 将查找与需要设置的属性名称相同的 bean。 byType：类似于byName自动装配，仅基于属性的类型。这意味着 Spring 将寻找具有相同类型属性的 bean 来设置。如果该类型的 bean 不止一个，框架会抛出异常。 constructor：自动装配是基于构造函数参数完成的，这意味着 Spring 将寻找与构造函数参数具有相同类型的 bean。  例如，让我们将上面定义的item1 bean 按类型自动装配到store bean 中： @Bean(autowire = Autowire.BY_TYPE) public class Store { private Item item; public setItem(Item item){ this.item = item; } } 我们还可以使用*@Autowired*注解注入 bean，以便按类型自动装配： public class Store { @Autowired private Item item; } 如果有多个相同类型的 bean，我们可以使用*@Qualifier*注解按名称引用一个 bean： public class Store { @Autowired @Qualifier(\u0026#34;item1\u0026#34;) private Item item; } 现在让我们通过 XML 配置按类型自动装配 bean： \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34; autowire=\u0026#34;byType\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; 接下来，让我们通过 XML将一个名为item的 bean 按名称注入到store bean 的**item属性中： \u0026lt;bean id=\u0026#34;item\u0026#34; class=\u0026#34;com.codingman.store.ItemImpl1\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34; autowire=\u0026#34;byName\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; 我们还可以通过构造函数参数或设置器显式定义依赖项来覆盖自动装配。 9. 延迟初始化 Bean 默认情况下，容器在初始化期间创建和配置所有单例 bean。为了避免这种情况，我们可以在 bean 配置中使用值为true的延迟初始化属性： \u0026lt;bean id=\u0026#34;item1\u0026#34; class=\u0026#34;com.codingman.store.ItemImpl1\u0026#34; lazy-init=\u0026#34;true\u0026#34; /\u0026gt; 因此，item1 bean 只会在第一次被请求时被初始化，而不是在启动时被初始化。这样做的好处是更快的初始化时间，但代价是在请求 bean 之前我们不会发现任何配置错误，这可能是应用程序已经运行后的几个小时甚至几天。 \u0026quot; ","permalink":"http://itcodingman.github.io/inversion_control_and_dependency_injection_in_spring/","tags":["Spring Core Basics","Spring DI"],"title":"Spring 控制反转和依赖注入简介"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将看一个实用的、以代码为中心的 Spring Batch 介绍。Spring Batch 是一个处理框架，专为作业的稳健执行而设计。 它的当前版本 4.3 支持 Spring 5 和 Java 8。它还适应 JSR-352，这是用于批处理的新 Java 规范。 以下是该框架的一些有趣且实用的用例。 2. 工作流程基础 Spring Batch 遵循传统的批处理架构，其中作业存储库执行调度和与作业交互的工作。 一个作业可以有多个步骤。每个步骤通常遵循读取数据、处理数据和写入数据的顺序。 当然，这里的框架将为我们完成大部分繁重的工作——尤其是在处理作业的低级持久性工作时——使用sqlite作为作业存储库。 2.1 示例用例 我们将在这里处理的简单用例是将一些金融交易数据从 CSV 迁移到 XML。 输入文件的结构非常简单。 它包含每行的交易，由用户名、用户 ID、交易日期和金额组成： username, userid, transaction_date, transaction_amount ann, 1234, 31/10/2015, 10000 bob, 2134, 3/12/2015, 12321 robin, 3134, 2/02/2015, 23411 3. Maven POM 本项目需要的依赖有spring core、spring batch和sqlite jdbc connector： \u0026lt;!-- SQLite database driver --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sqlite-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-oxm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.batch\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-batch-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. Spring批处理配置 我们要做的第一件事是使用 XML 配置 Spring Batch： \u0026lt;!-- connect to SQLite database --\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;org.sqlite.JDBC\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:sqlite:xxx.db\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- create job-meta tables automatically --\u0026gt; \u0026lt;jdbc:initialize-database data-source=\u0026#34;dataSource\u0026#34;\u0026gt; \u0026lt;jdbc:script location=\u0026#34;org/springframework/batch/core/schema-drop-sqlite.sql\u0026#34; /\u0026gt; \u0026lt;jdbc:script location=\u0026#34;org/springframework/batch/core/schema-sqlite.sql\u0026#34; /\u0026gt; \u0026lt;/jdbc:initialize-database\u0026gt; \u0026lt;!-- stored job-meta in memory --\u0026gt; \u0026lt;!-- \u0026lt;bean id=\u0026#34;jobRepository\u0026#34; class=\u0026#34;org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; --\u0026gt; \u0026lt;!-- stored job-meta in database --\u0026gt; \u0026lt;bean id=\u0026#34;jobRepository\u0026#34; class=\u0026#34;org.springframework.batch.core.repository.support.JobRepositoryFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseType\u0026#34; value=\u0026#34;sqlite\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class= \u0026#34;org.springframework.batch.support.transaction.ResourcelessTransactionManager\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;jobLauncher\u0026#34; class=\u0026#34;org.springframework.batch.core.launch.support.SimpleJobLauncher\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jobRepository\u0026#34; ref=\u0026#34;jobRepository\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 当然，也可以使用 Java 配置： @Configuration @EnableBatchProcessing public class SpringConfig { @Value(\u0026#34;org/springframework/batch/core/schema-drop-sqlite.sql\u0026#34;) private Resource dropReopsitoryTables; @Value(\u0026#34;org/springframework/batch/core/schema-sqlite.sql\u0026#34;) private Resource dataReopsitorySchema; @Bean public DataSource dataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;org.sqlite.JDBC\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:sqlite:xxx.db\u0026#34;); return dataSource; } @Bean public DataSourceInitializer dataSourceInitializer(DataSource dataSource) throws MalformedURLException { ResourceDatabasePopulator databasePopulator = new ResourceDatabasePopulator(); databasePopulator.addScript(dropReopsitoryTables); databasePopulator.addScript(dataReopsitorySchema); databasePopulator.setIgnoreFailedDrops(true); DataSourceInitializer initializer = new DataSourceInitializer(); initializer.setDataSource(dataSource); initializer.setDatabasePopulator(databasePopulator); return initializer; } private JobRepository getJobRepository() throws Exception { JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean(); factory.setDataSource(dataSource()); factory.setTransactionManager(getTransactionManager()); factory.afterPropertiesSet(); return (JobRepository) factory.getObject(); } private PlatformTransactionManager getTransactionManager() { return new ResourcelessTransactionManager(); } public JobLauncher getJobLauncher() throws Exception { SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); jobLauncher.setJobRepository(getJobRepository()); jobLauncher.afterPropertiesSet(); return jobLauncher; } } 5. Spring Batch 作业配置 现在让我们为 CSV 到 XML 工作编写工作描述： \u0026lt;import resource=\u0026#34;spring.xml\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;record\u0026#34; class=\u0026#34;com.codingman.spring_batch_intro.model.Transaction\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;itemReader\u0026#34; class=\u0026#34;org.springframework.batch.item.file.FlatFileItemReader\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resource\u0026#34; value=\u0026#34;input/record.csv\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;lineMapper\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.batch.item.file.mapping.DefaultLineMapper\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;lineTokenizer\u0026#34;\u0026gt; \u0026lt;bean class= \u0026#34;org.springframework.batch.item.file.transform.DelimitedLineTokenizer\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;names\u0026#34; value=\u0026#34;username,userid,transactiondate,amount\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;fieldSetMapper\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;com.codingman.spring_batch_intro.service.RecordFieldSetMapper\u0026#34; /\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;itemProcessor\u0026#34; class=\u0026#34;com.codingman.service.CustomItemProcessor\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;itemWriter\u0026#34; class=\u0026#34;org.springframework.batch.item.xml.StaxEventItemWriter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resource\u0026#34; value=\u0026#34;file:xml/output.xml\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;marshaller\u0026#34; ref=\u0026#34;recordMarshaller\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;rootTagName\u0026#34; value=\u0026#34;transactionRecord\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;recordMarshaller\u0026#34; class=\u0026#34;org.springframework.oxm.jaxb.Jaxb2Marshaller\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;classesToBeBound\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;com.codingman.spring_batch_intro.model.Transaction\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;batch:job id=\u0026#34;firstBatchJob\u0026#34;\u0026gt; \u0026lt;batch:step id=\u0026#34;step1\u0026#34;\u0026gt; \u0026lt;batch:tasklet\u0026gt; \u0026lt;batch:chunk reader=\u0026#34;itemReader\u0026#34; writer=\u0026#34;itemWriter\u0026#34; processor=\u0026#34;itemProcessor\u0026#34; commit-interval=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;/batch:chunk\u0026gt; \u0026lt;/batch:tasklet\u0026gt; \u0026lt;/batch:step\u0026gt; \u0026lt;/batch:job\u0026gt; 这是类似的基于 Java 的作业配置： public class SpringBatchConfig { @Autowired private JobBuilderFactory jobs; @Autowired private StepBuilderFactory steps; @Value(\u0026#34;input/record.csv\u0026#34;) private Resource inputCsv; @Value(\u0026#34;file:xml/output.xml\u0026#34;) private Resource outputXml; @Bean public ItemReader\u0026lt;Transaction\u0026gt; itemReader() throws UnexpectedInputException, ParseException { FlatFileItemReader\u0026lt;Transaction\u0026gt; reader = new FlatFileItemReader\u0026lt;Transaction\u0026gt;(); DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); String[] tokens = { \u0026#34;username\u0026#34;, \u0026#34;userid\u0026#34;, \u0026#34;transactiondate\u0026#34;, \u0026#34;amount\u0026#34; }; tokenizer.setNames(tokens); reader.setResource(inputCsv); DefaultLineMapper\u0026lt;Transaction\u0026gt; lineMapper = new DefaultLineMapper\u0026lt;Transaction\u0026gt;(); lineMapper.setLineTokenizer(tokenizer); lineMapper.setFieldSetMapper(new RecordFieldSetMapper()); reader.setLineMapper(lineMapper); return reader; } @Bean public ItemProcessor\u0026lt;Transaction, Transaction\u0026gt; itemProcessor() { return new CustomItemProcessor(); } @Bean public ItemWriter\u0026lt;Transaction\u0026gt; itemWriter(Marshaller marshaller) throws MalformedURLException { StaxEventItemWriter\u0026lt;Transaction\u0026gt; itemWriter = new StaxEventItemWriter\u0026lt;Transaction\u0026gt;(); itemWriter.setMarshaller(marshaller); itemWriter.setRootTagName(\u0026#34;transactionRecord\u0026#34;); itemWriter.setResource(outputXml); return itemWriter; } @Bean public Marshaller marshaller() { Jaxb2Marshaller marshaller = new Jaxb2Marshaller(); marshaller.setClassesToBeBound(new Class[] { Transaction.class }); return marshaller; } @Bean protected Step step1(ItemReader\u0026lt;Transaction\u0026gt; reader, ItemProcessor\u0026lt;Transaction, Transaction\u0026gt; processor, ItemWriter\u0026lt;Transaction\u0026gt; writer) { return steps.get(\u0026#34;step1\u0026#34;).\u0026lt;Transaction, Transaction\u0026gt; chunk(10) .reader(reader).processor(processor).writer(writer).build(); } @Bean(name = \u0026#34;firstBatchJob\u0026#34;) public Job job(@Qualifier(\u0026#34;step1\u0026#34;) Step step1) { return jobs.get(\u0026#34;firstBatchJob\u0026#34;).start(step1).build(); } } 现在我们有了整个配置，让我们分解它并开始讨论它。 5.1 使用ItemReader读取数据并创建对象 首先，我们配置了cvsFileItemReader ，它将从record.csv中读取数据并将其转换为Transaction对象： @SuppressWarnings(\u0026#34;restriction\u0026#34;) @XmlRootElement(name = \u0026#34;transactionRecord\u0026#34;) public class Transaction { private String username; private int userId; private LocalDateTime transactionDate; private double amount; /* getters and setters for the attributes */ @Override public String toString() { return \u0026#34;Transaction [username=\u0026#34; + username + \u0026#34;, userId=\u0026#34; + userId + \u0026#34;, transactionDate=\u0026#34; + transactionDate + \u0026#34;, amount=\u0026#34; + amount + \u0026#34;]\u0026#34;; } } 为此，它使用自定义映射器： public class RecordFieldSetMapper implements FieldSetMapper\u0026lt;Transaction\u0026gt; { public Transaction mapFieldSet(FieldSet fieldSet) throws BindException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd\u0026#34;); Transaction transaction = new Transaction(); transaction.setUsername(fieldSet.readString(\u0026#34;username\u0026#34;)); transaction.setUserId(fieldSet.readInt(1)); transaction.setAmount(fieldSet.readDouble(3)); String dateString = fieldSet.readString(2); transaction.setTransactionDate(LocalDate.parse(dateString, formatter).atStartOfDay()); return transaction; } } 5.2 使用ItemProcessor处理数据 我们创建了自己的项目处理器CustomItemProcessor。这不会处理与事务对象相关的任何内容。 它所做的只是将来自 reader 的原始对象传递给 writer： public class CustomItemProcessor implements ItemProcessor\u0026lt;Transaction, Transaction\u0026gt; { public Transaction process(Transaction item) { return item; } } 5.3 使用ItemWriter将对象写入 FS 最后，我们将此事务存储到位于xml/output.xml的 XML 文件中： \u0026lt;bean id=\u0026#34;itemWriter\u0026#34; class=\u0026#34;org.springframework.batch.item.xml.StaxEventItemWriter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resource\u0026#34; value=\u0026#34;file:xml/output.xml\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;marshaller\u0026#34; ref=\u0026#34;recordMarshaller\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;rootTagName\u0026#34; value=\u0026#34;transactionRecord\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 5.4 配置批处理作业 因此，我们所要做的就是使用batch:job语法将这些点与作业连接起来。 注意提交间隔。这是在将批次提交给itemWriter之前要保存在内存中的事务数。 它将在内存中保存事务直到该点（或直到遇到输入数据的结尾）： \u0026lt;batch:job id=\u0026#34;firstBatchJob\u0026#34;\u0026gt; \u0026lt;batch:step id=\u0026#34;step1\u0026#34;\u0026gt; \u0026lt;batch:tasklet\u0026gt; \u0026lt;batch:chunk reader=\u0026#34;itemReader\u0026#34; writer=\u0026#34;itemWriter\u0026#34; processor=\u0026#34;itemProcessor\u0026#34; commit-interval=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;/batch:chunk\u0026gt; \u0026lt;/batch:tasklet\u0026gt; \u0026lt;/batch:step\u0026gt; \u0026lt;/batch:job\u0026gt; 5.5 运行批处理作业 现在让我们设置并运行所有内容： public class App { public static void main(String[] args) { // Spring Java config  AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.register(SpringConfig.class); context.register(SpringBatchConfig.class); context.refresh(); JobLauncher jobLauncher = (JobLauncher) context.getBean(\u0026#34;jobLauncher\u0026#34;); Job job = (Job) context.getBean(\u0026#34;firstBatchJob\u0026#34;); System.out.println(\u0026#34;Starting the batch job\u0026#34;); try { JobExecution execution = jobLauncher.run(job, new JobParameters()); System.out.println(\u0026#34;Job Status : \u0026#34; + execution.getStatus()); System.out.println(\u0026#34;Job completed\u0026#34;); } catch (Exception e) { e.printStackTrace(); System.out.println(\u0026#34;Job failed\u0026#34;); } } } \u0026quot; ","permalink":"http://itcodingman.github.io/introduction_to_spring_batch/","tags":["Spring Batch"],"title":"Spring Batch 简介"},{"categories":["Spring Persistence"],"contents":"1. 概述 在本文中，我们将讨论如何使用 Spring 引导 Hibernate 5，同时使用 Java 和 XML 配置。 文章 Spring Boot with Hibernate 描述了如何在 Spring Boot 中使用 Hibernate。 2. Spring集成 使用本机 Hibernate API引导SessionFactory有点复杂，需要我们编写好几行代码（请查看官方文档）。 幸运的是，Spring支持引导SessionFactory因此我们只需要几行 Java 代码或 XML 配置。 3. Maven依赖 让我们首先将必要的依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.4.2.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-orm 模块提供了 Spring 与 Hibernate 的集成： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-orm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 为简单起见，我们将使用H2作为我们的数据库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.197\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最后，我们将使用Tomcat JDBC 连接池，它比Spring 提供的DriverManagerDataSource更适合生产目的： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tomcat\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tomcat-dbcp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. 配置 如前所述，Spring 支持我们引导 Hibernate SessionFactory。 我们所要做的就是定义一些 bean 以及一些参数。 使用 Spring，我们为这些配置提供了两种选择，一种基于 Java 的方式，一种基于 XML 的方式。 4.1 使用 Java 配置 对于将 Hibernate 5 与 Spring 一起使用，自Hibernate 4以来几乎没有变化：我们必须使用包org.springframework.orm.hibernate5中的LocalSessionFactoryBean而不是org.springframework.orm.hibernate4。 与之前的 Hibernate 4 一样，我们必须为LocalSessionFactoryBean、DataSource和PlatformTransactionManager定义 bean ，以及一些 Hibernate 特定的属性。 让我们创建HibernateConfig类来使用 Spring 配置 Hibernate 5： @Configuration @EnableTransactionManagement public class HibernateConf { @Bean public LocalSessionFactoryBean sessionFactory() { LocalSessionFactoryBean sessionFactory = new LocalSessionFactoryBean(); sessionFactory.setDataSource(dataSource()); sessionFactory.setPackagesToScan( {\u0026#34;com.codingman.demo.model\u0026#34; }); sessionFactory.setHibernateProperties(hibernateProperties()); return sessionFactory; } @Bean public DataSource dataSource() { BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\u0026#34;org.h2.Driver\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:h2:mem:db;DB_CLOSE_DELAY=-1\u0026#34;); dataSource.setUsername(\u0026#34;sa\u0026#34;); dataSource.setPassword(\u0026#34;sa\u0026#34;); return dataSource; } @Bean public PlatformTransactionManager hibernateTransactionManager() { HibernateTransactionManager transactionManager = new HibernateTransactionManager(); transactionManager.setSessionFactory(sessionFactory().getObject()); return transactionManager; } private final Properties hibernateProperties() { Properties hibernateProperties = new Properties(); hibernateProperties.setProperty( \u0026#34;hibernate.hbm2ddl.auto\u0026#34;, \u0026#34;create-drop\u0026#34;); hibernateProperties.setProperty( \u0026#34;hibernate.dialect\u0026#34;, \u0026#34;org.hibernate.dialect.H2Dialect\u0026#34;); return hibernateProperties; } } 4.2 使用 XML 配置 作为次要选项，我们还可以使用基于 XML 的配置来配置 Hibernate 5： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;sessionFactory\u0026#34; class=\u0026#34;org.springframework.orm.hibernate5.LocalSessionFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;com.codingman.demo.model\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernateProperties\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.hbm2ddl.auto\u0026#34;\u0026gt; create-drop \u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.dialect\u0026#34;\u0026gt; org.hibernate.dialect.H2Dialect \u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.apache.tomcat.dbcp.dbcp2.BasicDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:h2:mem:db;DB_CLOSE_DELAY=-1\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;sa\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;sa\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;txManager\u0026#34; class=\u0026#34;org.springframework.orm.hibernate5.HibernateTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;sessionFactory\u0026#34; ref=\u0026#34;sessionFactory\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 正如我们很容易看到的那样，我们定义的 bean 和参数与前面基于 Java 的配置完全相同。 要将 XML 引导到 Spring 上下文中，如果应用程序配置了 Java 配置，我们可以使用一个简单的 Java 配置文件： @Configuration @EnableTransactionManagement @ImportResource({\u0026#34;classpath:hibernate5Configuration.xml\u0026#34;}) public class HibernateXMLConf { // } 或者，如果整体配置是纯 XML，我们可以简单地将 XML 文件提供给 Spring 上下文。 5. 用法 至此，Hibernate 5 完全配置了 Spring，我们可以在需要时直接注入原始的 Hibernate SessionFactory ： public abstract class BarHibernateDAO { @Autowired private SessionFactory sessionFactory; // ... } 6. 支持的数据库 不幸的是，Hibernate 项目并没有完全提供支持数据库的官方列表。 话虽如此，很容易看出是否支持特定的数据库类型，我们可以查看支持的方言列表。 \u0026quot; ","permalink":"http://itcodingman.github.io/hibernate_5_spring/","tags":["Hibernate"],"title":"在 Spring 中使用 Hibernate 5"},{"categories":["REST","Spring"],"contents":"1. 概述 本教程将说明**如何使用 Spring 为 REST API 实现异常处理。**我们还将获得一些历史概览，并查看不同版本引入了哪些新选项。 *在 Spring 3.2 之前，在 Spring MVC 应用程序中处理异常的两种主要方法是HandlerExceptionResolver或@ExceptionHandler*注解。**两者都有一些明显的缺点。 从 3.2 开始，我们有了@ControllerAdvice*注解*来解决前两个解决方案的局限性，并在整个应用程序中促进统一的异常处理。 现在Spring 5 引入了ResponseStatusException 类——一种在我们的 REST API 中进行基本错误处理的快速方法。 所有这些都有一个共同点：它们很好地处理了**关注点的分离。**该应用程序可以正常抛出异常以指示某种失败，然后将单独处理。 最后，我们将看到 Spring Boot 带来了什么，以及我们如何配置它以满足我们的需求。 2. 方案一：Controller级@ExceptionHandler 第一个解决方案适用于*@Controller级别。我们将定义一个方法来处理异常并使用@ExceptionHandler* 对其进行注释： public class FooController{ //...  @ExceptionHandler({ CustomException1.class, CustomException2.class }) public void handleException() { //  } } 这种方法有一个主要缺点：**@ExceptionHandler注释方法仅对特定的 Controller 有效，**而不是对整个应用程序全局有效。当然，将它添加到每个控制器使其不太适合一般的异常处理机制。 我们可以通过让所有控制器扩展一个基本控制器类来解决这个限制。 然而，这种解决方案对于应用程序来说可能是个问题，无论出于何种原因，这是不可能的。例如，控制器可能已经从另一个基类扩展而来，该基类可能在另一个 jar 中或不可直接修改，或者它们本身可能不可直接修改。 接下来，我们将研究另一种解决异常处理问题的方法——一种全局的并且不包括对现有工件（例如控制器）的任何更改。 3. 解决方案2：HandlerExceptionResolver 第二种解决方案是定义一个HandlerExceptionResolver。这将解决应用程序抛出的任何异常。它还将允许我们在 REST API 中实现统一的异常处理机制。 在使用自定义解析器之前，让我们回顾一下现有的实现。 3.1 ExceptionHandlerExceptionResolver 这个解析器是在 Spring 3.1 中引入的，默认情况下在DispatcherServlet中启用。这实际上是前面介绍的*@ExceptionHandler*机制如何工作的核心组件。 3.2. DefaultHandlerExceptionResolver 这个解析器是在 Spring 3.0 中引入的，默认情况下它在DispatcherServlet中启用。 它用于解决相应的HTTP 状态代码的标准 Spring 异常，即客户端错误4xx和服务器错误5xx状态代码。这是它处理的 Spring 异常的完整列表以及它们如何映射到状态代码。 虽然它确实正确设置了响应的状态代码，但一个**限制是它没有为响应的正文设置任何内容。**对于 REST API——状态码实际上不足以呈现给客户端——响应也必须有一个主体，以允许应用程序提供有关失败的附加信息。 这可以通过ModelAndView配置视图分辨率和渲染错误内容来解决，但该解决方案显然不是最优的。这就是为什么 Spring 3.2 引入了一个更好的选项，我们将在后面的部分讨论。 3.3. ResponseStatusExceptionResolver 这个解析器也在 Spring 3.0 中引入，默认情况下在DispatcherServlet中启用。 它的主要职责是使用自定义异常上可用的*@ResponseStatus*注释并将这些异常映射到 HTTP 状态代码。 这样的自定义异常可能如下所示： @ResponseStatus(value = HttpStatus.NOT_FOUND) public class MyResourceNotFoundException extends RuntimeException { public MyResourceNotFoundException() { super(); } public MyResourceNotFoundException(String message, Throwable cause) { super(message, cause); } public MyResourceNotFoundException(String message) { super(message); } public MyResourceNotFoundException(Throwable cause) { super(cause); } } 与DefaultHandlerExceptionResolver相同，此解析器在处理响应主体的方式上受到限制——它确实将状态代码映射到响应上，但主体仍然为空。 3.4 自定义HandlerExceptionResolver DefaultHandlerExceptionResolver和ResponseStatusExceptionResolver的组合在为 Spring RESTful 服务提供良好的错误处理机制方面大有帮助。如前所述，缺点是无法控制响应的主体。 理想情况下，我们希望能够输出 JSON 或 XML，具体取决于客户端要求的格式（通过Accept标头）。 仅此一项就证明了创建一个新的自定义异常解析器是合理的： @Component public class RestResponseStatusExceptionResolver extends AbstractHandlerExceptionResolver { @Override protected ModelAndView doResolveException( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { try { if (ex instanceof IllegalArgumentException) { return handleIllegalArgument( (IllegalArgumentException) ex, response, handler); } ... } catch (Exception handlerException) { logger.warn(\u0026#34;Handling of [\u0026#34; + ex.getClass().getName() + \u0026#34;] resulted in Exception\u0026#34;, handlerException); } return null; } private ModelAndView handleIllegalArgument(IllegalArgumentException ex, HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_CONFLICT); String accept = request.getHeader(HttpHeaders.ACCEPT); ... return new ModelAndView(); } } 这里要注意的一个细节是我们可以访问请求本身，因此我们可以考虑客户端发送的Accept标头的值。 例如，如果客户端请求application/json，那么在出现错误情况的情况下，我们希望确保返回一个使用application/json编码的响应正文。 另一个重要的实现细节是我们返回一个 ModelAndView——这是响应的主体，它允许我们在上面设置任何必要的东西。 这种方法是一种一致且易于配置的机制，用于 Spring REST 服务的错误处理。 但是，它确实有局限性：它与低级HtttpServletResponse 交互并适合使用ModelAndView的旧 MVC 模型，因此仍有改进的空间。 4. 解决方案3：@ControllerAdvice Spring 3.2通过@ControllerAdvice注释支持全局@ExceptionHandler。 这启用了一种脱离旧 MVC 模型并利用ResponseEntity以及@ExceptionHandler的类型安全性和灵活性的机制： @ControllerAdvice public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler(value = { IllegalArgumentException.class, IllegalStateException.class }) protected ResponseEntity\u0026lt;Object\u0026gt; handleConflict( RuntimeException ex, WebRequest request) { String bodyOfResponse = \u0026#34;This should be application specific\u0026#34;; return handleExceptionInternal(ex, bodyOfResponse, new HttpHeaders(), HttpStatus.CONFLICT, request); } } @ControllerAdvice注解允许我们将之前的多个分散的@ExceptionHandler整合到一个单一的全局错误处理组件中。 实际的机制非常简单，但也非常灵活：  它使我们可以完全控制响应的主体以及状态代码。 它提供了多个异常到同一方法的映射，以便一起处理。 它充分利用了较新的 RESTful ResposeEntity响应。  这里要记住的一件事是将使用@ExceptionHandler声明的异常与用作方法参数的异常相匹配。 如果这些不匹配，编译器不会抱怨——没有理由应该抱怨——Spring 也不会抱怨。 但是，当在运行时实际抛出异常时，异常解析机制将失败，并显示： java.lang.IllegalStateException: No suitable resolver for argument [0] [type=...] HandlerMethod details: ... 5. 解决方案4：ResponseStatusException（Spring 5及以上） Spring 5 引入了ResponseStatusException类。 我们可以创建它的一个实例，提供一个HttpStatus以及一个可选的reason和cause： @GetMapping(value = \u0026#34;/{id}\u0026#34;) public Foo findById(@PathVariable(\u0026#34;id\u0026#34;) Long id, HttpServletResponse response) { try { Foo resourceById = RestPreconditions.checkFound(service.findOne(id)); eventPublisher.publishEvent(new SingleResourceRetrievedEvent(this, response)); return resourceById; } catch (MyResourceNotFoundException exc) { throw new ResponseStatusException( HttpStatus.NOT_FOUND, \u0026#34;Foo Not Found\u0026#34;, exc); } } 使用ResponseStatusException有什么好处？  非常适合原型设计：我们可以非常快速地实施基本解决方案。 一种类型，多种状态码：一种异常类型可能导致多种不同的响应。与@ExceptionHandler相比，这减少了紧密耦合。 我们不必创建尽可能多的自定义异常类。 我们可以更好地控制异常处理，因为可以通过编程方式创建异常。  那么权衡呢？  没有统一的异常处理方式：与提供全局方法的@ControllerAdvice相比，执行一些应用程序范围的约定更加困难。 代码复制：我们可能会发现自己在多个控制器中复制代码。  我们还应该注意到，可以在一个应用程序中组合不同的方法。 例如，我们可以 全局 实现@ControllerAdvice ，也可以在本地实现ResponseStatusException 。 但是，我们需要小心：如果可以以多种方式处理同一个异常，我们可能会注意到一些令人惊讶的行为。一种可能的约定是始终以一种方式处理一种特定类型的异常。 有关更多详细信息和更多示例，请参阅我们的ResponseStatusException教程。 6. 处理Spring Security中的访问被拒绝 当经过身份验证的用户尝试访问他没有足够权限访问的资源时，会发生访问被拒绝。 6.1 REST 和方法级安全性 最后，让我们看看如何处理由方法级安全注解（@PreAuthorize、@PostAuthorize和@Secure ）引发的 Access Denied 异常。 当然，我们也会使用前面讨论过的全局异常处理机制来处理AccessDeniedException： @ControllerAdvice public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler({ AccessDeniedException.class }) public ResponseEntity\u0026lt;Object\u0026gt; handleAccessDeniedException( Exception ex, WebRequest request) { return new ResponseEntity\u0026lt;Object\u0026gt;( \u0026#34;Access denied message here\u0026#34;, new HttpHeaders(), HttpStatus.FORBIDDEN); } ... } 7. Spring Boot 支持 Spring Boot 提供了一个 ErrorController实现以合理的方式处理错误。 简而言之，它为浏览器提供后备错误页面（又名 Whitelabel 错误页面），并为 RESTful、非 HTML 请求提供 JSON 响应： { \u0026#34;timestamp\u0026#34;: \u0026#34;2019-01-17T16:12:45.977+0000\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Error processing the request!\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/my-endpoint-with-exceptions\u0026#34; } 像往常一样，Spring Boot 允许使用属性配置这些功能：  server.error.whitelabel.enabled：可用于禁用 Whitelabel 错误页面并依赖 servlet 容器提供 HTML 错误消息 server.error.include-stacktrace：始终 具有值；在 HTML 和 JSON 默认响应中包含堆栈跟踪 server.error.include-message： 从 2.3 版本开始，Spring Boot 在响应中隐藏了message字段，以避免泄露敏感信息；我们可以使用这个属性和一个 always 值来启用它  除了这些属性之外，我们还可以为 /error 提供我们自己的视图解析器映射，覆盖 Whitelabel 页面。 我们还可以通过在上下文中包含一个ErrorAttributes bean 来自定义我们想要在响应中显示的属性 。我们可以扩展 Spring Boot 提供的 DefaultErrorAttributes类以使事情变得更简单： @Component public class MyCustomErrorAttributes extends DefaultErrorAttributes { @Override public Map\u0026lt;String, Object\u0026gt; getErrorAttributes( WebRequest webRequest, ErrorAttributeOptions options) { Map\u0026lt;String, Object\u0026gt; errorAttributes = super.getErrorAttributes(webRequest, options); errorAttributes.put(\u0026#34;locale\u0026#34;, webRequest.getLocale() .toString()); errorAttributes.remove(\u0026#34;error\u0026#34;); //...  return errorAttributes; } } 如果我们想进一步定义（或覆盖）应用程序将如何处理特定内容类型的错误，我们可以注册一个 ErrorController bean。 同样，我们可以利用 Spring Boot 提供的默认 BasicErrorController 来帮助我们。 例如，假设我们想要自定义我们的应用程序如何处理在 XML 端点中触发的错误。我们所要做的就是使用 @RequestMapping定义一个公共方法，并声明它产生application/xml媒体类型： @Component public class MyErrorController extends BasicErrorController { public MyErrorController( ErrorAttributes errorAttributes, ServerProperties serverProperties) { super(errorAttributes, serverProperties.getError()); } @RequestMapping(produces = MediaType.APPLICATION_XML_VALUE) public ResponseEntity\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; xmlError(HttpServletRequest request) { // ...  } } 注意：这里我们仍然依赖于server.error.我们可能已经在项目中定义的引导属性，这些属性绑定到ServerProperties bean。 \u0026quot; ","permalink":"http://itcodingman.github.io/exception_handling_for_rest_with_spring/","tags":[],"title":"使用 Spring REST 错误处理"},{"categories":["REST","Spring"],"contents":"1. 概述 在本教程中，我们将处理需要在 Spring 应用程序的内部实体和发布回客户端的外部**DTO （数据传输对象）之间发生的转换。** 2. 模型映射器 让我们首先介绍我们将用于执行此实体-DTO 转换的主库*ModelMapper*。 我们将在pom.xml中需要这个依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.modelmapper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;modelmapper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查此库是否有更新版本，请转到此处。 然后我们将在 Spring 配置中定义ModelMapper bean： @Bean public ModelMapper modelMapper() { return new ModelMapper(); } 3. DTO 接下来我们介绍一下这个双面问题的DTO端，Post DTO： public class PostDto { private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm\u0026#34;); private Long id; private String title; private String url; private String date; private UserDto user; public Date getSubmissionDateConverted(String timezone) throws ParseException { dateFormat.setTimeZone(TimeZone.getTimeZone(timezone)); return dateFormat.parse(this.date); } public void setSubmissionDate(Date date, String timezone) { dateFormat.setTimeZone(TimeZone.getTimeZone(timezone)); this.date = dateFormat.format(date); } // standard getters and setters } 请注意，两个自定义日期相关方法处理客户端和服务器之间来回的日期转换：  getSubmissionDateConverted()方法将日期字符串转换为服务器时区中的日期，以在持久的Post实体中使用它 setSubmissionDate()方法是在当前用户时区将 DTO 的日期设置为Post的日期  4. 服务层 现在让我们看一下服务级别操作，它显然适用于实体（而不是 DTO）： public List\u0026lt;Post\u0026gt; getPostsList( int page, int size, String sortDir, String sort) { PageRequest pageReq = PageRequest.of(page, size, Sort.Direction.fromString(sortDir), sort); Page\u0026lt;Post\u0026gt; posts = postRepository .findByUser(userService.getCurrentUser(), pageReq); return posts.getContent(); } 接下来我们将看一下服务之上的层，即控制器层。这是实际发生转换的地方。 5. 控制器层 接下来让我们检查一个标准控制器实现，为Post资源公开简单的 REST API。 我们将在这里展示一些简单的 CRUD 操作：创建、更新、获取一个和获取所有。鉴于操作非常简单，我们对 Entity-DTO 转换方面特别感兴趣： @Controller class PostRestController { @Autowired private IPostService postService; @Autowired private IUserService userService; @Autowired private ModelMapper modelMapper; @GetMapping @ResponseBody public List\u0026lt;PostDto\u0026gt; getPosts(...) { //...  List\u0026lt;Post\u0026gt; posts = postService.getPostsList(page, size, sortDir, sort); return posts.stream() .map(this::convertToDto) .collect(Collectors.toList()); } @PostMapping @ResponseStatus(HttpStatus.CREATED) @ResponseBody public PostDto createPost(@RequestBody PostDto postDto) { Post post = convertToEntity(postDto); Post postCreated = postService.createPost(post)); return convertToDto(postCreated); } @GetMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseBody public PostDto getPost(@PathVariable(\u0026#34;id\u0026#34;) Long id) { return convertToDto(postService.getPostById(id)); } @PutMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseStatus(HttpStatus.OK) public void updatePost(@PathVariable(\u0026#34;id\u0026#34;) Long id, @RequestBody PostDto postDto) { if(!Objects.equals(id, postDto.getId())){ throw new IllegalArgumentException(\u0026#34;IDs don\u0026#39;t match\u0026#34;); } Post post = convertToEntity(postDto); postService.updatePost(post); } } 这是我们从Post实体到PostDto的转换： private PostDto convertToDto(Post post) { PostDto postDto = modelMapper.map(post, PostDto.class); postDto.setSubmissionDate(post.getSubmissionDate(), userService.getCurrentUser().getPreference().getTimezone()); return postDto; } 这是从 DTO 到实体的转换： private Post convertToEntity(PostDto postDto) throws ParseException { Post post = modelMapper.map(postDto, Post.class); post.setSubmissionDate(postDto.getSubmissionDateConverted( userService.getCurrentUser().getPreference().getTimezone())); if (postDto.getId() != null) { Post oldPost = postService.getPostById(postDto.getId()); post.setRedditID(oldPost.getRedditID()); post.setSent(oldPost.isSent()); } return post; } 如我们所见，在模型映射器的帮助下，**转换逻辑快速而简单。**我们正在使用映射器的地图API，并且无需编写任何转换逻辑即可转换数据。 6. 单元测试 最后，让我们做一个非常简单的测试，以确保实体和 DTO 之间的转换工作正常： public class PostDtoUnitTest { private ModelMapper modelMapper = new ModelMapper(); @Test public void whenConvertPostEntityToPostDto_thenCorrect() { Post post = new Post(); post.setId(1L); post.setTitle(randomAlphabetic(6)); post.setUrl(\u0026#34;www.test.com\u0026#34;); PostDto postDto = modelMapper.map(post, PostDto.class); assertEquals(post.getId(), postDto.getId()); assertEquals(post.getTitle(), postDto.getTitle()); assertEquals(post.getUrl(), postDto.getUrl()); } @Test public void whenConvertPostDtoToPostEntity_thenCorrect() { PostDto postDto = new PostDto(); postDto.setId(1L); postDto.setTitle(randomAlphabetic(6)); postDto.setUrl(\u0026#34;www.test.com\u0026#34;); Post post = modelMapper.map(postDto, Post.class); assertEquals(postDto.getId(), post.getId()); assertEquals(postDto.getTitle(), post.getTitle()); assertEquals(postDto.getUrl(), post.getUrl()); } } \u0026quot; ","permalink":"http://itcodingman.github.io/entity_to_and_from_dto_for_a_java_spring_application/","tags":["DTO"],"title":"Spring REST API中从实体到 DTO 转换"},{"categories":["Spring"],"contents":"1. 简介 可以说，现代软件设计最重要的开发原则之一是依赖注入 (DI)，它很自然地源于另一个至关重要的原则：模块化。 这个教程将探讨 Spring 中一种特定类型的 DI 技术，称为基于构造函数的依赖注入， 简单地说，意味着我们在实例化时将所需的组件传递给一个类。 首先，我们需要在pom.xml中导入spring-context依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.8.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后我们需要设置一个配置文件。根据偏好，该文件可以是 POJO 或 XML 文件。 2. 基于注解的配置 Java 配置文件看起来类似于带有一些附加注释的 Java 对象： @Configuration @ComponentScan(\u0026#34;com.codingman.demodi\u0026#34;) public class Config { @Bean public Engine engine() { return new Engine(\u0026#34;v8\u0026#34;, 5); } @Bean public Transmission transmission() { return new Transmission(\u0026#34;sliding\u0026#34;); } } 在这里，我们使用注解来通知 Spring 运行时这个类提供了 bean 定义（@Bean注解），并且包com.codingman.demodi需要执行上下文扫描以查找其他 bean。接下来，我们定义一个Car类： @Component public class Car { @Autowired public Car(Engine engine, Transmission transmission) { this.engine = engine; this.transmission = transmission; } } Spring在进行包扫描时会遇到我们的Car类，并会通过调用@Autowired带注释的构造函数来初始化它的实例。 通过调用Config类的@Bean注解方法，我们将获得Engine 和 Transmission的实例。最后，我们需要使用我们的 POJO 配置来引导ApplicationContext： ApplicationContext context = new AnnotationConfigApplicationContext(Config.class); Car car = context.getBean(Car.class); 3. 隐式构造函数注入 从 Spring 4.3 开始，具有单个构造函数的类可以省略@Autowired注释。这是一个很好的便利和样板删除。 最重要的是，同样从 4.3 开始，我们可以在@Configuration注释类中利用基于构造函数的注入。另外，如果这样的类只有一个构造函数，我们也可以省略@Autowired注解。 4. 基于 XML 的配置 使用基于构造函数的依赖注入配置 Spring 运行时的另一种方法是使用 XML 配置文件： \u0026lt;bean id=\u0026#34;toyota\u0026#34; class=\u0026#34;com.codingman.demodi.domain.Car\u0026#34;\u0026gt; \u0026lt;constructor-arg index=\u0026#34;0\u0026#34; ref=\u0026#34;engine\u0026#34;/\u0026gt; \u0026lt;constructor-arg index=\u0026#34;1\u0026#34; ref=\u0026#34;transmission\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;engine\u0026#34; class=\u0026#34;com.codingman.demodi.domain.Engine\u0026#34;\u0026gt; \u0026lt;constructor-arg index=\u0026#34;0\u0026#34; value=\u0026#34;v4\u0026#34;/\u0026gt; \u0026lt;constructor-arg index=\u0026#34;1\u0026#34; value=\u0026#34;2\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transmission\u0026#34; class=\u0026#34;com.codingman.demodi.domain.Transmission\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;sliding\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 请注意，constructor-arg可以接受文字值或对另一个 bean 的引用，并且可以提供可选的显式索引和类型。我们可以使用Type和index属性来解决歧义（例如，如果构造函数采用相同类型的多个参数）。  name属性也可以用于 xml 到 java 变量的匹配，但是你的代码必须在编译时使用调试标志。  在这种情况下，我们需要使用ClassPathXmlApplicationContext引导我们的 Spring 应用程序上下文： ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;codingman.xml\u0026#34;); Car car = context.getBean(Car.class); 5. 优点和缺点 与字段注入相比，构造函数注入有一些优点。 第一个好处是可测试性。假设我们要对一个使用字段注入的 Spring bean 进行单元测试： public class UserService { @Autowired private UserRepository userRepository; } 在UserService 实例的构建过程中，我们无法初始化userRepository 状态。实现这一点的唯一方法是通过完全打破封装的反射 API此外，与简单的构造函数调用相比，生成的代码将不太安全。 此外，使用字段注入，我们无法强制执行类级别的不变量，因此可能会在没有正确初始化userRepository的情况下拥有 UserService 实例。因此，我们可能会在这里和那里遇到随机 的NullPointerException 。此外，使用构造函数注入，更容易构建不可变组件。 此外，从 OOP 的角度来看，使用构造函数创建对象实例更为自然。 另一方面，构造函数注入的主要缺点是其冗长，尤其是当 bean 具有少量依赖项时。有时这可能是因祸得福，因为我们可能会更加努力地将依赖项的数量保持在最低限度。 \u0026quot; ","permalink":"http://itcodingman.github.io/constructor_injection_in_spring/","tags":["Spring Core Basics","Spring DI"],"title":"Spring 的构造函数依赖注入"},{"categories":["REST","Spring"],"contents":"1.概述 在本教程中，我们将学习如何**在 Spring 中设置 REST，**包括控制器和 HTTP 响应代码、有效负载编组的配置和内容协商。 2. 了解 Spring 中的 REST Spring 框架支持两种创建 RESTful 服务的方式：  将 MVC 与ModelAndView一起使用 使用 HTTP 消息转换器  ModelAndView方法更老，文档更好，但也更冗长且配置繁重。它试图将 REST 范式硬塞到旧模型中，这并非没有问题。Spring 团队明白这一点，并从 Spring 3.0 开始提供一流的 REST 支持。 **新方法基于*HttpMessageConverter* 和注解，更轻量级且易于实现。**配置是最少的，它为我们对 RESTful 服务的期望提供了合理的默认值。 3. Java 配置 @Configuration @EnableWebMvc public class WebConfig{ // } 新的*@EnableWebMvc*注解做了一些有用的事情；具体来说，在 REST 的情况下，它会检测到类路径中 Jackson 和 JAXB 2 的存在，并自动创建和注册默认的 JSON 和 XML 转换器。注解的功能等同于 XML 版本： \u0026lt;mvc:注解驱动 /\u0026gt; 这是一条捷径，尽管它在许多情况下可能很有用，但并不完美。当我们需要更复杂的配置时，可以去掉注解，直接扩展WebMvcConfigurationSupport。 3.1 使用 Spring Boot 如果我们使用*@SpringBootApplication注解，并且spring-webmvc* 库位于类路径上，那么 @EnableWebMvc注解会自动添加，并带有默认的 autoconfiguration。 我们仍然可以通过在@Configuration 注释类上实现WebMvcConfigurer 接口 来将 MVC 功能添加到此配置中 。我们还可以使用 WebMvcRegistrationsAdapter实例来提供我们自己的 RequestMappingHandlerMapping、RequestMappingHandlerAdapter或ExceptionHandlerExceptionResolver 实现。 最后，如果我们想放弃 Spring Boot 的 MVC 特性并声明自定义配置，我们可以使用*@EnableWebMvc*注解来实现。 4. 测试 Spring 上下文 从 Spring 3.1 开始，我们获得了对@Configuration类的一流测试支持： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( classes = {WebConfig.class, PersistenceConfig.class}, loader = AnnotationConfigContextLoader.class) public class SpringContextIntegrationTest { @Test public void contextLoads(){ // When  } } 我们使用*@ContextConfiguration注解指定 Java 配置类。新的AnnotationConfigContextLoader从@Configuration*类加载 bean 定义。 请注意，WebConfig配置类未包含在测试中，因为它需要在未提供的 Servlet 上下文中运行。 4.1 使用 Spring Boot Spring Boot 提供了几个注解来以更直观的方式为我们的测试设置 Spring ApplicationContext 。 我们可以只加载应用程序配置的特定部分，也可以模拟整个上下文启动过程。 例如， 如果我们想在不启动服务器的情况下创建整个上下文，我们可以使用*@SpringBootTest注解。* 有了它，我们就可以添加*@AutoConfigureMockMvc* 来注入 MockMvc 实例并发送 HTTP 请求*：* @RunWith(SpringRunner.class) @SpringBootTest @AutoConfigureMockMvc public class FooControllerAppIntegrationTest { @Autowired private MockMvc mockMvc; @Test public void whenTestApp_thenEmptyResponse() throws Exception { this.mockMvc.perform(get(\u0026#34;/foos\u0026#34;) .andExpect(status().isOk()) .andExpect(...); } } 为了避免创建整个上下文并只测试我们的 MVC 控制器，我们可以使用 @WebMvcTest： @RunWith(SpringRunner.class) @WebMvcTest(FooController.class) public class FooControllerWebLayerIntegrationTest { @Autowired private MockMvc mockMvc; @MockBean private IFooService service; @Test() public void whenTestMvcController_thenRetrieveExpectedResult() throws Exception { // ...  this.mockMvc.perform(get(\u0026#34;/foos\u0026#34;) .andExpect(...); } } 我们可以在“Spring Boot 中的测试”文章中找到有关此主题的详细信息。 5. 控制器 **@RestController是 RESTful API 的整个 Web 层中的核心工件*。***就本文而言，控制器正在建模一个简单的 REST 资源Foo： @RestController @RequestMapping(\u0026#34;/foos\u0026#34;) class FooController { @Autowired private IFooService service; @GetMapping public List\u0026lt;Foo\u0026gt; findAll() { return service.findAll(); } @GetMapping(value = \u0026#34;/{id}\u0026#34;) public Foo findById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { return RestPreconditions.checkFound(service.findById(id)); } @PostMapping @ResponseStatus(HttpStatus.CREATED) public Long create(@RequestBody Foo resource) { Preconditions.checkNotNull(resource); return service.create(resource); } @PutMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseStatus(HttpStatus.OK) public void update(@PathVariable( \u0026#34;id\u0026#34; ) Long id, @RequestBody Foo resource) { Preconditions.checkNotNull(resource); RestPreconditions.checkNotNull(service.getById(resource.getId())); service.update(resource); } @DeleteMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseStatus(HttpStatus.OK) public void delete(@PathVariable(\u0026#34;id\u0026#34;) Long id) { service.deleteById(id); } } 正如我们所见，我们使用了一个简单的 Guava 风格的RestPreconditions实用程序： public class RestPreconditions { public static \u0026lt;T\u0026gt; T checkFound(T resource) { if (resource == null) { throw new MyResourceNotFoundException(); } return resource; } } Controller 实现是非公开的，因为它不需要。 通常，控制器是依赖链中的最后一个。它从 Spring 前端控制器（DispatcherServlet）接收 HTTP 请求，并将它们简单地委托给服务层。如果没有必须通过直接引用注入或操作控制器的用例，那么我们可能不希望将其声明为公共的。 请求映射很简单。与任何控制器一样，映射的实际值以及 HTTP 方法决定了请求的目标方法。@RequestBody将方法的参数绑定到 HTTP 请求的主体，而*@ResponseBody对响应和返回类型执行相同的操作。* @RestController 是在我们的类中包含 @ResponseBody 和 @Controller注释的简写。 他们还确保使用正确的 HTTP 转换器对资源进行编组和解组。将进行内容协商以选择将使用哪一个活动转换器，主要基于Accept标头，尽管也可以使用其他 HTTP 标头来确定表示形式。 6. 映射 HTTP 响应代码 HTTP 响应的状态码是 REST 服务最重要的部分之一，主题很快就会变得非常复杂。正确处理这些可能是服务的成败。 6.1 未映射的请求 如果 Spring MVC 接收到一个没有映射的请求，它认为该请求不允许，并返回一个 405 METHOD NOT ALLOWED 返回给客户端。 在向客户端返回405以指定允许哪些操作时，包含Allow HTTP 标头也是一种很好的做法。这是 Spring MVC 的标准行为，不需要任何额外的配置。 6.2 有效的映射请求 对于任何具有映射的请求，Spring MVC 认为该请求有效并以 200 OK 响应，如果没有另外指定其他状态代码。 正因为如此，控制器为create、update和delete操作声明了不同的@ResponseStatus，但没有为get声明，它确实应该返回默认的 200 OK。 6.3 客户端错误 在客户端错误的情况下，自定义异常被定义并映射到适当的错误代码。 简单地从 web 层的任何层抛出这些异常将确保 Spring 在 HTTP 响应上映射相应的状态代码： @ResponseStatus(HttpStatus.BAD_REQUEST) public class BadRequestException extends RuntimeException { // } @ResponseStatus(HttpStatus.NOT_FOUND) public class ResourceNotFoundException extends RuntimeException { // } 这些异常是 REST API 的一部分，因此，我们应该只在与 REST 对应的适当层中使用它们；例如，如果存在 DAO/DAL 层，则不应直接使用异常。 另请注意，这些不是检查异常，而是符合 Spring 实践和习惯用法的运行时异常。 6.4 使用@ExceptionHandler 将自定义异常映射到特定状态代码的另一个选项是在控制器中使用*@ExceptionHandler*注释。这种方法的问题在于注释仅适用于定义它的控制器。这意味着我们需要在每个控制器中单独声明它们。 当然，在 Spring 和 Spring Boot 中处理错误的方法更多，提供了更大的灵活性。 7. 额外的 Maven 依赖 除了标准 Web 应用程序所需的spring-webmvc依赖项之外，我们还需要为 REST API 设置内容编组和解组： \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 我们将使用这些库将 REST 资源的表示形式转换为 JSON 或 XML。 7.1 使用 Spring Boot 如果我们想检索 JSON 格式的资源，Spring Boot 提供了对不同库的支持，即 Jackson、Gson 和 JSON-B。 我们可以通过简单地在类路径中包含任何映射库来执行自动配置。 通常，如果我们正在开发一个 Web 应用程序，我们只需添加spring-boot-starter-web依赖项并依赖它来将所有必要的工件包含到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Spring Boot 默认使用 Jackson。 如果我们想以 XML 格式序列化我们的资源，我们必须将 Jackson XML 扩展 ( jackson-dataformat-xml ) 添加到我们的依赖项中，或者通过使用回退到 JAXB 实现（JDK 中默认提供） 我们资源上的*@XmlRootElement*注释。\u0026quot; ","permalink":"http://itcodingman.github.io/building_a_restful_web_service_with_spring_and_java_based_configuration/","tags":[],"title":"使用 Spring 和 Java Config 构建 REST API"},{"categories":["REST","Spring"],"contents":"1. 概述 本教程说明了如何使用 Spring 创建 Web 应用程序。 我们将研究用于构建应用程序的 Spring Boot 解决方案，并查看非 Spring Boot 方法。 我们将主要使用 Java 配置，但也会看看它们等效的 XML 配置。 2. 使用 Spring Boot 进行设置 2.1 Maven 依赖 首先，我们需要spring-boot-starter-web 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 该启动器包括：  spring-web和 Spring Web 应用程序所需的spring-webmvc模块 一个 Tomcat 启动器，这样我们就可以直接运行我们的 Web 应用程序，而无需显式安装任何服务器  2.2. 创建一个 Spring Boot 应用程序 开始使用 Spring Boot 最直接的方法是创建一个主类并使用 @SpringBootApplication对其进行注释： @SpringBootApplication public class SpringBootRestApplication { public static void main(String[] args) { SpringApplication.run(SpringBootRestApplication.class, args); } } 此单个注解等效于使用@Configuration、@EnableAutoConfiguration和@ComponentScan。 默认情况下，它将扫描同一包或以下的所有组件。 接下来，对于 Spring beans 的基于 Java 的配置，我们需要创建一个配置类并使用@Configuration注解对其进行注解： @Configuration public class WebConfig { } 这个注解是基于 Java 的 Spring 配置使用的主要工件；它本身使用@Component进行元注释，这使得带注释的类成为标准 bean，因此也是组件扫描的候选对象。 @Configuration类的主要目的是作为 Spring IoC 容器的 bean 定义的来源。更详细的描述请参见官方文档。 让我们也看看使用核心spring-webmvc库的解决方案。 3. 使用 spring-webmvc 进行设置 3.1 Maven 依赖项 首先，我们需要spring-webmvc依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.2 基于 Java 的 Web 配置 接下来，我们将添加具有@Configuration注解的配置类： @Configuration @EnableWebMvc @ComponentScan(basePackages = \u0026#34;com.codingman.controller\u0026#34;) public class WebConfig { } 在这里，与 Spring Boot 解决方案不同，我们必须显式定义@EnableWebMvc以设置默认 Spring MVC 配置和@ComponentScan以指定要扫描组件的包。 @EnableWebMvc注解提供Spring Web MVC配置，例如设置调度程序 servlet、启用@Controller和@RequestMapping注解以及设置其他默认值。 @ComponentScan配置组件扫描指令，指定要扫描的包。 3.3 初始化器类 接下来，我们需要添加一个实现 WebApplicationInitializer接口的类： public class AppInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext container) throws ServletException { AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); ctx.scan(\u0026#34;com.codingman\u0026#34;); container.addListener(new ContextLoaderListener(ctx)); ServletRegistration.Dynamic dyn = container.addServlet(\u0026#34;mvc\u0026#34;, new DispatcherServlet(ctx)); dyn.setLoadOnStartup(1); dyn.addMapping(\u0026#34;/\u0026#34;); } } 在这里，我们使用 AnnotationConfigWebApplicationContext类创建一个 Spring 上下文，这意味着我们只使用基于注释的配置。然后，我们指定要扫描组件和配置类的包。 最后，我们定义了 Web 应用程序的入口点——DispatcherServlet。 此类可以完全替换Servlet 3.0版本的web.xml文件。 4. XML 配置 让我们快速看一下等效的 XML Web 配置： \u0026lt;context:component-scan base-package=\u0026#34;com.codingman.controller\u0026#34; /\u0026gt; \u0026lt;mvc:annotation-driven /\u0026gt; 我们可以用上面的WebConfig类替换这个 XML 文件。 要启动应用程序，我们可以使用加载 XML 配置或 web.xml 文件的 Initializer 类。有关这两种方法的更多详细信息，请查看之前的文章。 \u0026quot; ","permalink":"http://itcodingman.github.io/bootstraping_a_web_application_with_spring_and_java_based_configuration/","tags":["Spring 5"],"title":"使用 Spring 5 创建 Web 应用程序"},{"categories":["REST","Spring Security"],"contents":"1. 概述 本文讨论如何在REST API 的相同 URI 结构上设置基本身份验证和摘要式身份验证。在之前的文章中，我们讨论了另一种保护 REST 服务的方法——基于表单的身份验证，因此基本和摘要式身份验证是自然的选择，也是更 RESTful 的一种。 2. 基本认证的配置 基于表单的身份验证不适合 RESTful 服务的主要原因是 Spring Security 将使用 Sessions——这当然是服务器上的状态，因此REST 中的无状态约束实际上被忽略了。 我们将从设置基本身份验证开始——首先我们从主**安全元素中删除旧的自定义入口点和过滤器： \u0026lt;http create-session=\u0026#34;stateless\u0026#34;\u0026gt; \u0026lt;intercept-url pattern=\u0026#34;/api/admin/**\u0026#34; access=\u0026#34;ROLE_ADMIN\u0026#34; /\u0026gt; \u0026lt;http-basic /\u0026gt; \u0026lt;/http\u0026gt; 请注意如何使用单个配置行添加对基本身份验证的支持 -  - 它处理BasicAuthenticationFilter和BasicAuthenticationEntryPoint的创建和连接。 2.1 满足无状态约束——摆脱会话 RESTful 架构风格的主要限制之一是客户端-服务器通信是完全无状态的，正如原始论文所述：  5.1.3 无状态 我们接下来为客户端-服务器交互添加一个约束：通信本质上必须是无状态的，如第 3.4.3 节（图 5-3）中的客户端-无状态-服务器（CSS）样式，这样从客户端到的每个请求服务器必须包含理解请求所需的所有信息，并且不能利用服务器上存储的任何上下文。因此，会话状态完全保留在客户端上。  服务端Session的概念在 Spring Security 中是一个由来已久的概念，直到现在完全移除它一直很困难，尤其是在使用命名空间进行配置的情况下。 然而，Spring Security为命名空间配置增加了一个用于创建会话的新无状态选项，这有效地保证了 Spring 不会创建或使用任何会话。这个新选项的作用是完全从安全过滤器链中删除所有与会话相关的过滤器，确保为每个请求执行身份验证。 3. 摘要认证的配置 从前面的配置开始，设置摘要认证所需的过滤器和入口点将被定义为 bean。然后，摘要入口点将覆盖由在幕后创建的入口点。最后，自定义摘要过滤器将被引入安全过滤器链中，使用安全命名空间的after语义将其直接定位在基本身份验证过滤器之后。 \u0026lt;http create-session=\u0026#34;stateless\u0026#34; entry-point-ref=\u0026#34;demoEntryPoint\u0026#34;\u0026gt; \u0026lt;intercept-url pattern=\u0026#34;/api/admin/**\u0026#34; access=\u0026#34;ROLE_ADMIN\u0026#34; /\u0026gt; \u0026lt;http-basic /\u0026gt; \u0026lt;custom-filter ref=\u0026#34;demoFilter\u0026#34; after=\u0026#34;BASIC_AUTH_FILTER\u0026#34; /\u0026gt; \u0026lt;/http\u0026gt; \u0026lt;beans:bean id=\u0026#34;demoFilter\u0026#34; class= \u0026#34;org.springframework.security.web.authentication.www.DigestAuthenticationFilter\u0026#34;\u0026gt; \u0026lt;beans:property name=\u0026#34;userDetailsService\u0026#34; ref=\u0026#34;userService\u0026#34; /\u0026gt; \u0026lt;beans:property name=\u0026#34;authenticationEntryPoint\u0026#34; ref=\u0026#34;demoEntryPoint\u0026#34; /\u0026gt; \u0026lt;/beans:bean\u0026gt; \u0026lt;beans:bean id=\u0026#34;demoEntryPoint\u0026#34; class= \u0026#34;org.springframework.security.web.authentication.www.DigestAuthenticationEntryPoint\u0026#34;\u0026gt; \u0026lt;beans:property name=\u0026#34;realmName\u0026#34; value=\u0026#34;Demo Authentication\u0026#34;/\u0026gt; \u0026lt;beans:property name=\u0026#34;key\u0026#34; value=\u0026#34;acegi\u0026#34; /\u0026gt; \u0026lt;/beans:bean\u0026gt; \u0026lt;authentication-manager\u0026gt; \u0026lt;authentication-provider\u0026gt; \u0026lt;user-service id=\u0026#34;userService\u0026#34;\u0026gt; \u0026lt;user name=\u0026#34;admin\u0026#34; password=\u0026#34;123\u0026#34; authorities=\u0026#34;ROLE_ADMIN\u0026#34; /\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34; password=\u0026#34;456\u0026#34; authorities=\u0026#34;ROLE_USER\u0026#34; /\u0026gt; \u0026lt;/user-service\u0026gt; \u0026lt;/authentication-provider\u0026gt; \u0026lt;/authentication-manager\u0026gt; 不幸的是，安全命名空间中不支持自动配置摘要式身份验证，就像可以使用配置基本身份验证一样。因此，必须手动定义必要的 bean 并将其连接到安全配置中。 4. 在同一个Restful服务中同时支持两种认证协议 单独的 Basic 或 Digest 身份验证可以在 Spring Security 中轻松实现；它在相同的 URI 映射上为相同的 RESTful Web 服务支持它们，这为服务的配置和测试引入了新的复杂性。 4.1 匿名请求 使用安全链中的基本过滤器和摘要过滤器，Spring Security 处理匿名请求（不包含身份验证凭据的请求,授权HTTP标头）的方式是，两个身份验证过滤器将找不到凭据并继续执行过滤链。然后，查看请求是如何未经过身份验证的，会抛出AccessDeniedException并在ExceptionTranslationFilter中捕获，它会启动摘要入口点，提示客户端输入凭据。 基本过滤器和摘要过滤器的职责都非常狭窄——如果它们无法识别请求中身份验证凭据的类型，它们将继续执行安全过滤器链。正因为如此，Spring Security 可以灵活地配置为支持同一 URI 上的多个身份验证协议。 当请求包含正确的身份验证凭据（基本或摘要）时，将正确使用该协议。但是，对于匿名请求，客户端只会收到摘要式身份验证凭据的提示。这是因为摘要入口点被配置为 Spring Security 链的主要和单一入口点；因此可以将摘要身份验证视为默认设置。 4.2 带有身份验证凭据的请求 带有 Basic 身份验证凭据的请求将由Authorization标头标识，该标头以前缀Basic开头。处理此类请求时，凭据将在基本身份验证过滤器中解码，并且请求将被授权。同样，带有摘要身份验证凭据的请求将使用前缀摘要作为其授权标头。 5. 测试两种场景 在使用基本或摘要进行身份验证后，测试将通过创建新资源来使用 REST 服务： @Test public void givenAuthenticatedByBasicAuth_whenAResourceIsCreated_then201IsReceived(){ // Given  // When  Response response = given() .auth().preemptive().basic( ADMIN_USERNAME, ADMIN_PASSWORD ) .contentType( HttpConstants.MIME_JSON ).body( new Foo( randomAlphabetic( 8 ) ) ) .post( paths.getFooURL() ); // Then  assertThat( response.getStatusCode(), is( 201 ) ); } @Test public void givenAuthenticatedByDigestAuth_whenAResourceIsCreated_then201IsReceived(){ // Given  // When  Response response = given() .auth().digest( ADMIN_USERNAME, ADMIN_PASSWORD ) .contentType( HttpConstants.MIME_JSON ).body( new Foo( randomAlphabetic( 8 ) ) ) .post( paths.getFooURL() ); // Then  assertThat( response.getStatusCode(), is( 201 ) ); } 请注意，使用基本身份验证的测试会抢先将凭据添加到请求中，无论服务器是否已对身份验证提出质疑。这是为了确保服务器不需要向客户端质询凭据，因为如果需要，质询将针对 Digest 凭据，因为这是默认设置。 \u0026quot; ","permalink":"http://itcodingman.github.io/basic_and_digest_authentication_for_a_rest_api_with_spring_security/","tags":["Authentication"],"title":"使用 Spring Security 的 REST 服务的基本和摘要式身份验证"},{"categories":["Persistence","Spring"],"contents":"1. 概述 这是对 Grails 3 和 GORM 的快速介绍。 我们当然会使用 Groovy，并且——隐含地——该框架还使用 Hibernate 来实现 ORM，Spring 框架用于依赖注入，SiteMash 用于布局和主题等。 2.数据源配置 我们无需指定任何显式数据源配置即可开始——默认情况下，Grails 使用 HSQLDB 数据库作为开发和测试环境。 但是如果你想改变这些默认值，你可以在application.yml中定义你选择的数据源： environments: development: dataSource: driverClassName : \u0026#34;com.mysql.jdbc.Driver\u0026#34; url : \u0026#34;jdbc:mysql://localhost:8080/test\u0026#34; dialect : org.hibernate.dialect.MySQL5InnoDBDialect 同样，我们可以在这里创建多个环境。 3. 域 Grails 能够基于数据库配置中的dbCreate属性为我们的域类创建数据库结构。 让我们在这里定义这些域类之一： Class User { String userName String password String email String age static constraints = { userName blank: false, unique: true password size: 5..10, blank: false email email: true, blank: true } } 请注意我们如何在模型中指定我们的验证约束，这使事情变得干净整洁，并且没有注释。 当实体被持久化时，这些约束将由 Grails 自动检查，如果这些约束中的任何一个被破坏，框架将抛出适当的验证异常。 我们还可以在模型的映射属性中指定 GORM 映射： static mapping = { sort \u0026#34;userName\u0026#34; } 现在，如果我们调用User.list() - 我们将返回按userName排序的结果。 我们当然可以通过将排序传递给列表 API 来实现相同的结果： User.list(sort: \u0026#34;userName\u0026#34;) 4. CRUD 操作 当我们看 API 操作时，脚手架在开始时扮演着非常有趣的角色；它允许您为域类生成基本的 CRUD API，包括：  必要的视图 标准 CRUD 操作的控制器操作 两种类型：动态和静态  以下是动态脚手架的工作原理： class UserController { static scaffold = true } 只需编写这一行代码，框架就会在运行时生成 7 个方法：显示、编辑、删除、创建、保存和更新。这些将作为该特定域实体的 API 发布。 静态脚手架示例：  使用脚手架创建视图：“ grails generate-views User ” 使用脚手架创建控制器和视图：“ grails generate-controller User ” 要在单个命令中创建所有内容，请使用：“ grails generate-all User ”  这些命令将为该特定域对象自动生成必要的管道。 现在让我们快速了解如何使用这些操作——例如，对于我们的User域对象。 创建新的User记录： def user = new User(username: \u0026#34;test\u0026#34;, password: \u0026#34;test123\u0026#34;, email: \u0026#34;a@a.com\u0026#34;, age: 14) user.save() 要获取单个记录： def user = User.get(1) 此get API 将以可编辑模式检索域对象。对于只读模式，我们可以使用read API： def user = User.read(1) 要更新现有记录： def user = User.get(1) user.userName = \u0026#34;testUpdate\u0026#34; user.age = 20 user.save() 以及对现有记录的简单删除操作： def user = User.get(1) user.delete() 5. GORM 查询 5.1 find 让我们从find API 开始： def user = User.find(\u0026#34;from User as u where u.username = \u0026#39;test\u0026#39; \u0026#34;) 我们还可以使用不同的语法来传递参数： def user = User.find(\u0026#34;from User as u where u.username?\u0026#34;, [\u0026#39;test\u0026#39;]) 我们还可以使用命名参数： def user = User.find(\u0026#34;from User as u where u.username=?\u0026#34;, [username: \u0026#39;test\u0026#39;]) 5.2 findBy Grails 提供了一个动态查找工具，它使用域属性在运行时执行查询并返回第一个匹配记录： def user = User.findByUsername(\u0026#34;test\u0026#34;) user = User.findByUsernameAndAge(\u0026#34;test\u0026#34;, 20) user = User.findByUsernameLike(\u0026#34;tes\u0026#34;) user = User.findByUsernameAndAgeNotEquals(\u0026#34;test\u0026#34;, \u0026#34;100\u0026#34;) 你可以在这里找到更多的表达方式。 5.3 Criteria 我们还可以使用一些灵活的标准检索数据： def user = User.find { username == \u0026#34;test\u0026#34;} def user = User.createCriteria() def results = user.list { like (\u0026#34;userName\u0026#34;, \u0026#34;te%\u0026#34;) and { between(\u0026#34;age\u0026#34;, 10, 20) } order(\u0026#34;userName\u0026#34;, \u0026#34;desc\u0026#34;) } 这里有一个说明——当使用条件查询时，使用“{}”而不是“()”。 5.4 执行查询/更新 GORM 还支持 HQL 查询语法——用于读取操作： def user = User.executeQuery( \u0026#34;select u.userName from User u where u.userName = ?\u0026#34;, [\u0026#39;test\u0026#39;]) 以及写操作： def user = User.executeUpdate(\u0026#34;delete User u where u.username =?\u0026#34;, [\u0026#39;test\u0026#39;]) \u0026quot; ","permalink":"http://itcodingman.github.io/grails_gorm_tutorial/","tags":[],"title":"Grails 3 和 GORM 简介"},{"categories":null,"contents":"","permalink":"http://itcodingman.github.io/search/","tags":null,"title":"Search"}]