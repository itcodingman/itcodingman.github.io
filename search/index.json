[{"categories":["Java"],"contents":"1. 概述 有时我们需要确定一个对象是否是原始类型，特别是对于包装原始类型。但是，标准 JDK 中没有内置方法来实现这一点。 在本快速教程中，我们将了解如何使用核心 Java 实现解决方案。然后我们将看看如何使用几个常用的库来实现这一点。 2. 原始类型和包装类 在 Java 中有九个预定义的对象来表示八个原语和一个*void类型。*每个原始类型都有一个对应的Wrapper Class。 要了解有关Primitives和Object的更多信息，请参阅这篇文章。 ** java.lang.Class.isPrimitive()方法可以判断指定的对象是否代表原始类型。但是，它不适用于原语的包装器。 例如，以下语句返回false： Integer.class.isPrimitive(); 现在让我们来看看实现这一目标的不同方法。 3. 使用核心 Java 首先，让我们定义一个存储包装器和原始类型类的HashMap变量： private static final Map\u0026lt;Class\u0026lt;?\u0026gt;, Class\u0026lt;?\u0026gt;\u0026gt; WRAPPER_TYPE_MAP; static { WRAPPER_TYPE_MAP = new HashMap\u0026lt;Class\u0026lt;?\u0026gt;, Class\u0026lt;?\u0026gt;\u0026gt;(16); WRAPPER_TYPE_MAP.put(Integer.class, int.class); WRAPPER_TYPE_MAP.put(Byte.class, byte.class); WRAPPER_TYPE_MAP.put(Character.class, char.class); WRAPPER_TYPE_MAP.put(Boolean.class, boolean.class); WRAPPER_TYPE_MAP.put(Double.class, double.class); WRAPPER_TYPE_MAP.put(Float.class, float.class); WRAPPER_TYPE_MAP.put(Long.class, long.class); WRAPPER_TYPE_MAP.put(Short.class, short.class); WRAPPER_TYPE_MAP.put(Void.class, void.class); } 如果对象是原始包装类，我们可以使用java.utils.Map.ContainsKey()方法从预定义的HashMap变量中查找它。 现在我们可以创建一个简单的实用方法来确定对象源是否为原始类型： public static boolean isPrimitiveType(Object source) { return WRAPPER_TYPE_MAP.containsKey(source.getClass()); } 让我们验证这是否按预期工作： assertTrue(PrimitiveTypeUtil.isPrimitiveType(false)); assertTrue(PrimitiveTypeUtil.isPrimitiveType(1L)); assertFalse(PrimitiveTypeUtil.isPrimitiveType(StringUtils.EMPTY)); 4. 使用 Apache Commons – ClassUtils.isPrimitiveOrWrapper() Apache Commons Lang有一个ClassUtils.isPrimitiveOrWrapper方法，可用于确定一个类是原始类还是原始类的包装器。 首先，让我们将Maven Central的commons-lang3依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;version\u0026gt; \u0026lt;dependency\u0026gt; 然后让我们测试一下： assertTrue(ClassUtils.isPrimitiveOrWrapper(Boolean.False.getClass())); assertTrue(ClassUtils.isPrimitiveOrWrapper(boolean.class)); assertFalse(ClassUtils.isPrimitiveOrWrapper(StringUtils.EMPTY.getClass())); 5. 使用Guava——Primitives.isWrapperType() Guava通过Primitives.isWrapperType方法提供了类似的实现。 同样，让我们​​首先添加来自Maven Central的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;artifactId\u0026gt; \u0026lt;version\u0026gt;31.0.1-jre\u0026lt;version\u0026gt; \u0026lt;dependency\u0026gt; 同样，我们可以使用以下方法对其进行测试： assertTrue(Primitives.isWrapperType(Boolean.FALSE.getClass())); assertFalse(Primitives.isWrapperType(StringUtils.EMPTY.getClass())); 但是，Primitives.isWrapperType方法不适用于原始类，以下代码将返回 false： assertFalse(Primitives.isWrapperType(boolean.class)); \u0026quot; ","permalink":"http://itcodingman.github.io/java_object_primitive_type/","tags":["Core Java"],"title":"确定对象是否为原始类型"},{"categories":["Java","Youtube"],"contents":"20分钟学习Tomcat   ","permalink":"http://itcodingman.github.io/20_mins_tomcat/","tags":[],"title":"20分钟学习Tomcat"},{"categories":["Java","Spring","BiliBili"],"contents":"Visual Studio Code Spring Boot 的安装及使用 Visual Studio Code和Spring Boot的安装及使用 \r","permalink":"http://itcodingman.github.io/vscode_spring_boot_install_introduce/","tags":[],"title":"Visual Studio Code Spring Boot 的安装及使用"},{"categories":["Python","Youtube"],"contents":"推箱子——pygame项目实战   ","permalink":"http://itcodingman.github.io/pygame_sokoban/","tags":[],"title":"推箱子——pygame项目实战"},{"categories":["Java","Youtube"],"contents":"10分钟学习Java Log   ","permalink":"http://itcodingman.github.io/10_mins_java_log/","tags":["JUL","Slf4j","Log4j","Log4j2","JCL","Logback","Commons logging"],"title":"10分钟学习Java Log"},{"categories":["Java","BiliBili"],"contents":"一小时学习Servlet 本教程将讲解如何使用 Java Servlet 来开发基于 web 的应用程序。 \r","permalink":"http://itcodingman.github.io/1_hour_servlet/","tags":[],"title":"一小时学习Servlet"},{"categories":["Python","BiliBili"],"contents":"conda的安装和使用、国内源、常用命令 conda的安装和使用、国内源、常用命令 \r","permalink":"http://itcodingman.github.io/conda_install_introduce/","tags":[],"title":"conda的安装和使用、国内源、常用命令"},{"categories":["Python","Youtube"],"contents":"扫雷——pygame项目实战   ","permalink":"http://itcodingman.github.io/pygame_minesweeper/","tags":[],"title":"扫雷——pygame项目实战"},{"categories":["Python","BiliBili"],"contents":"PIP安装和使用、国内源、常用命令 PIP安装和使用、国内源、常用命令 \r","permalink":"http://itcodingman.github.io/pip_install_introduce/","tags":[],"title":"PIP安装和使用、国内源、常用命令"},{"categories":["C++","Youtube"],"contents":"C++中地址和引用的区别   ","permalink":"http://itcodingman.github.io/c_plus_point_reference_diffrence/","tags":[],"title":"C++中地址和引用的区别"},{"categories":["Python","Youtube"],"contents":"10分钟学习PyScript   ","permalink":"http://itcodingman.github.io/10_mins_pyscript/","tags":[],"title":"10分钟学习PyScript"},{"categories":["Java","BiliBili"],"contents":"50分钟学习JSP JSP教程主要提供JSP基础知识以及部分常用的JSP进阶知识，大家在学习JSP之前，需要具备一定的HTML及Java基础。 \r","permalink":"http://itcodingman.github.io/50_mins_jsp/","tags":[],"title":"50分钟学习JSP"},{"categories":["Java","BiliBili"],"contents":"Eclipse、Tomcat和Java Web的安装、配置及开发 Eclipse、Tomcat和Java Web的安装、配置及开发 \r","permalink":"http://itcodingman.github.io/eclipse_tomcat_java_web_install_introduce/","tags":[],"title":"Eclipse、Tomcat和Java Web的安装、配置及开发"},{"categories":["Java","Youtube"],"contents":"20分钟学习Ant安装和使用   ","permalink":"http://itcodingman.github.io/20_mins_ant/","tags":[],"title":"20分钟学习Ant安装和使用"},{"categories":["Java","BiliBili"],"contents":"Eclipse和Java的安装 Eclipse和Java的安装 \r","permalink":"http://itcodingman.github.io/eclipse_java_install_introduce/","tags":[],"title":"Eclipse和Java的安装"},{"categories":["Java","Youtube"],"contents":"30分钟学习MyBatis通用CRUD Mapper   ","permalink":"http://itcodingman.github.io/30_mins_mybatis_generic_mapper/","tags":[],"title":"30分钟学习MyBatis通用CRUD Mapper"},{"categories":["Java","BiliBili"],"contents":"100分钟学习Java 这是一门针对初学者的完整课程，学习有关Java的所有知识。包括：语法、语句、字符串、操作符、函数、文件等 \r","permalink":"http://itcodingman.github.io/100_mins_java/","tags":[],"title":"100分钟学习Java"},{"categories":["Java","Spring","Youtube"],"contents":"15分钟学习MyBatis Generator   ","permalink":"http://itcodingman.github.io/15_mins_mybatis_generator/","tags":[],"title":"15分钟学习MyBatis Generator"},{"categories":["Java","BiliBili"],"contents":"Visual Studio Code Java 的安装及使用 VisualStudioCode和Java的安装及使用 \r","permalink":"http://itcodingman.github.io/vscode_java_install_introduce/","tags":[],"title":"Visual Studio Code Java 的安装及使用"},{"categories":["Java","Spring","Youtube"],"contents":"15分钟学习Spring Boot和MyBatis   ","permalink":"http://itcodingman.github.io/15_mins_spring_boot_mybatis/","tags":[],"title":"15分钟学习Spring Boot和MyBatis"},{"categories":["C++","BiliBili"],"contents":"Visaul Studio Code C++ 安装及使用 Visaul Studio Code C++ 安装及使用 \r","permalink":"http://itcodingman.github.io/vscode_c_install_introduce/","tags":[],"title":"Visaul Studio Code C++ 安装及使用"},{"categories":["Java","Spring","Youtube"],"contents":"15分钟学习Spring和MyBatis   ","permalink":"http://itcodingman.github.io/15_mins_spring_mybatis/","tags":[],"title":"15分钟学习Spring和MyBatis"},{"categories":["Python","BiliBili"],"contents":"jupyter notebook安装及使用 Jupyter Notebook是以网页的形式打开，可以在网页页面中直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示的程序。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。 \r","permalink":"http://itcodingman.github.io/jupyter_notebook_install_introduce/","tags":[],"title":"jupyter notebook安装及使用"},{"categories":["Java","Youtube"],"contents":"40分钟学习MyBatis   ","permalink":"http://itcodingman.github.io/40_mins_mybatis/","tags":[],"title":"40分钟学习MyBatis"},{"categories":["C++","BiliBili"],"contents":"100分钟学习C++ 这是一门针对初学者的完整课程，学习有关C++的所有知识。包括：语法、语句、字符串、操作符、函数、文件等 \r","permalink":"http://itcodingman.github.io/100_mins_c/","tags":[],"title":"100分钟学习C++"},{"categories":["Java","Spring","Youtube"],"contents":"40分钟学习Spring Boot Web   ","permalink":"http://itcodingman.github.io/40_mins_spring_boot_web/","tags":[],"title":"40分钟学习Spring Boot Web"},{"categories":["Python","BiliBili"],"contents":"15分钟学习Numpy的通用函数 这是一门针对初学者的完整课程，学习有关NumPy的通用函数知识。包括：ufunc、计算、连接、差分等 \r","permalink":"http://itcodingman.github.io/15_mins_numpy_ufunc/","tags":[],"title":"15分钟学习Numpy的通用函数"},{"categories":["Java","Spring","Youtube"],"contents":"30分钟学习Spring MVC和Thymeleaf   ","permalink":"http://itcodingman.github.io/30_mins_spring_mvc_thymeleaf/","tags":[],"title":"30分钟学习Spring MVC和Thymeleaf"},{"categories":["Python","BiliBili"],"contents":"15分钟学习NumPy和数据分布 这是一门针对初学者的完整课程，学习有关NumPy的数据分布知识。包括：随机数、正态分布、泊松分布等数据分布 \r","permalink":"http://itcodingman.github.io/15_mins_numpy_data_distribution/","tags":[],"title":"15分钟学习NumPy和数据分布"},{"categories":["Java","Youtube"],"contents":"50分钟学习Thymeleaf   ","permalink":"http://itcodingman.github.io/50_mins_thymeleaf/","tags":[],"title":"50分钟学习Thymeleaf"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和SciPy 这是一门针对初学者的完整课程，学习有关SciPy的所有知识。包括：常数、优化器、稀疏矩阵、图、空间数据、MatLib、统计等 \r","permalink":"http://itcodingman.github.io/30_mins_scipy/","tags":[],"title":"30分钟学习Python和SciPy"},{"categories":["Java","Youtube"],"contents":"40分钟学习JPA   ","permalink":"http://itcodingman.github.io/40_mins_jpa/","tags":[],"title":"40分钟学习JPA"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和NumPy 这是一门针对初学者的完整课程，学习有关NumPy的所有知识。包括：数组、索引、切片、连接、拆分、排序、查询等 \r","permalink":"http://itcodingman.github.io/30_mins_numpy/","tags":[],"title":"30分钟学习Python和NumPy"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring Data JPA   ","permalink":"http://itcodingman.github.io/10_mins_spring_data_jpa/","tags":[],"title":"10分钟学习Spring Data JPA"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和Matplotlib 这是一门针对初学者的完整课程，学习有关MatplotLib的所有知识。包括：绘图、标记、标签、网格、多图、散点图、柱状图、直方图、饼图等 \r","permalink":"http://itcodingman.github.io/30_mins_matplotlib/","tags":[],"title":"30分钟学习Python和Matplotlib"},{"categories":["Python","BiliBili"],"contents":"30分钟学习Python和Pandas Pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。 \r","permalink":"http://itcodingman.github.io/30_mins_pandas/","tags":[],"title":"30分钟学习Python和Pandas"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring JPA   ","permalink":"http://itcodingman.github.io/10_mins_spring_jpa/","tags":[],"title":"10分钟学习Spring JPA"},{"categories":["Python","BiliBili"],"contents":"100分钟学习Python 这是一门针对初学者的完整课程，学习有关Python的所有知识。包括：语法、语句、字符串、操作符、函数、文件等 \r","permalink":"http://itcodingman.github.io/100_mins_python/","tags":[],"title":"100分钟学习Python"},{"categories":["Java","Youtube"],"contents":"30分钟学习JDBC   ","permalink":"http://itcodingman.github.io/30_mins_jdbc/","tags":[],"title":"30分钟学习JDBC"},{"categories":["Python","BiliBili"],"contents":"一小时学习Python和Flask 这是一门针对初学者的完整课程，学习有关Flask的所有知识。包括：基础知识（路由、变量及URL规则、 模板、 静态文件、 重定向和错误 ）和高级知识（Cookies及会话、 消息闪现、 WTF表单、文件上传、 SQLAlchemy及数据库、Sjiax）。 \r","permalink":"http://itcodingman.github.io/1_hour_flask/","tags":[],"title":"一小时学习Python和Flask"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring Data JDBC   ","permalink":"http://itcodingman.github.io/10_mins_spring_data_jdbc/","tags":[],"title":"10分钟学习Spring Data JDBC"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring Boot JDBC   ","permalink":"http://itcodingman.github.io/10_mins_spring_boot_jdbc/","tags":[],"title":"10分钟学习Spring Boot JDBC"},{"categories":["Python","BiliBili"],"contents":"一小时学习Python和Mediapipe 这是一门针对初学者的完整课程，学习有关MediaPipe的所有知识。包括：人脸识别、匹配、手势、姿势、自拍背景等。 \r","permalink":"http://itcodingman.github.io/1_hour_python_mediapipe/","tags":[],"title":"一小时学习Python和Mediapipe"},{"categories":["Java","Spring","Youtube"],"contents":"40分钟学习Spring Boot Spring Boot 教程包括 Spring Boot 的所有主题，例如特性、项目、maven 项目、启动项目向导、Spring Initializr、CLI、应用程序、注释、依赖管理、属性、启动器、执行器等。   ","permalink":"http://itcodingman.github.io/40_mins_spring_boot/","tags":[],"title":"40分钟学习Spring Boot"},{"categories":["Python","BiliBili"],"contents":"一小时学习Python和OpenCV 这是一门针对初学者的完整课程，学习有关OpenCV的所有知识。包括：基础知识（图像和视频的读取、图像变换、图形绘制）和高级知识（色彩空间、位操作、直方图和边缘检测、滤波）。最后部分讲解人脸检测和识别 。 \r","permalink":"http://itcodingman.github.io/1_hour_python_opencv/","tags":[],"title":"一小时学习Python和OpenCV"},{"categories":["Python","Youtube"],"contents":"使用OpenCV和EasyOCR识别车牌   ","permalink":"http://itcodingman.github.io/opencv_easyocr_anpr/","tags":[],"title":"使用OpenCV和EasyOCR识别车牌"},{"categories":["Java","Spring","Youtube"],"contents":"30分钟学习Spring MVC #SpringMVC   ","permalink":"http://itcodingman.github.io/30_mins_spring_mvc_springmvc/","tags":[],"title":"30分钟学习Spring MVC #SpringMVC"},{"categories":["Python","Youtube"],"contents":"10分钟学习TesseractOCR   ","permalink":"http://itcodingman.github.io/10_mins_tesseractocr/","tags":[],"title":"10分钟学习TesseractOCR"},{"categories":["Python","Youtube"],"contents":"10分钟学习EasyOCR   ","permalink":"http://itcodingman.github.io/10_mins_easyocr/","tags":["EasyOCR","OCR"],"title":"10分钟学习EasyOCR"},{"categories":["Java","Youtube"],"contents":"maven安装和使用   ","permalink":"http://itcodingman.github.io/maven_install_introduce/","tags":[],"title":"maven安装和使用"},{"categories":["Java","Spring","Youtube"],"contents":"Spring Tools 4 安装和使用   ","permalink":"http://itcodingman.github.io/spring_tools_install_introduce/","tags":[],"title":"Spring Tools 4 安装和使用"},{"categories":["Java","Spring","Youtube"],"contents":"10分钟学习Spring JDBC   ","permalink":"http://itcodingman.github.io/10_mins_spring_jdbc/","tags":[],"title":"10分钟学习Spring JDBC"},{"categories":["Java","Spring","Youtube"],"contents":"45分钟学习Spring Framework   ","permalink":"http://itcodingman.github.io/45_mins_spring_framework/","tags":[],"title":"45分钟学习Spring Framework"},{"categories":["Java","Youtube"],"contents":"30分钟学习Struts2 Struts 2 教程涵盖了 Struts 2 Framework 的所有主题，并为初学者和有经验的人提供了简化的示例。   ","permalink":"http://itcodingman.github.io/30_mins_struts2/","tags":[],"title":"30分钟学习Struts2"},{"categories":["Python","Youtube"],"contents":"10分钟学习Opencv目标跟踪 Object Tracking Opencv目标跟踪 Object Tracking   ","permalink":"http://itcodingman.github.io/10_mins_opencv_object_tracking/","tags":[],"title":"10分钟学习Opencv目标跟踪 Object Tracking"},{"categories":["Java","Spring","Youtube"],"contents":"Visual Studio Code Spring Boot 的安装及使用 Visual Studio Code和Spring Boot的安装及使用   ","permalink":"http://itcodingman.github.io/vscode_spring_boot_install_introduce/","tags":[],"title":"Visual Studio Code Spring Boot 的安装及使用"},{"categories":["Java","Youtube"],"contents":"一小时学习Servlet 本教程将讲解如何使用 Java Servlet 来开发基于 web 的应用程序。   ","permalink":"http://itcodingman.github.io/1_hour_servlet/","tags":[],"title":"一小时学习Servlet"},{"categories":["Python","Youtube"],"contents":"conda的安装和使用、国内源、常用命令 conda的安装和使用、国内源、常用命令   ","permalink":"http://itcodingman.github.io/conda_install_introduce/","tags":[],"title":"conda的安装和使用、国内源、常用命令"},{"categories":["Python","Youtube"],"contents":"PIP安装和使用、国内源、常用命令 PIP安装和使用、国内源、常用命令   ","permalink":"http://itcodingman.github.io/pip_install_introduce/","tags":[],"title":"PIP安装和使用、国内源、常用命令"},{"categories":["Java","Youtube"],"contents":"50分钟学习JSP JSP教程主要提供JSP基础知识以及部分常用的JSP进阶知识，大家在学习JSP之前，需要具备一定的HTML及Java基础。   ","permalink":"http://itcodingman.github.io/50_mins_jsp/","tags":[],"title":"50分钟学习JSP"},{"categories":["Youtube"],"contents":"20分钟学习web技术 本课程将系统学习Web基础知识及常用功能   ","permalink":"http://itcodingman.github.io/20_mins_web/","tags":[],"title":"20分钟学习web技术"},{"categories":["BiliBili"],"contents":"20分钟学习web技术 本课程将系统学习Web基础知识及常用功能 \r","permalink":"http://itcodingman.github.io/20_mins_web/","tags":[],"title":"20分钟学习web技术"},{"categories":["Java","Youtube"],"contents":"Eclipse、Tomcat和Java Web的安装、配置及开发 Eclipse、Tomcat和Java Web的安装、配置及开发   ","permalink":"http://itcodingman.github.io/eclipse_tomcat_java_web_install_introduce/","tags":[],"title":"Eclipse、Tomcat和Java Web的安装、配置及开发"},{"categories":["Java","Youtube"],"contents":"Eclipse和Java的安装 Eclipse和Java的安装   ","permalink":"http://itcodingman.github.io/eclipse_java_install_introduce/","tags":[],"title":"Eclipse和Java的安装"},{"categories":["Java","Youtube"],"contents":"100分钟学习Java 这是一门针对初学者的完整课程，学习有关Java的所有知识。包括：语法、语句、字符串、操作符、函数、文件等   ","permalink":"http://itcodingman.github.io/100_mins_java/","tags":[],"title":"100分钟学习Java"},{"categories":["Java","Youtube"],"contents":"Visual Studio Code Java 的安装及使用 VisualStudioCode和Java的安装及使用   ","permalink":"http://itcodingman.github.io/vscode_java_install_introduce/","tags":[],"title":"Visual Studio Code Java 的安装及使用"},{"categories":["C++","Youtube"],"contents":"Visaul Studio Code C++ 安装及使用 Visaul Studio Code C++ 安装及使用   ","permalink":"http://itcodingman.github.io/vscode_c_install_introduce/","tags":[],"title":"Visaul Studio Code C++ 安装及使用"},{"categories":["Python","Youtube"],"contents":"jupyter notebook安装及使用 Jupyter Notebook是以网页的形式打开，可以在网页页面中直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示的程序。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。   ","permalink":"http://itcodingman.github.io/jupyter_notebook_install_introduce/","tags":[],"title":"jupyter notebook安装及使用"},{"categories":["C++","Youtube"],"contents":"100分钟学习C++ 这是一门针对初学者的完整课程，学习有关C++的所有知识。包括：语法、语句、字符串、操作符、函数、文件等   ","permalink":"http://itcodingman.github.io/100_mins_c/","tags":[],"title":"100分钟学习C++"},{"categories":["Python","Youtube"],"contents":"15分钟学习Numpy的通用函数 这是一门针对初学者的完整课程，学习有关NumPy的通用函数知识。包括：ufunc、计算、连接、差分等   ","permalink":"http://itcodingman.github.io/15_mins_numpy_ufunc/","tags":[],"title":"15分钟学习Numpy的通用函数"},{"categories":["Python","Youtube"],"contents":"15分钟学习NumPy和数据分布 这是一门针对初学者的完整课程，学习有关NumPy的数据分布知识。包括：随机数、正态分布、泊松分布等数据分布   ","permalink":"http://itcodingman.github.io/15_mins_numpy_data_distribution/","tags":[],"title":"15分钟学习NumPy和数据分布"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和SciPy 这是一门针对初学者的完整课程，学习有关SciPy的所有知识。包括：常数、优化器、稀疏矩阵、图、空间数据、MatLib、统计等   ","permalink":"http://itcodingman.github.io/30_mins_scipy/","tags":[],"title":"30分钟学习Python和SciPy"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和NumPy 这是一门针对初学者的完整课程，学习有关NumPy的所有知识。包括：数组、索引、切片、连接、拆分、排序、查询等   ","permalink":"http://itcodingman.github.io/30_mins_numpy/","tags":[],"title":"30分钟学习Python和NumPy"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和Matplotlib 这是一门针对初学者的完整课程，学习有关MatplotLib的所有知识。包括：绘图、标记、标签、网格、多图、散点图、柱状图、直方图、饼图等   ","permalink":"http://itcodingman.github.io/30_mins_matplotlib/","tags":[],"title":"30分钟学习Python和Matplotlib"},{"categories":["Python","Youtube"],"contents":"100分钟学习Python 这是一门针对初学者的完整课程，学习有关Python的所有知识。包括：语法、语句、字符串、操作符、函数、文件等   ","permalink":"http://itcodingman.github.io/100_mins_python/","tags":[],"title":"100分钟学习Python"},{"categories":["Python","Youtube"],"contents":"30分钟学习Python和Pandas Pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。   ","permalink":"http://itcodingman.github.io/30_mins_pandas/","tags":[],"title":"30分钟学习Python和Pandas"},{"categories":["Python","Youtube"],"contents":"一小时学习Python和Mediapipe 这是一门针对初学者的完整课程，学习有关MediaPipe的所有知识。包括：人脸识别、匹配、手势、姿势、自拍背景等。   ","permalink":"http://itcodingman.github.io/1_hour_python_mediapipe/","tags":[],"title":"一小时学习Python和Mediapipe"},{"categories":["Python"],"contents":"一小时学习python和flask 这是一门针对初学者的完整课程，学习有关Flask的所有知识。包括：基础知识（路由、变量及URL规则、 模板、 静态文件、重定向和错误 ）和高级知识（Cookies及会话、 消息闪现、 WTF表单、文件上传、 SQLAlchemy及数据库、Sjiax）。   ","permalink":"http://itcodingman.github.io/1_hour_python_flask/","tags":["Python","Flask"],"title":"一小时学习python和flask"},{"categories":["Python","Youtube"],"contents":"一小时学习Python和Flask 这是一门针对初学者的完整课程，学习有关Flask的所有知识。包括：基础知识（路由、变量及URL规则、 模板、 静态文件、 重定向和错误 ）和高级知识（Cookies及会话、 消息闪现、 WTF表单、文件上传、 SQLAlchemy及数据库、Sjiax）。   ","permalink":"http://itcodingman.github.io/1_hour_flask/","tags":[],"title":"一小时学习Python和Flask"},{"categories":["Python","Youtube"],"contents":"一小时学习Python和OpenCV 这是一门针对初学者的完整课程，学习有关OpenCV的所有知识。包括：基础知识（图像和视频的读取、图像变换、图形绘制）和高级知识（色彩空间、位操作、直方图和边缘检测、滤波）。最后部分讲解人脸检测和识别 。   ","permalink":"http://itcodingman.github.io/1_hour_python_opencv/","tags":[],"title":"一小时学习Python和OpenCV"},{"categories":["Jakarta EE"],"contents":"1. 概述 Velocity是一个基于 Java 的模板引擎。 它是一个开源 Web 框架，旨在用作 MVC 架构中的视图组件，它提供了一些现有技术（如 JSP）的替代方案。 Velocity 可用于生成 XML 文件、SQL、PostScript 和大多数其他基于文本的格式。 在本文中，我们将探讨如何使用它来创建动态网页。 2. Velocity是如何工作的 Velocity 的核心类是VelocityEngine。 它使用数据模型和速度模板编排读取、解析和生成内容的整个过程。 简而言之，对于任何典型的速度应用程序，我们需要遵循以下步骤：  初始化Velocity引擎 读入模板 将数据模型放入上下文对象中 将模板与上下文数据合并并渲染视图  让我们按照这些简单的步骤来看一个示例： VelocityEngine velocityEngine = new VelocityEngine(); velocityEngine.init(); Template t = velocityEngine.getTemplate(\u0026#34;index.vm\u0026#34;); VelocityContext context = new VelocityContext(); context.put(\u0026#34;name\u0026#34;, \u0026#34;World\u0026#34;); StringWriter writer = new StringWriter(); t.merge( context, writer ); 3. Maven依赖 要使用 Velocity，我们需要在 Maven 项目中添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.velocity\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;velocity\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.velocity\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;velocity-tools\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这两个依赖项的最新版本可以在这里：velocity和velocity-tools。 4. Velocity模板语言 Velocity 模板语言 (VTL) 通过使用 VTL 引用提供了将动态内容合并到网页中的最简单和最干净的方法。 速度模板中的 VTL 引用以*$开头，用于获取与该引用关联的值。VTL 还提供了一组指令，可用于操作 Java 代码的输出。这些指令以# 开头。* 4.1 参考 Velocity 中有三种类型的引用，变量，属性和方法：  变量——在页面中使用*#set*指令或从 Java 对象的字段返回的值定义：  #set ($message=\u0026#34;Hello World\u0026#34;)  属性——引用对象中的字段；它们还可以引用属性的getter方法：  $customer.name  方法– 指 Java 对象上的方法：  $customer.getName() 每个引用产生的最终值在呈现到最终输出时都会转换为字符串。 4.2. 指令 VTL 提供了丰富的指令集：  set – 可用于设置参考值；此值可以分配给变量或属性引用：  #set ($message = \u0026#34;Hello World\u0026#34;) #set ($customer.name = \u0026#34;Brian Mcdonald\u0026#34;)  条件—— #if、#elseif和*#else*指令提供了一种基于条件检查生成内容的方法：  #if($employee.designation == \u0026#34;Manager\u0026#34;) \u0026lt;h3\u0026gt; Manager \u0026lt;/h3\u0026gt; #elseif($employee.designation == \u0026#34;Senior Developer\u0026#34;) \u0026lt;h3\u0026gt; Senior Software Engineer \u0026lt;/h3\u0026gt; #else \u0026lt;h3\u0026gt; Trainee \u0026lt;/h3\u0026gt; #end  loops – #foreach指令允许循环对象集合：  \u0026lt;ul\u0026gt; #foreach($product in $productList) \u0026lt;li\u0026gt; $product \u0026lt;/li\u0026gt; #end \u0026lt;/ul\u0026gt;  include - #include元素提供将文件导入模板的能力：  #include(\u0026#34;one.gif\u0026#34;,\u0026#34;two.txt\u0026#34;,\u0026#34;three.html\u0026#34;...)  parse – #parse语句允许模板设计者导入另一个包含 VTL 的本地文件；然后 Velocity 将解析内容并呈现它：  #parse (Template)  evaluate– #evaluate指令可用于动态评估 VTL；这允许模板在渲染时评估字符串，例如国际化模板：  #set($firstName = \u0026#34;David\u0026#34;) #set($lastName = \u0026#34;Johnson\u0026#34;) #set($dynamicsource = \u0026#34;$firstName$lastName\u0026#34;) #evaluate($dynamicsource)  break - #break指令停止当前执行范围的任何进一步呈现（即*#foreach*，#parse） stop – #stop指令停止模板的任何进一步渲染和执行。 velocimacros – #macro指令允许模板设计者定义 VTL 的重复段：  #macro(tablerows) \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; #end *这个宏现在可以作为#tablerows()*放在模板中的任何位置： #macro(tablerows $color $productList) #foreach($product in $productList) \u0026lt;tr\u0026gt; \u0026lt;td bgcolor=$color\u0026gt;$product.name\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; #end #end 4.3. 其它功能  math – 一些内置的数学函数，可以在模板中使用：  #set($percent = $number / 100) #set($remainder = $dividend % $divisor)  范围运算符– 可以与*#set和#foreach 结合使用：*  #set($array = [0..10]) #foreach($elem in $arr) $elem #end 5. Velocity Servlet程序 Velocity Engine 的主要工作是根据模板生成内容。 引擎本身不包含任何与网络相关的功能。要实现 Web 应用程序，我们需要使用 servlet 或基于 servlet 的框架。 Velocity 提供了一个开箱即用的实现VelocityViewServlet，它是velocity-tools 子项目的一部分。 为了利用VelocityViewServlet提供的内置功能，我们可以从VelocityViewServlet扩展我们的 servlet并覆盖*handleRequest()*方法： public class ProductServlet extends VelocityViewServlet { ProductService service = new ProductService(); @Override public Template handleRequest( HttpServletRequest request, HttpServletResponse response, Context context) throws Exception { List\u0026lt;Product\u0026gt; products = service.getProducts(); context.put(\u0026#34;products\u0026#34;, products); return getTemplate(\u0026#34;index.vm\u0026#34;); } } 6.配置 6.1 网页配置 现在让我们看看如何在web.xml中配置**VelocityViewServlet。 我们需要指定可选的初始化参数，包括velocity.properties和toolbox.xml： \u0026lt;web-app\u0026gt; \u0026lt;display-name\u0026gt;apache-velocity\u0026lt;/display-name\u0026gt; //... \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;velocity\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.apache.velocity.tools.view.VelocityViewServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;org.apache.velocity.properties\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/velocity.properties\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; //... \u0026lt;/web-app\u0026gt; 我们还需要为这个 servlet 指定映射。所有对速度模板 ( *.vm ) 的请求都需要由速度 servlet 提供服务： \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;velocityLayout\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.vm\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 6.2. 资源加载器 Velocity 提供灵活的资源加载系统。它允许一个或多个资源加载器同时运行：  文件资源加载器 JarResourceLoader 类路径资源加载器 URL资源加载器 数据源资源加载器 WebappResourceLoader  这些资源加载器在velocity.properties 中配置： resource.loader=webapp webapp.resource.loader.class=org.apache.velocity.tools.view.WebappResourceLoader webapp.resource.loader.path = webapp.resource.loader.cache = true 7. Velocity模板 Velocity 模板是编写所有视图生成逻辑的地方。这些页面是使用 Velocity 模板语言 (VTL) 编写的： \u0026lt;html\u0026gt; ... \u0026lt;body\u0026gt; \u0026lt;center\u0026gt; ... \u0026lt;h2\u0026gt;$products.size() Products on Sale!\u0026lt;/h2\u0026gt; \u0026lt;br/\u0026gt; We are proud to offer these fine products at these amazing prices. ... #set( $count = 1 ) \u0026lt;table class=\u0026#34;gridtable\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Serial #\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Product Name\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Price\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; #foreach( $product in $products ) \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;$count)\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;$product.getName()\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;$product.getPrice()\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; #set( $count = $count + 1 ) #end \u0026lt;/table\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 8. 管理页面布局 Velocity 为基于 Velocity Tool 的应用程序提供了简单的布局控制和可定制的错误屏幕。 VelocityLayoutServlet封装了此功能以呈现指定的布局。VelocityLayoutServlet是 VelocityViewServlet 的扩展*。* 8.1 网页配置 让我们看看如何配置VelocityLayoutServlet。servlet 被定义用于拦截速度模板页面的请求，并且布局特定属性在velocity.properties文件中定义： \u0026lt;web-app\u0026gt; // ... \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;velocityLayout\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.apache.velocity.tools.view.VelocityLayoutServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;org.apache.velocity.properties\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/velocity.properties\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; // ... \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;velocityLayout\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.vm\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; // ... \u0026lt;/web-app\u0026gt; 8.2. 布局模板 布局模板定义了速度页面的典型结构。默认情况下，VelocityLayoutServlet在布局文件夹下搜索Default.vm 。覆盖少数属性可以更改此位置： tools.view.servlet.layout.directory = layout/ tools.view.servlet.layout.default.template = Default.vm 布局文件由页眉模板、页脚模板和一个速度变量*$screen_content 组成*，它呈现请求的速度页面的内容： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Velocity\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; #parse(\u0026#34;/fragments/header.vm\u0026#34;) \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;!-- View index.vm is inserted here --\u0026gt; $screen_content \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; #parse(\u0026#34;/fragments/footer.vm\u0026#34;) \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 8.3. 请求屏幕中的布局规范 特定屏幕的布局可以定义为页面开头的速度变量。这是通过将这一行放在页面中来完成的： #set($layout = \u0026#34;MyOtherLayout.vm\u0026#34;) 8.4. 请求参数中的布局规范 我们可以在查询字符串layout=MyOtherLayout.vm中添加一个请求参数，VLS 会找到它并在该布局内渲染屏幕，而不是搜索默认布局。 8.5 错误屏幕 可以使用速度布局实现自定义错误屏幕。VelocityLayoutServlet提供了两个变量*$error_cause和$stack_trace*来呈现异常细节。 错误页面可以在velocity.properties文件中配置： tools.view.servlet.error.template = Error.vm \u0026quot; ","permalink":"http://itcodingman.github.io/apache_velocity/","tags":[],"title":"Apache Velocity 简介"},{"categories":["Security","Spring"],"contents":"1. 概述 在本文中，我们将了解 Tomcat 服务器基础知识、它的工作原理以及如何启用 Tomcat 的单点登录 ( SSO ) 功能。我们将探索 Tomcat 服务器和 Web 应用程序所需的配置。 2.Tomcat架构 构成 Catalina servlet 容器的主要部分是包含定义连接器的服务和由主机构建的引擎的服务器，最后，这些主机将包含上下文或 Web 应用程序。 连接器侦听客户端的请求并发送回响应。在 Tomcat 10 中，我们可以找到以下协议的连接器：HTTP/1.1、HTTP/2和AJP。 引擎将处理连接器收到的请求并生成输出。它将包含一个 处理管道，这是一个进程链，每个请求都会执行以产生响应。这些过程就是 Tomcat 的阀门。例如，Tomcat 上的 SSO 是作为阀门实现的。 之后，我们找到将定义将网络名称与服务器相关联的虚拟主机的主机。这是定义 SSO 阀的级别，因此主机的所有上下文都将位于 SSO 之下。 最后，我们将拥有与主机关联的上下文元素。这些上下文是将在服务器上运行的 Web 应用程序。上下文必须遵循 servlet 规范 2.3 或更高版本。 3. Tomcat 单点登录 Tomcat 在必须在主机级别配置的 Valve 中实现单点登录功能。它的工作方式是 SSO 阀门将存储用户凭据并在需要时传递它们，因此用户无需再次登录。 SSO 阀需要满足以下要求：  Realm或“用户数据库”必须由虚拟主机下的所有 Web 应用程序共享。 Web 应用程序身份验证机制必须是标准身份验证器之一：Basic、Digest、Form、SSL或SPNEGO。 当客户端请求受保护的资源时，服务器将执行 Web 应用程序的身份验证机制。 服务器将使用经过身份验证的用户的角色访问虚拟主机下的 Web 应用程序的受保护资源，而无需再次登录。 当用户退出 Web 应用程序时，服务器将使所有 Web 应用程序中的用户会话无效。 客户端必须接受 cookie。cookie 存储将请求与用户凭据相关联的令牌。  3.1 Tomcat 服务器配置 在服务器端，我们需要配置SingleSignOn阀门和领域或“用户数据库”。这些配置在 Tomcat 安装的 conf 文件夹下的 server.xml 文件中。要添加 SSO 阀，我们需要取消注释以下行： \u0026lt;Valve className=\u0026#34;org.apache.catalina.authenticator.SingleSignOn\u0026#34; /\u0026gt; 对于本文的示例，我们将依赖默认配置的 Realm，我们只需要将用户添加到数据库中。领域定义如下所示： \u0026lt;Realm className=\u0026#34;org.apache.catalina.realm.UserDatabaseRealm\u0026#34; resourceName=\u0026#34;UserDatabase\u0026#34;/\u0026gt; 此配置使用全局 JNDI 资源来定义用户数据库的来源： \u0026lt;Resource name=\u0026#34;UserDatabase\u0026#34; auth=\u0026#34;Container\u0026#34; type=\u0026#34;org.apache.catalina.UserDatabase\u0026#34; description=\u0026#34;User database that can be updated and saved\u0026#34; factory=\u0026#34;org.apache.catalina.users.MemoryUserDatabaseFactory\u0026#34; pathname=\u0026#34;conf/tomcat-users.xml\u0026#34; /\u0026gt; 该资源将实例化一个 org.apache.catalina.UserDatabase 类型的对象，并将使用工厂类**org.apache.catalina.users.MemoryUserDatabaseFactory从 tomcat-users.xml 文件中填充它 。 最后，在这里我们看看如何添加一个具有文章示例所需的管理员角色的用户。我们需要修改tomcat-users.xml文件： \u0026lt;tomcat-users xmlns=\u0026#34;http://tomcat.apache.org/xml\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://tomcat.apache.org/xml tomcat-users.xsd\u0026#34; version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;role rolename=\u0026#34;admin\u0026#34;/\u0026gt; \u0026lt;user username=\u0026#34;demo\u0026#34; password=\u0026#34;demo\u0026#34; roles=\u0026#34;admin\u0026#34;/\u0026gt; \u0026lt;/tomcat-users\u0026gt; 3.2. Web 应用程序配置 一旦我们配置了服务器，让我们通过每个 servlet 的 WEB-INF 文件夹中的 web.xml 配置文件来配置 servlet。 所有需要 SSO 的 Web 应用程序都必须具有受保护的资源并使用一种 Tomcat 身份验证方法。正如 Servlet API 规范 2.3 中定义的那样，Web 应用程序的身份验证机制在web-app元素内的 login-config 元素中定义。此元素将包含需要使用以下值之一的身份验证方法表单：BASIC、DIGEST、FORM 或 CLIENT-CERT。每种身份验证方法都有不同的配置，但我们将在Tomcat Web 应用程序配置部分仅讨论 DIGEST 和 FORM 身份验证方法。 要完成 Web 应用配置，我们需要设置保护区。在 web-app 元素下的 web.xml 文件中，我们可以根据需要添加任意数量的安全约束元素。每个安全约束都定义了受保护资源的 URL 模式，并将设置允许的角色。此外，我们需要为所有角色定义安全角色元素，并且它们必须与 tomcat-users.xml 文件中的定义相匹配。我们将在下一节中看到一个示例。 4. 示例认证机制 现在我们知道如何配置 Web 应用程序，让我们看两个示例：Ping 和 Pong。我们选择了不同的身份验证机制来证明 SSO 可以很好地与不同的机制配合使用。 4.1 Ping 认证机制 在 ping web 应用程序中，我们使用 FORM 身份验证方法。FORM认证方式需要登录表单，网页登录失败。例如，当我们想要将登录页面自定义为 Web 应用程序时，此方法将很有用，配置如下所示： \u0026lt;login-config\u0026gt; \u0026lt;auth-method\u0026gt;FORM\u0026lt;/auth-method\u0026gt; \u0026lt;form-login-config\u0026gt; \u0026lt;form-login-page\u0026gt;/logging.html\u0026lt;/form-login-page\u0026gt; \u0026lt;form-error-page\u0026gt;/logging_error.html\u0026lt;/form-error-page\u0026gt; \u0026lt;/form-login-config\u0026gt; \u0026lt;/login-config\u0026gt; **登录页面必须遵循 servlet 规范 2.3 的登录表单注释中定义的一些严格规则，**因为我们既不能选择表单名称，也不能选择输入字段。它们必须是j_security_check、 j_username和j_password。这是为了实现登录表单与各种资源一起使用，并且无需在服务器中配置出站表单的操作字段。在这里，我们可以看到它必须是什么样子的示例： \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Ping - Login\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;j_security_check\u0026#34;\u0026gt; \u0026lt;table \u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;User name: \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;j_username\u0026#34; size=\u0026#34;20\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Password: \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;j_password\u0026#34; size=\u0026#34;20\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;reset\u0026#34; value=\u0026#34;Reset\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 为了理解服务器收到来自 FORM 认证的 Web 应用的受保护资源的请求时会发生什么，让我们总结一下这种认证机制的流程。 首先，客户端请求一个受保护的资源。如果服务器不包含有效的 SSO 会话 ID，则服务器会将客户端重定向到日志记录表单。用户填写表单并将其凭据发送到服务器后，身份验证机制将启动。 用户认证成功后，服务器会检查用户的角色，如果安全约束至少允许其中之一，服务器会将客户端重定向到请求的 URL。在另一种情况下，服务器会将客户端重定向到错误页面。 4.2. 认证机制 在 Pong Web 应用程序中，我们使用 DIGEST 身份验证机制，配置将如下所示： \u0026lt;login-config\u0026gt; \u0026lt;auth-method\u0026gt;DIGEST\u0026lt;/auth-method\u0026gt; \u0026lt;/login-config\u0026gt; **DIGEST 身份验证机制流程类似于 BASIC 身份验证：**当客户端请求受保护的资源时，服务器返回一个对话框以请求用户凭据。如果认证成功，则服务器返回请求的资源，但在另一种情况下，服务器再次发送认证对话框。 尽管 DIGEST 和 BASIC 身份验证方法相似，但有一个重要区别：密码保留在服务器中。 4.3. Web 应用安全约束配置 在这一点上，我们不打算区分 Ping 和 Pong。尽管它们具有不同值的元素，但配置的重要部分在两个应用程序中将保持不变： \u0026lt;security-constraint\u0026gt; \u0026lt;display-name\u0026gt;Ping Login Auth\u0026lt;/display-name\u0026gt; \u0026lt;web-resource-collection\u0026gt; \u0026lt;web-resource-name\u0026gt;PingRestrictedAccess\u0026lt;/web-resource-name\u0026gt; \u0026lt;url-pattern\u0026gt;/private/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/web-resource-collection\u0026gt; \u0026lt;auth-constraint\u0026gt; \u0026lt;role-name\u0026gt;admin\u0026lt;/role-name\u0026gt; \u0026lt;/auth-constraint\u0026gt; \u0026lt;user-data-constraint\u0026gt; \u0026lt;transport-guarantee\u0026gt;NONE\u0026lt;/transport-guarantee\u0026gt; \u0026lt;/user-data-constraint\u0026gt; \u0026lt;/security-constraint\u0026gt; 安全约束定义私有文件夹下的所有内容都是受保护的资源，并且还定义了需要具有管理员角色才能访问资源。 5. 运行示例 现在我们需要安装一个Tomcat 10服务器，按照文章前面所示调整配置，将 Ping 和 Pong web 应用程序放在 Tomcat 的 web 应用程序文件夹下。 一旦服务器启动并运行，并且两个应用程序都已部署，请求资源 http://localhost:8080/ping/private。 服务器将显示登录身份验证，因为我们没有登录： 然后我们需要引入Tomcat服务器配置部分配置的凭据并提交表单。如果服务器验证了凭据，那么我们将看到一个网页，其中包含指向 pong 私有部分的链接： 如果服务器不验证访问，我们将看到登录错误页面。 成功登录 Ping 应用程序后，我们可以看到 SSO 机制正在运行，单击指向 pong 私有部分的链接。如果会话已经处于活动状态，服务器将发送 Pong 的受保护资源，而无需我们再次登录。 最后，我们可以检查会话过期后，服务器会再次显示登录页面。我们可以通过等待几分钟并单击指向 ping 私人部分的链接来做到这一点。 6. 其他 SSO 解决方案 在本文中，我们介绍了 Tomcat 服务器实现的 Web-SSO。如果我们想探索其他 SSO 选项，这里有一些流行的选项：  Spring Security 和 OpenID Connect 带有KeyCloak的 Spring Security OAuth 带有 Spring Security 的 SAML Apereo 中央认证服务 \u0026quot;  ","permalink":"http://itcodingman.github.io/apache_tomcat_sso/","tags":[],"title":"使用 Apache Tomcat 的 SSO"},{"categories":["Data"],"contents":"1. 概述 Apache Tika是一个工具包，用于从各种类型的文档中提取内容和元数据，例如 Word、Excel 和 PDF，甚至是 JPEG 和 MP4 等多媒体文件。 所有基于文本的和多媒体文件都可以使用一个通用界面进行解析，使 Tika 成为一个功能强大且用途广泛的内容分析库。 在本文中，我们将介绍 Apache Tika，包括它的解析 API 以及它如何自动检测文档的内容类型。还将提供工作示例来说明该库的操作。 2. 入门 为了使用 Apache Tika 解析文档，我们只需要一个 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tika\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tika-parsers\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到此工件的最新版本。 3. Parser API Parser API 是 Apache Tika 的核心，抽象出解析操作的复杂性。此 API 依赖于一个方法： void parse( InputStream stream, ContentHandler handler, Metadata metadata, ParseContext context) throws IOException, SAXException, TikaException 该方法的参数含义如下：  stream —— 从要解析的文档创建的InputStream实例 handler —— 一个ContentHandler对象，接收从输入文档解析的一系列 XHTML SAX 事件；然后，此处理程序将处理事件并以特定形式导出结果 metadata —— 一个Metadata对象，在解析器内外传递元数据属性 context —— 一个ParseContext实例，携带特定于上下文的信息，用于自定义解析过程  如果无法从输入流中读取，则 parse 方法抛出 IOException，如果无法解析从流中获取的文档，则抛出 TikaException ，如果处理程序无法处理事件，则抛出SAXException 。 在解析文档时，Tika 会尽可能地重用现有的解析器库，例如 Apache POI 或 PDFBox。因此，大多数Parser实现类只是这些外部库的适配器。 在第 5 节中，我们将了解如何使用处理程序和元数据参数来提取文档的内容和元数据。 为方便起见，我们可以使用外观类Tika来访问Parser API 的功能。 4. 自动检测 Apache Tika 可以根据文档本身而不是附加信息自动检测文档的类型及其语言。 4.1 文档类型检测 文档类型的检测可以使用Detector接口的实现类来完成，它有一个方法： MediaType detect(java.io.InputStream input, Metadata metadata) throws IOException 此方法获取一个文档及其关联的元数据，然后返回一个MediaType对象，该对象描述有关文档类型的最佳猜测。 元数据并不是检测器所依赖的唯一信息来源。检测器还可以使用魔术字节，这是文件开头附近的一种特殊模式，或者将检测过程委托给更合适的检测器。 事实上，检测器使用的算法是依赖于实现的。 例如，默认检测器首先使用魔术字节，然后是元数据属性。如果此时还没有找到内容类型，它将使用服务加载器来发现所有可用的检测器并依次尝试它们。 4.2. 语言检测 除了文档的类型，即使没有元数据信息的帮助，Tika 也可以识别其语言。 在以前的 Tika 版本中，使用LanguageIdentifier实例检测文档的语言。 但是，LanguageIdentifier已被弃用，取而代之的是 Web 服务，这在Getting Started文档中没有明确说明。 现在通过抽象类LanguageDetector的子类型提供语言检测服务。使用网络服务，您还可以访问成熟的在线翻译服务，例如谷歌翻译或微软翻译。 为简洁起见，我们不会详细介绍这些服务。 5. Tika在行动 本节使用工作示例说明 Apache Tika 功能。 插图方法将包装在一个类中： public class TikaAnalysis { // illustration methods } 5.1 检测文档类型 下面是我们可以用来检测从InputStream读取的文档类型的代码： public static String detectDocTypeUsingDetector(InputStream stream) throws IOException { Detector detector = new DefaultDetector(); Metadata metadata = new Metadata(); MediaType mediaType = detector.detect(stream, metadata); return mediaType.toString(); } 假设我们在类路径中有一个名为tika.txt的 PDF 文件。该文件的扩展名已更改以试图欺骗我们的分析工具。通过测试仍然可以找到并确认文档的真实类型： @Test public void whenUsingDetector_thenDocumentTypeIsReturned() throws IOException { InputStream stream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;tika.txt\u0026#34;); String mediaType = TikaAnalysis.detectDocTypeUsingDetector(stream); assertEquals(\u0026#34;application/pdf\u0026#34;, mediaType); stream.close(); } 很明显，错误的文件扩展名无法阻止 Tika 找到正确的媒体类型，这要归功于文件开头的魔术字节*%PDF 。* 为方便起见，我们可以使用Tika门面类重新编写检测代码，结果相同： public static String detectDocTypeUsingFacade(InputStream stream) throws IOException { Tika tika = new Tika(); String mediaType = tika.detect(stream); return mediaType; } 5.2. 提取内容 现在让我们提取文件的内容并将结果作为字符串返回——使用Parser API： public static String extractContentUsingParser(InputStream stream) throws IOException, TikaException, SAXException { Parser parser = new AutoDetectParser(); ContentHandler handler = new BodyContentHandler(); Metadata metadata = new Metadata(); ParseContext context = new ParseContext(); parser.parse(stream, handler, metadata, context); return handler.toString(); } 给定类路径中包含以下内容的 Microsoft Word 文件： Apache Tika - a content analysis toolkit The Apache Tika™ toolkit detects and extracts metadata and text ... 内容可以提取和验证： @Test public void whenUsingParser_thenContentIsReturned() throws IOException, TikaException, SAXException { InputStream stream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;tika.docx\u0026#34;); String content = TikaAnalysis.extractContentUsingParser(stream); assertThat(content, containsString(\u0026#34;Apache Tika - a content analysis toolkit\u0026#34;)); assertThat(content, containsString(\u0026#34;detects and extracts metadata and text\u0026#34;)); stream.close(); } 同样，使用Tika类可以更方便地编写代码： public static String extractContentUsingFacade(InputStream stream) throws IOException, TikaException { Tika tika = new Tika(); String content = tika.parseToString(stream); return content; } 5.3. 提取元数据 除了文档的内容，Parser API 还可以提取元数据： public static Metadata extractMetadatatUsingParser(InputStream stream) throws IOException, SAXException, TikaException { Parser parser = new AutoDetectParser(); ContentHandler handler = new BodyContentHandler(); Metadata metadata = new Metadata(); ParseContext context = new ParseContext(); parser.parse(stream, handler, metadata, context); return metadata; } 当类路径中存在 Microsoft Excel 文件时，此测试用例确认提取的元数据是正确的： @Test public void whenUsingParser_thenMetadataIsReturned() throws IOException, TikaException, SAXException { InputStream stream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;tika.xlsx\u0026#34;); Metadata metadata = TikaAnalysis.extractMetadatatUsingParser(stream); assertEquals(\u0026#34;org.apache.tika.parser.DefaultParser\u0026#34;, metadata.get(\u0026#34;X-Parsed-By\u0026#34;)); assertEquals(\u0026#34;Microsoft Office User\u0026#34;, metadata.get(\u0026#34;Author\u0026#34;)); stream.close(); } 最后，这是使用Tika外观类的另一个版本的提取方法： public static Metadata extractMetadatatUsingFacade(InputStream stream) throws IOException, TikaException { Tika tika = new Tika(); Metadata metadata = new Metadata(); tika.parse(stream, metadata); return metadata; } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_tika/","tags":[],"title":"使用 Apache Tika 进行内容分析"},{"categories":["Data"],"contents":"1. 概述 在本文中，我们将了解如何借助名为Apache Thrift的 RPC 框架开发跨平台的客户端-服务器应用程序。 我们将涵盖：  使用 IDL 定义数据类型和服务接口 安装库并生成不同语言的源代码 以特定语言实现定义的接口 实施客户端/服务器软件  如果您想直接看示例，请直接进入第 5 节。 2. Apache Thrift Apache Thrift 最初由 Facebook 开发团队开发，目前由 Apache 维护。 与管理跨平台对象序列化/反序列化过程的Protocol Buffers相比， Thrift 主要关注系统组件之间的通信层。 Thrift 使用一种特殊的接口描述语言 (IDL) 来定义数据类型和服务接口，这些数据类型和服务接口存储为*.thrift*文件，稍后用作编译器的输入，用于生成通过不同编程语言进行通信的客户端和服务器软件的源代码。 要在您的项目中使用 Apache Thrift，请添加以下 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.thrift\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;libthrift\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.10.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以在Maven 存储库中找到最新版本。 3.界面描述语言 如前所述，IDL允许以中性语言定义通信接口。您将在下面找到当前支持的类型。 3.1 基本类型  bool – 一个布尔值（真或假） byte – 一个 8 位有符号整数 i16 – 16 位有符号整数 i32 – 32 位有符号整数 i64 – 64 位有符号整数 double – 64 位浮点数 string – 使用 UTF-8 编码编码的文本字符串  3.2. 特殊类型  二进制- 未编码的字节序列 optional – Java 8 的可选类型  3.3. 结构 Thrift结构相当于 OOP 语言中的类，但没有继承。结构有一组强类型字段，每个字段都有一个唯一的名称作为标识符。字段可能有各种注释（数字字段 ID、可选的默认值等）。 3.4. 容器 Thrift 容器是强类型容器：  list – 元素的有序列表 set – 一组无序的唯一元素 map\u0026lt;type1,type2\u0026gt; – 值的严格唯一键映射  容器元素可以是任何有效的 Thrift 类型。 3.5. 例外 异常在功能上等同于structs，只是它们继承自本机异常。 3.6. 服务 服务实际上是使用 Thrift 类型定义的通信接口。它们由一组命名函数组成，每个函数都有一个参数列表和一个返回类型。 4. 源代码生成 4.1 语言支持 当前支持的语言有一长串：  C++ C＃ Go Java Javascript Node.js Perl PHP Python Ruby  您可以在此处查看完整列表。 4.2. 使用库的可执行文件 只需下载最新版本，如有必要，构建并安装它，并使用以下语法： cd path/to/thrift thrift -r --gen [LANGUAGE] [FILENAME] 在上面设置的命令中，[LANGUAGE]是支持的语言之一，[FILENAME ] 是具有 IDL 定义的文件。 注意*-r标志。它告诉 Thrift 一旦注意到包含在给定的.thrift*文件中，就递归地生成代码。 4.3. 使用 Maven 插件 在pom.xml文件中添加插件： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.thrift.tools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-thrift-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.1.11\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;thriftExecutable\u0026gt;path/to/thrift\u0026lt;/thriftExecutable\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;thrift-sources\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;generate-sources\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;compile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 之后只需执行以下命令： mvn clean install 请注意，此插件将不再有任何进一步的维护。请访问此页面了解更多信息。 5. 客户端-服务器应用程序示例 5.1 定义 Thrift 文件 让我们编写一些带有异常和结构的简单服务： namespace cpp com.codingman.thrift.impl namespace java com.codingman.thrift.impl exception InvalidOperationException { 1: i32 code, 2: string description } struct CrossPlatformResource { 1: i32 id, 2: string name, 3: optional string salutation } service CrossPlatformService { CrossPlatformResource get(1:i32 id) throws (1:InvalidOperationException e), void save(1:CrossPlatformResource resource) throws (1:InvalidOperationException e), list \u0026lt;CrossPlatformResource\u0026gt; getList() throws (1:InvalidOperationException e), bool ping() throws (1:InvalidOperationException e) } 如您所见，语法非常简单且不言自明。我们定义了一组命名空间（每种实现语言）、一个异常类型、一个结构，最后是一个服务接口，这些接口将在不同的组件之间共享。 然后将其存储为service.thrift文件。 5.2. 编译和生成代码 现在是时候运行一个编译器来为我们生成代码了： thrift -r -out generated --gen java /path/to/service.thrift 如您所见，我们添加了一个特殊标志*-out*来指定生成文件的输出目录。如果您没有收到任何错误，生成的目录将包含 3 个文件：  CrossPlatformResource.java CrossPlatformService.java InvalidOperationException.java  让我们通过运行以下命令生成服务的 C++ 版本： thrift -r -out generated --gen cpp /path/to/service.thrift 现在我们得到相同服务接口的 2 个不同的有效实现（Java 和 C++）。 5.3. 添加服务实现 尽管 Thrift 为我们完成了大部分工作，但我们仍然需要编写自己的CrossPlatformService实现。为此，我们只需要实现一个CrossPlatformService.Iface接口： public class CrossPlatformServiceImpl implements CrossPlatformService.Iface { @Override public CrossPlatformResource get(int id) throws InvalidOperationException, TException { return new CrossPlatformResource(); } @Override public void save(CrossPlatformResource resource) throws InvalidOperationException, TException { saveResource(); } @Override public List\u0026lt;CrossPlatformResource\u0026gt; getList() throws InvalidOperationException, TException { return Collections.emptyList(); } @Override public boolean ping() throws InvalidOperationException, TException { return true; } } 5.4. 编写服务器 正如我们所说，我们想要构建一个跨平台的客户端-服务器应用程序，因此我们需要一个服务器。Apache Thrift 的伟大之处在于它拥有自己的客户端-服务器通信框架，这让通信变得轻而易举： public class CrossPlatformServiceServer { public void start() throws TTransportException { TServerTransport serverTransport = new TServerSocket(9090); server = new TSimpleServer(new TServer.Args(serverTransport) .processor(new CrossPlatformService.Processor\u0026lt;\u0026gt;(new CrossPlatformServiceImpl()))); System.out.print(\u0026#34;Starting the server... \u0026#34;); server.serve(); System.out.println(\u0026#34;done.\u0026#34;); } public void stop() { if (server != null \u0026amp;\u0026amp; server.isServing()) { System.out.print(\u0026#34;Stopping the server... \u0026#34;); server.stop(); System.out.println(\u0026#34;done.\u0026#34;); } } } 首先是定义一个传输层，实现TServerTransport接口（或者更准确地说是抽象类）。既然我们在谈论服务器，我们需要提供一个端口来监听。然后我们需要定义一个TServer实例并选择一个可用的实现：  TSimpleServer – 用于简单服务器 TThreadPoolServer – 用于多线程服务器 TNonblockingServer – 用于非阻塞多线程服务器  最后，为选择的服务器提供一个处理器实现，它已经由 Thrift 为我们生成，即CrossPlatofformService.Processor类。 5.5. 编写客户端 这是客户端的实现： TTransport transport = new TSocket(\u0026#34;localhost\u0026#34;, 9090); transport.open(); TProtocol protocol = new TBinaryProtocol(transport); CrossPlatformService.Client client = new CrossPlatformService.Client(protocol); boolean result = client.ping(); transport.close(); 从客户的角度来看，这些操作非常相似。 首先，定义传输并将其指向我们的服务器实例，然后选择合适的协议。唯一的区别是我们在这里初始化了客户端实例，它再次由 Thrift 生成，即CrossPlatformService.Client类。 由于它基于*.thrift*文件定义，我们可以直接调用那里描述的方法。在这个特定的示例中，client.ping()将对服务器进行远程调用，该服务器将以true响应。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_thrift/","tags":[],"title":"使用 Apache Thrift"},{"categories":["Java"],"contents":"1. 概述 如今，从社交网络到银行业务，从医疗保健到政府服务，所有活动都可以在线进行。因此，他们严重依赖 Web 应用程序。 Web 应用程序使用户能够消费/享受公司提供的在线服务。同时，它充当后端软件的接口。 在这个介绍性教程中，我们将探索 Apache Tapestry Web 框架并使用它提供的基本功能创建一个简单的 Web 应用程序。 2. Apache Tapestry Apache Tapestry 是一个基于组件的框架，用于构建可扩展的 Web 应用程序。 它遵循约定优于配置的范式，并使用注释和命名约定进行配置。 所有组件都是简单的 POJO。同时，它们是从零开始开发的，不依赖于其他库。 除了 Ajax 支持之外，Tapestry 还具有出色的异常报告功能。它还提供了一个广泛的内置通用组件库。 在其他重要功能中，一个突出的特点是代码的热重载。因此，使用此功能，我们可以立即看到开发环境中的变化。 3. 设置 Apache Tapestry 需要一组简单的工具来创建 Web 应用程序：  Java 1.6 或更高版本 构建工具（Maven 或 Gradle） IDE（Eclipse 或 IntelliJ） 应用服务器（Tomcat 或 Jetty）  在本教程中，我们将结合使用 Java 8、Maven、Eclipse 和 Jetty Server。 要设置最新的Apache Tapestry 项目，我们将使用Maven 原型并按照官方文档提供的说明进行操作： $ mvn archetype:generate -DarchetypeCatalog=http://tapestry.apache.org 或者，如果我们有一个现有项目，我们可以简单地将Tapestry-core Maven 依赖项添加到pom.xml： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tapestry\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tapestry-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.4.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 一旦我们准备好设置，我们可以通过以下 Maven 命令启动应用程序apache-tapestry ： $ mvn jetty:run 默认情况下，可以通过localhost:8080/apache-tapestry 访问该应用程序： 4. 项目结构 让我们探索一下 Apache Tapestry 创建的项目布局： 我们可以看到一个类似 Maven 的项目结构，以及一些基于约定的包。 Java 类被放置在src/main/java并被分类为components、pages和services 。 同样，src/main/resources包含我们的模板（类似于 HTML 文件）——它们具有*.tml*扩展名。 对于放置在组件和页面目录下的每个 Java 类，都应该创建一个同名的模板文件。** src/main/webapp目录包含图像、样式表和 JavaScript 文件等资源。同样，测试文件放在src/test中。 最后，src/site将包含文档文件。 为了更好的理解，我们来看看在 Eclipse IDE 中打开的项目结构： 5. 注释 让我们讨论Apache Tapestry 为日常使用提供的一些方便的注释。展望未来，我们将在我们的实现中使用这些注释。 5.1 @Inject @Inject注解在org.apache.tapestry5.ioc.annotations包中可用，它提供了一种在 Java 类中注入依赖项的简单方法。 这个注解对于注入资产、块、资源和服务非常方便。 5.2. @InjectPage 在org.apache.tapestry5.annotations包中可用，@InjectPage注释允许我们将页面注入另一个组件。此外，注入的页面始终是只读属性。 5.3. @InjectComponent 类似地，@InjectComponent注解允许我们注入模板中定义的组件。 5.4. @Log @Log注释在org.apache.tapestry5.annotations包中可用，并且可以方便地在任何方法上启用 DEBUG 级别的日志记录。它记录方法的进入和退出，以及参数值。 5.5. @Property 在org.apache.tapestry5.annotations包中可用， @Property注释将字段标记为属性。同时，它会自动为属性创建 getter 和 setter。 5.6. @Parameter 类似地，*@Parameter*注解表示一个字段是一个组件参数。 6.页面 因此，我们都准备好探索框架的基本功能。让我们在我们的应用程序中创建一个新的主页。 首先，我们将在src/main/java的pages目录中定义一个 Java 类Home： public class Home { } 6.1模板 然后，我们将在src/main/resources下的pages目录中创建一个对应的Home.tml模板。 扩展名为*.tml*（Tapestry 标记语言）的文件类似于 Apache Tapestry 提供的具有 XML 标记的 HTML/XHTML 文件。 例如，让我们看一下Home.tml模板： \u0026lt;html xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_4.xsd\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;apache-tapestry Home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 瞧！只需重启 Jetty 服务器，我们就可以在localhost:8080/apache-tapestry/home 访问主页： 6.2. Property 让我们探索如何在主页上呈现属性。 为此，我们将在Home类中添加一个属性和一个 getter 方法： @Property private String appName = \u0026#34;apache-tapestry\u0026#34;; public Date getCurrentTime() { return new Date(); } 要在主页上呈现appName属性，我们可以简单地使用*${appName}*。 同样，我们可以编写*${currentTime}从页面访问getCurrentTime*方法。 6.3. 本土化 Apache Tapestry 提供集成的本地化支持。按照惯例，页面名称属性文件保存要在页面上呈现的所有本地消息的列表。 例如，我们将在主页的**pages目录中创建一个带有本地消息的home.properties文件： introMsg=Welcome to the Apache Tapestry Tutorial 消息属性不同于 Java 属性。 出于同样的原因，带有消息前缀的键名用于呈现消息属性——例如，${message:introMsg}。 6.4. 布局组件 让我们通过创建Layout.java类来定义一个基本的布局组件。我们将文件保存在src/main/java的**components目录中： public class Layout { @Property @Parameter(required = true, defaultPrefix = BindingConstants.LITERAL) private String title; } 在这里，title属性被标记为必需，并且绑定的默认前缀设置为文字String。 然后，我们会在src/main/resources的components目录下编写一个对应的模板文件Layout.tml： \u0026lt;html xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_4.xsd\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;${title}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;t:body /\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;© Your Company\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 现在，让我们使用主页上的布局： \u0026lt;html t:type=\u0026#34;layout\u0026#34; title=\u0026#34;apache-tapestry Home\u0026#34; xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_4.xsd\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Home! ${appName}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;${message:introMsg}\u0026lt;/h2\u0026gt; \u0026lt;h3\u0026gt;${currentTime}\u0026lt;/h3\u0026gt; \u0026lt;/html\u0026gt; 请注意，命名空间用于标识Apache Tapestry 提供的元素（ t:type和*t:body ）。*同时，命名空间还提供了组件和属性。 在这里，t:type将设置主页上的布局。并且，t:body元素将插入页面的内容。 让我们看一下带有布局的主页： 7.表格 让我们创建一个带有表单的登录页面，以允许用户登录。 如前所述，我们将首先创建一个 Java 类Login： public class Login { // ...  @InjectComponent private Form login; @Property private String email; @Property private String password; } 在这里，我们定义了两个属性—— email和password。此外，我们还为登录注入了一个表单组件。 然后，让我们创建一个对应的模板login.tml： \u0026lt;html t:type=\u0026#34;layout\u0026#34; title=\u0026#34;apache-tapestry com.example\u0026#34; xmlns:t=\u0026#34;http://tapestry.apache.org/schema/tapestry_5_3.xsd\u0026#34; xmlns:p=\u0026#34;tapestry:parameter\u0026#34;\u0026gt; \u0026lt;t:form t:id=\u0026#34;login\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Please sign in\u0026lt;/h2\u0026gt; \u0026lt;t:textfield t:id=\u0026#34;email\u0026#34; placeholder=\u0026#34;Email address\u0026#34;/\u0026gt; \u0026lt;t:passwordfield t:id=\u0026#34;password\u0026#34; placeholder=\u0026#34;Password\u0026#34;/\u0026gt; \u0026lt;t:submit class=\u0026#34;btn btn-large btn-primary\u0026#34; value=\u0026#34;Sign in\u0026#34;/\u0026gt; \u0026lt;/t:form\u0026gt; \u0026lt;/html\u0026gt; 现在，我们可以在localhost:8080/apache-tapestry/login 访问登录页面： 8. 验证 Apache Tapestry 提供了一些用于表单验证的内置方法。它还提供了处理表单提交成功或失败的方法。 内置方法遵循事件和组件名称的约定。例如，方法onValidationFromLogin将验证Login组件。 同样，像onSuccessFromLogin和onFailureFromLogin这样的方法分别用于成功和失败事件。 因此，让我们将这些内置方法添加到Login类中： public class Login { // ...  void onValidateFromLogin() { if (email == null) System.out.println(\u0026#34;Email is null); if (password == null) System.out.println(\u0026#34;Password is null); } Object onSuccessFromLogin() { System.out.println(\u0026#34;Welcome! Login Successful\u0026#34;); return Home.class; } void onFailureFromLogin() { System.out.println(\u0026#34;Please try again with correct credentials\u0026#34;); } } 9. 警报 如果没有适当的警报，表单验证是不完整的。更不用说，该框架还内置了对警报消息的支持。 为此，我们将首先在Login类中注入AlertManager的实例来管理警报*。然后，将现有方法中的println*语句替换为警告消息： public class Login { // ...  @Inject private AlertManager alertManager; void onValidateFromLogin() { if(email == null || password == null) { alertManager.error(\u0026#34;Email/Password is null\u0026#34;); login.recordError(\u0026#34;Validation failed\u0026#34;); //submission failure on the form  } } Object onSuccessFromLogin() { alertManager.success(\u0026#34;Welcome! Login Successful\u0026#34;); return Home.class; } void onFailureFromLogin() { alertManager.error(\u0026#34;Please try again with correct credentials\u0026#34;); } } 让我们看看登录失败时的警报： 10. Ajax 到目前为止，我们已经探索了使用表单创建一个简单的主页。同时，我们看到了对警报消息的验证和支持。 接下来，让我们探索一下 Apache Tapestry 对 Ajax 的内置支持。 首先，我们将在Home类中注入AjaxResponseRenderer和Block组件的实例。然后，我们将创建一个onCallAjax方法来处理 Ajax 调用： public class Home { // ....  @Inject private AjaxResponseRenderer ajaxResponseRenderer; @Inject private Block ajaxBlock; @Log void onCallAjax() { ajaxResponseRenderer.addRender(\u0026#34;ajaxZone\u0026#34;, ajaxBlock); } } 此外，我们需要在Home.tml中进行一些更改。 首先，我们将添加eventLink以调用onCallAjax方法。然后，我们将添加一个id 为ajaxZone的zone元素来呈现 Ajax 响应。 最后，我们需要一个块组件，该组件将被注入Home类并呈现为 Ajax 响应： \u0026lt;p\u0026gt;\u0026lt;t:eventlink event=\u0026#34;callAjax\u0026#34; zone=\u0026#34;ajaxZone\u0026#34; class=\u0026#34;btn btn-default\u0026#34;\u0026gt;Call Ajax\u0026lt;/t:eventlink\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;t:zone t:id=\u0026#34;ajaxZone\u0026#34;\u0026gt;\u0026lt;/t:zone\u0026gt; \u0026lt;t:block t:id=\u0026#34;ajaxBlock\u0026#34;\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;h2\u0026gt;Rendered through Ajax\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The current time is: \u0026lt;strong\u0026gt;${currentTime}\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/t:block\u0026gt; 我们来看看更新后的主页： 然后，我们可以单击 Call Ajax 按钮并查看ajaxResponseRenderer的运行情况： 11. 记录 要启用内置的日志记录功能，需要注入Logger的实例。然后，我们可以使用它来记录任何级别的日志，例如 TRACE、DEBUG 和 INFO。 因此，让我们在Home类中进行必要的更改： public class Home { // ...  @Inject private Logger logger; void onCallAjax() { logger.info(\u0026#34;Ajax call\u0026#34;); ajaxResponseRenderer.addRender(\u0026#34;ajaxZone\u0026#34;, ajaxBlock); } } 现在，当我们单击 Call Ajax 按钮时，记录器将在 INFO 级别记录： [INFO] pages.Home Ajax call \u0026quot; ","permalink":"http://itcodingman.github.io/apache_tapestry/","tags":[],"title":"Apache Tapestry 简介"},{"categories":["Architecture","Java"],"contents":" 概述   本教程将介绍分布式实时计算系统Apache Storm 。 我们将重点关注并涵盖：  Apache Storm 到底是什么以及它解决了什么问题 它的架构，以及 如何在项目中使用它  什么是 Apache Storm？   Apache Storm 是用于实时计算的免费和开源分布式系统。 它提供容错性、可扩展性和保证数据处理，尤其擅长处理无界数据流。 Storm 的一些很好的用例可以是处理信用卡操作以检测欺诈或处理来自智能家居的数据以检测故障传感器。 Storm 允许与市场上可用的各种数据库和排队系统集成。 Maven依赖   在我们使用 Apache Storm 之前，我们需要在我们的项目中包含storm-core 依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.storm\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;storm-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 如果我们打算在 Storm 集群上运行我们的应用程序，我们应该只使用提供的范围 。 要在本地运行应用程序，我们可以使用所谓的本地模式，在本地进程中模拟 Storm 集群，在这种情况下我们应该删除 提供的。 数据模型   Apache Storm 的数据模型由两个元素组成：元组和流。 4.1 元组 元组是具有动态类型的命名字段的有序列表。 这意味着我们不需要显式声明字段的类型。 Storm 需要知道如何序列化元组中使用的所有值。默认情况下，它已经可以序列化原始类型、字符串和字节数组。 而且由于 Storm 使用 Kryo 序列化，我们需要使用 Config注册序列化器 以使用自定义类型。我们可以通过以下两种方式之一来做到这一点： 首先，我们可以使用其全名注册要序列化的类： Config config = new Config(); config.registerSerialization(User.class); 在这种情况下，Kryo 将使用*FieldSerializer序列化类。*默认情况下，这将序列化类的所有非瞬态字段，包括私有的和公共的。 或者，我们可以同时提供要序列化的类和我们希望 Storm 用于该类的序列化器： Config config = new Config(); config.registerSerialization(User.class, UserSerializer.class); 要创建自定义序列化程序，我们需要扩展具有 写入和 读取两种方法 的通用类Serializer 。 4.2. Stream Stream是 Storm 生态系统中的核心抽象。 Stream是一个无界的元组序列。 Storms 允许并行处理多个流。 每个流都有一个在声明期间提供和分配的 id。 拓扑   实时 Storm 应用的逻辑被封装到拓扑中。拓扑由 spouts和bolts组成。 5.1 Spout Spout 是流的来源。它们向拓扑发出元组。 元组可以从各种外部系统（如 Kafka、Kestrel 或 ActiveMQ）中读取。 Spout 可以是 可靠的 或 不可靠的。可靠 意味着 spout 可以回复 Storm 处理失败的元组。 不可靠意味着 spout 不响应，因为它将使用即发即弃机制来发出元组。 要创建自定义 spout，我们需要实现 IRichSpout接口或扩展任何已经实现该接口的类，例如抽象 BaseRichSpout类。 让我们创建一个 不可靠的spout： public class RandomIntSpout extends BaseRichSpout { private Random random; private SpoutOutputCollector outputCollector; @Override public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) { random = new Random(); outputCollector = spoutOutputCollector; } @Override public void nextTuple() { Utils.sleep(1000); outputCollector.emit(new Values(random.nextInt(), System.currentTimeMillis())); } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { outputFieldsDeclarer.declare(new Fields(\u0026#34;randomInt\u0026#34;, \u0026#34;timestamp\u0026#34;)); } } 我们自定义的 RandomIntSpout将每秒生成随机整数和时间戳。 5.2. Bolts **Bolts 处理流中的元组。**它们可以执行各种操作，如过滤、聚合或自定义函数。 有些操作需要多个步骤，因此在这种情况下我们需要使用多个螺栓。 要创建自定义 Bolt，我们需要实现 IRichBolt或更简单的操作 IBasicBolt接口。 还有多个帮助类可用于实现 *Bolt。*在这种情况下，我们将使用 BaseBasicBolt： public class PrintingBolt extends BaseBasicBolt { @Override public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) { System.out.println(tuple); } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { } } 这个自定义 的PrintingBolt将简单地将所有元组打印到控制台。 创建一个简单的拓扑   让我们把这些想法放在一个简单的拓扑中。我们的拓扑将有一个 spout 和三个 bolt。 6.1 随机数Spout 一开始，我们将创建一个不可靠的 spout。它将每秒从 (0,100) 范围内生成随机整数： public class RandomNumberSpout extends BaseRichSpout { private Random random; private SpoutOutputCollector collector; @Override public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) { random = new Random(); collector = spoutOutputCollector; } @Override public void nextTuple() { Utils.sleep(1000); int operation = random.nextInt(101); long timestamp = System.currentTimeMillis(); Values values = new Values(operation, timestamp); collector.emit(values); } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { outputFieldsDeclarer.declare(new Fields(\u0026#34;operation\u0026#34;, \u0026#34;timestamp\u0026#34;)); } } 6.2. 过滤Bolt 接下来，我们将创建一个Bolt，它将过滤掉所有 操作 等于 0 的元素： public class FilteringBolt extends BaseBasicBolt { @Override public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) { int operation = tuple.getIntegerByField(\u0026#34;operation\u0026#34;); if (operation \u0026gt; 0) { basicOutputCollector.emit(tuple.getValues()); } } @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) { outputFieldsDeclarer.declare(new Fields(\u0026#34;operation\u0026#34;, \u0026#34;timestamp\u0026#34;)); } } 6.3. 聚合Bolt 接下来，让我们创建一个更复杂的 Bolt，它将汇总每天的所有积极操作。 为此，我们将使用一个专门为实现在窗口上操作而不是在单个元组上操作的Bolt而创建的特定类： BaseWindowedBolt。 Windows是流处理中的一个基本概念，它将无限的流分成有限的块。然后我们可以对每个块应用计算。窗户一般有两种： 时间窗口用于使用时间戳对给定时间段的元素进行分组。时间窗口可能有不同数量的元素。 计数窗口用于创建具有定义大小的窗口。在这种情况下，所有窗口都将具有相同的大小，如果元素少于定义的大小，则不会发出窗口。 我们的AggregatingBolt将生成来自**时间窗口的所有正操作的总和以及它的开始和结束时间戳： public class AggregatingBolt extends BaseWindowedBolt { private OutputCollector outputCollector; @Override public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) { this.outputCollector = collector; } @Override public void declareOutputFields(OutputFieldsDeclarer declarer) { declarer.declare(new Fields(\u0026#34;sumOfOperations\u0026#34;, \u0026#34;beginningTimestamp\u0026#34;, \u0026#34;endTimestamp\u0026#34;)); } @Override public void execute(TupleWindow tupleWindow) { List\u0026lt;Tuple\u0026gt; tuples = tupleWindow.get(); tuples.sort(Comparator.comparing(this::getTimestamp)); int sumOfOperations = tuples.stream() .mapToInt(tuple -\u0026gt; tuple.getIntegerByField(\u0026#34;operation\u0026#34;)) .sum(); Long beginningTimestamp = getTimestamp(tuples.get(0)); Long endTimestamp = getTimestamp(tuples.get(tuples.size() - 1)); Values values = new Values(sumOfOperations, beginningTimestamp, endTimestamp); outputCollector.emit(values); } private Long getTimestamp(Tuple tuple) { return tuple.getLongByField(\u0026#34;timestamp\u0026#34;); } } 请注意，在这种情况下，直接获取列表的第一个元素是安全的。这是因为每个窗口都是使用 元组 的**时间戳字段计算的 ，所以每个窗口中必须****至少有一个元素。 6.4. 文件写入Bolt 最后，我们将创建一个 Bolt，它将所有 sumOfOperations大于 2000 的元素，序列化并将它们写入文件： public class FileWritingBolt extends BaseRichBolt { public static Logger logger = LoggerFactory.getLogger(FileWritingBolt.class); private BufferedWriter writer; private String filePath; private ObjectMapper objectMapper; @Override public void cleanup() { try { writer.close(); } catch (IOException e) { logger.error(\u0026#34;Failed to close writer!\u0026#34;); } } @Override public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) { objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); try { writer = new BufferedWriter(new FileWriter(filePath)); } catch (IOException e) { logger.error(\u0026#34;Failed to open a file for writing.\u0026#34;, e); } } @Override public void execute(Tuple tuple) { int sumOfOperations = tuple.getIntegerByField(\u0026#34;sumOfOperations\u0026#34;); long beginningTimestamp = tuple.getLongByField(\u0026#34;beginningTimestamp\u0026#34;); long endTimestamp = tuple.getLongByField(\u0026#34;endTimestamp\u0026#34;); if (sumOfOperations \u0026gt; 2000) { AggregatedWindow aggregatedWindow = new AggregatedWindow( sumOfOperations, beginningTimestamp, endTimestamp); try { writer.write(objectMapper.writeValueAsString(aggregatedWindow)); writer.newLine(); writer.flush(); } catch (IOException e) { logger.error(\u0026#34;Failed to write data to file.\u0026#34;, e); } } } // public constructor and other methods } 请注意，我们不需要声明输出，因为这将是我们拓扑中的最后一个Bolt 6.5 运行拓扑 最后，我们可以将所有内容放在一起并运行我们的拓扑： public static void runTopology() { TopologyBuilder builder = new TopologyBuilder(); Spout random = new RandomNumberSpout(); builder.setSpout(\u0026#34;randomNumberSpout\u0026#34;); Bolt filtering = new FilteringBolt(); builder.setBolt(\u0026#34;filteringBolt\u0026#34;, filtering) .shuffleGrouping(\u0026#34;randomNumberSpout\u0026#34;); Bolt aggregating = new AggregatingBolt() .withTimestampField(\u0026#34;timestamp\u0026#34;) .withLag(BaseWindowedBolt.Duration.seconds(1)) .withWindow(BaseWindowedBolt.Duration.seconds(5)); builder.setBolt(\u0026#34;aggregatingBolt\u0026#34;, aggregating) .shuffleGrouping(\u0026#34;filteringBolt\u0026#34;); String filePath = \u0026#34;./src/main/resources/data.txt\u0026#34;; Bolt file = new FileWritingBolt(filePath); builder.setBolt(\u0026#34;fileBolt\u0026#34;, file) .shuffleGrouping(\u0026#34;aggregatingBolt\u0026#34;); Config config = new Config(); config.setDebug(false); LocalCluster cluster = new LocalCluster(); cluster.submitTopology(\u0026#34;Test\u0026#34;, config, builder.createTopology()); } 为了使数据流过拓扑中的每一部分，我们需要指出如何连接它们。shuffleGroup允许我们声明 filterBolt 的数据 将来自 randomNumberSpout。 对于每个 Bolt，我们需要添加 shuffleGroup，它定义了这个 Bolt 的元素来源。 元素的来源可能是一个 Spout或另一个 *Bolt。如果我们为多个 bolt 设置相同的源，*源将向它们中的每一个发出所有元素。 在这种情况下，我们的拓扑将使用 LocalCluster 在本地运行作业。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_storm/","tags":[],"title":"Apache Storm 简介"},{"categories":["DevOps"],"contents":"1. 简介 Apache Spark是一个开源集群计算框架。它为 Scala、Java、Python 和 R 提供了优雅的开发 API，允许开发人员跨不同的数据源执行各种数据密集型工作负载，包括 HDFS、Cassandra、HBase、S3 等。 从历史上看，Hadoop 的 MapReduce 被证明对于一些迭代和交互式计算工作效率低下，最终导致了 Spark 的发展。使用 Spark，我们在内存中运行逻辑的速度比使用 Hadoop 快两个数量级，或者在磁盘上运行速度快一个数量级。 2. Spark 架构 Spark 应用程序在集群上作为独立的进程集运行，如下图所述： 这些进程集由主程序（称为驱动程序）中的SparkContext对象协调。**SparkContext连接到几种类型的集群管理器（Spark 自己的独立集群管理器、Mesos 或 YARN），它们在应用程序之间分配资源。 连接后，Spark 会在集群中的节点上获取执行程序，这些节点是为您的应用程序运行计算和存储数据的进程。 接下来，它将您的应用程序代码（由传递给SparkContext的 JAR 或 Python 文件定义）发送到执行程序。最后，SparkContext将任务发送给执行器运行。 3. 核心组件 下图清晰地展示了 Spark 的不同组件： 3.1 Spark Core Spark Core 组件负责所有基本的 I/O 功能、调度和监控 Spark 集群上的作业、任务调度、与不同存储系统的联网、故障恢复和高效的内存管理。 与 Hadoop 不同，Spark 通过使用称为 RDD（弹性分布式数据集）的特殊数据结构，避免将共享数据存储在 Amazon S3 或 HDFS 等中间存储中。 弹性分布式数据集是不可变的，是记录的分区集合，可以并行操作并允许容错“内存中”计算。 RDD 支持两种操作：   转换——Spark RDD 转换是一个从现有 RDD 生成新 RDD 的函数。Transformer 将 RDD 作为输入，并产生一个或多个 RDD 作为输出。转换本质上是惰性的，即当我们调用一个动作时它们会被执行   动作**-**转换从彼此创建 RDD，但是当我们想要使用实际数据集时，此时会执行动作。因此，**Action是提供非 RDD 值的 Spark RDD 操作。**动作值存储到驱动程序或外部存储系统   动作是从 Executor 向驱动程序发送数据的方式之一。 执行者是负责执行任务的代理。而驱动程序是一个 JVM 进程，它协调工作人员和任务的执行。Spark 的一些动作是计数和收集。 3.2. Spark SQL Spark SQL 是用于结构化数据处理的 Spark 模块。它主要用于执行 SQL 查询。DataFrame构成了 Spark SQL 的主要抽象。排序到命名列中的分布式数据集合在 Spark 中称为DataFrame。 Spark SQL 支持从 Hive、Avro、Parquet、ORC、JSON 和 JDBC 等不同来源获取数据。它还可以使用 Spark 引擎扩展到数千个节点和数小时的查询，该引擎提供完整的中间查询容错。 3.3. Spark Streaming Spark Streaming 是核心 Spark API 的扩展，支持实时数据流的可扩展、高吞吐量、容错流处理。可以从多个来源获取数据，例如 Kafka、Flume、Kinesis 或 TCP 套接字。 最后，处理后的数据可以推送到文件系统、数据库和实时仪表板。 3.4. Spark Mlib MLlib 是 Spark 的机器学习 (ML) 库。它的目标是使实用的机器学习变得可扩展且简单。在高层次上，它提供了以下工具：  ML 算法——常见的学习算法，例如分类、回归、聚类和协同过滤 特征化——特征提取、转换、降维和选择 Pipelines——用于构建、评估和调整 ML Pipelines 的工具 持久性——保存和加载算法、模型和管道 实用工具——线性代数、统计、数据处理等。  3.5. Spark GraphX **GraphX 是用于图形和图形并行计算的组件。**在高层次上，GraphX 通过引入新的 Graph 抽象扩展了 Spark RDD：一个有向多重图，其属性附加到每个顶点和边。 为了支持图计算，GraphX 公开了一组基本操作符（例如subgraph、joinVertices和aggregateMessages）。 此外，GraphX 包括越来越多的图形算法和构建器，以简化图形分析任务。 4. Spark 中的“Hello World” 现在我们了解了核心组件，我们可以继续进行简单的基于 Maven 的 Spark 项目——用于计算字数。 我们将演示 Spark 在本地模式下运行，其中所有组件都在同一台机器上本地运行，它是主节点、执行程序节点或 Spark 的独立集群管理器。 4.1 Maven 设置 让我们在pom.xml文件中建立一个带有Spark 相关依赖项的 Java Maven 项目： \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spark-core_2.10\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 4.2. 字数 - Spark 作业 现在让我们编写 Spark 作业来处理包含句子的文件并输出不同的单词及其在文件中的计数： public static void main(String[] args) throws Exception { if (args.length \u0026lt; 1) { System.err.println(\u0026#34;Usage: JavaWordCount \u0026lt;file\u0026gt;\u0026#34;); System.exit(1); } SparkConf sparkConf = new SparkConf().setAppName(\u0026#34;JavaWordCount\u0026#34;); JavaSparkContext ctx = new JavaSparkContext(sparkConf); JavaRDD\u0026lt;String\u0026gt; lines = ctx.textFile(args[0], 1); JavaRDD\u0026lt;String\u0026gt; words = lines.flatMap(s -\u0026gt; Arrays.asList(SPACE.split(s)).iterator()); JavaPairRDD\u0026lt;String, Integer\u0026gt; ones = words.mapToPair(word -\u0026gt; new Tuple2\u0026lt;\u0026gt;(word, 1)); JavaPairRDD\u0026lt;String, Integer\u0026gt; counts = ones.reduceByKey((Integer i1, Integer i2) -\u0026gt; i1 + i2); List\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; output = counts.collect(); for (Tuple2\u0026lt;?, ?\u0026gt; tuple : output) { System.out.println(tuple._1() + \u0026#34;: \u0026#34; + tuple._2()); } ctx.stop(); } 请注意，我们将本地文本文件的路径作为参数传递给 Spark 作业。 SparkContext对象是Spark的主要入口点，表示与已经运行的 Spark 集群的连接。它使用SparkConf对象来描述应用程序配置。SparkContext用于读取内存中的文本文件作为JavaRDD对象。 接下来，我们使用flatmap方法将行**JavaRDD对象转换为单词JavaRDD对象，首先将每行转换为空格分隔的单词，然后将每行处理的输出展平。 我们再次应用变换操作mapToPair，它基本上将每个单词的出现映射到单词的元组和 1 的计数。 然后，我们应用reduceByKey操作将多次出现的计数为 1 的单词分组到单词元组中，并将计数相加。 最后，我们执行收集RDD 动作以获得最终结果。 4.3. 执行——Spark 作业 现在让我们使用 Maven 构建项目以在目标文件夹中生成apache-spark-1.0-SNAPSHOT.jar 。 接下来，我们需要将这个 WordCount 作业提交给 Spark： ${spark-install-dir}/bin/spark-submit --class com.codingman.WordCount --master local ${WordCount-MavenProject}/target/apache-spark-1.0-SNAPSHOT.jar ${WordCount-MavenProject}/src/main/resources/spark_example.txt 在运行上述命令之前，需要更新 Spark 安装目录和 WordCount Maven 项目目录。 在提交时，幕后会发生几个步骤：  从驱动程序代码，SparkContext连接到集群管理器（在我们的例子中，火花独立集群管理器在本地运行） 集群管理器在其他应用程序之间分配资源 Spark 在集群中的节点上获取执行器。在这里，我们的字数统计应用程序将获得自己的执行程序进程 应用程序代码（jar 文件）被发送到执行器 任务由SparkContext发送给执行者。  最后，将 spark 作业的结果返回给驱动程序，我们将看到文件中的字数作为输出： Hello 1 from 2 Baledung 2 Keep 1 Learning 1 Spark 1 Bye 1 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_spark/","tags":["Spark"],"title":"Apache Spark 简介"},{"categories":["Data","NoSQL"],"contents":"1. 概述 Apache Solr是一个建立在 Lucene 之上的开源搜索平台。Apache SolrJ 是一个基于 Java 的 Solr 客户端，它为搜索的主要功能（如索引、查询和删除文档）提供接口。 在本文中，我们将探讨如何使用 SolrJ 与 Apache Solr 服务器交互。 2. 设置 为了在您的机器上安装 Solr 服务器，请参阅Solr 快速入门指南。 安装过程很简单——只需下载 zip/tar 包，解压缩内容，然后从命令行启动服务器。对于本文，我们将创建一个具有名为“bigboxstore”的核心的 Solr 服务器： bin/solr start bin/solr create -c \u0026#39;bigboxstore\u0026#39; 默认情况下，Solr 侦听端口 8983 以获取传入的 HTTP 查询。您可以通过在浏览器中打开http://localhost:8983/solr/#/bigboxstore URL 并观察 Solr Dashboard来验证它是否已成功启动。 3. Maven配置 现在我们已经启动并运行了 Solr 服务器，让我们直接跳到 SolrJ Java 客户端。要在您的项目中使用 SolrJ，您需要在pom.xml文件中声明以下 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.solr\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;solr-solrj\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您总能找到由Maven Central托管的最新版本。 4. Apache SolrJ Java API 让我们通过连接到我们的 Solr 服务器来启动 SolrJ 客户端： String urlString = \u0026#34;http://localhost:8983/solr/bigboxstore\u0026#34;; HttpSolrClient solr = new HttpSolrClient.Builder(urlString).build(); solr.setParser(new XMLResponseParser()); 注意：SolrJ 使用二进制格式而不是 XML作为其默认响应格式。为了与 Solr 兼容，需要将*setParser()*显式调用到 XML，如上所示。可以在此处找到有关此的更多详细信息。 4.1 索引文件 让我们使用SolrInputDocument定义要索引的数据，并使用*add()*方法将其添加到我们的索引中： SolrInputDocument document = new SolrInputDocument(); document.addField(\u0026#34;id\u0026#34;, \u0026#34;123456\u0026#34;); document.addField(\u0026#34;name\u0026#34;, \u0026#34;Ann\u0026#34;); document.addField(\u0026#34;price\u0026#34;, \u0026#34;599.99\u0026#34;); solr.add(document); solr.commit(); 注意：任何修改 Solr 数据库的操作都需要在该操作后跟commit()。 4.2. 使用 Bean 进行索引 您还可以使用 beans 索引 Solr 文档。让我们定义一个 ProductBean，它的属性用 @Field注释： public class ProductBean { String id; String name; String price; @Field(\u0026#34;id\u0026#34;) protected void setId(String id) { this.id = id; } @Field(\u0026#34;name\u0026#34;) protected void setName(String name) { this.name = name; } @Field(\u0026#34;price\u0026#34;) protected void setPrice(String price) { this.price = price; } // getters and constructor omitted for space } 然后，让我们将 bean 添加到我们的索引中： solrClient.addBean( new ProductBean(\u0026#34;888\u0026#34;, \u0026#34;Apple iPhone X\u0026#34;, \u0026#34;299.99\u0026#34;) ); solrClient.commit(); 4.3. 按字段和ID查询索引文档 让我们通过使用SolrQuery查询我们的 Solr 服务器来验证我们的文档是否已添加。 来自服务器的QueryResponse将包含一个SolrDocument对象列表，该对象与格式为field:value 的任何查询匹配。在本例中，我们按价格查询： SolrQuery query = new SolrQuery(); query.set(\u0026#34;q\u0026#34;, \u0026#34;price:599.99\u0026#34;); QueryResponse response = solr.query(query); SolrDocumentList docList = response.getResults(); assertEquals(docList.getNumFound(), 1); for (SolrDocument doc : docList) { assertEquals((String) doc.getFieldValue(\u0026#34;id\u0026#34;), \u0026#34;123456\u0026#34;); assertEquals((Double) doc.getFieldValue(\u0026#34;price\u0026#34;), (Double) 599.99); } 一个更简单的选择是使用getById()按Id查询。如果找到匹配项，它将仅返回一个文档： SolrDocument doc = solr.getById(\u0026#34;123456\u0026#34;); assertEquals((String) doc.getFieldValue(\u0026#34;name\u0026#34;), \u0026#34;Ann\u0026#34;); assertEquals((Double) doc.getFieldValue(\u0026#34;price\u0026#34;), (Double) 599.99); 4.4. 删除文件 当我们想从索引中删除文档时，我们可以使用*deleteById()*并验证它是否已被删除： solr.deleteById(\u0026#34;123456\u0026#34;); solr.commit(); SolrQuery query = new SolrQuery(); query.set(\u0026#34;q\u0026#34;, \u0026#34;id:123456\u0026#34;); QueryResponse response = solr.query(query); SolrDocumentList docList = response.getResults(); assertEquals(docList.getNumFound(), 0); 我们还可以选择deleteByQuery()，所以让我们尝试删除任何具有特定名称的文档： solr.deleteByQuery(\u0026#34;name:Ann\u0026#34;); solr.commit(); SolrQuery query = new SolrQuery(); query.set(\u0026#34;q\u0026#34;, \u0026#34;id:123456\u0026#34;); QueryResponse response = solr.query(query); SolrDocumentList docList = response.getResults(); assertEquals(docList.getNumFound(), 0); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_solrj/","tags":["Lucene"],"title":"Apache SolrJ 在 Java 中使用 Solr 指南"},{"categories":["Security"],"contents":"1. 简介 在本教程中，我们将了解如何使用Apache Shiro Java 安全框架实现细粒度的基于权限的访问控制。 2. 设置 我们将使用与 Shiro 介绍相同的设置——也就是说，我们只会将shiro-core模块添加到我们的依赖项中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 此外，出于测试目的，我们将通过将以下shiro.ini文件放在类路径的根目录中来使用简单的 INI 领域： [users] jane.admin = password, admin john.editor = password2, editor zoe.author = password3, author [roles] admin = * editor = articles:* author = articles:create, articles:edit 然后，我们将使用上述领域初始化 Shiro： IniRealm iniRealm = new IniRealm(\u0026#34;classpath:shiro.ini\u0026#34;); SecurityManager securityManager = new DefaultSecurityManager(iniRealm); SecurityUtils.setSecurityManager(securityManager); 3. 角色和权限 通常，当我们谈论身份验证和授权时，我们会以用户和角色的概念为中心。 特别是，**角色是应用程序或服务的用户的横切类别。**因此，所有具有特定角色的用户都可以访问某些资源和操作，并且可能对应用程序或服务的其他部分具有受限访问权限。 角色集通常是预先设计的，很少更改以适应新的业务需求。但是，角色也可以动态定义——例如，由管理员定义。 使用 Shiro，我们有多种测试用户是否具有特定角色的方法。最直接的方法是使用hasRole方法： Subject subject = SecurityUtils.getSubject(); if (subject.hasRole(\u0026#34;admin\u0026#34;)) { logger.info(\u0026#34;Welcome Admin\u0026#34;); } 3.1 权限 但是，如果我们通过测试用户是否具有特定角色来检查授权，则会出现问题。事实上，**我们正在硬编码角色和权限之间的关系。**换句话说，当我们想要授予或撤销对资源的访问权限时，我们将不得不更改源代码。当然，这也意味着重建和重新部署。 我们可以做得更好；这就是为什么我们现在要介绍权限的概念。权限代表我们可以授权或拒绝的软件可以做什么，而**不是谁可以做。**例如，“编辑当前用户的个人资料”、“批准文档”或“创建新文章”。 Shiro 对权限的假设很少。在最简单的情况下，权限是纯字符串： Subject subject = SecurityUtils.getSubject(); if (subject.isPermitted(\u0026#34;articles:create\u0026#34;)) { //Create a new article } 请注意，权限的使用在 Shiro 中完全是可选的。 3.2. 将权限与用户关联 Shiro 具有将权限与角色或单个用户关联的灵活模型。但是，典型领域，包括我们在本教程中使用的简单 INI 领域，仅将权限与角色相关联。 因此，由Principal标识的用户具有多个角色，并且每个角色具有多个 Permission。 例如，我们可以看到在我们的 INI 文件中，用户zoe.author具有作者角色，这赋予了他们文章：创建和 文章：编辑权限： [users] zoe.author = password3, author #Other users... [roles] author = articles:create, articles:edit #Other roles... 类似地，其他领域类型（例如内置的 JDBC 领域）可以配置为将权限与角色相关联。 4. 通配符权限 **Shiro 中权限的默认实现是通配符权限，**是各种权限方案的灵活表示。 我们在 Shiro 中用字符串表示通配符权限。权限字符串由一个或多个以冒号分隔的组件组成，例如： articles:edit:1 字符串每个部分的含义取决于应用程序，因为 Shiro 不强制执行任何规则。但是，在上面的示例中，我们可以很清楚地将字符串解释为层次结构：  我们公开的资源类别（文章） 对此类资源的操作（编辑） 我们要允许或拒绝操作的特定资源的 id  这种三层结构的 resource:action:id 是 Shiro 应用程序中的一种常见模式，因为它既简单又有效地代表了许多不同的场景。 因此，我们可以重新访问我们之前的示例以遵循此方案： Subject subject = SecurityUtils.getSubject(); if (subject.isPermitted(\u0026#34;articles:edit:123\u0026#34;)) { //Edit article with id 123 } 请注意，通配符权限字符串中的组件数不必是三个，即使通常情况下三个组件也是如此。 4.1 权限含义和实例级粒度 当我们将通配符权限与 Shiro 权限的另一个特性（隐含）结合使用时，通配符权限就会大放异彩。 **当我们测试角色时，我们会测试确切的成员资格：**一个Subject有一个特定的角色，或者没有。换句话说，Shiro 测试角色的平等性。 另一方面，**当我们测试权限时，我们会测试含义：**Subject的权限是否暗示我们正在测试它的权限？ 具体含义取决于权限的实现。事实上，对于通配符权限，其含义是部分字符串匹配，顾名思义，可能存在通配符。 因此，假设我们为作者角色分配了以下权限： [roles] author = articles:* 然后，每个具有作者角色的人都将被允许对文章进行所有可能的操作： Subject subject = SecurityUtils.getSubject(); if (subject.isPermitted(\u0026#34;articles:create\u0026#34;)) { //Create a new article } 也就是说，字符串articles:*将匹配第一个组件是articles 的任何通配符权限。 使用这个方案，我们既可以分配非常具体的权限——对具有给定 id 的特定资源的特定操作——也可以分配广泛的权限，例如编辑任何文章或对任何文章执行任何操作。 当然，出于性能原因，由于这不是简单的相等比较，我们应该始终针对最具体的权限进行测试： if (subject.isPermitted(\u0026#34;articles:edit:1\u0026#34;)) { //Better than \u0026#34;articles:*\u0026#34;  //Edit article } 5. 自定义权限实现 让我们简要介绍一下权限自定义。尽管通配符权限涵盖了广泛的场景，但我们可能希望用为我们的应用程序定制的解决方案来替换它们。 假设我们需要对路径的权限进行建模，以便路径上的权限意味着对所有子路径的权限。实际上，我们可以对任务使用通配符权限，但让我们忽略它。 那么，我们需要什么？  权限实现 告诉四郎这件事  让我们看看如何实现这两点。 5.1编写权限实现 Permission实现是一个只有一个方法的类——意味着： public class PathPermission implements Permission { private final Path path; public PathPermission(Path path) { this.path = path; } @Override public boolean implies(Permission p) { if(p instanceof PathPermission) { return ((PathPermission) p).path.startsWith(path); } return false; } } 如果 这意味着另一个权限对象，则该方法返回true ，否则返回**false。 5.2. 告诉 Shiro 我们的实施 然后，有多种方法可以将Permission实现集成到 Shiro 中，但最直接的方法是将自定义PermissionResolver注入我们的Realm： IniRealm realm = new IniRealm(); Ini ini = Ini.fromResourcePath(Main.class.getResource(\u0026#34;/com/.../shiro.ini\u0026#34;).getPath()); realm.setIni(ini); realm.setPermissionResolver(new PathPermissionResolver()); realm.init(); SecurityManager securityManager = new DefaultSecurityManager(realm); PermissionResolver负责将我们权限的字符串表示形式转换为实际的**Permission对象：** public class PathPermissionResolver implements PermissionResolver { @Override public Permission resolvePermission(String permissionString) { return new PathPermission(Paths.get(permissionString)); } } 我们必须使用基于路径的权限修改我们之前的shiro.ini ： [roles] admin = / editor = /articles author = /articles/drafts 然后，我们将能够检查路径的权限： if(currentUser.isPermitted(\u0026#34;/articles/drafts/new-article\u0026#34;)) { log.info(\u0026#34;You can access articles\u0026#34;); } 请注意，这里我们以编程方式配置一个简单的领域。在典型的应用程序中，我们将使用shiro.ini文件或 Spring 等其他方式来配置 Shiro 和领域。一个真实的 shiro.ini文件可能包含： [main] permissionResolver = com.codingman.shiro.permissions.custom.PathPermissionResolver dataSource = org.apache.shiro.jndi.JndiObjectFactory dataSource.resourceName = java://app/jdbc/myDataSource jdbcRealm = org.apache.shiro.realm.jdbc.JdbcRealm jdbcRealm.dataSource = $dataSource jdbcRealm.permissionResolver = $permissionResolver \u0026quot; ","permalink":"http://itcodingman.github.io/apache_shiro_access_control/","tags":[],"title":"使用 Apache Shiro 的基于权限的访问控制"},{"categories":["Security"],"contents":"1. 概述 在本文中，我们将介绍Apache Shiro，一个通用的 Java 安全框架。 该框架是高度可定制和模块化的，因为它提供身份验证、授权、加密和会话管理。 2.依赖 Apache Shiro 有很多模块。但是，在本教程中，我们仅使用shiro-core工件。 让我们将它添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本的 Apache Shiro 模块可以在 Maven Central 上找到。 3. 配置安全管理器 SecurityManager是 Apache Shiro 框架的核心部分。应用程序通常会运行它的单个实例。 在本教程中，我们将在桌面环境中探索该框架。要配置框架，我们需要在资源文件夹中创建一个shiro.ini文件，内容如下： [users] user = password, admin user2 = password2, editor user3 = password3, author [roles] admin = * editor = articles:* author = articles:compose,articles:save shiro.ini配置文件的*[users]部分定义了SecurityManager*识别的用户凭据。格式为：p rincipal (username) = password, role1, role2, \u0026hellip;, role。 角色及其相关权限在*[roles]部分中声明。管理员角色被授予对应用程序每个部分的权限和访问权限。这由通配符(*)*符号表示。 编辑角色拥有与文章相关的所有权限，而作者角色只能撰写和保存文章。 SecurityManager用于配置SecurityUtils类。从SecurityUtils我们可以获取当前与系统交互的用户，并进行认证和授权操作。 让我们使用IniRealm从shiro.ini文件加载我们的用户和角色定义，然后使用它来配置DefaultSecurityManager对象： IniRealm iniRealm = new IniRealm(\u0026#34;classpath:shiro.ini\u0026#34;); SecurityManager securityManager = new DefaultSecurityManager(iniRealm); SecurityUtils.setSecurityManager(securityManager); Subject currentUser = SecurityUtils.getSubject(); 现在我们有了一个知道shiro.ini文件中定义的用户凭据和角色的SecurityManager，让我们继续进行用户身份验证和授权。 4. 认证 在 Apache Shiro 的术语中，Subject是与系统交互的任何实体。它可以是人、脚本或 REST 客户端。 调用SecurityUtils.getSubject()返回当前Subject的一个实例，即currentUser。 现在我们有了currentUser对象，我们可以对提供的凭据执行身份验证： if (!currentUser.isAuthenticated()) { UsernamePasswordToken token = new UsernamePasswordToken(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); token.setRememberMe(true); try { currentUser.login(token); } catch (UnknownAccountException uae) { log.error(\u0026#34;Username Not Found!\u0026#34;, uae); } catch (IncorrectCredentialsException ice) { log.error(\u0026#34;Invalid Credentials!\u0026#34;, ice); } catch (LockedAccountException lae) { log.error(\u0026#34;Your Account is Locked!\u0026#34;, lae); } catch (AuthenticationException ae) { log.error(\u0026#34;Unexpected Error!\u0026#34;, ae); } } 首先，我们检查当前用户是否尚未通过身份验证。*然后我们使用用户的主体（用户名）和凭证（密码）*创建一个身份验证令牌。 接下来，我们尝试使用令牌登录。如果提供的凭据是正确的，那么一切都会好起来的。 不同的情况有不同的例外。也可以抛出更适合应用程序要求的自定义异常。这可以通过继承 AccountException类来完成。 5. 授权 身份验证试图验证用户的身份，而授权试图控制对系统中某些资源的访问。 回想一下，我们为在shiro.ini文件中创建的每个用户分配了一个或多个角色。此外，在角色部分，我们为每个角色定义了不同的权限或访问级别。 现在让我们看看如何在我们的应用程序中使用它来实施用户访问控制。 在shiro.ini文件中，我们赋予管理员对系统每个部分的完全访问权限。 编辑可以完全访问有关文章的每个资源/操作，并且作者仅限于撰写和保存文章。 让我们根据角色欢迎当前用户： if (currentUser.hasRole(\u0026#34;admin\u0026#34;)) { log.info(\u0026#34;Welcome Admin\u0026#34;); } else if(currentUser.hasRole(\u0026#34;editor\u0026#34;)) { log.info(\u0026#34;Welcome, Editor!\u0026#34;); } else if(currentUser.hasRole(\u0026#34;author\u0026#34;)) { log.info(\u0026#34;Welcome, Author\u0026#34;); } else { log.info(\u0026#34;Welcome, Guest\u0026#34;); } 现在，让我们看看当前用户在系统中被允许做什么： if(currentUser.isPermitted(\u0026#34;articles:compose\u0026#34;)) { log.info(\u0026#34;You can compose an article\u0026#34;); } else { log.info(\u0026#34;You are not permitted to compose an article!\u0026#34;); } if(currentUser.isPermitted(\u0026#34;articles:save\u0026#34;)) { log.info(\u0026#34;You can save articles\u0026#34;); } else { log.info(\u0026#34;You can not save articles\u0026#34;); } if(currentUser.isPermitted(\u0026#34;articles:publish\u0026#34;)) { log.info(\u0026#34;You can publish articles\u0026#34;); } else { log.info(\u0026#34;You can not publish articles\u0026#34;); } 6. 领域配置 在实际应用程序中，我们需要一种从数据库而不是从shiro.ini文件中获取用户凭据的方法。这就是 Realm 概念发挥作用的地方。 在 Apache Shiro 的术语中，Realm是一个 DAO，它指向身份验证和授权所需的用户凭据存储。 要创建领域，我们只需要实现领域接口。这可能很乏味；但是，该框架带有默认实现，我们可以从中继承。这些实现之一是JdbcRealm。 我们创建了一个自定义领域实现，它扩展了 JdbcRealm类并覆盖了以下方法：doGetAuthenticationInfo()、doGetAuthorizationInfo()、getRoleNamesForUser()和getPermissions()。 让我们通过继承 JdbcRealm类来创建一个领域： public class MyCustomRealm extends JdbcRealm { //... } 为了简单起见，我们使用java.util.Map来模拟一个数据库： private Map\u0026lt;String, String\u0026gt; credentials = new HashMap\u0026lt;\u0026gt;(); private Map\u0026lt;String, Set\u0026lt;String\u0026gt;\u0026gt; roles = new HashMap\u0026lt;\u0026gt;(); private Map\u0026lt;String, Set\u0026lt;String\u0026gt;\u0026gt; perm = new HashMap\u0026lt;\u0026gt;(); { credentials.put(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); credentials.put(\u0026#34;user2\u0026#34;, \u0026#34;password2\u0026#34;); credentials.put(\u0026#34;user3\u0026#34;, \u0026#34;password3\u0026#34;); roles.put(\u0026#34;user\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;admin\u0026#34;))); roles.put(\u0026#34;user2\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;editor\u0026#34;))); roles.put(\u0026#34;user3\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;author\u0026#34;))); perm.put(\u0026#34;admin\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;*\u0026#34;))); perm.put(\u0026#34;editor\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;articles:*\u0026#34;))); perm.put(\u0026#34;author\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;articles:compose\u0026#34;, \u0026#34;articles:save\u0026#34;))); } 让我们继续并覆盖doGetAuthenticationInfo()： protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { UsernamePasswordToken uToken = (UsernamePasswordToken) token; if(uToken.getUsername() == null || uToken.getUsername().isEmpty() || !credentials.containsKey(uToken.getUsername())) { throw new UnknownAccountException(\u0026#34;username not found!\u0026#34;); } return new SimpleAuthenticationInfo( uToken.getUsername(), credentials.get(uToken.getUsername()), getName()); } 我们首先将提供的AuthenticationToken转换为UsernamePasswordToken。从uToken中，我们提取用户名（uToken.getUsername()）并使用它从数据库中获取用户凭据（密码）。 如果没有找到记录——我们抛出一个UnknownAccountException，否则我们使用凭证和用户名来构造一个从该方法返回的SimpleAuthenticatioInfo对象。 如果用户凭证使用盐进行哈希处理，我们需要返回一个SimpleAuthenticationInfo以及相关的盐： return new SimpleAuthenticationInfo( uToken.getUsername(), credentials.get(uToken.getUsername()), ByteSource.Util.bytes(\u0026#34;salt\u0026#34;), getName() ); 我们还需要覆盖doGetAuthorizationInfo()以及getRoleNamesForUser()和getPermissions()。 最后，让我们将自定义领域插入到securityManager中。我们需要做的就是用我们的自定义领域替换上面的IniRealm，并将其传递给DefaultSecurityManager的构造函数： Realm realm = new MyCustomRealm(); SecurityManager securityManager = new DefaultSecurityManager(realm); 代码的所有其他部分都与以前相同。这就是我们使用自定义领域正确配置securityManager所需的全部内容。 现在的问题是——框架如何匹配凭证？ 默认情况下，JdbcRealm使用SimpleCredentialsMatcher ，它仅通过比较**AuthenticationToken和AuthenticationInfo中的凭据来检查是否相等。 如果我们散列密码，我们需要通知框架使用HashedCredentialsMatcher。可以在此处找到具有散列密码的领域的 INI 配置。 7. 登出 现在我们已经验证了用户，是时候实现注销了。这只需调用一个方法即可完成——该方法使用户会话无效并将用户注销： currentUser.logout(); 8. 会话管理 该框架自然带有其会话管理系统。如果在 Web 环境中使用，则默认为HttpSession实现。 对于独立应用程序，它使用其企业会话管理系统。好处是即使在桌面环境中，您也可以像在典型 Web 环境中那样使用会话对象。 让我们看一个简单的示例并与当前用户的会话进行交互： Session session = currentUser.getSession(); session.setAttribute(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); String value = (String) session.getAttribute(\u0026#34;key\u0026#34;); if (value.equals(\u0026#34;value\u0026#34;)) { log.info(\u0026#34;Retrieved the correct value! [\u0026#34; + value + \u0026#34;]\u0026#34;); } 9. Shiro 用于使用 Spring 的 Web 应用程序 到目前为止，我们已经概述了 Apache Shiro 的基本结构，并且我们已经在桌面环境中实现了它。让我们继续将框架集成到 Spring Boot 应用程序中。 请注意，这里的主要焦点是 Shiro，而不是 Spring 应用程序——我们只会使用它来支持一个简单的示例应用程序。 9.1 依赖项 首先，我们需要将 Spring Boot 父依赖添加到我们的pom.xml中： \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 接下来，我们必须将以下依赖项添加到同一个pom.xml文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-freemarker\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-spring-boot-web-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${apache-shiro-core-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 9.2. 配置 将shiro-spring-boot-web-starter依赖添加到我们的pom.xml将默认配置 Apache Shiro 应用程序的一些功能，例如SecurityManager。 但是，我们仍然需要配置Realm和 Shiro 安全过滤器。我们将使用上面定义的相同自定义领域。 因此，在运行 Spring Boot 应用程序的主类中，让我们添加以下Bean定义： @Bean public Realm realm() { return new MyCustomRealm(); } @Bean public ShiroFilterChainDefinition shiroFilterChainDefinition() { DefaultShiroFilterChainDefinition filter = new DefaultShiroFilterChainDefinition(); filter.addPathDefinition(\u0026#34;/secure\u0026#34;, \u0026#34;authc\u0026#34;); filter.addPathDefinition(\u0026#34;/**\u0026#34;, \u0026#34;anon\u0026#34;); return filter; } 在ShiroFilterChainDefinition中，我们将authc过滤器应用于*/secure路径，并使用 Ant 模式将anon过滤器应用于其他路径。* Web 应用程序默认提供 authc和anon过滤器。其他默认过滤器可以在这里找到。 如果我们没有定义Realm bean，ShiroAutoConfiguration将默认提供一个IniRealm实现，该实现期望在src/main/resources或src/main/resources/META-INF中找到一个**shiro.ini文件。 如果我们不定义ShiroFilterChainDefinition bean，框架会保护所有路径并将登录 URL 设置为login.jsp。 我们可以通过将以下条目添加到我们的application.properties来更改此默认登录 URL 和其他默认值： shiro.loginUrl = /login shiro.successUrl = /secure shiro.unauthorizedUrl = /login 现在authc过滤器已应用于*/secure*，对该路由的所有请求都需要表单身份验证。 9.3. 认证和授权 让我们创建一个具有以下路径映射的ShiroSpringController ： /index、/login、/logout和*/secure。* *login()*方法是我们实现如上所述的实际用户身份验证的地方。如果身份验证成功，用户将被重定向到安全页面： Subject subject = SecurityUtils.getSubject(); if(!subject.isAuthenticated()) { UsernamePasswordToken token = new UsernamePasswordToken( cred.getUsername(), cred.getPassword(), cred.isRememberMe()); try { subject.login(token); } catch (AuthenticationException ae) { ae.printStackTrace(); attr.addFlashAttribute(\u0026#34;error\u0026#34;, \u0026#34;Invalid Credentials\u0026#34;); return \u0026#34;redirect:/login\u0026#34;; } } return \u0026#34;redirect:/secure\u0026#34;; 现在在*secure()实现中，currentUser是通过调用SecurityUtils.getSubject() 获得的。*用户的角色和权限以及用户的主体被传递到安全页面： Subject currentUser = SecurityUtils.getSubject(); String role = \u0026#34;\u0026#34;, permission = \u0026#34;\u0026#34;; if(currentUser.hasRole(\u0026#34;admin\u0026#34;)) { role = role + \u0026#34;You are an Admin\u0026#34;; } else if(currentUser.hasRole(\u0026#34;editor\u0026#34;)) { role = role + \u0026#34;You are an Editor\u0026#34;; } else if(currentUser.hasRole(\u0026#34;author\u0026#34;)) { role = role + \u0026#34;You are an Author\u0026#34;; } if(currentUser.isPermitted(\u0026#34;articles:compose\u0026#34;)) { permission = permission + \u0026#34;You can compose an article, \u0026#34;; } else { permission = permission + \u0026#34;You are not permitted to compose an article!, \u0026#34;; } if(currentUser.isPermitted(\u0026#34;articles:save\u0026#34;)) { permission = permission + \u0026#34;You can save articles, \u0026#34;; } else { permission = permission + \u0026#34;\\nYou can not save articles, \u0026#34;; } if(currentUser.isPermitted(\u0026#34;articles:publish\u0026#34;)) { permission = permission + \u0026#34;\\nYou can publish articles\u0026#34;; } else { permission = permission + \u0026#34;\\nYou can not publish articles\u0026#34;; } modelMap.addAttribute(\u0026#34;username\u0026#34;, currentUser.getPrincipal()); modelMap.addAttribute(\u0026#34;permission\u0026#34;, permission); modelMap.addAttribute(\u0026#34;role\u0026#34;, role); return \u0026#34;secure\u0026#34;; **我们完成了。**这就是我们如何将 Apache Shiro 集成到 Spring Boot 应用程序中。 另外，请注意，该框架提供了额外的注释，可以与过滤器链定义一起使用以保护我们的应用程序。 10. JEE 集成 将 Apache Shiro 集成到 JEE 应用程序中只需配置web.xml文件。配置期望shiro.ini在类路径中。此处提供了详细的示例配置。此外，可以在此处找到 JSP 标记。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_shiro/","tags":[],"title":"Apache Shiro 简介"},{"categories":["Data","Spring Boot"],"contents":"1. 简介 在本教程中，我们将使用 Spring Boot 和开源分布式消息传递和流数据平台 Apache RocketMQ 创建消息生产者和消费者。 2. 依赖 对于 Maven 项目，我们需要添加RocketMQ Spring Boot Starter依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 产生消息 对于我们的示例，我们将创建一个基本的消息生产者，每当用户在购物车中添加或删除商品时，它都会发送事件。 首先，让我们在application.properties中设置我们的服务器位置和组名： rocketmq.name-server=127.0.0.1:9876 rocketmq.producer.group=cart-producer-group 请注意，如果我们有多个名称服务器，我们可以将它们列出为 host:port;host:port。 现在，为了简单起见，我们将创建一个CommandLineRunner应用程序并在应用程序启动期间生成一些事件： @SpringBootApplication public class CartEventProducer implements CommandLineRunner { @Autowired private RocketMQTemplate rocketMQTemplate; public static void main(String[] args) { SpringApplication.run(CartEventProducer.class, args); } public void run(String... args) throws Exception { rocketMQTemplate.convertAndSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); rocketMQTemplate.convertAndSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;computer\u0026#34;, 2)); rocketMQTemplate.convertAndSend(\u0026#34;cart-item-removed-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); } } CartItemEvent仅包含两个属性——商品的 id 和数量： class CartItemEvent { private String itemId; private int quantity; // constructor, getters and setters } 在上面的例子中，我们使用了convertAndSend()方法，一个由AbstractMessageSendingTemplate抽象类定义的通用方法，来发送我们的购物车事件。它有两个参数：一个目的地，在我们的例子中是一个主题名称，以及一个消息负载。 4.消息消费者 使用 RocketMQ 消息就像创建一个带有*@RocketMQMessageListener注解的 Spring 组件并实现RocketMQListener*接口一样简单： @SpringBootApplication public class CartEventConsumer { public static void main(String[] args) { SpringApplication.run(CartEventConsumer.class, args); } @Service @RocketMQMessageListener( topic = \u0026#34;cart-item-add-topic\u0026#34;, consumerGroup = \u0026#34;cart-consumer_cart-item-add-topic\u0026#34; ) public class CardItemAddConsumer implements RocketMQListener\u0026lt;CartItemEvent\u0026gt; { public void onMessage(CartItemEvent addItemEvent) { log.info(\u0026#34;Adding item: {}\u0026#34;, addItemEvent); // additional logic  } } @Service @RocketMQMessageListener( topic = \u0026#34;cart-item-removed-topic\u0026#34;, consumerGroup = \u0026#34;cart-consumer_cart-item-removed-topic\u0026#34; ) public class CardItemRemoveConsumer implements RocketMQListener\u0026lt;CartItemEvent\u0026gt; { public void onMessage(CartItemEvent removeItemEvent) { log.info(\u0026#34;Removing item: {}\u0026#34;, removeItemEvent); // additional logic  } } } 我们需要为我们正在监听的每个消息主题创建一个单独的组件。在每一个监听器中，我们通过@RocketMQMessageListener 注解定义主题名称和消费组名称*。* 5. 同步和异步传输 在前面的示例中，我们使用了convertAndSend方法来发送我们的消息。不过，我们还有其他一些选择。 例如，我们可以调用与 convertAndSend不同的syncSend ，因为它返回SendResult对象。 例如，它可以用来验证我们的消息是否成功发送或获取它的 id： public void run(String... args) throws Exception { SendResult addBikeResult = rocketMQTemplate.syncSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); SendResult addComputerResult = rocketMQTemplate.syncSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;computer\u0026#34;, 2)); SendResult removeBikeResult = rocketMQTemplate.syncSend(\u0026#34;cart-item-removed-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1)); } 与*convertAndSend 一样，*此方法仅在发送过程完成时返回。 在需要高可靠性的情况下，比如重要的通知消息或短信通知，我们应该使用同步传输。 另一方面，我们可能希望异步发送消息并在发送完成时收到通知。 我们可以使用 asyncSend来做到这一点，它接受一个 SendCallback作为参数并立即返回： rocketMQTemplate.asyncSend(\u0026#34;cart-item-add-topic\u0026#34;, new CartItemEvent(\u0026#34;bike\u0026#34;, 1), new SendCallback() { @Override public void onSuccess(SendResult sendResult) { log.error(\u0026#34;Successfully sent cart item\u0026#34;); } @Override public void onException(Throwable throwable) { log.error(\u0026#34;Exception during cart item sending\u0026#34;, throwable); } }); 我们在需要高吞吐量的情况下使用异步传输。 最后，对于吞吐量要求非常高的场景，我们可以使用sendOneWay代替asyncSend。 sendOneWay 与**asyncSend的不同之处在于它不保证消息会被发送。 单向传输也可以用于普通的可靠性情况，例如收集日志。 6. 在事务中发送消息 RocketMQ 为我们提供了在事务中发送消息的能力。我们可以使用*sendInTransaction()*方法来做到这一点： MessageBuilder.withPayload(new CartItemEvent(\u0026#34;bike\u0026#34;, 1)).build(); rocketMQTemplate.sendMessageInTransaction(\u0026#34;test-transaction\u0026#34;, \u0026#34;topic-name\u0026#34;, msg, null); 另外，我们必须实现一个RocketMQLocalTransactionListener接口： @RocketMQTransactionListener(txProducerGroup=\u0026#34;test-transaction\u0026#34;) class TransactionListenerImpl implements RocketMQLocalTransactionListener { @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) { // ... local transaction process, return ROLLBACK, COMMIT or UNKNOWN  return RocketMQLocalTransactionState.UNKNOWN; } @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) { // ... check transaction status and return ROLLBACK, COMMIT or UNKNOWN  return RocketMQLocalTransactionState.COMMIT; } } 在sendMessageInTransaction()中，第一个参数是事务名称。它必须与@RocketMQTransactionListener的成员字段txProducerGroup 相同。 7. 消息生产者配置 我们还可以配置消息生产者本身的各个方面：  Rocketmq.producer.send-message-timeout：消息发送超时时间，以毫秒为单位——默认值为 3000 RocketMQ.producer.compress-message-body-threshold：超过该阈值，RocketMQ 将压缩消息 - 默认值为 1024。 Rocketmq.producer.max-message-size：最大消息大小（以字节为单位）——默认值为 4096。 Rocketmq.producer.retry-times-when-send-async-failed：发送失败前在异步模式下内部执行的最大重试次数——默认值为 2。 Rocketmq.producer.retry-next-server：指示是否在内部发送失败时重试另一个代理 - 默认值为false。 Rocketmq.producer.retry-times-when-send-failed：发送失败前在异步模式下内部执行的最大重试次数——默认值为 2。 \u0026quot;  ","permalink":"http://itcodingman.github.io/apache_rocketmq_spring_boot/","tags":["Messaging"],"title":"带有 Spring Boot 的 Apache RocketMQ"},{"categories":["Architecture","Java"],"contents":"1. 简介 Apache Pulsar是 Yahoo 开发的基于分布式开源发布/订阅的消息传递系统。 它的创建是为了支持 Yahoo 的关键应用程序，如 Yahoo Mail、Yahoo Finance、Yahoo Sports 等。然后，在 2016 年，它在 Apache 软件基金会下开源。 2. 架构 Pulsar 是一种用于服务器到服务器消息传递的多租户、高性能解决方案。它由一组代理和 bookie 以及用于配置和管理的内置Apache ZooKeeper组成。bookie来自*Apache BookKeeper* ，它为消息提供存储，直到它们被使用。 在一个集群中，我们将拥有：  多个集群代理处理来自生产者的传入消息并将消息分发给消费者 Apache BookKeeper 支持消息持久化 Apache ZooKeeper 存储集群配置  为了更好地理解这一点，让我们看一下文档中的架构图： 3. 主要特点 让我们从快速浏览一些关键特性开始：  对多个集群的内置支持 支持跨多个集群的消息地理复制 多种订阅模式 可扩展到数百万个主题 使用 Apache BookKeeper 来保证消息传递。 低延迟  现在，让我们详细讨论一些关键功能。 3.1 消息模型 该框架提供了一个灵活的消息传递模型。一般来说，消息传递架构有两种消息传递模型，即队列和发布者/订阅者。发布者/订阅者是一个广播消息系统，其中消息被发送给所有消费者。另一方面，排队是点对点通信。 Pulsar 将这两个概念结合在一个通用 API中。发布者将消息发布到不同的主题。然后这些消息被广播到所有订阅者。 消费者订阅以获取消息。该库允许消费者选择不同的方式来消费同一订阅中的消息，包括独占、共享和故障转移。我们将在后面的部分详细讨论这些订阅类型。 3.2. 部署模式 Pulsar 内置了对不同环境中部署的支持。这意味着我们可以在标准的本地机器上使用它，或者将它部署在 Kubernetes 集群、谷歌或 AWS 云中。 它可以作为单个节点执行以用于开发和测试目的。在这种情况下，所有组件（代理、BookKeeper 和 ZooKeeper）都在单个进程中运行。 3.3. 异地复制 该库为数据的异地复制提供了开箱即用的支持。 我们可以通过配置不同的地理区域来启用多个集群之间的消息复制。 消息数据近乎实时地复制。如果跨集群发生网络故障，数据始终是安全的并存储在 BookKeeper 中。复制系统会继续重试，直到复制成功。 地理复制功能还允许组织跨不同的云提供商部署 Pulsar 并复制数据。这有助于他们避免使用专有的云提供商 API。 3.4. 持久性 Pulsar 读取并确认数据后，保证数据不丢失。数据持久性与配置为存储数据的磁盘数量有关。 Pulsar 通过使用在存储节点中运行的 bookies（Apache BookKeeper 实例）来确保持久性。每当 bookie 收到消息时，它都会在内存中保存一份副本，并将数据写入 WAL（预写日志）。此日志的工作方式与数据库 WAL 相同。Bookies 操作数据库事务原理，确保即使机器发生故障也不会丢失数据。 除此之外，Pulsar 还可以承受多个节点故障。库将数据复制到多个 bookie，然后向生产者发送确认消息。这种机制即使在多个硬件故障的情况下也能保证零数据丢失。 4. 单节点设置 现在让我们看看如何搭建 Apache Pulsar 的单节点集群。 Apache 还提供了一个简单的 客户端 API ，其中包含 Java、Python 和 C++ 的绑定。稍后我们将创建一个简单的 Java 生产者和订阅示例。 4.1 安装 Apache Pulsar 以二进制发行版的形式提供。让我们从下载它开始： wget https://archive.apache.org/dist/incubator/pulsar/pulsar-2.1.1-incubating/apache-pulsar-2.1.1-incubating-bin.tar.gz 下载完成后，我们可以解压缩 zip 文件。未归档的发行版将包含bin、conf、example、licenses 和lib文件夹。 之后，我们需要下载内置的连接器。这些现在作为一个单独的包发货： wget https://archive.apache.org/dist/incubator/pulsar/pulsar-2.1.1-incubating/apache-pulsar-io-connectors-2.1.1-incubating-bin.tar.gz 让我们解压连接器并将连接器文件夹复制到 Pulsar 文件夹中。 4.2. 启动实例 要启动一个独立实例，我们可以执行： bin/pulsar standalone 5. Java客户端 现在我们将创建一个 Java 项目来生成和使用消息。我们还将为不同的订阅类型创建示例。 5.1 设置项目 我们首先将pulsar-client依赖项添加到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.pulsar\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pulsar-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1-incubating\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5.2. 生产者 让我们继续创建一个Producer示例。在这里，我们将创建一个主题和一个生产者。 首先，我们需要创建一个 PulsarClient ，它将使用自己的协议**连接到特定主机和端口上的 Pulsar 服务 。**许多生产者和消费者可以共享一个客户端对象。 现在，我们将创建一个 具有特定主题名称的Producer ： private static final String SERVICE_URL = \u0026#34;pulsar://localhost:6650\u0026#34;; private static final String TOPIC_NAME = \u0026#34;test-topic\u0026#34;; PulsarClient client = PulsarClient.builder() .serviceUrl(SERVICE_URL) .build(); Producer\u0026lt;byte[]\u0026gt; producer = client.newProducer() .topic(TOPIC_NAME) .compressionType(CompressionType.LZ4) .create(); 生产者将发送 5 条消息： IntStream.range(1, 5).forEach(i -\u0026gt; { String content = String.format(\u0026#34;hi-pulsar-%d\u0026#34;, i); Message\u0026lt;byte[]\u0026gt; msg = MessageBuilder.create() .setContent(content.getBytes()) .build(); MessageId msgId = producer.send(msg); }); 5.3. 消费者 接下来，我们将创建消费者以获取生产者创建的消息。消费者也需要相同的PulsarClient 来连接我们的服务器： Consumer\u0026lt;byte[]\u0026gt; consumer = client.newConsumer() .topic(TOPIC_NAME) .subscriptionType(SubscriptionType.Shared) .subscriptionName(SUBSCRIPTION_NAME) .subscribe(); 在这里，我们创建了具有 共享订阅类型的客户端*。*这允许多个消费者附加到同一个订阅并获取消息。 5.4. 消费者订阅类型 在上面的消费者示例中，我们创建了一个共享类型的订阅。我们还可以创建 独占和故障转移订阅。 独占 订阅只允许订阅一个消费者。 另一方面，af ailover 订阅 允许用户定义后备消费者，以防一个消费者失败，如下面的 Apache 图表所示： \u0026quot; ","permalink":"http://itcodingman.github.io/apache_pulsar/","tags":["Messaging"],"title":"Apache Pulsar 简介"},{"categories":["Data"],"contents":"1. 简介 我们可以使用 Apache POI 在 Microsoft Excel 电子表格中以编程方式创建多行文本。但是，它不会显示为多行。这是因为使用代码向单元格添加文本不会自动调整单元格高度并应用所需的格式将其转换为多行文本。 这个简短的教程将演示正确显示此类文本所需的代码。 2. Apache POI 和 Maven 依赖 Apache POI 是一个开源库，允许软件开发人员创建和操作 Microsoft Office 文档。作为先决条件，读者可以参考我们关于在 Java 中使用 Microsoft Excel \u0026ldquo;在 Java 中使用 Microsoft Excel\u0026quot;的文章以及关于如何使用 Apache POI 在 Excel 中插入行 \u0026ldquo;使用 Apache POI 在 Excel 中插入一行\u0026quot;的教程。 首先，我们首先需要将Apache POI 依赖项添加到我们的项目 pom.xml 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 添加和格式化多行文本 让我们从一个包含多行文本的单元格开始： cell.setCellValue(\u0026#34;Hello \\n world!\u0026#34;); 如果我们要使用上面的代码生成并保存一个 Excel 文件。它将如下图所示： 我们可以点击上图中的 1 和 2 来验证文本确实是多行文本。 使用代码格式化单元格并将其行高扩展为等于或大于两行文本的任何值： cell.getRow() .setHeightInPoints(cell.getSheet().getDefaultRowHeightInPoints() * 2); 之后，我们需要设置单元格样式来换行： CellStyle cellStyle = cell.getSheet().getWorkbook().createCellStyle(); cellStyle.setWrapText(true); cell.setCellStyle(cellStyle); 保存使用上述代码生成的文件并在 Microsoft Excel 中查看它会在单元格中显示多行文本。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_write_multiline_text/","tags":["Excel"],"title":"使用 Apache POI 的 Excel 单元格中的多行文本"},{"categories":["Java"],"contents":"1. 简介 在本文中，我们将了解如何使用Apache POI创建演示文稿。 该库使我们能够创建 PowerPoint 演示文稿、阅读现有演示文稿并更改其内容。 2.Maven依赖 首先，我们需要将以下依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以从 Maven Central 下载这两个库的最新版本。 3. Apache POI Apache POI库支持*.ppt和*.pptx文件，它为 Powerpoint \u0026lsquo;97(-2007) 文件格式提供 HSLF 实现，为 PowerPoint 2007 OOXML 文件格式提供 XSLF。 由于这两种实现不存在通用接口，因此在使用较新的.pptx文件格式时，我们必须记住使用XMLSlideShow、XSLFSlide和XSLFTextShape类。 而且，当需要使用较旧的*.ppt格式时，请使用HSLFSlideShow*、HSLFSlide和HSLFTextParagraph类。 我们将在示例中使用新的*.pptx*文件格式，我们要做的第一件事是创建一个新的演示文稿，向其中添加一张幻灯片（可能使用预定义的布局）并保存它。 一旦这些操作变得清晰，我们就可以开始处理图像、文本和表格。 3.1 创建新演示文稿 让我们首先创建新的演示文稿： XMLSlideShow ppt = new XMLSlideShow(); ppt.createSlide(); 3.2. 添加新幻灯片 在向演示文稿添加新幻灯片时，我们还可以选择从预定义的布局创建它。为此，我们首先必须检索保存布局的XSLFSlideMaster（第一个是默认主控）： XSLFSlideMaster defaultMaster = ppt.getSlideMasters().get(0); 现在，我们可以检索XSLFSlideLayout并在创建新幻灯片时使用它： XSLFSlideLayout layout = defaultMaster.getLayout(SlideLayout.TITLE_AND_CONTENT); XSLFSlide slide = ppt.createSlide(layout); 让我们看看如何在模板中填充占位符： XSLFTextShape titleShape = slide.getPlaceholder(0); XSLFTextShape contentShape = slide.getPlaceholder(1); 请记住，每个模板都有其占位符，即XSLFAutoShape子类的实例，其数量可能因模板而异。 让我们看看如何从幻灯片中快速检索所有占位符： for (XSLFShape shape : slide.getShapes()) { if (shape instanceof XSLFAutoShape) { // this is a template placeholder  } } 3.3. 保存演示文稿 一旦我们创建了幻灯片，下一步就是保存它： FileOutputStream out = new FileOutputStream(\u0026#34;powerpoint.pptx\u0026#34;); ppt.write(out); out.close(); 4. 使用对象 现在我们已经了解了如何创建新的演示文稿、向其中添加幻灯片（使用或不使用预定义模板）并保存它，我们可以开始添加文本、图像、链接和表格。 让我们从文本开始。 4.1 文本 在演示文稿中处理文本时，如在 MS PowerPoint 中，我们必须在幻灯片中创建文本框，添加段落，然后将文本添加到段落中： XSLFTextBox shape = slide.createTextBox(); XSLFTextParagraph p = shape.addNewTextParagraph(); XSLFTextRun r = p.addNewTextRun(); r.setText(\u0026#34;Codingman\u0026#34;); r.setFontColor(Color.green); r.setFontSize(24.); 配置XSLFTextRun时，可以通过选择字体系列以及文本是否应为粗体、斜体或下划线来自定义其样式。 4.2. 超链接 在演示文稿中添加文本时，有时添加超链接会很有用。 一旦我们创建了XSLFTextRun对象，我们现在可以添加一个链接： XSLFHyperlink link = r.createHyperlink(); link.setAddress(\u0026#34;http://www.google.com\u0026#34;); 4.3. 图片 我们也可以添加图片： byte[] pictureData = IOUtils.toByteArray( new FileInputStream(\u0026#34;logo-leaf.png\u0026#34;)); XSLFPictureData pd = ppt.addPicture(pictureData, PictureData.PictureType.PNG); XSLFPictureShape picture = slide.createPicture(pd); 但是，如果没有适当的配置，图像将被放置在幻灯片的左上角。为了正确放置它，我们必须配置它的锚点： picture.setAnchor(new Rectangle(320, 230, 100, 92)); XSLFPictureShape接受一个矩形作为锚点，它允许我们使用前两个参数配置 x/y 坐标，并使用后两个参数配置图像的宽度/高度*。* 4.4. 列表 演示文稿中的文本通常以列表的形式表示，无论是否编号。 现在让我们定义一个要点列表： XSLFTextShape content = slide.getPlaceholder(1); XSLFTextParagraph p1 = content.addNewTextParagraph(); p1.setIndentLevel(0); p1.setBullet(true); r1 = p1.addNewTextRun(); r1.setText(\u0026#34;Bullet\u0026#34;); 同样，我们可以定义一个编号列表： XSLFTextParagraph p2 = content.addNewTextParagraph(); p2.setBulletAutoNumber(AutoNumberingScheme.alphaLcParenRight, 1); p2.setIndentLevel(1); XSLFTextRun r2 = p2.addNewTextRun(); r2.setText(\u0026#34;Numbered List Item - 1\u0026#34;); 如果我们使用多个列表，定义indentLevel以实现项目的正确缩进总是很重要的。 4.5. 表 表格是演示文稿中的另一个关键对象，在我们想要显示数据时很有帮助。 让我们从创建一个表开始： XSLFTable tbl = slide.createTable(); tbl.setAnchor(new Rectangle(50, 50, 450, 300)); 现在，我们可以添加一个标题： int numColumns = 3; XSLFTableRow headerRow = tbl.addRow(); headerRow.setHeight(50); for (int i = 0; i \u0026lt; numColumns; i++) { XSLFTableCell th = headerRow.addCell(); XSLFTextParagraph p = th.addNewTextParagraph(); p.setTextAlign(TextParagraph.TextAlign.CENTER); XSLFTextRun r = p.addNewTextRun(); r.setText(\u0026#34;Header \u0026#34; + (i + 1)); tbl.setColumnWidth(i, 150); } 完成表头后，我们可以在表格中添加行和单元格以显示数据： for (int rownum = 1; rownum \u0026lt; numRows; rownum++) { XSLFTableRow tr = tbl.addRow(); tr.setHeight(50); for (int i = 0; i \u0026lt; numColumns; i++) { XSLFTableCell cell = tr.addCell(); XSLFTextParagraph p = cell.addNewTextParagraph(); XSLFTextRun r = p.addNewTextRun(); r.setText(\u0026#34;Cell \u0026#34; + (i*rownum + 1)); } } 使用表格时，重要的是要提醒您可以自定义每个单元格的边框和背景。 5. 更改演示文稿 并非总是在制作幻灯片时，我们必须创建一个新的，但我们必须更改已经存在的。 让我们看一下我们在上一节中创建的那个，然后我们可以开始修改它： 5.1 阅读演示文稿 阅读演示文稿非常简单，可以使用接受FileInputStream的**XMLSlideShow重载构造函数来完成： XMLSlideShow ppt = new XMLSlideShow( new FileInputStream(\u0026#34;slideshow.pptx\u0026#34;)); 5.2. 更改幻灯片顺序 在我们的演示文稿中添加幻灯片时，最好将它们按正确的顺序放置以使幻灯片正确流动。 如果没有发生这种情况，则可以重新排列幻灯片的顺序。让我们看看如何将第四张幻灯片移动到第二张： List\u0026lt;XSLFSlide\u0026gt; slides = ppt.getSlides(); XSLFSlide slide = slides.get(3); ppt.setSlideOrder(slide, 1); 5.3. 删除幻灯片 也可以从演示文稿中删除幻灯片。 让我们看看如何删除第四张幻灯片： ppt.removeSlide(3); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_slideshow/","tags":[],"title":"用 Java 创建 MS PowerPoint 演示文稿"},{"categories":["Data"],"contents":"1. 简介 在 Java 中读取 Excel 文件时，我们通常希望读取单元格的值以执行一些计算或生成报告。但是，我们可能会遇到一个或多个包含公式而不是原始数据值的单元格。那么，我们如何获得这些单元格的实际数据值呢？ 在本教程中，我们将研究使用Apache POI Java 库读取 Excel 单元格值的不同方法——而不是计算单元格值的公式。 有两种方法可以解决这个问题：  获取单元格的最后一个缓存值 在运行时评估公式以获取单元格值  2. Maven依赖 我们需要在我们的 pom.xml 文件中为 Apache POI 添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  可以从 Maven Central 下载最新版本的poi-ooxml 。 3.获取最后一个缓存值 当公式计算单元格的值时，Excel 会为单元格存储两个对象。一是公式本身，二是缓存值。缓存的值包含公式计算的最后一个值。 所以这里的想法是我们可以获取最后一个缓存值并将其视为单元格值。最后一个缓存值是正确的单元格值可能并不总是正确的。但是，当我们使用已保存的 Excel 文件并且最近没有对文件进行修改时，最后缓存的值应该是单元格值。 让我们看看如何获取单元格的最后一个缓存值： FileInputStream inputStream = new FileInputStream(new File(\u0026#34;temp.xlsx\u0026#34;)); Workbook workbook = new XSSFWorkbook(inputStream); Sheet sheet = workbook.getSheetAt(0); CellAddress cellAddress = new CellAddress(\u0026#34;C2\u0026#34;); Row row = sheet.getRow(cellAddress.getRow()); Cell cell = row.getCell(cellAddress.getColumn()); if (cell.getCellType() == CellType.FORMULA) { switch (cell.getCachedFormulaResultType()) { case BOOLEAN: System.out.println(cell.getBooleanCellValue()); break; case NUMERIC: System.out.println(cell.getNumericCellValue()); break; case STRING: System.out.println(cell.getRichStringCellValue()); break; } } 4.评估公式以获取单元格值 Apache POI 提供了一个** FormulaEvaluator类，它使我们能够计算**Excel 表格中公式的结果。 因此，我们可以直接使用FormulaEvaluator在运行时计算单元格值。FormulaEvaluator类提供了一个名为evaluateFormulaCell 的方法，该方法计算给定Cell对象的单元格值并返回一个CellType对象，该对象表示单元格值的数据类型。 让我们看看这种方法的实际效果： // existing Workbook setup  FormulaEvaluator evaluator = workbook.getCreationHelper().createFormulaEvaluator(); // existing Sheet, Row, and Cell setup  if (cell.getCellType() == CellType.FORMULA) { switch (evaluator.evaluateFormulaCell(cell)) { case BOOLEAN: System.out.println(cell.getBooleanCellValue()); break; case NUMERIC: System.out.println(cell.getNumericCellValue()); break; case STRING: System.out.println(cell.getStringCellValue()); break; } } 5. 选择哪种方法 这两种方法之间的简单区别在于，第一种方法使用最后一个缓存值，第二种方法在运行时计算公式。 如果我们正在使用已保存的 Excel 文件并且我们不打算在运行时对该电子表格进行更改，那么缓存值方法会更好，因为我们不必评估公式。 但是，如果我们知道我们将在运行时进行频繁的更改，那么最好在运行时评估公式以获取单元格值。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_read_cell_value_formula/","tags":["Excel"],"title":"使用 Apache POI 读取 Excel 单元格值而不是公式"},{"categories":["Data"],"contents":"1. 概述 在本快速教程中，我们将演示如何使用 Apache POI 在 Excel 中格式化数字单元格。 2. Apache POI Apache POI是一个开源的纯 Java 项目。它提供了用于读取和写入 Microsoft Office 格式文件的库，例如 Word、PowerPoint 和Excel。 在使用较新的*.xlsx* 文件格式时，我们将使用 XSSFWorkbook类，对于*.xls* 格式，我们使用 HSSFWorkbook类*。* 3. 数字格式 Apache POI的setCellValue方法只接受**double作为输入或可以隐式转换为double并返回double作为数值的输入。setCellStyle方法用于添加所需的样式。Excel 数字格式中的 # 字符意味着如果需要在此处放置一个数字，而字符 0 意味着始终在此处放置一个数字，即使它是不必要的 0。 3.1 仅显示值的格式 让我们使用 0.00 或 #.## 等模式格式化*双精度值。*首先，我们将创建一个简单的实用方法来格式化单元格值： public static void applyNumericFormat(Workbook outWorkbook, Row row, Cell cell, Double value, String styleFormat) { CellStyle style = outWorkbook.createCellStyle(); DataFormat format = outWorkbook.createDataFormat(); style.setDataFormat(format.getFormat(styleFormat)); cell.setCellValue(value); cell.setCellStyle(style); } 让我们验证一个简单的代码来验证上述方法： File file = new File(\u0026#34;number_test.xlsx\u0026#34;); try (Workbook outWorkbook = new XSSFWorkbook()) { Sheet sheet = outWorkbook.createSheet(\u0026#34;Numeric Sheet\u0026#34;); Row row = sheet.createRow(0); Cell cell = row.createCell(0); ExcelNumericFormat.applyNumericFormat(outWorkbook, row, cell, 10.251, \u0026#34;0.00\u0026#34;); FileOutputStream fileOut = new FileOutputStream(file); outWorkbook.write(fileOut); fileOut.close(); } 这将在电子表格中添加数字单元格： 注意：显示值为格式化后的值，实际值不变。如果我们尝试访问同一个单元格，我们仍然会得到 10.251。 让我们验证实际值： try (Workbook inWorkbook = new XSSFWorkbook(\u0026#34;number_test.xlsx\u0026#34;)) { Sheet sheet = inWorkbook.cloneSheet(0); Row row = sheet.getRow(0); Assertions.assertEquals(10.251, row.getCell(0).getNumericCellValue()); } 3.2. 实际值和显示值的格式 让我们使用模式格式化显示和实际值： File file = new File(\u0026#34;number_test.xlsx\u0026#34;); try (Workbook outWorkbook = new HSSFWorkbook()) { Sheet sheet = outWorkbook.createSheet(\u0026#34;Numeric Sheet\u0026#34;); Row row = sheet.createRow(0); Cell cell = row.createCell(0); DecimalFormat df = new DecimalFormat(\u0026#34;#,###.##\u0026#34;); ExcelNumericFormat.applyNumericFormat(outWorkbook, row, cell, Double.valueOf(df.format(10.251)), \u0026#34;#,###.##\u0026#34;); FileOutputStream fileOut = new FileOutputStream(file); outWorkbook.write(fileOut); fileOut.close(); } 这将在电子表格中添加数字单元格并显示格式化的值，并且还会更改实际值： 让我们在上述情况下断言实际值： try (Workbook inWorkbook = new XSSFWorkbook(\u0026#34;number_test.xlsx\u0026#34;)) { Sheet sheet = inWorkbook.cloneSheet(0); Row row = sheet.getRow(0); Assertions.assertEquals(10.25, row.getCell(0).getNumericCellValue()); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_numeric_format/","tags":["Excel"],"title":"使用 POI 的数字格式"},{"categories":["Data"],"contents":"1. 简介 Apache POI是一个开源库，供软件开发人员创建和操作 Microsoft Office 文档。除其他功能外，它还允许开发人员以编程方式更改文档格式。 在本文中，我们将讨论在使用名为CellStyle的类时如何在 Microsoft Excel 中更改单元格的样式。也就是说，使用这个类，我们可以编写代码来修改Microsoft Excel 文档中单元格的样式。首先，它是 Apache POI 库提供的一项功能，允许在工作簿中创建具有多种格式属性的样式。其次，可以将样式应用于该工作簿中的多个单元格。 除此之外，我们还将了解使用CellStyle类的常见缺陷。 2. Apache POI 和 Maven 依赖 让我们将Apache POI作为依赖项添加到我们的项目pom.xml 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 创建CellStyle 让我们从实例化CellStyle开始： Workbook workbook = new XSSFWorkbook(fileLocation); CellStyle cellStyle = wb.createCellStyle(); 接下来，设置好所需的格式化属性。例如，下面的代码会将其设置为日期格式： cellStyle.setDataFormat(createHelper.createDataFormat().getFormat(\u0026#34;m/d/yy h:mm\u0026#34;)); 最重要的是，我们可以设置CellStyle的多个格式属性来获得所需的样式组合。例如，我们将以下代码应用于同一个CellStyle对象。因此，它具有日期格式样式以及居中对齐的文本样式： cellStyle.setAlignment(HorizontalAlignment.CENTER); 请注意，CellStyle有几个我们可以修改的格式属性：    财产 描述     数据格式 单元格的数据格式，例如日期   结盟 单元格的水平对齐类型   隐 是否要隐藏单元格   缩进 用于缩进单元格中文本的空格数   边框底部,    左边框，     右边框， 边框顶部 | 用于单元格的底部、左侧、右侧和顶部边框的边框类型 | | 字体 | 此样式的字体属性，例如字体颜色 | 稍后我们将在使用Font属性更改字体样式时再次查看它。 4. 使用CellStyle格式化字体 CellStyle的Font属性是我们设置字体相关格式的地方。例如，我们可以设置字体名称、颜色和大小。我们可以设置字体是粗体还是斜体。Font的两个属性都可以是true或false。我们还可以将下划线样式设置为：    价值 财产     U_NONE 没有下划线的文字   U_SINGLE 单下划线文本，其中只有单词带下划线   U_SINGLE_ACCOUNTING 几乎整个单元格宽度都带有下划线的单个下划线文本   U_DOUBLE 双下划线文本，其中只有单词带下划线   U_DOUBLE_ACCOUNTING 双下划线文本，几乎整个单元格宽度都带有下划线    让我们从前面的例子继续。我们将编写一个名为CellStyler的类，其中包含一个为警告文本创建样式的方法： public class CellStyler { public CellStyle createWarningColor(Workbook workbook) { CellStyle style = workbook.createCellStyle(); Font font = workbook.createFont(); font.setFontName(\u0026#34;Courier New\u0026#34;); font.setBold(true); font.setUnderline(Font.U_SINGLE); font.setColor(HSSFColorPredefined.DARK_RED.getIndex()); style.setFont(font); style.setAlignment(HorizontalAlignment.CENTER); style.setVerticalAlignment(VerticalAlignment.CENTER); return style; } } 现在，让我们创建一个 Apache POI 工作簿并获取第一个工作表： Workbook workbook = new XSSFWorkbook(fileLocation); Sheet sheet = workbook.getSheetAt(0); 请注意，我们正在设置行高，以便我们可以看到文本对齐的效果： Row row1 = sheet.createRow(0); row1.setHeightInPoints((short) 40); 让我们实例化该类并使用它来设置样式 CellStyler styler = new CellStyler(); CellStyle style = styler.createWarningColor(workbook); Cell cell1 = row1.createCell(0); cell1.setCellStyle(style); cell1.setCellValue(\u0026#34;Hello\u0026#34;); Cell cell2 = row1.createCell(1); cell2.setCellStyle(style); cell2.setCellValue(\u0026#34;world!\u0026#34;); 现在，让我们将此工作簿保存到一个文件中，并在 Microsoft Excel 中打开该文件以查看字体样式效果，我们应该在其中看到：  5. 常见的陷阱 让我们看看使用CellStyle 时常犯的两个错误。 5.1 意外修改所有单元格样式 首先，从单元格中获取CellStyle并开始修改它是一个常见的错误。getCellStyle方法的 Apache POI 文档提到单元格的getCellStyle方法将始终返回非空值。这意味着单元格有一个默认值，这也是工作簿中所有单元格最初使用的默认样式。因此，下面的代码将使所有单元格都具有日期格式： cell.setCellValue(rdf.getEffectiveDate()); cell.getCellStyle().setDataFormat(HSSFDataFormat.getBuiltinFormat(\u0026#34;d-mmm-yy\u0026#34;)); 5.2. 为每个单元格创建新样式 另一个常见的错误是工作簿中有太多相似的样式： CellStyle style1 = codeToCreateCellStyle(); Cell cell1 = row1.createCell(0); cell1.setCellStyle(style1); CellStyle style2 = codeToCreateCellStyle(); Cell cell2 = row1.createCell(1); cell2.setCellStyle(style2); 一个CellStyle的范围是一个工作簿。因此，多个单元格应共享类似的样式。在上面的示例中，样式应该只创建一次并在cell1和cell2之间共享： CellStyle style1 = codeToCreateCellStyle(); Cell cell1 = row1.createCell(0); cell1.setCellStyle(style1); cell1.setCellValue(\u0026#34;Hello\u0026#34;); Cell cell2 = row1.createCell(1); cell2.setCellStyle(style1); cell2.setCellValue(\u0026#34;world!\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_change_cell_font/","tags":["Excel"],"title":"使用 Apache POI 更改单元格字体样式"},{"categories":["Data"],"contents":"1. 概述 在 Excel 工作表上，当我们通过更改表头的背景颜色来突出显示表头时，它总是看起来很优雅。本文介绍如何使用Apache POI更改单元格背景颜色。 此外，我们建议阅读我们在 Java 中使用 Microsoft Excel教程，以了解在 Java 中使用 Excel 的一些基础知识。 2. Maven依赖 首先，我们需要在pom.xml中添加**poi-ooxml作为依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.更改单元格背景颜色 3.1 关于单元格背景 在 Excel 工作表上，我们可以通过填充颜色或图案来更改单元格背景。在下图中，单元格A1填充有浅蓝色背景，而单元格B1填充有图案。此图案有黑色背景和顶部的浅蓝色斑点： 3.2. 更改背景颜色的代码 Apache POI 提供了三种更改背景颜色的方法。在CellStyle类中，我们可以为此目的使用setFillForegroundColor、setFillPattern和setFillBackgroundColor方法。**在IndexedColors类中定义了一个颜色列表。同样，在FillPatternType中定义了一个模式列表。 有时，名称setFillBackgroundColor可能会误导我们。但是，该方法本身不足以改变单元格背景。要通过填充纯色来更改单元格背景，我们使用setFillForegroundColor和setFillPattern方法。第一种方法告诉要填充什么颜色，而第二种方法指定要使用的纯色填充图案。 以下代码段是更改单元格背景的示例方法，如单元格A1所示： public void changeCellBackgroundColor(Cell cell) { CellStyle cellStyle = cell.getCellStyle(); if(cellStyle == null) { cellStyle = cell.getSheet().getWorkbook().createCellStyle(); } cellStyle.setFillForegroundColor(IndexedColors.LIGHT_BLUE.getIndex()); cellStyle.setFillPattern(FillPatternType.SOLID_FOREGROUND); cell.setCellStyle(cellStyle); } 要使用图案更改单元格背景，我们需要使用两种颜色：一种颜色填充整个背景，另一种颜色在第一种颜色之上填充图案。在这里，我们需要使用所有这三种方法。 这里使用方法setFillBackgroundColor来指定背景颜色。仅使用此方法不会产生任何效果。我们需要使用setFillForegroundColor选择第二种颜色并使用setFillPattern来说明图案类型。 以下代码段是更改单元格背景的示例方法，如单元格B1所示： public void changeCellBackgroundColorWithPattern(Cell cell) { CellStyle cellStyle = cell.getCellStyle(); if(cellStyle == null) { cellStyle = cell.getSheet().getWorkbook().createCellStyle(); } cellStyle.setFillBackgroundColor(IndexedColors.BLACK.index); cellStyle.setFillPattern(FillPatternType.BIG_SPOTS); cellStyle.setFillForegroundColor(IndexedColors.LIGHT_BLUE.getIndex()); cell.setCellStyle(cellStyle); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_background_color/","tags":["Excel"],"title":"使用 Apache POI 设置单元格的背景颜色"},{"categories":["Java"],"contents":"1. 概述 在本教程中，我们将学习如何使用Apache POI Java 库为 Excel 工作表添加边框。 有关 excel 处理的更多基础知识，我们可以从使用 Java 中的 Microsoft Excel开始。 2.Excel边框 我们可以为 Excel 单元格或一系列单元格创建边框。这些边界线可以有多种样式。一些示例样式包括粗线、细线、中线、虚线。为了增加更多种类，我们可以有彩色边框。 此图像显示了其中一些品种边界：  单元格B2带有粗线边框 D2细胞具有宽紫色边框 F2单元格有一个疯狂的边框，边框的每一边都有不同的样式和颜色 范围B4:F6带有中等大小的边框 区域B8:F9带有中等大小的橙色边框  3. Excel 边框编码 Apache POI 库提供了多种处理边界的方法。一种简单的方法是引用单元格范围并应用边框。 3.1 单元格范围或区域 要引用一系列单元格，我们可以使用CellRangeAddress类： CellRangeAddress region = new CellRangeAddress(7, 8, 1, 5); CellRangeAddress构造函数采用第一行、最后一行、第一列和最后一列四个参数。每个行和列索引都从零开始。在上面的代码中，它指的是单元格范围B8:F9。 我们还可以使用CellRangeAddress类引用一个单元格： CellRangeAddress region = new CellRangeAddress(1, 1, 5, 5); 上面的代码是指F2单元格。 3.2. 单元格边界 每个边框有四个边：上、下、左和右边框。我们必须分别设置边框样式的每一侧。BorderStyle类提供了多种样式。 我们可以使用RangeUtil类设置边框： RegionUtil.setBorderTop(BorderStyle.DASH_DOT, region, sheet); RegionUtil.setBorderBottom(BorderStyle.DOUBLE, region, sheet); RegionUtil.setBorderLeft(BorderStyle.DOTTED, region, sheet); RegionUtil.setBorderRight(BorderStyle.SLANTED_DASH_DOT, region, sheet); 3.3. 边框颜色 边框颜色也必须在每一侧单独设置。IndexedColors类提供了一系列要使用的颜色。 我们可以使用RangeUtil类设置边框颜色： RegionUtil.setTopBorderColor(IndexedColors.RED.index, region, sheet); RegionUtil.setBottomBorderColor(IndexedColors.GREEN.index, region, sheet); RegionUtil.setLeftBorderColor(IndexedColors.BLUE.index, region, sheet); RegionUtil.setRightBorderColor(IndexedColors.VIOLET.index, region, sheet); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_poi_add_borders/","tags":["Excel"],"title":"使用 Apache POI 为 Excel 单元格添加边框"},{"categories":["Algorithms"],"contents":"1. 概述 Apache OpenNLP 是一个开源的自然语言处理 Java 库。 它具有用于命名实体识别、句子检测、POS 标记和标记化等用例的 API。 在本教程中，我们将了解如何将此 API 用于不同的用例。 2. Maven 设置 首先，我们需要将主要依赖添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.opennlp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opennlp-tools\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新的稳定版本可以在Maven Central上找到。 一些用例需要经过训练的模型。您可以在此处下载预定义模型，并在此处下载有关这些模型的详细信息。 3. 句子检测 让我们从了解什么是句子开始。 句子检测是关于识别句子的开头和结尾，这通常取决于手头的语言。这也称为“句子边界消歧”（SBD）。 在某些情况下，由于句号的模棱两可，句子检测非常具有挑战性。句点通常表示句子的结尾，但也可以出现在电子邮件地址、缩写、小数点和许多其他地方。 对于大多数 NLP 任务，对于句子检测，我们需要一个经过训练的模型作为输入，我们希望它位于*/resources*文件夹中。 为了实现句子检测，我们加载模型并将其传递给 SentenceDetectorME的实例。然后，我们只需将文本传递给*sentDetect()*方法以在句子边界处拆分它： @Test public void givenEnglishModel_whenDetect_thenSentencesAreDetected() throws Exception { String paragraph = \u0026#34;This is a statement. This is another statement.\u0026#34; + \u0026#34;Now is an abstract word for time, \u0026#34; + \u0026#34;that is always flying. And my email address is [[email protected]](cdn-cgi/l/email-protection)\u0026#34;; InputStream is = getClass().getResourceAsStream(\u0026#34;/models/en-sent.bin\u0026#34;); SentenceModel model = new SentenceModel(is); SentenceDetectorME sdetector = new SentenceDetectorME(model); String sentences[] = sdetector.sentDetect(paragraph); assertThat(sentences).contains( \u0026#34;This is a statement.\u0026#34;, \u0026#34;This is another statement.\u0026#34;, \u0026#34;Now is an abstract word for time, that is always flying.\u0026#34;, \u0026#34;And my email address is [[email protected]](cdn-cgi/l/email-protection)\u0026#34;); } 注意：后缀“ME”用于 Apache OpenNLP 的许多类名中，表示基于“最大熵”的算法。 4. 分词 现在我们可以将文本语料库划分为句子，我们可以开始更详细地分析句子。 标记化的目标是将一个句子分成更小的部分，称为标记。通常，这些标记是单词、数字或标点符号。 OpenNLP 中提供了三种类型的标记器。 4.1 使用TokenizerME 在这种情况下，我们首先需要加载模型。我们可以从这里下载模型文件，将它放在*/resources*文件夹中，然后从那里加载它。 接下来，我们将使用加载的模型创建TokenizerME的实例 ，并使用tokenize()方法对任何字符串执行标记化： @Test public void givenEnglishModel_whenTokenize_thenTokensAreDetected() throws Exception { InputStream inputStream = getClass() .getResourceAsStream(\u0026#34;/models/en-token.bin\u0026#34;); TokenizerModel model = new TokenizerModel(inputStream); TokenizerME tokenizer = new TokenizerME(model); String[] tokens = tokenizer.tokenize(\u0026#34;Demo is a Spring Resource.\u0026#34;); assertThat(tokens).contains( \u0026#34;Demo\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;Spring\u0026#34;, \u0026#34;Resource\u0026#34;, \u0026#34;.\u0026#34;); } 正如我们所见，分词器已将所有单词和句点字符识别为单独的令牌。此标记器也可以与自定义训练模型一起使用。 **4.2. WhitespaceTokenizer ** 顾名思义，这个分词器只是使用空白字符作为分隔符将句子拆分为分词： @Test public void givenWhitespaceTokenizer_whenTokenize_thenTokensAreDetected() throws Exception { WhitespaceTokenizer tokenizer = WhitespaceTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;Demo is a Spring Resource.\u0026#34;); assertThat(tokens) .contains(\u0026#34;Demo\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;Spring\u0026#34;, \u0026#34;Resource.\u0026#34;); } 我们可以看到句子被空格分割，因此我们得到“资源”。（末尾带有句点字符）作为单个标记，而不是单词“资源”和句点字符的两个不同标记。 **4.3. SimpleTokenizer ** 这个分词器比WhitespaceTokenizer稍微复杂一点，它将句子分成单词、数字和标点符号。这是默认行为，不需要任何模型： @Test public void givenSimpleTokenizer_whenTokenize_thenTokensAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer .tokenize(\u0026#34;Demo is a Spring Resource.\u0026#34;); assertThat(tokens) .contains(\u0026#34;Demo\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;Spring\u0026#34;, \u0026#34;Resource\u0026#34;, \u0026#34;.\u0026#34;); } 5. 命名实体识别 现在我们已经了解了标记化，让我们看一下基于成功标记化的第一个用例：命名实体识别 (NER)。 NER 的目标是在给定文本中找到命名实体，例如人、位置、组织和其他命名事物。 OpenNLP 使用人名、日期和时间、位置和组织的预定义模型。我们需要使用TokenNameFinderModel加载模型并将其传递给*NameFinderME 的实例。然后我们可以使用find()*方法在给定文本中查找命名实体： @Test public void givenEnglishPersonModel_whenNER_thenPersonsAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer .tokenize(\u0026#34;John is 26 years old. His best friend\u0026#39;s \u0026#34; + \u0026#34;name is Leonard. He has a sister named Penny.\u0026#34;); InputStream inputStreamNameFinder = getClass() .getResourceAsStream(\u0026#34;/models/en-ner-person.bin\u0026#34;); TokenNameFinderModel model = new TokenNameFinderModel( inputStreamNameFinder); NameFinderME nameFinderME = new NameFinderME(model); List\u0026lt;Span\u0026gt; spans = Arrays.asList(nameFinderME.find(tokens)); assertThat(spans.toString()) .isEqualTo(\u0026#34;[[0..1) person, [13..14) person, [20..21) person]\u0026#34;); } 正如我们在断言中看到的，结果是一个Span对象列表，其中包含组成文本中命名实体的标记的开始和结束索引。 6. 词性标注 另一个需要标记列表作为输入的用例是词性标记。 **词性（POS）识别词的类型。**OpenNLP 对不同的词性使用以下标签：  **NN –**名词、单数或质量 **DT——**确定者 **VB——**动词，基本形式 **VBD——**动词，过去式 **VBZ –**动词，第三人称单数现在时 **IN——**介词或从属连词 **NNP –**专有名词，单数 TO—— “到”这个词 **JJ——**形容词  这些标签与 Penn Tree Bank 中定义的标签相同。如需完整列表，请参阅 此列表。 与 NER 示例类似，我们加载适当的模型，然后 在一组标记上使用POSTaggerME 及其方法tag()来标记句子： @Test public void givenPOSModel_whenPOSTagging_thenPOSAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;John has a sister named Penny.\u0026#34;); InputStream inputStreamPOSTagger = getClass() .getResourceAsStream(\u0026#34;/models/en-pos-maxent.bin\u0026#34;); POSModel posModel = new POSModel(inputStreamPOSTagger); POSTaggerME posTagger = new POSTaggerME(posModel); String tags[] = posTagger.tag(tokens); assertThat(tags).contains(\u0026#34;NNP\u0026#34;, \u0026#34;VBZ\u0026#34;, \u0026#34;DT\u0026#34;, \u0026#34;NN\u0026#34;, \u0026#34;VBN\u0026#34;, \u0026#34;NNP\u0026#34;, \u0026#34;.\u0026#34;); } *tag()*方法将标记映射到 POS 标签列表中。示例中的结果是：  “John” - NNP（专有名词） “has” – VBZ（动词） “a” – DT（决定者） “sister”——NN（名词） “named” – VBZ（动词） “Penny” – NNP（专有名词） “.” - 时期  7. 词形还原 现在我们有了句子中标记的词性信息，我们可以进一步分析文本。 词形还原是将具有时态、性别、情绪或其他信息的词形映射到词****的基本形式的过程——也称为“引理”。 lemmatizer 将标记及其词性标记作为输入并返回单词的 lemma。因此，在词形还原之前，句子应该通过分词器和词性标注器。 Apache OpenNLP 提供两种类型的词形还原：  统计 - 需要使用训练数据构建的 lemmatizer 模型来查找给定单词的 lemma 基于字典 - 需要包含单词、POS 标签和相应引理的所有有效组合的字典  对于统计词形还原，我们需要训练一个模型，而对于字典词形还原，我们只需要一个像这样的字典文件。 让我们看一个使用字典文件的代码示例： @Test public void givenEnglishDictionary_whenLemmatize_thenLemmasAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;John has a sister named Penny.\u0026#34;); InputStream inputStreamPOSTagger = getClass() .getResourceAsStream(\u0026#34;/models/en-pos-maxent.bin\u0026#34;); POSModel posModel = new POSModel(inputStreamPOSTagger); POSTaggerME posTagger = new POSTaggerME(posModel); String tags[] = posTagger.tag(tokens); InputStream dictLemmatizer = getClass() .getResourceAsStream(\u0026#34;/models/en-lemmatizer.dict\u0026#34;); DictionaryLemmatizer lemmatizer = new DictionaryLemmatizer( dictLemmatizer); String[] lemmas = lemmatizer.lemmatize(tokens, tags); assertThat(lemmas) .contains(\u0026#34;O\u0026#34;, \u0026#34;have\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;sister\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;O\u0026#34;, \u0026#34;O\u0026#34;); } 正如我们所见，我们得到了每个标记的引理。“O”表示无法确定引理，因为该词是专有名词。所以，我们没有“John”和“Penny”的引理。 但是我们已经确定了句子其他单词的引理：  有——有 一个 - 一个 姐姐——姐姐 命名——名字  8. 分块 词性信息在分块中也很重要—— 将句子分成语法上有意义的词组，如名词组或动词组。 *与之前类似，我们标记一个句子并在调用chunk()*方法之前对标记使用词性标记 ： @Test public void givenChunkerModel_whenChunk_thenChunksAreDetected() throws Exception { SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE; String[] tokens = tokenizer.tokenize(\u0026#34;He reckons the current account deficit will narrow to only 8 billion.\u0026#34;); InputStream inputStreamPOSTagger = getClass() .getResourceAsStream(\u0026#34;/models/en-pos-maxent.bin\u0026#34;); POSModel posModel = new POSModel(inputStreamPOSTagger); POSTaggerME posTagger = new POSTaggerME(posModel); String tags[] = posTagger.tag(tokens); InputStream inputStreamChunker = getClass() .getResourceAsStream(\u0026#34;/models/en-chunker.bin\u0026#34;); ChunkerModel chunkerModel = new ChunkerModel(inputStreamChunker); ChunkerME chunker = new ChunkerME(chunkerModel); String[] chunks = chunker.chunk(tokens, tags); assertThat(chunks).contains( \u0026#34;B-NP\u0026#34;, \u0026#34;B-VP\u0026#34;, \u0026#34;B-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;B-VP\u0026#34;, \u0026#34;I-VP\u0026#34;, \u0026#34;B-PP\u0026#34;, \u0026#34;B-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;I-NP\u0026#34;, \u0026#34;O\u0026#34;); } 正如我们所看到的，我们从分块器中获得了每个标记的输出。“B”代表块的开始，“I”代表块的延续，“O”代表没有块。 解析我们示例的输出，我们得到 6 个块：  “他”——名词短语 “估计” - 动词短语 “经常账户赤字”——名词短语 “将缩小” - 动词短语 “to”——介词短语 “只有 80 亿”——名词短语  9. 语言检测 除了已经讨论过的用例之外，OpenNLP 还提供了一个语言检测 API，允许识别特定文本的语言。 对于语言检测，我们需要一个训练数据文件。这样的文件包含带有某种语言句子的行。每一行都标有正确的语言，为机器学习算法提供输入。 可以在此处下载用于语言检测的样本训练数据文件。 我们可以将训练数据文件加载到 LanguageDetectorSampleStream 中， 定义一些训练数据参数，创建模型，然后使用该模型检测文本的语言： @Test public void givenLanguageDictionary_whenLanguageDetect_thenLanguageIsDetected() throws FileNotFoundException, IOException { InputStreamFactory dataIn = new MarkableFileInputStreamFactory( new File(\u0026#34;src/main/resources/models/DoccatSample.txt\u0026#34;)); ObjectStream lineStream = new PlainTextByLineStream(dataIn, \u0026#34;UTF-8\u0026#34;); LanguageDetectorSampleStream sampleStream = new LanguageDetectorSampleStream(lineStream); TrainingParameters params = new TrainingParameters(); params.put(TrainingParameters.ITERATIONS_PARAM, 100); params.put(TrainingParameters.CUTOFF_PARAM, 5); params.put(\u0026#34;DataIndexer\u0026#34;, \u0026#34;TwoPass\u0026#34;); params.put(TrainingParameters.ALGORITHM_PARAM, \u0026#34;NAIVEBAYES\u0026#34;); LanguageDetectorModel model = LanguageDetectorME .train(sampleStream, params, new LanguageDetectorFactory()); LanguageDetector ld = new LanguageDetectorME(model); Language[] languages = ld .predictLanguages(\u0026#34;estava em uma marcenaria na Rua Bruno\u0026#34;); assertThat(Arrays.asList(languages)) .extracting(\u0026#34;lang\u0026#34;, \u0026#34;confidence\u0026#34;) .contains( tuple(\u0026#34;pob\u0026#34;, 0.9999999950605625), tuple(\u0026#34;ita\u0026#34;, 4.939427661577956E-9), tuple(\u0026#34;spa\u0026#34;, 9.665954064665144E-15), tuple(\u0026#34;fra\u0026#34;, 8.250349924885834E-25))); } 结果是最可能的语言列表以及置信度分数。 并且，通过丰富的模型，我们可以通过这种类型的检测实现非常高的准确度。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_open_nlp/","tags":[],"title":"Apache OpenNLP 简介"},{"categories":["Architecture"],"contents":"1. 概述 我们通常在同一个机器集群上部署各种应用程序。例如，现在很常见的是 在同一个集群中拥有像Apache Spark或Apache Flink这样的分布式处理引擎和像Apache Cassandra这样的分布式数据库。 Apache Mesos 是一个允许此类应用程序之间有效资源共享的平台。 在本文中，我们将首先讨论部署在同一集群上的应用程序中的资源分配问题。稍后，我们将看到 Apache Mesos 如何在应用程序之间提供更好的资源利用率。 2. 共享集群 许多应用程序需要共享一个集群。总的来说，有两种常见的方法：  静态分区集群并在每个分区上运行应用程序 将一组机器分配给一个应用程序  尽管这些方法允许应用程序彼此独立运行，但它并没有实现高资源利用率。 例如，考虑一个应用程序，它只运行了很短的时间，然后是一段时间的不活动。现在，由于我们为该应用程序分配了静态机器或分区，因此在非活动期间我们有未使用的资源。 我们可以通过将非活动期间的空闲资源重新分配给其他应用程序来优化资源利用率。 Apache Mesos 有助于在应用程序之间进行动态资源分配。 3. Apache Mesos 使用我们上面讨论的两种集群共享方法，应用程序只知道它们正在运行的特定分区或机器的资源。但是，Apache Mesos 为应用程序提供了集群中所有资源的抽象视图。 我们很快就会看到，Mesos 充当机器和应用程序之间的接口。它为应用程序提供**集群中所有机器上的可用资源。它经常更新此信息以包括由已达到完成状态的应用程序释放的资源。**这允许应用程序就在哪台机器上执行哪个任务做出最佳决定。 为了理解 Mesos 是如何工作的，让我们来看看它的架构：  此图像是 Mesos 官方文档的一部分（来源）。在这里，Hadoop和MPI是共享集群的两个应用程序。 我们将在接下来的几节中讨论此处显示的每个组件。 3.1 Mesos 大师 Master 是此设置中的核心组件，用于存储集群中资源的当前状态。此外，它通过传递有关资源和任务等信息，充当代理和应用程序之间的协调器。 由于 master 中的任何故障都会导致有关资源和任务的状态丢失，因此我们将其部署在高可用性配置中。从上图中可以看出，Mesos 部署了备用主守护进程和一个领导者。这些守护进程依靠 Zookeeper 来在发生故障时恢复状态。 3.2. Mesos 代理 Mesos 集群必须在每台机器上运行一个代理。这些代理会定期向主服务器报告它们的资源，并依次接收应用程序已安排运行的任务。此循环在计划任务完成或丢失后重复。 我们将在以下部分中了解应用程序如何在这些代理上调度和执行任务。 3.3. 中观框架 Mesos 允许应用程序实现一个抽象组件，该组件与 Master 交互以**接收集群中的可用资源，并根据它们做出调度决策。**这些组件称为框架。 一个 Mesos 框架由两个子组件组成：  调度程序- 使应用程序能够根据所有代理上的可用资源来调度任务 Executor – 在所有代理上运行，并包含在该代理上执行任何计划任务所需的所有信息  这个流程描述了整个过程： 首先，代理向主报告他们的资源。此时，master 将这些资源提供给所有已注册的调度程序。此过程称为资源提供，我们将在下一节中详细讨论。 然后调度程序选择最好的代理并通过 Master 在其上执行各种任务。一旦执行者完成分配的任务，代理就会重新将他们的资源发布给主节点。Master 对集群中的所有框架重复这个资源共享过程。 Mesos 允许应用程序以各种编程语言实现其自定义调度程序和执行程序。调度程序的Java 实现必须实现调度程序接口： public class HelloWorldScheduler implements Scheduler { @Override public void registered(SchedulerDriver schedulerDriver, Protos.FrameworkID frameworkID, Protos.MasterInfo masterInfo) { } @Override public void reregistered(SchedulerDriver schedulerDriver, Protos.MasterInfo masterInfo) { } @Override public void resourceOffers(SchedulerDriver schedulerDriver, List\u0026lt;Offer\u0026gt; list) { } @Override public void offerRescinded(SchedulerDriver schedulerDriver, OfferID offerID) { } @Override public void statusUpdate(SchedulerDriver schedulerDriver, Protos.TaskStatus taskStatus) { } @Override public void frameworkMessage(SchedulerDriver schedulerDriver, Protos.ExecutorID executorID, Protos.SlaveID slaveID, byte[] bytes) { } @Override public void disconnected(SchedulerDriver schedulerDriver) { } @Override public void slaveLost(SchedulerDriver schedulerDriver, Protos.SlaveID slaveID) { } @Override public void executorLost(SchedulerDriver schedulerDriver, Protos.ExecutorID executorID, Protos.SlaveID slaveID, int i) { } @Override public void error(SchedulerDriver schedulerDriver, String s) { } } 可以看出，它主要由各种回调方法组成，特别是用于与主设备通信。 同样，执行器的实现必须实现Executor接口： public class HelloWorldExecutor implements Executor { @Override public void registered(ExecutorDriver driver, Protos.ExecutorInfo executorInfo, Protos.FrameworkInfo frameworkInfo, Protos.SlaveInfo slaveInfo) { } @Override public void reregistered(ExecutorDriver driver, Protos.SlaveInfo slaveInfo) { } @Override public void disconnected(ExecutorDriver driver) { } @Override public void launchTask(ExecutorDriver driver, Protos.TaskInfo task) { } @Override public void killTask(ExecutorDriver driver, Protos.TaskID taskId) { } @Override public void frameworkMessage(ExecutorDriver driver, byte[] data) { } @Override public void shutdown(ExecutorDriver driver) { } } 我们将在后面的部分中看到调度器和执行器的操作版本。 4. 资源管理 4.1 资源优惠 正如我们之前所讨论的，代理将其资源信息发布给主节点。反过来，主节点将这些资源提供给集群中运行的框架。此过程称为资源报价。 资源报价由两部分组成——资源和属性。 资源用于发布代理机器的内存、CPU、磁盘等硬件信息。 每个代理都有五种预定义资源：  中央处理器 显卡 内存 磁盘 港口  这些资源的值可以定义为以下三种类型之一：  标量- 用于使用浮点数表示数字信息以允许小数值，例如 1.5G 内存 范围——用于表示标量值的范围——例如，端口范围 Set – 用于表示多个文本值  默认情况下，Mesos 代理会尝试从机器上检测这些资源。 但是，在某些情况下，我们可以在代理上配置自定义资源。此类自定义资源的值应再次采用上述任何一种类型。 例如，我们可以使用以下资源启动我们的代理： --resources=\u0026#39;cpus:24;gpus:2;mem:24576;disk:409600;ports:[21000-24000,30000-34000];bugs(debug_role):{a,b,c}\u0026#39; 可以看出，我们已经为代理配置了一些预定义资源和一个名为bugs的自定义资源，它是 集合类型。 除了资源之外，代理还可以向主服务器发布键值属性。这些属性充当代理的附加元数据，并帮助框架进行调度决策。 一个有用的示例可以是将代理添加到不同的机架或区域，然后在同一机架或区域上安排各种任务以实现数据本地化： --attributes=\u0026#39;rack:abc;zone:west;os:centos5;level:10;keys:[1000-1500]\u0026#39; 与资源类似，属性值可以是标量、范围或文本类型。 4.2. 资源角色 许多现代操作系统支持多个用户。同样，Mesos 也支持同一个集群中的多个用户。这些用户称为角色。我们可以将每个角色视为集群中的资源消费者。 因此，Mesos 代理可以根据不同的分配策略对不同角色下的资源进行划分。此外，框架可以在集群中订阅这些角色，并对不同角色下的资源进行细粒度控制。 例如，考虑一个集群托管应用程序，这些应用程序为组织中的不同用户提供服务。因此，通过将资源划分为角色，每个应用程序都可以彼此隔离工作。 此外，框架可以使用这些角色来实现数据局部性。 例如，假设我们在集群中有两个应用程序，名为生产者和 消费者。在这里， 生产者将数据写入一个持久卷， 消费者随后可以读取该卷。我们可以 通过与生产者共享卷 来优化消费者 应用程序。 由于 Mesos 允许多个应用程序订阅同一个角色，我们可以将持久卷与资源角色相关联。此外，生产者和 消费者的框架都将订阅相同的资源角色。因此，消费者应用程序现在可以在与生产者应用程序相同的卷上启动数据读取任务。 4.3. 资源预留 现在可能会出现关于 Mesos 如何将集群资源分配给不同角色的问题。Mesos 通过预留分配资源。 有两种类型的预订：  静态预留 动态预订  静态预留类似于我们在前面部分讨论的代理启动时的资源分配： --resources=\u0026#34;cpus:4;mem:2048;cpus(Demo):8;mem(Demo):4096\u0026#34; 这里唯一的区别是，现在 Mesos 代理为名为Demo的角色保留了 8 个 CPU 和 4096m 内存。 与静态预留不同，动态预留允许我们重新调整角色内的资源。Mesos 允许框架和集群操作员通过框架消息作为对资源提供的响应或通过HTTP 端点动态更改资源分配。 Mesos 将所有没有任何角色的资源分配给一个名为 (*) 的默认角色。Master 向所有框架提供此类资源，无论它们是否订阅。 4.4. 资源权重和配额 通常，Mesos 主节点使用公平策略提供资源。它使用加权的优势资源公平 (wDRF) 来识别缺乏资源的角色。然后，master 向订阅了这些角色的框架提供更多资源。 尽管在应用程序之间公平共享资源是 Mesos 的一个重要特性，但它并不总是必要的。假设一个集群托管具有低资源占用的应用程序以及具有高资源需求的应用程序。在此类部署中，我们希望根据应用程序的性质分配资源。 Mesos 允许框架**通过订阅角色并为该角色添加更高的权重值来要求更多资源。**因此，如果有两个角色，一个是权重 1，另一个是权重 2，Mesos 会将两倍的公平资源分配给第二个角色。 与资源类似，我们可以通过HTTP 端点配置权重。 除了确保为具有权重的角色分配公平的资源外，Mesos 还确保为角色分配最少的资源。 Mesos 允许我们为资源角色添加配额。配额指定角色可以保证接收的最小资源量。 5. 实施框架 正如我们在前面部分中讨论的，Mesos 允许应用程序以他们选择的语言提供框架实现。在 Java 中，使用主类（作为框架进程的入口点）以及前面讨论的调度器和 执行器 的实现来实现框架。 5.1 框架主类 在我们实现调度器和执行器之前，我们将首先实现我们框架的入口点：  向主人注册自己 向代理提供执行程序运行时信息 启动调度程序  我们将首先为 Mesos添加一个Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.mesos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mesos\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.28.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，我们将为我们的框架实现 HelloWorldMain。我们要做的第一件事是在 Mesos 代理上启动执行器进程： public static void main(String[] args) { String path = System.getProperty(\u0026#34;user.dir\u0026#34;) + \u0026#34;/target/libraries2-1.0.0-SNAPSHOT.jar\u0026#34;; CommandInfo.URI uri = CommandInfo.URI.newBuilder().setValue(path).setExtract(false).build(); String helloWorldCommand = \u0026#34;java -cp libraries2-1.0.0-SNAPSHOT.jar com.codingman.mesos.executors.HelloWorldExecutor\u0026#34;; CommandInfo commandInfoHelloWorld = CommandInfo.newBuilder() .setValue(helloWorldCommand) .addUris(uri) .build(); ExecutorInfo executorHelloWorld = ExecutorInfo.newBuilder() .setExecutorId(Protos.ExecutorID.newBuilder() .setValue(\u0026#34;HelloWorldExecutor\u0026#34;)) .setCommand(commandInfoHelloWorld) .setName(\u0026#34;Hello World (Java)\u0026#34;) .setSource(\u0026#34;java\u0026#34;) .build(); } 在这里，我们首先配置了执行器二进制位置。Mesos 代理将在框架注册时下载此二进制文件。接下来，代理将运行给定的命令来启动执行程序进程。 接下来，我们将初始化我们的框架并启动调度程序： FrameworkInfo.Builder frameworkBuilder = FrameworkInfo.newBuilder() .setFailoverTimeout(120000) .setUser(\u0026#34;\u0026#34;) .setName(\u0026#34;Hello World Framework (Java)\u0026#34;); frameworkBuilder.setPrincipal(\u0026#34;test-framework-java\u0026#34;); MesosSchedulerDriver driver = new MesosSchedulerDriver(new HelloWorldScheduler(), frameworkBuilder.build(), args[0]); 最后，**我们将启动向 Master 注册自身的MesosSchedulerDriver。为了成功注册，我们必须将 Master 的 IP 作为程序参数 args[0]传递给这个主类： int status = driver.run() == Protos.Status.DRIVER_STOPPED ? 0 : 1; driver.stop(); System.exit(status); 在上面显示的类中， CommandInfo、ExecutorInfo 和FrameworkInfo都是master 和框架之间的protobuf 消息的 Java 表示。 5.2. 实现调度器 从 Mesos 1.0 开始，我们可以从任何 Java 应用程序调用HTTP 端点来向 Mesos 主机发送和接收消息。其中一些消息包括，例如，框架注册、资源报价和报价拒绝。 对于Mesos 0.28 或更早版本，我们需要实现Scheduler接口： 在大多数情况下，我们将只关注 调度程序的**resourceOffers方法 。让我们看看调度程序如何接收资源并根据它们初始化任务。 首先，我们将了解调度程序如何为任务分配资源： @Override public void resourceOffers(SchedulerDriver schedulerDriver, List\u0026lt;Offer\u0026gt; list) { for (Offer offer : list) { List\u0026lt;TaskInfo\u0026gt; tasks = new ArrayList\u0026lt;TaskInfo\u0026gt;(); Protos.TaskID taskId = Protos.TaskID.newBuilder() .setValue(Integer.toString(launchedTasks++)).build(); System.out.println(\u0026#34;Launching printHelloWorld \u0026#34; + taskId.getValue() + \u0026#34; Hello World Java\u0026#34;); Protos.Resource.Builder cpus = Protos.Resource.newBuilder() .setName(\u0026#34;cpus\u0026#34;) .setType(Protos.Value.Type.SCALAR) .setScalar(Protos.Value.Scalar.newBuilder() .setValue(1)); Protos.Resource.Builder mem = Protos.Resource.newBuilder() .setName(\u0026#34;mem\u0026#34;) .setType(Protos.Value.Type.SCALAR) .setScalar(Protos.Value.Scalar.newBuilder() .setValue(128)); 在这里，我们为我们的任务分配了 1 个 CPU 和 128M 内存。接下来，我们将使用SchedulerDriver在代理上启动任务： TaskInfo printHelloWorld = TaskInfo.newBuilder() .setName(\u0026#34;printHelloWorld \u0026#34; + taskId.getValue()) .setTaskId(taskId) .setSlaveId(offer.getSlaveId()) .addResources(cpus) .addResources(mem) .setExecutor(ExecutorInfo.newBuilder(helloWorldExecutor)) .build(); List\u0026lt;OfferID\u0026gt; offerIDS = new ArrayList\u0026lt;\u0026gt;(); offerIDS.add(offer.getId()); tasks.add(printHelloWorld); schedulerDriver.launchTasks(offerIDS, tasks); } } 或者， 调度程序经常发现需要拒绝资源提供。例如，如果 调度程序由于缺乏资源而无法在代理上启动任务，它必须立即拒绝该提议： schedulerDriver.declineOffer(offer.getId()); 5.3. 执行者 正如我们前面所讨论的，框架的执行器组件负责在 Mesos 代理上执行应用程序任务。 我们使用 HTTP 端点在 Mesos 1.0中实现*调度程序。*同样，我们可以将HTTP 端点用于执行程序。 在前面的部分中，我们讨论了框架如何配置代理以启动执行程序进程： java -cp libraries2-1.0.0-SNAPSHOT.jar com.codingman.mesos.executors.HelloWorldExecutor 值得注意的是，此命令将 HelloWorldExecutor视为主类。我们将实现这个main方法来初始化与 Mesos 代理连接的MesosExecutorDriver以接收任务并共享其他信息，例如任务状态： public class HelloWorldExecutor implements Executor { public static void main(String[] args) { MesosExecutorDriver driver = new MesosExecutorDriver(new HelloWorldExecutor()); System.exit(driver.run() == Protos.Status.DRIVER_STOPPED ? 0 : 1); } } 现在要做的最后一件事是接受来自框架的任务并在代理上启动它们。启动任何任务的信息都包含在HelloWorldExecutor 中： public void launchTask(ExecutorDriver driver, TaskInfo task) { Protos.TaskStatus status = Protos.TaskStatus.newBuilder() .setTaskId(task.getTaskId()) .setState(Protos.TaskState.TASK_RUNNING) .build(); driver.sendStatusUpdate(status); System.out.println(\u0026#34;Execute Task!!!\u0026#34;); status = Protos.TaskStatus.newBuilder() .setTaskId(task.getTaskId()) .setState(Protos.TaskState.TASK_FINISHED) .build(); driver.sendStatusUpdate(status); } 当然，这只是一个简单的实现，但它解释了 executor 如何在每个阶段与 master 共享任务状态，然后在发送完成状态之前执行任务。 在某些情况下，执行器还可以将数据发送回调度器： String myStatus = \u0026#34;Hello Framework\u0026#34;; driver.sendFrameworkMessage(myStatus.getBytes()); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_mesos/","tags":[],"title":"Apache Mesos 指南"},{"categories":["REST"],"contents":"1. 概述 在本教程中，我们将探索 Apache Meecrowave框架的基本功能。 Meecrowave 是来自 Apache 的轻量级微服务框架，它与 CDI、JAX-RS 和 JSON API 配合得非常好。设置和部署非常简单。它还消除了部署重型应用服务器（如 Tomcat、Glassfish、Wildfly 等）的麻烦。 2.Maven依赖 要使用 Meecrowave，让我们在 pom.xml 中定义依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.meecrowave\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;meecrowave-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在Maven Central上检查最新版本。 3. 启动一个简单的服务器 我要启动一个 Meecrowave 服务器，我们需要做的就是编写 main方法，**创建一个Meecrowave实例并调用 main bake()方法： public static void main(String[] args) { try (Meecrowave meecrowave = new Meecrowave()) { meecrowave.bake().await(); } } 如果我们把应用打包成分发包，就不需要这个main方法；我们将在后面的部分中对此进行研究。在从 IDE 测试应用程序时，主类很有用。 作为一个优势，在 IDE 中开发时，一旦我们使用主类运行应用程序，它会随着代码更改自动重新加载，从而省去了一次又一次地重新启动服务器以进行测试的麻烦。 请注意，如果我们使用的是 Java 9，请不要忘记将 javax .xml.bind模块添加到 VM： --add-module javax.xml.bind 以这种方式创建服务器将使用默认配置启动它。我们可以使用 Meecrowave.Builder类以编程方式更新默认配置*：* Meecrowave.Builder builder = new Meecrowave.Builder(); builder.setHttpPort(8080); builder.setScanningPackageIncludes(\u0026#34;com.codingman.meecrowave\u0026#34;); builder.setJaxrsMapping(\u0026#34;/api/*\u0026#34;); builder.setJsonpPrettify(true); 并在烘焙服务器时使用此 构建器实例： try (Meecrowave meecrowave = new Meecrowave(builder)) { meecrowave.bake().await(); } 这里有更多可配置的属性 。 4. REST 端点 现在，一旦服务器准备就绪，让我们创建一些 REST 端点： @RequestScoped @Path(\u0026#34;article\u0026#34;) public class ArticleEndpoints { @GET public Response getArticle() { return Response.ok().entity(new Article(\u0026#34;name\u0026#34;, \u0026#34;author\u0026#34;)).build(); } @POST public Response createArticle(Article article) { return Response.status(Status.CREATED).entity(article).build(); } } 请注意，我们主要使用 JAX-RS 注释来创建 REST 端点。在此处阅读有关 JAX-RS 的更多信息。 在下一节中，我们将看到如何测试这些端点。 5. 测试 使用 Meecrowave 编写的 REST API 编写单元测试用例就像编写带注释的 JUnit 测试用例一样简单。 让我们首先将测试依赖项添加到我们的 pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.meecrowave\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;meecrowave-junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 要查看最新版本，请查看Maven Central。 另外，让我们添加OkHttp作为我们测试的 HTTP 客户端： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.squareup.okhttp3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;okhttp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.10.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在这里查看最新版本。 现在有了依赖关系，让我们继续编写测试： @RunWith(MonoMeecrowave.Runner.class) public class ArticleEndpointsIntegrationTest { @ConfigurationInject private Meecrowave.Builder config; private static OkHttpClient client; @BeforeClass public static void setup() { client = new OkHttpClient(); } @Test public void whenRetunedArticle_thenCorrect() { String base = \u0026#34;http://localhost:\u0026#34; + config.getHttpPort(); Request request = new Request.Builder() .url(base + \u0026#34;/article\u0026#34;) .build(); Response response = client.newCall(request).execute(); assertEquals(200, response.code()); } } 在编写测试用例时，使用MonoMeecrowave.Runner类注释测试类 ，同时注入配置，以访问 Meecrowave 用于测试服务器的随机端口 6. 依赖注入 要将依赖项注入到类中，我们需要在特定范围内注释这些类。 让我们以ArticleService类为例 ： @ApplicationScoped public class ArticleService { public Article createArticle(Article article) { return article; } } 现在让我们使用javax.inject.Inject注释将其注入到我们的 ArticleEndpoints实例中 ： @Inject ArticleService articleService; 7. 打包应用程序 使用 Meecrowave Maven 插件创建分发包变得非常简单： \u0026lt;build\u0026gt; ... \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.meecrowave\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;meecrowave-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 一旦我们有了插件，让我们使用 Maven 目标 meecrowave:bundle来打包应用程序。 打包后，它将在目标目录中创建一个 zip： meecrowave-meecrowave-distribution.zip 此 zip 包含部署应用程序所需的工件： |____meecrowave-distribution | |____bin | | |____meecrowave.sh | |____logs | | |____you_can_safely_delete.txt | |____lib | |____conf | | |____log4j2.xml | | |____meecrowave.properties 让我们导航到 bin 目录并启动应用程序： ./meecrowave.sh start 要停止应用程序： ./meecrowave.sh stop \u0026quot; ","permalink":"http://itcodingman.github.io/apache_meecrowave/","tags":[],"title":"使用 Apache Meecrowave 构建微服务"},{"categories":["Algorithms","DevOps"],"contents":"1. 概述 在本教程中，我们将使用 Apache Kafka 进入事件驱动架构的数据建模领域。 2. 设置 Kafka 集群由多个注册到 Zookeeper 集群的 Kafka 代理组成。为了简单起见，我们将使用由 Confluent 发布的**现成 Docker 镜像和docker-compose**配置。 首先，让我们为 3 节点 Kafka 集群下载docker-compose.yml ： $ BASE_URL=\u0026#34;https://raw.githubusercontent.com/confluentinc/cp-docker-images/5.3.3-post/examples/kafka-cluster\u0026#34; $ curl -Os \u0026#34;$BASE_URL\u0026#34;/docker-compose.yml 接下来，让我们启动 Zookeeper 和 Kafka 代理节点： $ docker-compose up -d 最后，我们可以验证所有 Kafka 代理都已启动： $ docker-compose logs kafka-1 kafka-2 kafka-3 | grep started kafka-1_1 | [2020-12-27 10:15:03,783] INFO [KafkaServer id=1] started (kafka.server.KafkaServer) kafka-2_1 | [2020-12-27 10:15:04,134] INFO [KafkaServer id=2] started (kafka.server.KafkaServer) kafka-3_1 | [2020-12-27 10:15:03,853] INFO [KafkaServer id=3] started (kafka.server.KafkaServer) 3. 活动基础 在我们开始为事件驱动系统进行数据建模之前，我们需要了解一些概念，例如事件、事件流、生产者-消费者和主题。 3.1 事件 Kafka 世界中的事件是域世界中发生的事情的信息日志。它通过将信息记录为键值对消息以及一些其他属性（例如时间戳、元信息和标头）来实现这一点。 假设我们正在模拟一个国际象棋游戏；那么一个事件可能是一个动作： 我们可以注意到，事件保存了参与者、动作和发生时间的关键信息。在这种情况下，Player1是演员，动作是在12/2020/25 00:08:30将车从单元格**a1移动到a5。 3.2. 消息流 Apache Kafka 是一种流处理系统，可将事件捕获为消息流。在我们的国际象棋游戏中，我们可以将事件流视为玩家下棋的日志。 在每个事件发生时，板的快照将代表其状态。使用传统的表模式存储对象的最新静态状态通常很常见。 另一方面，事件流可以帮助我们以事件的形式捕捉两个连续状态之间的动态变化。如果我们播放一系列这些不可变的事件，我们可以从一种状态转换到另一种状态。这就是事件流和传统表之间的关系，通常称为流表对偶性。 让我们可视化棋盘上只有两个连续事件的事件流： 4. 话题 在本节中，我们将学习如何对通过 Apache Kafka 路由的消息进行分类。 4.1分类 在 Apache Kafka 这样的消息传递系统中，任何产生事件的东西通常都称为生产者。而阅读和消费这些消息的人称为消费者。 在现实世界的场景中，每个生产者都可以生成不同类型的事件，所以如果我们期望消费者过滤与他们相关的消息而忽略其余的消息，那将是浪费大量精力。 为了解决这个基本问题，Apache Kafka 使用的主题本质上是属于一起的消息组。因此，消费者在使用事件消息时可以更有效率。 在我们的棋盘示例中，可以使用一个主题将所有移动分组到chess-moves主题下： $ docker run \\  --net=host --rm confluentinc/cp-kafka:5.0.0 \\  kafka-topics --create --topic chess-moves \\  --if-not-exists \\  --partitions 1 --replication-factor 1 \\  --zookeeper localhost:32181 Created topic \u0026#34;chess-moves\u0026#34;. 4.2. 生产者-消费者 现在，让我们看看生产者和消费者如何使用 Kafka 的主题进行消息处理。我们将使用Kafka 发行版附带的kafka-console-producer和kafka-console-consumer实用程序来演示这一点。 让我们启动一个名为kafka-producer的容器，我们将在其中调用 producer 实用程序： $ docker run \\ --net=host \\ --name=kafka-producer \\ -it --rm \\ confluentinc/cp-kafka:5.0.0 /bin/bash # kafka-console-producer --broker-list localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves \\ --property parse.key=true --property key.separator=: 同时，我们可以启动一个名为kafka-consumer的容器，我们将在其中调用消费者实用程序： $ docker run \\ --net=host \\ --name=kafka-consumer \\ -it --rm \\ confluentinc/cp-kafka:5.0.0 /bin/bash # kafka-console-consumer --bootstrap-server localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves --from-beginning \\ --property print.key=true --property print.value=true --property key.separator=: 现在，让我们通过制作人记录一些游戏动作： \u0026gt;{Player1 : Rook, a1-\u0026gt;a5} 当消费者处于活动状态时，它将使用作为Player1的键接收此消息： {Player1 : Rook, a1-\u0026gt;a5} 5. 分区 接下来，让我们看看如何使用分区创建进一步的消息分类并提高整个系统的性能。 5.1 并发 我们可以将一个主题划分为多个分区，调用多个消费者来消费来自不同分区的消息。通过启用这种并发行为，可以提高系统的整体性能。 默认情况下，在创建主题期间支持–bootstrap-server选项的 Kafka 版本将创建主题的单个分区，**除非在创建主题时明确指定。但是，对于预先存在的主题，我们可以增加分区的数量。让我们将chess-moves主题的分区号设置为3 ： $ docker run \\ --net=host \\ --rm confluentinc/cp-kafka:5.0.0 \\ bash -c \u0026#34;kafka-topics --alter --zookeeper localhost:32181 --topic chess-moves --partitions 3\u0026#34; WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected Adding partitions succeeded! 5.2. 分区键 在一个主题中，Kafka 使用分区键跨多个分区处理消息。一方面，生产者隐式使用它来将消息路由到其中一个分区。另一方面，每个消费者都可以从特定分区读取消息。 默认情况下，生产者将生成键的哈希值，后跟带有分区数的模数。然后，它会将消息发送到计算出的标识符所标识的分区。 让我们使用kafka-console-producer实用程序创建新的事件消息，但这次我们将记录两个玩家的动作： # kafka-console-producer --broker-list localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves \\ --property parse.key=true --property key.separator=: \u0026gt;{Player1: Rook, a1 -\u0026gt; a5} \u0026gt;{Player2: Bishop, g3 -\u0026gt; h4} \u0026gt;{Player1: Rook, a5 -\u0026gt; e5} \u0026gt;{Player2: Bishop, h4 -\u0026gt; g3} 现在，我们可以有两个消费者，一个从分区 1 读取，另一个从分区 2 读取： # kafka-console-consumer --bootstrap-server localhost:19092,localhost:29092,localhost:39092 \\ --topic chess-moves --from-beginning \\ --property print.key=true --property print.value=true \\ --property key.separator=: \\ --partition 1 {Player2: Bishop, g3 -\u0026gt; h4} {Player2: Bishop, h4 -\u0026gt; g3} 我们可以看到 Player2 的所有移动都被记录到分区 1 中。以同样的方式，我们可以检查 Player1 的移动是否被记录到 partition-0 中。 6. 缩放 我们如何概念化主题和分区对于水平扩展至关重要。一方面，主题更像是数据的预定义分类。另一方面，分区是动态发生的数据的动态分类。 此外，我们可以在一个主题中配置多少个分区是有实际限制的。这是因为每个分区都映射到代理节点的文件系统中的一个目录。当我们增加分区数量时，我们也会增加操作系统上打开文件句柄的数量。 根据经验，Confluent 的专家建议将每个代理的分区数限制为100 x b x r，其中b是 Kafka 集群中代理的数量，r是复制因子。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_kafka_data_modeling/","tags":["Kafka"],"title":"使用 Apache Kafka 进行数据建模"},{"categories":["Spring Data","Spring Persistence"],"contents":"1. 概述 在本快速指南中，我们将重点介绍如何将 Spring Data API 与 Apache Ignite 平台集成。 要了解 Apache Ignite，请查看我们之前的指南。 2. Maven 设置 除了现有的依赖项，我们还必须启用 Spring Data 支持： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ignite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ignite-spring-data\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${ignite.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; ignite-spring-data工件可以从Maven Central下载。 3. 模型和存储库 为了演示集成，我们将构建一个应用程序，使用 Spring Data API将员工存储到 Ignite 的缓存中。 EmployeeDTO的 POJO将如下所示： public class EmployeeDTO implements Serializable { @QuerySqlField(index = true) private Integer id; @QuerySqlField(index = true) private String name; @QuerySqlField(index = true) private boolean isEmployed; // getters, setters } 在这里，@QuerySqlField注释允许使用 SQL 查询字段。 接下来，我们将创建存储库来持久化 Employee对象： @RepositoryConfig(cacheName = \u0026#34;demoCache\u0026#34;) public interface EmployeeRepository extends IgniteRepository\u0026lt;EmployeeDTO, Integer\u0026gt; { EmployeeDTO getEmployeeDTOById(Integer id); } **Apache Ignite 使用自己的IgniteRepository，它从 Spring Data 的CrudRepository扩展而来。**它还允许从 Spring Data 访问 SQL 网格。 这支持标准的 CRUD 方法，除了一些不需要 id 的方法。我们将在我们的测试部分更详细地了解原因。 ** @RepositoryConfig注释将EmployeeRepository映射到 Ignite 的demoCache。** 4. Spring配置 现在让我们创建我们的 Spring 配置类。 我们将使用 @EnableIgniteRepositories 注释来添加对 Ignite 存储库的支持： @Configuration @EnableIgniteRepositories public class SpringDataConfig { @Bean public Ignite igniteInstance() { IgniteConfiguration config = new IgniteConfiguration(); CacheConfiguration cache = new CacheConfiguration(\u0026#34;demoCache\u0026#34;); cache.setIndexedTypes(Integer.class, EmployeeDTO.class); config.setCacheConfiguration(cache); return Ignition.start(config); } } 在这里，igniteInstance() 方法创建Ignite实例并将其传递给IgniteRepositoryFactoryBean以便访问 Apache Ignite 集群。 我们还定义并设置了demoCache配置。*setIndexedTypes()*方法设置缓存的 SQL 模式。 5. 测试存储库 为了测试应用程序，让我们在应用程序上下文中注册SpringDataConfiguration并从中获取EmployeeRepository： AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.register(SpringDataConfig.class); context.refresh(); EmployeeRepository repository = context.getBean(EmployeeRepository.class); 然后，我们要创建EmployeeDTO实例并将其保存在缓存中： EmployeeDTO employeeDTO = new EmployeeDTO(); employeeDTO.setId(1); employeeDTO.setName(\u0026#34;John\u0026#34;); employeeDTO.setEmployed(true); repository.save(employeeDTO.getId(), employeeDTO); 这里我们使用了IgniteRepository的save (key, value)方法。原因是尚不支持**标准的CrudRepository save(entity)、save(entities)、delete(entity)操作。 *这背后的问题是CrudRepository.save()*方法生成的 ID 在集群中不是唯一的。 相反，我们必须使用 save *(key, value)、save(Map\u0026lt;ID, Entity\u0026gt; values)、deleteAll(Iterableids)*方法。 之后，我们可以使用 Spring Data 的*getEmployeeDTOById()*方法从缓存中获取员工对象： EmployeeDTO employee = repository.getEmployeeDTOById(employeeDTO.getId()); System.out.println(employee); 输出显示我们成功获取了初始对象： EmployeeDTO{id=1, name=\u0026#39;John\u0026#39;, isEmployed=true} 或者，我们可以使用IgniteCache API 检索相同的对象： IgniteCache\u0026lt;Integer, EmployeeDTO\u0026gt; cache = ignite.cache(\u0026#34;demoCache\u0026#34;); EmployeeDTO employeeDTO = cache.get(employeeId); 或者使用标准 SQL： SqlFieldsQuery sql = new SqlFieldsQuery( \u0026#34;select * from EmployeeDTO where isEmployed = \u0026#39;true\u0026#39;\u0026#34;); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_ignite_spring_data/","tags":[],"title":"Apache Ignite 与 Spring Data"},{"categories":["Persistence"],"contents":"1. 简介 Apache Ignite 是一个以内存为中心的开源分布式平台。我们可以将它用作数据库、缓存系统或用于内存数据处理。 该平台使用内存作为存储层，因此具有令人印象深刻的性能。简单地说，这是目前生产使用中最快的原子数据处理平台之一。 2. 安装和设置 首先，请查看 入门页面 以获取初始设置和安装说明。 我们将要构建的应用程序的 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ignite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ignite-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${ignite.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ignite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ignite-indexing\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${ignite.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; ignite-core是项目的唯一强制依赖。由于我们还想与 SQL 交互，所以这里也ignite-indexing${ignite.version}是 Apache Ignite 的最新版本。 作为最后一步，我们启动 Ignite 节点： Ignite node started OK (id=53c77dea) Topology snapshot [ver=1, servers=1, clients=0, CPUs=4, offheap=1.2GB, heap=1.0GB] Data Regions Configured: ^-- default [initSize=256.0 MiB, maxSize=1.2 GiB, persistenceEnabled=false] 上面的控制台输出表明我们准备好了。 3. 内存架构 该平台基于持久内存架构。这使得能够在磁盘和内存中存储和处理数据。它通过有效利用集群的 RAM 资源来提高性能。 内存和磁盘中的数据具有相同的二进制表示。这意味着在从一层移动到另一层时无需额外转换数据。 持久内存架构分为称为页面的固定大小的块。页面存储在 Java 堆之外并组织在 RAM 中。它有一个唯一标识符：FullPageId。 页面使用PageMemory抽象与内存交互 。 它有助于读取、写入页面，还有助于分配页面 id。在内存中，Ignite 将页面与Memory Buffers相关联。 4. 内存页 一个页面可以有以下状态：  Unloaded – 内存中没有加载页面缓冲区 清除——页面缓冲区被加载并与磁盘上的数据同步 Durty – 页缓冲区保存的数据与磁盘中的数据不同 检查点脏——在第一个修改保存到磁盘之前，还有另一个修改开始。这里开始一个检查点，PageMemory为每个 Page 保留两个内存缓冲区。  **持久内存在本地分配一个称为Data Region的内存段。**默认情况下，它的容量为集群内存的 20%。多区域配置允许将可用数据保存在内存中。 该区域的最大容量是一个内存段。它是物理内存或连续字节数组。 为了避免内存碎片，一个页面包含多个键值条目。每个新条目都将添加到最佳页面。如果键值对大小超过页面的最大容量，Ignite 会将数据存储在多个页面中。相同的逻辑适用于更新数据。 SQL 和缓存索引存储在称为 B+ 树的结构中。缓存键按其键值排序。 5. 生命周期 每个 Ignite 节点都在单个 JVM 实例上运行。但是，可以配置为在单个 JVM 进程中运行多个 Ignite 节点。 让我们来看看生命周期事件类型：  BEFORE_NODE_START – 在 Ignite 节点启动之前 AFTER_NODE_START – 在 Ignite 节点启动后触发 BEFORE_NODE_STOP – 在启动节点停止之前 AFTER_NODE_STOP – Ignite 节点停止后  要启动默认的 Ignite 节点： Ignite ignite = Ignition.start(); 或者从配置文件： Ignite ignite = Ignition.start(\u0026#34;config/example-cache.xml\u0026#34;); 如果我们需要对初始化过程进行更多控制，还有另一种借助LifecycleBean接口的方法： public class CustomLifecycleBean implements LifecycleBean { @Override public void onLifecycleEvent(LifecycleEventType lifecycleEventType) throws IgniteException { if(lifecycleEventType == LifecycleEventType.AFTER_NODE_START) { // ...  } } } 在这里，我们可以使用生命周期事件类型在节点启动/停止之前或之后执行操作。 为此，我们将带有CustomLifecycleBean的配置实例传递给 start 方法： IgniteConfiguration configuration = new IgniteConfiguration(); configuration.setLifecycleBeans(new CustomLifecycleBean()); Ignite ignite = Ignition.start(configuration); 6. 内存数据网格 Ignite 数据网格是一种分布式键值存储，对于分区 HashMap非常熟悉。它是水平缩放的。这意味着我们添加更多的集群节点，更多的数据被缓存或存储在内存中。 作为缓存的附加层，它可以为 NoSql、RDMS 数据库等 3rd 方软件提供显着的性能提升。 6.1 缓存支持 数据访问 API 基于 JCache JSR 107 规范。 例如，让我们使用模板配置创建缓存： IgniteCache\u0026lt;Employee, Integer\u0026gt; cache = ignite.getOrCreateCache( \u0026#34;baeldingCache\u0026#34;); 让我们看看这里发生了什么以了解更多详细信息。首先，Ignite 找到缓存存储的内存区域。 然后，B+树索引Page会根据key hash code来定位。如果索引存在，就会定位到对应key的数据Page。 当索引为 NULL 时，平台使用给定的键创建新的数据条目。 接下来，让我们添加一些Employee对象： cache.put(1, new Employee(1, \u0026#34;John\u0026#34;, true)); cache.put(2, new Employee(2, \u0026#34;Anna\u0026#34;, false)); cache.put(3, new Employee(3, \u0026#34;George\u0026#34;, true)); 同样，持久内存将寻找缓存所属的内存区域。根据缓存键，索引页将位于 B+ 树结构中。 当索引页面不存在时，会请求一个新页面并将其添加到树中。 接下来，将数据页分配给索引页。 要从缓存中读取员工，我们只需使用键值： Employee employee = cache.get(1); 6.2. 流媒体支持 内存数据流为基于磁盘和文件系统的数据处理应用程序提供了另一种方法。Streaming API 将高负载数据流拆分为多个阶段并路由它们进行处理。 我们可以修改我们的示例并从文件中流式传输数据。首先，我们定义一个数据流送器： IgniteDataStreamer\u0026lt;Integer, Employee\u0026gt; streamer = ignite .dataStreamer(cache.getName()); 接下来，我们可以注册一个流转换器来将接收到的员工标记为已雇用： streamer.receiver(StreamTransformer.from((e, arg) -\u0026gt; { Employee employee = e.getValue(); employee.setEmployed(true); e.setValue(employee); return employee; })); 作为最后一步，我们遍历employees.txt文件行并将它们转换为 Java 对象： Path path = Paths.get(IgniteStream.class.getResource(\u0026#34;employees.txt\u0026#34;) .toURI()); Gson gson = new Gson(); Files.lines(path) .forEach(l -\u0026gt; streamer.addData( employee.getId(), gson.fromJson(l, Employee.class))); *使用*streamer.addData()将员工对象放入流中。 7. SQL 支持 该平台提供以内存为中心、容错的 SQL 数据库。 我们可以使用纯 SQL API 或 JDBC 进行连接。这里的 SQL 语法是 ANSI-99，因此支持查询中的所有标准聚合函数，DML，DDL 语言操作。 7.1 JDBC 为了更实用，让我们创建一个员工表并向其中添加一些数据。 为此，我们注册一个 JDBC 驱动程序并打开一个连接作为下一步： Class.forName(\u0026#34;org.apache.ignite.IgniteJdbcThinDriver\u0026#34;); Connection conn = DriverManager.getConnection(\u0026#34;jdbc:ignite:thin://127.0.0.1/\u0026#34;); 在标准 DDL 命令的帮助下，我们填充Employee表： sql.executeUpdate(\u0026#34;CREATE TABLE Employee (\u0026#34; + \u0026#34; id LONG PRIMARY KEY, name VARCHAR, isEmployed tinyint(1)) \u0026#34; + \u0026#34; WITH \\\u0026#34;template=replicated\\\u0026#34;\u0026#34;); 在 WITH 关键字之后，我们可以设置缓存配置模板。这里我们使用REPLICATED。默认情况下，模板模式为PARTITIONED。要指定数据的副本数，我们也可以在此处指定BACKUPS参数，默认为 0。 然后，让我们使用 INSERT DML 语句添加一些数据： PreparedStatement sql = conn.prepareStatement( \u0026#34;INSERT INTO Employee (id, name, isEmployed) VALUES (?, ?, ?)\u0026#34;); sql.setLong(1, 1); sql.setString(2, \u0026#34;James\u0026#34;); sql.setBoolean(3, true); sql.executeUpdate(); // add the rest 之后，我们选择记录： ResultSet rs = sql.executeQuery(\u0026#34;SELECT e.name, e.isEmployed \u0026#34; + \u0026#34; FROM Employee e \u0026#34; + \u0026#34; WHERE e.isEmployed = TRUE \u0026#34;) 7.2. 查询对象 还可以对缓存中存储的 Java 对象执行查询。Ignite 将 Java 对象视为单独的 SQL 记录： IgniteCache\u0026lt;Integer, Employee\u0026gt; cache = ignite.cache(\u0026#34;demoCache\u0026#34;); SqlFieldsQuery sql = new SqlFieldsQuery( \u0026#34;select name from Employee where isEmployed = \u0026#39;true\u0026#39;\u0026#34;); QueryCursor\u0026lt;List\u0026lt;?\u0026gt;\u0026gt; cursor = cache.query(sql); for (List\u0026lt;?\u0026gt; row : cursor) { // do something with the row } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_ignite/","tags":[],"title":"Apache Ignite 指南"},{"categories":["HTTP Client-Side"],"contents":"1. 概述 Apache HttpClient是一个流行的 Java 库，它提供了高效且功能丰富的包，实现了最新 HTTP 标准的客户端。该库专为扩展而设计，同时为基本 HTTP 方法提供强大的支持。 在本教程中，我们将了解 Apache HttpClient API 设计。我们将解释HttpClient和CloseableHttpClient之间的区别。此外，我们将检查如何使用HttpClients或HttpClientBuilder创建**CloseableHttpClient实例。 最后，我们将推荐我们应该在自定义代码中使用哪些上述 API。此外，我们将查看哪些 API 类实现了Closeable接口，因此需要我们关闭它们的实例以释放资源。 2. API 设计 让我们先来看看 API 是如何设计的，重点是它的高级类和接口。在下面的类图中，我们将展示经典执行 HTTP 请求和处理 HTTP 响应所需的 API 的一部分： 此外，Apache HttpClient API 还支持异步HTTP 请求/响应交换，以及使用RxJava的反应式消息交换。 3. HttpClient与CloseableHttpClient HttpClient是一个高级接口，代表了 HTTP 请求执行的基本契约。它对请求执行过程没有任何限制。此外，它还保留了状态管理、身份验证和重定向到各个客户端实现等细节。 我们可以将任何客户端实现转换为HttpClient接口。因此，我们可以使用它通过默认的客户端实现来执行基本的 HTTP 请求： HttpClient httpClient = HttpClients.createDefault(); HttpGet httpGet = new HttpGet(serviceUrl); HttpResponse response = httpClient.execute(httpGet); assertThat(response.getCode()).isEqualTo(HttpStatus.SC_OK); 但是，上面的代码会导致SonarQube出现阻塞问题。原因是默认客户端实现返回一个Closeable HttpClient的实例，它需要关闭。 CloseableHttpClient是一个抽象类，表示HttpClient接口的****基本实现。但是，它也实现了Closeable接口。因此，我们应该在使用后关闭它的所有实例。我们可以使用try-with-resources或在finally子句中调用close方法来关闭它们： try (CloseableHttpClient httpClient = HttpClients.createDefault()) { HttpGet httpGet = new HttpGet(serviceUrl); HttpResponse response = httpClient.execute(httpGet); assertThat(response.getCode()).isEqualTo(HttpStatus.SC_OK); } 因此，在我们的自定义代码中，我们应该使用CloseableHttpClient类，而不是HttpClient接口。 4. HttpClients与HttpClientBuilder 在上面的示例中，我们使用HttpClients类中的静态方法来获取默认客户端实现。HttpClients是一个实用类，包含用于创建CloseableHttpClient实例的工厂方法： CloseableHttpClient httpClient = HttpClients.createDefault(); 我们可以使用HttpClientBuilder类实现相同的目的*。HttpClientBuilder是**用于创建CloseableHttpClient*实例的Builder 设计模式**的实现： CloseableHttpClient httpClient = HttpClientBuilder.create().build(); 在内部，HttpClients使用HttpClientBuilder创建客户端实现实例。因此，我们应该更喜欢在我们的自定义代码中使用*HttpClients 。*鉴于它是一个更高级别的类，它的内部结构可能会随着新版本的发布而改变。 5. 资源管理 我们需要在CloseableHttpClient实例超出范围后关闭它们的原因是关闭关联的连接管理器。此外，我们还应该使用CloseableHttpResponse以确保正确释放系统资源。 5.1 CloseableHttpResponse CloseableHttpResponse是一个实现ClassicHttpResponse接口的类。但是，ClassicHttpResponse还扩展了HttpResponse、HttpEntityContainer和Closeable接口。 底层HTTP 连接由响应对象持有，以允许直接从网络套接字流式传输响应内容。因此，我们应该在自定义代码中使用CloseableHttpResponse类而不是HttpResponse接口。我们还需要确保在使用响应后调用close方法： try (CloseableHttpClient httpClient = HttpClientBuilder.create().build()) { HttpGet httpGet = new HttpGet(serviceUrl); try (CloseableHttpResponse response = httpClient.execute(httpGet)) { HttpEntity entity = response.getEntity(); EntityUtils.consume(entity); } } 我们应该注意到，当响应内容没有被完全消耗时，底层连接不能被安全地重用。在这种情况下，连接将被连接管理器关闭并丢弃。 5.2. 重用客户端 关闭CloseableHttpClient实例并为每个请求创建一个新实例可能是一项昂贵的操作。相反，我们可以重用CloseableHttpClient的单个实例来发送多个请求： try (CloseableHttpClient httpClient = HttpClientBuilder.create().build()) { HttpGet httpGetOne = new HttpGet(serviceOneUrl); try (CloseableHttpResponse responseOne = httpClient.execute(httpGetOne)) { HttpEntity entityOne = responseOne.getEntity(); EntityUtils.consume(entityOne); assertThat(responseOne.getCode()).isEqualTo(HttpStatus.SC_OK); } HttpGet httpGetTwo = new HttpGet(serviceTwoUrl); try (CloseableHttpResponse responseTwo = httpClient.execute(httpGetTwo)) { HttpEntity entityTwo = responseTwo.getEntity(); EntityUtils.consume(entityTwo); assertThat(responseTwo.getCode()).isEqualTo(HttpStatus.SC_OK); } } 因此，我们避免关闭内部关联的连接管理器并创建一个新的。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_vs_closeablehttpclient/","tags":["Apache HttpClient"],"title":"Apache HttpClient 与 CloseableHttpClient"},{"categories":["HTTP Client-Side","Security"],"contents":"1. 简介 Apache HttpClient 是一个用于与 HTTP 服务器通信的低级、轻量级客户端 HTTP 库。在本教程中，我们将学习如何在使用HttpClient时配置支持的传输层安全 (TLS) 版本。我们将从概述客户端和服务器之间的 TLS 版本协商如何工作开始。之后，我们将了解在使用 HttpClient 时配置支持的 TLS 版本的三种不同方式。 2. TLS版本协商 TLS 是一种互联网协议，可在两方之间提供安全、可信的通信。它封装了 HTTP 等应用层协议。自 1999 年首次发布以来，TLS 协议已经进行了多次修订。**因此，客户端和服务器首先就建立新连接时将使用哪个版本的 TLS 达成一致非常重要。**客户端和服务器交换 hello 消息后就 TLS 版本达成一致：  客户端发送支持的 TLS 版本列表。 服务器选择一个并在响应中包含所选版本。 客户端和服务器使用所选版本继续连接设置。  由于存在降级攻击的风险，正确配置 Web 客户端支持的 TLS 版本非常重要。请注意，为了使用最新版本的 TLS (TLS 1.3)，我们必须使用 Java 11 或更高版本。 3. 静态设置 TLS 版本 3.1 SSLConnectionSocketFactory 让我们使用HttpClients #custom构建器方法公开的HttpClientBuilder 来自定义我们的HTTPClient配置。此构建器模式允许我们传入我们自己的SSLConnectionSocketFactory，它将使用所需的支持 TLS 版本集进行实例化： SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( SSLContexts.createDefault(), new String[] { \u0026#34;TLSv1.2\u0026#34;, \u0026#34;TLSv1.3\u0026#34; }, null, SSLConnectionSocketFactory.getDefaultHostnameVerifier()); CloseableHttpClient httpClient = HttpClients.custom().setSSLSocketFactory(sslsf).build(); 返回的Httpclient对象现在可以执行 HTTP 请求。通过在SSLConnectionSocketFactory构造函数中显式设置支持的协议，客户端将仅支持通过 TLS 1.2 或 TLS 1.3 进行通信。请注意，在 4.3 之前的 Apache HttpClient 版本中，该类称为SSLSocketFactory。 3.2. Java 运行时参数 或者，我们可以使用 Java 的https.protocols系统属性配置支持的 TLS 版本。这种方法可以避免将值硬编码到应用程序代码中。相反，我们将配置HttpClient以在设置连接时使用系统属性。HttpClient API 提供了两种方法来做到这一点。第一个是通过HttpClients#createSystem： CloseableHttpClient httpClient = HttpClients.createSystem(); 如果需要更多的客户端配置，我们可以使用 builder 方法来代替： CloseableHttpClient httpClient = HttpClients.custom().useSystemProperties().build(); 这两种方法都告诉HttpClient在连接配置期间使用系统属性。这允许我们在应用程序运行时使用命令行参数设置所需的 TLS 版本。例如： $ java -Dhttps.protocols=TLSv1.1,TLSv1.2,TLSv1.3 -jar webClient.jar 4. 动态设置TLS版本 还可以根据主机名和端口等连接详细信息设置 TLS 版本。我们将扩展SSLConnectionSocketFactory并覆盖prepareSocket方法。客户端在发起新连接之前调用*prepareSocket方法。***这将让我们决定在每个连接的基础上使用哪些 TLS 协议。**也可以启用对旧 TLS 版本的支持，但前提是远程主机具有特定的子域： SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(SSLContexts.createDefault()){ @Override protected void prepareSocket(SSLSocket socket) { String hostname = socket.getInetAddress().getHostName(); if (hostname.endsWith(\u0026#34;internal.system.com\u0026#34;)){ socket.setEnabledProtocols(new String[] { \u0026#34;TLSv1\u0026#34;, \u0026#34;TLSv1.1\u0026#34;, \u0026#34;TLSv1.2\u0026#34;, \u0026#34;TLSv1.3\u0026#34; }); } else { socket.setEnabledProtocols(new String[] {\u0026#34;TLSv1.3\u0026#34;}); } } };\u0026lt;br /\u0026gt; CloseableHttpClient httpClient = HttpClients.custom().setSSLSocketFactory(sslsf).build(); 在上面的示例中，prepareSocket方法首先获取SSLSocket将连接到的远程主机名。**然后使用主机名来确定要启用的 TLS 协议。**现在，我们的 HTTP 客户端将对每个请求强制执行 TLS 1.3，除非目标主机名的格式为 * .internal.example.com。通过在创建新SSLSocket之前插入自定义逻辑的能力，我们的应用程序现在可以自定义 TLS 通信细节。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_tls/","tags":[],"title":"如何在 Apache HttpClient 中设置 TLS 版本"},{"categories":["HTTP Client-Side"],"contents":"1. 简介 HttpClient是 Apache HttpComponents 项目的一部分，该项目提供了一个专注于 HTTP 和相关协议的低级 Java 组件工具集。HttpClient 最基本的功能是执行 HTTP 方法。 在这个简短的教程中，我们将讨论向HttpClient请求添加参数。我们将学习如何将UriBuilder与 String 名称-值对以及NameValuePair一起使用。同样，我们将看到如何使用UrlEncodedFormEntity传递参数。 2. 使用UriBuilder为HttpClient请求添加参数 UriBuilder帮助我们通过构建器模式轻松创建 URI 和添加参数。我们可以使用字符串名称-值对添加参数，或者为此目的使用NameValuePair的类。 在此示例中，最终到达 URL 应如下所示： https://example.com?param1=value1\u0026amp;param2=value2 让我们看看如何使用字符串名称-值对： public CloseableHttpResponse sendHttpRequest() { HttpGet httpGet = new HttpGet(\u0026#34;https://example.com\u0026#34;); URI uri = new URIBuilder(httpGet.getURI()) .addParameter(\u0026#34;param1\u0026#34;, \u0026#34;value1\u0026#34;) .addParameter(\u0026#34;param2\u0026#34;, \u0026#34;value2\u0026#34;) .build(); ((HttpRequestBase) httpGet).setURI(uri); CloseableHttpResponse response = client.execute(httpGet); client.close(); } 此外，我们可以使用HttpClient请求的NameValuePair列表： public CloseableHttpResponse sendHttpRequest() { List nameValuePairs = new ArrayList(); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param1\u0026#34;, \u0026#34;value1\u0026#34;)); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param2\u0026#34;, \u0026#34;value2\u0026#34;)); HttpGet httpGet = new HttpGet(\u0026#34;https://example.com\u0026#34;); URI uri = new URIBuilder(httpGet.getURI()) .addParameters(nameValuePairs) .build(); ((HttpRequestBase) httpGet).setURI(uri); CloseableHttpResponse response = client.execute(httpGet); client.close(); } 类似地，UriBuilder可用于向其他 HttpClient 请求方法添加参数。 3. 使用UrlEncodedFormEntity为HttpClient请求添加参数 另一种方法是利用UrlEncodedFormEntity： public CloseableHttpResponse sendHttpRequest() { List nameValuePairs = new ArrayList(); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param1\u0026#34;, \u0026#34;value1\u0026#34;)); nameValuePairs.add(new BasicNameValuePair(\u0026#34;param2\u0026#34;, \u0026#34;value2\u0026#34;)); HttpPost httpPost = new HttpPost(\u0026#34;https://example.com\u0026#34;); httpPost.setEntity(new UrlEncodedFormEntity(nameValuePairs, StandardCharsets.UTF_8)); CloseableHttpResponse response = client.execute(httpPost); client.close(); } 请注意，** UrlEncodedFormEntity不能用于 GET 请求**，因为 GET 请求没有可以包含实体的主体。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_parameters/","tags":["Apache HttpClient"],"title":"向 Apache HttpClient 请求添加参数"},{"categories":["HTTP Client-Side"],"contents":"1. 概述 在本文中，我们将展示如何使用HttpClient扩展 URL 。 一个简单的例子是原始 URL 被缩短了一次- 被诸如bit.ly之类的服务所缩短。 一个更复杂的例子是，当URL 被不同的此类服务多次缩短时，需要多次传递才能到达原始的完整 URL。 如果您想更深入地挖掘并学习可以使用 HttpClient 做的其他很酷的事情 - 前往**主要的 HttpClient 教程 \u0026ldquo;你可以用 HttpClient 4 做一些很酷的基本和更高级的事情\u0026rdquo;**。 2. 展开 URL 让我们从简单的开始，扩展一个仅通过一次缩短 URL 服务的 URL。 我们首先需要的是一个不会自动跟随重定向的 HTTP 客户端： CloseableHttpClient client = HttpClientBuilder.create().disableRedirectHandling().build(); 这是必要的，因为我们需要手动拦截重定向响应并从中提取信息。 我们首先向缩短的 URL 发送请求——我们得到的响应将是301 Moved Permanently。 然后，我们需要提取指向下一个的Location标头，在本例中是最终 URL： public String expandSingleLevel(String url) throws IOException { HttpHead request = null; try { request = new HttpHead(url); HttpResponse httpResponse = client.execute(request); int statusCode = httpResponse.getStatusLine().getStatusCode(); if (statusCode != 301 \u0026amp;\u0026amp; statusCode != 302) { return url; } Header[] headers = httpResponse.getHeaders(HttpHeaders.LOCATION); Preconditions.checkState(headers.length == 1); String newUrl = headers[0].getValue(); return newUrl; } catch (IllegalArgumentException uriEx) { return url; } finally { if (request != null) { request.releaseConnection(); } } } 最后，使用“未缩短”的 URL 进行简单的实时测试： @Test public final void givenShortenedOnce_whenUrlIsExpanded_thenCorrectResult() throws IOException { final String expectedResult = \u0026#34;https://www.codingman.com/rest-versioning\u0026#34;; final String actualResult = expandSingleLevel(\u0026#34;http://bit.ly/3LScTri\u0026#34;); assertThat(actualResult, equalTo(expectedResult)); } 3. 处理多个 URL 短 URL 的问题在于，它们可能会被完全不同的服务**多次缩短。**扩展这样的 URL 需要多次传递才能到达原始 URL。 我们将应用之前定义的expandSingleLevel原始操作来简单地遍历所有中间 URL 并到达最终目标： public String expand(String urlArg) throws IOException { String originalUrl = urlArg; String newUrl = expandSingleLevel(originalUrl); while (!originalUrl.equals(newUrl)) { originalUrl = newUrl; newUrl = expandSingleLevel(originalUrl); } return newUrl; } 现在，通过扩展多级 URL 的新机制，让我们定义一个测试并使其工作： @Test public final void givenShortenedMultiple_whenUrlIsExpanded_thenCorrectResult() throws IOException { final String expectedResult = \u0026#34;https://www.codingman.com/rest-versioning\u0026#34;; final String actualResult = expand(\u0026#34;http://t.co/e4rDDbnzmk\u0026#34;); assertThat(actualResult, equalTo(expectedResult)); } 这一次，短 URL—— http://t.co/e4rDDbnzmk——实际上被缩短了两次——一次通过bit.ly，第二次通过t.co服务——被正确地扩展为原始 URL。 4. 检测重定向循环 最后，某些 URL 无法扩展，因为它们形成了重定向循环。这种类型的问题会被HttpClient检测到，但是由于我们关闭了重定向的自动跟踪，它不再这样做了。 URL 扩展机制的最后一步是检测重定向循环，并在发生此类循环时快速失败。 为了使其生效，我们需要从之前定义的expandSingleLevel方法中获取一些附加信息——主要是，我们还需要返回响应的状态码以及 URL。 由于 java 不支持多个返回值，我们将把信息包装在org.apache.commons.lang3.tuple.Pair对象中——该方法的新签名现在将是： public Pair\u0026lt;Integer, String\u0026gt; expandSingleLevelSafe(String url) throws IOException { 最后，让我们在主扩展机制中包含重定向循环检测： public String expandSafe(String urlArg) throws IOException { String originalUrl = urlArg; String newUrl = expandSingleLevelSafe(originalUrl).getRight(); List\u0026lt;String\u0026gt; alreadyVisited = Lists.newArrayList(originalUrl, newUrl); while (!originalUrl.equals(newUrl)) { originalUrl = newUrl; Pair\u0026lt;Integer, String\u0026gt; statusAndUrl = expandSingleLevelSafe(originalUrl); newUrl = statusAndUrl.getRight(); boolean isRedirect = statusAndUrl.getLeft() == 301 || statusAndUrl.getLeft() == 302; if (isRedirect \u0026amp;\u0026amp; alreadyVisited.contains(newUrl)) { throw new IllegalStateException(\u0026#34;Likely a redirect loop\u0026#34;); } alreadyVisited.add(newUrl); } return newUrl; } 就是这样*——expandSafe*机制能够通过任意数量的 URL 缩短服务扩展 URL，同时在重定向循环中快速正确地失败。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_expand_url/","tags":["Apache HttpClient"],"title":"使用 Apache HttpClient 展开缩短的 URL"},{"categories":["HTTP Client-Side"],"contents":"1. 概述 在本教程中，我们将展示如何在**Apache 的 HttpClient**中启用日志记录。此外，我们将解释如何在库中实现日志记录。之后，我们将展示如何启用不同级别的日志记录。 2. 日志实现 HttpClient 库提供了高效、最新且功能丰富的 HTTP 协议实现客户端站点。 事实上，作为一个库，HttpClient 并不强制实现日志记录。为此，4.5 版提供了带有Commons Logging的日志。同样，最新版本 5.1 使用SLF4J提供的日志外观。两个版本都使用层次结构模式来匹配记录器及其配置。 因此，可以为单个类或与相同功能相关的所有类设置记录器。 3. 日志类型 让我们看一下库定义的日志级别。我们可以区分 3 种类型的日志：  上下文日志——记录有关 HttpClient 的所有内部操作的信息。它还包含电线和标题日志。 线路日志记录——仅记录传输到服务器和从服务器传输的数据 标头日志记录——仅记录 HTTP 标头  在 4.5 版本中，对应的包是org.apache.http.impl.client和org.apache.http.wire、org.apache.http.headers。 因此，在 5.1 版中，有包org.apache.hc.client5.http、org.apache.hc.client5.http.wire和 org.apache.hc.client5.http.headers。 4. Log4j 配置 让我们看看如何启用两个版本的登录。我们的目标是在两个版本中实现相同的灵活性。在 4.1 版中，我们会将日志重定向到 SLF4j。因此，可以使用不同的日志记录框架。 4.1 4.5版配置 让我们添加httpclient依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.8\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;commons-logging\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;commons-logging\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 我们将使用jul-to-slf4j将日志重定向到 SLF4J。因此我们排除了 commons-logging。然后让我们在 JUL 和 SLF4J 之间的桥上添加一个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jul-to-slf4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.26\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 因为 SLF4J 只是一个门面，我们需要一个绑定。在我们的示例中，我们将使用logback： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在让我们创建ApacheHttpClientUnitTest类： public class ApacheHttpClientUnitTest { private final Logger logger = LoggerFactory.getLogger(this.getClass()); public static final String DUMMY_URL = \u0026#34;https://postman-echo.com/get\u0026#34;; @Test public void whenUseApacheHttpClient_thenCorrect() throws IOException { HttpGet request = new HttpGet(DUMMY_URL); try (CloseableHttpClient client = HttpClients.createDefault(); CloseableHttpResponse response = client.execute(request)) { HttpEntity entity = response.getEntity(); logger.debug(\u0026#34;Response -\u0026gt; {}\u0026#34;, EntityUtils.toString(entity)); } } } 测试获取一个虚拟网页并将内容打印到日志中。 现在让我们用我们的logback.xml文件定义一个记录器配置： \u0026lt;configuration debug=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender name=\u0026#34;stdout\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%date [%level] %logger - %msg %n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;com.codingman.httpclient.readresponsebodystring\u0026#34; level=\u0026#34;debug\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.apache.http\u0026#34; level=\u0026#34;debug\u0026#34;/\u0026gt; \u0026lt;root level=\u0026#34;WARN\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;stdout\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 运行我们的测试后，可以在控制台中找到所有 HttpClient 的日志： ... 2021-06-19 22:24:45,378 [DEBUG] org.apache.http.impl.execchain.MainClientExec - Executing request GET /get HTTP/1.1 2021-06-19 22:24:45,378 [DEBUG] org.apache.http.impl.execchain.MainClientExec - Target auth state: UNCHALLENGED 2021-06-19 22:24:45,379 [DEBUG] org.apache.http.impl.execchain.MainClientExec - Proxy auth state: UNCHALLENGED 2021-06-19 22:24:45,382 [DEBUG] org.apache.http.headers - http-outgoing-0 \u0026gt;\u0026gt; GET /get HTTP/1.1 ... 4.2. 5.1版本配置 现在让我们看看更高版本。**它包含重新设计的日志记录。因此，它使用 SLF4J 而不是 Commons Logging。**因此，记录器外观的绑定是唯一的附加依赖项。因此，我们将像第一个示例一样使用logback-classic 。 让我们添加httpclient5依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents.client5\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 让我们添加一个与上一个示例类似的测试： public class ApacheHttpClient5UnitTest { private final Logger logger = LoggerFactory.getLogger(this.getClass()); public static final String DUMMY_URL = \u0026#34;https://postman-echo.com/get\u0026#34;; @Test public void whenUseApacheHttpClient_thenCorrect() throws IOException, ParseException { HttpGet request = new HttpGet(DUMMY_URL); try (CloseableHttpClient client = HttpClients.createDefault(); CloseableHttpResponse response = client.execute(request)) { HttpEntity entity = response.getEntity(); logger.debug(\u0026#34;Response -\u0026gt; {}\u0026#34;, EntityUtils.toString(entity)); } } } 接下来，我们需要在logback.xml文件中添加一个记录器： \u0026lt;configuration debug=\u0026#34;false\u0026#34;\u0026gt; ... \u0026lt;logger name=\u0026#34;org.apache.hc.client5.http\u0026#34; level=\u0026#34;debug\u0026#34;/\u0026gt; ... \u0026lt;/configuration\u0026gt; 让我们运行测试类ApacheHttpClient5UnitTest并检查输出。它类似于旧版本： ... 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.classic.InternalHttpClient - ep-0000000000 endpoint connected 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.classic.MainClientExec - ex-0000000001 executing GET /get HTTP/1.1 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.classic.InternalHttpClient - ep-0000000000 start execution ex-0000000001 2021-06-19 22:27:16,944 [DEBUG] org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager - ep-0000000000 executing exchange ex-0000000001 over http-outgoing-0 2021-06-19 22:27:16,960 [DEBUG] org.apache.hc.client5.http.headers - http-outgoing-0 \u0026gt;\u0026gt; GET /get HTTP/1.1 ... \u0026quot; ","permalink":"http://itcodingman.github.io/apache_httpclient_enable_logging/","tags":["Apache HttpClient"],"title":"为 Apache HttpClient 启用日志记录"},{"categories":["Persistence"],"contents":"1. 概述 Apache Geode是一个分布式内存数据网格，支持缓存和数据计算。 在本教程中，我们将介绍 Geode 的关键概念并使用其 Java 客户端运行一些代码示例。 2. 设置 首先，我们需要下载并安装 Apache Geode 并设置gfsh环境。为此，我们可以按照Geode 官方指南中的说明进行操作。 其次，本教程将创建一些文件系统工件。因此，我们可以通过创建一个临时目录并从那里启动东西来隔离它们。 2.1 安装和配置 从我们的临时目录中，我们需要启动一个Locator实例： gfsh\u0026gt; start locator --name=locator --bind-address=localhost **定位器 负责 Geode Cluster的不同成员之间的协调，**我们可以通过 JMX 进一步管理它。 接下来，让我们启动一个Server实例来托管一个或多个数据Region： gfsh\u0026gt; start server --name=server1 --server-port=0 我们将*\u0026ndash;server-port选项设置为 0，以便 Geode 选择任何可用端口。虽然如果我们忽略它，服务器将使用默认端口 40404。**服务器是集群的可配置成员，作为长期进程运行并负责管理数据区域***。 最后，我们需要一个 Region： gfsh\u0026gt; create region --name=demo --type=REPLICATE 该区域最终是我们存储数据的地方。 2.2. 确认 在我们继续之前，让我们确保一切正常。 首先，让我们检查一下我们是否有我们的 Server和我们的 Locator： gfsh\u0026gt; list members Name | Id ------- | ---------------------------------------------------------- server1 | 192.168.0.105(server1:6119)\u0026lt;v1\u0026gt;:1024 locator | 127.0.0.1(locator:5996:locator)\u0026lt;ec\u0026gt;\u0026lt;v0\u0026gt;:1024 [Coordinator] 接下来，我们有我们的 Region： gfsh\u0026gt; describe region --name=demo .......................................................... Name : demo Data Policy : replicate Hosting Members : server1 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ----------- | --------------- Region | data-policy | REPLICATE | size | 0 | scope | distributed-ack 此外，我们的临时目录下的文件系统上应该有一些目录，称为“locator”和“server1”。 有了这个输出，我们知道我们已经准备好继续前进了。 3. Maven依赖 现在我们有了一个正在运行的 Geode，让我们开始查看客户端代码。 要在我们的 Java 代码中使用 Geode，我们需要将 Apache Geode Java 客户端库添加到我们的 pom中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.geode\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;geode-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 让我们从在几个区域中简单地存储和检索一些数据开始。 4. 简单的存储和检索 让我们演示如何存储单个值、批量值以及自定义对象。 要开始在我们的“demo”区域中存储数据，让我们使用定位器连接到它： @Before public void connect() { this.cache = new ClientCacheFactory() .addPoolLocator(\u0026#34;localhost\u0026#34;, 10334) .create(); this.region = cache.\u0026lt;String, String\u0026gt; createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY) .create(\u0026#34;demo\u0026#34;); } 4.1 保存单个值 现在，我们可以简单地在我们的区域中存储和检索数据： @Test public void whenSendMessageToRegion_thenMessageSavedSuccessfully() { this.region.put(\u0026#34;A\u0026#34;, \u0026#34;Hello\u0026#34;); this.region.put(\u0026#34;B\u0026#34;, \u0026#34;demo\u0026#34;); assertEquals(\u0026#34;Hello\u0026#34;, region.get(\u0026#34;A\u0026#34;)); assertEquals(\u0026#34;demo\u0026#34;, region.get(\u0026#34;B\u0026#34;)); } 4.2. 一次保存多个值 我们还可以一次保存多个值，例如在尝试减少网络延迟时： @Test public void whenPutMultipleValuesAtOnce_thenValuesSavedSuccessfully() { Supplier\u0026lt;Stream\u0026lt;String\u0026gt;\u0026gt; keys = () -\u0026gt; Stream.of(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;); Map\u0026lt;String, String\u0026gt; values = keys.get() .collect(Collectors.toMap(Function.identity(), String::toLowerCase)); this.region.putAll(values); keys.get() .forEach(k -\u0026gt; assertEquals(k.toLowerCase(), this.region.get(k))); } 4.3. 保存自定义对象 字符串很有用，但我们迟早需要存储自定义对象。 假设我们有一个要使用以下键类型存储的客户记录： public class CustomerKey implements Serializable { private long id; private String country; // getters and setters  // equals and hashcode } 以及以下值类型： public class Customer implements Serializable { private CustomerKey key; private String firstName; private String lastName; private Integer age; // getters and setters } 有几个额外的步骤可以存储这些： 首先，**他们应该实现 Serializable。**虽然这不是一个严格的要求，但通过使它们可序列化，Geode 可以更健壮地存储它们。 其次，它们需要位于我们应用程序的类路径以及 Geode Server的类路径中。 为了让它们进入服务器的类路径，让我们将它们打包，比如使用 mvn clean package。 然后我们可以在新的启动服务器命令中引用生成的 jar ： gfsh\u0026gt; stop server --name=server1 gfsh\u0026gt; start server --name=server1 --classpath=../lib/apache-geode-1.0-SNAPSHOT.jar --server-port=0 同样，我们必须从临时目录运行这些命令。 最后，让我们使用与创建“demo”区域相同的命令在服务器上创建一个名为“demo-customers”的新区域： gfsh\u0026gt; create region --name=demo-customers --type=REPLICATE 在代码中，我们将像以前一样访问定位器，指定自定义类型： @Before public void connect() { // ... connect through the locator  this.customerRegion = this.cache.\u0026lt;CustomerKey, Customer\u0026gt; createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY) .create(\u0026#34;demo-customers\u0026#34;); } 然后，我们可以像以前一样存储我们的客户： @Test public void whenPutCustomKey_thenValuesSavedSuccessfully() { CustomerKey key = new CustomerKey(123); Customer customer = new Customer(key, \u0026#34;William\u0026#34;, \u0026#34;Russell\u0026#34;, 35); this.customerRegion.put(key, customer); Customer storedCustomer = this.customerRegion.get(key); assertEquals(\u0026#34;William\u0026#34;, storedCustomer.getFirstName()); assertEquals(\u0026#34;Russell\u0026#34;, storedCustomer.getLastName()); } 5. 区域类型 对于大多数环境，我们将拥有多个副本或多个分区，具体取决于我们的读写吞吐量要求。 到目前为止，我们已经使用了内存中的复制区域。让我们仔细看看。 5.1 复制区域 顾名思义，**复制区域在多个服务器上维护其数据的副本。**让我们测试一下。 从工作目录中的gfsh控制台，让我们再向集群添加一个名为server2的**服务器： gfsh\u0026gt; start server --name=server2 --classpath=../lib/apache-geode-1.0-SNAPSHOT.jar --server-port=0 请记住，当我们制作“demo”时，我们使用了*–type=REPLICATE*。因此，Geode 会自动将我们的数据复制到新服务器。 让我们通过停止server1 来验证这一点： gfsh\u0026gt; stop server --name=server1 然后，让我们对“demo”区域执行快速查询。 如果数据复制成功，我们将返回结果： gfsh\u0026gt; query --query=\u0026#39;select e.key from /demo.entries e\u0026#39; Result : true Limit : 100 Rows : 5 Result ------ C B A E D 所以，看起来复制成功了！ 向我们的区域添加副本可提高数据可用性。而且，因为不止一台服务器可以响应查询，我们也将获得更高的读取吞吐量。 但是，*如果他们俩都崩溃了怎么办？由于这些是内存区域，因此数据将丢失。***为此，我们可以改为使用 –type=REPLICATE_PERSISTENT，它还在复制时将数据存储在磁盘上。 5.2. 分区区域 对于更大的数据集，我们可以通过配置 Geode 将一个区域拆分为单独的分区或存储桶来更好地扩展系统。 让我们创建一个名为“demo-partitioned”的分区区域： gfsh\u0026gt; create region --name=demo-partitioned --type=PARTITION 添加一些数据： gfsh\u0026gt; put --region=demo-partitioned --key=\u0026#34;1\u0026#34; --value=\u0026#34;one\u0026#34; gfsh\u0026gt; put --region=demo-partitioned --key=\u0026#34;2\u0026#34; --value=\u0026#34;two\u0026#34; gfsh\u0026gt; put --region=demo-partitioned --key=\u0026#34;3\u0026#34; --value=\u0026#34;three\u0026#34; 并快速验证： gfsh\u0026gt; query --query=\u0026#39;select e.key, e.value from /demo-partitioned.entries e\u0026#39; Result : true Limit : 100 Rows : 3 key | value --- | ----- 2 | two 1 | one 3 | three 然后，为了验证数据是否已分区，让我们再次停止server1并重新查询： gfsh\u0026gt; stop server --name=server1 gfsh\u0026gt; query --query=\u0026#39;select e.key, e.value from /demo-partitioned.entries e\u0026#39; Result : true Limit : 100 Rows : 1 key | value --- | ----- 2 | two 这次我们只取回了一些数据条目，因为那台服务器只有一个数据分区，所以当 server1掉线时，它的数据也丢失了。 **但是如果我们需要分区和冗余呢？**Geode 还支持许多其他类型。以下三个很方便：  PARTITION_REDUNDANT在集群的不同成员之间分区 和复制我们的数据 PARTITION_PERSISTENT像**PARTITION 一样对数据进行分区，但是到磁盘，并且 PARTITION_REDUNDANT_PERSISTENT为我们提供了所有三种行为。  6.对象查询语言 Geode 还支持对象查询语言或 OQL，它比简单的键查找功能更强大。这有点像 SQL。 对于这个例子，让我们使用我们之前构建的“demo-customer”区域。 如果我们再添加几个客户： Map\u0026lt;CustomerKey, Customer\u0026gt; data = new HashMap\u0026lt;\u0026gt;(); data.put(new CustomerKey(1), new Customer(\u0026#34;Gheorge\u0026#34;, \u0026#34;Manuc\u0026#34;, 36)); data.put(new CustomerKey(2), new Customer(\u0026#34;Allan\u0026#34;, \u0026#34;McDowell\u0026#34;, 43)); this.customerRegion.putAll(data); 然后我们可以使用 QueryService查找名字为“Allan”的客户： QueryService queryService = this.cache.getQueryService(); String query = \u0026#34;select * from /demo-customers c where c.firstName = \u0026#39;Allan\u0026#39;\u0026#34;; SelectResults\u0026lt;Customer\u0026gt; results = (SelectResults\u0026lt;Customer\u0026gt;) queryService.newQuery(query).execute(); assertEquals(1, results.size()); 7. 功能 内存数据网格更强大的概念之一是“将计算应用于数据”的想法。 简而言之，由于 Geode 是纯 Java，我们不仅可以轻松发送数据，还可以轻松地对这些数据执行逻辑。 这可能会让我们想起 PL-SQL 或 Transact-SQL 等 SQL 扩展的想法。 7.1 定义函数 为了给 Geode 定义一个工作单元，我们实现了 Geode 的 Function接口。 例如，假设我们需要将所有客户的姓名都更改为大写。 我们可以只实现Function，而不是查询数据并让我们的应用程序完成工作： public class UpperCaseNames implements Function\u0026lt;Boolean\u0026gt; { @Override public void execute(FunctionContext\u0026lt;Boolean\u0026gt; context) { RegionFunctionContext regionContext = (RegionFunctionContext) context; Region\u0026lt;CustomerKey, Customer\u0026gt; region = regionContext.getDataSet(); for ( Map.Entry\u0026lt;CustomerKey, Customer\u0026gt; entry : region.entrySet() ) { Customer customer = entry.getValue(); customer.setFirstName(customer.getFirstName().toUpperCase()); } context.getResultSender().lastResult(true); } @Override public String getId() { return getClass().getName(); } } 请注意， getId必须返回一个唯一值，因此类名通常是一个不错的选择。 FunctionContext包含我们所有的区域数据，因此我们可以对其进行更复杂的查询，或者像我们在这里所做的那样，对其进行变异。 而且Function比这更强大，所以请查看官方手册，尤其是getResultSender方法。 7.2. 部署功能 我们需要让 Geode 知道我们的函数才能运行它。就像我们对自定义数据类型所做的那样，我们将打包 jar。 但这一次，我们可以只使用 deploy命令： gfsh\u0026gt; deploy --jar=./lib/apache-geode-1.0-SNAPSHOT.jar 7.3. 执行功能 现在，我们可以使用FunctionService 从应用程序中执行Function： @Test public void whenExecuteUppercaseNames_thenCustomerNamesAreUppercased() { Execution execution = FunctionService.onRegion(this.customerRegion); execution.execute(UpperCaseNames.class.getName()); Customer customer = this.customerRegion.get(new CustomerKey(1)); assertEquals(\u0026#34;GHEORGE\u0026#34;, customer.getFirstName()); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_geode/","tags":[],"title":"Apache Geode 快速指南"},{"categories":["Data"],"contents":"1. 概述 Apache Flink 是一个大数据处理框架，它允许程序员以非常高效和可扩展的方式处理大量数据。 在本文中，我们将介绍***Apache Flink*** Java API****中可用的一些核心 API 概念和标准数据转换。这个 API 的流畅风格使得使用 Flink 的中心结构——分布式集合变得容易。 首先，我们将看一下 Flink 的DataSet API 转换，并使用它们来实现一个字数统计程序。然后我们将简要介绍 Flink 的DataStream API，它允许您以实时方式处理事件流。 2. Maven依赖 首先，我们需要将 Maven 依赖项添加到flink-java和flink-test-utils库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-test-utils_2.10\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;scope\u0026gt; \u0026lt;/dependency\u0026gt; 3. 核心 API 概念 在使用 Flink 时，我们需要了解与它的 API 相关的几件事：  **每个 Flink 程序都会对分布式数据集合进行转换。**提供了用于转换数据的各种功能，包括过滤、映射、连接、分组和聚合 Flink 中的sink操作触发流的执行以产生程序所需的结果，例如将结果保存到文件系统或打印到标准输出 Flink 转换是惰性的，这意味着它们在调用sink操作之前不会执行 **Apache Flink API 支持两种操作模式——批处理和实时。**如果您正在处理可以在批处理模式下处理的有限数据源，您将使用DataSet API。如果您想实时处理无限的数据流，则需要使用DataStream API  4. 数据集 API 转换 Flink 程序的入口点是ExecutionEnvironment类的实例——它定义了程序执行的上下文。 让我们创建一个ExecutionEnvironment来开始我们的处理： ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); **请注意，当您在本地机器上启动应用程序时，它将在本地 JVM 上执行处理。**如果您想在机器集群上开始处理，则需要在这些机器上安装Apache Flink并相应地配置ExecutionEnvironment。 4.1 创建数据集 要开始执行数据转换，我们需要为我们的程序提供数据。 让我们使用ExecutionEnvironement创建**DataSet类的实例： DataSet\u0026lt;Integer\u0026gt; amounts = env.fromElements(1, 29, 40, 50); 您可以从多个源创建数据集，例如 Apache Kafka、CSV、文件或几乎任何其他数据源。 4.2. 过滤和减少 创建DataSet类的实例后，您可以对其应用转换。 假设您要过滤高于某个阈值的数字，然后将它们全部相加*。您可以使用filter()和reduce()*转换来实现这一点： int threshold = 30; List\u0026lt;Integer\u0026gt; collect = amounts .filter(a -\u0026gt; a \u0026gt; threshold) .reduce((integer, t1) -\u0026gt; integer + t1) .collect(); assertThat(collect.get(0)).isEqualTo(90); 请注意，collect()方法是触发实际数据转换的接收器操作。 4.3. 地图 假设您有一个Person对象的DataSet ： private static class Person { private int age; private String name; // standard constructors/getters/setters } 接下来，让我们创建这些对象的DataSet： DataSet\u0026lt;Person\u0026gt; personDataSource = env.fromCollection( Arrays.asList( new Person(23, \u0026#34;Tom\u0026#34;), new Person(75, \u0026#34;Michael\u0026#34;))); 假设您只想从集合的每个对象中提取年龄字段。您可以使用map()转换仅获取**Person类的特定字段： List\u0026lt;Integer\u0026gt; ages = personDataSource .map(p -\u0026gt; p.age) .collect(); assertThat(ages).hasSize(2); assertThat(ages).contains(23, 75); 4.4. 加入 当您有两个数据集时，您可能希望将它们加入某个id字段。为此，您可以使用*join()*转换。 让我们创建用户的交易和地址的集合： Tuple3\u0026lt;Integer, String, String\u0026gt; address = new Tuple3\u0026lt;\u0026gt;(1, \u0026#34;5th Avenue\u0026#34;, \u0026#34;London\u0026#34;); DataSet\u0026lt;Tuple3\u0026lt;Integer, String, String\u0026gt;\u0026gt; addresses = env.fromElements(address); Tuple2\u0026lt;Integer, String\u0026gt; firstTransaction = new Tuple2\u0026lt;\u0026gt;(1, \u0026#34;Transaction_1\u0026#34;); DataSet\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;\u0026gt; transactions = env.fromElements(firstTransaction, new Tuple2\u0026lt;\u0026gt;(12, \u0026#34;Transaction_2\u0026#34;)); 两个元组中的第一个字段都是整数类型，这是一个id字段，我们要在其上连接两个数据集。 要执行实际的加入逻辑，我们需要为地址和交易实现一个*KeySelector接口：* private static class IdKeySelectorTransaction implements KeySelector\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;, Integer\u0026gt; { @Override public Integer getKey(Tuple2\u0026lt;Integer, String\u0026gt; value) { return value.f0; } } private static class IdKeySelectorAddress implements KeySelector\u0026lt;Tuple3\u0026lt;Integer, String, String\u0026gt;, Integer\u0026gt; { @Override public Integer getKey(Tuple3\u0026lt;Integer, String, String\u0026gt; value) { return value.f0; } } 每个选择器只返回应该执行连接的字段。 不幸的是，这里不能使用 lambda 表达式，因为 Flink 需要泛型类型信息。 接下来，让我们使用这些选择器实现合并逻辑： List\u0026lt;Tuple2\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;, Tuple3\u0026lt;Integer, String, String\u0026gt;\u0026gt;\u0026gt; joined = transactions.join(addresses) .where(new IdKeySelectorTransaction()) .equalTo(new IdKeySelectorAddress()) .collect(); assertThat(joined).hasSize(1); assertThat(joined).contains(new Tuple2\u0026lt;\u0026gt;(firstTransaction, address)); 4.5. 种类 假设您有以下Tuple2 集合： Tuple2\u0026lt;Integer, String\u0026gt; secondPerson = new Tuple2\u0026lt;\u0026gt;(4, \u0026#34;Tom\u0026#34;); Tuple2\u0026lt;Integer, String\u0026gt; thirdPerson = new Tuple2\u0026lt;\u0026gt;(5, \u0026#34;Scott\u0026#34;); Tuple2\u0026lt;Integer, String\u0026gt; fourthPerson = new Tuple2\u0026lt;\u0026gt;(200, \u0026#34;Michael\u0026#34;); Tuple2\u0026lt;Integer, String\u0026gt; firstPerson = new Tuple2\u0026lt;\u0026gt;(1, \u0026#34;Jack\u0026#34;); DataSet\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;\u0026gt; transactions = env.fromElements( fourthPerson, secondPerson, thirdPerson, firstPerson); 如果要按元组的第一个字段对该集合进行排序，可以使用*sortPartitions()*转换： List\u0026lt;Tuple2\u0026lt;Integer, String\u0026gt;\u0026gt; sorted = transactions .sortPartition(new IdKeySelectorTransaction(), Order.ASCENDING) .collect(); assertThat(sorted) .containsExactly(firstPerson, secondPerson, thirdPerson, fourthPerson); 5. 字数统计 字数统计问题是一种常用来展示大数据处理框架能力的问题。基本解决方案涉及计算文本输入中的单词出现次数。让我们使用 Flink 来实现这个问题的解决方案。 作为我们解决方案的第一步，我们创建了一个LineSplitter类，它将我们的输入拆分为标记（单词），为每个标记收集一个Tuple2键值对。在每个元组中，键是在文本中找到的单词，值是整数一 (1)。 此类实现了*FlatMapFunction* 接口，该接口将String作为输入并生成*Tuple2 \u0026lt;String, Integer\u0026gt;：* public class LineSplitter implements FlatMapFunction\u0026lt;String, Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; { @Override public void flatMap(String value, Collector\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; out) { Stream.of(value.toLowerCase().split(\u0026#34;\\\\W+\u0026#34;)) .filter(t -\u0026gt; t.length() \u0026gt; 0) .forEach(token -\u0026gt; out.collect(new Tuple2\u0026lt;\u0026gt;(token, 1))); } } 我们在Collector类上调用*collect()*方法，在处理管道中向前推送数据。 我们的下一步也是最后一步是按元组的第一个元素（单词）对元组进行分组，然后对第二个元素执行求和聚合以产生单词出现的计数： public static DataSet\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; startWordCount( ExecutionEnvironment env, List\u0026lt;String\u0026gt; lines) throws Exception { DataSet\u0026lt;String\u0026gt; text = env.fromCollection(lines); return text.flatMap(new LineSplitter()) .groupBy(0) .aggregate(Aggregations.SUM, 1); } 我们使用了三种类型的 Flink 转换：flatMap()、groupBy()和aggregate()。 让我们编写一个测试来断言字数统计实现按预期工作： List\u0026lt;String\u0026gt; lines = Arrays.asList( \u0026#34;This is a first sentence\u0026#34;, \u0026#34;This is a second sentence with a one word\u0026#34;); DataSet\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; result = WordCount.startWordCount(env, lines); List\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; collect = result.collect(); assertThat(collect).containsExactlyInAnyOrder( new Tuple2\u0026lt;\u0026gt;(\u0026#34;a\u0026#34;, 3), new Tuple2\u0026lt;\u0026gt;(\u0026#34;sentence\u0026#34;, 2), new Tuple2\u0026lt;\u0026gt;(\u0026#34;word\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;is\u0026#34;, 2), new Tuple2\u0026lt;\u0026gt;(\u0026#34;this\u0026#34;, 2), new Tuple2\u0026lt;\u0026gt;(\u0026#34;second\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;first\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;with\u0026#34;, 1), new Tuple2\u0026lt;\u0026gt;(\u0026#34;one\u0026#34;, 1)); 6.数据流API 6.1 创建数据流 Apache Flink 还支持通过其 DataStream API 处理事件流。如果我们想开始消费事件，我们首先需要使用StreamExecutionEnvironment类： StreamExecutionEnvironment executionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment(); 接下来，我们可以使用来自各种来源的executionEnvironment创建一个事件流。它可能是一些像Apache Kafka这样的消息总线，但在这个例子中，我们将简单地从几个字符串元素创建一个源： DataStream\u0026lt;String\u0026gt; dataStream = executionEnvironment.fromElements( \u0026#34;This is a first sentence\u0026#34;, \u0026#34;This is a second sentence with a one word\u0026#34;); 我们可以对DataStream的每个元素应用转换，就像在普通的DataSet类中一样： SingleOutputStreamOperator\u0026lt;String\u0026gt; upperCase = text.map(String::toUpperCase); 为了触发执行，我们需要调用一个接收器操作，例如print()，它只会将转换结果打印到标准输出，然后是StreamExecutionEnvironment类的*execute()*方法： upperCase.print(); env.execute(); 它将产生以下输出： 1\u0026gt; THIS IS A FIRST SENTENCE 2\u0026gt; THIS IS A SECOND SENTENCE WITH A ONE WORD 6.2. 事件窗口化 在实时处理事件流时，您有时可能需要将事件组合在一起并在这些事件的窗口上应用一些计算。 假设我们有一个事件流，其中每个事件都是由事件编号和事件发送到我们系统时的时间戳组成的对，并且我们可以容忍无序的事件，但前提是它们是无序的。迟到了二十多秒。 对于这个例子，让我们首先创建一个流来模拟两个相隔几分钟的事件，并定义一个时间戳提取器来指定我们的延迟阈值： SingleOutputStreamOperator\u0026lt;Tuple2\u0026lt;Integer, Long\u0026gt;\u0026gt; windowed = env.fromElements( new Tuple2\u0026lt;\u0026gt;(16, ZonedDateTime.now().plusMinutes(25).toInstant().getEpochSecond()), new Tuple2\u0026lt;\u0026gt;(15, ZonedDateTime.now().plusMinutes(2).toInstant().getEpochSecond())) .assignTimestampsAndWatermarks( new BoundedOutOfOrdernessTimestampExtractor \u0026lt;Tuple2\u0026lt;Integer, Long\u0026gt;\u0026gt;(Time.seconds(20)) { @Override public long extractTimestamp(Tuple2\u0026lt;Integer, Long\u0026gt; element) { return element.f1 * 1000; } }); 接下来，让我们定义一个窗口操作，将我们的事件分组为 5 秒的窗口，并对这些事件应用转换： SingleOutputStreamOperator\u0026lt;Tuple2\u0026lt;Integer, Long\u0026gt;\u0026gt; reduced = windowed .windowAll(TumblingEventTimeWindows.of(Time.seconds(5))) .maxBy(0, true); reduced.print(); 它将获取每五秒窗口的最后一个元素，因此它会打印出： 1\u0026gt; (15,1491221519) 请注意，我们看不到第二个事件，因为它晚于指定的延迟阈值到达。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_flink/","tags":[],"title":"Apache Flink 与 Java 简介"},{"categories":["Data"],"contents":"1. 简介 在本教程中，我们将了解如何使用事件数据和Apache Druid。我们将介绍事件数据和 Druid 架构的基础知识。作为其中的一部分，我们将创建一个简单的数据管道，利用 Druid 的各种功能，涵盖各种数据摄取模式和查询准备数据的不同方式。 2.基本概念 在深入了解 Apache Druid 的操作细节之前，我们先来了解一些基本概念。我们感兴趣的领域是大规模事件数据的实时分析。 因此，必须了解我们所说的事件数据的含义以及大规模实时分析它们需要什么。 2.1 什么是事件数据？ 事件数据是指关于在特定时间点发生的变化的一条信息。事件数据在当今的应用程序中几乎无处不在。从经典的应用程序日志到由事物生成的现代传感器数据，它几乎无处不在。这些通常以大规模生成的机器可读信息为特征。 它们为预测、自动化、通信和集成等多种功能提供支持，仅举几例。此外，它们在事件驱动架构中也很重要。 2.2. 什么是阿帕奇德鲁伊？ Apache Druid 是一个实时分析数据库，旨在对面向事件的数据进行快速分析。Druid 于 2011 年启动，2012 年在 GPL 许可下开源，并于 2015 年迁移到 Apache 许可。它由 Apache 基金会管理，社区贡献了多个组织。它提供实时摄取、快速查询性能和高可用性。 Druid 这个名字指的是它的架构可以转变来解决不同类型的数据问题。它通常用于商业智能应用程序以分析大量实时和历史数据。 3. Druid架构 Druid 是一个用 Java 编写的面向列的分布式数据源。它能够摄取大量事件数据并在这些数据之上提供低延迟查询。此外，它提供了任意切片和切块数据的可能性。 了解 Druid 架构如何支持这些特性非常有趣。在本节中，我们将介绍 Druid 架构的一些重要部分。 3.1数据存储设计 了解 Druid 如何构建和存储其数据非常重要，这允许分区和分布。Druid在处理过程中默认对数据进行分区，并将它们存储到块和段中： Druid**将数据存储在我们所知的“数据源”**中，这在逻辑上类似于关系数据库中的表。一个 Druid 集群可以并行处理多个数据源，从各种来源摄取。 每个数据源都是分区的——默认情况下基于时间，如果配置了其他属性，则进一步基于其他属性。数据的时间范围称为“块” ——例如，如果数据按小时分区，则为一小时的数据。 每个块进一步划分为一个或多个“段”，这些“段”是由多行数据组成的单个文件。一个数据源可能有从几个段到数百万个段的任何地方。 3.2. 德鲁伊进程 Druid 具有多进程和分布式架构。因此，每个过程都可以独立扩展，从而使我们能够创建灵活的集群。让我们了解作为 Druid 一部分的重要过程：  Coordinator：该进程主要负责段管理和分发，并与历史进程通信，根据配置加载或删除段 Overlord：这是负责接受任务、协调任务分发、围绕任务创建锁以及向调用者返回状态的主要进程 Broker：这是所有查询都发送到分布式集群中执行的进程；它从 Zookeeper 收集元数据并将查询路由到具有正确段的进程 路由器：这是一个可选进程，可用于将查询路由到不同的代理进程，从而为更重要数据的查询提供查询隔离 历史：这些是存储可查询数据的进程；他们与 Zookeeper 保持持续的联系，并监视他们必须加载和服务的分段信息 MiddleManager：这些是执行提交任务的工作进程；他们将任务转发给在不同 JVM 中运行的 Peons，从而提供资源和日志隔离  3.3. 外部依赖 除了核心进程之外，Druid 还依赖于几个外部依赖项才能使其集群按预期运行。 让我们看看Druid集群是如何与核心进程和外部依赖一起形成的：  Druid 使用深度存储来存储已摄取到系统中的任何数据。这些不用于响应查询，而是用作数据备份和在进程之间传输数据。这些可以是从本地文件系统到分布式对象存储（如 S3 和 HDFS）的任何内容。 元数据存储用于保存共享系统元数据，如段使用信息和任务信息。但是，它从未用于存储实际数据。它是一个关系数据库，如 Apache Derby、PostgreSQL 或 MySQL。 Druid 使用 Apache Zookeeper 来管理当前的集群状态。它促进了 Druid 集群中的许多操作，例如协调者/霸主领导者选举、段发布协议和段加载/删除协议。 4. Druid设置 Druid 旨在部署为可扩展的容错集群。但是，建立生产级 Druid 集群并非易事。正如我们之前看到的，有许多流程和外部依赖项需要设置和配置。由于可以以灵活的方式创建集群，因此我们必须注意我们的要求，以适当地设置各个流程。 此外，Druid仅在类 Unix 环境中受支持，而不在 Windows 上受支持。此外，运行 Druid 进程需要 Java 8 或更高版本。有几种单服务器配置可用于在单台机器上设置 Druid 以运行教程和示例。但是，为了运行生产工作负载，建议设置一个具有多台机器的成熟 Druid 集群。 出于本教程的目的，我们将借助Docker Hub 上发布的官方 Docker 镜像在单台机器上设置 Druid。这使我们也可以在 Windows 上运行 Druid，正如我们之前讨论的那样，它不受其他支持。有一个Docker compose 文件可用，它为每个 Druid 进程及其外部依赖项创建一个容器。 我们必须将配置值作为环境变量提供给 Druid。实现这一点的最简单方法是在与 Docker compose 文件相同的目录中提供一个名为“environment”的文件。 一旦我们有了 Docker compose 和环境文件，启动 Druid 就像在同一目录中运行命令一样简单： docker-compose up 这将调出单机 Druid 设置所需的所有容器。我们必须小心为 Docker 机器提供足够的内存，因为 Druid 会消耗大量资源。 5. 读取数据 使用 Druid 构建数据管道的第一步是将数据加载到 Druid 中。这个过程在 Druid 架构中称为数据读取或索引。我们必须找到合适的数据集才能继续本教程。 现在，正如我们迄今为止所收集的那样，我们必须收集事件数据并具有一些时间性质，以充分利用 Druid 基础设施。 Druid 的官方指南使用简单而优雅的数据，其中包含特定日期的 Wikipedia 页面编辑。我们将继续在此处的教程中使用它。 5.1 数据模型 让我们首先检查我们拥有的数据的结构。我们创建的大多数数据管道对数据异常非常敏感，因此有必要尽可能地清理数据。 尽管执行数据分析有复杂的方法和工具，但我们将从目视检查开始。快速分析表明，输入数据具有以 JSON 格式捕获的事件，其中单个事件包含典型属性： { \u0026#34;time\u0026#34;: \u0026#34;2015-09-12T02:10:26.679Z\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#pt.wikipedia\u0026#34;, \u0026#34;cityName\u0026#34;: null, \u0026#34;comment\u0026#34;: \u0026#34;Houveram problemas na última edição e tive de refazê-las, junto com as atualizações da página.\u0026#34;, \u0026#34;countryIsoCode\u0026#34;: \u0026#34;BR\u0026#34;, \u0026#34;countryName\u0026#34;: \u0026#34;Brazil\u0026#34;, \u0026#34;isAnonymous\u0026#34;: true, \u0026#34;isMinor\u0026#34;: false, \u0026#34;isNew\u0026#34;: false, \u0026#34;isRobot\u0026#34;: false, \u0026#34;isUnpatrolled\u0026#34;: true, \u0026#34;metroCode\u0026#34;: null, \u0026#34;namespace\u0026#34;: \u0026#34;Main\u0026#34;, \u0026#34;page\u0026#34;: \u0026#34;Catarina Muniz\u0026#34;, \u0026#34;regionIsoCode\u0026#34;: null, \u0026#34;regionName\u0026#34;: null, \u0026#34;user\u0026#34;: \u0026#34;181.213.37.148\u0026#34;, \u0026#34;delta\u0026#34;: 197, \u0026#34;added\u0026#34;: 197, \u0026#34;deleted\u0026#34;: 0 } 虽然定义此事件的属性有很多，但在使用 Druid 时，有一些是我们特别感兴趣的：  时间戳 方面 指标  Druid 需要一个特定的属性来标识为时间戳列。在大多数情况下，Druid 的数据解析器能够自动检测出最佳候选者。但是我们总是有选择的余地，特别是如果我们的数据中没有合适的属性。 维度是 Druid 按原样存储的属性。我们可以将它们用于任何目的，例如分组、过滤或应用聚合器。我们可以在摄取规范中选择维度，我们将在本教程中进一步讨论。 与维度不同，指标是默认**以聚合形式存储的属性。**我们可以为 Druid 选择一个聚合函数，以便在摄取期间应用到这些属性。与启用汇总一起，这些可以导致紧凑的数据表示。 5.2. 读取方法 现在，我们将讨论在 Druid 中执行数据读取的各种方法。通常，事件驱动的数据本质上是流式传输的，这意味着它们会随着时间的推移以不同的速度生成，就像维基百科的编辑一样。 但是，我们可能会在一段时间内对数据进行批处理，其中数据本质上更加静态，就像去年发生的所有 Wikipedia 编辑一样。 我们可能还需要解决不同的数据用例，而 Druid 对其中的大多数都提供了出色的支持。让我们回顾一下在数据管道中使用 Druid 的两种最常见的方式：  流式读取 批量读取  在 Druid 中读取数据的最常见方式是通过 Apache Streaming 服务，Druid 可以直接从 Kafka 读取数据。Druid 也支持 Kinesis 等其他平台。我们必须在 Overload 进程上启动主管，该进程创建和管理 Kafka 索引任务。我们可以通过 Overload 进程的 HTTP POST 命令提交作为 JSON 文件的主管规范来启动主管。 或者，我们可以批量读取数据——例如，从本地或远程文件。它为基于 Hadoop 的批量摄取提供了一种选择，用于从 Hadoop 文件系统中以 Hadoop 文件格式摄取数据。更常见的是，我们可以选择顺序或并行的原生批量摄取。这是一种更方便、更简单的方法，因为它没有任何外部依赖项。 5.3. 定义任务规范 在本教程中，我们将为我们拥有的输入数据设置一个本机批量读取任务。我们可以选择从 Druid 控制台配置任务，这为我们提供了直观的图形界面。或者，我们可以将任务规范定义为 JSON 文件，并使用脚本或命令行将其提交给霸主进程。 让我们首先定义一个简单的任务规范，用于在名为wikipedia-index.json的文件中摄取我们的数据： { \u0026#34;type\u0026#34; : \u0026#34;index_parallel\u0026#34;, \u0026#34;spec\u0026#34; : { \u0026#34;dataSchema\u0026#34; : { \u0026#34;dataSource\u0026#34; : \u0026#34;wikipedia\u0026#34;, \u0026#34;dimensionsSpec\u0026#34; : { \u0026#34;dimensions\u0026#34; : [ \u0026#34;channel\u0026#34;, \u0026#34;cityName\u0026#34;, \u0026#34;comment\u0026#34;, \u0026#34;countryIsoCode\u0026#34;, \u0026#34;countryName\u0026#34;, \u0026#34;isAnonymous\u0026#34;, \u0026#34;isMinor\u0026#34;, \u0026#34;isNew\u0026#34;, \u0026#34;isRobot\u0026#34;, \u0026#34;isUnpatrolled\u0026#34;, \u0026#34;metroCode\u0026#34;, \u0026#34;namespace\u0026#34;, \u0026#34;page\u0026#34;, \u0026#34;regionIsoCode\u0026#34;, \u0026#34;regionName\u0026#34;, \u0026#34;user\u0026#34;, { \u0026#34;name\u0026#34;: \u0026#34;added\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;deleted\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;delta\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } ] }, \u0026#34;timestampSpec\u0026#34;: { \u0026#34;column\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;iso\u0026#34; }, \u0026#34;metricsSpec\u0026#34; : [], \u0026#34;granularitySpec\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;uniform\u0026#34;, \u0026#34;segmentGranularity\u0026#34; : \u0026#34;day\u0026#34;, \u0026#34;queryGranularity\u0026#34; : \u0026#34;none\u0026#34;, \u0026#34;intervals\u0026#34; : [\u0026#34;2015-09-12/2015-09-13\u0026#34;], \u0026#34;rollup\u0026#34; : false } }, \u0026#34;ioConfig\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;index_parallel\u0026#34;, \u0026#34;inputSource\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;local\u0026#34;, \u0026#34;baseDir\u0026#34; : \u0026#34;quickstart/tutorial/\u0026#34;, \u0026#34;filter\u0026#34; : \u0026#34;wikiticker-2015-09-12-sampled.json.gz\u0026#34; }, \u0026#34;inputFormat\u0026#34; : { \u0026#34;type\u0026#34;: \u0026#34;json\u0026#34; }, \u0026#34;appendToExisting\u0026#34; : false }, \u0026#34;tuningConfig\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;index_parallel\u0026#34;, \u0026#34;maxRowsPerSegment\u0026#34; : 5000000, \u0026#34;maxRowsInMemory\u0026#34; : 25000 } } } 让我们根据我们在前面的小节中介绍的基础知识来理解这个任务规范：  我们选择了index_parallel任务，它为我们提供了并行的本地批量摄取 我们将在此任务中使用的数据源名称为“ wikipedia” 我们数据的时间戳来自属性“时间” 我们正在添加许多数据属性作为维度 在当前任务中，我们没有为我们的数据使用任何指标 此任务应禁用默认启用的汇总 该任务的输入源是一个名为wikiticker-2015-09-12-sampled.json.gz的本地文件 我们没有使用任何辅助分区，我们可以在tuneConfig中定义  此任务规范假设我们已下载数据文件 wikiticker-2015-09-12-sampled.json.gz并将其保存在运行 Druid 的本地计算机上。当我们将 Druid 作为 Docker 容器运行时，这可能会更棘手。幸运的是，Druid在quickstart/tutorial位置默认提供了这个示例数据。 5.4. 提交任务规范 最后，我们可以使用curl之类的工具通过命令行将此任务规范提交给霸主进程： curl -X \u0026#39;POST\u0026#39; -H \u0026#39;Content-Type:application/json\u0026#39; -d @wikipedia-index.json http://localhost:8081/druid/indexer/v1/task 通常，如果提交成功，**上述命令会返回任务的 ID 。**我们可以通过 Druid 控制台或执行查询来验证我们的摄取任务的状态，我们将在下一节中介绍。 5.5. 高级读取概念 Druid 最适合我们需要处理大量数据的情况——当然不是我们在本教程中看到的那种数据！现在，要大规模启用功能，Druid 架构必须提供合适的工具和技巧。 虽然我们不会在本教程中使用它们，但让我们快速讨论汇总和分区。 事件数据很快就会增长到海量，这会影响我们可以实现的查询性能。在许多情况下，我们可能会随着时间的推移汇总数据。这就是我们在 Druid 中所熟知的 roll-up。启用汇总后，Druid 会在摄取期间努力汇总具有相同维度和时间戳的行。虽然它可以节省空间，但roll-up确实会导致查询精度的损失，因此我们必须合理使用它。 面对不断增长的数据量，实现更好性能的另一种潜在方法是分配数据，从而分配工作负载。默认情况下，Druid根据时间戳将数据划分为包含一个或多个段的时间块。此外，我们可以决定使用自然维度进行二次分区以提高数据局部性。此外，Druid 首先按时间戳对每个段内的数据进行排序，然后按我们配置的其他维度进行排序。 6. 查询数据 一旦我们成功地执行了数据摄取，它应该可以供我们查询了。在 Druid 中有多种查询数据的方法。在 Druid 中执行查询的最简单方法是通过 Druid 控制台。但是，我们也可以通过发送 HTTP 命令或使用命令行工具来执行查询。 在 Druid 中构造查询的两种突出方式是原生查询和类似 SQL 的查询。我们将以这两种方式构建一些基本查询，并使用curl通过 HTTP 发送它们。让我们看看如何对我们之前在 Druid 中摄取的数据创建一些简单的查询。 6.1 本机查询 Druid 中的原生查询使用 JSON 对象，我们可以将其发送到代理或路由器进行处理。我们可以通过 HTTP POST 命令发送查询，以及其他方式来执行相同的操作。 让我们创建一个名为simple_query_native.json的 JSON 文件： { \u0026#34;queryType\u0026#34; : \u0026#34;topN\u0026#34;, \u0026#34;dataSource\u0026#34; : \u0026#34;wikipedia\u0026#34;, \u0026#34;intervals\u0026#34; : [\u0026#34;2015-09-12/2015-09-13\u0026#34;], \u0026#34;granularity\u0026#34; : \u0026#34;all\u0026#34;, \u0026#34;dimension\u0026#34; : \u0026#34;page\u0026#34;, \u0026#34;metric\u0026#34; : \u0026#34;count\u0026#34;, \u0026#34;threshold\u0026#34; : 10, \u0026#34;aggregations\u0026#34; : [ { \u0026#34;type\u0026#34; : \u0026#34;count\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;count\u0026#34; } ] } 这是一个简单的查询，用于获取 2019 年 9 月 12 日至 13 日期间页面编辑次数最多的前十个页面。 让我们使用curl通过 HTTP 发布： curl -X \u0026#39;POST\u0026#39; -H \u0026#39;Content-Type:application/json\u0026#39; -d @simple_query_native.json http://localhost:8888/druid/v2?pretty 此响应包含 JSON 格式的前十页的详细信息： [ { \u0026#34;timestamp\u0026#34; : \u0026#34;2015-09-12T00:46:58.771Z\u0026#34;, \u0026#34;result\u0026#34; : [ { \u0026#34;count\u0026#34; : 33, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:Vandalismusmeldung\u0026#34; }, { \u0026#34;count\u0026#34; : 28, \u0026#34;page\u0026#34; : \u0026#34;User:Cyde/List of candidates for speedy deletion/Subpage\u0026#34; }, { \u0026#34;count\u0026#34; : 27, \u0026#34;page\u0026#34; : \u0026#34;Jeremy Corbyn\u0026#34; }, { \u0026#34;count\u0026#34; : 21, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:Administrators\u0026#39; noticeboard/Incidents\u0026#34; }, { \u0026#34;count\u0026#34; : 20, \u0026#34;page\u0026#34; : \u0026#34;Flavia Pennetta\u0026#34; }, { \u0026#34;count\u0026#34; : 18, \u0026#34;page\u0026#34; : \u0026#34;Total Drama Presents: The Ridonculous Race\u0026#34; }, { \u0026#34;count\u0026#34; : 18, \u0026#34;page\u0026#34; : \u0026#34;User talk:Dudeperson176123\u0026#34; }, { \u0026#34;count\u0026#34; : 18, \u0026#34;page\u0026#34; : \u0026#34;Wikipédia:Le Bistro/12 septembre 2015\u0026#34; }, { \u0026#34;count\u0026#34; : 17, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:In the news/Candidates\u0026#34; }, { \u0026#34;count\u0026#34; : 17, \u0026#34;page\u0026#34; : \u0026#34;Wikipedia:Requests for page protection\u0026#34; } ] } ] 6.2. Druid SQL Druid 有一个内置的 SQL 层，它为我们提供了以熟悉的类似 SQL 的结构构建查询的自由。它利用 Apache Calcite 来解析和规划查询。但是，Druid SQL 将 SQL 查询转换为查询代理上的本机查询，然后再将它们发送到数据进程。 让我们看看如何创建与以前相同的查询，但使用 Druid SQL。和以前一样，我们将创建一个名为simple_query_sql.json的 JSON 文件： { \u0026#34;query\u0026#34;:\u0026#34;SELECT page, COUNT(*) AS counts / FROM wikipedia WHERE \\\u0026#34;__time\\\u0026#34; / BETWEEN TIMESTAMP \u0026#39;2015-09-12 00:00:00\u0026#39; AND TIMESTAMP \u0026#39;2015-09-13 00:00:00\u0026#39; / GROUP BY page ORDER BY Edits DESC LIMIT 10\u0026#34; } 请注意，为了便于阅读，查询已分成多行，但它应该出现在单行上。同样，和以前一样，我们将通过 HTTP 发布此查询，但发送到不同的端点： curl -X \u0026#39;POST\u0026#39; -H \u0026#39;Content-Type:application/json\u0026#39; -d @simple_query_sql.json http://localhost:8888/druid/v2/sql 输出应该与我们之前使用本机查询实现的非常相似。 6.3. 查询类型 在前面的部分中，我们看到了一种查询类型，我们根据间隔获取度量“计数”的前十个结果。这只是 Druid 支持的一种查询类型，称为TopN查询。当然，我们可以通过使用过滤器和聚合使这个简单的TopN查询更有趣。但这不在本教程的范围内。但是，我们可能会对 Druid 中的其他几个查询感兴趣。 一些流行的包括 Timeseries 和 GroupBy。 时间序列查询返回一个 JSON 对象数组，其中每个对象表示时间序列查询中描述的一个值——例如，过去一个月的一个维度的每日平均值。 GroupBy查询返回一个 JSON 对象数组，其中每个对象代表一个分组，如 group-by 查询中所述。例如，我们可以查询一个维度在过去一个月中按另一个维度分组的日平均值。 还有其他几种查询类型，包括Scan、Search、TimeBoundary、SegmentMetadata和DatasourceMetadata。 6.4. 高级查询概念 Druid 提供了一些复杂的方法来创建复杂的查询，以创建有趣的数据应用程序。这些包括各种对数据进行切片和切块的方法，同时仍然能够提供令人难以置信的查询性能。 虽然对它们的详细讨论超出了本教程的范围，但让我们讨论一些重要的，例如连接和查找、多租户和查询缓存。 Druid 支持两种加入数据的方式。第一个是连接运算符，第二个是查询时查找。但是，为了获得更好的查询性能，建议避免查询时连接。 多租户是指在同一个 Druid 基础设施上支持多个租户的特性，同时仍然为它们提供逻辑隔离。在 Druid 中，可以通过每个租户的单独数据源或租户的数据分区来实现这一点。 最后，查询缓存是数据密集型应用程序性能的关键。Druid 支持分段和查询结果级别的查询结果缓存。此外，缓存数据可以驻留在内存中或外部持久存储中。 7. 语言绑定 尽管 Druid 对在 JSON 中创建摄取规范和定义查询具有出色的支持，但有时在 JSON 中定义这些查询可能很乏味，尤其是在查询变得复杂时。不幸的是，Druid 没有提供任何特定语言的客户端库来帮助我们在这方面。但是社区已经开发了相当多的语言绑定。一个这样的客户端库也可用于 Java。 我们将快速了解如何使用 Java 中的这个客户端库构建我们之前使用的TopN查询。 让我们首先在 Maven 中定义所需的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;in.zapr.druid\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druidry\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在此之后，我们应该能够使用客户端库并创建我们的TopN查询： DateTime startTime = new DateTime(2015, 9, 12, 0, 0, 0, DateTimeZone.UTC); DateTime endTime = new DateTime(2015, 9, 13, 0, 0, 0, DateTimeZone.UTC); Interval interval = new Interval(startTime, endTime); Granularity granularity = new SimpleGranularity(PredefinedGranularity.ALL); DruidDimension dimension = new SimpleDimension(\u0026#34;page\u0026#34;); TopNMetric metric = new SimpleMetric(\u0026#34;count\u0026#34;); DruidTopNQuery query = DruidTopNQuery.builder() .dataSource(\u0026#34;wikipedia\u0026#34;) .dimension(dimension) .threshold(10) .topNMetric(metric) .granularity(granularity) .filter(filter) .aggregators(Arrays.asList(new LongSumAggregator(\u0026#34;count\u0026#34;, \u0026#34;count\u0026#34;))) .intervals(Collections.singletonList(interval)).build(); 在此之后，我们可以简单地生成所需的 JSON 结构，我们可以在 HTTP POST 调用中使用它： ObjectMapper mapper = new ObjectMapper(); String requiredJson = mapper.writeValueAsString(query); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_druid_event_driven_data/","tags":[],"title":"使用 Apache Druid 的事件驱动数据"},{"categories":["Spring"],"contents":"1. 概述 本教程的重点是配置和使用Apache CXF框架以及 Spring - 使用 Java 或 XML 配置。 这是 Apache CXF 系列的第二篇；第一个侧重于将 CXF 的基础知识作为 JAX-WS 标准 API 的实现。 2. Maven依赖 与上一个教程类似，需要包含以下两个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-frontend-jaxws\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-transports-http\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 有关最新版本的 Apache CXF 工件，请查看apache-cxf。 此外，支持 Spring 还需要以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 Spring 工件。 最后，因为我们将使用 Java Servlet 3.0+ API 而不是传统的web.xml部署描述符以编程方式配置应用程序，所以我们需要以下工件： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在这里我们可以找到最新版本的 Servlet API。 3. 服务器端组件 现在让我们看一下为了发布 Web 服务端点而需要在服务器端出现的组件。 3.1 WebApplicationInitilizer接口 WebApplicationInitializer接口被实现为以编程方式为应用程序配置ServletContext接口。当出现在类路径上时，它的onStartup方法由 servlet 容器自动调用，然后ServletContext被实例化和初始化。 下面是如何定义一个类来实现WebApplicationInitializer接口： public class AppInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext container) { // Method implementation  } } onStartup *()*方法是使用如下所示的代码片段实现的。 首先，创建并配置 Spring 应用程序上下文以注册包含配置元数据的类： AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(ServiceConfiguration.class); ServiceConfiguration类使用@Configuration注解进行注解，以提供 bean 定义。这个类将在下一小节中讨论。 以下片段显示了如何将 Spring 应用程序上下文添加到 servlet 上下文中： container.addListener(new ContextLoaderListener(context)); 由 Apache CXF 定义的CXFServlet类被生成并注册以处理传入的请求： ServletRegistration.Dynamic dispatcher = container.addServlet(\u0026#34;dispatcher\u0026#34;, new CXFServlet()); 应用程序上下文加载配置文件中定义的 Spring 元素。在这种情况下，servlet 的名称是cxf ，因此默认情况下，上下文会在名为cxf-servlet.xml的文件中查找这些元素。 最后，CXF servlet 被映射到一个相对 URL： dispatcher.addMapping(\u0026#34;/services\u0026#34;); 3.2. 好旧的web.xml 或者，如果我们想使用（有点过时的）部署描述符而不是WebApplicationInitilizer接口，则相应的web.xml文件应该包含以下 servlet 定义： \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;cxf\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.apache.cxf.transport.servlet.CXFServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;cxf\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/services/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 3.3. 服务配置类 现在让我们看一下服务配置——首先是一个包含 Web 服务端点的 bean 定义的基本框架： @Configuration public class ServiceConfiguration { // Bean definitions } 第一个需要的 bean 是*SpringBus——*它为 Apache CXF 提供扩展以与 Spring 框架一起工作： @Bean public SpringBus springBus() { return new SpringBus(); } 还需要使用SpringBus bean和 Web 服务实现器来创建**EnpointImpl bean 。此 bean 用于在给定的 HTTP 地址发布端点： @Bean public Endpoint endpoint() { EndpointImpl endpoint = new EndpointImpl(springBus(), new DemoImpl()); endpoint.publish(\u0026#34;http://localhost:8080/services/demo\u0026#34;); return endpoint; } DemoImpl类用于实现 Web 服务接口。其定义在下一小节中给出。 或者，我们也可以在 XML 配置文件中声明服务器端点。具体来说，下面的cxf-servlet.xml文件与 3.1 小节中定义的web.xml部署描述符一起使用，并描述了完全相同的端点： \u0026lt;jaxws:endpoint id=\u0026#34;demo\u0026#34; implementor=\u0026#34;com.codingman.cxf.spring.DemoImpl\u0026#34; address=\u0026#34;http://localhost:8080/services/demo\u0026#34; /\u0026gt; 请注意，XML 配置文件以部署描述符中定义的 servlet 名称命名，即cxf。 3.4. 类型定义 接下来——这里是前面小节中已经提到的实现者的定义： @WebService(endpointInterface = \u0026#34;com.codingman.cxf.spring.demo\u0026#34;) public class DemoImpl implements Demo { private int counter; public String hello(String name) { return \u0026#34;Hello \u0026#34; + name + \u0026#34;!\u0026#34;; } public String register(Student student) { counter++; return student.getName() + \u0026#34; is registered student number \u0026#34; + counter; } } 此类为Apache CXF 将包含在已发布的 WSDL 元数据中的Demo端点接口提供了一个实现： @WebService public interface Demo { String hello(String name); String register(Student student); } 端点接口和实现者都使用Student类，定义如下： public class Student { private String name; // constructors, getters and setters } 4. 客户端 Bean 为了利用 Spring 框架，我们在*@Configuration*注解的类中声明一个 bean： @Configuration public class ClientConfiguration { // Bean definitions } 定义了一个名为client的 bean ： @Bean(name = \u0026#34;client\u0026#34;) public Object generateProxy() { return proxyFactoryBean().create(); } 客户端bean 代表Web 服务的代理。它是通过调用JaxWsProxyFactoryBean bean 上的**create方法创建的，这是一个用于创建 JAX-WS 代理的工厂。 JaxWsProxyFactoryBean对象通过以下方法创建和配置： @Bean public JaxWsProxyFactoryBean proxyFactoryBean() { JaxWsProxyFactoryBean proxyFactory = new JaxWsProxyFactoryBean(); proxyFactory.setServiceClass(Demo.class); proxyFactory.setAddress(\u0026#34;http://localhost:8080/services/demo\u0026#34;); return proxyFactory; } 工厂的serviceClass属性表示 Web 服务接口，而address属性表示代理进行远程调用的 URL 地址。 此外，对于客户端的 Spring bean，可以恢复为 XML 配置文件。以下元素声明了与我们上面以编程方式配置的相同的 bean： \u0026lt;bean id=\u0026#34;client\u0026#34; factory-bean=\u0026#34;clientFactory\u0026#34; factory-method=\u0026#34;create\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;clientFactory\u0026#34; class=\u0026#34;org.apache.cxf.jaxws.JaxWsProxyFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;serviceClass\u0026#34; value=\u0026#34;com.codingman.cxf.spring.demo\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;address\u0026#34; value=\u0026#34;http://localhost:8080/services/demo\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 5. 测试用例 本节描述用于说明 Apache CXF 对 Spring 的支持的测试用例。测试用例在名为StudentTest的类中定义。 首先，我们需要从前面提到的ServiceConfiguration配置类中加载一个 Spring 应用上下文，并将其缓存在context字段中： private ApplicationContext context = new AnnotationConfigApplicationContext(ClientConfiguration.class); 接下来，声明服务端点接口的代理并从应用程序上下文加载： private Demo demoProxy = (Demo) context.getBean(\u0026#34;client\u0026#34;); 这个Demo代理将用于下面描述的测试用例。 在第一个测试用例中，我们证明当在代理上本地调用hello方法时，响应与端点**实现者从远程 Web 服务返回的响应完全相同： @Test public void whenUsingHelloMethod_thenCorrect() { String response = demoProxy.hello(\u0026#34;John Bob\u0026#34;); assertEquals(\u0026#34;Hello John Bob!\u0026#34;, response); } 在第二个测试用例中，学生通过在本地调用代理上的register方法注册课程，代理反过来又调用 Web 服务。然后，该远程服务将计算学生人数并将其返回给呼叫者。以下代码片段证实了我们的预期： @Test public void whenUsingRegisterMethod_thenCorrect() { Student student1 = new Student(\u0026#34;Adam\u0026#34;); Student student2 = new Student(\u0026#34;Eve\u0026#34;); String student1Response = demoProxy.register(student1); String student2Response = demoProxy.register(student2); assertEquals(\u0026#34;Adam is registered student number 1\u0026#34;, student1Response); assertEquals(\u0026#34;Eve is registered student number 2\u0026#34;, student2Response); } 6. 集成测试 为了在服务器上部署为 Web 应用程序，需要先将本教程中的代码片段打包到 WAR 文件中。这可以通过在 POM 文件中声明包装属性来实现： \u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt; 打包作业由 Maven WAR 插件实现： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 该插件将编译后的源代码打包成 WAR 文件。由于我们使用 Java 代码配置 servlet 上下文，因此不需要存在传统的web.xml部署描述符。因此，failOnMissingWebXml属性必须设置为false以避免在执行插件时失败。 我们可以通过此链接获取最新版本的 Maven WAR 插件。 为了说明 Web 服务的操作，我们创建了一个集成测试。该测试首先生成 WAR 文件并启动嵌入式服务器，然后让客户端调用 Web 服务，验证后续响应并最终停止服务器。 以下插件需要包含在 Maven POM 文件中。有关更多详细信息，请查看此集成测试教程。 这是 Maven Surefire 插件： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;StudentTest.java\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 这个插件的最新版本可以在这里找到。 声明了一个带有integration id的配置文件部分以方便集成测试： \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;integration\u0026lt;/id\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; ... \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; Maven Cargo 插件包含在集成配置文件中： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.cargo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cargo-maven2-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;container\u0026gt; \u0026lt;containerId\u0026gt;jetty9x\u0026lt;/containerId\u0026gt; \u0026lt;type\u0026gt;embedded\u0026lt;/type\u0026gt; \u0026lt;/container\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;cargo.hostname\u0026gt;localhost\u0026lt;/cargo.hostname\u0026gt; \u0026lt;cargo.servlet.port\u0026gt;8080\u0026lt;/cargo.servlet.port\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;start-server\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;pre-integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;start\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;stop-server\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;post-integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;stop\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 请注意，为了清楚起见，仅包含cargo.hostname和*cargo.servlet.port配置属性。*这些配置属性可以省略而不会对应用程序产生任何影响，因为它们的值与默认值相同。该插件启动服务器，等待连接，最后停止服务器以释放系统资源。 这个链接允许我们查看最新版本的 Maven Cargo 插件。 Maven Surefire 插件在集成配置文件中再次声明，以覆盖其在主构建部分中的配置并执行上一节中描述的测试用例： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;test\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;none\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 现在整个过程可以通过命令运行：mvn -Pintegration clean install。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cxf_with_spring/","tags":["Apache CXF"],"title":"使用 Spring 的 Apache CXF 指南"},{"categories":["REST"],"contents":"1. 概述 本教程将Apache CXF介绍为符合 JAX-RS 标准的框架，该标准定义了 Java 生态系统对 REpresentational State Transfer (REST) 架构模式的支持。 具体来说，它逐步描述了如何构建和发布 RESTful Web 服务，以及如何编写单元测试来验证服务。 这是 Apache CXF 系列的第三篇；第一个侧重于将 CXF 用作完全兼容 JAX-WS 的实现。第二篇文章提供了如何将 CXF 与 Spring 一起使用的指南。 2. Maven依赖  第一个必需的依赖项是org.apache.cxf:cxf- rt -frontend- jaxrs。该工件提供 JAX-RS API 以及 CXF 实现： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-frontend-jaxrs\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在本教程中，我们使用 CXF 创建服务器端点来发布 Web 服务，而不是使用 servlet 容器。因此，需要在 Maven POM 文件中包含以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-transports-http-jetty\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最后，让我们添加 HttpClient 库以方便单元测试： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在这里您可以找到最新版本的cxf-rt-frontend-jaxrs依赖项。您可能还想参考此链接以获取org.apache.cxf:cxf-rt-transports-http-jetty工件的最新版本。最后，可以在这里找到最新版本的 httpclient。 3. 资源类和请求映射 让我们开始实现一个简单的例子；我们将使用两个资源课程和学生来设置我们的 REST API。 我们将从简单开始，然后逐步转向更复杂的示例。 3.1 资源 以下是Student资源类的定义： @XmlRootElement(name = \u0026#34;Student\u0026#34;) public class Student { private int id; private String name; // standard getters and setters  // standard equals and hashCode implementations  } 请注意，我们使用*@XmlRootElement*注释告诉 JAXB 这个类的实例应该被编组为 XML。 接下来是Course资源类的定义： @XmlRootElement(name = \u0026#34;Course\u0026#34;) public class Course { private int id; private String name; private List\u0026lt;Student\u0026gt; students = new ArrayList\u0026lt;\u0026gt;(); private Student findById(int id) { for (Student student : students) { if (student.getId() == id) { return student; } } return null; } // standard getters and setters  // standard equals and hasCode implementations  } 最后，让我们实现*CourseRepository——*它是根资源并作为 Web 服务资源的入口点： @Path(\u0026#34;course\u0026#34;) @Produces(\u0026#34;text/xml\u0026#34;) public class CourseRepository { private Map\u0026lt;Integer, Course\u0026gt; courses = new HashMap\u0026lt;\u0026gt;(); // request handling methods  private Course findById(int id) { for (Map.Entry\u0026lt;Integer, Course\u0026gt; course : courses.entrySet()) { if (course.getKey() == id) { return course.getValue(); } } return null; } } 注意带有@Path注释的映射。CourseRepository是这里的根资源，因此它被映射为处理以course开头的所有 URL 。 @Produces注解的值用于告诉服务器在将此类中的方法返回的对象发送给客户端之前将其转换为 XML 文档。我们在这里使用 JAXB 作为默认值，因为没有指定其他绑定机制。 3.2. 简单的数据设置 因为这是一个简单的示例实现，所以我们使用内存中的数据而不是成熟的持久性解决方案。 考虑到这一点，让我们实现一些简单的设置逻辑来将一些数据填充到系统中： { Student student1 = new Student(); Student student2 = new Student(); student1.setId(1); student1.setName(\u0026#34;Student A\u0026#34;); student2.setId(2); student2.setName(\u0026#34;Student B\u0026#34;); List\u0026lt;Student\u0026gt; course1Students = new ArrayList\u0026lt;\u0026gt;(); course1Students.add(student1); course1Students.add(student2); Course course1 = new Course(); Course course2 = new Course(); course1.setId(1); course1.setName(\u0026#34;REST with Spring\u0026#34;); course1.setStudents(course1Students); course2.setId(2); course2.setName(\u0026#34;Learn Spring Security\u0026#34;); courses.put(1, course1); courses.put(2, course2); } 此类中处理 HTTP 请求的方法将在下一小节中介绍。 3.3. API – 请求映射方法 现在，让我们来看看实际 REST API 的实现。 我们将开始在资源 POJO 中添加 API 操作——使用*@Path*注释。 重要的是要理解这与典型 Spring 项目中的方法有很大不同——API 操作将在控制器中定义，而不是在 POJO 本身上。 让我们从Course类中定义的映射方法开始： @GET @Path(\u0026#34;{studentId}\u0026#34;) public Student getStudent(@PathParam(\u0026#34;studentId\u0026#34;)int studentId) { return findById(studentId); } 简单地说，该方法在处理GET请求时被调用，由*@GET*注解表示。 注意到从 HTTP 请求映射studentId路径参数的简单语法。 然后我们简单地使用findById帮助器方法返回相应的Student实例。 以下方法通过将接收到的Student对象添加到学生列表来处理由*@POST注释指示的POST*请求： @POST @Path(\u0026#34;\u0026#34;) public Response createStudent(Student student) { for (Student element : students) { if (element.getId() == student.getId() { return Response.status(Response.Status.CONFLICT).build(); } } students.add(student); return Response.ok(student).build(); } 如果创建操作成功，则返回200 OK响应，如果具有提交id的对象已经存在，则返回409 Conflict 。 另请注意，我们可以跳过*@Path*注释，因为它的值是一个空字符串。 最后一个方法处理DELETE请求。它从学生列表中删除一个元素，其id是接收到的路径参数，并返回一个OK (200) 状态的响应。如果没有与指定id关联的元素，这意味着没有要删除的内容，则此方法返回Not Found (404) 状态的响应： @DELETE @Path(\u0026#34;{studentId}\u0026#34;) public Response deleteStudent(@PathParam(\u0026#34;studentId\u0026#34;) int studentId) { Student student = findById(studentId); if (student == null) { return Response.status(Response.Status.NOT_FOUND).build(); } students.remove(student); return Response.ok().build(); } 让我们继续请求CourseRepository类的映射方法。 以下getCourse方法返回Course对象，该对象是**课程映射中条目的值，其键是接收到的GET请求的courseId路径参数。在内部，该方法将路径参数分派给findById辅助方法以完成其工作。 @GET @Path(\u0026#34;courses/{courseId}\u0026#34;) public Course getCourse(@PathParam(\u0026#34;courseId\u0026#34;) int courseId) { return findById(courseId); } 以下方法更新课程地图的现有条目，其中接收到的PUT请求的正文是条目值，courseId参数是关联的键： @PUT @Path(\u0026#34;courses/{courseId}\u0026#34;) public Response updateCourse(@PathParam(\u0026#34;courseId\u0026#34;) int courseId, Course course) { Course existingCourse = findById(courseId); if (existingCourse == null) { return Response.status(Response.Status.NOT_FOUND).build(); } if (existingCourse.equals(course)) { return Response.notModified().build(); } courses.put(courseId, course); return Response.ok().build(); } 如果更新成功，则此updateCourse方法返回OK (200) 状态的响应，不更改任何内容，如果现有对象和上传的对象具有相同的字段值，则返回Not Modified (304) 响应。如果在课程地图中找不到具有给定ID的**课程实例，该方法将返回具有未找到(404) 状态的响应。 这个根资源类的第三种方法不直接处理任何 HTTP 请求。相反，它将请求委托给Course类，其中请求由匹配方法处理： @Path(\u0026#34;courses/{courseId}/students\u0026#34;) public Course pathToStudent(@PathParam(\u0026#34;courseId\u0026#34;) int courseId) { return findById(courseId); } 我们已经在Course类中展示了之前处理委托请求的方法。 4.服务器端点 本节重点介绍 CXF 服务器的构建，该服务器用于发布 RESTful Web 服务，其资源已在上一节中描述。第一步是实例化一个JAXRSServerFactoryBean对象并设置根资源类： JAXRSServerFactoryBean factoryBean = new JAXRSServerFactoryBean(); factoryBean.setResourceClasses(CourseRepository.class); 然后需要在工厂 bean 上设置资源提供者来管理根资源类的生命周期。我们使用默认的单例资源提供程序，它为每个请求返回相同的资源实例： factoryBean.setResourceProvider( new SingletonResourceProvider(new CourseRepository())); 我们还设置了一个地址来指示发布 Web 服务的 URL： factoryBean.setAddress(\u0026#34;http://localhost:8080/\u0026#34;); 现在可以使用factoryBean创建一个新**服务器，该服务器将开始侦听传入连接： Server server = factoryBean.create(); 本节上面的所有代码都应该包装在main方法中： public class RestfulServer { public static void main(String args[]) throws Exception { // code snippets shown above  } } 该main方法的调用在第 6 节中介绍。 5. 测试用例 本节介绍用于验证我们之前创建的 Web 服务的测试用例。这些测试在响应四种最常用方法的 HTTP 请求后验证服务的资源状态，即GET、POST、PUT和DELETE。 5.1。准备 首先，在测试类中声明了两个静态字段，命名为RestfulTest： private static String BASE_URL = \u0026#34;http://localhost:8080/\u0026#34;; private static CloseableHttpClient client; 在运行测试之前，我们创建一个客户端对象，用于与服务器通信并在之后销毁它： @BeforeClass public static void createClient() { client = HttpClients.createDefault(); } @AfterClass public static void closeClient() throws IOException { client.close(); } 客户端实例现在已准备好供测试用例使用。 5.2. 获取请求 在测试类中，我们定义了两种方法来向运行 Web 服务的服务器发送GET请求。 第一种方法是根据资源中的ID获取**Course实例： private Course getCourse(int courseOrder) throws IOException { URL url = new URL(BASE_URL + courseOrder); InputStream input = url.openStream(); Course course = JAXB.unmarshal(new InputStreamReader(input), Course.class); return course; } 第二种是在给定资源中课程和学生的id的情况下获取**Student实例： private Student getStudent(int courseOrder, int studentOrder) throws IOException { URL url = new URL(BASE_URL + courseOrder + \u0026#34;/students/\u0026#34; + studentOrder); InputStream input = url.openStream(); Student student = JAXB.unmarshal(new InputStreamReader(input), Student.class); return student; } 这些方法将 HTTP GET请求发送到服务资源，然后将 XML 响应解组到相应类的实例。两者都用于在执行POST、PUT和DELETE请求后验证服务资源状态。 5.3. POST请求 本小节介绍了POST请求的两个测试用例，说明了上传的Student实例导致冲突以及成功创建时Web 服务的操作。 在第一个测试中，我们使用了一个从conflict_student.xml文件中解组的**Student对象，该文件位于类路径中，内容如下： \u0026lt;Student\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student B\u0026lt;/name\u0026gt; \u0026lt;/Student\u0026gt; 这是将该内容转换为POST请求正文的方式： HttpPost httpPost = new HttpPost(BASE_URL + \u0026#34;1/students\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;conflict_student.xml\u0026#34;); httpPost.setEntity(new InputStreamEntity(resourceStream)); 设置Content-Type标头是为了告诉服务器请求的内容类型是 XML： httpPost.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); 由于上传的Student对象已经存在于第一个Course实例中，我们希望创建失败并返回一个带有Conflict (409) 状态的响应。以下代码片段验证了预期： HttpResponse response = client.execute(httpPost); assertEquals(409, response.getStatusLine().getStatusCode()); 在下一个测试中，我们从名为created_student.xml的文件中提取 HTTP 请求的主体，该文件也在类路径中。这是文件的内容： \u0026lt;Student\u0026gt; \u0026lt;id\u0026gt;3\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student C\u0026lt;/name\u0026gt; \u0026lt;/Student\u0026gt; 与前面的测试用例类似，我们构建并执行一个请求，然后验证是否成功创建了一个新实例： HttpPost httpPost = new HttpPost(BASE_URL + \u0026#34;2/students\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;created_student.xml\u0026#34;); httpPost.setEntity(new InputStreamEntity(resourceStream)); httpPost.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); HttpResponse response = client.execute(httpPost); assertEquals(200, response.getStatusLine().getStatusCode()); 我们可以确认 Web 服务资源的新状态： Student student = getStudent(2, 3); assertEquals(3, student.getId()); assertEquals(\u0026#34;Student C\u0026#34;, student.getName()); 这是对新Student对象请求的 XML 响应如下所示： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;Student\u0026gt; \u0026lt;id\u0026gt;3\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student C\u0026lt;/name\u0026gt; \u0026lt;/Student\u0026gt; 5.4. PUT请求 让我们从一个无效的更新请求开始，其中正在更新的Course对象不存在。以下是用于替换Web 服务资源中不存在的Course对象的实例内容： \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;3\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Apache CXF Support for RESTful\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 该内容存储在类路径上名为non_existent_course.xml的文件中。它被提取，然后通过以下代码用于填充PUT请求的主体： HttpPut httpPut = new HttpPut(BASE_URL + \u0026#34;3\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;non_existent_course.xml\u0026#34;); httpPut.setEntity(new InputStreamEntity(resourceStream)); 设置Content-Type标头是为了告诉服务器请求的内容类型是 XML： httpPut.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); 由于我们故意发送无效请求来更新不存在的对象，因此预计会收到*Not Found (404) 响应。*响应已验证： HttpResponse response = client.execute(httpPut); assertEquals(404, response.getStatusLine().getStatusCode()); 在PUT请求的第二个测试用例中，我们提交了一个具有相同字段值的Course对象。由于在这种情况下没有任何更改，我们希望返回未修改(304) 状态的响应。整个过程如图： HttpPut httpPut = new HttpPut(BASE_URL + \u0026#34;1\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;unchanged_course.xml\u0026#34;); httpPut.setEntity(new InputStreamEntity(resourceStream)); httpPut.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); HttpResponse response = client.execute(httpPut); assertEquals(304, response.getStatusLine().getStatusCode()); 其中未更改的课程.xml 是类路径上保存用于更新的信息的文件。这是它的内容： \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;1\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;REST with Spring\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 在PUT请求的最后一个演示中，我们执行了一个有效的更新。以下是changed_course.xml文件的内容，其内容用于更新 Web 服务资源中的Course实例： \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Apache CXF Support for RESTful\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 这是构建和执行请求的方式： HttpPut httpPut = new HttpPut(BASE_URL + \u0026#34;2\u0026#34;); InputStream resourceStream = this.getClass().getClassLoader() .getResourceAsStream(\u0026#34;changed_course.xml\u0026#34;); httpPut.setEntity(new InputStreamEntity(resourceStream)); httpPut.setHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/xml\u0026#34;); 让我们验证对服务器的PUT请求并验证成功上传： HttpResponse response = client.execute(httpPut); assertEquals(200, response.getStatusLine().getStatusCode()); 让我们验证 Web 服务资源的新状态： Course course = getCourse(2); assertEquals(2, course.getId()); assertEquals(\u0026#34;Apache CXF Support for RESTful\u0026#34;, course.getName()); 以下代码片段显示了发送对先前上传的Course对象的 GET 请求时 XML 响应的内容： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Apache CXF Support for RESTful\u0026lt;/name\u0026gt; \u0026lt;/Course\u0026gt; 5.5. 删除请求 首先，让我们尝试删除一个不存在的Student实例。操作应该会失败，并且会出现Not Found (404) 状态的相应响应： HttpDelete httpDelete = new HttpDelete(BASE_URL + \u0026#34;1/students/3\u0026#34;); HttpResponse response = client.execute(httpDelete); assertEquals(404, response.getStatusLine().getStatusCode()); 在DELETE请求的第二个测试用例中，我们创建、执行和验证请求： HttpDelete httpDelete = new HttpDelete(BASE_URL + \u0026#34;1/students/1\u0026#34;); HttpResponse response = client.execute(httpDelete); assertEquals(200, response.getStatusLine().getStatusCode()); 我们使用以下代码片段验证 Web 服务资源的新状态： Course course = getCourse(1); assertEquals(1, course.getStudents().size()); assertEquals(2, course.getStudents().get(0).getId()); assertEquals(\u0026#34;Student B\u0026#34;, course.getStudents().get(0).getName()); 接下来，我们列出在请求Web 服务资源中的第一个Course对象后收到的 XML 响应： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;Course\u0026gt; \u0026lt;id\u0026gt;1\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;REST with Spring\u0026lt;/name\u0026gt; \u0026lt;students\u0026gt; \u0026lt;id\u0026gt;2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Student B\u0026lt;/name\u0026gt; \u0026lt;/students\u0026gt; \u0026lt;/Course\u0026gt; 很明显，第一个Student已成功移除。 6. 测试执行 第 4 节描述了如何在RestfulServer类的main方法中创建和销毁一个Server实例。 使服务器启动并运行的最后一步是调用该main方法。为了实现这一点，在 Maven POM 文件中包含并配置了 Exec Maven 插件： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.mojo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;exec-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0\u0026lt;version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt; com.codingman.cxf.jaxrs.implementation.RestfulServer \u0026lt;/mainClass\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 这个插件的最新版本可以通过这个链接找到。 在编译和打包本教程中说明的工件的过程中，Maven Surefire 插件会自动执行包含在名称以 Test 开头或结尾的类中的所有测试。如果是这种情况，则应将插件配置为排除这些测试： \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/ServiceTest\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 使用上述配置，ServiceTest被排除在外，因为它是测试类的名称。您可以为该类选择任何名称，前提是其中包含的测试在服务器准备好连接之前不由 Maven Surefire 插件运行。 有关最新版本的 Maven Surefire 插件，请查看此处。 现在您可以执行exec:java目标来启动 RESTful Web 服务服务器，然后使用 IDE 运行上述测试。等效地，您可以通过在终端中执行命令mvn -Dtest=ServiceTest test来开始测试。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cxf_rest_api/","tags":["Apache CXF"],"title":"Apache CXF 对 RESTful Web 服务的支持"},{"categories":["Cloud","DevOps"],"contents":"1. 简介 Apache Curator是 Apache Zookeeper 的 Java 客户端，Apache Zookeeper是分布式应用程序的流行协调服务。 在本教程中，我们将介绍 Curator 提供的一些最相关的功能：  连接管理——管理连接和重试策略 异步——通过添加异步功能和使用 Java 8 lambda 来增强现有客户端 配置管理——对系统进行集中配置 强类型模型——使用类型模型 食谱——实现领导者选举、分布式锁或计数器  2. 先决条件 首先，建议快速了解一下Apache Zookeeper及其功能。 对于本教程，我们假设已经有一个独立的 Zookeeper 实例在127.0.0.1:2181上运行；如果您刚刚开始，这里有关于如何安装和运行它的说明。 首先，我们需要将curator-x-async依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-x-async\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.1\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本的 Apache Curator 4.XX 与 Zookeeper 3.5.X 存在硬依赖关系，目前仍处于测试阶段。 因此，在本文中，我们将使用当前最新的稳定版 Zookeeper 3.4.11。 所以我们需要排除 Zookeeper 依赖，并将Zookeeper 版本的依赖添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 有关兼容性的更多信息，请参阅此链接。 3. 连接管理 Apache Curator 的基本用例是连接到正在运行的 Apache Zookeeper 实例。 该工具提供了一个工厂来使用重试策略建立与 Zookeeper 的连接： int sleepMsBetweenRetries = 100; int maxRetries = 3; RetryPolicy retryPolicy = new RetryNTimes( maxRetries, sleepMsBetweenRetries); CuratorFramework client = CuratorFrameworkFactory .newClient(\u0026#34;127.0.0.1:2181\u0026#34;, retryPolicy); client.start(); assertThat(client.checkExists().forPath(\u0026#34;/\u0026#34;)).isNotNull(); 在这个快速示例中，我们将重试 3 次，并在重试之间等待 100 毫秒，以防出现连接问题。 使用CuratorFramework客户端连接到 Zookeeper后，我们现在可以浏览路径、获取/设置数据并与服务器进行交互。 4.异步 Curator Async 模块包装了上述CuratorFramework客户端，以使用CompletionStage Java 8 API提供非阻塞功能。 让我们看看前面的示例如何使用 Async 包装器： int sleepMsBetweenRetries = 100; int maxRetries = 3; RetryPolicy retryPolicy = new RetryNTimes(maxRetries, sleepMsBetweenRetries); CuratorFramework client = CuratorFrameworkFactory .newClient(\u0026#34;127.0.0.1:2181\u0026#34;, retryPolicy); client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); AtomicBoolean exists = new AtomicBoolean(false); async.checkExists() .forPath(\u0026#34;/\u0026#34;) .thenAcceptAsync(s -\u0026gt; exists.set(s != null)); await().until(() -\u0026gt; assertThat(exists.get()).isTrue()); 现在，*checkExists()操作在异步模式下工作，不会阻塞主线程。我们还可以使用thenAcceptAsync()*方法一个接一个地链接操作，该方法使用CompletionStage API。 5. 配置管理 在分布式环境中，最常见的挑战之一是管理许多应用程序之间的共享配置。我们可以使用 Zookeeper 作为数据存储来保存我们的配置。 让我们看一个使用 Apache Curator 获取和设置数据的示例： CuratorFramework client = newClient(); client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); String key = getKey(); String expected = \u0026#34;my_value\u0026#34;; client.create().forPath(key); async.setData() .forPath(key, expected.getBytes()); AtomicBoolean isEquals = new AtomicBoolean(); async.getData() .forPath(key) .thenAccept(data -\u0026gt; isEquals.set(new String(data).equals(expected))); await().until(() -\u0026gt; assertThat(isEquals.get()).isTrue()); 在这个例子中，我们创建节点路径，在 Zookeeper 中设置数据，然后我们检查它的值是否相同来恢复它。关键字段可以是像*/config/dev/my_key*这样的节点路径。 5.1 观察者 Zookeeper 中另一个有趣的特性是能够监视键或节点。它允许我们监听配置的变化并更新我们的应用程序，而无需重新部署. 让我们看看上面的例子在使用 watchers 时的样子： CuratorFramework client = newClient() client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); String key = getKey(); String expected = \u0026#34;my_value\u0026#34;; async.create().forPath(key); List\u0026lt;String\u0026gt; changes = new ArrayList\u0026lt;\u0026gt;(); async.watched() .getData() .forPath(key) .event() .thenAccept(watchedEvent -\u0026gt; { try { changes.add(new String(client.getData() .forPath(watchedEvent.getPath()))); } catch (Exception e) { // fail ...  }}); // Set data value for our key async.setData() .forPath(key, expected.getBytes()); await() .until(() -\u0026gt; assertThat(changes.size()).isEqualTo(1)); 我们配置观察者，设置数据，然后确认被观察事件被触发。我们可以一次观察一个节点或一组节点。 6. 强类型模型 Zookeeper 主要处理字节数组，所以我们需要对我们的数据进行序列化和反序列化。这使我们能够灵活地处理任何可序列化的实例，但它可能难以维护。 为了在这里提供帮助，Curator 添加了类型化模型的概念，它委托序列化/反序列化并允许我们直接使用我们的类型。让我们看看它是如何工作的。 首先，我们需要一个序列化器框架。Curator 建议使用 Jackson 实现，所以让我们将Jackson 依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.13.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在，让我们尝试持久化我们的自定义类HostConfig： public class HostConfig { private String hostname; private int port; // getters and setters } 我们需要提供从HostConfig类到路径的模型规范映射，并使用 Apache Curator 提供的建模框架包装器： ModelSpec\u0026lt;HostConfig\u0026gt; mySpec = ModelSpec.builder( ZPath.parseWithIds(\u0026#34;/config/dev\u0026#34;), JacksonModelSerializer.build(HostConfig.class)) .build(); CuratorFramework client = newClient(); client.start(); AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); ModeledFramework\u0026lt;HostConfig\u0026gt; modeledClient = ModeledFramework.wrap(async, mySpec); modeledClient.set(new HostConfig(\u0026#34;host-name\u0026#34;, 8080)); modeledClient.read() .whenComplete((value, e) -\u0026gt; { if (e != null) { fail(\u0026#34;Cannot read host config\u0026#34;, e); } else { assertThat(value).isNotNull(); assertThat(value.getHostname()).isEqualTo(\u0026#34;host-name\u0026#34;); assertThat(value.getPort()).isEqualTo(8080); } }); 读取路径*/config/dev时的whenComplete()方法将返回 Zookeeper 中的HostConfig*实例。 7. recipes Zookeeper 提供此指南来实现高级解决方案或配方，例如领导者选举、分布式锁或共享计数器。 Apache Curator 为大多数这些配方提供了一个实现。要查看完整列表，请访问文档。 所有这些recipes都在一个单独的模块中可用： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 让我们直接进入并通过一些简单的例子开始理解这些。 7.1 领袖选举 在分布式环境中，我们可能需要一个主节点或领导节点来协调一项复杂的工作。 这是Curator中领导人选举配方的用法： CuratorFramework client = newClient(); client.start(); LeaderSelector leaderSelector = new LeaderSelector(client, \u0026#34;/mutex/select/leader/for/job/A\u0026#34;, new LeaderSelectorListener() { @Override public void stateChanged( CuratorFramework client, ConnectionState newState) { } @Override public void takeLeadership( CuratorFramework client) throws Exception { } }); // join the members group leaderSelector.start(); // wait until the job A is done among all members leaderSelector.close(); 当我们启动领导者选择器时，我们的节点会加入路径*/mutex/select/leader/for/job/A中的成员组。一旦我们的节点成为领导者，将调用takeLeadership*方法，我们作为领导者可以恢复工作。 7.2. 共享锁 共享锁配方是关于拥有一个完全分布式的锁： CuratorFramework client = newClient(); client.start(); InterProcessSemaphoreMutex sharedLock = new InterProcessSemaphoreMutex( client, \u0026#34;/mutex/process/A\u0026#34;); sharedLock.acquire(); // do process A  sharedLock.release(); 当我们获取锁时，Zookeeper 确保没有其他应用程序同时获取相同的锁。 7.3. 计数器 Counters 配方在所有客户端之间协调一个共享的Integer ： CuratorFramework client = newClient(); client.start(); SharedCount counter = new SharedCount(client, \u0026#34;/counters/A\u0026#34;, 0); counter.start(); counter.setCount(counter.getCount() + 1); assertThat(counter.getCount()).isEqualTo(1); 在此示例中，Zookeeper 将Integer值存储在路径*/counters/A中，如果尚未创建路径，则将该值初始化为0* 。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_curator/","tags":[],"title":"Apache Curator 简介"},{"categories":["Data"],"contents":"1. 简介 在本教程中，我们将 使用示例数据处理应用程序演示Apache Crunch 。我们将使用MapReduce框架运行这个应用程序。 我们将首先简要介绍一些 Apache Crunch 概念。然后我们将进入一个示例应用程序。在这个应用程序中，我们将进行文本处理：  首先，我们将从文本文件中读取行 稍后，我们将它们拆分为单词并删除一些常用单词 然后，我们将剩余的单词分组以获得唯一单词列表及其计数 最后，我们将此列表写入文本文件  2. 什么是MapReduce？ MapReduce 是一种分布式并行编程框架，用于在服务器集群上处理大量数据。Hadoop 和 Spark 等软件框架实现了 MapReduce。 **Crunch 提供了一个框架，用于在 Java 中编写、测试和运行 MapReduce 管道。**在这里，我们不直接编写 MapReduce 作业。相反，我们使用 Crunch API 定义数据管道（即执行输入、处理和输出步骤的操作）。Crunch Planner 将它们映射到 MapReduce 作业并在需要时执行它们。 **因此，每个 Crunch 数据管道都由Pipeline接口的一个实例进行协调。该接口还定义了通过Source实例将数据读入管道以及将数据从管道写入Target实例的方法。 我们有 3 个接口来表示数据：  PCollection – 不可变的分布式元素集合 PTable\u0026lt;K , V \u0026gt; – 一个不可变的、分布式的、无序的键和值的多映射 PGroupedTable\u0026lt;K , V \u0026gt; – K 类型键到可迭代 V的分布式排序映射，可仅迭代一次  ** DoFn是所有数据处理函数的基类**。它对应 于 MapReduce中的Mapper、 Reducer 和 Combiner类。我们将大部分开发时间用于编写和测试使用它的逻辑计算。 现在我们对 Crunch 更加熟悉了，让我们使用它来构建示例应用程序。 3. 建立一个 Crunch 项目 首先，让我们用 Maven 建立一个 Crunch 项目。我们可以通过两种方式做到这一点：  在现有项目的pom.xml文件中添加所需的依赖项 使用原型生成启动项目  让我们快速浏览一下这两种方法。 3.1 Maven 依赖项 为了将 Crunch 添加到现有项目，让我们在 pom.xml文件中添加所需的依赖项。 首先，让我们添加crunch-core库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.crunch\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;crunch-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，让我们添加hadoop-client库来与 Hadoop 通信。我们使用匹配Hadoop安装的版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.hadoop\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hadoop-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 我们可以查看 Maven Central 以获取最新版本的crunch-core和hadoop-client库。 3.2. Maven 原型 另一种方法是使用 Crunch 提供的 Maven 原型快速生成一个入门项目： mvn archetype:generate -Dfilter=org.apache.crunch:crunch-archetype 当上述命令提示时，我们提供 Crunch 版本和项目工件详细信息。 4. 紧缩管道设置 设置好项目后，我们需要创建一个Pipeline对象。 Crunch 有 3 个Pipeline实现：  MRPipeline – 在 Hadoop MapReduce 中执行 SparkPipeline – 作为一系列 Spark 管道执行 MemPipeline – 在客户端内存中执行，对单元测试很有用  通常，我们使用MemPipeline的实例进行开发和测试。稍后我们使用MRPipeline或SparkPipeline的实例进行实际执行。 如果我们需要一个内存管道，我们可以使用静态方法getInstance来获取MemPipeline实例： Pipeline pipeline = MemPipeline.getInstance(); 但是现在，让我们创建一个MRPipeline实例 来使用 Hadoop 执行应用程序*：* Pipeline pipeline = new MRPipeline(WordCount.class, getConf()); 5. 读取输入数据 创建管道对象后，我们要读取输入数据。 ** Pipeline接口提供了一种从文本文件读取输入的便捷方法**， 即 readTextFile(pathName)。 让我们调用这个方法来读取输入文本文件： PCollection\u0026lt;String\u0026gt; lines = pipeline.readTextFile(inputPath); 上面的代码将文本文件读取为String的集合。 下一步，让我们编写一个读取输入的测试用例： @Test public void givenPipeLine_whenTextFileRead_thenExpectedNumberOfRecordsRead() { Pipeline pipeline = MemPipeline.getInstance(); PCollection\u0026lt;String\u0026gt; lines = pipeline.readTextFile(INPUT_FILE_PATH); assertEquals(21, lines.asCollection() .getValue() .size()); } 在这个测试中，我们验证我们在读取文本文件时获得了预期的行数。 6. 数据处理步骤 读取输入数据后，我们需要对其进行处理。 Crunch API 包含许多 DoFn的子类来处理常见的数据处理场景：  FilterFn – 根据布尔条件过滤集合成员 MapFn – 将每个输入记录映射到一个输出记录 CombineFn – 将多个值组合成一个值 JoinFn – 执行连接，例如内连接、左外连接、右外连接和完全外连接  让我们通过使用这些类来实现以下数据处理逻辑：  将输入文件中的每一行拆分为单词 删除停用词 计算唯一的单词  6.1 将一行文本拆分为单词 首先，让我们创建Tokenizer类来将一行拆分为单词。 我们将扩展 DoFn 类。这个类有一个叫做process的抽象方法。此方法处理来自PCollection的输入记录并将输出发送到Emitter。 我们需要在这个方法中实现拆分逻辑： public class Tokenizer extends DoFn\u0026lt;String, String\u0026gt; { private static final Splitter SPLITTER = Splitter .onPattern(\u0026#34;\\\\s+\u0026#34;) .omitEmptyStrings(); @Override public void process(String line, Emitter\u0026lt;String\u0026gt; emitter) { for (String word : SPLITTER.split(line)) { emitter.emit(word); } } } 在上面的实现中，我们使用了Guava库中的Splitter类从一行中提取单词。 接下来，让我们为Tokenizer类编写一个单元测试 ： @RunWith(MockitoJUnitRunner.class) public class TokenizerUnitTest { @Mock private Emitter\u0026lt;String\u0026gt; emitter; @Test public void givenTokenizer_whenLineProcessed_thenOnlyExpectedWordsEmitted() { Tokenizer splitter = new Tokenizer(); splitter.process(\u0026#34; hello world \u0026#34;, emitter); verify(emitter).emit(\u0026#34;hello\u0026#34;); verify(emitter).emit(\u0026#34;world\u0026#34;); verifyNoMoreInteractions(emitter); } } 上面的测试验证是否返回了正确的单词。 最后，让我们使用这个类分割从输入文本文件中读取的行。 PCollection接口的parallelDo方法将给定的DoFn应用于所有元素并返回一个新的PCollection。** 让我们在 lines 集合上调用这个方法并传递一个Tokenizer的实例： PCollection\u0026lt;String\u0026gt; words = lines.parallelDo(new Tokenizer(), Writables.strings()); 结果，我们得到了输入文本文件中的单词列表。我们将在下一步中删除停用词。 6.2. 删除停用词 与上一步类似，让我们创建一个StopWordFilter类来过滤掉停用词。 但是，我们将扩展 FilterFn而不是DoFn。FilterFn有一个名为**accept的抽象方法。我们需要在这个方法中实现过滤逻辑： public class StopWordFilter extends FilterFn\u0026lt;String\u0026gt; { // English stop words, borrowed from Lucene.  private static final Set\u0026lt;String\u0026gt; STOP_WORDS = ImmutableSet .copyOf(new String[] { \u0026#34;a\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;are\u0026#34;, \u0026#34;as\u0026#34;, \u0026#34;at\u0026#34;, \u0026#34;be\u0026#34;, \u0026#34;but\u0026#34;, \u0026#34;by\u0026#34;, \u0026#34;for\u0026#34;, \u0026#34;if\u0026#34;, \u0026#34;in\u0026#34;, \u0026#34;into\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;it\u0026#34;, \u0026#34;no\u0026#34;, \u0026#34;not\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;on\u0026#34;, \u0026#34;or\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;such\u0026#34;, \u0026#34;t\u0026#34;, \u0026#34;that\u0026#34;, \u0026#34;the\u0026#34;, \u0026#34;their\u0026#34;, \u0026#34;then\u0026#34;, \u0026#34;there\u0026#34;, \u0026#34;these\u0026#34;, \u0026#34;they\u0026#34;, \u0026#34;this\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;was\u0026#34;, \u0026#34;will\u0026#34;, \u0026#34;with\u0026#34; }); @Override public boolean accept(String word) { return !STOP_WORDS.contains(word); } } 接下来，让我们编写StopWordFilter类的单元测试： public class StopWordFilterUnitTest { @Test public void givenFilter_whenStopWordPassed_thenFalseReturned() { FilterFn\u0026lt;String\u0026gt; filter = new StopWordFilter(); assertFalse(filter.accept(\u0026#34;the\u0026#34;)); assertFalse(filter.accept(\u0026#34;a\u0026#34;)); } @Test public void givenFilter_whenNonStopWordPassed_thenTrueReturned() { FilterFn\u0026lt;String\u0026gt; filter = new StopWordFilter(); assertTrue(filter.accept(\u0026#34;Hello\u0026#34;)); assertTrue(filter.accept(\u0026#34;World\u0026#34;)); } @Test public void givenWordCollection_whenFiltered_thenStopWordsRemoved() { PCollection\u0026lt;String\u0026gt; words = MemPipeline .collectionOf(\u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;sentence\u0026#34;); PCollection\u0026lt;String\u0026gt; noStopWords = words.filter(new StopWordFilter()); assertEquals(ImmutableList.of(\u0026#34;This\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;sentence\u0026#34;), Lists.newArrayList(noStopWords.materialize())); } } 此测试验证过滤逻辑是否正确执行。 最后，让我们使用StopWordFilter来过滤上一步生成的单词列表。 PCollection接口的filter方法将给定的FilterFn应用于所有元素并返回一个新的PCollection。 让我们在 words 集合上调用这个方法并传递一个StopWordFilter的实例： PCollection\u0026lt;String\u0026gt; noStopWords = words.filter(new StopWordFilter()); 结果，我们得到了过滤后的单词集合。 6.3. 计算唯一单词 在获得过滤后的单词集合后，我们要计算每个单词出现的频率。 PCollection接口有许多方法来执行常见的聚合：  min – 返回集合的最小元素 max – 返回集合的最大元素 length – 返回集合中元素的数量 count – 返回一个PTable，其中包含集合中每个唯一元素的计数  让我们使用count方法来获取唯一单词及其计数： // The count method applies a series of Crunch primitives and returns // a map of the unique words in the input PCollection to their counts. PTable\u0026lt;String, Long\u0026gt; counts = noStopWords.count(); 7. 指定输出 作为前面步骤的结果，我们有一个单词表和它们的计数。我们想将此结果写入文本文件。 Pipeline接口提供了方便****的 方法来编写输出： void write(PCollection\u0026lt;?\u0026gt; collection, Target target); void write(PCollection\u0026lt;?\u0026gt; collection, Target target, Target.WriteMode writeMode); \u0026lt;T\u0026gt; void writeTextFile(PCollection\u0026lt;T\u0026gt; collection, String pathName); 因此，让我们调用 writeTextFile方法： pipeline.writeTextFile(counts, outputPath); 8. 管理管道执行 到目前为止，所有步骤都刚刚定义了数据管道。未读取或处理任何输入。这是因为 Crunch 使用了惰性执行模型。 在 Pipeline 接口上调用控制作业计划和执行的方法之前，它不会运行 MapReduce 作业：  run - 准备一个执行计划来创建所需的输出，然后同步执行它 完成- 运行生成输出所需的任何剩余作业，然后清理创建的任何中间数据文件 runAsync - 类似于 run 方法，但以非阻塞方式执行  因此，让我们调用done方法将管道作为 MapReduce 作业执行： PipelineResult result = pipeline.done(); 上面的语句运行 MapReduce 作业以读取输入、处理它们并将结果写入输出目录。 9. 整合管道 到目前为止，我们已经开发并单元测试了读取输入数据、处理它并写入输出文件的逻辑。 接下来，让我们将它们放在一起构建整个数据管道： public int run(String[] args) throws Exception { String inputPath = args[0]; String outputPath = args[1]; // Create an object to coordinate pipeline creation and execution.  Pipeline pipeline = new MRPipeline(WordCount.class, getConf()); // Reference a given text file as a collection of Strings.  PCollection\u0026lt;String\u0026gt; lines = pipeline.readTextFile(inputPath); // Define a function that splits each line in a PCollection of Strings into  // a PCollection made up of the individual words in the file.  // The second argument sets the serialization format.  PCollection\u0026lt;String\u0026gt; words = lines.parallelDo(new Tokenizer(), Writables.strings()); // Take the collection of words and remove known stop words.  PCollection\u0026lt;String\u0026gt; noStopWords = words.filter(new StopWordFilter()); // The count method applies a series of Crunch primitives and returns  // a map of the unique words in the input PCollection to their counts.  PTable\u0026lt;String, Long\u0026gt; counts = noStopWords.count(); // Instruct the pipeline to write the resulting counts to a text file.  pipeline.writeTextFile(counts, outputPath); // Execute the pipeline as a MapReduce.  PipelineResult result = pipeline.done(); return result.succeeded() ? 0 : 1; } 10. Hadoop 启动配置 数据管道因此准备就绪。 但是，我们需要代码来启动它。因此，让我们编写启动应用程序的main方法： public class WordCount extends Configured implements Tool { public static void main(String[] args) throws Exception { ToolRunner.run(new Configuration(), new WordCount(), args); } ToolRunner.run 从命令行 解析 Hadoop 配置并执行 MapReduce 作业。 11. 运行应用程序 完整的应用程序现已准备就绪。让我们运行以下命令来构建它： mvn package 作为上述命令的结果，我们在目标目录中获得了打包的应用程序和一个特殊的作业 jar。 让我们使用这个作业 jar 在 Hadoop 上执行应用程序： hadoop jar target/crunch-1.0-SNAPSHOT-job.jar \u0026lt;input file path\u0026gt; \u0026lt;output directory\u0026gt; 应用程序读取输入文件并将结果写入输出文件。输出文件包含唯一单词及其计数，类似于以下内容： [Add,1] [Added,1] [Admiration,1] [Admitting,1] [Allowance,1] 除了 Hadoop，我们还可以在 IDE 中运行应用程序，作为独立应用程序或单元测试。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_crunch/","tags":[],"title":"Apache Crunch 指南"},{"categories":["Java Collections"],"contents":"1. 概述 在本文中，我们将探索 Apache Commons Collections 库的SetUtils API。简而言之，这些实用程序可用于对Java 中的Set数据结构执行某些操作。 2. 依赖安装 为了让我们在项目中使用SetUtils库，我们需要在项目的pom.xml文件中添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 或者，如果我们的项目是基于 Gradle 的，我们应该将依赖项添加到项目的build.gradle文件中。此外，我们需要将mavenCentral()添加到**build.gradle文件的存储库部分： compile \u0026#39;org.apache.commons:commons-collections4:4.1\u0026#39; 3. SetUtils SetUtils库的predicatedSet()方法允许定义要插入到集合中的所有元素应满足的条件。它接受一个源Set对象和一个谓词。 我们可以使用它来轻松验证Set的所有元素是否满足特定条件，这在开发第三方库/API 时会很方便。 如果任何元素的验证失败，将抛出IllegalArgumentException 。下面的代码段防止将 不以 \u0026lsquo;L\u0026rsquo; 开头的字符串添加到sourceSet或返回的验证集中： Set\u0026lt;String\u0026gt; validatingSet = SetUtils.predicatedSet(sourceSet, s -\u0026gt; s.startsWith(\u0026#34;L\u0026#34;)); 该库还具有predicatedSortedSet()和predicatedNavigableSet()分别用于处理SortedSet和NavigableSet。 4. 集合的并集、差集和交集 该库具有可以计算集合元素的并集、差集和交集的方法。 difference()方法接受两个Set对象并返回一个不可变的SetUtils 。**设置视图对象。返回的SetUtils。**SetView包含在 set a但不在 set b中的元素： Set\u0026lt;Integer\u0026gt; a = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 5)); Set\u0026lt;Integer\u0026gt; b = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2)); SetUtils.SetView\u0026lt;Integer\u0026gt; result = SetUtils.difference(a, b); assertTrue(result.size() == 1 \u0026amp;\u0026amp; result.contains(5)); 请注意，尝试在返回的SetUtils 上执行写操作，如add()或addAll() 。**SetView将抛出UnsupportedOperationException。 要修改返回的结果，我们需要调用返回的SetUtils的toSet()方法。**SetView获取一个可写的Set对象： Set\u0026lt;Integer\u0026gt; mutableSet = result.toSet(); SetUtils库的union方法完全符合它的意思——它返回集合a和b的所有元素。union方法还返回一个不可变的SetUtil.SetView对象： Set\u0026lt;Integer\u0026gt; expected = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 5)); SetUtils.SetView\u0026lt;Integer\u0026gt; union = SetUtils.union(a, b); assertTrue(SetUtils.isEqualSet(expected, union)); 注意assert 语句中使用的*isEqualSet()*****方法。**它是SetUtils库的一个方便的静态方法，可以有效地检查两个集合是否相等。 要获得集合的交集，即集合a和集合b中都存在的元素，我们将使用SetUtils。**交集（）方法。此方法还返回一个SetUtil.SetView对象： Set\u0026lt;Integer\u0026gt; expected = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2)); SetUtils.SetView\u0026lt;Integer\u0026gt; intersect = SetUtils.intersection(a, b); assertTrue(SetUtils.isEqualSet(expected, intersect)); 5. 转换集合元素 让我们看看另一个令人兴奋的方法*——SetUtils*。transformedSet（)。此方法接受一个Set对象和一个Transformer接口。在源集合的支持下，它使用*Transformer接口的**transform()*方法来转换集合的每个元素。 转换逻辑在*Transformer接口的**transform()*方法中定义，该方法应用于添加到集合中的每个元素。下面的代码片段将添加到集合中的每个元素乘以 2： Set\u0026lt;Integer\u0026gt; a = SetUtils.transformedSet(new HashSet\u0026lt;\u0026gt;(), e -\u0026gt; e * 2 ); a.add(2); assertEquals(a.toArray()[0], 4); *transformSet()*方法非常方便——它们甚至可以用来转换集合的元素——比如从字符串到整数。只要确保输出的类型是输入的子类型。 假设我们正在使用SortedSet或NavigableSet而不是HashSet，我们可以分别使用transformedSortedSet()或transformedNavigableSet()。 请注意，将一个新的HashSet实例传递给transformSet()方法。在将现有的非空Set传递给方法的情况下，不会转换预先存在的元素。 如果我们想要转换预先存在的元素（以及之后添加的元素），我们需要使用*org.apache.commons.collections4.set.TransformedSet的**transformSet()*方法： Set\u0026lt;Integer\u0026gt; source = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1)); Set\u0026lt;Integer\u0026gt; newSet = TransformedSet.transformedSet(source, e -\u0026gt; e * 2); assertEquals(newSet.toArray()[0], 2); assertEquals(source.toArray()[0], 2); 请注意，源集中的元素被转换，结果被复制到返回的newSet。 6. disjunction SetUtils库提供了一个静态方法，可用于查找集合析取。集合 a 和集合 b的析取是集合a和集合b唯一的所有元素。 让我们看看如何使用SetUtils库的*disjunction()*方法： Set\u0026lt;Integer\u0026gt; a = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 5)); Set\u0026lt;Integer\u0026gt; b = new HashSet\u0026lt;\u0026gt;(Arrays.asList(1, 2, 3)); SetUtils.SetView\u0026lt;Integer\u0026gt; result = SetUtils.disjunction(a, b); assertTrue( result.toSet().contains(5) \u0026amp;\u0026amp; result.toSet().contains(3)); 7. SetUtils库中的其他方法 SetUtils库中还有其他方法可以轻松处理集合数据：  我们可以使用synchronizedSet()或synchronizedSortedSet()来获得一个线程安全的Set。但是，如文档中所述，我们必须手动同步返回集的迭代器以避免非确定性行为 我们可以使用SetUtils.unmodifiableSet()来获取只读集。请注意，尝试将元素添加到返回的Set对象将引发UnsupportedOperationException 还有一个*SetUtils.emptySet()*方法，它返回一个类型安全、不可变的空集 SetUtils.emptyIfNull ()方法接受一个可为空的Set对象。如果提供的Set为空，则返回一个空的只读 S et；否则，它返回提供的Set SetUtils.orderedSet()将返回一个Set对象，该对象维护添加元素的顺序 *SetUtils.hashCodeForSet()*可以为一个集合生成一个哈希码——这样两个相同元素的集合将具有相同的哈希码 SetUtils.newIdentityHashSet()将返回一个使用==而不是equals()方法来匹配元素的HashSet 。 请在此处阅读其注意事项 \u0026quot;  ","permalink":"http://itcodingman.github.io/apache_commons_setutils/","tags":["Java Set"],"title":"Apache Commons Collections SetUtils"},{"categories":["Java Collections"],"contents":"1. 概述 Apache Commons Collections 库提供了补充 Java Collections Framework的有用类。 在本文中，我们将回顾接口OrderedMap，它扩展了java.util.Map。 2. Maven依赖 我们需要做的第一件事是在pom.xml中添加 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您可以在Maven 中央存储库中找到该库的最新版本。 3. OrderedMap属性 简单来说，一个实现了OrderedMap接口的地图：  保持其键集的顺序，尽管该集未排序 可以使用方法在两个方向上进行迭代：firstKey()和nextKey()，或lastKey()和previousKey() 可以用MapIterator遍历（也由库提供） 提供查找、更改、删除或替换元素的方法  **4. 使用OrderedMap ** 让我们在测试类中设置跑步者及其年龄的OrderedMap 。我们将使用LinkedMap——库中提供的OrderedMap实现之一。 首先，让我们设置跑步者和年龄的数组，我们将使用它们来加载地图并验证值的顺序： public class OrderMapUnitTest { private String[] names = {\u0026#34;Emily\u0026#34;, \u0026#34;Mathew\u0026#34;, \u0026#34;Rose\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;Anna\u0026#34;}; private Integer[] ages = {37, 28, 40, 36, 21}; private LinkedMap\u0026lt;String, Integer\u0026gt; runnersLinkedMap; //... } 现在，让我们初始化我们的地图： @Before public void createRunners() { this.runnersLinkedMap = new LinkedMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; RUNNERS_COUNT; i++) { runners.put(this.names[i], this.ages[i]); } } 4.1 前向迭代 让我们看看如何使用前向迭代器： @Test public void givenALinkedMap_whenIteratedForwards_thenPreservesOrder() { String name = this.runnersLinkedMap.firstKey(); int i = 0; while (name != null) { assertEquals(name, names[i]); name = this.runnersLinkedMap.nextKey(name); i++; } } 请注意，当我们到达最后一个键时，方法nextKey()将返回一个空值。 4.2. 向后迭代 现在让我们从最后一个键开始迭代： @Test public void givenALinkedMap_whenIteratedBackwards_thenPreservesOrder() { String name = this.runnersLinkedMap.lastKey(); int i = RUNNERS_COUNT - 1; while (name != null) { assertEquals(name, this.names[i]); name = this.runnersLinkedMap.previousKey(name); i--; } } **一旦我们到达第一个键，previousKey()方法将返回 null。 4.3. MapIterator示例 现在让我们使用mapIterator()方法来获取MapIterator，因为我们展示了它如何保留数组names和age中定义的跑步者的顺序： @Test public void givenALinkedMap_whenIteratedWithMapIterator_thenPreservesOrder() { OrderedMapIterator\u0026lt;String, Integer\u0026gt; runnersIterator = this.runnersLinkedMap.mapIterator(); int i = 0; while (runnersIterator.hasNext()) { runnersIterator.next(); assertEquals(runnersIterator.getKey(), this.names[i]); assertEquals(runnersIterator.getValue(), this.ages[i]); i++; } } 4.4. 移除元素 最后，让我们检查如何通过索引或对象删除元素： @Test public void givenALinkedMap_whenElementRemoved_thenSizeDecrease() { LinkedMap\u0026lt;String, Integer\u0026gt; lmap = (LinkedMap\u0026lt;String, Integer\u0026gt;) this.runnersLinkedMap; Integer johnAge = lmap.remove(\u0026#34;John\u0026#34;); assertEquals(johnAge, new Integer(36)); assertEquals(lmap.size(), RUNNERS_COUNT - 1); Integer emilyAge = lmap.remove(0); assertEquals(emilyAge, new Integer(37)); assertEquals(lmap.size(), RUNNERS_COUNT - 2); } 5. 提供的实现 目前，在库的 4.1 版本中，OrderedMap接口有两种实现*——ListOrderedMap和LinkedMap*。 ListOrderedMap使用java.util.List跟踪键集的顺序。它是OrderedMap的装饰器，可以使用静态方法ListOrderedMap.decorate(Map map)从任何**Map创建。 LinkedMap基于HashMap并通过允许双向迭代和OrderedMap接口的其他方法对其进行了改进。 两种实现还提供了OrderedMap接口之外的三个方法：  asList() – 获取List类型的列表（其中K是键的类型），保留映射的顺序 get(int index) – 获取位置index处的元素，而不是接口中提供的方法get(Object o) indexOf(Object o) – 获取对象o在有序映射中  我们可以将OrderedMap转换为LinkedMap以使用*asList()*方法： @Test public void givenALinkedMap_whenConvertedToList_thenMatchesKeySet() { LinkedMap\u0026lt;String, Integer\u0026gt; lmap = (LinkedMap\u0026lt;String, Integer\u0026gt;) this.runnersLinkedMap; List\u0026lt;String\u0026gt; listKeys = new ArrayList\u0026lt;\u0026gt;(); listKeys.addAll(this.runnersLinkedMap.keySet()); List\u0026lt;String\u0026gt; linkedMap = lmap.asList(); assertEquals(listKeys, linkedMap); } 然后我们可以检查LinkedMap实现中方法*indexOf(Object o)和get(int index)*的功能： @Test public void givenALinkedMap_whenSearchByIndexIsUsed_thenMatchesConstantArray() { LinkedMap\u0026lt;String, Integer\u0026gt; lmap = (LinkedMap\u0026lt;String, Integer\u0026gt;) this.runnersLinkedMap; for (int i = 0; i \u0026lt; RUNNERS_COUNT; i++) { String name = lmap.get(i); assertEquals(name, this.names[i]); assertEquals(lmap.indexOf(this.names[i]), i); } } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_ordered_map/","tags":["Java Map"],"title":"Apache Commons Collections OrderedMap"},{"categories":["Java Collections"],"contents":"1. 概述 在本快速教程中，我们将了解 Apache Commons Collections 库中提供的MultiValuedMap接口。 MultiValuedMap 提供了一个简单的 API，用于将每个键映射到 Java 中的值集合。*它是org.apache.commons.collections4.MultiMap*的继承者 *，*后者在 Commons Collection 4.1 中已被弃用。 2. Maven依赖 对于 Maven 项目，我们需要添加commons-collections4依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; **3. 将元素添加到MultiValuedMap ** 我们可以使用 put和putAll方法添加元素。 让我们从创建 MultiValuedMap的实例开始： MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); 接下来，让我们看看如何使用put方法一次添加一个元素 ： map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); 此外，让我们使用putAll方法添加一些元素，该方法在一次调用中将一个键映射到多个元素： map.putAll(\u0026#34;vehicles\u0026#34;, Arrays.asList(\u0026#34;car\u0026#34;, \u0026#34;bike\u0026#34;)); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;vehicles\u0026#34;)) .containsExactly(\u0026#34;car\u0026#34;, \u0026#34;bike\u0026#34;); 4. 从 MultiValuedMap中检索元素 MultiValuedMap提供检索键、值和键值映射的方法。让我们来看看其中的每一个。 4.1 获取键的所有值 要获取与键关联的所有值，我们可以使用get方法，该方法返回一个Collection： assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;fruits\u0026#34;)) .containsExactly(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;); 4.2. 获取所有键值映射 或者，我们可以使用 entries方法来获取 映射中包含的所有键值映射的集合： Collection\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = map.entries(); 4.3. 获取所有密钥 有两种方法可以检索 MultiValuedMap 中包含的所有键。 让我们使用keys方法来获取键的MultiSet视图： MultiSet\u0026lt;String\u0026gt; keys = map.keys(); assertThat(keys).contains(\u0026#34;fruits\u0026#34;, \u0026#34;vehicles\u0026#34;); 或者，我们可以使用keySet方法获取键的Set视图： Set\u0026lt;String\u0026gt; keys = map.keySet(); assertThat(keys).contains(\u0026#34;fruits\u0026#34;, \u0026#34;vehicles\u0026#34;); 4.4. 获取地图的所有值 最后，如果我们想要获取地图中包含的所有值的 Collection视图，我们可以使用values方法： Collection\u0026lt;String\u0026gt; values = map.values(); assertThat(values).contains(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;car\u0026#34;, \u0026#34;bike\u0026#34;); 5. 从 MultiValuedMap中移除元素 现在，让我们看看删除元素和键值映射的所有方法。 5.1 删除映射到键的所有元素 首先，让我们看看如何使用remove方法删除与指定键关联的所有值： Collection\u0026lt;String\u0026gt; removedValues = map.remove(\u0026#34;fruits\u0026#34;); assertThat(map.containsKey(\u0026#34;fruits\u0026#34;)).isFalse(); assertThat(removedValues).contains(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;); 此方法返回已删除值的 Collection视图。 5.2. 删除单个键值映射 现在，假设我们有一个映射到多个值的键，但我们只想删除一个映射值，留下其他值。我们可以使用 removeMapping方法轻松做到这一点： boolean isRemoved = map.removeMapping(\u0026#34;fruits\u0026#34;,\u0026#34;apple\u0026#34;); assertThat(map.containsMapping(\u0026#34;fruits\u0026#34;,\u0026#34;apple\u0026#34;)).isFalse(); 5.3. 删除所有键值映射 最后，我们可以使用 clear方法从地图中删除所有映射： map.clear(); assertThat(map.isEmpty()).isTrue(); 6. 检查MultiValuedMap中的元素 接下来，让我们看一下检查我们的地图中是否存在指定的键或值的各种方法。 6.1 检查密钥是否存在 要确定我们的地图是否包含指定键的映射，我们可以使用 containsKey方法： assertThat(map.containsKey(\u0026#34;vehicles\u0026#34;)).isTrue(); 6.2. 检查值是否存在 接下来，假设我们要检查映射中的至少一个键是否包含特定值的映射。我们可以使用 containsValue方法做到这一点： assertThat(map.containsValue(\u0026#34;orange\u0026#34;)).isTrue(); 6.3. 检查是否存在键值映射 同样，如果我们想检查一个映射是否包含特定键值对的映射，我们可以使用containsMapping 方法： assertThat(map.containsMapping(\u0026#34;fruits\u0026#34;,\u0026#34;orange\u0026#34;)).isTrue(); 6.4. 检查地图是否为空 要检查一个映射是否根本不包含任何键值映射，我们可以使用 isEmpty方法： assertThat(map.isEmpty()).isFalse; 6.5。检查地图的大小 最后，我们可以使用 size方法得到地图的总大小。当一个映射有多个值的键时，映射的总大小是所有键的所有值的计数： assertEquals(4, map.size()); 7. 实施 Apache Commons Collections Library 也提供了这个接口的多种实现。让我们来看看它们。 7.1 ArrayListValuedHashMap ArrayListValuedHashMap在内部 使用ArrayList 来存储与每个键关联的值，因此它允许重复的键值对： MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;fruits\u0026#34;)) .containsExactly(\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;orange\u0026#34;); 现在，值得注意的是这个类不是线程安全的。因此，如果我们想从多个线程中使用这个映射，我们必须确保使用适当的同步。 7.2. HashSetValuedHashMap HashSetValuedHashMap 使用HashSet来 存储每个给定键的值。因此，它不允许重复的键值对。 让我们看一个简单的例子，我们添加了两次相同的键值映射： MultiValuedMap\u0026lt;String, String\u0026gt; map = new HashSetValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); assertThat((Collection\u0026lt;String\u0026gt;) map.get(\u0026#34;fruits\u0026#34;)) .containsExactly(\u0026#34;apple\u0026#34;); 请注意，与我们之前使用 ArrayListValuedHashMap 的示例不同， HashSetValuedHashMap实现忽略了重复映射。 HashSetValuedHashMap 类也不 是线程安全的。 7.3. 不可修改的多值映射 UnmodifiableMultiValuedMap是一个装饰器类，当我们需要 MultiValuedMap的不可变实例时很有用 ——也就是说，它不应该允许进一步修改： @Test(expected = UnsupportedOperationException.class) public void givenUnmodifiableMultiValuedMap_whenInserting_thenThrowingException() { MultiValuedMap\u0026lt;String, String\u0026gt; map = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;apple\u0026#34;); map.put(\u0026#34;fruits\u0026#34;, \u0026#34;orange\u0026#34;); MultiValuedMap\u0026lt;String, String\u0026gt; immutableMap = MultiMapUtils.unmodifiableMultiValuedMap(map); immutableMap.put(\u0026#34;fruits\u0026#34;, \u0026#34;banana\u0026#34;); // throws exception } 再次值得注意的是，修改最终put将导致UnsupportedOperationException。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_multi_valued_map/","tags":["Java Map"],"title":"Apache Commons MultiValuedMap 指南"},{"categories":["Java"],"contents":"1. 概述 我们经常需要使用数学工具，有时java.lang.Math根本不够用。幸运的是，Apache Commons 的目标是使用Apache Commons Math填补标准库的漏洞。 Apache Commons Math 是最大的 Java 数学函数和实用程序开源库。鉴于本文只是一个介绍，我们将仅概述该库并展示最引人注目的用例。 2. 从 Apache Commons Math 开始 2.1 Apache Commons Math 的用法 Apache Commons Math 由数学函数（例如erf）、表示数学概念的结构（如复数、多项式、向量等）以及我们可以应用于这些结构的算法（求根、优化、曲线拟合、计算几何图形的交叉点等）。 2.2. Maven 配置 如果您使用的是 Maven，只需添加此依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-math3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.3. 包装概述 Apache Commons Math 分为几个包：  ***org.apache.commons.math3.stat –***统计和统计测试 ***org.apache.commons.math3.distribution -***概率分布 ***org.apache.commons.math3.random –***随机数、字符串和数据生成 ***org.apache.commons.math3.analysis –***求根、积分、插值、多项式等。 ***org.apache.commons.math3.linear -***矩阵，求解线性系统 ***org.apache.commons.math3.geometry -***几何（欧几里得空间和二进制空间分区） ***org.apache.commons.math3.transform –***变换方法（快速傅里叶） ***org.apache.commons.math3.ode -***常微分方程积分 ***org.apache.commons.math3.fitting –***曲线拟合 ***org.apache.commons.math3.optim -***函数最大化或最小化 ***org.apache.commons.math3.genetics -***遗传算法 ***org.apache.commons.math3.ml -***机器学习（聚类和神经网络） ***org.apache.commons.math3.util –***扩展 java.lang.Math 的常用数学/统计函数 ***org.apache.commons.math3.special –***特殊函数（Gamma，Beta） ***org.apache.commons.math3.complex -***复数 ***org.apache.commons.math3.fraction -***有理数  3. 统计、概率和随机性 3.1 统计数据 org.apache.commons.math3.stat包提供了多种统计计算工具。例如，要计算均值、标准差等，我们可以使用DescriptiveStatistics： double[] values = new double[] {65, 51 , 16, 11 , 6519, 191 ,0 , 98, 19854, 1, 32}; DescriptiveStatistics descriptiveStatistics = new DescriptiveStatistics(); for (double v : values) { descriptiveStatistics.addValue(v); } double mean = descriptiveStatistics.getMean(); double median = descriptiveStatistics.getPercentile(50); double standardDeviation = descriptiveStatistics.getStandardDeviation(); 在这个包中，我们可以找到计算协方差、相关性或执行统计测试的工具（使用TestUtils）。 3.2. 概率和分布 在核心 Java 中，*Math.random()*可用于生成随机值，但这些值均匀分布在 0 和 1 之间。 有时，我们希望使用更复杂的分布产生随机值。为此，我们可以使用org.apache.commons.math3.distribution提供的框架。 以下是如何根据均值为 10、标准差为 3 的正态分布生成随机值： NormalDistribution normalDistribution = new NormalDistribution(10, 3); double randomValue = normalDistribution.sample(); 或者我们可以获得离散分布的值的概率P(X = x) ，或连续分布的累积概率**P(X \u0026lt;= x)。 4.分析 分析相关函数和算法可以在org.apache.commons.math3.analysis中找到。 4.1 求根 根是函数值为 0 的值。Commons-Math 包括几种求根算法的实现。 在这里，我们尝试找到v -\u0026gt; (v * v) – 2的根： UnivariateFunction function = v -\u0026gt; Math.pow(v, 2) - 2; UnivariateSolver solver = new BracketingNthOrderBrentSolver(1.0e-12, 1.0e-8, 5); double c = solver.solve(100, function, -10.0, 10.0, 0); 首先，我们从定义函数开始，然后定义求解器，并设置所需的精度。最后，我们调用solve() API。 寻根操作将使用多次迭代执行，因此需要在执行时间和准确性之间找到一个折衷方案。 4.2. 计算积分 集成几乎就像根查找一样工作： UnivariateFunction function = v -\u0026gt; v; UnivariateIntegrator integrator = new SimpsonIntegrator(1.0e-12, 1.0e-8, 1, 32); double i = integrator.integrate(100, function, 0, 10); 我们首先定义一个函数，在现有的可用集成解决方案中选择一个集成器，我们设置所需的精度，最后进行集成。 5. 线性代数 如果我们有一个 AX = B 形式的线性方程组，其中 A 是实数矩阵，B 是实数向量 – Commons Math 提供了表示矩阵和向量的结构，还提供了求解器来找到X 的值： RealMatrix a = new Array2DRowRealMatrix( new double[][] { { 2, 3, -2 }, { -1, 7, 6 }, { 4, -3, -5 } }, false); RealVector b = new ArrayRealVector(n ew double[] { 1, -2, 1 }, false); DecompositionSolver solver = new LUDecomposition(a).getSolver(); RealVector solution = solver.solve(b); 这个例子非常简单：我们从一个双精度数组定义一个矩阵a，从一个向量数组定义一个向量b。 然后，我们创建一个LUDecomposition，它为 AX = B 形式的方程提供求解器。顾名思义，LUDecomposition依赖于LU 分解，因此仅适用于方阵。 对于其他矩阵，存在不同的求解器，通常使用最小二乘法求解方程。 6.几何 包org.apache.commons.math3.geometry提供了几个表示几何对象的类和几个操作它们的工具。重要的是要注意，这个包分为不同的子包，关于我们想要使用的几何类型： 重要的是要注意，这个包分为不同的子包，关于我们想要使用的几何类型：  ***org.apache.commons.math3.geometry.euclidean.oned -***一维欧几里得几何 org.apache.commons.math3.geometry.euclidean.twod - 2D 欧几里得几何 org.apache.commons.math3.geometry.euclidean.threed - 3D 欧几里得几何 ***org.apache.commons.math3.geometry.spherical.oned -***一维球面几何 org.apache.commons.math3.geometry.spherical.twod - 2D 球面几何  最有用的类可能是Vector2D、Vector3D、Line和Segment。它们分别用于表示 2D 矢量（或点）、3D 矢量、线和线段。 使用上述类时，可以执行一些计算。例如，以下代码执行两条二维线的交点计算： Line l1 = new Line(new Vector2D(0, 0), new Vector2D(1, 1), 0); Line l2 = new Line(new Vector2D(0, 1), new Vector2D(1, 1.5), 0); Vector2D intersection = l1.intersection(l2); 使用这些结构来获取点到线的距离，或线到另一条线的最近点（在 3D 中）也是可行的。 7. 优化、遗传算法和机器学习 Commons-Math 还为与优化和机器学习相关的更复杂任务提供了一些工具和算法。 7.1 优化 优化通常包括最小化或最大化成本函数。优化算法可以在org.apache.commons.math3.optim和org.apache.commons.math3.optimimization中找到。它包括线性和非线性优化算法。 我们可以注意到optim和optimization包中有重复的类：优化包大部分已被弃用，并将在 Commons Math 4 中删除。 7.2. 遗传算法 遗传算法是一种元启发式算法：当确定性算法太慢时，它们是为问题找到可接受解决方案的解决方案。可以在此处找到遗传算法的概述。 org.apache.commons.math3.genetics包提供了一个使用遗传算法执行计算的框架。它包含可用于表示种群和染色体的结构，以及用于执行突变、交叉和选择操作的标准算法。 以下类提供了一个很好的起点：  *GeneticAlgorithm –*遗传算法框架 *人口-*代表人口的界面 *染色体——*代表染色体的界面  7.3. 机器学习 Commons-Math 中的机器学习分为两部分：聚类和神经网络。 聚类部分包括根据距离度量的相似性在向量上放置标签。提供的聚类算法基于 K-means 算法。 神经网络部分给出了表示网络（Network）和神经元（Neuron）的类。有人可能会注意到，与最常见的神经网络框架相比，提供的功能有限，但它对于要求不高的小型应用程序仍然有用。 8. 实用程序 8.1 快速数学 FastMath是一个位于org.apache.commons.math3.util中的静态类，其工作方式与**java.lang.Math完全相同。 它的目的是提供至少与我们在java.lang.Math中可以找到的功能相同的功能，但实现速度更快。因此，当程序严重依赖数学计算时，最好将对Math.sin()的调用（例如）替换为对FastMath.sin()的调用，以提高应用程序的性能。另一方面，请注意FastMath不如java.lang.Math 准确。 8.2. 常用和特殊功能 Commons-Math 提供了java.lang.Math中未实现的标准数学函数（如阶乘）。大多数这些函数都可以在包org.apache.commons.math3.special和org.apache.commons.math3.util中找到。 例如，如果我们想计算 10 的阶乘，我们可以简单地执行以下操作： long factorial = CombinatorialUtils.factorial(10); 与算术相关的函数（gcd、lcm等）可以在ArithmeticUtils中找到，与组合相关的函数可以在CombinatorialUtils中找到。其他一些特殊功能，例如erf，可以在org.apache.commons.math3.special中访问。 8.3. 分数和复数 也可以使用 commons-math 处理更复杂的类型：分数和复数。这些结构允许我们对这种数字执行特定的计算。 然后，我们可以计算两个分数的总和并将结果显示为分数的字符串表示形式（即以“a / b”的形式）： Fraction lhs = new Fraction(1, 3); Fraction rhs = new Fraction(2, 5); Fraction sum = lhs.add(rhs); String str = new FractionFormat().format(sum); 或者，我们可以快速计算复数的幂： Complex first = new Complex(1.0, 3.0); Complex second = new Complex(2.0, 5.0); Complex power = first.pow(second); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_math/","tags":["Math"],"title":"Apache Commons Math 简介"},{"categories":["Java Collections"],"contents":"1. 简介 MapUtils是 Apache Commons Collections 项目中可用的工具之一。 简单地说，它提供了实用方法和装饰器来处理java.util.Map和java.util.SortedMap实例。 2. 设置 让我们从添加依赖项开始： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 实用方法 3.1 从数组创建Map 现在，让我们设置用于创建Map的数组： public class MapUtilsTest { private String[][] color2DArray = new String[][] { {\u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;}, {\u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;}, {\u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34;} }; private String[] color1DArray = new String[] { \u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;, \u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;, \u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34; }; private Map\u0026lt;String, String\u0026gt; colorMap; //... } 让我们看看如何从二维数组创建Map： @Test public void whenCreateMapFrom2DArray_theMapIsCreated() { this.colorMap = MapUtils.putAll( new HashMap\u0026lt;\u0026gt;(), this.color2DArray); assertThat( this.colorMap, is(aMapWithSize(this.color2DArray.length))); assertThat(this.colorMap, hasEntry(\u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34;)); } 我们也可以使用一维数组。在这种情况下，数组被视为备用索引中的键和值： @Test public void whenCreateMapFrom1DArray_theMapIsCreated() { this.colorMap = MapUtils.putAll( new HashMap\u0026lt;\u0026gt;(), this.color1DArray); assertThat( this.colorMap, is(aMapWithSize(this.color1DArray.length / 2))); assertThat(this.colorMap, hasEntry(\u0026#34;RED\u0026#34;, \u0026#34;#FF0000\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;GREEN\u0026#34;, \u0026#34;#00FF00\u0026#34;)); assertThat(this.colorMap, hasEntry(\u0026#34;BLUE\u0026#34;, \u0026#34;#0000FF\u0026#34;)); } 3.2. 打印Map的内容 很多时候，在调试或调试日志中，我们想打印整个地图： @Test public void whenVerbosePrintMap_thenMustPrintFormattedMap() { MapUtils.verbosePrint(System.out, \u0026#34;Optional Label\u0026#34;, this.colorMap); } 结果： Optional Label = { RED = #FF0000 BLUE = #0000FF GREEN = #00FF00 } 我们还可以使用*debugPrint()*额外打印值的数据类型。 3.3. 获取Value MapUtils提供了一些方法，用于以null安全的方式从给定键的映射中提取值。 例如，getString()从Map中获取一个String。String值是通过toString()获得的。如果值为null或转换失败，我们可以选择指定要返回的默认值： @Test public void whenGetKeyNotPresent_thenMustReturnDefaultValue() { String defaultColorStr = \u0026#34;COLOR_NOT_FOUND\u0026#34;; String color = MapUtils .getString(this.colorMap, \u0026#34;BLACK\u0026#34;, defaultColorStr); assertEquals(color, defaultColorStr); } 请注意，这些方法是null安全的，即它们可以安全地处理null map 参数： @Test public void whenGetOnNullMap_thenMustReturnDefaultValue() { String defaultColorStr = \u0026#34;COLOR_NOT_FOUND\u0026#34;; String color = MapUtils.getString(null, \u0026#34;RED\u0026#34;, defaultColorStr); assertEquals(color, defaultColorStr); } 即使地图为null ，这里的颜色也会得到COLOR_NOT_FOUND的值。 3.4. 反转Map 我们还可以轻松地反转地图： @Test public void whenInvertMap_thenMustReturnInvertedMap() { Map\u0026lt;String, String\u0026gt; invColorMap = MapUtils.invertMap(this.colorMap); int size = invColorMap.size(); Assertions.assertThat(invColorMap) .hasSameSizeAs(colorMap) .containsKeys(this.colorMap.values().toArray(new String[] {})) .containsValues(this.colorMap.keySet().toArray(new String[] {})); } 这会将colorMap反转为： { #00FF00 = GREEN #FF0000 = RED #0000FF = BLUE } 如果源映射为多个键关联相同的值，则在反转后，其中一个值将随机成为键。 3.5. 空和空检查 如果Map为null或为空，isEmpty()方法返回true 。 safeAddToMap()方法防止向Map 添加空元素。 4. 装饰器 这些方法为地图添加了额外的功能。 在大多数情况下，最好不要存储对装饰 Map 的引用*。* 4.1 固定大小的Map *fixedSizeMap()*返回由给定地图支持的固定大小地图。元素可以更改，但不能添加或删除： @Test(expected = IllegalArgumentException.class) public void whenCreateFixedSizedMapAndAdd_thenMustThrowException() { Map\u0026lt;String, String\u0026gt; rgbMap = MapUtils .fixedSizeMap(MapUtils.putAll(new HashMap\u0026lt;\u0026gt;(), this.color1DArray)); rgbMap.put(\u0026#34;ORANGE\u0026#34;, \u0026#34;#FFA500\u0026#34;); } 4.2. 预测Map predicatedMap()方法返回一个Map确保所有持有的元素与提供的谓词匹配： @Test(expected = IllegalArgumentException.class) public void whenAddDuplicate_thenThrowException() { Map\u0026lt;String, String\u0026gt; uniqValuesMap = MapUtils.predicatedMap(this.colorMap, null, PredicateUtils.uniquePredicate()); uniqValuesMap.put(\u0026#34;NEW_RED\u0026#34;, \u0026#34;#FF0000\u0026#34;); } *在这里，我们使用PredicateUtils.uniquePredicate()为值指定谓词。任何将重复值插入此映射的尝试都将导致java.lang。*非法参数异常。 我们可以通过实现Predicate接口来实现自定义谓词。 4.3. lazyMap *lazyMap()*返回一个映射，其中值在请求时被初始化。 如果传递给此映射的Map.get(Object)方法的键在映射中不存在，则Transformer实例将用于创建将与请求的键关联的新对象： @Test public void whenCreateLazyMap_theMapIsCreated() { Map\u0026lt;Integer, String\u0026gt; intStrMap = MapUtils.lazyMap( new HashMap\u0026lt;\u0026gt;(), TransformerUtils.stringValueTransformer()); assertThat(intStrMap, is(anEmptyMap())); intStrMap.get(1); intStrMap.get(2); intStrMap.get(3); assertThat(intStrMap, is(aMapWithSize(3))); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_map_utils/","tags":["Java Map"],"title":"Apache Commons Collections MapUtils"},{"categories":["Java"],"contents":"1. 概述 创建 Apache Commons 项目的目的是为开发人员提供一组可以在日常代码中使用的通用库。 在本教程中，我们将探索 Commons IO 模块的一些关键实用程序类及其最著名的功能。 ** 2.Maven依赖** 要使用该库，让我们在pom.xml中包含以下 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-io\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-io\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 该库的最新版本可以在Maven Central中找到。 3. 实用程序类 简单地说，实用程序类提供了一组静态方法，可用于对文件执行常见任务。 **3.1 FileUtils ** 该类提供了对文件的不同操作，例如打开、读取、复制和移动。 让我们看看如何使用FileUtils读取或复制文件： File file = FileUtils.getFile(getClass().getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath()); File tempDir = FileUtils.getTempDirectory(); FileUtils.copyFileToDirectory(file, tempDir); File newTempFile = FileUtils.getFile(tempDir, file.getName()); String data = FileUtils.readFileToString(newTempFile, Charset.defaultCharset()); 3.2. FilenameUtils 此实用程序提供了一种与操作系统无关的方法来对文件名执行常用功能。让我们看看我们可以使用的一些不同的方法： String fullPath = FilenameUtils.getFullPath(path); String extension = FilenameUtils.getExtension(path); String baseName = FilenameUtils.getBaseName(path); 3.3. FileSystemUtils 我们可以使用FileSystemUtils来检查给定卷或驱动器上的可用空间： long freeSpace = FileSystemUtils.freeSpaceKb(\u0026#34;/\u0026#34;); 4.输入输出 这个包提供了几种处理输入和输出流的实现。 我们将专注于TeeInputStream和TeeOutputSteam。单词“ Tee ”（源自字母“ T ”）通常用于描述将单个输入拆分为两个不同的输出。 让我们看一个示例，该示例演示了如何将单个输入流写入两个不同的输出流： String str = \u0026#34;Hello World.\u0026#34;; ByteArrayInputStream inputStream = new ByteArrayInputStream(str.getBytes()); ByteArrayOutputStream outputStream1 = new ByteArrayOutputStream(); ByteArrayOutputStream outputStream2 = new ByteArrayOutputStream(); FilterOutputStream teeOutputStream = new TeeOutputStream(outputStream1, outputStream2); new TeeInputStream(inputStream, teeOutputStream, true) .read(new byte[str.length()]); assertEquals(str, String.valueOf(outputStream1)); assertEquals(str, String.valueOf(outputStream2)); 5. 过滤器  Commons IO 包含一个有用的文件过滤器列表。当开发人员想要从异构文件列表中缩小到特定的所需文件列表时，这些可以派上用场。 该库还支持对给定文件列表的AND和OR逻辑运算。因此，我们可以混合和匹配这些过滤器以获得所需的结果。 让我们看一个使用WildcardFileFilter和SuffixFileFilter检索名称中带有“ ple ”且后缀为“ txt ”的文件的示例。请注意，我们使用ANDFileFilter包装上述过滤器： @Test public void whenGetFilewith_ANDFileFilter_thenFind_sample_txt() throws IOException { String path = getClass().getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath(); File dir = FileUtils.getFile(FilenameUtils.getFullPath(path)); assertEquals(\u0026#34;sample.txt\u0026#34;, dir.list(new AndFileFilter( new WildcardFileFilter(\u0026#34;*ple*\u0026#34;, IOCase.INSENSITIVE), new SuffixFileFilter(\u0026#34;txt\u0026#34;)))[0]); } 6. Comparator  Comparator包提供了不同类型的文件比较。我们将在这里探讨两种不同的比较器。 6.1 PathFileComparator PathFileComparator类可用于以区分大小写、不区分大小写或系统相关的区分大小写的方式**按路径对文件列表或数组进行排序。**让我们看看如何使用此实用程序对资源目录中的文件路径进行排序： @Test public void whenSortDirWithPathFileComparator_thenFirstFile_aaatxt() throws IOException { PathFileComparator pathFileComparator = new PathFileComparator( IOCase.INSENSITIVE); String path = FilenameUtils.getFullPath(getClass() .getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath()); File dir = new File(path); File[] files = dir.listFiles(); pathFileComparator.sort(files); assertEquals(\u0026#34;aaa.txt\u0026#34;, files[0].getName()); } 请注意，我们使用了IOCase.INSENSITIVE配置。PathFileComparator还提供了许多具有不同区分大小写和反向排序选项的单例实例。 这些静态字段包括PATH_COMPARATOR、PATH_INSENSITIVE_COMPARATOR、PATH_INSENSITIVE_REVERSE、PATH_SYSTEM_COMPARATOR等等。 6.2. SizeFileComparator SizeFileComparator，顾名思义，是用来比较两个文件的大小（长度）的。如果第一个文件的大小小于第二个文件的大小，则返回一个负整数值。如果文件大小相等，则返回零，如果第一个文件的大小大于第二个文件的大小，则返回正值。 让我们编写一个单元测试来演示文件大小的比较： @Test public void whenSizeFileComparator_thenLargerFile_large() throws IOException { SizeFileComparator sizeFileComparator = new SizeFileComparator(); File largerFile = FileUtils.getFile(getClass().getClassLoader() .getResource(\u0026#34;fileTest.txt\u0026#34;) .getPath()); File smallerFile = FileUtils.getFile(getClass().getClassLoader() .getResource(\u0026#34;sample.txt\u0026#34;) .getPath()); int i = sizeFileComparator.compare(largerFile, smallerFile); Assert.assertTrue(i \u0026gt; 0); } 7. 文件监视器 Commons IO 监视器包提供了跟踪文件或目录更改的能力。让我们看一个快速示例，说明如何将FileAlterationMonitor与**FileAlterationObserver和FileAlterationListener一起使用来监视文件或文件夹。 当FileAlterationMonitor启动时，我们将开始接收有关正在监视的目录上的文件更改的通知*：* FileAlterationObserver observer = new FileAlterationObserver(folder); FileAlterationMonitor monitor = new FileAlterationMonitor(5000); FileAlterationListener fal = new FileAlterationListenerAdaptor() { @Override public void onFileCreate(File file) { // on create action  } @Override public void onFileDelete(File file) { // on delete action  } }; observer.addListener(fal); monitor.addObserver(observer); monitor.start(); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_io/","tags":["Java IO"],"title":"Apache Commons IO"},{"categories":["Algorithms"],"contents":"1. 概述 在本教程中，我们将了解如何借助 Apache Commons Frequency类在直方图上呈现数据。 Frequency 类是本文探讨的 Apache Commons Math 库的一部分。 直方图是连接条形图，显示数据集中一系列数据的出现。它与条形图的不同之处在于它用于显示连续的定量变量的分布，而条形图用于显示分类数据。 2.项目依赖 在本文中，我们将使用具有以下依赖项的 Maven 项目： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-math3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.knowm.xchart\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xchart\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; commons-math3库包含 我们将用来确定数据集中变量出现的 *频率 类。*我们将使用 xchart 库在 GUI 中显示直方图 。 最新版本的commons-math3和xchart 可以在 Maven Central 上找到。 3. 计算变量的频率 在本教程中，我们将使用包含特定学校学生年龄的数据集。我们希望看到不同年龄组的频率并在直方图上观察它们的分布。 让我们用 List集合来表示数据集，并使用它来填充 Frequency类的实例： List\u0026lt;Integer\u0026gt; datasetList = Arrays.asList( 36, 25, 38, 46, 55, 68, 72, 55, 36, 38, 67, 45, 22, 48, 91, 46, 52, 61, 58, 55); Frequency frequency = new Frequency(); datasetList.forEach(d -\u0026gt; frequency.addValue(Double.parseDouble(d.toString()))); 现在我们已经填充了 Frequency类的实例，我们将获取 bin 中每个年龄的计数并将其相加，以便我们可以获得特定年龄组中年龄的总频率： datasetList.stream() .map(d -\u0026gt; Double.parseDouble(d.toString())) .distinct() .forEach(observation -\u0026gt; { long observationFrequency = frequency.getCount(observation); int upperBoundary = (observation \u0026gt; classWidth) ? Math.multiplyExact( (int) Math.ceil(observation / classWidth), classWidth) : classWidth; int lowerBoundary = (upperBoundary \u0026gt; classWidth) ? Math.subtractExact(upperBoundary, classWidth) : 0; String bin = lowerBoundary + \u0026#34;-\u0026#34; + upperBoundary; updateDistributionMap(lowerBoundary, bin, observationFrequency); }); 从上面的代码片段中，我们首先 使用 Frequency类的getCount()确定观察的 频率。该方法返回观察的发生总数*。* 使用当前观察，我们通过计算其相对于类宽度的上下边界（即 10 ）来动态确定它所属的组。 上下边界连接起来形成一个 bin， 使用updateDistributionMap()将其与**观察频率一起存储在distributionMap中。 如果 bin已经存在，我们更新频率，否则我们将其添加为键并将当前观察的频率设置为其值。请注意，我们会跟踪处理后的观察结果以避免重复。 频率类还具有确定数据集中变量的百分比和累积百分比的方法。 4. 绘制直方图 现在我们已经将原始数据集处理为年龄组及其各自频率的地图，我们可以使用 xchart库在直方图中显示数据： CategoryChart chart = new CategoryChartBuilder().width(800).height(600) .title(\u0026#34;Age Distribution\u0026#34;) .xAxisTitle(\u0026#34;Age Group\u0026#34;) .yAxisTitle(\u0026#34;Frequency\u0026#34;) .build(); chart.getStyler().setLegendPosition(Styler.LegendPosition.InsideNW); chart.getStyler().setAvailableSpaceFill(0.99); chart.getStyler().setOverlapped(true); List yData = new ArrayList(); yData.addAll(distributionMap.values()); List xData = Arrays.asList(distributionMap.keySet().toArray()); chart.addSeries(\u0026#34;age group\u0026#34;, xData, yData); new SwingWrapper\u0026lt;\u0026gt;(chart).displayChart(); 我们使用图表构建器创建了一个 CategoryChart实例，然后我们对其进行配置并使用 x 和 y 轴的数据填充它。 最后，我们使用SwingWrapper在 GUI 中显示图表 ： 从上面的直方图可以看出，80-90 岁的学生没有，而 50-60 岁的学生占主导地位。这很可能是博士生或博士后。 我们也可以说直方图具有正态分布。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_frequency/","tags":[],"title":"Apache Commons Frequency"},{"categories":["Persistence"],"contents":"1. 概述 Apache Commons DbUtils 是一个小型库，它使使用 JDBC 变得更加容易。 在本文中，我们将实施示例来展示其特性和功能。 2. 设置 2.1 Maven 依赖项 首先，我们需要将commons-dbutils和h2依赖添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-dbutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-dbutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.196\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 你可以在 Maven Central 上找到最新版本的commons-dbutils和h2 。 2.2. 测试数据库 有了我们的依赖关系，让我们创建一个脚本来创建我们将使用的表和记录： CREATETABLEemployee(idintNOTNULLPRIMARYKEYauto_increment,firstnamevarchar(255),lastnamevarchar(255),salarydouble,hireddatedate,);CREATETABLEemail(idintNOTNULLPRIMARYKEYauto_increment,employeeidint,addressvarchar(255));INSERTINTOemployee(firstname,lastname,salary,hireddate)VALUES(\u0026#39;John\u0026#39;,\u0026#39;Doe\u0026#39;,10000.10,to_date(\u0026#39;01-01-2001\u0026#39;,\u0026#39;dd-mm-yyyy\u0026#39;));//...INSERTINTOemail(employeeid,address)VALUES(1,\u0026#39;[[email protected]](cdn-cgi/l/email-protection)\u0026#39;);//...本文中的所有示例测试用例都将使用新创建的与 H2 内存数据库的连接： public class DbUtilsUnitTest { private Connection connection; @Before public void setupDB() throws Exception { Class.forName(\u0026#34;org.h2.Driver\u0026#34;); String db = \u0026#34;jdbc:h2:mem:;INIT=runscript from \u0026#39;classpath:/employees.sql\u0026#39;\u0026#34;; connection = DriverManager.getConnection(db); } @After public void closeBD() { DbUtils.closeQuietly(connection); } // ... } 2.3. POJO 最后，我们需要两个简单的类： public class Employee { private Integer id; private String firstName; private String lastName; private Double salary; private Date hiredDate; // standard constructors, getters, and setters } public class Email { private Integer id; private Integer employeeId; private String address; // standard constructors, getters, and setters } 3. 简介 DbUtils 库提供QueryRunner类作为大多数可用功能的主要入口点。 此类通过接收到数据库的连接、要执行的 SQL 语句以及为查询的占位符提供值的可选参数列表来工作。 正如我们稍后将看到的，一些方法还接收一个ResultSetHandler实现——它负责将ResultSet实例转换为我们的应用程序期望的对象。 \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; 当然，该库已经提供了几种处理最常见转换的实现，例如列表、映射和 JavaBean。 4. 查询数据 现在我们知道了基础知识，我们已经准备好查询我们的数据库了。 让我们从一个使用MapListHandler获取数据库中所有记录作为地图列表的快速示例开始： @Test public void givenResultHandler_whenExecutingQuery_thenExpectedList() throws SQLException { MapListHandler beanListHandler = new MapListHandler(); QueryRunner runner = new QueryRunner(); List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; list = runner.query(connection, \u0026#34;SELECT * FROM employee\u0026#34;, beanListHandler); assertEquals(list.size(), 5); assertEquals(list.get(0).get(\u0026#34;firstname\u0026#34;), \u0026#34;John\u0026#34;); assertEquals(list.get(4).get(\u0026#34;firstname\u0026#34;), \u0026#34;Christian\u0026#34;); } 接下来，这是一个使用BeanListHandler将结果转换为Employee实例的示例： @Test public void givenResultHandler_whenExecutingQuery_thenEmployeeList() throws SQLException { BeanListHandler\u0026lt;Employee\u0026gt; beanListHandler = new BeanListHandler\u0026lt;\u0026gt;(Employee.class); QueryRunner runner = new QueryRunner(); List\u0026lt;Employee\u0026gt; employeeList = runner.query(connection, \u0026#34;SELECT * FROM employee\u0026#34;, beanListHandler); assertEquals(employeeList.size(), 5); assertEquals(employeeList.get(0).getFirstName(), \u0026#34;John\u0026#34;); assertEquals(employeeList.get(4).getFirstName(), \u0026#34;Christian\u0026#34;); } 对于返回单个值的查询，我们可以使用ScalarHandler： @Test public void givenResultHandler_whenExecutingQuery_thenExpectedScalar() throws SQLException { ScalarHandler\u0026lt;Long\u0026gt; scalarHandler = new ScalarHandler\u0026lt;\u0026gt;(); QueryRunner runner = new QueryRunner(); String query = \u0026#34;SELECT COUNT(*) FROM employee\u0026#34;; long count = runner.query(connection, query, scalarHandler); assertEquals(count, 5); } 要了解所有ResultSerHandler实现，可以参考ResultSetHandler文档。 4.1 自定义处理程序 当我们需要更多地控制如何将结果转换为对象时，我们还可以创建一个自定义处理程序以传递给QueryRunner的方法。 这可以通过实现ResultSetHandler接口或扩展库提供的现有实现之一来完成。 让我们看看第二种方法的外观。首先，让我们在Employee类中添加另一个字段： public class Employee { private List\u0026lt;Email\u0026gt; emails; // ... } 现在，让我们创建一个扩展BeanListHandler类型并为每个员工设置电子邮件列表的类： public class EmployeeHandler extends BeanListHandler\u0026lt;Employee\u0026gt; { private Connection connection; public EmployeeHandler(Connection con) { super(Employee.class); this.connection = con; } @Override public List\u0026lt;Employee\u0026gt; handle(ResultSet rs) throws SQLException { List\u0026lt;Employee\u0026gt; employees = super.handle(rs); QueryRunner runner = new QueryRunner(); BeanListHandler\u0026lt;Email\u0026gt; handler = new BeanListHandler\u0026lt;\u0026gt;(Email.class); String query = \u0026#34;SELECT * FROM email WHERE employeeid = ?\u0026#34;; for (Employee employee : employees) { List\u0026lt;Email\u0026gt; emails = runner.query(connection, query, handler, employee.getId()); employee.setEmails(emails); } return employees; } } 请注意，我们期望构造函数中有一个Connection对象，以便我们可以执行查询以获取电子邮件。 最后，让我们测试一下我们的代码，看看是否一切都按预期工作： @Test public void givenResultHandler_whenExecutingQuery_thenEmailsSetted() throws SQLException { EmployeeHandler employeeHandler = new EmployeeHandler(connection); QueryRunner runner = new QueryRunner(); List\u0026lt;Employee\u0026gt; employees = runner.query(connection, \u0026#34;SELECT * FROM employee\u0026#34;, employeeHandler); assertEquals(employees.get(0).getEmails().size(), 2); assertEquals(employees.get(2).getEmails().size(), 3); } 4.2. 自定义行处理器 在我们的示例中，employee表的列名与Employee类的字段名匹配（匹配不区分大小写）。然而，情况并非总是如此——例如当列名使用下划线来分隔复合词时。 在这些情况下，我们可以利用RowProcessor接口及其实现将列名映射到我们类中的适当字段。 让我们看看这是什么样子。首先，让我们创建另一个表并在其中插入一些记录： CREATETABLEemployee_legacy(idintNOTNULLPRIMARYKEYauto_increment,first_namevarchar(255),last_namevarchar(255),salarydouble,hired_datedate,);INSERTINTOemployee_legacy(first_name,last_name,salary,hired_date)VALUES(\u0026#39;John\u0026#39;,\u0026#39;Doe\u0026#39;,10000.10,to_date(\u0026#39;01-01-2001\u0026#39;,\u0026#39;dd-mm-yyyy\u0026#39;));//...现在，让我们修改我们的EmployeeHandler类： public class EmployeeHandler extends BeanListHandler\u0026lt;Employee\u0026gt; { // ...  public EmployeeHandler(Connection con) { super(Employee.class, new BasicRowProcessor(new BeanProcessor(getColumnsToFieldsMap()))); // ...  } public static Map\u0026lt;String, String\u0026gt; getColumnsToFieldsMap() { Map\u0026lt;String, String\u0026gt; columnsToFieldsMap = new HashMap\u0026lt;\u0026gt;(); columnsToFieldsMap.put(\u0026#34;FIRST_NAME\u0026#34;, \u0026#34;firstName\u0026#34;); columnsToFieldsMap.put(\u0026#34;LAST_NAME\u0026#34;, \u0026#34;lastName\u0026#34;); columnsToFieldsMap.put(\u0026#34;HIRED_DATE\u0026#34;, \u0026#34;hiredDate\u0026#34;); return columnsToFieldsMap; } // ... } 请注意，我们正在使用BeanProcessor进行列到字段的实际映射，并且仅用于需要处理的那些。 最后，让我们测试一切是否正常： @Test public void givenResultHandler_whenExecutingQuery_thenAllPropertiesSetted() throws SQLException { EmployeeHandler employeeHandler = new EmployeeHandler(connection); QueryRunner runner = new QueryRunner(); String query = \u0026#34;SELECT * FROM employee_legacy\u0026#34;; List\u0026lt;Employee\u0026gt; employees = runner.query(connection, query, employeeHandler); assertEquals((int) employees.get(0).getId(), 1); assertEquals(employees.get(0).getFirstName(), \u0026#34;John\u0026#34;); } 5. 插入记录 QueryRunner类提供了两种在数据库中创建记录的方法*。* 第一个是使用*update()*方法并传递 SQL 语句和可选的替换参数列表。该方法返回插入的记录数： @Test public void whenInserting_thenInserted() throws SQLException { QueryRunner runner = new QueryRunner(); String insertSQL = \u0026#34;INSERT INTO employee (firstname,lastname,salary, hireddate) \u0026#34; + \u0026#34;VALUES (?, ?, ?, ?)\u0026#34;; int numRowsInserted = runner.update( connection, insertSQL, \u0026#34;Leia\u0026#34;, \u0026#34;Kane\u0026#34;, 60000.60, new Date()); assertEquals(numRowsInserted, 1); } 第二种是使用insert()方法，除了 SQL 语句和替换参数之外，还需要一个ResultSetHandler来转换生成的自动生成的键。返回值将是处理程序返回的内容： @Test public void givenHandler_whenInserting_thenExpectedId() throws SQLException { ScalarHandler\u0026lt;Integer\u0026gt; scalarHandler = new ScalarHandler\u0026lt;\u0026gt;(); QueryRunner runner = new QueryRunner(); String insertSQL = \u0026#34;INSERT INTO employee (firstname,lastname,salary, hireddate) \u0026#34; + \u0026#34;VALUES (?, ?, ?, ?)\u0026#34;; int newId = runner.insert( connection, insertSQL, scalarHandler, \u0026#34;Jenny\u0026#34;, \u0026#34;Medici\u0026#34;, 60000.60, new Date()); assertEquals(newId, 6); } 6. 更新和删除 QueryRunner类的*update()*方法也可用于修改和删除数据库中的记录。 它的用法是微不足道的。以下是如何更新员工工资的示例： @Test public void givenSalary_whenUpdating_thenUpdated() throws SQLException { double salary = 35000; QueryRunner runner = new QueryRunner(); String updateSQL = \u0026#34;UPDATE employee SET salary = salary * 1.1 WHERE salary \u0026lt;= ?\u0026#34;; int numRowsUpdated = runner.update(connection, updateSQL, salary); assertEquals(numRowsUpdated, 3); } 这是另一个删除具有给定 id 的员工的方法： @Test public void whenDeletingRecord_thenDeleted() throws SQLException { QueryRunner runner = new QueryRunner(); String deleteSQL = \u0026#34;DELETE FROM employee WHERE id = ?\u0026#34;; int numRowsDeleted = runner.update(connection, deleteSQL, 3); assertEquals(numRowsDeleted, 1); } 7. 异步操作 DbUtils 提供了AsyncQueryRunner类来异步执行操作。该类的方法与QueryRunner类的方法有对应关系，只是它们返回一个Future实例。 下面是一个获取数据库中所有员工的示例，最多等待 10 秒才能得到结果： @Test public void givenAsyncRunner_whenExecutingQuery_thenExpectedList() throws Exception { AsyncQueryRunner runner = new AsyncQueryRunner(Executors.newCachedThreadPool()); EmployeeHandler employeeHandler = new EmployeeHandler(connection); String query = \u0026#34;SELECT * FROM employee\u0026#34;; Future\u0026lt;List\u0026lt;Employee\u0026gt;\u0026gt; future = runner.query(connection, query, employeeHandler); List\u0026lt;Employee\u0026gt; employeeList = future.get(10, TimeUnit.SECONDS); assertEquals(employeeList.size(), 5); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_dbutils/","tags":[],"title":"Apache Commons DbUtils 指南"},{"categories":["Data"],"contents":"1. 概述 Apache Commons CSV 库具有许多用于创建和读取 CSV 文件的有用功能。 在这个快速教程中，我们将通过一个简单的例子来了解如何使用这个库。 2.Maven依赖 首先，我们将使用 Maven 导入该库的最新版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-csv\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查这个库的最新版本——去这里。 3. 读取 CSV 文件 考虑以下名为 book.csv 的 CSV 文件，其中包含一本书的属性： author,title Dan Simmons,Hyperion Douglas Adams,The Hitchhiker\u0026#39;s Guide to the Galaxy 让我们看看如何阅读它： Map\u0026lt;String, String\u0026gt; AUTHOR_BOOK_MAP = new HashMap\u0026lt;\u0026gt;() { { put(\u0026#34;Dan Simmons\u0026#34;, \u0026#34;Hyperion\u0026#34;); put(\u0026#34;Douglas Adams\u0026#34;, \u0026#34;The Hitchhiker\u0026#39;s Guide to the Galaxy\u0026#34;); } }); String[] HEADERS = { \u0026#34;author\u0026#34;, \u0026#34;title\u0026#34;}; @Test public void givenCSVFile_whenRead_thenContentsAsExpected() throws IOException { Reader in = new FileReader(\u0026#34;book.csv\u0026#34;); Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withHeader(HEADERS) .withFirstRecordAsHeader() .parse(in); for (CSVRecord record : records) { String author = record.get(\u0026#34;author\u0026#34;); String title = record.get(\u0026#34;title\u0026#34;); assertEquals(AUTHOR_BOOK_MAP.get(author), title); } } 我们在跳过第一行后读取 CSV 文件的记录，因为它是标题。 有不同类型的CSVFormat指定 CSV 文件的格式，您可以在下一段中看到一个示例。 4. 创建 CSV 文件 让我们看看如何创建与上面相同的 CSV 文件： public void createCSVFile() throws IOException { FileWriter out = new FileWriter(\u0026#34;book_new.csv\u0026#34;); try (CSVPrinter printer = new CSVPrinter(out, CSVFormat.DEFAULT .withHeader(HEADERS))) { AUTHOR_BOOK_MAP.forEach((author, title) -\u0026gt; { printer.printRecord(author, title); }); } } 将使用适当的标题创建新的 CSV 文件，因为我们已经在CSVFormat声明中指定了它们。 5. 标题和阅读栏 有不同的方法来读取和写入标头。同样，读取列值也有不同的方法。 让我们一一介绍： 5.1 按索引访问列 这是读取列值的最基本方法。当 CSV 文件的标题未知时，可以使用此方法： Reader in = new FileReader(\u0026#34;book.csv\u0026#34;); Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT.parse(in); for (CSVRecord record : records) { String columnOne = record.get(0); String columnTwo = record.get(1); } 5.2. 通过预定义的标题访问列 与通过索引访问相比，这是一种更直观的访问列的方式： Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withHeader(\u0026#34;author\u0026#34;, \u0026#34;title\u0026#34;).parse(in); for (CSVRecord record : records) { String author = record.get(\u0026#34;author\u0026#34;); String title = record.get(\u0026#34;title\u0026#34;); } 5.3. 使用枚举作为标题 使用字符串访问列值可能容易出错。使用 Enums 而不是 Strings 将使代码更加标准化和易于理解： enum BookHeaders { author, title } Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withHeader(BookHeaders.class).parse(in); for (CSVRecord record : records) { String author = record.get(BookHeaders.author); String title = record.get(BookHeaders.title); } 5.4. 跳过标题行 通常，CSV 文件在第一行包含标题。因此，在大多数情况下，跳过它并从第二行开始读取是安全的。 这将自动检测标题访问列值： Iterable\u0026lt;CSVRecord\u0026gt; records = CSVFormat.DEFAULT .withFirstRowAsHeader().parse(in); for (CSVRecord record : records) { String author = record.get(\u0026#34;author\u0026#34;); String title = record.get(\u0026#34;title\u0026#34;); } 5.5. 创建带有标题的文件 同样，我们可以创建一个 CSV 文件，其中第一行包含标题： FileWriter out = new FileWriter(\u0026#34;book_new.csv\u0026#34;); CSVPrinter printer = CSVFormat.DEFAULT .withHeader(\u0026#34;author\u0026#34;, \u0026#34;title\u0026#34;).print(out); \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_csv/","tags":[],"title":"Apache Commons CSV 简介"},{"categories":["Guava","Java Collections"],"contents":"1. 概述 在本教程中，我们将比较两个基于 Java 的开源库：Apache Commons和Google Guava。这两个库都具有丰富的功能集，其中包含大量实用程序 API，主要位于集合和 I/O 领域。 为简洁起见，这里我们将仅描述集合框架中最常用的几个以及代码示例。我们还将看到它们之间差异的摘要。 2. 两个的简史 Google Guava 是 Google 的一个项目，主要由该组织的工程师开发，虽然现在已经开源。启动它的主要动机是将 JDK 1.5 中引入的泛型包含到 Java Collections Framework或JCF中，并增强其功能。 自成立以来，该库已扩展其功能，现在包括图形、函数式编程、范围对象、缓存和字符串操作。 Apache Commons 最初是作为 Jakarta 项目的一个补充核心 Java 集合 API 的项目，最终成为 Apache 软件基金会的一个项目。多年来，它已扩展到其他各个领域的大量可重用 Java 组件，包括（但不限于）成像、I/O、密码学、缓存、网络、验证和对象池。 由于这是一个开源项目，来自 Apache 社区的开发人员不断添加到该库以扩展其功能。但是，他们非常注意保持向后兼容性。 3. Maven依赖 要包含 Guava，我们需要将其依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;31.0.1-jre\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 它的最新版本信息可以在Maven上找到。 对于 Apache Commons，它有点不同。根据我们要使用的实用程序，我们必须添加那个特定的。例如，对于集合，我们需要添加： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在我们的代码示例中，我们将使用commons-collections4。 现在让我们进入有趣的部分吧！ 4. 双向Map 可以通过键和值访问的映射称为双向映射。JCF 没有此功能。 让我们看看我们的两种技术如何提供它们。在这两种情况下，我们都会以一周中的几天为例来获取给定日期的日期名称，反之亦然。 4.1 Guava 的BiMap Guava 提供了一个接口 - BiMap，作为双向地图。它可以使用其实现之一 EnumBiMap、EnumHashBiMap、HashBiMap或ImmutableBiMap来实例化。 这里我们使用HashBiMap： BiMap\u0026lt;Integer, String\u0026gt; daysOfWeek = HashBiMap.create(); 填充它类似于 Java 中的任何地图： daysOfWeek.put(1, \u0026#34;Monday\u0026#34;); daysOfWeek.put(2, \u0026#34;Tuesday\u0026#34;); daysOfWeek.put(3, \u0026#34;Wednesday\u0026#34;); daysOfWeek.put(4, \u0026#34;Thursday\u0026#34;); daysOfWeek.put(5, \u0026#34;Friday\u0026#34;); daysOfWeek.put(6, \u0026#34;Saturday\u0026#34;); daysOfWeek.put(7, \u0026#34;Sunday\u0026#34;); 这里有一些 JUnit 测试来证明这个概念： @Test public void givenBiMap_whenValue_thenKeyReturned() { assertEquals(Integer.valueOf(7), daysOfWeek.inverse().get(\u0026#34;Sunday\u0026#34;)); } @Test public void givenBiMap_whenKey_thenValueReturned() { assertEquals(\u0026#34;Tuesday\u0026#34;, daysOfWeek.get(2)); } 4.2. Apache 的BidiMap 同样，Apache 为我们提供了它的BidiMap接口： BidiMap\u0026lt;Integer, String\u0026gt; daysOfWeek = new TreeBidiMap\u0026lt;Integer, String\u0026gt;(); 这里我们使用TreeBidiMap。但是，还有其他实现，例如DualHashBidiMap和DualTreeBidiMap。 要填充它，我们可以像上面对 BiMap所做的那样放置值。 它的用法也很相似： @Test public void givenBidiMap_whenValue_thenKeyReturned() { assertEquals(Integer.valueOf(7), daysOfWeek.inverseBidiMap().get(\u0026#34;Sunday\u0026#34;)); } @Test public void givenBidiMap_whenKey_thenValueReturned() { assertEquals(\u0026#34;Tuesday\u0026#34;, daysOfWeek.get(2)); } 在一些简单的性能测试中，这个双向映射仅在插入方面落后于Guava 对应映射。获取键和值要快得多。 5. 将键映射到多个值 对于我们想要将多个键映射到不同值的用例，例如水果和蔬菜的购物车集合，这两个库为我们提供了独特的解决方案。 5.1 Guava 的MultiMap 首先，让我们看看如何实例化和初始化MultiMap： Multimap\u0026lt;String, String\u0026gt; groceryCart = ArrayListMultimap.create(); groceryCart.put(\u0026#34;Fruits\u0026#34;, \u0026#34;Apple\u0026#34;); groceryCart.put(\u0026#34;Fruits\u0026#34;, \u0026#34;Grapes\u0026#34;); groceryCart.put(\u0026#34;Fruits\u0026#34;, \u0026#34;Strawberries\u0026#34;); groceryCart.put(\u0026#34;Vegetables\u0026#34;, \u0026#34;Spinach\u0026#34;); groceryCart.put(\u0026#34;Vegetables\u0026#34;, \u0026#34;Cabbage\u0026#34;); 然后，我们将使用几个 JUnit 测试来查看它的实际效果： @Test public void givenMultiValuedMap_whenFruitsFetched_thenFruitsReturned() { List\u0026lt;String\u0026gt; fruits = Arrays.asList(\u0026#34;Apple\u0026#34;, \u0026#34;Grapes\u0026#34;, \u0026#34;Strawberries\u0026#34;); assertEquals(fruits, groceryCart.get(\u0026#34;Fruits\u0026#34;)); } @Test public void givenMultiValuedMap_whenVeggiesFetched_thenVeggiesReturned() { List\u0026lt;String\u0026gt; veggies = Arrays.asList(\u0026#34;Spinach\u0026#34;, \u0026#34;Cabbage\u0026#34;); assertEquals(veggies, groceryCart.get(\u0026#34;Vegetables\u0026#34;)); } 此外，MultiMap使我们能够从地图中删除给定条目或整组值： @Test public void givenMultiValuedMap_whenFuitsRemoved_thenVeggiesPreserved() { assertEquals(5, groceryCart.size()); groceryCart.remove(\u0026#34;Fruits\u0026#34;, \u0026#34;Apple\u0026#34;); assertEquals(4, groceryCart.size()); groceryCart.removeAll(\u0026#34;Fruits\u0026#34;); assertEquals(2, groceryCart.size()); } 如我们所见，这里我们首先从Fruits集中移除**Apple，然后移除整个Fruits集中。 5.2. Apache 的多值映射 同样，让我们​​从实例化MultiValuedMap开始： MultiValuedMap\u0026lt;String, String\u0026gt; groceryCart = new ArrayListValuedHashMap\u0026lt;\u0026gt;(); 由于填充它与我们在上一节中看到的相同，让我们快速看一下用法： @Test public void givenMultiValuedMap_whenFruitsFetched_thenFruitsReturned() { List\u0026lt;String\u0026gt; fruits = Arrays.asList(\u0026#34;Apple\u0026#34;, \u0026#34;Grapes\u0026#34;, \u0026#34;Strawberries\u0026#34;); assertEquals(fruits, groceryCart.get(\u0026#34;Fruits\u0026#34;)); } @Test public void givenMultiValuedMap_whenVeggiesFetched_thenVeggiesReturned() { List\u0026lt;String\u0026gt; veggies = Arrays.asList(\u0026#34;Spinach\u0026#34;, \u0026#34;Cabbage\u0026#34;); assertEquals(veggies, groceryCart.get(\u0026#34;Vegetables\u0026#34;)); } 我们可以看到，它的用法也是一样的！ 但是，在这种情况下，我们无法灵活地删除单个条目，例如Apple from Fruits。 我们只能删除整组Fruits： @Test public void givenMultiValuedMap_whenFuitsRemoved_thenVeggiesPreserved() { assertEquals(5, groceryCart.size()); groceryCart.remove(\u0026#34;Fruits\u0026#34;); assertEquals(2, groceryCart.size()); } 6. 将多个键映射到一个值 在这里，我们将举例说明要映射到各个城市的纬度和经度： cityCoordinates.put(\u0026#34;40.7128° N\u0026#34;, \u0026#34;74.0060° W\u0026#34;, \u0026#34;New York\u0026#34;); cityCoordinates.put(\u0026#34;48.8566° N\u0026#34;, \u0026#34;2.3522° E\u0026#34;, \u0026#34;Paris\u0026#34;); cityCoordinates.put(\u0026#34;19.0760° N\u0026#34;, \u0026#34;72.8777° E\u0026#34;, \u0026#34;Mumbai\u0026#34;); 现在，我们将看看如何实现这一目标。 6.1 Guava的Table Guava 提供了满足上述用例的Table ： Table\u0026lt;String, String, String\u0026gt; cityCoordinates = HashBasedTable.create(); 以下是我们可以从中得出的一些用法： @Test public void givenCoordinatesTable_whenFetched_thenOK() { List expectedLongitudes = Arrays.asList(\u0026#34;74.0060° W\u0026#34;, \u0026#34;2.3522° E\u0026#34;, \u0026#34;72.8777° E\u0026#34;); assertArrayEquals(expectedLongitudes.toArray(), cityCoordinates.columnKeySet().toArray()); List expectedCities = Arrays.asList(\u0026#34;New York\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;Mumbai\u0026#34;); assertArrayEquals(expectedCities.toArray(), cityCoordinates.values().toArray()); assertTrue(cityCoordinates.rowKeySet().contains(\u0026#34;48.8566° N\u0026#34;)); } 如我们所见，我们可以获得行、列和值的Set视图。 Table还为我们提供了查询其行或列的能力。 让我们考虑一个电影表来证明这一点： Table\u0026lt;String, String, String\u0026gt; movies = HashBasedTable.create(); movies.put(\u0026#34;Tom Hanks\u0026#34;, \u0026#34;Meg Ryan\u0026#34;, \u0026#34;You\u0026#39;ve Got Mail\u0026#34;); movies.put(\u0026#34;Tom Hanks\u0026#34;, \u0026#34;Catherine Zeta-Jones\u0026#34;, \u0026#34;The Terminal\u0026#34;); movies.put(\u0026#34;Bradley Cooper\u0026#34;, \u0026#34;Lady Gaga\u0026#34;, \u0026#34;A Star is Born\u0026#34;); movies.put(\u0026#34;Keenu Reaves\u0026#34;, \u0026#34;Sandra Bullock\u0026#34;, \u0026#34;Speed\u0026#34;); movies.put(\u0026#34;Tom Hanks\u0026#34;, \u0026#34;Sandra Bullock\u0026#34;, \u0026#34;Extremely Loud \u0026amp; Incredibly Close\u0026#34;); 以下是我们可以在电影 表上进行的一些示例、不言自明的搜索： @Test public void givenMoviesTable_whenFetched_thenOK() { assertEquals(3, movies.row(\u0026#34;Tom Hanks\u0026#34;).size()); assertEquals(2, movies.column(\u0026#34;Sandra Bullock\u0026#34;).size()); assertEquals(\u0026#34;A Star is Born\u0026#34;, movies.get(\u0026#34;Bradley Cooper\u0026#34;, \u0026#34;Lady Gaga\u0026#34;)); assertTrue(movies.containsValue(\u0026#34;Speed\u0026#34;)); } 但是，Table限制我们只能将两个键映射到一个值。在 Guava 中，我们还没有将两个以上的键映射到单个值的替代方法。 6.2. Apache 的 MultiKeyMap 回到我们的cityCoordinates示例，下面是我们如何使用MultiKeyMap来操作它： @Test public void givenCoordinatesMultiKeyMap_whenQueried_thenOK() { MultiKeyMap\u0026lt;String, String\u0026gt; cityCoordinates = new MultiKeyMap\u0026lt;String, String\u0026gt;(); // populate with keys and values as shown previously  List expectedLongitudes = Arrays.asList(\u0026#34;72.8777° E\u0026#34;, \u0026#34;2.3522° E\u0026#34;, \u0026#34;74.0060° W\u0026#34;); List longitudes = new ArrayList\u0026lt;\u0026gt;(); cityCoordinates.forEach((key, value) -\u0026gt; { longitudes.add(key.getKey(1)); }); assertArrayEquals(expectedLongitudes.toArray(), longitudes.toArray()); List expectedCities = Arrays.asList(\u0026#34;Mumbai\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;New York\u0026#34;); List cities = new ArrayList\u0026lt;\u0026gt;(); cityCoordinates.forEach((key, value) -\u0026gt; { cities.add(value); }); assertArrayEquals(expectedCities.toArray(), cities.toArray()); } 正如我们从上面的代码片段中看到的那样，要获得与 Guava 的Table相同的断言，我们必须遍历MultiKeyMap。 然而，** MultiKeyMap也提供了将两个以上的键映射到一个值的可能性**。例如，它使我们能够将一周中的几天映射为工作日或周末： @Test public void givenDaysMultiKeyMap_whenFetched_thenOK() { days = new MultiKeyMap\u0026lt;String, String\u0026gt;(); days.put(\u0026#34;Monday\u0026#34;, \u0026#34;Tuesday\u0026#34;, \u0026#34;Wednesday\u0026#34;, \u0026#34;Thursday\u0026#34;, \u0026#34;Friday\u0026#34;, \u0026#34;Weekday\u0026#34;); days.put(\u0026#34;Saturday\u0026#34;, \u0026#34;Sunday\u0026#34;, \u0026#34;Weekend\u0026#34;); assertFalse(days.get(\u0026#34;Saturday\u0026#34;, \u0026#34;Sunday\u0026#34;).equals(\u0026#34;Weekday\u0026#34;)); } 7. Apache Commons Collections 与 Google Guava 根据其工程师的说法，Google Guava 的诞生是出于在库中使用泛型的需要，而 Apache Commons 没有提供。它还遵循 tee 的集合 API 要求。另一个主要优势是它正在积极开发中，新版本经常发布。 但是，在从集合中获取值时，Apache 在性能方面提供了优势。不过，就插入时间而言，番石榴仍然占据优势。 尽管我们只比较了代码示例中的集合 API，但与 Guava 相比，Apache Commons 作为一个整体提供了更大范围的功能。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_collections_vs_guava/","tags":[],"title":"Apache Commons Collections 与 Google Guava"},{"categories":["Java Collections"],"contents":"1. 概述 简而言之，Apache CollectionUtils为常见操作提供了实用方法，涵盖了广泛的用例，并有助于避免编写样板代码。该库针对较旧的 JVM 版本，因为目前 Java 8 的Stream API 提供了类似的功能。 2. Maven依赖 我们需要添加以下依赖项才能使用CollectionUtils： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到该库的最新版本。 3. 设置 让我们添加客户和地址类： public class Customer { private Integer id; private String name; private Address address; // standard getters and setters } public class Address { private String locality; private String city; // standard getters and setters } 我们还将保留以下Customer和List实例，以便测试我们的实现： Customer customer1 = new Customer(1, \u0026#34;Daniel\u0026#34;, \u0026#34;locality1\u0026#34;, \u0026#34;city1\u0026#34;); Customer customer2 = new Customer(2, \u0026#34;Fredrik\u0026#34;, \u0026#34;locality2\u0026#34;, \u0026#34;city2\u0026#34;); Customer customer3 = new Customer(3, \u0026#34;Kyle\u0026#34;, \u0026#34;locality3\u0026#34;, \u0026#34;city3\u0026#34;); Customer customer4 = new Customer(4, \u0026#34;Bob\u0026#34;, \u0026#34;locality4\u0026#34;, \u0026#34;city4\u0026#34;); Customer customer5 = new Customer(5, \u0026#34;Cat\u0026#34;, \u0026#34;locality5\u0026#34;, \u0026#34;city5\u0026#34;); Customer customer6 = new Customer(6, \u0026#34;John\u0026#34;, \u0026#34;locality6\u0026#34;, \u0026#34;city6\u0026#34;); List\u0026lt;Customer\u0026gt; list1 = Arrays.asList(customer1, customer2, customer3); List\u0026lt;Customer\u0026gt; list2 = Arrays.asList(customer4, customer5, customer6); List\u0026lt;Customer\u0026gt; list3 = Arrays.asList(customer1, customer2); List\u0026lt;Customer\u0026gt; linkedList1 = new LinkedList\u0026lt;\u0026gt;(list1); 4. CollectionUtils 让我们来看看Apache Commons CollectionUtils类中一些最常用的方法。 4.1 仅添加非空元素 我们可以使用CollectionUtils 的 addIgnoreNull方法仅将非空元素添加到提供的集合中。 这个方法的第一个参数是我们想要添加元素的集合，第二个参数是我们想要添加的元素： @Test public void givenList_whenAddIgnoreNull_thenNoNullAdded() { CollectionUtils.addIgnoreNull(list1, null); assertFalse(list1.contains(null)); } 请注意，null未添加到列表中。 4.2. 整理清单 **我们可以使用collat​​e方法来整理两个已经排序的列表。**此方法将我们要合并的两个列表作为参数并返回一个排序列表： @Test public void givenTwoSortedLists_whenCollated_thenSorted() { List\u0026lt;Customer\u0026gt; sortedList = CollectionUtils.collate(list1, list2); assertEquals(6, sortedList.size()); assertTrue(sortedList.get(0).getName().equals(\u0026#34;Bob\u0026#34;)); assertTrue(sortedList.get(2).getName().equals(\u0026#34;Daniel\u0026#34;)); } 4.3. 变换对象 我们可以使用transform方法将 A 类的对象转换为 B 类的不同对象。该方法将 A 类的对象列表和转换器作为参数。 此操作的结果是 B 类对象的列表： @Test public void givenListOfCustomers_whenTransformed_thenListOfAddress() { Collection\u0026lt;Address\u0026gt; addressCol = CollectionUtils.collect(list1, new Transformer\u0026lt;Customer, Address\u0026gt;() { public Address transform(Customer customer) { return customer.getAddress(); } }); List\u0026lt;Address\u0026gt; addressList = new ArrayList\u0026lt;\u0026gt;(addressCol); assertTrue(addressList.size() == 3); assertTrue(addressList.get(0).getLocality().equals(\u0026#34;locality1\u0026#34;)); } 4.4. 过滤对象 使用过滤器，我们可以从列表中删除不满足给定条件的对象***。*** 该方法将列表作为第一个参数，将Predicate作为第二个参数。 *filterInverse方法则相反。*当Predicate返回 true 时，它​​会从列表中删除对象。 如果修改了输入列表，即从列表中过滤出至少一个对象，则filter和filterInverse都返回true ： @Test public void givenCustomerList_WhenFiltered_thenCorrectSize() { boolean isModified = CollectionUtils.filter(linkedList1, new Predicate\u0026lt;Customer\u0026gt;() { public boolean evaluate(Customer customer) { return Arrays.asList(\u0026#34;Daniel\u0026#34;,\u0026#34;Kyle\u0026#34;).contains(customer.getName()); } }); assertTrue(linkedList1.size() == 2); } 如果我们希望返回结果列表而不是布尔标志，我们可以使用select和selectRejected 。 4.5. 检查非空 *当我们想要检查列表中是否至少有一个元素时，isNotEmpty方法非常方便。***另一种检查方法是： boolean isNotEmpty = (list != null \u0026amp;\u0026amp; list.size() \u0026gt; 0); 尽管上面的代码行相同，但CollectionUtils.isNotEmpty使我们的代码更干净： @Test public void givenNonEmptyList_whenCheckedIsNotEmpty_thenTrue() { assertTrue(CollectionUtils.isNotEmpty(list1)); } **isEmpty则相反。**它检查给定列表是否为空或列表中是否有零个元素： List\u0026lt;Customer\u0026gt; emptyList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Customer\u0026gt; nullList = null; assertTrue(CollectionUtils.isEmpty(nullList)); assertTrue(CollectionUtils.isEmpty(emptyList)); 4.6. 检查包含 我们可以使用isSubCollection来检查一个集合是否包含在另一个集合中。isSubCollection将两个集合作为参数，如果第一个集合是第二个集合的子集合，则返回true ： @Test public void givenCustomerListAndASubcollection_whenChecked_thenTrue() { assertTrue(CollectionUtils.isSubCollection(list3, list1)); } 如果一个对象在第一个集合中出现的次数小于或等于它在第二个集合中出现的次数，则一个集合是另一个集合的子集合。 4.7. 集合的交集 **我们可以使用CollectionUtils.intersection方法来获取两个集合的交集。**此方法接受两个集合并返回两个输入集合中共有的元素集合： @Test public void givenTwoLists_whenIntersected_thenCheckSize() { Collection\u0026lt;Customer\u0026gt; intersection = CollectionUtils.intersection(list1, list3); assertTrue(intersection.size() == 2); } 元素在结果集合中出现的次数是它在每个给定集合中出现的次数的最小值。 4.8. 减去集合 CollectionUtils.subtract将两个集合作为输入并返回一个集合，该集合包含第一个集合中存在但第二个集合中不存在的元素： @Test public void givenTwoLists_whenSubtracted_thenCheckElementNotPresentInA() { Collection\u0026lt;Customer\u0026gt; result = CollectionUtils.subtract(list1, list3); assertFalse(result.contains(customer1)); } 一个集合在结果中出现的次数是它在第一个集合中出现的次数减去它在第二个集合中出现的次数。 4.9. 集合合并 CollectionUtils.union合并两个集合并返回一个集合，该集合包含第一个或第二个集合中的所有元素。 @Test public void givenTwoLists_whenUnioned_thenCheckElementPresentInResult() { Collection\u0026lt;Customer\u0026gt; union = CollectionUtils.union(list1, list2); assertTrue(union.contains(customer1)); assertTrue(union.contains(customer4)); } 元素在结果集合中出现的次数是它在每个给定集合中出现的次数的最大值。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_collection_utils/","tags":[],"title":"Apache Commons CollectionUtils 指南"},{"categories":["Java"],"contents":"1. 简介 Apache Commons Chain是一个使用责任链模式的库——通常用于组织复杂的处理流程，其中多个接收者可以处理一个请求。 在这篇快速文章中，我们将通过一个表示从 ATM 取款的示例。 2. Maven依赖 首先，我们将使用 Maven 导入该库的最新版本： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-chain\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-chain\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查这个库的最新版本——去这里。 3. 示例链 ATM 将一个数字作为输入并将其传递给负责执行不同操作的处理程序。这些包括计算要分发的钞票数量，并向银行和客户发送有关交易的通知。 4. 链上下文 上下文表示应用程序的当前状态，存储有关事务的信息。 对于我们的 ATM 取款请求，我们需要的信息是：  提款总额 100面额纸币数量 50面额纸币数量 10面额纸币数量 剩余金额  此状态在一个类中定义： public class AtmRequestContext extends ContextBase { int totalAmountToBeWithdrawn; int noOfHundredsDispensed; int noOfFiftiesDispensed; int noOfTensDispensed; int amountLeftToBeWithdrawn; // standard setters \u0026amp; getters } 5. 命令 Command将Context作为输入并对其进行处理。 我们将把上面提到的每个步骤作为一个命令来实现： public class HundredDenominationDispenser implements Command { @Override public boolean execute(Context context) throws Exception { intamountLeftToBeWithdrawn = (int) context.get(\u0026#34;amountLeftToBeWithdrawn); if (amountLeftToBeWithdrawn \u0026gt;= 100) { context.put(\u0026#34;noOfHundredsDispensed\u0026#34;, amountLeftToBeWithdrawn / 100); context.put(\u0026#34;amountLeftToBeWithdrawn\u0026#34;, amountLeftToBeWithdrawn % 100); } return false; } } FiftyDenominationDispenser和TenDenominationDispenser的Command*类似。 6. 链条 Chain是按指定顺序执行的命令的集合。我们的Chain将由上述Command和最后的AuditFilter 组成： public class AtmWithdrawalChain extends ChainBase { public AtmWithdrawalChain() { super(); addCommand(new HundredDenominationDispenser()); addCommand(new FiftyDenominationDispenser()); addCommand(new TenDenominationDispenser()); addCommand(new AuditFilter()); } } 当Chain中的任何命令返回 true 时，它会强制Chain结束。 7. 过滤 过滤器也是一个命令，但具有在Chain执行后调用的postProcess方法。 我们的Filter将向客户和银行发送通知： public class AuditFilter implements Filter { @Override public boolean postprocess(Context context, Exception exception) { // send notification to bank and user  return false; } @Override public boolean execute(Context context) throws Exception { return false; } } 8. 链目录 它是具有逻辑名称的Chain和命令的集合。 在我们的例子中，我们的目录将包含AtmWithdrawalChain。 public class AtmCatalog extends CatalogBase { public AtmCatalog() { super(); addCommand(\u0026#34;atmWithdrawalChain\u0026#34;, new AtmWithdrawalChain()); } } 9. 使用链条 让我们看看我们如何使用上述Chain来处理提款请求。我们将首先创建一个Context，然后将其传递给Chain。Chain将处理Context。 我们将编写一个测试用例来演示我们的AtmWithdrawalChain： public class AtmChainTest { @Test public void givenInputsToContext_whenAppliedChain_thenExpectedContext() throws Exception { Context context = new AtmRequestContext(); context.put(\u0026#34;totalAmountToBeWithdrawn\u0026#34;, 460); context.put(\u0026#34;amountLeftToBeWithdrawn\u0026#34;, 460); Catalog catalog = new AtmCatalog(); Command atmWithdrawalChain = catalog.getCommand(\u0026#34;atmWithdrawalChain\u0026#34;); atmWithdrawalChain.execute(context); assertEquals(460, (int) context.get(\u0026#34;totalAmountToBeWithdrawn\u0026#34;)); assertEquals(0, (int) context.get(\u0026#34;amountLeftToBeWithdrawn\u0026#34;)); assertEquals(4, (int) context.get(\u0026#34;noOfHundredsDispensed\u0026#34;)); assertEquals(1, (int) context.get(\u0026#34;noOfFiftiesDispensed\u0026#34;)); assertEquals(1, (int) context.get(\u0026#34;noOfTensDispensed\u0026#34;)); } } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_chain/","tags":["Pattern"],"title":"Apache Commons Chain"},{"categories":["Data"],"contents":"1. 概述 Apache Commons BeansUtils 包含使用 Java bean 所需的所有工具。 简单地说，bean 是一个简单的 Java 类，包含字段、getter/setter 和无参数构造函数。 Java 提供反射和自省功能来识别 getter-setter 方法并动态调用它们。但是，这些 API 可能很难学习，并且可能需要开发人员编写样板代码来执行最简单的操作。 2. Maven依赖 这是在使用它之前需要在 POM 文件中包含的 Maven 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-beanutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-beanutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本可以在这里找到。 3. 创建一个 Java Bean 让我们使用典型的 getter 和 setter 方法创建两个 bean 类Course和Student 。 public class Course { private String name; private List\u0026lt;String\u0026gt; codes; private Map\u0026lt;String, Student\u0026gt; enrolledStudent = new HashMap\u0026lt;\u0026gt;(); // standard getters/setters } public class Student { private String name; // standard getters/setters } 我们有一个具有课程名称、课程代码和多个注册学生的课程类。注册学生由唯一的注册 ID 标识。课程类在Map对象中维护注册学生，其中注册 ID 是键，学生对象将是值。 4. 访问属性  Bean 的属性可以分为三类。 4.1 简单属性 单值属性也称为简单或标量。 它们的值可能是原始类型（例如 int、float）或复杂类型对象。BeanUtils 有一个PropertyUtils类，它允许我们修改 Java Bean 中的简单属性。 这是设置属性的示例代码： Course course = new Course(); String name = \u0026#34;Computer Science\u0026#34;; List\u0026lt;String\u0026gt; codes = Arrays.asList(\u0026#34;CS\u0026#34;, \u0026#34;CS01\u0026#34;); PropertyUtils.setSimpleProperty(course, \u0026#34;name\u0026#34;, name); PropertyUtils.setSimpleProperty(course, \u0026#34;codes\u0026#34;, codes); 4.2. 索引属性 索引属性有一个集合作为可以使用索引号单独访问的值。作为 JavaBean 的扩展，BeanUtils 也将java.util.List类型值视为索引。 我们可以使用PropertyUtils 的 setIndexedProperty方法修改索引属性的单个值。 这是修改索引属性的示例代码： PropertyUtils.setIndexedProperty(course, \u0026#34;codes[1]\u0026#34;, \u0026#34;CS02\u0026#34;); 4.3. 映射属性 任何以java.util.Map作为基础类型的属性都称为映射属性。BeanUtils 允许我们使用字符串值键更新映射中的单个值。 这是修改映射属性中的值的示例代码： Student student = new Student(); String studentName = \u0026#34;Joe\u0026#34;; student.setName(studentName); PropertyUtils.setMappedProperty(course, \u0026#34;enrolledStudent(ST-1)\u0026#34;, student); 5. 嵌套属性访问 如果一个属性值是一个对象并且我们需要访问该对象内部的一个属性值——那将是访问一个嵌套属性。PropertyUtils也允许我们访问和修改嵌套属性。 假设我们想通过Course对象访问Student类的 name 属性。我们可能会写： String name = course.getEnrolledStudent(\u0026#34;ST-1\u0026#34;).getName(); 我们可以使用getNestedProperty访问嵌套属性值，并使用 PropertyUtils 中的**setNestedProperty方法修改嵌套属性。这是代码： Student student = new Student(); String studentName = \u0026#34;Joe\u0026#34;; student.setName(studentName); String nameValue = (String) PropertyUtils.getNestedProperty( course, \u0026#34;enrolledStudent(ST-1).name\u0026#34;); 6. 复制Bean属性 将一个对象的属性复制到另一个对象对于开发人员来说通常是乏味且容易出错的。BeanUtils类提供了一个copyProperties方法，该方法将源对象的属性复制到**两个对象中属性名称相同的目标对象。 让我们创建另一个 bean 类，作为我们在上面创建的Course具有相同的属性，除了它不会有registeredStudent属性而是属性名称将是students。让我们将该类命名为CourseEntity。该类将如下所示： public class CourseEntity { private String name; private List\u0026lt;String\u0026gt; codes; private Map\u0026lt;String, Student\u0026gt; students = new HashMap\u0026lt;\u0026gt;(); // standard getters/setters } 现在我们将Course对象的属性复制到CourseEntity对象： Course course = new Course(); course.setName(\u0026#34;Computer Science\u0026#34;); course.setCodes(Arrays.asList(\u0026#34;CS\u0026#34;)); course.setEnrolledStudent(\u0026#34;ST-1\u0026#34;, new Student()); CourseEntity courseEntity = new CourseEntity(); BeanUtils.copyProperties(courseEntity, course); 请记住，这将仅复制具有相同名称的属性。因此，它不会复制Course类中的属性registeredStudent，因为 CourseEntity**类中没有同名的属性。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_beanutils/","tags":[],"title":"Apache Commons BeanUtils"},{"categories":["Java Collections"],"contents":"1. 简介 在这篇快速文章中，我们将重点介绍如何使用 Apache 的Bag集合。 2. Maven依赖 在开始之前，我们需要从Maven Central导入最新的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Bag与Collection 简而言之，Bag是一个允许存储多个项目及其重复次数的集合： public void whenAdded_thenCountIsKept() { Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;( Arrays.asList(1, 2, 3, 3, 3, 1, 4)); assertThat(2, equalTo(bag.getCount(1))); } 3.1 违反Collection合同 在阅读Bag的 API 文档时，我们可能会注意到某些方法被标记为违反标准 Java 的 Collection 契约。 例如，当我们使用 Java 集合中的add() API 时，即使项目已经在集合中，我们也会收到true ： Collection\u0026lt;Integer\u0026gt; collection = new ArrayList\u0026lt;\u0026gt;(); collection.add(1); assertThat(collection.add(1), is(true)); 当我们添加集合中已经可用的元素时，来自Bag实现的相同 API将返回false ： Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;(); bag.add(1); assertThat(bag.add(1), is(not(true))); 为了解决这些问题，Apache Collections 的库提供了一个名为CollectionBag 的装饰器。我们可以使用它来使我们的包集合符合 Java集合合约： public void whenBagAddAPILikeCollectionAPI_thenTrue() { Bag\u0026lt;Integer\u0026gt; bag = CollectionBag.collectionBag(new HashBag\u0026lt;\u0026gt;()); bag.add(1); assertThat(bag.add(1), is((true))); } 4. 包的实现 现在让我们在 Apache 的集合库中探索Bag接口的各种实现。 4.1 哈希包 我们可以添加一个元素并指示 API 该元素在我们的包集合中应具有的副本数： public void givenAdd_whenCountOfElementsDefined_thenCountAreAdded() { Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;(); bag.add(1, 5); // adding 1 five times  assertThat(5, equalTo(bag.getCount(1))); } 我们还可以从我们的包中删除特定数量的副本或元素的每个实例： public void givenMultipleCopies_whenRemove_allAreRemoved() { Bag\u0026lt;Integer\u0026gt; bag = new HashBag\u0026lt;\u0026gt;( Arrays.asList(1, 2, 3, 3, 3, 1, 4)); bag.remove(3, 1); // remove one element, two still remain  assertThat(2, equalTo(bag.getCount(3))); bag.remove(1); // remove all  assertThat(0, equalTo(bag.getCount(1))); } 4.2. TreeBag TreeBag实现与任何其他树一样工作，另外还维护Bag**语义。 我们可以自然地使用TreeBag对整数数组进行排序，然后查询每个单独元素在集合中的实例数： public void givenTree_whenDuplicateElementsAdded_thenSort() { TreeBag\u0026lt;Integer\u0026gt; bag = new TreeBag\u0026lt;\u0026gt;(Arrays.asList(7, 5, 1, 7, 2, 3, 3, 3, 1, 4, 7)); assertThat(bag.first(), equalTo(1)); assertThat(bag.getCount(bag.first()), equalTo(2)); assertThat(bag.last(), equalTo(7)); assertThat(bag.getCount(bag.last()), equalTo(3)); } TreeBag实现了一个SortedBag接口，该接口的所有实现都可以使用装饰器CollectionSortedBag来遵守 Java Collections 契约： public void whenTreeAddAPILikeCollectionAPI_thenTrue() { SortedBag\u0026lt;Integer\u0026gt; bag = CollectionSortedBag.collectionSortedBag(new TreeBag\u0026lt;\u0026gt;()); bag.add(1); assertThat(bag.add(1), is((true))); } 4.3. SynchronizedSortedBag Bag的另一个广泛使用的实现是SynchronizedSortedBag。准确地说，这是一个SortedBag实现的同步装饰器。 我们可以将此装饰器与上一节中的TreeBag（SortedBag 的实现*）*一起使用，以同步对我们包的访问： public void givenSortedBag_whenDuplicateElementsAdded_thenSort() { SynchronizedSortedBag\u0026lt;Integer\u0026gt; bag = SynchronizedSortedBag .synchronizedSortedBag(new TreeBag\u0026lt;\u0026gt;( Arrays.asList(7, 5, 1, 7, 2, 3, 3, 3, 1, 4, 7))); assertThat(bag.first(), equalTo(1)); assertThat(bag.getCount(bag.first()), equalTo(2)); assertThat(bag.last(), equalTo(7)); assertThat(bag.getCount(bag.last()), equalTo(3)); } 我们可以使用 API 的组合——Collections.synchronizedSortedMap()和TreeMap——来模拟我们在这里使用SynchronizedSortedBag所做的事情。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_commons_bag/","tags":[],"title":"Apache Commons Bag"},{"categories":["Persistence"],"contents":"1. 概述 之前，我们专注于如何开始使用 Apache Cayenne。 在本文中，我们将介绍如何使用 ORM 编写简单和高级查询。 2. 设置 该设置类似于上一篇文章中使用的设置。 **3.对象选择 ** 让我们从简单的开始，看看我们如何获取名字中包含“Paul”的所有作者： @Test public void whenContainsObjS_thenWeGetOneRecord() { List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.contains(\u0026#34;Paul\u0026#34;)) .select(context); assertEquals(authors.size(), 1); } 接下来，让我们看看如何在 Author\u0026rsquo;s name 列上应用不区分大小写的 LIKE 类型的查询： @Test void whenLikeObjS_thenWeGetTwoAuthors() { List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.likeIgnoreCase(\u0026#34;Paul%\u0026#34;)) .select(context); assertEquals(authors.size(), 2); } 接下来，*endsWith()*表达式将只返回一条记录，因为只有一位作者具有匹配的姓名： @Test void whenEndsWithObjS_thenWeGetOrderedAuthors() { List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.endsWith(\u0026#34;Sarra\u0026#34;)) .select(context); Author firstAuthor = authors.get(0); assertEquals(authors.size(), 1); assertEquals(firstAuthor.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 更复杂的是查询名称在列表中的作者： @Test void whenInObjS_thenWeGetAuthors() { List names = Arrays.asList( \u0026#34;Paul Xavier\u0026#34;, \u0026#34;pAuL Smith\u0026#34;, \u0026#34;Vicky Sarra\u0026#34;); List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.in(names)) .select(context); assertEquals(authors.size(), 3); } 第九个是相反的，这里只有“Vicky”会出现在结果中： @Test void whenNinObjS_thenWeGetAuthors() { List names = Arrays.asList( \u0026#34;Paul Xavier\u0026#34;, \u0026#34;pAuL Smith\u0026#34;); List\u0026lt;Author\u0026gt; authors = ObjectSelect.query(Author.class) .where(Author.NAME.nin(names)) .select(context); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 请注意，以下两个代码是相同的，因为它们都将创建具有相同参数的相同类型的表达式： Expression qualifier = ExpressionFactory .containsIgnoreCaseExp(Author.NAME.getName(), \u0026#34;Paul\u0026#34;); Author.NAME.containsIgnoreCase(\u0026#34;Paul\u0026#34;); 以下是*Expression* 和ExpressionFactory类中一些可用表达式的列表*：*  likeExp : 用于构建 LIKE 表达式 likeIgnoreCaseExp：用于构建 LIKE_IGNORE_CASE 表达式 containsExp : LIKE 查询的表达式，其模式匹配字符串中的任何位置 containsIgnoreCaseExp ：与**containsExp相同，但使用不区分大小写的方法 startsWithExp：模式应该匹配字符串的开头 startsWithIgnoreCaseExp：类似于startsWithExp但使用不区分大小写的方法 endsWithExp : 匹配字符串结尾的表达式 endsWithIgnoreCaseExp：使用不区分大小写的方法匹配字符串结尾的表达式 expTrue : 布尔真表达式 expFalse : 用于布尔假表达式 andExp：用于用and运算符链接两个表达式 orExp : 使用or运算符链接两个表达式  4. SelectQuery 它是用户应用程序中使用最广泛的查询类型。SelectQuery描述了一个简单而强大的 API，其行为类似于 SQL 语法，但仍然使用 Java 对象和方法，然后使用构建器模式来构造更复杂的表达式。 在这里，我们谈论的是一种表达式语言，其中我们使用Expression（用于构建表达式）又名限定符和Ordering（用于对结果排序）类构建查询，这些类接下来由 ORM 转换为原生 SQL。 为了看到这一点，我们汇总了一些测试，在实践中展示了如何构建一些表达式和对数据进行排序。 让我们应用一个 LIKE 查询来获取名称为“Paul”的作者**：** @Test void whenLikeSltQry_thenWeGetOneAuthor() { Expression qualifier = ExpressionFactory.likeExp(Author.NAME.getName(), \u0026#34;Paul%\u0026#34;); SelectQuery query = new SelectQuery(Author.class, qualifier); List\u0026lt;Author\u0026gt; authorsTwo = context.performQuery(query); assertEquals(authorsTwo.size(), 1); } 这意味着如果您不向查询 ( SelectQuery ) 提供任何表达式，则结果将是 Author 表的所有记录。 可以使用containsIgnoreCaseExp表达式执行类似的查询，以获取姓名中包含 Paul 的所有作者，无论字母的大小写如何： @Test void whenCtnsIgnorCaseSltQry_thenWeGetTwoAuthors() { Expression qualifier = ExpressionFactory .containsIgnoreCaseExp(Author.NAME.getName(), \u0026#34;Paul\u0026#34;); SelectQuery query = new SelectQuery(Author.class, qualifier); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); assertEquals(authors.size(), 2); } 类似地，让我们以不区分大小写的方式（containsIgnoreCaseExp ）获取名称包含“Paul”的作者，并以字母 h结尾的名称（endsWithExp ）： @Test void whenCtnsIgnorCaseEndsWSltQry_thenWeGetTwoAuthors() { Expression qualifier = ExpressionFactory .containsIgnoreCaseExp(Author.NAME.getName(), \u0026#34;Paul\u0026#34;) .andExp(ExpressionFactory .endsWithExp(Author.NAME.getName(), \u0026#34;h\u0026#34;)); SelectQuery query = new SelectQuery( Author.class, qualifier); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;pAuL Smith\u0026#34;); } 可以使用Ordering类执行升序： @Test void whenAscOrdering_thenWeGetOrderedAuthors() { SelectQuery query = new SelectQuery(Author.class); query.addOrdering(Author.NAME.asc()); List\u0026lt;Author\u0026gt; authors = query.select(context); Author firstAuthor = authors.get(0); assertEquals(authors.size(), 3); assertEquals(firstAuthor.getName(), \u0026#34;Paul Xavier\u0026#34;); } 这里不使用query.addOrdering(Author.NAME.asc())，我们也可以只使用SortOrder类来获取升序： query.addOrdering(Author.NAME.getName(), SortOrder.ASCENDING); 相对有降序排列： @Test void whenDescOrderingSltQry_thenWeGetOrderedAuthors() { SelectQuery query = new SelectQuery(Author.class); query.addOrdering(Author.NAME.desc()); List\u0026lt;Author\u0026gt; authors = query.select(context); Author firstAuthor = authors.get(0); assertEquals(authors.size(), 3); assertEquals(firstAuthor.getName(), \u0026#34;pAuL Smith\u0026#34;); } 正如我们在前面的示例中看到的 - 设置此排序的另一种方法是： query.addOrdering(Author.NAME.getName(), SortOrder.DESCENDING); **5. SQLTemplate ** SQLTemplate也是我们可以与 Cayenne 一起使用以不使用对象样式查询的一种替代方法。 使用SQLTemplate构建查询与使用某些参数编写本机 SQL 语句直接相关。让我们实现一些简单的例子。 以下是我们在每次测试后删除所有作者的方法： @After void deleteAllAuthors() { SQLTemplate deleteAuthors = new SQLTemplate( Author.class, \u0026#34;delete from author\u0026#34;); context.performGenericQuery(deleteAuthors); } 要查找所有记录的作者，我们只需要应用 SQL 查询select * from Author，我们将直接看到结果是正确的，因为我们恰好保存了三个作者： @Test void givenAuthors_whenFindAllSQLTmplt_thenWeGetThreeAuthors() { SQLTemplate select = new SQLTemplate( Author.class, \u0026#34;select * from Author\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(select); assertEquals(authors.size(), 3); } 接下来，让我们获取名为“Vicky Sarra”的作者： @Test void givenAuthors_whenFindByNameSQLTmplt_thenWeGetOneAuthor() { SQLTemplate select = new SQLTemplate( Author.class, \u0026#34;select * from Author where name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(select); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 6. EJBQL查询 接下来，让我们通过*EJBQLQuery 查询数据，*它是作为在 Cayenne 中采用 Java Persistence API 的实验的一部分而创建的。 在这里，查询以参数化的对象样式应用；让我们看一些实际的例子。 首先，所有已保存作者的搜索将如下所示： @Test void givenAuthors_whenFindAllEJBQL_thenWeGetThreeAuthors() { EJBQLQuery query = new EJBQLQuery(\u0026#34;select a FROM Author a\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); assertEquals(authors.size(), 3); } 让我们再次使用名称“Vicky Sarra”搜索作者，但现在使用EJBQLQuery： @Test void givenAuthors_whenFindByNameEJBQL_thenWeGetOneAuthor() { EJBQLQuery query = new EJBQLQuery( \u0026#34;select a FROM Author a WHERE a.name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(query); Author author = authors.get(0); assertEquals(authors.size(), 1); assertEquals(author.getName(), \u0026#34;Vicky Sarra\u0026#34;); } 一个更好的例子是更新作者： @Test void whenUpdadingByNameEJBQL_thenWeGetTheUpdatedAuthor() { EJBQLQuery query = new EJBQLQuery( \u0026#34;UPDATE Author AS a SET a.name \u0026#34; + \u0026#34;= \u0026#39;Vicky Edison\u0026#39; WHERE a.name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;); QueryResponse queryResponse = context.performGenericQuery(query); EJBQLQuery queryUpdatedAuthor = new EJBQLQuery( \u0026#34;select a FROM Author a WHERE a.name = \u0026#39;Vicky Edison\u0026#39;\u0026#34;); List\u0026lt;Author\u0026gt; authors = context.performQuery(queryUpdatedAuthor); Author author = authors.get(0); assertNotNull(author); } 如果我们只想选择一列，我们应该使用这个查询*“select a.name FROM Author a”*。 7. SQLExec SQLExec也是从 Cayenne M4 版本引入的一个新的 Fluent 查询 API。 一个简单的插入看起来像这样： @Test void whenInsertingSQLExec_thenWeGetNewAuthor() { int inserted = SQLExec .query(\u0026#34;INSERT INTO Author (name) VALUES (\u0026#39;codingman\u0026#39;)\u0026#34;) .update(context); assertEquals(inserted, 1); } 接下来，我们可以根据作者的姓名更新作者： @Test void whenUpdatingSQLExec_thenItsUpdated() { int updated = SQLExec.query( \u0026#34;UPDATE Author SET name = \u0026#39;codingman\u0026#39; \u0026#34; + \u0026#34;WHERE name = \u0026#39;Vicky Sarra\u0026#39;\u0026#34;) .update(context); assertEquals(updated, 1); } 我们可以从文档中获得更多细节。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cayenne_query/","tags":[],"title":"Apache Cayenne 中的高级查询"},{"categories":["Persistence"],"contents":"1. 概述 Apache Cayenne是一个开源库，在 Apache 许可下分发，提供建模工具、对象关系映射（又名 ORM）等功能，用于本地持久性操作和远程服务。 在以下部分中，我们将了解如何使用 Apache Cayenne ORM 与 MySQL 数据库进行交互。 2. Maven依赖 首先，我们只需要添加以下依赖项，即可将 Apache Cayenne 和 MySQL 连接器与 JDBC 驱动程序一起访问我们的intro_cayenne数据库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cayenne\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cayenne-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.M5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.44\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 让我们配置 Cayenne 建模器插件，该插件将用于设计或设置我们的映射文件，该文件充当数据库模式和 Java 对象之间的桥梁： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cayenne.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-cayenne-modeler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.M5\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; 建议不要手动构建 XML 映射文件（很少制作），而是使用建模器，它是 Cayenne 发行版附带的一个非常高级的工具。 根据您的操作系统，可以从这个存档下载它，或者只使用作为 Maven 插件包含的跨平台版本 (JAR)。 Maven 中央存储库托管最新版本的Apache Cayenne、他的建模器和MySQL 连接器。 接下来，让我们使用mvn install构建我们的项目，并使用命令mvn cayenne-modeler:run 启动建模器 GUI，以获取此屏幕的输出： 3. 设置 要让 Apache Cayenne 查找正确的本地数据库，我们只需在资源目录中的文件cayenne-project.xml中使用正确的驱动程序、URL 和用户填充他的配置文件： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;domain project-version=\u0026#34;9\u0026#34;\u0026gt; \u0026lt;node name=\u0026#34;datanode\u0026#34; factory =\u0026#34;org.apache.cayenne.configuration.server.XMLPoolingDataSourceFactory\u0026#34; schema-update-strategy =\u0026#34;org.apache.cayenne.access.dbsync.CreateIfNoSchemaStrategy\u0026#34;\u0026gt; \u0026lt;data-source\u0026gt; \u0026lt;driver value=\u0026#34;com.mysql.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;url value =\u0026#34;jdbc:mysql://localhost:3306/intro_cayenne;create=true\u0026#34;/\u0026gt; \u0026lt;connectionPool min=\u0026#34;1\u0026#34; max=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;login userName=\u0026#34;root\u0026#34; password=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;/data-source\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/domain\u0026gt; 在这里我们可以看到：  本地数据库名为intro_cayenne 如果尚未创建，Cayenne 将为我们完成 我们将使用用户名root和密码root进行连接（根据在您的数据库管理系统中注册的用户进行更改）  在内部，它是XMLPoolingDataSourceFactory负责从与DataNodeDescriptor关联的 XML 资源加载 JDBC 连接信息。 请注意，这些参数与数据库管理系统和 JDBC 驱动程序相关，因为该库可以支持许多不同的数据库。 在此详细列表中，它们中的每一个都有一个可用的适配器。请注意，尚未提供 4.0 版的完整文档，因此我们在此处参考之前的版本。 4. 映射和数据库设计 4.1 造型 现在让我们单击*“打开项目”，导航到项目的资源文件夹并选择文件cayenne-project.xml，*建模器将显示以下内容： 在这里，我们可以选择从现有数据库创建映射结构 **或手动进行。**本文将处理使用建模器和现有数据库进入 Cayenne 并快速了解其工作原理的问题。 让我们看一下我们的intro_cayenne数据库，它在两个表之间具有一对多的关系，因为作者可以发布或拥有许多文章：  作者：id（PK）和姓名 文章：id (PK)、title、content和author_id(FK)  现在让我们转到“工具 \u0026gt; 重新设计数据库模式”，我们将自动填充所有映射配置。在提示屏幕上，只需填写cayenne-project.xml文件中可用的数据源配置，然后点击继续： 在下一个屏幕上，我们需要检查“使用 Java 原始类型”，如下所示： 我们还需要确保将com.codingman.apachecayenne.persistent作为 Java 包并保存；我们将看到 XML 配置文件已更新其defaultPackage属性以匹配 Java 包： 在每个ObjEntity 中，我们必须为子类指定包，如下图所示，然后再次单击*“保存”*图标： 现在在*“Tools \u0026gt; Generate Classes”菜单上，选择“ Standard Persistent Objects ”作为类型；并在“类”选项卡上检查所有类并点击“生成”*。 回到源码看看我们的持久化对象已经生成成功了，说说*_Article.java和_Author.java*。 请注意，所有这些配置都保存在文件datamap.map.xml中，该文件也位于资源文件夹中。 4.2. 映射结构 资源文件夹中生成的 XML 映射文件使用了一些与 Apache Cayenne 相关的唯一标签：  DataNode() – 数据库的模型，其内容连接到数据库所需的所有信息（数据库名称、驱动程序和用户凭据） DataMap() – 它是持久实体及其关系的容器 DbAttribute() – 表示数据库表中的列 DbEntity() - 单个数据库表或视图的模型，它可以有DbAttributes和关系 ObjEntity() ——单个持久化java类的模型；由对应于实体类属性的 ObjAttributes 和作为具有另一个实体类型的属性的 ObjRelationships 组成 Embeddable() – Java 类的模型，充当 ObjEntity 的属性，但对应于数据库中的多个列 Procedure() – 在数据库中注册存储过程 Query() - 查询的模型，用于在配置文件中映射查询，不要忘记我们也可以在代码中做到这一点  这是完整的细节。 5. Cayenne API 剩下的唯一步骤是使用 Cayenne API 使用生成的类来执行我们的数据库操作，因为我们知道将我们的持久类子类化只是以后用于自定义模型的最佳实践。 5.1 创建对象 在这里，我们只是保存了一个Author对象，稍后检查数据库中是否只有一条该类型的记录： @Test public void whenInsert_thenWeGetOneRecordInTheDatabase() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); long records = ObjectSelect.dataRowQuery(Author.class) .selectCount(context); assertEquals(1, records); } 5.2. 读取对象 保存Author后，我们只需通过特定属性的简单查询来选择它： @Test public void whenInsert_andQueryByFirstName_thenWeGetTheAuthor() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); assertEquals(\u0026#34;Paul\u0026#34;, expectedAuthor.getName()); } 5.3. 检索一个类的所有记录 我们将保存两个作者并检索作者对象的集合以检查是否只保存了这两个： @Test public void whenInsert_andQueryAll_thenWeGetTwoAuthors() { Author firstAuthor = context.newObject(Author.class); firstAuthor.setName(\u0026#34;Paul\u0026#34;); Author secondAuthor = context.newObject(Author.class); secondAuthor.setName(\u0026#34;Ludovic\u0026#34;); context.commitChanges(); List\u0026lt;Author\u0026gt; authors = ObjectSelect .query(Author.class) .select(context); assertEquals(2, authors.size()); } 5.4. 更新对象 更新过程也很简单，但我们需要先拥有所需的对象，然后再修改其属性并将其应用于数据库： @Test public void whenUpdating_thenWeGetAnUpatedeAuthor() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); expectedAuthor.setName(\u0026#34;Garcia\u0026#34;); context.commitChanges(); assertEquals(author.getName(), expectedAuthor.getName()); } 5.5. 附加对象 我们可以将一篇文章分配给作者： @Test public void whenAttachingToArticle_thenTheRelationIsMade() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); Article article = context.newObject(Article.class); article.setTitle(\u0026#34;My post title\u0026#34;); article.setContent(\u0026#34;The content\u0026#34;); article.setAuthor(author); context.commitChanges(); Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Smith\u0026#34;)) .selectOne(context); Article expectedArticle = (expectedAuthor.getArticles()).get(0); assertEquals(article.getTitle(), expectedArticle.getTitle()); } 5.6. 删除对象 删除保存的对象会将其从数据库中完全删除，此后我们将看到null作为查询的结果： @Test public void whenDeleting_thenWeLostHisDetails() { Author author = context.newObject(Author.class); author.setName(\u0026#34;Paul\u0026#34;); context.commitChanges(); Author savedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); if(savedAuthor != null) { context.deleteObjects(author); context.commitChanges(); } Author expectedAuthor = ObjectSelect.query(Author.class) .where(Author.NAME.eq(\u0026#34;Paul\u0026#34;)) .selectOne(context); assertNull(expectedAuthor); } 5.7. 删除班级的所有记录 也可以使用SQLTemplate删除表的所有记录，这里我们在每个测试方法之后执行此操作，以便在每个测试启动之前始终拥有一个 void 数据库*：* @After public void deleteAllRecords() { SQLTemplate deleteArticles = new SQLTemplate( Article.class, \u0026#34;delete from article\u0026#34;); SQLTemplate deleteAuthors = new SQLTemplate( Author.class, \u0026#34;delete from author\u0026#34;); context.performGenericQuery(deleteArticles); context.performGenericQuery(deleteAuthors); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_cayenne_orm/","tags":[],"title":"Apache Cayenne ORM 简介"},{"categories":["Spring Boot"],"contents":"1. 概述 Apache Camel 的核心是一个集成引擎，简单地说，它可用于促进各种技术之间的交互。 这些服务和技术之间的桥梁被称为*路由。*路由在引擎（CamelContext）上实现，它们与所谓的“交换消息”进行通信。 2. Maven依赖 首先，我们需要包含 Spring Boot、Camel、带有 Swagger 和 JSON 的 Rest API 的依赖项： \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-servlet-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-jackson-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-swagger-java-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel.springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 可以在此处找到最新版本的 Apache Camel 依赖项。 3.主类 让我们首先创建一个 Spring Boot应用程序： @SpringBootApplication @ComponentScan(basePackages=\u0026#34;com.codingman.camel\u0026#34;) public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 4. Spring Boot 的 Camel 配置 现在让我们使用 Spring 配置我们的应用程序，从配置文件（属性）开始。 例如，让我们在src/main/resources的application.properties文件中为我们的应用程序配置一个日志： logging.config=classpath:logback.xml camel.springboot.name=MyCamel server.address=0.0.0.0 management.address=0.0.0.0 management.port=8081 endpoints.enabled = true endpoints.health.enabled = true 此示例显示了一个application.properties文件，该文件还设置了 Logback 配置的路径。通过将 IP 设置为“0.0.0.0”，我们完全限制了 Spring Boot 提供的 Web 服务器上的管理员和管理访问。此外，我们还启用了对我们的应用程序端点以及健康检查端点的所需网络访问。 另一个配置文件是application.yml。在其中，我们将添加一些属性来帮助我们将值注入我们的应用程序路由： server: port: 8080 camel: springboot: name: ServicesRest management: port: 8081 endpoints: enabled: false health: enabled: true quickstart: generateOrderPeriod: 10s processOrderPeriod: 30s 5. 设置 Camel Servlet 开始使用 Camel 的一种方法是将其注册为 servlet，以便它可以拦截 HTTP 请求并将它们重定向到我们的应用程序。 如前所述，盯着 Camel 的 2.18 及以下版本，我们可以利用我们的*application.yml——*通过为最终 URL 创建一个参数。稍后它将被注入到我们的 Java 代码中： codingman: api: path: \u0026#39;/camel\u0026#39; 回到我们的Application类，我们需要在上下文路径的根目录注册 Camel servlet，它将在应用程序启动时从 application.yml 中的引用**codingman.api.path注入： @Value(\u0026#34;${codingman.api.path}\u0026#34;) String contextPath; @Bean ServletRegistrationBean servletRegistrationBean() { ServletRegistrationBean servlet = new ServletRegistrationBean (new CamelHttpTransportServlet(), contextPath+\u0026#34;/*\u0026#34;); servlet.setName(\u0026#34;CamelServlet\u0026#34;); return servlet; } 从 Camel 的 2.19 版开始，此配置已被删除，因为CamelServlet默认设置为*“/camel”*。 6. 建立路线 让我们通过从 Camel 扩展RouteBuilder类开始创建路由，并将其设置为*@Component*以便组件扫描例程可以在 Web 服务器初始化期间找到它： @Component class RestApi extends RouteBuilder { @Override public void configure() { CamelContext context = new DefaultCamelContext(); restConfiguration()... rest(\u0026#34;/api/\u0026#34;)... from(\u0026#34;direct:remoteService\u0026#34;)... } } 在这个类中，我们重写了Camel 的*RouteBuilder类的**configure()*方法。 Camel 总是需要一个CamelContext实例——保存传入和传出消息的核心组件。 在这个简单的示例中，DefaultCamelContext就足够了，因为它只是将消息和路由绑定到其中，就像我们将要创建的 REST 服务一样。 **6.1 restConfiguration()路由 接下来，我们为计划在*restConfiguration()*方法中创建的端点创建一个 REST 声明： restConfiguration() .contextPath(contextPath) .port(serverPort) .enableCORS(true) .apiContextPath(\u0026#34;/api-doc\u0026#34;) .apiProperty(\u0026#34;api.title\u0026#34;, \u0026#34;Test REST API\u0026#34;) .apiProperty(\u0026#34;api.version\u0026#34;, \u0026#34;v1\u0026#34;) .apiContextRouteId(\u0026#34;doc-api\u0026#34;) .component(\u0026#34;servlet\u0026#34;) .bindingMode(RestBindingMode.json) 在这里，我们使用来自 YAML 文件的注入属性注册上下文路径。我们的应用程序的端口也应用了相同的逻辑。CORS 已启用，允许跨站点使用此 Web 服务。绑定模式允许并将参数转换为我们的 API。 接下来，我们将 Swagger 文档添加到我们之前设置的 URI、标题和版本中。当我们为 REST Web 服务创建方法/端点时，Swagger 文档将自动更新。 这个 Swagger 上下文本身就是一个 Camel 路由，在启动过程中我们可以在服务器日志中看到一些关于它的技术信息。我们的示例文档默认在http://localhost:8080/camel/api-doc 提供。 **6.2. rest()路由 现在，让我们从上面列出的*configure()方法中实现**rest()*方法调用： rest(\u0026#34;/api/\u0026#34;) .id(\u0026#34;api-route\u0026#34;) .consumes(\u0026#34;application/json\u0026#34;) .post(\u0026#34;/bean\u0026#34;) .bindingMode(RestBindingMode.json_xml) .type(MyBean.class) .to(\u0026#34;direct:remoteService\u0026#34;); 对于那些熟悉 API 的人来说，这种方法非常简单。id是CamelContext内部路由的标识。下一行定义 MIME 类型。这里定义了绑定模式，以表明我们可以在*restConfiguration()*上设置模式。 post()方法向API 添加一个操作，生成一个“ POST /bean ”端点，而MyBean（一个具有整数 id和字符串名称的常规 Java bean ）定义了预期的参数。 类似地，GET、PUT 和 DELETE 等 HTTP 操作也都以get()、put()、*delete()*的形式可用。 最后，*to()*方法创建了通往另一条路线的桥梁。在这里，它告诉 Camel 在其上下文/引擎中搜索我们将要创建的另一条路线——该路线由值/id “ *direct: \u0026hellip; ”命名和检测，与**from()*方法中定义的路线相匹配。 *6.3. 带有*transform()的from()路由 使用 Camel 时，路由接收参数，然后转换、转换和处理这些参数。之后，它将这些参数发送到另一个路由，该路由将结果转发到所需的输出（文件、数据库、SMTP 服务器或 REST API 响应）。 在本文中，我们只在我们要覆盖的*configure()方法中创建另一个路由。这将是我们最后一个to()*路线的目的地路线： from(\u0026#34;direct:remoteService\u0026#34;) .routeId(\u0026#34;direct-route\u0026#34;) .tracing() .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.id}\u0026#34;) .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.name}\u0026#34;) .transform().simple(\u0026#34;Hello ${in.body.name}\u0026#34;) .setHeader(Exchange.HTTP_RESPONSE_CODE, constant(200)); *from()方法遵循相同的原则，并且与rest()方法有许多相同的方法，除了它从 Camel 上下文消息中消费。这就是参数“ direct-route ”的原因，它创建了指向上述方法rest().to()*的链接。 许多其他转换是可用的，包括提取为 Java 原语（或对象）并将其发送到持久层。请注意，路由总是从传入消息中读取，因此链式路由将忽略传出消息。 我们的例子已经准备好了，我们可以试试：  运行提示命令：mvn spring-boot:run 使用标头参数向http://localhost:8080/camel/api/bean发出 POST 请求： Content-Type: application/json和有效负载*{“id”: 1,”name”: “World”}* 我们应该会收到 201 的返回码和响应：Hello, World  6.4. 简单的脚本语言 该示例使用*tracking()方法输出日志记录。请注意，我们使用了${}*占位符；这些是属于 Camel 的称为 SIMPLE 的脚本语言的一部分。它适用于通过路由交换的消息，例如消息中的正文。 在我们的示例中，我们使用 SIMPLE 将 Camel 消息正文中的 bean 属性输出到日志中。 我们也可以使用它来进行简单的转换，如*transform()*方法所示。 **6.5 from()路由与process() ** 让我们做一些更有意义的事情，比如调用一个服务层返回处理过的数据。SIMPLE 不适用于繁重的数据处理，因此让我们将*transform()替换为process()*方法： from(\u0026#34;direct:remoteService\u0026#34;) .routeId(\u0026#34;direct-route\u0026#34;) .tracing() .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.id}\u0026#34;) .log(\u0026#34;\u0026gt;\u0026gt;\u0026gt; ${body.name}\u0026#34;) .process(new Processor() { @Override public void process(Exchange exchange) throws Exception { MyBean bodyIn = (MyBean) exchange.getIn().getBody(); ExampleServices.example(bodyIn); exchange.getIn().setBody(bodyIn); } }) .setHeader(Exchange.HTTP_RESPONSE_CODE, constant(200)); 这允许我们将数据提取到一个 bean 中，与之前在type()方法中定义的相同，并在我们的ExampleServices层中处理它。 由于我们之前将bindingMode()设置为 JSON，因此响应已经是正确的 JSON 格式，基于我们的 POJO 生成。这意味着对于ExampleServices类： public class ExampleServices { public static void example(MyBean bodyIn) { bodyIn.setName( \u0026#34;Hello, \u0026#34; + bodyIn.getName() ); bodyIn.setId(bodyIn.getId() * 10); } } 现在，相同的 HTTP 请求返回响应代码 201 和正文：{“id”：10，“name”：“Hello, World”}。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_camel_spring_boot/","tags":["Apache Camel"],"title":"带有 Spring Boot 的 Apache Camel"},{"categories":["Data"],"contents":"1. 概述 Apache Camel是一个开源集成框架，旨在简化集成系统。 它允许最终用户使用相同的 API 集成各种系统，提供对多种协议和数据类型的支持，同时具有可扩展性并允许引入自定义协议。 2. Maven依赖 为了使用 Camel，我们需要先添加 Maven 依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.18.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 Camel 工件。 3. 领域特定语言 路由和路由引擎是 Camel 的核心部分。路由包含不同系统之间集成的流程和逻辑。 为了更轻松、更简洁地定义路由，Camel 为 Java 或 Groovy 等编程语言提供了几种不同的领域特定语言 (DSL)。另一方面，它还提供了使用 Spring DSL 在 XML 中定义路由。 使用 Java DSL 或 Spring DSL 主要是用户偏好，因为大多数功能都可用。 Java DSL 提供了更多 Spring DSL 不支持的特性。然而，Spring DSL 有时更有益，因为无需重新编译代码即可更改 XML。 4. 术语和架构 现在让我们讨论基本的 Camel 术语和架构。 首先，我们将在这里看一下 Camel 的核心概念：  消息包含正在传输到路由的数据。每条消息都有一个唯一的标识符，它由正文、标题和附件构成 Exchange是消息的容器，它是在消费者在路由过程中收到消息时创建的。Exchange 允许系统之间进行不同类型的交互——它可以定义单向消息或请求-响应消息 端点是系统可以接收或发送消息的通道。它可以引用 Web 服务 URI、队列 URI、文件、电子邮件地址等 组件充当端点工厂。简而言之，组件使用相同的方法和语法为不同的技术提供接口。Camel 已经在其 DSL 中为几乎所有可能的技术支持许多组件，但它也提供了编写自定义组件的能力 Processor是一个简单的 Java 接口，用于向路由添加自定义集成逻辑。它包含一个单一的流程方法，用于在消费者收到的消息上执行自定义业务逻辑  在高层次上，Camel 的架构很简单。CamelContext代表 Camel 运行时系统，它连接不同的概念，例如路由、组件或端点。 在此之下，处理器处理端点之间的路由和转换，而端点则集成不同的系统。 5. 定义路线 可以使用 Java DSL 或 Spring DSL 定义路由。 我们将通过定义一个路由来说明这两种样式，该路由使用一个文件夹中的文件并将它们移动到另一个文件夹，同时为每个文件名添加时间戳。 5.1 使用 Java DSL 进行路由 要使用 Java DSL 定义路由，我们首先需要创建一个DefaultCamelContext实例。之后，我们需要扩展RouteBuilder类并实现包含路由流的配置方法： private static final long DURATION_MILIS = 10000; private static final String SOURCE_FOLDER = \u0026#34;src/test/source-folder\u0026#34;; private static final String DESTINATION_FOLDER = \u0026#34;src/test/destination-folder\u0026#34;; @Test public void moveFolderContentJavaDSLTest() throws Exception { CamelContext camelContext = new DefaultCamelContext(); camelContext.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(\u0026#34;file://\u0026#34; + SOURCE_FOLDER + \u0026#34;?delete=true\u0026#34;).process( new FileProcessor()).to(\u0026#34;file://\u0026#34; + DESTINATION_FOLDER); } }); camelContext.start(); Thread.sleep(DURATION_MILIS); camelContext.stop(); } configure方法可以这样读取：从源文件夹读取文件，使用 FileProcessor 处理它们并将结果发送到目标文件夹。设置delete=true表示文件处理成功后将从源文件夹中删除。 为了启动 Camel，我们需要在CamelContext上调用**start方法。调用Thread.sleep是为了让 Camel 有时间将文件从一个文件夹移动到另一个文件夹。 FileProcessor实现Processor接口并包含单个进程方法，其中包含用于修改文件名的逻辑： public class FileProcessor implements Processor { public void process(Exchange exchange) throws Exception { String originalFileName = (String) exchange.getIn().getHeader( Exchange.FILE_NAME, String.class); Date date = new Date(); SimpleDateFormat dateFormat = new SimpleDateFormat( \u0026#34;yyyy-MM-dd HH-mm-ss\u0026#34;); String changedFileName = dateFormat.format(date) + originalFileName; exchange.getIn().setHeader(Exchange.FILE_NAME, changedFileName); } } 为了检索文件名，我们必须从交换中检索传入消息并访问其标题。与此类似，要修改文件名，我们必须更新消息头。 5.2. 使用 Spring DSL 进行路由 在使用 Spring DSL 定义路由时，我们使用 XML 文件来设置路由和处理器。这允许我们使用 Spring 无需代码即可配置路由，并最终为我们提供了完全控制反转的好处。 这已经在现有文章中介绍过，因此我们将重点关注使用 Spring DSL 和 Java DSL，这通常是定义路由的首选方式。 在这种安排中，CamelContext 是在 Spring XML 文件中使用 Camel 的自定义 XML 语法定义的，但没有像使用 XML 的“纯”Spring DSL 那样的路由定义： \u0026lt;bean id=\u0026#34;fileRouter\u0026#34; class=\u0026#34;com.codingman.camel.file.FileRouter\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;fileProcessor\u0026#34; class=\u0026#34;com.codingman.camel.file.FileProcessor\u0026#34; /\u0026gt; \u0026lt;camelContext xmlns=\u0026#34;http://camel.apache.org/schema/spring\u0026#34;\u0026gt; \u0026lt;routeBuilder ref=\u0026#34;fileRouter\u0026#34; /\u0026gt; \u0026lt;/camelContext\u0026gt; 通过这种方式，我们告诉 Camel 使用FileRouter类，该类包含我们在 Java DSL 中的路由定义： public class FileRouter extends RouteBuilder { private static final String SOURCE_FOLDER = \u0026#34;src/test/source-folder\u0026#34;; private static final String DESTINATION_FOLDER = \u0026#34;src/test/destination-folder\u0026#34;; @Override public void configure() throws Exception { from(\u0026#34;file://\u0026#34; + SOURCE_FOLDER + \u0026#34;?delete=true\u0026#34;).process( new FileProcessor()).to(\u0026#34;file://\u0026#34; + DESTINATION_FOLDER); } } 为了测试这一点，我们必须创建一个ClassPathXmlApplicationContext实例，它将在 Spring 中加载我们的CamelContext： @Test public void moveFolderContentSpringDSLTest() throws InterruptedException { ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;camel-context.xml\u0026#34;); Thread.sleep(DURATION_MILIS); applicationContext.close(); } 通过使用这种方法，我们获得了 Spring 提供的额外灵活性和好处，以及使用 Java DSL 实现 Java 语言的所有可能性。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_camel_intro/","tags":["Apache Camel"],"title":"Apache Camel 简介"},{"categories":["Jakarta EE"],"contents":"1. 简介 在本文中，我们将看看Apache BVal库对Java Bean Validation规范 ( JSR 349 )**的实现。 2. Maven依赖 为了使用Apache BVal，我们首先需要将以下依赖项添加到我们的pom.xml文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.bval\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bval-jsr\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.validation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;validation-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 自定义BVal约束可以在可选的bval-extras依赖项中找到： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.bval\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bval-extras\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本的bval-jsr、bval-extras和validation-api可以从 Maven Central 下载。 3. 应用约束 Apache BVal为**javax.validation包中定义的所有约束提供了实现。为了对 bean 的属性应用约束，我们可以在属性声明中添加约束注解。 让我们创建一个具有四个属性的User类，然后应用*@NotNull*、@Size和*@Min*注释： public class User { @NotNull private String email; private String password; @Size(min=1, max=20) private String name; @Min(18) private int age; // standard constructor, getters, setters } 4. 验证 Bean 要验证应用于User类的约束，我们需要获取一个ValidatorFactory实例和一个或多个Validator实例。 **4.1 获取ValidatorFactory ** Apache BVal文档建议获取此类的单个实例，因为工厂创建是一个要求很高的过程： ValidatorFactory validatorFactory = Validation.byProvider(ApacheValidationProvider.class) .configure().buildValidatorFactory(); **4.2. 获取Validator ** 接下来，我们需要从上面定义的validatorFactory中获取一个Validator实例： Validator validator = validatorFactory.getValidator(); 这是一个线程安全的实现，所以我们可以安全地重用已经创建的实例。 Validator类提供了三种确定 bean 有效性的方法：validate ()、validateProperty()和validateValue()。 这些方法中的每一个都返回一组ConstraintViolation对象，其中包含有关未遵守的约束的信息。 4.3. validate() API *validate()*方法检查整个 bean的有效性，这意味着它验证应用于作为参数传递的对象属性的所有约束。 让我们创建一个JUnit测试，我们在其中定义一个User对象并使用*validate()*方法来测试它的属性： @Test public void givenUser_whenValidate_thenValidationViolations() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;nameTooLong_______________\u0026#34;, 15); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validate(user); assertTrue(\u0026#34;no violations\u0026#34;, violations.size() \u0026gt; 0); } 4.4. validateProperty() API *validateProperty()*方法可用于验证 bean的单个属性。 \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; 让我们创建一个JUnit测试，我们将在其中定义一个年龄属性小于所需最小值 18的User对象，并验证验证此属性是否会导致一次违规： @Test public void givenInvalidAge_whenValidateProperty_thenConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;Ana\u0026#34;, 12); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; propertyViolations = validator.validateProperty(user, \u0026#34;age\u0026#34;); assertEquals(\u0026#34;size is not 1\u0026#34;, 1, propertyViolations.size()); } 4.5. validateValue() API *validateValue()*方法可用于在将某个值设置到 bean 之前检查某个值是否是 bean 属性的有效值。 让我们使用User对象创建一个JUnit测试，然后验证值20是否是**age属性的有效值： @Test public void givenValidAge_whenValidateValue_thenNoConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;Ana\u0026#34;, 18); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; valueViolations = validator.validateValue(User.class, \u0026#34;age\u0026#34;, 20); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, valueViolations.size()); } 4.6. 关闭ValidatorFactory 使用ValidatorFactory后，我们必须记得在最后关闭它： if (validatorFactory != null) { validatorFactory.close(); } 5. 非JSR约束 Apache BVal库还提供了一系列不属于JSR规范的约束，并提供了额外的更强大的验证功能。 bval -jsr包包含两个附加约束：@Email用于验证有效的电子邮件地址，@NotEmpty用于确保值不为空。 其余的自定义BVal约束在可选包bval-extras中提供。 此包包含**用于验证各种数字格式的约束，例如确保数字是有效国际银行帐号的@IBAN注释、验证有效标准书号的 @Isbn 注释和验证国际文章编号的@ EAN13注释. \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; 该库还提供注释以确保各种类型的信用卡号的有效性： @AmericanExpress、 @Diners 、@Discover、@Mastercard和*@Visa*。 您可以使用*@Domain和@InetAddress*注释来确定一个值是否包含有效的域或Internet 地址。 最后，该包包含*@Directory和@NotDirectory注释，用于**验证File*对象是否为目录**。 让我们在User类上定义额外的属性，并将一些非JSR注释应用到它们： public class User { @NotNull @Email private String email; @NotEmpty private String password; @Size(min=1, max=20) private String name; @Min(18) private int age; @Visa private String cardNumber = \u0026#34;\u0026#34;; @IBAN private String iban = \u0026#34;\u0026#34;; @InetAddress private String website = \u0026#34;\u0026#34;; @Directory private File mainDirectory = new File(\u0026#34;.\u0026#34;); // standard constructor, getters, setters } 可以以与JSR约束类似的方式测试约束： @Test public void whenValidateNonJSR_thenCorrect() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;pass\u0026#34;, \u0026#34;Ana\u0026#34;, 20); user.setCardNumber(\u0026#34;1234\u0026#34;); user.setIban(\u0026#34;1234\u0026#34;); user.setWebsite(\u0026#34;10.0.2.50\u0026#34;); user.setMainDirectory(new File(\u0026#34;.\u0026#34;)); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validateProperty(user,\u0026#34;iban\u0026#34;); assertEquals(\u0026#34;size is not 1\u0026#34;, 1, violations.size()); violations = validator.validateProperty(user,\u0026#34;website\u0026#34;); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, violations.size()); violations = validator.validateProperty(user, \u0026#34;mainDirectory\u0026#34;); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, violations.size()); } 虽然这些额外的注解可以方便地满足潜在的验证需求，但使用不属于JSR规范的注解的一个缺点是，如果以后有必要，您不能轻易地切换到不同的JSR实现。 6. 自定义约束 为了定义我们自己的约束，我们首先需要按照标准语法创建一个注解。 让我们创建一个密码注释，它将定义用户密码必须满足的条件： \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; @Constraint(validatedBy = { PasswordValidator.class }) @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER }) @Retention(RetentionPolicy.RUNTIME) public @interface Password { String message() default \u0026#34;Invalid password\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; int length() default 6; int nonAlpha() default 1; } ** 密码值的实际验证是在一个实现ConstraintValidator接口**的类中完成的——在我们的例子中，是PasswordValidator类。此类重写isValid()方法并验证密码的长度是否小于length属性，以及是否包含少于nonAlpha属性中指定数量的非字母数字字符： public class PasswordValidator implements ConstraintValidator\u0026lt;Password, String\u0026gt; { private int length; private int nonAlpha; @Override public void initialize(Password password) { this.length = password.length(); this.nonAlpha = password.nonAlpha(); } @Override public boolean isValid(String value, ConstraintValidatorContext ctx) { if (value.length() \u0026lt; length) { return false; } int nonAlphaNr = 0; for (int i = 0; i \u0026lt; value.length(); i++) { if (!Character.isLetterOrDigit(value.charAt(i))) { nonAlphaNr++; } } if (nonAlphaNr \u0026lt; nonAlpha) { return false; } return true; } } 让我们将自定义约束应用于User类的密码属性： @Password(length = 8) private String password; 我们可以创建一个JUnit测试来验证无​​效的密码值是否会导致违反约束： @Test public void givenValidPassword_whenValidatePassword_thenNoConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;Ana\u0026#34;, 20); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validateProperty(user, \u0026#34;password\u0026#34;); assertEquals( \u0026#34;message incorrect\u0026#34;, \u0026#34;Invalid password\u0026#34;, violations.iterator().next().getMessage()); } 现在让我们创建一个JUnit测试，在其中我们验证一个有效的密码值： @Test public void givenValidPassword_whenValidatePassword_thenNoConstraintViolation() { User user = new User(\u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;password#\u0026#34;, \u0026#34;Ana\u0026#34;, 20); Set\u0026lt;ConstraintViolation\u0026lt;User\u0026gt;\u0026gt; violations = validator.validateProperty(user, \u0026#34;password\u0026#34;); assertEquals(\u0026#34;size is not 0\u0026#34;, 0, violations.size()); } \u0026quot; ","permalink":"http://itcodingman.github.io/apache_bval/","tags":[],"title":"Apache BVal 简介"},{"categories":["Data"],"contents":" 概述   在本教程中，我们将介绍 Apache Beam 并探索其基本概念。 我们将首先展示使用 Apache Beam 的用例和好处，然后我们将介绍基本概念和术语。之后，我们将通过一个简单的示例来说明 Apache Beam 的所有重要方面。 什么是 Apache Beam？   **Apache Beam (Batch + strEAM) 是用于批处理和流式数据处理作业的统一编程模型。**它提供了一个软件开发工具包来定义和构建数据处理管道以及执行它们的运行器。 **Apache Beam 旨在提供可移植的编程层。**事实上，Beam Pipeline Runners 将数据处理管道转换为与用户选择的后端兼容的 API。目前，支持这些分布式处理后端：  Apache Apex Apache Flink Apache Gearpump (incubating) Apache Samza Apache Spark Google Cloud Dataflow Hazelcast Jet  为什么选择 Apache Beam？   **Apache Beam 融合了批处理和流式数据处理，而其他人通常通过单独的 API 来实现。**因此，很容易将流式流程更改为批处理流程，反之亦然，例如，随着需求的变化。 **Apache Beam 提高了可移植性和灵活性。**我们专注于我们的逻辑而不是潜在的细节。此外，我们可以随时更改数据处理后端。 有适用于 Apache Beam 的 Java、Python、Go 和 Scala SDK。事实上，团队中的每个人都可以使用他们选择的语言来使用它。 基本概念   使用 Apache Beam，我们可以构建工作流图（管道）并执行它们。编程模型中的关键概念是：  PCollection – 表示可以是固定批次或数据流的数据集 PTransform – 一种数据处理操作，采用一个或多个PCollection并输出零个或多个PCollection Pipeline – 表示PCollection 和PTransform的有向无环图，因此封装了整个数据处理作业 PipelineRunner –在指定的分布式处理后端执行Pipeline  简单来说，一个PipelineRunner执行一个Pipeline， 一个Pipeline由PCollection 和PTransform组成。 字数统计示例   现在我们已经了解了 Apache Beam 的基本概念，让我们设计和测试一个字数统计任务。 5.1 构建Beam管道 设计工作流图是每个 Apache Beam 作业的第一步。让我们定义一个字数统计任务的步骤：  从来源阅读文本。 将文本拆分为单词列表。 小写所有单词。 修剪标点符号。 过滤停用词。 计算每个唯一的单词。  为此，我们需要使用PCollection和PTransform抽象将上述步骤转换为单个管道。 5.2. 依赖项 在我们实现工作流图之前，我们应该将Apache Beam 的核心依赖添加到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.beam\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;beam-sdks-java-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${beam.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Beam Pipeline Runners 依靠分布式处理后端来执行任务。让我们添加DirectRunner作为运行时依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.beam\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;beam-runners-direct-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${beam.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 与其他 Pipeline Runners 不同，DirectRunner不需要任何额外的设置，这使其成为初学者的不错选择。 5.3. 执行 Apache Beam 利用 Map-Reduce 编程范式（与Java Streams相同）。事实上，在我们继续之前，有一个reduce()、filter()、count()、map()和flatMap()的基本概念是个好主意。 创建管道是我们要做的第一件事： PipelineOptions options = PipelineOptionsFactory.create(); Pipeline p = Pipeline.create(options); 现在我们应用我们的六步字数统计任务： PCollection\u0026lt;KV\u0026lt;String, Long\u0026gt;\u0026gt; wordCount = p .apply(\u0026#34;(1) Read all lines\u0026#34;, TextIO.read().from(inputFilePath)) .apply(\u0026#34;(2) Flatmap to a list of words\u0026#34;, FlatMapElements.into(TypeDescriptors.strings()) .via(line -\u0026gt; Arrays.asList(line.split(\u0026#34;\\\\s\u0026#34;)))) .apply(\u0026#34;(3) Lowercase all\u0026#34;, MapElements.into(TypeDescriptors.strings()) .via(word -\u0026gt; word.toLowerCase())) .apply(\u0026#34;(4) Trim punctuations\u0026#34;, MapElements.into(TypeDescriptors.strings()) .via(word -\u0026gt; trim(word))) .apply(\u0026#34;(5) Filter stopwords\u0026#34;, Filter.by(word -\u0026gt; !isStopWord(word))) .apply(\u0026#34;(6) Count words\u0026#34;, Count.perElement()); apply()的第一个（可选）参数是一个字符串，它只是为了提高代码的可读性。以下是上述代码中每个apply()的作用：  首先，我们使用TextIO 逐行读取输入文本文件。 用空格分割每一行，我们将它平面映射到一个单词列表。 字数不区分大小写，因此我们将所有单词小写。 早些时候，我们用空格分割行，最后得到像“word！”这样的词。和“单词？”，所以我们删除了标点符号。 “is”和“by”等停用词几乎在每个英文文本中都很常见，因此我们将它们删除。 最后，我们使用内置函数*Count.perElement()*计算唯一词。  如前所述，管道在分布式后端进行处理。不可能在内存中迭代PCollection，因为它分布在多个后端。相反，我们将结果写入外部数据库或文件。 首先，我们将PCollection转换为String。然后，我们使用TextIO来编写输出： wordCount.apply(MapElements.into(TypeDescriptors.strings()) .via(count -\u0026gt; count.getKey() + \u0026#34; --\u0026gt; \u0026#34; + count.getValue())) .apply(TextIO.write().to(outputFilePath)); 现在我们的Pipeline定义已经完成，我们可以运行和测试它。 5.4. 运行和测试 到目前为止，我们已经为字数统计任务定义了一个流水线。此时，让我们运行Pipeline： p.run().waitUntilFinish(); 在这行代码中，Apache Beam 会将我们的任务发送到多个DirectRunner实例。因此，最后将生成几个输出文件。它们将包含以下内容： ... apache --\u0026gt; 3 beam --\u0026gt; 5 rocks --\u0026gt; 2 ... 在 Apache Beam 中定义和运行分布式作业就像这样简单而富有表现力。为了比较，Apache Spark、Apache Flink和Hazelcast Jet上也提供了字数统计实现。 我们从这里走向何方？   我们成功地计算了输入文件中的每个单词，但我们还没有最常见单词的报告。当然，对PCollection进行排序是我们下一步要解决的好问题。 稍后，我们可以了解更多关于 Windowing、Triggers、Metrics 和更复杂的 Transforms 的知识。Apache Beam 文档提供了深入的信息和参考资料。 \u0026quot; ","permalink":"http://itcodingman.github.io/apache_beam/","tags":[],"title":"Apache Beam 简介"},{"categories":["Architecture"],"contents":" 概述   在分布式架构中，应用程序通常需要在它们之间交换数据。一方面，这可以通过彼此直接通信来完成。另一方面，为了达到高可用性和分区容错，以及在应用程序之间获得松耦合，消息传递是一个合适的解决方案。 因此，我们可以在多种产品之间进行选择。Apache 基金会提供了 ActiveMQ 和 Kafka，我们将在本文中对它们进行比较。 一般情况   2.1 Active MQ **Active MQ 是传统的消息代理之一，其目标是确保应用程序之间的数据交换以安全可靠的方式进行。**它处理少量数据，因此专门用于定义良好的消息格式和事务消息传递。 我们必须注意，除了这个“经典”版本之外，还有另一个版本：Active MQ Artemis。这个下一代代理基于 HornetQ，其代码于 2015 年由 RedHat 提供给 Apache 基金会。在Active MQ 网站上，据说：  一旦 Artemis 与“经典”代码库达到足够的功能对等水平，它将成为 ActiveMQ 的下一个主要版本。  因此，为了进行比较，我们需要考虑两个版本。*我们将使用术语“Active MQ”和“Artemis”*来区分它们。 2.2. Kafka 与 Active MQ 相比，**Kafka 是一个分布式系统，旨在处理大量数据。**我们可以将其用于传统消息传递以及：  网站活动跟踪 指标 日志聚合 流处理 事件溯源 提交日志  随着使用微服务构建的典型云架构的出现，这些要求变得非常重要。 2.3. JMS 的作用和消息传递的演变 Java 消息服务 (JMS) 是用于在 Java EE 应用程序中发送和接收消息的通用 API。它是消息传递系统早期发展的一部分，今天它仍然是一个标准。在 Jakarta EE 中，它被采用为Jakarta Messaging。因此，了解核心概念可能会有所帮助：   Java 原生但独立于供应商的 API   需要JCA 资源适配器来实现特定于供应商的通信协议   消息目标模型：  队列( P2P ) 确保消息排序和一次性消息处理，即使在多个消费者的情况下 主题（PubSub）作为发布-订阅模式的实现，这意味着多个消费者将在订阅主题期间接收消息    消息格式：  标头作为经纪人处理的标准化元信息（如优先级或到期日期） 消费者可用于消息处理的非标准化元信息的属性 包含有效负载的Body – JMS 声明了五种类型的消息，但这仅与使用 API 有关，与此比较无关    **然而，演变朝着一个开放和独立的方向发展——独立于消费者和生产者的平台，独立于消息代理的供应商。**有一些协议定义了自己的目标模型：  AMQP —— 独立于供应商的消息传递的二进制协议——使用通用节点 MQTT —— 嵌入式系统和物联网的轻量级二进制协议——使用主题 STOMP —— 一个简单的基于文本的协议，甚至允许从浏览器发送消息 – 使用通用目的地  **另一项发展是通过云架构的传播，根据“即发即弃”原则，将以前可靠的单个消息传输（“传统消息传递”）添加到处理大量数据中。**可以说，Active MQ 和 Kafka 的比较是对这两种方法的典型代表的比较。例如，Kafka 的替代品可能是NATS。 3.比较 在本节中，我们将比较 Active MQ 和 Kafka 在架构和开发方面最有趣的特性。 3.1 消息目标模型、协议和 API Active MQ 完全实现了Queues和Topics的 JMS 消息目的地模型，并将 AMQP、MQTT 和 STOMP 消息映射到它们。例如，STOMP 消息映射到Topic中的 JMS BytesMessage。此外，它还支持OpenWire，它允许跨语言访问 Active MQ。 Artemis 独立于标准 API 和协议定义了自己的消息目标模型，并且还需要将它们映射到此模型：   消息被发送到一个Address，它被赋予一个唯一的名称、一个Routing Type和零个或多个Queues。   路由类型确定消息如何从地址路由到绑定到该地址的队列。定义了两种类型：  ANYCAST：消息被路由到地址上的单个队列 MULTICAST：消息被路由到地址上的每个队列    Kafka 只定义了Topics，它由多个Partition（至少 1 个）和可以放置在不同 broker 上的 Replica*组成。*找到划分主题的最佳策略是一项挑战。我们必须注意：  一条消息被分配到一个分区中。 只有一个分区内的消息才能保证排序。 默认情况下，后续消息在主题的分区之间循环分发。 如果我们使用消息键，那么具有相同键的消息将落在同一个分区中。  Kafka 有自己的API。虽然也有JMS 的资源适配器，但我们应该知道这些概念并不完全兼容。官方不支持 AMQP、MQTT 和 STOMP，但有AMQP和MQTT的连接器。 3.2. 消息格式和处理 Active MQ 支持由标头、属性和正文组成的 JMS 标准消息格式（如上所述）。代理必须维护每条消息的传递状态，从而导致吞吐量降低。由于它受 JMS 支持，消费者可以从目标同步拉取消息，或者消息可以由代理异步推送。 Kafka 没有定义任何消息格式——这完全是生产者的责任。每条消息没有任何传递状态，只有每个消费者和分区的偏移量。**Offset是最后发送的消息的索引。这不仅更快，而且还允许通过重置偏移量来重新发送消息，而无需询问生产者。 3.3. Spring 和 CDI 集成 JMS 是 Java/Jakarta EE 标准，因此完全集成到 Java/Jakarta EE 应用程序中。因此，与 Active MQ 和 Artemis 的连接很容易由应用程序服务器管理。使用 Artemis，我们甚至可以使用嵌入式代理。对于 Kafka，托管连接仅在使用Resource Adapter for JMS或Eclipse MicroProfile Reactive时可用。 Spring 集成了JMS以及AMQP、MQTT和STOMP。还支持kafka。借助 Spring Boot，我们可以为Active MQ、Artemis和Kafka使用嵌入式代理。 Active MQ/Artemis 和 Kafka 用例   以下几点为我们指明了何时最好使用哪种产品。 4.1 Active MQ/Artemis 的用例  每天只处理少量消息 高水平的可靠性和事务性 即时数据转换，ETL 作业  4.2. Kafka的用例   处理大量数据  实时数据处理 应用程序活动跟踪 记录和监控    无需数据转换的消息传递（有可能，但并不容易）   没有传输保证的消息传递（有可能，但不容易）   Active MQ 和 Kafka 的区别      标准 活动 MQ 经典 活跃的 MQ 阿尔忒弥斯 卡夫卡     用例 传统消息传递（可靠、事务性） 分布式事件流    P2P 消息传递 尾巴 路由类型为 ANYCAST 的地址 –   PubSub 消息传递 话题 路由类型为 MULTICAST 的地址 话题   API / 协议 JMS，AMQP。MQTT、STOMP、OpenWire Kafka 客户端、AMQP 和 MQTT 连接器、JMS 资源适配器    拉式与推送式消息传递 基于推送 基于拉的    消息传递的责任 生产者必须确保消息被传递 消费者消费它应该消费的消息    交易支持 JMS, XA 自定义事务管理器    可扩展性 经纪人网络 集群 高度可扩展（分区和副本）   消费者越多…… …性能越慢 ……不减速    \u0026quot;       ","permalink":"http://itcodingman.github.io/apache_activemq_vs_kafka/","tags":["Kafka"],"title":"Apache ActiveMQ 与 Kafka"},{"categories":["DevOps","Gradle","Maven"],"contents":"1. 简介 在本文中，我们将探讨主导 JVM 生态系统的三个 Java 构建自动化工具——Ant、Maven 和 Gradle。 我们将介绍它们中的每一个，并探索 Java 构建自动化工具是如何演变的。 2. Apache Ant 一开始，Make是唯一一款超越本土解决方案的构建自动化工具。Make 自 1976 年以来一直存在，因此，它在 Java 早期用于构建 Java 应用程序。 但是，C 程序的许多约定并不适合 Java 生态系统，因此 Ant 及时取代了它作为更好的选择。 Apache Ant（“Another Neat Tool”）是一个 Java 库，用于自动化 Java 应用程序的构建过程。此外，Ant 可用于构建非 Java 应用程序。它最初是 Apache Tomcat 代码库的一部分，并于 2000 年作为独立项目发布。 在许多方面，Ant 与 Make 非常相似，而且它非常简单，因此任何人都可以在没有任何特定先决条件的情况下开始使用它。Ant 构建文件是用 XML 编写的，按照惯例，它们被称为build.xml。 构建过程的不同阶段称为“target”。 下面是一个带有HelloWorld主类的简单 Java 项目的build.xml文件示例： \u0026lt;project\u0026gt; \u0026lt;target name=\u0026#34;clean\u0026#34;\u0026gt; \u0026lt;delete dir=\u0026#34;classes\u0026#34; /\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;compile\u0026#34; depends=\u0026#34;clean\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;classes\u0026#34; /\u0026gt; \u0026lt;javac srcdir=\u0026#34;src\u0026#34; destdir=\u0026#34;classes\u0026#34; /\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;jar\u0026#34; depends=\u0026#34;compile\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;jar\u0026#34; /\u0026gt; \u0026lt;jar destfile=\u0026#34;jar/HelloWorld.jar\u0026#34; basedir=\u0026#34;classes\u0026#34;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name=\u0026#34;Main-Class\u0026#34; value=\u0026#34;antExample.HelloWorld\u0026#34; /\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;run\u0026#34; depends=\u0026#34;jar\u0026#34;\u0026gt; \u0026lt;java jar=\u0026#34;jar/HelloWorld.jar\u0026#34; fork=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt; 该构建文件定义了四个目标：clean、compile、jar和run。例如，我们可以通过运行来编译代码： ant compile 这将首先触发目标clean，这将删除“classes”目录。之后，目标compile将重新创建目录并将 src 文件夹编译到其中。 **Ant 的主要优点是它的灵活性。Ant 没有强加任何编码约定或项目结构。**因此，这意味着 Ant 需要开发人员自己编写所有命令，这有时会导致难以维护的巨大 XML 构建文件。 由于没有约定，只知道 Ant 并不意味着我们会很快理解任何 Ant 构建文件。习惯一个不熟悉的 Ant 文件可能需要一些时间，与其他较新的工具相比，这是一个劣势。 起初，Ant 没有对依赖管理的内置支持。然而，随着依赖管理在后来的几年中成为必须，Apache Ivy被开发为 Apache Ant 项目的子项目。它与 Apache Ant 集成，并且遵循相同的设计原则。 然而，最初的 Ant 限制是由于没有对依赖管理的内置支持以及在处理不可管理的 XML 构建文件时的挫败感，这导致了 Maven 的创建。 3. Apache Maven Apache Maven是一个依赖管理和构建自动化工具，主要用于 Java 应用程序。**Maven 继续像 Ant 一样使用 XML 文件，但以一种更易于管理的方式。**这里的游戏名称是约定优于配置。 Ant 提供了灵活性并要求一切从头开始编写，而Maven 依赖于约定并提供预定义的命令（目标）。 简而言之，Maven 允许我们专注于构建应该做什么，并为我们提供了框架来完成它。Maven 的另一个积极方面是它为依赖管理提供了内置支持。 Maven 的配置文件，包含构建和依赖管理指令，按照约定称为pom.xml。此外，Maven 还规定了严格的项目结构，而 Ant 也提供了灵活性。 下面是一个pom.xml文件示例，用于与之前的HelloWorld主类相同的简单 Java 项目： \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;codingman\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mavenExample\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;description\u0026gt;Maven example\u0026lt;/description\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.12\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 但是，现在项目结构也已经标准化，并且符合 Maven 约定： +---src | +---main | | +---java | | | \\---com | | | \\---codingman | | | \\---maven | | | HelloWorld.java | | | | | \\---resources | \\---test | +---java | \\---resources 与 Ant 相比，无需手动定义构建过程中的每个阶段。相反，我们可以简单地调用 Maven 的内置命令。 例如，我们可以通过运行来编译代码： mvn compile 正如官方页面所指出的，**Maven 的核心可以被认为是一个插件执行框架，因为所有工作都是由插件完成的。**Maven 支持范围广泛的可用插件，每个插件都可以额外配置。 可用的插件之一是 Apache Maven 依赖插件，它有一个复制依赖目标，它将我们的依赖复制到指定的目录。 为了展示这个插件，让我们在pom.xml文件中包含这个插件，并为我们的依赖项配置一个输出目录： \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-dependency-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;copy-dependencies\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;copy-dependencies\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;outputDirectory\u0026gt;target/dependencies \u0026lt;/outputDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 这个插件将在package阶段执行，所以如果我们运行： mvn package 我们将执行此插件并将依赖项复制到 target/dependencies 文件夹。 还有一篇关于如何使用不同的 Maven 插件创建可执行 JAR 的文章。此外，有关 Maven 的详细概述，请查看有关 Maven 的核心指南，其中探讨了 Maven 的一些关键特性。 Maven 变得非常流行，因为构建文件现在已经标准化，并且与 Ant 相比，维护构建文件所需的时间明显减少。然而，尽管比 Ant 文件更标准化，Maven 配置文件仍然趋于变得庞大和繁琐。 **Maven 的严格约定的代价是灵活性不如 Ant。**目标定制非常困难，因此与 Ant 相比，编写定制构建脚本要困难得多。 尽管 Maven 在使应用程序的构建过程更容易和更标准化方面做出了一些重大改进，但由于比 Ant 灵活得多，它仍然要付出代价。这导致了 Gradle 的创建，它结合了两全其美——Ant 的灵活性和 Maven 的特性。 4. Gradle Gradle是一个依赖管理和构建自动化工具，它建立在 Ant 和 Maven 的概念之上。 关于 Gradle，我们首先要注意的一点是它不使用 XML 文件，这与 Ant 或 Maven 不同。 随着时间的推移，开发人员对拥有和使用特定领域的语言越来越感兴趣——简单地说，这将允许他们使用为特定领域量身定制的语言来解决特定领域中的问题。 这被 Gradle 采用，它使用基于Groovy或Kotlin的 DSL 。**由于该语言是专门为解决特定领域问题而设计的，因此这导致了更小的配置文件和更少的混乱。**Gradle 的配置文件按照惯例在 Groovy 中称为build.gradle ，在 Kotlin中称为build.gradle.kts 。 请注意，Kotlin 在自动完成和错误检测方面提供了比 Groovy 更好的 IDE 支持。 下面是一个build.gradle文件的示例，用于与之前的**HelloWorld主类相同的简单 Java 项目： apply plugin: \u0026#39;java\u0026#39; repositories { mavenCentral() } jar { baseName = \u0026#39;gradleExample\u0026#39; version = \u0026#39;0.0.1-SNAPSHOT\u0026#39; } dependencies { testImplementation \u0026#39;junit:junit:4.12\u0026#39; } 我们可以通过运行来编译代码： gradle classes Gradle 的核心是有意提供很少的功能。**插件添加了所有有用的功能。**在我们的示例中，我们使用了java插件，它允许我们编译 Java 代码和其他有价值的功能。 **Gradle 将其构建步骤命名为“任务”，而不是 Ant 的“目标”或 Maven 的“阶段”。**在 Maven 中，我们使用了 Apache Maven Dependency Plugin，将依赖项复制到指定目录是一个特定的目标。使用 Gradle，我们可以使用任务来做同样的事情： task copyDependencies(type: Copy) { from configurations.compile into \u0026#39;dependencies\u0026#39; } 我们可以通过执行以下命令来运行此任务： gradle copyDependencies \u0026quot; ","permalink":"http://itcodingman.github.io/ant_maven_gradle/","tags":[],"title":"Ant vs Maven vs Gradle"},{"categories":["REST","Spring Data"],"contents":"1. 概述 在本教程中，我们将创建一个简单的 CRUD 应用程序示例，使用 AngularJS 作为前端，使用 Spring Data REST 作为后端。 2. 创建 REST 数据服务 为了创建对持久性的支持，我们将使用 Spring Data REST 规范，该规范将使我们能够对数据模型执行 CRUD 操作。 您可以在Spring Data REST 简介中找到有关如何设置 REST 端点的所有必要信息。在本文中，我们将重用我们为介绍教程设置的现有项目。 对于持久性，我们将使用内存数据库中的H2。 作为数据模型，上一篇文章定义了一个WebsiteUser类，具有id、name和email属性以及一个名为UserRepository的存储库接口。 定义此接口指示 Spring 创建对公开 REST 集合资源和项目资源的支持。现在让我们仔细看看我们稍后将从AngularJS调用的端点。 2.1 Collection资源 我们将在端点*/users*处获得所有用户的列表。可以使用 GET 方法调用此 URL，并将返回以下形式的 JSON 对象： { \u0026#34;_embedded\u0026#34; : { \u0026#34;users\u0026#34; : [ { \u0026#34;name\u0026#34; : \u0026#34;Bryan\u0026#34;, \u0026#34;age\u0026#34; : 20, \u0026#34;_links\u0026#34; : { \u0026#34;self\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; }, \u0026#34;User\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; } } }, ... ] } } 2.2. Item资源 可以通过使用不同的 HTTP 方法和请求有效负载访问*/users/{userID}形式的 URL 来操作单个WebsiteUser对象。* 为了检索WebsiteUser对象，我们可以使用GET 方法访问*/users/{userID} 。*这将返回以下形式的 JSON 对象： { \u0026#34;name\u0026#34; : \u0026#34;Bryan\u0026#34;, \u0026#34;email\u0026#34; : \u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;, \u0026#34;_links\u0026#34; : { \u0026#34;self\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; }, \u0026#34;User\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/users/1\u0026#34; } } } 要添加新的WebsiteUser，我们需要使用 POST 方法调用*/users* 。新的WebsiteUser记录的属性将作为 JSON 对象添加到请求正文中： \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; {name: \u0026#34;Bryan\u0026#34;, email: \u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;} 如果没有错误，此 URL 将返回状态代码 201 CREATED。 如果我们想更新WebsiteUser记录的属性，我们需要使用 PATCH 方法和包含新值的请求正文调用 URL /users/{UserID} ： {name: \u0026#34;Bryan\u0026#34;, email: \u0026#34;[[email protected]](cdn-cgi/l/email-protection)\u0026#34;} 要删除WebsiteUser记录，我们可以使用 DELETE 方法调用 URL */users/{UserID} 。*如果没有错误，则返回状态码 204 NO CONTENT。 2.3. MVC 配置 我们还将添加一个基本的 MVC 配置以在我们的应用程序中显示 html 文件： @Configuration @EnableWebMvc public class MvcConfig implements WebMvcConfigurer { public MvcConfig(){ super(); } @Override public void configureDefaultServletHandling( DefaultServletHandlerConfigurer configurer) { configurer.enable(); } @Bean WebServerFactoryCustomizer\u0026lt;ConfigurableServletWebServerFactory\u0026gt; enableDefaultServlet() { return (factory) -\u0026gt; factory.setRegisterDefaultServlet(true); } } 2.4. 允许跨域请求 如果我们想将AngularJS前端应用程序与 REST API 分开部署——那么我们需要启用跨域请求。 \u0026lt;script data-cfasync=\u0026#34;false\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt; Spring Data REST 从版本 1.5.0.RELEASE 开始添加了对此的支持。要允许来自不同域的请求，您只需将*@CrossOrigin*注释添加到存储库： @CrossOrigin @RepositoryRestResource(collectionResourceRel = \u0026#34;users\u0026#34;, path = \u0026#34;users\u0026#34;) public interface UserRepository extends CrudRepository\u0026lt;WebsiteUser, Long\u0026gt; {} 因此，在来自 REST 端点的每个响应中，都会添加一个Access-Control-Allow-Origin标头。 3. 创建 AngularJS 客户端 为了创建我们的 CRUD 应用程序的前端，我们将使用*AngularJS——*一个众所周知的 JavaScript 框架，它简化了前端应用程序的创建。 为了使用AngularJS，我们首先需要在我们的 html 页面中包含angular.min.js文件，该文件将被称为users.html： \u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/angularjs/1.5.6/angular.min.js\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 接下来，我们需要创建一个 Angular 模块、控制器和服务，它们将调用 REST 端点并显示返回的数据。 这些将被放置在一个名为app.js的 JavaScript 文件中，该文件也需要包含在users.html页面中： \u0026lt;script src=\u0026#34;view/app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 3.1 Angular服务 首先，让我们创建一个名为UserCRUDService的 Angular 服务，它将利用注入的AngularJS $http服务来调用服务器。每个调用都将放在一个单独的方法中。 让我们看一下使用*/users/{userID}*端点定义通过 id 检索用户的方法： app.service(\u0026#39;UserCRUDService\u0026#39;, [ \u0026#39;$http\u0026#39;, function($http) { this.getUser = function getUser(userId) { return $http({ method : \u0026#39;GET\u0026#39;, url : \u0026#39;users/\u0026#39; + userId }); } } ]); 接下来，让我们定义addUser方法，该方法向**/users URL 发出POST 请求，并在data属性中发送用户值： this.addUser = function addUser(name, email) { return $http({ method : \u0026#39;POST\u0026#39;, url : \u0026#39;users\u0026#39;, data : { name : name, email: email } }); } updateUser方法与上面的方法类似，不同之处在于它将有一个id参数并发出 PATCH 请求： this.updateUser = function updateUser(id, name, email) { return $http({ method : \u0026#39;PATCH\u0026#39;, url : \u0026#39;users/\u0026#39; + id, data : { name : name, email: email } }); } 删除WebsiteUser记录的方法会发出 DELETE 请求： this.deleteUser = function deleteUser(id) { return $http({ method : \u0026#39;DELETE\u0026#39;, url : \u0026#39;users/\u0026#39; + id }) } 最后，让我们看一下检索整个用户列表的方法： this.getAllUsers = function getAllUsers() { return $http({ method : \u0026#39;GET\u0026#39;, url : \u0026#39;users\u0026#39; }); } 所有这些服务方法都将由AngularJS控制器调用。 3.2. Angular控制器 我们将创建一个UserCRUDCtrl AngularJS控制器，该控制器将注入一个UserCRUDService并使用服务方法从服务器获取响应，处理成功和错误情况，并设置包含响应数据的*$scope*变量以在 HTML 页面中显示它. 我们看一下调用getUser(userId)服务函数的getUser( )函数，定义了成功和错误的两个回调方法。如果服务器请求成功，则将响应保存在用户变量中；否则，将处理错误消息： app.controller(\u0026#39;UserCRUDCtrl\u0026#39;, [\u0026#39;$scope\u0026#39;,\u0026#39;UserCRUDService\u0026#39;, function ($scope,UserCRUDService) { $scope.getUser = function () { var id = $scope.user.id; UserCRUDService.getUser($scope.user.id) .then(function success(response) { $scope.user = response.data; $scope.user.id = id; $scope.message=\u0026#39;\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error (response) { $scope.message = \u0026#39;\u0026#39;; if (response.status === 404){ $scope.errorMessage = \u0026#39;User not found!\u0026#39;; } else { $scope.errorMessage = \u0026#34;Error getting user!\u0026#34;; } }); }; }]); *addUser()*函数将调用相应的服务函数并处理响应： $scope.addUser = function () { if ($scope.user != null \u0026amp;\u0026amp; $scope.user.name) { UserCRUDService.addUser($scope.user.name, $scope.user.email) .then (function success(response){ $scope.message = \u0026#39;User added!\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error(response){ $scope.errorMessage = \u0026#39;Error adding user!\u0026#39;; $scope.message = \u0026#39;\u0026#39;; }); } else { $scope.errorMessage = \u0026#39;Please enter a name!\u0026#39;; $scope.message = \u0026#39;\u0026#39;; } } *updateUser()和deleteUser()*函数与上面的函数类似： $scope.updateUser = function () { UserCRUDService.updateUser($scope.user.id, $scope.user.name, $scope.user.email) .then(function success(response) { $scope.message = \u0026#39;User data updated!\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error(response) { $scope.errorMessage = \u0026#39;Error updating user!\u0026#39;; $scope.message = \u0026#39;\u0026#39;; }); } $scope.deleteUser = function () { UserCRUDService.deleteUser($scope.user.id) .then (function success(response) { $scope.message = \u0026#39;User deleted!\u0026#39;; $scope.User = null; $scope.errorMessage=\u0026#39;\u0026#39;; }, function error(response) { $scope.errorMessage = \u0026#39;Error deleting user!\u0026#39;; $scope.message=\u0026#39;\u0026#39;; }); } 最后，让我们定义检索用户列表并将其存储在users变量中的函数： $scope.getAllUsers = function () { UserCRUDService.getAllUsers() .then(function success(response) { $scope.users = response.data._embedded.users; $scope.message=\u0026#39;\u0026#39;; $scope.errorMessage = \u0026#39;\u0026#39;; }, function error (response) { $scope.message=\u0026#39;\u0026#39;; $scope.errorMessage = \u0026#39;Error getting users!\u0026#39;; }); } 3.3. 网页 users.html页面将使用上一节中定义的控制器函数和存储的变量*。* 首先，为了使用 Angular 模块，我们需要设置ng-app属性： \u0026lt;html ng-app=\u0026#34;app\u0026#34;\u0026gt; 然后，为了避免每次使用控制器的函数时都输入UserCRUDCtrl.getUser()，我们可以将 HTML 元素包装在一个带有ng-controller属性集的div中： \u0026lt;div ng-controller=\u0026#34;UserCRUDCtrl\u0026#34;\u0026gt; 让我们创建一个表单来输入和显示我们想要操作的WebiteUser对象的值。其中每一个都有一个ng-model属性集，它将它绑定到属性的值： \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td width=\u0026#34;100\u0026#34;\u0026gt;ID:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;id\u0026#34; ng-model=\u0026#34;user.id\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td width=\u0026#34;100\u0026#34;\u0026gt;Name:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;name\u0026#34; ng-model=\u0026#34;user.name\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td width=\u0026#34;100\u0026#34;\u0026gt;Age:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;age\u0026#34; ng-model=\u0026#34;user.email\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; 例如，将id输入绑定到user.id变量意味着每当输入的值发生更改时，都会在user.id变量中设置该值，反之亦然。 接下来，让我们使用ng-click属性来定义将触发调用定义的每个 CRUD 控制器函数的链接： \u0026lt;a ng-click=\u0026#34;getUser(user.id)\u0026#34;\u0026gt;Get User\u0026lt;/a\u0026gt; \u0026lt;a ng-click=\u0026#34;updateUser(user.id,user.name,user.email)\u0026#34;\u0026gt;Update User\u0026lt;/a\u0026gt; \u0026lt;a ng-click=\u0026#34;addUser(user.name,user.email)\u0026#34;\u0026gt;Add User\u0026lt;/a\u0026gt; \u0026lt;a ng-click=\u0026#34;deleteUser(user.id)\u0026#34;\u0026gt;Delete User\u0026lt;/a\u0026gt; 最后，让我们按名称完整显示用户列表： \u0026lt;a ng-click=\u0026#34;getAllUsers()\u0026#34;\u0026gt;Get all Users\u0026lt;/a\u0026gt;\u0026lt;br/\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;div ng-repeat=\u0026#34;usr in users\u0026#34;\u0026gt; {{usr.name}} {{usr.email}} \u0026quot; ","permalink":"http://itcodingman.github.io/angularjs_crud_with_spring_data_rest/","tags":["Spring Data REST"],"title":"带有 Spring Data REST 的 AngularJS CRUD 应用程序"},{"categories":["REST"],"contents":"1. 概述 在这个快速教程中，我们将学习如何从一个简单的 AngularJS 前端使用 RESTful API。 我们将在表格中显示数据，创建资源，更新它，最后删除它。 2. REST API 首先，让我们快速浏览一下我们的简单 API——使用分页公开Feed资源：  分页 - GET /api/myFeeds?page={page}\u0026amp;size={size}\u0026amp;sortDir={dir}\u0026amp;sort={propertyName}* 创建 - POST /api/myFeeds* 更新 – PUT /api/myFeeds/{id}* 删除 - DELETE/api/myFeeds/{id}*  这里的一个快速说明是分页使用以下 4 个参数：  page : 请求页面的索引 size : 每页最大记录数 sort : 用于排序的属性名称 sortDir : 排序方向  以下是Feed资源的示例： { \u0026#34;id\u0026#34;:1, \u0026#34;name\u0026#34;:\u0026#34;codingman feed\u0026#34;, \u0026#34;url\u0026#34;:\u0026#34;/feed\u0026#34; } 3. Feeds页面 现在，让我们看看我们的Feeds页面： \u0026lt;script src=\u0026#34;http://ajax.googleapis.com/ajax/libs/angularjs/1.3.14/angular.min.js\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://ajax.googleapis.com/ajax/libs/angularjs/1.3.14/angular-resource.min.js\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script th:src=\u0026#34;@{/resources/ng-table.min.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script th:src=\u0026#34;@{/resources/mainCtrl.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; ng-click=\u0026#34;addNewFeed()\u0026#34;\u0026gt;Add New RSS Feed\u0026lt;/a\u0026gt; \u0026lt;table ng-table=\u0026#34;tableParams\u0026#34;\u0026gt; \u0026lt;tr ng-repeat=\u0026#34;row in $data track by row.id\u0026#34;\u0026gt; \u0026lt;td data-title=\u0026#34;\u0026#39;Name\u0026#39;\u0026#34; sortable=\u0026#34;\u0026#39;name\u0026#39;\u0026#34;\u0026gt;{{row.name}}\u0026lt;/td\u0026gt; \u0026lt;td data-title=\u0026#34;\u0026#39;Feed URL\u0026#39;\u0026#34; sortable=\u0026#34;\u0026#39;url\u0026#39;\u0026#34;\u0026gt;{{row.url}}\u0026lt;/td\u0026gt; \u0026lt;td data-title=\u0026#34;\u0026#39;Actions\u0026#39;\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; ng-click=\u0026#34;editFeed(row) \u0026#34;\u0026gt;Edit\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; ng-click=\u0026#34;confirmDelete(row.id) \u0026#34;\u0026gt;Delete\u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 请注意，我们使用ng-table来显示数据——更多内容将在以下部分中介绍。 4. Angular控制器 接下来，让我们看看我们的 AngularJS 控制器： var app = angular.module(\u0026#39;myApp\u0026#39;, [\u0026#34;ngTable\u0026#34;, \u0026#34;ngResource\u0026#34;]); app.controller(\u0026#39;mainCtrl\u0026#39;, function($scope, NgTableParams, $resource) { ... }); 注意：  我们注入了ngTable模块以使用它在用户友好的表格中显示我们的数据并处理分页/排序操作 我们还注入了 ngResource模块来使用它来访问我们的 REST API 资源  5. AngularJS 数据表 现在让我们快速浏览一下ng-table模块——这是配置： $scope.feed = $resource(\u0026#34;api/myFeeds/:feedId\u0026#34;,{feedId:\u0026#39;@id\u0026#39;}); $scope.tableParams = new NgTableParams({}, { getData: function(params) { var queryParams = { page:params.page() - 1, size:params.count() }; var sortingProp = Object.keys(params.sorting()); if(sortingProp.length == 1){ queryParams[\u0026#34;sort\u0026#34;] = sortingProp[0]; queryParams[\u0026#34;sortDir\u0026#34;] = params.sorting()[sortingProp[0]]; } return $scope.feed.query(queryParams, function(data, headers) { var totalRecords = headers(\u0026#34;PAGING_INFO\u0026#34;).split(\u0026#34;,\u0026#34;)[0].split(\u0026#34;=\u0026#34;)[1]; params.total(totalRecords); return data; }).$promise; } }); API 需要某种分页样式，因此我们需要在表格中自定义它以匹配它。我们使用ng-module中的参数并在这里创建我们自己的queryParams。 关于分页的一些附加说明：  *params.page()*从 1 开始，所以我们还需要确保它在与 API 通信时变为零索引 params.sorting()返回一个对象 - 例如{“name”: “asc”}，因此我们需要将键和值分隔为两个不同的参数 - sort，sortDir 我们从响应的 HTTP 标头中提取总元素数  6. 更多操作 最后，我们可以使用*ngResource*模块执行很多操作—— $resource确实涵盖了可用操作方面的完整 HTTP 语义。我们还可以定义我们的自定义功能。 我们在上一节中使用query来获取提要列表。请注意，get和query都执行GET——但query用于处理数组响应。 6.1 添加新Feed 为了添加新的提要，我们将使用*$resource方法save*- 如下： $scope.feed = {name:\u0026#34;New feed\u0026#34;, url: \u0026#34;http://www.example.com/feed\u0026#34;}; $scope.createFeed = function(){ $scope.feeds.save($scope.feed, function(){ $scope.tableParams.reload(); }); } 6.2. 更新Feed 我们可以使用我们自己的自定义方法和*$resource* - 如下： $scope.feeds = $resource(\u0026#34;api/myFeeds/:feedId\u0026#34;,{feedId:\u0026#39;@id\u0026#39;},{ \u0026#39;update\u0026#39;: { method:\u0026#39;PUT\u0026#39; } }); $scope.updateFeed = function(){ $scope.feeds.update($scope.feed, function(){ $scope.tableParams.reload(); }); } 请注意我们如何配置自己的更新方法来发送PUT请求。 6.3. 删除Feed 最后，我们可以使用delete方法删除一个Feed： $scope.confirmDelete = function(id){ $scope.feeds.delete({feedId:id}, function(){ $scope.tableParams.reload(); }); } 7. AngularJs 对话框 现在，让我们看看如何使用*ngDialog*模块来显示用于添加/更新我们的提要的简单表单。 这是我们的模板，我们可以在单独的 HTML 页面或同一页面中定义它： \u0026lt;script type=\u0026#34;text/ng-template\u0026#34; id=\u0026#34;templateId\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ngdialog-message\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{feed.name}}\u0026lt;/h2\u0026gt; \u0026lt;input ng-model=\u0026#34;feed.name\u0026#34;/\u0026gt; \u0026lt;input ng-model=\u0026#34;feed.url\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;ngdialog-buttons mt\u0026#34;\u0026gt; \u0026lt;button ng-click=\u0026#34;save()\u0026#34;\u0026gt;Save\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/script\u0026gt; 然后我们将打开我们的对话框来添加/编辑一个提要： $scope.addNewFeed = function(){ $scope.feed = {name:\u0026#34;New Feed\u0026#34;, url: \u0026#34;\u0026#34;}; ngDialog.open({ template: \u0026#39;templateId\u0026#39;, scope: $scope}); } $scope.editFeed = function(row){ $scope.feed.id = row.id; $scope.feed.name = row.name; $scope.feed.url = row.url; ngDialog.open({ template: \u0026#39;templateId\u0026#39;, scope: $scope}); } $scope.save = function(){ ngDialog.close(\u0026#39;ngdialog1\u0026#39;); if(! $scope.feed.id){ $scope.createFeed(); } else{ $scope.updateFeed(); } } 注意：  *$scope.save()*在用户点击对话框中的保存按钮时被调用 $scope.addNewFeed()在用户单击提要页面中的添加新Feed按钮时被调用——它初始化一个新提要对象（没有id） 当用户想要编辑 Feeds 表中的特定行时调用*$scope.editFeed()*  8. 错误处理 最后，让我们看看如何使用 AngularJS 处理响应错误消息。 为了全局处理服务器错误响应——而不是每个请求——我们将向*$httpProvider*注册一个拦截器： app.config([\u0026#39;$httpProvider\u0026#39;, function ($httpProvider) { $httpProvider.interceptors.push(function ($q,$rootScope) { return { \u0026#39;responseError\u0026#39;: function (responseError) { $rootScope.message = responseError.data.message; return $q.reject(responseError); } }; }); }]); 这是我们在 HTML 中的消息表示： \u0026lt;div ng-show=\u0026#34;message\u0026#34; class=\u0026#34;alert alert-danger\u0026#34;\u0026gt; {{message}} \u0026lt;/div\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/angular_js_rest_api/","tags":[],"title":"用于 REST API 的简单 AngularJS 前端"},{"categories":["Sorting"],"contents":"1. 简介 在本教程中，我们将研究快速排序算法并了解它是如何工作的。 快速排序是一种分而治之的算法。这意味着每次迭代的工作原理是将输入分成两部分，然后对它们进行排序，然后再将它们组合在一起 它最初由 Tony Hoare 开发并于 1961 年发布，它仍然是可用的更有效的通用排序算法之一。 2. 算法要求 使用快速排序算法的唯一真正要求是比较两个元素的定义明确的操作。我们可以确定任何元素是否严格小于另一个元素。这种比较的确切性质并不重要，只要它是一致的。请注意，不需要直接相等比较，只需要小于比较。 对于许多类型，这是一个不可否认的比较。例如，数字隐含地定义了如何执行此操作。其他类型不太明显，但我们仍然可以根据排序的要求来定义它。例如，在对字符串进行排序时，我们需要确定字符大小写是否重要或 Unicode 字符如何工作。 3. 二叉树排序 二叉树排序是一种算法，我们在其中构建由我们正在排序的元素组成的平衡二叉树。一旦我们有了这个，我们就可以从这棵树中构建结果。 这个想法是选择一个枢轴作为树上的节点，然后 根据它们是否小于枢轴元素，将所有元素分配给节点的左分支或 *右分支。*然后我们可以递归地对这些分支进行排序，直到我们有一个完全排序的树。 3.1 示例 例如，要对数字列表“3 7 8 5 2 1 9 5 4”进行排序，我们的第一遍将如下所示： Input: 3 7 8 5 2 1 9 5 4 Pivot = 3 Left = 2 1 Right = 7 8 5 9 5 4 这给了我们原始输入的两个分区。** Left列表中的所有内容都严格小于 Pivot，而其他所有内容都在Right列表中**。 接下来，我们使用相同的算法对这两个列表进行排序： Input: 2 1 Pivot = 2 Left = 1 Right = Empty Input: 7 8 5 9 5 4 Pivot = 7 Left = 5 5 4 Right = 8 9 当我们从第一遍对左侧分区进行排序时，我们最终得到了两个长度为 one 或更少的列表。然后这些已经排序——因为不可能有一个未排序的大小为 1 的列表。这意味着我们可以在这里停下来，而是专注于正确分区的剩余部分。 此时，我们有以下结构： / [1] 2 / \\ [] 3 \\ / [5 5 4] 7 \\ [8 9] 我们可以看到我们已经接近排序列表了。我们还有两个分区要排序，然后我们就完成了： 1 / 2 4 / / 3 5 \\ / \\ 7 5 \\ 8 \\ 9 这在算法的 5 遍中对列表进行了排序，适用于越来越小的子列表。但是，内存需求相对较高，必须额外分配 17 个元素的内存来对原始列表中的 9 个元素进行排序。 4. 快速排序的总体思路 快速排序算法在概念上类似于二叉树排序。它不是在我们需要排序的每个步骤中构建子列表，而是在原始列表中完成所有工作。 它的工作原理是围绕选定的枢轴动态交换列表中的元素，然后递归地将子列表排序到该枢轴的任一侧。这使得它的空间效率显着提高，这对于大型列表可能很重要。 快速排序取决于两个关键因素——选择主元和 划分元素的机制。 这个算法的关键是 配分函数，我们很快就会讲到。这将返回输入数组的索引，使得该索引下方的每个元素排序为小于该索引处的元素，并且该索引处的元素排序为小于其上方的所有元素。 这样做将涉及交换数组中的一些元素，以使它们成为该索引的适当一侧。 一旦我们完成了这个分区，我们就将算法应用到这个索引两侧的两个分区上。当我们的分区每个只包含一个元素时，这最终完成，此时输入数组现在已排序。 因此，我们可以将快速排序算法总结为三个步骤：   选择一个元素作为枢轴   通过将较小的元素移动到枢轴的左侧并将较大的元素移动到其右侧来划分问题集   在每个分区上重复上述步骤   快速排序示例    这里我们有一个包含十个未排序值的数组，我们将使用 Quicksort 对其进行排序： **我们要采取的第一步是从这个数组中选择一个元素作为我们的枢轴。**我们可以用不同的方式选择一个主元，但对于这个例子，我们总是选择数组的最右边的元素，即数字 5。 现在我们已经确定了 5 作为我们的枢轴，让我们根据我们的枢轴对数组进行分区，将大于 5 的数字放在右侧，将小于 5 的数字放在左侧。在这一点上，我们并不真正担心对数字进行排序，只是我们已经将它们移动到关于枢轴的正确位置。 在此过程中，我们将数组围绕枢轴 5 划分为两部分： 让我们取最左边的分区（索引 0 - 1）并重复这些步骤。我们将选择数字 2 作为我们的支点并相应地重新排列，这为我们提供了以下信息： 接下来，我们取最右边的分区（索引 3 - 9）并将 10 作为我们的枢轴；任何大于 10 的数字都将移至其右侧，小于 10 的数字将移至其左侧： 正如我们通过定位每个选定的枢轴所看到的那样，我们正在慢慢接近排序数组！如果我们继续在索引 5 到 9 的剩余分区上重复这些步骤，我们将最终达到我们的数组从最小到最大排序的点。 下图显示了所有步骤，最终为我们提供了一个排序数组： 正如我们所看到的，这些步骤可能会根据我们选择枢轴元素的方式而有所不同。因此，让我们开始讨论选择支点的主要方法。 快速排序实现   快速排序算法有多种实现。这些实现在选择枢轴元素的方式方面彼此不同。让我们讨论分区方法。 6.1 Lomuto 分区 Lomuto 分区归功于 Nico Lomuto。这通过迭代输入数组来工作，交换严格小于预先选择的枢轴元素的元素。它们出现在数组的较早位置，但在滑动目标索引上。 然后，这个滑动目标索引就是我们将返回的新分区索引，以供更大算法的下一次递归使用。 这是为了确保我们的滑动目标索引的位置使得数组中它之前的所有元素都小于这个元素，并且这个元素小于数组中它之后的所有元素。 让我们用伪代码来看看这个： fun quicksort(input : T[], low : int, high : int) if (low \u0026lt; high) p := partition(input, low, high) quicksort(input, low, p - 1) quicksort(input, p + 1, high) fun partition(input: T[], low: int, high: int) : int pivot := input[high] partitionIndex := low loop j from low to (high - 1) if (input[j] \u0026lt; pivot) then swap(input[partitionIndex], input[j]) partitionIndex := partitionIndex + 1 swap(input[partitionIndex], input[high] return partitionIndex 作为一个工作示例，我们可以从之前对数组进行分区： Sorting input: 3,7,8,5,2,1,9,5,4 from 0 to 8 Pivot: 4 Partition Index: 0 When j == 0 =\u0026gt; input[0] == 3 =\u0026gt; Swap 3 for 3 =\u0026gt; input := 3,7,8,5,2,1,9,5,4, partitionIndex := 1 When j == 1 =\u0026gt; input[1] == 7 =\u0026gt; No Change When j == 2 =\u0026gt; input[2] == 8 =\u0026gt; No Change When j == 3 =\u0026gt; input[3] == 5 =\u0026gt; No Change When j == 4 =\u0026gt; input[4] == 7 =\u0026gt; Swap 7 for 2 =\u0026gt; input := 3,2,8,5,7,1,9,5,4, partitionIndex := 2 When j == 5 =\u0026gt; input[5] == 8 =\u0026gt; Swap 8 for 1 =\u0026gt; input := 3,2,1,5,7,8,9,5,4, partitionIndex := 3 When j == 6 =\u0026gt; input[6] == 9 =\u0026gt; No Change When j == 7 =\u0026gt; input[7] == 5 =\u0026gt; No Change After Loop =\u0026gt; Swap 4 for 5 =\u0026gt; input := 3,2,1,4,7,8,9,5,5, partitionIndex := 3 通过这个我们可以看到，我们已经执行了 3 次交换，并确定了索引“3”的新分区点。这些交换之后的数组使得元素 0、1 和 2 都小于元素 3，并且元素 3 小于元素 4、5、6、7 和 8。 完成此操作后，将递归更大的算法，这样我们将从 0 到 2 对子数组进行排序，从 4 到 8 对子数组进行排序。例如，对从 0 到 2 的子数组重复此操作，我们会这样做： Sorting input: 3,2,1,4,7,8,9,5,5 from 0 to 2 Pivot: 1 Partition Index: 0 When j == 0 =\u0026gt; input[0] == 3 =\u0026gt; No Change When j == 1 =\u0026gt; input[1] == 2 =\u0026gt; No Change After Loop =\u0026gt; Swap 1 for 3 =\u0026gt; input := 1,2,3,4,7,8,9,5,5, partitionIndex := 0 请注意，我们仍在传递整个输入数组以供算法使用，但因为我们有低和高索引，我们实际上只关注我们关心的位。这是一种效率，意味着我们不需要复制整个数组或其中的部分。 在整个算法中，对整个数组进行排序，我们执行了 12 次不同的交换以获得结果。 6.2. 霍尔分区 Hoare 分区是由 Tony Hoare 在 Quicksort 算法最初发布时提出的。它不是从低到高跨数组工作，而是从两端一次向中心迭代。这意味着我们有更多的迭代，更多的比较，但更少的交换。 这可能很重要，因为通常比较内存值比交换它们便宜。 在伪代码中： fun quicksort(input : T[], low : int, high : int) if (low \u0026lt; high) p := partition(input, low, high) quicksort(input, low, p) // Note that this is different than when using Lomuto quicksort(input, p + 1, high) fun partition(input : T[], low: int, high: int) : int pivotPoint := floor((high + low) / 2) pivot := input[pivotPoint] high++ low-- loop while True low++ loop while (input[low] \u0026lt; pivot) high-- loop while (input[high] \u0026gt; pivot) if (low \u0026gt;= high) return high swap(input[low], input[high]) 作为一个工作示例，我们可以从之前对数组进行分区： Sorting input: 3,7,8,5,2,1,9,5,4 from 0 to 8 Pivot: 2 Loop #1 Iterate low =\u0026gt; input[0] == 3 =\u0026gt; Stop, low == 0 Iterate high =\u0026gt; input[8] == 4 =\u0026gt; high := 7 Iterate high =\u0026gt; input[7] == 5 =\u0026gt; high := 6 Iterate high =\u0026gt; input[6] == 9 =\u0026gt; high := 5 Iterate high =\u0026gt; input[5] == 1 =\u0026gt; Stop, high == 5 Swap 1 for 3 =\u0026gt; input := 1,7,8,5,2,3,9,5,4 Low := 1 High := 4 Loop #2 Iterate low =\u0026gt; input[1] == 7 =\u0026gt; Stop, low == 1 Iterate high =\u0026gt; input[4] == 2 =\u0026gt; Stop, high == 4 Swap 2 for 7 =\u0026gt; input := 1,2,8,5,7,3,9,5,4 Low := 2 High := 3 Loop #3 Iterate low =\u0026gt; input[2] == 8 =\u0026gt; Stop, low == 2 Iterate high =\u0026gt; input[3] == 5 =\u0026gt; high := 2 Iterate high =\u0026gt; input[2] == 8 =\u0026gt; high := 1 Iterate high =\u0026gt; input[1] == 2 =\u0026gt; Stop, high == 1 Return 1 从表面上看，这看起来是一个更复杂的算法，正在做更多的工作。但是，总体而言，它的工作成本较低。整个算法只需要 8 次交换而不是 Lomuto 分区方案所需的 12 次即可达到相同的结果。 7. 算法调整 根据具体要求，我们可以对正常算法进行一些调整。这些并不适合每种情况，因此我们应该仅在适当的时候使用它们，但它们可以对结果产生重大影响。 7.1 枢轴选择 选择要围绕的元素对算法的效率具有重要意义。上面，我们选择了一个固定元素。如果列表真正按随机顺序打乱，这很有效，但列表越有序，效率就越低。 如果我们要对列表 1, 2, 3, 4, 5, 6, 7, 8, 9进行排序，那么 Hoare 分区方案以零交换进行排序，但 Lomuto 方案需要 44。同样，列表 *9, 8, 7、6、5、4、3、2、1 需要与 Hoare 交换 4次，*与 Lomuto 交换 24 次。 在 Hoare 分区方案中，这已经很不错了，但是 Lomuto 方案可以改进很多。通过改变我们选择枢轴的方式，通过使用三个固定点的中值，我们可以获得显着的改进。 这种调整简称为三中位数： mid := (low + high) / 2 if (input[mid] \u0026lt; input[low]) swap(input[mid], input[low]) if (input[high] \u0026lt; input[low]) swap(input[high], input[low]) if (input[mid] \u0026lt; input[high]) swap(input[mid], input[high]) 我们将其应用于算法的每一次通过。这需要三个固定点并确保它们以相反的顺序预先排序。 这似乎不寻常，但影响不言而喻。使用它对列表 1、2、3、4、5、6、7、8、9进行排序现在需要 16 次交换，而之前需要 44 次。这减少了 64% 的工作量。但是，列表 9, 8, 7, 6, 5, 4, 3, 2, 1只下降到 19 次交换，而不是之前的 24 次，列表 3, 7, 8, 5, 2, 1, 9 , 5, 4从之前的 12 上升到 18。 7.2. 重复元素 当有大量直接相等的元素时，快速排序会受到轻微影响。它仍然会尝试对所有这些进行排序，并且可能会做很多不必要的工作。 我们可以做的一个调整是在分割阶段检测这些相等的元素，并在它们的任一侧返回边界，而不仅仅是一个点。然后，我们可以将一整段相等的元素视为已经排序，并只处理两边的元素。 让我们用伪代码来看看： fun quicksort(input : T[], low : int, high : int) if (low \u0026lt; high) (left, right) := partition(input, low, high) quicksort(input, low, left - 1) quicksort(input, right + 1, high) 每次分区方案返回一个主元时，它都会返回所有具有相同值的相邻元素的下索引和上索引。这可以快速删除列表的较大部分，而无需处理它们。 为了实现这一点，我们需要能够比较元素的相等和小于。然而，这通常是更容易实现的比较。 8. 算法性能 快速排序算法通常被认为是非常有效的。平均而言，它具有O(n log(n))对任意输入进行排序的性能。 原始的 Lomuto 分区方案将降级为O(n)列表已经排序并且我们选择最终元素作为枢轴的情况。正如我们所见，当我们为枢轴选择实施三中位数时，这种情况会有所改善，事实上，这会将我们带回到O(n log(n)) 相反，Hoare 分区方案可能会导致更多的比较，因为它递归low-\u0026gt;p而不是low-\u0026gt;p-1. 这意味着递归进行更多比较，即使它导致更少的交换。 \u0026quot; ","permalink":"http://itcodingman.github.io/algorithm_quicksort/","tags":[],"title":"快速排序算法概述"},{"categories":["Reactive","Spring"],"contents":"1. 简介 在本文中，我们将专注于将 Akka 与 Spring 框架集成——以允许将基于 Spring 的服务注入 Akka actor。 在阅读本文之前，建议先了解 Akka 的基础知识。 2. As中的依赖注入 Akka是一个基于 Actor 并发模型的强大应用框架。该框架是用 Scala 编写的，这当然也使其在基于 Java 的应用程序中完全可用。因此**，我们经常希望将 Akka 与现有的基于 Spring 的应用程序集成，**或者简单地使用 Spring 将 bean 连接到 actor。 Spring/Akka 集成的问题在于 Spring 中 bean 的管理和 Akka 中 Actor 的管理之间的差异：Actor 具有不同于典型 Spring bean 生命周期的特定生命周期。 此外，actor 被拆分为一个 actor 本身（这是一个内部实现细节，不能由 Spring 管理）和一个 actor 引用，它可以被客户端代码访问，以及在不同的 Akka 运行时之间可序列化和可移植。 幸运的是，Akka 提供了一种机制，即Akka 扩展，这使得使用外部依赖注入框架变得相当容易。 3. Maven依赖 为了在我们的 Spring 项目中演示 Akka 的使用，我们需要一个最基本的 Spring 依赖项——spring- context库和akka-actor库。库版本可以提取到pom的**部分： \u0026lt;properties\u0026gt; \u0026lt;spring.version\u0026gt;4.3.1.RELEASE\u0026lt;/spring.version\u0026gt; \u0026lt;akka.version\u0026gt;2.4.8\u0026lt;/akka.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${akka.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 确保检查 Maven Central 以获取最新版本的spring-context和akka-actor依赖项。 请注意，akka-actor依赖项的名称中有一个*_2.11*后缀，这表示此版本的 Akka 框架是针对 Scala 版本 2.11 构建的。相应版本的 Scala 库将传递地包含在您的构建中。 4. 将 Spring Beans 注入 Akka Actors 让我们创建一个简单的 Spring/Akka 应用程序，该应用程序由一个参与者组成，该参与者可以通过向这个人发出问候来回答这个人的名字。问候的逻辑将被提取到一个单独的服务中。我们希望将此服务自动连接到一个参与者实例。Spring 集成将帮助我们完成这项任务。 4.1 定义演员和服务 为了演示将服务注入到 actor 中，我们将创建一个简单的类GreetingActor，定义为无类型的 actor（扩展 Akka 的UntypedActor基类）。每个 Akka Actor 的主要方法是onReceive方法，它接收消息并根据某些指定的逻辑对其进行处理。 在我们的例子中，GreetingActor实现检查消息是否是预定义的Greet类型，然后从**Greet实例中获取人名，然后使用GreetingService接收此人的问候语，并使用接收到的问候语字符串回答发件人。如果消息属于其他未知类型，则将其传递给参与者预定义的未处理方法。 我们来看一下： @Component @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public class GreetingActor extends UntypedActor { private GreetingService greetingService; // constructor  @Override public void onReceive(Object message) throws Throwable { if (message instanceof Greet) { String name = ((Greet) message).getName(); getSender().tell(greetingService.greet(name), getSelf()); } else { unhandled(message); } } public static class Greet { private String name; // standard constructors/getters  } } 注意Greet消息类型被定义为这个actor内部的一个静态内部类，这被认为是一个很好的实践。接受的消息类型应尽可能靠近参与者定义，以避免混淆该参与者可以处理哪些消息类型。 还要注意 Spring 注释@Component和@Scope——**它们将类定义为具有原型范围的 Spring 管理的 bean。 范围非常重要，因为每个 bean 检索请求都应该产生一个新创建的实例，因为这种行为与 Akka 的 actor 生命周期相匹配。如果您在其他范围内实现此 bean，则在 Akka 中重新启动 actor 的典型情况很可能无法正常运行。 最后，请注意我们不必显式地*@Autowire* GreetingService实例——这是可能的，因为 Spring 4.3 的新特性称为隐式构造函数注入。 GreeterService的实现非常简单，请注意我们通过向其添加*@Component注释将其定义为 Spring 管理的 bean（具有默认的单例*范围）： @Component public class GreetingService { public String greet(String name) { return \u0026#34;Hello, \u0026#34; + name; } } 4.2. 通过 Akka 扩展添加 Spring 支持 将 Spring 与 Akka 集成的最简单方法是通过 Akka 扩展。 **扩展是每个参与者系统创建的单例实例。**它由一个实现标记接口Extension的扩展类本身和一个通常继承AbstractExtensionId的扩展 id 类组成。 由于这两个类是紧密耦合的，因此实现嵌套在 ExtensionId 类中的Extension类是有意义的： public class SpringExtension extends AbstractExtensionId\u0026lt;SpringExtension.SpringExt\u0026gt; { public static final SpringExtension SPRING_EXTENSION_PROVIDER = new SpringExtension(); @Override public SpringExt createExtension(ExtendedActorSystem system) { return new SpringExt(); } public static class SpringExt implements Extension { private volatile ApplicationContext applicationContext; public void initialize(ApplicationContext applicationContext) { this.applicationContext = applicationContext; } public Props props(String actorBeanName) { return Props.create( SpringActorProducer.class, applicationContext, actorBeanName); } } } 首先——SpringExtension从AbstractExtensionId类中实现了一个createExtension方法——它负责创建扩展实例，即SpringExt对象。 SpringExtension类也有一个静态字段SPRING_EXTENSION_PROVIDER ，它包含对其唯一实例的引用。添加一个私有构造函数来明确声明SpringExtention应该是一个单例类通常是有意义的，但为了清楚起见，我们将省略它。 其次，静态内部类SpringExt就是扩展本身。由于Extension只是一个标记接口，我们可以按照我们认为合适的方式定义这个类的内容。 在我们的例子中，我们需要initialize方法来保存一个 Spring ApplicationContext实例——这个方法在每个扩展初始化时只会被调用一次。 我们还需要props方法来创建Props对象。Props实例是一个演员的蓝图，在我们的例子中，Props.create方法接收一个SpringActorProducer类和该类的构造函数参数。这些是这个类的构造函数将被调用的参数。 每次我们需要 Spring 管理的 Actor 引用时，都会执行props方法。 第三个也是最后一个难题是SpringActorProducer类。它实现了 Akka 的IndirectActorProducer接口，该接口允许通过实现producer和actorClass方法来覆盖 actor 的实例化过程。 你可能已经猜到了，它不会直接实例化，而是总是从 Spring 的ApplicationContext中检索一个actor实例。由于我们已将 actor设为原型作用域的 bean，因此每次调用 producer方法都将返回该 actor 的一个新实例： public class SpringActorProducer implements IndirectActorProducer { private ApplicationContext applicationContext; private String beanActorName; public SpringActorProducer(ApplicationContext applicationContext, String beanActorName) { this.applicationContext = applicationContext; this.beanActorName = beanActorName; } @Override public Actor produce() { return (Actor) applicationContext.getBean(beanActorName); } @Override public Class\u0026lt;? extends Actor\u0026gt; actorClass() { return (Class\u0026lt;? extends Actor\u0026gt;) applicationContext .getType(beanActorName); } } 4.3. 把它们放在一起 剩下要做的就是创建一个 Spring 配置类（标有*@Configuration注释），它将告诉 Spring 扫描当前包以及所有嵌套包（这是由@ComponentScan*注释确保的）并创建一个 Spring 容器. 我们只需要添加一个额外的 bean—— ActorSystem实例——并在这个**ActorSystem上初始化 Spring 扩展： @Configuration @ComponentScan public class AppConfiguration { @Autowired private ApplicationContext applicationContext; @Bean public ActorSystem actorSystem() { ActorSystem system = ActorSystem.create(\u0026#34;akka-spring-demo\u0026#34;); SPRING_EXTENSION_PROVIDER.get(system) .initialize(applicationContext); return system; } } 4.4. 检索Spring的 Actor 为了测试一切正常，我们可以将ActorSystem实例注入我们的代码（一些 Spring 管理的应用程序代码或基于 Spring 的测试），使用我们的扩展为一个演员创建一个Props对象，检索一个演员的引用通过Props对象并尝试向某人打招呼： ActorRef greeter = system.actorOf(SPRING_EXTENSION_PROVIDER.get(system) .props(\u0026#34;greetingActor\u0026#34;), \u0026#34;greeter\u0026#34;); FiniteDuration duration = FiniteDuration.create(1, TimeUnit.SECONDS); Timeout timeout = Timeout.durationToTimeout(duration); Future\u0026lt;Object\u0026gt; result = ask(greeter, new Greet(\u0026#34;John\u0026#34;), timeout); Assert.assertEquals(\u0026#34;Hello, John\u0026#34;, Await.result(result, duration)); 这里我们使用典型的akka.pattern.Patterns.ask模式，它返回一个 Scala 的Future实例。一旦计算完成，Future将使用我们在**GreetingActor.onMessasge方法中返回的值解析。 我们可以通过将 Scala 的Await.result方法应用于Future来等待结果，或者，更优选地，使用异步模式构建整个应用程序。 \u0026quot; ","permalink":"http://itcodingman.github.io/akka_with_spring/","tags":["Akka"],"title":"用 Akka 介绍 Spring"},{"categories":["Data","Reactive"],"contents":"1. 概述 在本文中，我们将研究建立在 Akka actor 框架之上的akka-streams库，它遵循响应式流宣言。Akka Streams API 允许我们从独立的步骤轻松组合数据转换流。 此外，所有处理都是以反应式、非阻塞和异步的方式完成的。 2.Maven依赖 首先，我们需要将akka-stream 和akka-stream-testkit库添加到我们的pom.xml 中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-stream_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-stream-testkit_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Streams API 要使用 Akka Streams，我们需要了解核心 API 概念：  Source —— akka-stream库中处理的入口点——我们可以从多个源创建这个类的实例；例如，如果我们想从单个StringSourcesingle()从IterableItemCreateSource Flow – 主要处理构建块– 每个Flow实例都有一个输入和一个输出值 Materializer——如果我们希望我们的Flow有一些副作用，比如记录或保存结果，我们可以使用它；最常见的是，我们将NotUsed别名作为Materializer传递，以表示我们的Flow不应该有任何副作用 Sink 操作——当我们构建一个Streams 时，它不会执行，直到我们在其上注册一个Sink 操作——它是一个终端操作，会触发整个Streams  4.在 Akka Streams 中创建Flow 让我们从构建一个简单的示例开始，我们将在其中展示如何**创建和组合多个Flow——**以处理整数流并从流中计算整数对的平均移动窗口。 我们将解析一个以分号分隔的整数字符串作为输入，以创建示例的akka-stream 源。 4.1 使用stream解析输入 首先，让我们创建一个DataImporter类，它将采用 ActorSystem 的一个实例*，我们稍后将使用它来创建我们的Flow*： public class DataImporter { private ActorSystem actorSystem; // standard constructors, getters... } 接下来，让我们创建一个parseLine方法，该方法将从我们的分隔输入字符串生成一个整数列表。请记住，我们在这里使用 Java Stream API 仅用于解析： private List\u0026lt;Integer\u0026gt; parseLine(String line) { String[] fields = line.split(\u0026#34;;\u0026#34;); return Arrays.stream(fields) .map(Integer::parseInt) .collect(Collectors.toList()); } 我们的初始Flow会将parseLine应用于我们的输入，以创建一个输入类型为String且输出类型为Integer的Flow： private Flow\u0026lt;String, Integer, NotUsed\u0026gt; parseContent() { return Flow.of(String.class) .mapConcat(this::parseLine); } 当我们调用parseLine()方法时，编译器知道该 lambda 函数的参数将是一个字符串——与我们的Flow*的输入类型相同。 请注意，我们使用的是mapConcat()方法——等效于 Java 8 flatMap()方法——因为我们希望将parseLine()返回的整数列表扁平化为整数流，以便我们处理中的后续步骤不需要处理List。 4.2 使用Streams执行计算 至此，我们有了解析整数的流程。现在，我们需要实现将所有输入元素组合成对并计算这些对的平均值的逻辑。 现在，我们将创建一个*Integer流并使用grouped()*方法对**它们进行分组。 接下来，我们要计算平均值。 由于我们对处理这些平均值的顺序不感兴趣，因此我们可以使用*mapAsyncUnordered()*方法使用多个线程并行计算平均值，并将线程数作为参数传递给该方法。 将作为 lambda 传递给Flow的操作需要返回CompletableFuture，因为该操作将在单独的线程中异步计算： private Flow\u0026lt;Integer, Double, NotUsed\u0026gt; computeAverage() { return Flow.of(Integer.class) .grouped(2) .mapAsyncUnordered(8, integers -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; integers.stream() .mapToDouble(v -\u0026gt; v) .average() .orElse(-1.0))); } 我们正在计算八个并行线程的平均值。请注意，我们使用 Java 8 Stream API 来计算平均值。 4.3. 将多个Flow组合成一个Flow Flow API 是一个流畅的抽象，它允许我们组合多个Flow实例来实现我们的最终处理目标。我们可以有细粒度的流程，例如，一个正在解析*JSON，*另一个正在做一些转换，另一个正在收集一些统计信息。 这样的粒度将帮助我们创建更多可测试的代码，因为我们可以独立地测试每个处理步骤。 我们在上面创建了两个可以相互独立工作的流程。现在，我们想将它们组合在一起。 首先，我们要解析我们的输入String，接下来，我们要计算元素流的平均值。 *我们可以使用via()*方法来组合我们的流程： Flow\u0026lt;String, Double, NotUsed\u0026gt; calculateAverage() { return Flow.of(String.class) .via(parseContent()) .via(computeAverage()); } 我们创建了一个输入类型为String的**Flow和两个其他流。parseContent ()**流接受一个字符串输入并返回一个整数作为输出。computeAverage() 流采用该Integer并计算返回Double作为输出类型的平均值。 5. 向流中添加Sink 正如我们所提到的，到目前为止，整个Flow还没有执行，因为它是惰性的。**要开始执行Flow，我们需要定义一个Sink。例如，Sink操作可以将数据保存到数据库中，或将结果发送到某些外部 Web 服务。 假设我们有一个带有以下save()方法的**AverageRepository类，它将结果写入我们的数据库： CompletionStage\u0026lt;Double\u0026gt; save(Double average) { return CompletableFuture.supplyAsync(() -\u0026gt; { // write to database  return average; }); } 现在，我们要创建一个使用此方法保存Flow处理结果的Sink操作。要创建我们的Sink，我们首先需要**创建一个Flow，它将我们的处理结果作为输入类型**。接下来，我们要将所有结果保存到数据库中。 同样，我们不关心元素的顺序，因此我们可以使用*mapAsyncUnordered()方法并行执行save()*操作。 要从Flow中创建Sink，我们需要使用Sink.ignore()作为第一个参数和Keep.right()作为第二个参数调用toMat() ，因为我们想要返回处理的状态： private Sink\u0026lt;Double, CompletionStage\u0026lt;Done\u0026gt;\u0026gt; storeAverages() { return Flow.of(Double.class) .mapAsyncUnordered(4, averageRepository::save) .toMat(Sink.ignore(), Keep.right()); } 6. 定义流量来源 我们需要做的最后一件事是*从输入String创建一个Source。我们可以使用*via()方法将calculateAverage()流应用到这个源。 然后，要将Sink添加到处理中，我们需要调用runWith()方法并传递我们刚刚创建的storeAverages() Sink： CompletionStage\u0026lt;Done\u0026gt; calculateAverageForContent(String content) { return Source.single(content) .via(calculateAverage()) .runWith(storeAverages(), ActorMaterializer.create(actorSystem)) .whenComplete((d, e) -\u0026gt; { if (d != null) { System.out.println(\u0026#34;Import finished \u0026#34;); } else { e.printStackTrace(); } }); } 请注意，当处理完成时，我们正在添加*whenComplete()*回调，我们可以在其中根据处理的结果执行一些操作。 7. 测试Akka 流 我们可以使用akka-stream-testkit 测试我们的处理。 测试处理的实际逻辑的最佳方法是测试所有Flow逻辑并使用TestSink触发计算并对结果进行断言。 在我们的测试中，我们正在创建我们想要测试的Flow ，接下来，我们将从测试输入内容创建一个Source ： @Test public void givenStreamOfIntegers_whenCalculateAverageOfPairs_thenShouldReturnProperResults() { // given  Flow\u0026lt;String, Double, NotUsed\u0026gt; tested = new DataImporter(actorSystem).calculateAverage(); String input = \u0026#34;1;9;11;0\u0026#34;; // when  Source\u0026lt;Double, NotUsed\u0026gt; flow = Source.single(input).via(tested); // then  flow .runWith(TestSink.probe(actorSystem), ActorMaterializer.create(actorSystem)) .request(4) .expectNextUnordered(5d, 5.5); } 我们正在检查我们是否期望四个输入参数，并且两个平均值的结果可以以任何顺序到达，因为我们的处理是以异步和并行方式完成的。 \u0026quot; ","permalink":"http://itcodingman.github.io/akka_streams/","tags":["Akka"],"title":"Akka Streams 指南"},{"categories":["Java"],"contents":" 概述   当我们希望我们的 Web 客户端与我们的服务器保持对话时，WebSockets 可能是一个有用的解决方案。WebSockets 保持持久的全双工连接。这使我们能够在服务器和客户端之间发送双向消息。 在本教程中，我们将学习如何在Play Framework中将 WebSockets 与Akka一起使用。 设置   让我们设置一个简单的聊天应用程序。用户将向服务器发送消息，服务器将响应来自JSONPlaceholder的消息。 2.1 设置 Play 框架应用程序 我们将使用 Play 框架构建这个应用程序。 让我们按照Introduction to Play in Java 中的说明设置和运行一个简单的 Play Framework 应用程序。 2.2. 添加必要的 JavaScript 文件 此外，我们还需要使用 JavaScript 来编写客户端脚本。这将使我们能够接收从服务器推送的新消息。我们将为此使用jQuery库。 让我们将 jQuery 添加到app/views/ index.scala.html文件的底部： \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.4.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 2.3. 设置 Akka 最后，我们将使用 Akka 来处理服务器端的 WebSocket 连接。 让我们导航到build.sbt文件并添加依赖项。 我们需要添加 *as-actor*和 *as-testkit*依赖项： libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-actor\u0026#34; % akkaVersion libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-testkit\u0026#34; % akkaVersion 我们需要这些能够使用和测试 Akka 框架代码。 接下来，我们将使用 Akka 流。所以让我们添加*akka-stream*依赖项： libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-stream\u0026#34; % akkaVersion 最后，我们需要从 Akka actor 调用一个 rest 端点。为此，我们需要 *akka-http*依赖项。当我们这样做时，端点将返回我们必须反序列化的 JSON 数据，因此我们还需要添加akka-http-jackson依赖项： libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http-jackson\u0026#34; % akkaHttpVersion libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-http\u0026#34; % akkaHttpVersion 现在我们都准备好了。让我们看看如何让 WebSockets 工作！ 使用 Akka Actor 处理 WebSocket   **Play 的 WebSocket 处理机制是围绕 Akka 流构建的。**WebSocket 被建模为流。因此，传入的 WebSocket 消息被馈送到流中，流产生的消息被发送到客户端。 要使用 Actor 处理 WebSocket，我们需要将ActorRef转换为流的 Play 实用程序ActorFlow。这主要需要一些Java代码，稍加配置。 3.1 WebSocket 控制器方法 首先，我们需要一个Materializer实例。Materializer 是流执行引擎的工厂。 我们需要将ActorSystem和Materializer注入控制器app/controllers/HomeController.java： private ActorSystem actorSystem; private Materializer materializer; @Inject public HomeController( ActorSystem actorSystem, Materializer materializer) { this.actorSystem = actorSystem; this.materializer = materializer; } 现在让我们添加一个套接字控制器方法： public WebSocket socket() { return WebSocket.Json .acceptOrResult(this::createActorFlow); } 这里我们调用函数acceptOrResult，它接受请求头并返回一个future。返回的未来是处理 WebSocket 消息的流。 相反，我们可以拒绝请求并返回拒绝结果。 现在，让我们创建流程： private CompletionStage\u0026lt;F.Either\u0026lt;Result, Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt;\u0026gt;\u0026gt; createActorFlow(Http.RequestHeader request) { return CompletableFuture.completedFuture( F.Either.Right(createFlowForActor())); } Play Framework 中的 F类定义了一组函数式编程风格的助手。在这种情况下，我们使用F.Either.Right来接受连接并返回流。 假设我们想在客户端未通过身份验证时拒绝连接。 为此，我们可以检查会话中是否设置了用户名。如果不是，我们拒绝与 HTTP 403 Forbidden 的连接： private CompletionStage\u0026lt;F.Either\u0026lt;Result, Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt;\u0026gt;\u0026gt; createActorFlow2(Http.RequestHeader request) { return CompletableFuture.completedFuture( request.session() .getOptional(\u0026#34;username\u0026#34;) .map(username -\u0026gt; F.Either.\u0026lt;Result, Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt;\u0026gt;Right( createFlowForActor())) .orElseGet(() -\u0026gt; F.Either.Left(forbidden()))); } 我们使用F.Either.Left 来拒绝连接，就像我们使用F.Either.Right提供流一样。 最后，我们将流程链接到将处理消息的参与者： private Flow\u0026lt;JsonNode, JsonNode, ?\u0026gt; createFlowForActor() { return ActorFlow.actorRef(out -\u0026gt; Messenger.props(out), actorSystem, materializer); } ActorFlow.actorRef创建了一个由 Messenger actor处理的流。 3.2. routes文件 现在，让我们在conf/routes中添加控制器方法的路由定义： GET / controllers.HomeController.index(request: Request) GET /chat controllers.HomeController.socket GET /chat/with/streams controllers.HomeController.akkaStreamsSocket GET /assets/*file controllers.Assets.versioned(path=\u0026#34;/public\u0026#34;, file: Asset) 这些路由定义将传入的 HTTP 请求映射到控制器操作方法，如Routing in Play Applications in Java 中所述。 3.3. Actor 实现 Actor 类最重要的部分是 createReceive方法，它决定了 Actor 可以处理哪些消息： @Override public Receive createReceive() { return receiveBuilder() .match(JsonNode.class, this::onSendMessage) .matchAny(o -\u0026gt; log.error(\u0026#34;Received unknown message: {}\u0026#34;, o.getClass())) .build(); } Actor 会将与JsonNode类 匹配的所有消息转发到onSendMessage处理程序方法： private void onSendMessage(JsonNode jsonNode) { RequestDTO requestDTO = MessageConverter.jsonNodeToRequest(jsonNode); String message = requestDTO.getMessage().toLowerCase(); //..  processMessage(requestDTO); } 然后处理程序将使用processMessage方法响应每条消息： private void processMessage(RequestDTO requestDTO) { CompletionStage\u0026lt;HttpResponse\u0026gt; responseFuture = getRandomMessage(); responseFuture.thenCompose(this::consumeHttpResponse) .thenAccept(messageDTO -\u0026gt; out.tell(MessageConverter.messageToJsonNode(messageDTO), getSelf())); } 3.4. 使用 Akka HTTP 使用 Rest API 我们将向JSONPlaceholder Posts的虚拟消息生成器发送 HTTP 请求。当响应到达时，我们通过写出将响应发送给客户端。 让我们有一个使用随机帖子 ID 调用端点的方法： private CompletionStage\u0026lt;HttpResponse\u0026gt; getRandomMessage() { int postId = ThreadLocalRandom.current().nextInt(0, 100); return Http.get(getContext().getSystem()) .singleRequest(HttpRequest.create( \u0026#34;https://jsonplaceholder.typicode.com/posts/\u0026#34; + postId)); } 我们还在处理通过调用服务获得的HttpResponse以获得 JSON 响应： private CompletionStage\u0026lt;MessageDTO\u0026gt; consumeHttpResponse( HttpResponse httpResponse) { Materializer materializer = Materializer.matFromSystem(getContext().getSystem()); return Jackson.unmarshaller(MessageDTO.class) .unmarshal(httpResponse.entity(), materializer) .thenApply(messageDTO -\u0026gt; { log.info(\u0026#34;Received message: {}\u0026#34;, messageDTO); discardEntity(httpResponse, materializer); return messageDTO; }); } MessageConverter类是用于在 JsonNode和 DTO之间进行转换的 实用程序： public static MessageDTO jsonNodeToMessage(JsonNode jsonNode) { ObjectMapper mapper = new ObjectMapper(); return mapper.convertValue(jsonNode, MessageDTO.class); } 接下来，我们需要丢弃实体。如果实体对我们没有任何用途，则discardEntityBytes便捷方法的目的是轻松丢弃实体。 让我们看看如何丢弃字节： private void discardEntity( HttpResponse httpResponse, Materializer materializer) { HttpMessage.DiscardedEntity discarded = httpResponse.discardEntityBytes(materializer); discarded.completionStage() .whenComplete((done, ex) -\u0026gt; log.info(\u0026#34;Entity discarded completely!\u0026#34;)); } 现在已经完成了 WebSocket 的处理，让我们看看如何使用 HTML5 WebSockets 设置客户端。 设置 WebSocket 客户端   对于我们的客户，让我们构建一个简单的基于 Web 的聊天应用程序。 4.1 控制器动作 我们需要定义一个呈现索引页面的控制器动作。我们将把它放在控制器类app.controllers.HomeController 中： public Result index(Http.Request request) { String url = routes.HomeController.socket() .webSocketURL(request); return ok(views.html.index.render(url)); } 4.2. 模板页面 现在，让我们转到app/views/ndex.scala.html页面并为接收到的消息添加一个容器和一个用于捕获新消息的表单： \u0026lt;div id=\u0026#34;messageContent\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;F \u0026lt;form\u0026gt; \u0026lt;textarea id=\u0026#34;messageInput\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;button id=\u0026#34;sendButton\u0026#34;\u0026gt;Send\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 我们还需要通过在app/views/index.scala.html页面顶部声明此参数来传递 WebSocket 控制器操作的 URL： @(url: String) 4.3. JavaScript 中的 WebSocket 事件处理程序 现在，我们可以添加 JavaScript 来处理 WebSocket 事件。为简单起见，我们将在app/views/index.scala.html页面的底部添加 JavaScript 函数。 让我们声明事件处理程序： var webSocket; var messageInput; function init() { initWebSocket(); } function initWebSocket() { webSocket = new WebSocket(\u0026#34;@url\u0026#34;); webSocket.onopen = onOpen; webSocket.onclose = onClose; webSocket.onmessage = onMessage; webSocket.onerror = onError; } 让我们自己添加处理程序： function onOpen(evt) { writeToScreen(\u0026#34;CONNECTED\u0026#34;); } function onClose(evt) { writeToScreen(\u0026#34;DISCONNECTED\u0026#34;); } function onError(evt) { writeToScreen(\u0026#34;ERROR: \u0026#34; + JSON.stringify(evt)); } function onMessage(evt) { var receivedData = JSON.parse(evt.data); appendMessageToView(\u0026#34;Server\u0026#34;, receivedData.body); } 然后，为了呈现输出，我们将使用函数appendMessageToView和writeToScreen： function appendMessageToView(title, message) { $(\u0026#34;#messageContent\u0026#34;).append(\u0026#34;\u0026lt;p\u0026gt;\u0026#34; + title + \u0026#34;: \u0026#34; + message + \u0026#34;\u0026lt;/p\u0026gt;\u0026#34;); } function writeToScreen(message) { console.log(\u0026#34;New message: \u0026#34;, message); } 4.4. 运行和测试应用程序 我们已准备好测试应用程序，让我们运行它： cd websockets sbt run 随着应用程序的运行，我们可以通过访问*http://localhost:9000*与服务器聊天： 每次我们输入消息并点击 发送时，服务器都会立即响应来自 JSON 占位符服务的一些lorem ipsum 。 使用 Akka Streams 直接处理 WebSockets   如果我们正在处理来自源的事件流并将其发送到客户端，那么我们可以围绕 Akka 流进行建模。 让我们看看如何在服务器每两秒发送一次消息的示例中使用 Akka 流。 我们将从HomeController中的 WebSocket 操作开始： public WebSocket akkaStreamsSocket() { return WebSocket.Json.accept(request -\u0026gt; { Sink\u0026lt;JsonNode, ?\u0026gt; in = Sink.foreach(System.out::println); MessageDTO messageDTO = new MessageDTO(\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;Title\u0026#34;, \u0026#34;Test Body\u0026#34;); Source\u0026lt;JsonNode, ?\u0026gt; out = Source.tick( Duration.ofSeconds(2), Duration.ofSeconds(2), MessageConverter.messageToJsonNode(messageDTO) ); return Flow.fromSinkAndSource(in, out); }); } Source# tick方法采用三个参数。第一个是处理第一个滴答之前的初始延迟，第二个是连续滴答之间的间隔。我们在上面的代码片段中将这两个值都设置为两秒。第三个参数是应在每次报价时返回的对象。 要查看此操作，我们需要修改index操作中的 URL 并使其指向akkaStreamsSocket端点： String url = routes.HomeController.akkaStreamsSocket().webSocketURL(request); 现在刷新页面，我们将每两秒看到一个新条目： 终止 Actor   在某些时候，我们需要通过用户请求或超时来关闭聊天。 6.1 处理 Actor 终止 我们如何检测 WebSocket 何时关闭？ 当处理 WebSocket 的 actor 终止时，Play 将自动关闭 WebSocket。所以我们可以通过实现Actor#postStop方法来处理这种情况： @Override public void postStop() throws Exception { log.info(\u0026#34;Messenger actor stopped at {}\u0026#34;, OffsetDateTime.now() .format(DateTimeFormatter.ISO_OFFSET_DATE_TIME)); } 6.2. 手动终止 Actor 此外，如果我们必须停止演员，我们可以向演员发送PoisonPill。在我们的示例应用程序中，我们应该能够处理“停止”请求。 让我们看看如何在 onSendMessage方法中做到这一点： private void onSendMessage(JsonNode jsonNode) { RequestDTO requestDTO = MessageConverter.jsonNodeToRequest(jsonNode); String message = requestDTO.getMessage().toLowerCase(); if(\u0026#34;stop\u0026#34;.equals(message)) { MessageDTO messageDTO = createMessageDTO(\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;Stop\u0026#34;, \u0026#34;Stopping actor\u0026#34;); out.tell(MessageConverter.messageToJsonNode(messageDTO), getSelf()); self().tell(PoisonPill.getInstance(), getSelf()); } else { log.info(\u0026#34;Actor received. {}\u0026#34;, requestDTO); processMessage(requestDTO); } } 当我们收到一条消息时，我们会检查它是否是一个停止请求。如果是，我们发送 PoisonPill。否则，我们处理请求。 配置选项   我们可以根据如何处理 WebSocket 来配置几个选项。让我们看几个。 7.1 WebSocket 帧长度 WebSocket 通信涉及数据帧的交换。 WebSocket 帧长度是可配置的。我们可以根据应用要求调整帧长度。 **配置较短的帧长度可能有助于减少使用长数据帧的拒绝服务攻击。**我们可以通过在 application.conf 中指定最大长度来更改应用程序的帧长度： play.server.websocket.frame.maxLength = 64k 我们还可以通过将最大长度指定为命令行参数来设置此配置选项： sbt -Dwebsocket.frame.maxLength=64k run 7.2. 连接空闲超时 默认情况下，我们用来处理 WebSocket 的actor在一分钟后终止。**这是因为运行我们的应用程序的 Play 服务器的默认空闲超时时间为 60 秒。**这意味着所有在 60 秒内未收到请求的连接都会自动关闭。 我们可以通过配置选项来改变它。让我们转到我们的application.conf并将服务器更改为没有空闲超时： play.server.http.idleTimeout = \u0026#34;infinite\u0026#34; 或者我们可以将选项作为命令行参数传入： sbt -Dhttp.idleTimeout=infinite run 我们也可以通过 在 build.sbt中指定**devSettings来配置它。 build.sbt中指定的配置选项仅在开发中使用，它们将在生产中被忽略： PlayKeys.devSettings += \u0026#34;play.server.http.idleTimeout\u0026#34; -\u0026gt; \u0026#34;infinite\u0026#34; 如果我们重新运行应用程序，actor 不会终止。 我们可以将值更改为秒： PlayKeys.devSettings += \u0026#34;play.server.http.idleTimeout\u0026#34; -\u0026gt; \u0026#34;120 s\u0026#34; 我们可以在 Play Framework 文档中找到有关可用配置选项的更多信息。 \u0026quot; ","permalink":"http://itcodingman.github.io/akka_play_websockets/","tags":["Akka","Play","WebSockets"],"title":"带有 Play 框架和 Akka 的 WebSockets"},{"categories":["Reactive"],"contents":" 概述   在本教程中，借助 Akka 的Actor和Stream模型，我们将学习如何设置 Akka 以创建提供基本 CRUD 操作的 HTTP API。 2.Maven依赖 首先，让我们看一下开始使用 Akka HTTP 所需的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-http_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;10.0.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-stream_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-http-jackson_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;10.0.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-http-testkit_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;10.0.11\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 当然，我们可以在Maven Central上找到这些 Akka 库的最新版本。 创建一个Actor   例如，我们将构建一个允许我们管理用户资源的 HTTP API。API 将支持两种操作：  创建新用户 加载现有用户  在我们提供 HTTP API 之前，我们需要实现一个提供我们需要的操作的 actor： class UserActor extends AbstractActor { private UserService userService = new UserService(); static Props props() { return Props.create(UserActor.class); } @Override public Receive createReceive() { return receiveBuilder() .match(CreateUserMessage.class, handleCreateUser()) .match(GetUserMessage.class, handleGetUser()) .build(); } private FI.UnitApply\u0026lt;CreateUserMessage\u0026gt; handleCreateUser() { return createUserMessage -\u0026gt; { userService.createUser(createUserMessage.getUser()); sender() .tell(new ActionPerformed( String.format(\u0026#34;User %s created.\u0026#34;, createUserMessage.getUser().getName())), getSelf()); }; } private FI.UnitApply\u0026lt;GetUserMessage\u0026gt; handleGetUser() { return getUserMessage -\u0026gt; { sender().tell(userService.getUser(getUserMessage.getUserId()), getSelf()); }; } } 基本上，我们正在扩展AbstractActor类并实现它的*createReceive()*方法。 在*createReceive()*中，我们将传入消息类型映射到处理相应类型消息的方法。 消息类型是简单的可序列化容器类，其中包含一些描述特定操作的字段。GetUserMessage并具有单个字段userId 来标识要加载的用户。CreateUserMessage包含一个User对象，其中包含我们创建新用户所需的用户数据。 稍后，我们将看到如何将传入的 HTTP 请求转换为这些消息。 最终，我们将所有消息委托给一个UserService实例，该实例提供了管理持久用户对象所需的业务逻辑。 另外，请注意 *props()方法。**虽然props()方法对于扩展*AbstractActor不是必需的，但稍后在创建ActorSystem时会派上用场 。 有关演员的更深入讨论，请查看我们对 Akka Actors 的介绍。 定义 HTTP 路由   有了一个为我们做实际工作的参与者，我们剩下要做的就是提供一个 HTTP API，将传入的 HTTP 请求委托给我们的参与者。 Akka 使用路由的概念来描述 HTTP API。对于每个操作，我们都需要一条路线。 为了创建一个 HTTP 服务器，我们扩展了框架类HttpApp并实现了routes方法： class UserServer extends HttpApp { private final ActorRef userActor; Timeout timeout = new Timeout(Duration.create(5, TimeUnit.SECONDS)); UserServer(ActorRef userActor) { this.userActor = userActor; } @Override public Route routes() { return path(\u0026#34;users\u0026#34;, this::postUser) .orElse(path(segment(\u0026#34;users\u0026#34;).slash(longSegment()), id -\u0026gt; route(getUser(id)))); } private Route getUser(Long id) { return get(() -\u0026gt; { CompletionStage\u0026lt;Optional\u0026lt;User\u0026gt;\u0026gt; user = PatternsCS.ask(userActor, new GetUserMessage(id), timeout) .thenApply(obj -\u0026gt; (Optional\u0026lt;User\u0026gt;) obj); return onSuccess(() -\u0026gt; user, performed -\u0026gt; { if (performed.isPresent()) return complete(StatusCodes.OK, performed.get(), Jackson.marshaller()); else return complete(StatusCodes.NOT_FOUND); }); }); } private Route postUser() { return route(post(() -\u0026gt; entity(Jackson.unmarshaller(User.class), user -\u0026gt; { CompletionStage\u0026lt;ActionPerformed\u0026gt; userCreated = PatternsCS.ask(userActor, new CreateUserMessage(user), timeout) .thenApply(obj -\u0026gt; (ActionPerformed) obj); return onSuccess(() -\u0026gt; userCreated, performed -\u0026gt; { return complete(StatusCodes.CREATED, performed, Jackson.marshaller()); }); }))); } } 现在，这里有相当多的样板，但请注意，我们遵循与之前映射操作相同的模式**，这次是路由。**让我们分解一下。 在getUser()中，我们只需将传入的用户 ID 包装在GetUserMessage类型的消息中，然后将该消息转发给我们的userActor。 一旦参与者处理完消息，就会调用onSuccess处理程序，在该处理程序中，我们通过发送具有特定 HTTP 状态和特定 JSON 正文的响应来*完成HTTP 请求。*我们使用Jackson marshaller 将 actor 给出的答案序列化为 JSON 字符串。 在postUser()中，我们做的事情有点不同，因为我们期望 HTTP 请求中有一个 JSON 正文。我们使用entity()方法将传入的 JSON 主体映射到User对象中，然后将其包装到CreateUserMessage中并将其传递给我们的actor。同样，我们使用 Jackson 在 Java 和 JSON 之间进行映射，反之亦然。 由于HttpApp期望我们提供单个*Route对象，因此我们在routes方法中将两个路由合并为一个。**在这里，我们使用path*指令最终提供我们的 API 应该可用的 URL 路径。 我们将postUser()提供的路由绑定到路径 /users。如果传入的请求不是 POST 请求，Akka 将自动进入orElse分支并期望路径为*/users/*并且 HTTP 方法为 GET。 如果 HTTP 方法是 GET，请求将被转发到getUser() 路由。如果用户不存在，Akka 将返回 HTTP 状态 404（未找到）。如果方法既不是 POST 也不是 GET，Akka 将返回 HTTP 状态 405（不允许方法）。 有关如何使用 Akka 定义 HTTP 路由的更多信息，请查看Akka 文档。 启动服务器   一旦我们像上面那样创建了一个HttpApp实现，我们可以用几行代码启动我们的 HTTP 服务器： public static void main(String[] args) throws Exception { ActorSystem system = ActorSystem.create(\u0026#34;userServer\u0026#34;); ActorRef userActor = system.actorOf(UserActor.props(), \u0026#34;userActor\u0026#34;); UserServer server = new UserServer(userActor); server.startServer(\u0026#34;localhost\u0026#34;, 8080, system); } 我们只需创建一个具有UserActor类型的单个 Actor 的*ActorSystem并在localhost*上启动服务器。** \u0026quot; ","permalink":"http://itcodingman.github.io/akka_http/","tags":["Akka"],"title":"Akka HTTP 简介"},{"categories":["Reactive"],"contents":"1. 简介 Akka是一个开源库，可通过利用 Actor 模型帮助使用 Java 或 Scala 轻松开发并发和分布式应用程序。 在本教程中，我们将介绍基本功能，例如定义参与者、他们如何通信以及我们如何杀死他们。在最后的笔记中，我们还将记录使用 Akka 时的一些最佳实践。 2. Actor模型 Actor 模型对计算机科学界来说并不陌生。它由 Carl Eddie Hewitt 于 1973 年首次引入，作为处理并发计算的理论模型。 当软件行业开始意识到实现并发和分布式应用程序的陷阱时，它开始显示出它的实际适用性。 **一个actor代表一个独立的计算单元。**一些重要的特征是：  Actor 封装了它的状态和部分应用程序逻辑 参与者仅通过异步消息进行交互，从不通过直接方法调用 每个参与者都有一个唯一的地址和一个邮箱，其他参与者可以在其中传递消息 Actor 将按顺序处理邮箱中的所有消息（邮箱的默认实现是 FIFO 队列） 演员系统以树状层次结构组织 演员可以创建其他演员，可以向任何其他演员发送消息并停止自己或已创建任何演员  2.1 优点 开发并发应用程序很困难，因为我们需要处理同步、锁和共享内存。通过使用 Akka Actor，我们可以轻松编写异步代码，而无需锁和同步。 使用消息而不是方法调用的优点之一是发送者线程在向另一个参与者发送消息时不会阻塞以等待返回值。接收参与者将通过向发送者发送回复消息来响应结果。 使用消息的另一大好处是我们不必担心多线程环境中的同步问题。这是因为所有消息都是按顺序处理的。 Akka actor 模型的另一个优点是错误处理。通过在层次结构中组织参与者，每个参与者都可以将失败通知其父级，因此它可以采取相应的行动。父actor可以决定停止或重新启动子actor。 3. 设置 为了利用 Akka actor，我们需要从Maven Central添加以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor_2.12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. 创建一个Actor 如前所述，参与者是在层次系统中定义的。共享一个公共配置的所有参与者都将由一个ActorSystem 定义。 现在，我们将简单地定义一个具有默认配置和自定义名称的ActorSystem ： ActorSystem system = ActorSystem.create(\u0026#34;test-system\u0026#34;); 即使我们还没有创建任何演员，系统已经包含 3 个主要演员：  具有地址“/”的根监护actor，其名称表示actor系统层次结构的根 具有地址“/user”的用户监护人actor。这将是我们定义的所有actor的父级 具有地址“/system”的系统守护者actor。这将是 Akka 系统内部定义的所有参与者的父级  任何 Akka Actor 都将扩展AbstractActor抽象类并实现*createReceive()*方法来处理来自其他 Actor 的传入消息： public class MyActor extends AbstractActor { public Receive createReceive() { return receiveBuilder().build(); } } **这是我们可以创建的最基本的actor。**它可以接收来自其他参与者的消息并将丢弃它们，因为在*ReceiveBuilder 中没有定义匹配的消息模式。*我们将在本文后面讨论消息模式匹配。 现在我们已经创建了我们的第一个actor，我们应该将它包含在ActorSystem中： ActorRef readingActorRef = system.actorOf(Props.create(MyActor.class), \u0026#34;my-actor\u0026#34;); 4.1 actor配置 ** Props类包含actor配置。**我们可以配置诸如调度程序、邮箱或部署配置之类的东西。此类是不可变的，因此是线程安全的，因此可以在创建新参与者时共享它。 强烈推荐并认为最佳实践是在 actor 对象中定义工厂方法来处理Props对象的创建。 举例来说，让我们定义一个将进行一些文本处理的actor。Actor 将收到一个String对象，它将在该对象上进行处理： public class ReadingActor extends AbstractActor { private String text; public static Props props(String text) { return Props.create(ReadingActor.class, text); } // ... } 现在，要创建这种类型的actor的实例，我们只需使用props()工厂方法将String参数传递给构造函数： ActorRef readingActorRef = system.actorOf( ReadingActor.props(TEXT), \u0026#34;readingActor\u0026#34;); 现在我们知道了如何定义一个actor，让我们看看它们是如何在actor系统中进行通信的。 5. Actor消息 为了相互交互，参与者可以发送和接收来自系统中任何其他参与者的消息。这些消息可以是任何类型的对象，条件是它是不可变的。 **在 Actor 类中定义消息是最佳实践。**这有助于编写易于理解的代码，并且知道参与者可以处理哪些消息。 5.1 发送消息 在 Akka Actor 系统内部，消息使用以下方法发送：  tell（） ask（） forward（）  **当我们想要发送消息但不期望响应时，我们可以使用*tell()*方法。**从性能的角度来看，这是最有效的方法： readingActorRef.tell(new ReadingActor.ReadLines(), ActorRef.noSender()); 第一个参数代表我们发送给actor地址readingActorRef的消息。 第二个参数指定发件人是谁。当接收消息的参与者需要向发送者以外的参与者（例如发送参与者的父节点）发送响应时，这很有用。 通常，我们可以将第二个参数设置为null或ActorRef.noSender()，因为我们不期望回复。*当我们需要一个演员的回应时，我们可以使用*ask()方法： CompletableFuture\u0026lt;Object\u0026gt; future = ask(wordCounterActorRef, new WordCounterActor.CountWords(line), 1000).toCompletableFuture(); 当请求参与者响应时，会返回一个CompletionStage对象，因此处理保持非阻塞状态。 我们必须注意的一个非常重要的事实是在将响应的参与者内部进行错误处理。要返回一个包含异常的Future对象，我们必须向发送者 actor 发送一条Status.Failure消息。 当参与者在处理消息时抛出异常并且*ask()*调用将超时并且在日志中不会看到对异常的引用时，这不会自动完成： @Override public Receive createReceive() { return receiveBuilder() .match(CountWords.class, r -\u0026gt; { try { int numberOfWords = countWordsFromLine(r.line); getSender().tell(numberOfWords, getSelf()); } catch (Exception ex) { getSender().tell( new akka.actor.Status.Failure(ex), getSelf()); throw ex; } }).build(); } 我们还有类似于*tell()的forward()*方法。不同之处在于发送消息时保留了消息的原始发送者，因此转发消息的actor仅充当中间actor： printerActorRef.forward( new PrinterActor.PrintFinalResult(totalNumberOfWords), getContext()); 5.2. 接收消息 *每个参与者都将实现*createReceive()方法，该方法处理所有传入消息。*receiveBuilder()*就像一个 switch 语句，试图将接收到的消息与定义的消息类型匹配： public Receive createReceive() { return receiveBuilder().matchEquals(\u0026#34;printit\u0026#34;, p -\u0026gt; { System.out.println(\u0026#34;The address of this actor is: \u0026#34; + getSelf()); }).build(); } 收到消息后，会将消息放入 FIFO 队列，因此消息按顺序处理。 6. 杀死Actor 当我们使用完一个 actor 后，我们可以通过从ActorRefFactory接口调用***stop()***方法来停止它： system.stop(myActorRef); 我们可以使用这个方法来终止任何子actor或actor本身。重要的是要注意停止是异步完成的，并且当前消息处理将在actor终止之前完成。演员邮箱将不再接受传入的消息。 通过停止父actor，我们还将向所有由它生成的子actor发送终止信号。 当我们不再需要actor系统时，我们可以终止它以释放所有资源并防止任何内存泄漏： Future\u0026lt;Terminated\u0026gt; terminateResponse = system.terminate(); 这将停止系统监护参与者，因此此 Akka 系统中定义的所有参与者。 我们还可以向我们想要杀死的任何参与者发送PoisonPill消息： myActorRef.tell(PoisonPill.getInstance(), ActorRef.noSender()); PoisonPill消息将像任何其他消息一样被Actor 接收并放入队列中。Actor 将处理所有消息，直到到达PoisonPill one。只有这样，参与者才会开始终止过程。 另一个用于杀死演员的特殊消息是Kill消息。与PoisonPill 不同， actor在处理此消息时会抛出ActorKilledException ： myActorRef.tell(Kill.getInstance(), ActorRef.noSender()); \u0026quot; ","permalink":"http://itcodingman.github.io/akka_actors_java/","tags":["Akka"],"title":"Java 中的 Akka Actor 简介"},{"categories":["Programming"],"contents":" 简介   在本文中，我们将介绍 Java Ahead of Time (AOT) 编译器，该编译器在JEP-295中进行了描述，并在 Java 9 中作为实验性特性添加。 首先，我们将了解 AOT 是什么，其次，我们将看一个简单的示例。第三，我们将看到 AOT 的一些限制，最后，我们将讨论一些可能的用例。 什么是提前编译？   AOT 编译是提高 Java 程序性能，尤其是 JVM 启动时间的一种方法。JVM 执行 Java 字节码并将经常执行的代码编译为本机代码。这称为即时 (JIT) 编译。JVM 根据执行期间收集的分析信息决定要 JIT 编译哪些代码。 虽然这种技术使 JVM 能够生成高度优化的代码并提高峰值性能，但启动时间可能不是最佳的，因为执行的代码尚未 JIT 编译。AOT 旨在改善这个所谓的预热期。用于 AOT 的编译器是 Graal。 在本文中，我们不会详细介绍 JIT 和 Graal。请参阅我们的其他文章，了解Java 9 和 10 的性能改进概述 ，以及 对 Graal JIT 编译器的深入了解。 例子   对于这个例子，我们将使用一个非常简单的类，编译它，然后看看如何使用生成的库。 3.1 AOT 编译 让我们快速浏览一下我们的示例类： public class JaotCompilation { public static void main(String[] argv) { System.out.println(message()); } public static String message() { return \u0026#34;The JAOT compiler says \u0026#39;Hello\u0026#39;\u0026#34;; } } 在我们可以使用 AOT 编译器之前，我们需要使用 Java 编译器编译该类： javac JaotCompilation.java 然后我们将生成的 JaotCompilation.class传递 给 AOT 编译器，它与标准 Java 编译器位于同一目录中： jaotc --output jaotCompilation.so JaotCompilation.class 这会在当前目录中生成库 jaotCompilation.so 。 3.2. 运行程序 然后我们可以执行程序： java -XX:AOTLibrary=./jaotCompilation.so JaotCompilation 参数*-XX:AOTLibrary* 接受库的相对或完整路径。或者，我们可以将库复制到 Java 主目录中的lib文件夹中，并且只传递库的名称。 3.3. 验证库是否被调用和使用 通过添加-XX:+PrintAOT作为 JVM 参数，我们可以看到该库确实已加载： java -XX:+PrintAOT -XX:AOTLibrary=./jaotCompilation.so JaotCompilation 输出将如下所示： 77 1 loaded ./jaotCompilation.so aot library 但是，这仅告诉我们库已加载，而不是实际使用。通过传递参数*-verbose*，我们可以看到库中的方法确实被调用了： java -XX:AOTLibrary=./jaotCompilation.so -verbose -XX:+PrintAOT JaotCompilation 输出将包含以下行： 11 1 loaded ./jaotCompilation.so aot library 116 1 aot[ 1] jaotc.JaotCompilation.\u0026lt;init\u0026gt;()V 116 2 aot[ 1] jaotc.JaotCompilation.message()Ljava/lang/String; 116 3 aot[ 1] jaotc.JaotCompilation.main([Ljava/lang/String;)V The JAOT compiler says \u0026#39;Hello\u0026#39; AOT 编译库包含一个类指纹，它必须与.class*文件的指纹匹配。* 让我们更改JaotCompilation.java类中的代码以返回不同的消息： public static String message() { return \u0026#34;The JAOT compiler says \u0026#39;Good morning\u0026#39;\u0026#34;; } 如果我们在没有 AOT 编译修改后的类的情况下执行程序： java -XX:AOTLibrary=./jaotCompilation.so -verbose -XX:+PrintAOT JaotCompilation 然后输出将仅包含： 11 1 loaded ./jaotCompilation.so aot library The JAOT compiler says \u0026#39;Good morning\u0026#39; **我们可以看到库中的方法不会被调用，因为类的字节码已经改变。**这背后的想法是，无论是否加载了 AOT 编译库，程序总是会产生相同的结果。 更多 AOT 和 JVM 参数   4.1 Java 模块的 AOT 编译 也可以 AOT 编译模块： jaotc --output javaBase.so --module java.base 生成的库javaBase.so大小约为 320 MB，加载需要一些时间。可以通过选择要 AOT 编译的包和类来减小大小。 我们将在下面介绍如何做到这一点，但是，我们不会深入研究所有细节。 4.2. 使用编译命令进行选择性编译 **为了防止 Java 模块的 AOT 编译库变得太大，我们可以添加编译命令来限制 AOT 编译的范围。**这些命令需要在一个文本文件中——在我们的示例中，我们将使用文件 complileCommands.txt： compileOnly java.lang.* 然后，我们将其添加到编译命令中： jaotc --output javaBaseLang.so --module java.base --compile-commands compileCommands.txt 生成的库将仅包含java.lang 包中的 AOT 编译类。 为了获得真正的性能改进，我们需要找出在 JVM 预热期间调用了哪些类。 这可以通过添加几个 JVM 参数来实现： java -XX:+UnlockDiagnosticVMOptions -XX:+LogTouchedMethods -XX:+PrintTouchedMethodsAtExit JaotCompilation 在本文中，我们不会深入研究这种技术。 4.3. 单个类的 AOT 编译 我们可以使用参数–class-name编译单个类： jaotc --output javaBaseString.so --class-name java.lang.String 生成的库将仅包含类String。 4.4. 为分层编译 默认情况下，将始终使用 AOT 编译的代码，并且库中包含的类不会发生 JIT 编译。如果我们想在库中包含分析信息，我们可以添加参数 compile-for-tiered： jaotc --output jaotCompilation.so --compile-for-tiered JaotCompilation.class 库中的预编译代码将一直使用，直到字节码符合 JIT 编译条件。 AOT 编译的可能用例   AOT 的一个用例是短运行程序，它在任何 JIT 编译发生之前完成执行。 另一个用例是嵌入式环境，其中 JIT 是不可能的。 此时，我们还需要注意的是，AOT编译库只能从具有相同字节码的Java类中加载，因此无法通过JNI加载。 AOT 和亚马逊 Lambda   AOT 编译代码的一个可能用例是短寿命的 lambda 函数，其中短启动时间很重要。在本节中，我们将了解如何在 AWS Lambda 上运行 AOT 编译的 Java 代码。 **使用 AWS Lambda 进行 AOT 编译需要在与 AWS 上使用的操作系统兼容的操作系统上构建库。**在撰写本文时，这是Amazon Linux 2。 此外，Java 版本需要匹配。AWS 提供了Amazon Corretto Java 11 JVM。为了有一个环境来编译我们的库，我们将在 Docker 中安装Amazon Linux 2和Amazon Corretto 。 我们不会讨论使用 Docker 和 AWS Lambda 的所有细节，而只会概述最重要的步骤。有关如何使用 Docker 的更多信息，请参阅此处的官方文档。 有关使用 Java 创建 Lambda 函数的更多详细信息，您可以查看我们的文章AWS Lambda With Java。 6.1 我们的开发环境的配置 首先，我们需要为Amazon Linux 2拉取 Docker 映像并安装Amazon Corretto： # download Amazon Linux  docker pull amazonlinux # inside the Docker container, install Amazon Corretto yum install java-11-amazon-corretto # some additional libraries needed for jaotc yum install binutils.x86_64 6.2. 编译类和库 在我们的 Docker 容器中，我们执行以下命令： # create folder aot mkdir aot cd aot mkdir jaotc cd jaotc 文件夹的名称只是一个示例，当然可以是任何其他名称。 package jaotc; public class JaotCompilation { public static int message(int input) { return input * 2; } } 下一步是编译类和库： javac JaotCompilation.java cd .. jaotc -J-XX:+UseSerialGC --output jaotCompilation.so jaotc/JaotCompilation.class 在这里，使用与 AWS 上相同的垃圾收集器很重要。如果我们的库无法在 AWS Lambda 上加载，我们可能希望使用以下命令检查实际使用的垃圾收集器： java -XX:+PrintCommandLineFlags -version 现在，我们可以创建一个包含我们的库和类文件的 zip 文件： zip -r jaot.zip jaotCompilation.so jaotc/ 6.3. 配置 AWS Lambda 最后一步是登录 AWS Lamda 控制台，上传 zip 文件并使用以下参数配置 Lambda：  运行时：Java 11 处理程序：jaotc.JaotCompilation::message  此外，我们需要创建一个名为 JAVA_TOOL_OPTIONS 的环境变量并将其值设置为： -XX:+UnlockExperimentalVMOptions -XX:+PrintAOT -XX:AOTLibrary=./jaotCompilation.so 这个变量允许我们将参数传递给 JVM。 最后一步是为我们的 Lambda 配置输入。默认是 JSON 输入，不能传递给我们的函数，因此我们需要将其设置为包含整数的字符串，例如“1”。 最后，我们可以执行我们的 Lambda 函数，并且应该在日志中看到我们的 AOT 编译库已加载： 57 1 loaded ./jaotCompilation.so aot library \u0026quot; ","permalink":"http://itcodingman.github.io/ahead_of_time_compilation/","tags":[],"title":"提前编译 (AoT)"},{"categories":["XML"],"contents":"1. 概述 本教程介绍了Aegis数据绑定，这是一个可以在 Java 对象和 XML 模式描述的 XML 文档之间映射的子系统。Aegis 允许对映射过程进行详细控制，同时将编程工作量降至最低。 Aegis 是Apache CXF的一部分，但不限于仅在此框架内使用。相反，这种数据绑定机制可以在任何地方使用，因此在本教程中，我们将重点关注它作为独立子系统的使用。 2. Maven依赖 激活 Aegis 数据绑定所需的唯一依赖项是： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.cxf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cxf-rt-databinding-aegis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到此工件的最新版本。 3. 类型定义 本节介绍用于说明 Aegis 的三种类型的定义。 3.1。课程 这是我们示例中最简单的类，定义为： public class Course { private int id; private String name; private String instructor; private Date enrolmentDate; // standard getters and setters } 3.2. CourseRepo CourseRepo是我们模型中的顶级类型。我们将它定义为一个接口而不是一个类，以演示编组 Java 接口是多么容易，这在没有自定义适配器的 JAXB 中是不可能的： public interface CourseRepo { String getGreeting(); void setGreeting(String greeting); Map\u0026lt;Integer, Course\u0026gt; getCourses(); void setCourses(Map\u0026lt;Integer, Course\u0026gt; courses); void addCourse(Course course); } 请注意，我们使用返回类型Map声明getCourses方法。这是为了表达 Aegis 相对于 JAXB 的另一个优势。后者无法在没有自定义适配器的情况下编组地图，而前者可以。 3.3. CourseRepoImpl 此类提供CourseRepo接口的实现： public class CourseRepoImpl implements CourseRepo { private String greeting; private Map\u0026lt;Integer, Course\u0026gt; courses = new HashMap\u0026lt;\u0026gt;(); // standard getters and setters  @Override public void addCourse(Course course) { courses.put(course.getId(), course); } } 4. 自定义数据绑定 为了使自定义生效，XML 映射文件必须存在于类路径中。要求将这些文件放在一个目录中，该目录的结构对应于相关 Java 类型的包层次结构。 例如，如果一个完全限定的名称类名为package.ClassName，则其关联的映射文件必须位于类路径上的package/ClassName子目录中。映射文件的名称必须与附加了*.aegis.xml*后缀的关联 Java 类型相同。 4.1 CourseRepo映射 CourseRepo接口属于com.codingman.cxf.aegis包，所以其对应的映射文件命名为CourseRepo.aegis.xml，放到classpath的com/codingman/cxf/aegis目录下。 在CourseRepo映射文件中，我们更改与**CourseRepo接口关联的 XML 元素的名称和命名空间，以及它的greeting属性的样式： \u0026lt;mappings xmlns:ns=\u0026#34;http://courserepo.codingman.com\u0026#34;\u0026gt; \u0026lt;mapping name=\u0026#34;ns:Codingman\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;greeting\u0026#34; style=\u0026#34;attribute\u0026#34;/\u0026gt; \u0026lt;/mapping\u0026gt; \u0026lt;/mappings\u0026gt; 4.2. Course映射 与CourseRepo类型类似， Course类的映射文件名为Course.aegis.xml，也位于com/codingman/cxf/aegis目录下。 在这个映射文件中，我们指示 Aegis 在编组时忽略Course类的instructor属性，以便其值在从输出 XML 文档重新创建的对象中不可用： \u0026lt;mappings\u0026gt; \u0026lt;mapping\u0026gt; \u0026lt;property name=\u0026#34;instructor\u0026#34; ignore=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/mapping\u0026gt; \u0026lt;/mappings\u0026gt; Aegis 的主页是我们可以找到更多自定义选项的地方。 5. 测试 本节是设置和执行测试用例的分步指南，说明 Aegis 数据绑定的使用。 为了方便测试过程，我们在测试类中声明了两个字段： public class CodingmanTest { private AegisContext context; private String fileName = \u0026#34;codingman.xml\u0026#34;; // other methods } 这些字段已在此处定义以供此类的其他方法使用。 5.1 AegisContext初始化 首先，必须创建一个AegisContext对象： context = new AegisContext(); 然后配置并初始化该AegisContext实例。以下是我们为上下文设置根类的方法： Set\u0026lt;Type\u0026gt; rootClasses = new HashSet\u0026lt;Type\u0026gt;(); rootClasses.add(CourseRepo.class); context.setRootClasses(rootClasses); Aegis 为Set对象中的每个类型创建一个 XML 映射元素。在本教程中，我们仅将 CourseRepo设置为根类型。 现在，让我们为上下文设置实现映射，以指定CourseRepo接口的代理类： Map\u0026lt;Class\u0026lt;?\u0026gt;, String\u0026gt; beanImplementationMap = new HashMap\u0026lt;\u0026gt;(); beanImplementationMap.put(CourseRepoImpl.class, \u0026#34;CourseRepo\u0026#34;); context.setBeanImplementationMap(beanImplementationMap); Aegis 上下文的最后一个配置是告诉它在相应的 XML 文档中设置xsi:type 属性。此属性携带相关 Java 对象的实际类型名称，除非被映射文件覆盖： context.setWriteXsiTypes(true); 我们的AegisContext实例现在可以初始化了： context.initialize(); 为了保持代码干净，我们将本小节中的所有代码片段收集到一个辅助方法中： private void initializeContext() { // ... } 5.2. 简单的数据设置 由于本教程的简单性，我们直接在内存中生成示例数据，而不是依赖于持久解决方案。让我们使用以下设置逻辑填充课程存储库： private CourseRepoImpl initCourseRepo() { Course restCourse = new Course(); restCourse.setId(1); restCourse.setName(\u0026#34;REST with Spring\u0026#34;); restCourse.setInstructor(\u0026#34;Eugen\u0026#34;); restCourse.setEnrolmentDate(new Date(1234567890000L)); Course securityCourse = new Course(); securityCourse.setId(2); securityCourse.setName(\u0026#34;Learn Spring Security\u0026#34;); securityCourse.setInstructor(\u0026#34;Eugen\u0026#34;); securityCourse.setEnrolmentDate(new Date(1456789000000L)); CourseRepoImpl courseRepo = new CourseRepoImpl(); courseRepo.setGreeting(\u0026#34;Welcome to Beldung!\u0026#34;); courseRepo.addCourse(restCourse); courseRepo.addCourse(securityCourse); return courseRepo; } 5.3. 绑定 Java 对象和 XML 元素 将 Java 对象编组为 XML 元素需要采取的步骤通过以下辅助方法进行说明： private void marshalCourseRepo(CourseRepo courseRepo) throws Exception { AegisWriter\u0026lt;XMLStreamWriter\u0026gt; writer = context.createXMLStreamWriter(); AegisType aegisType = context.getTypeMapping().getType(CourseRepo.class); XMLStreamWriter xmlWriter = XMLOutputFactory.newInstance() .createXMLStreamWriter(new FileOutputStream(fileName)); writer.write(courseRepo, new QName(\u0026#34;http://aegis.cxf.codingman.com\u0026#34;, \u0026#34;codingman\u0026#34;), false, xmlWriter, aegisType); xmlWriter.close(); } 正如我们所见，AegisWriter和AegisType对象必须从AegisContext实例中创建。然后AegisWriter对象将给定的 Java 实例编组到指定的输出。 在这种情况下，这是一个XMLStreamWriter对象，它与以文件系统中**fileName类级字段的值命名的文件相关联。 以下方法将 XML 文档解组为给定类型的 Java 对象： private CourseRepo unmarshalCourseRepo() throws Exception { AegisReader\u0026lt;XMLStreamReader\u0026gt; reader = context.createXMLStreamReader(); XMLStreamReader xmlReader = XMLInputFactory.newInstance() .createXMLStreamReader(new FileInputStream(fileName)); CourseRepo courseRepo = (CourseRepo) reader.read( xmlReader, context.getTypeMapping().getType(CourseRepo.class)); xmlReader.close(); return courseRepo; } 在这里，从AegisContext实例生成一个**AegisReader对象。然后，AegisReader对象根据提供的输入创建一个 Java 对象。在此示例中，该输入是一个XMLStreamReader对象，该对象由我们在上面描述的**marshalCourseRepo方法中生成的文件支持。 5.4. 测试 现在，是时候将前面小节中定义的所有辅助方法组合成一个测试方法了： @Test public void whenMarshalingAndUnmarshalingCourseRepo_thenCorrect() throws Exception { initializeContext(); CourseRepo inputRepo = initCourseRepo(); marshalCourseRepo(inputRepo); CourseRepo outputRepo = unmarshalCourseRepo(); Course restCourse = outputRepo.getCourses().get(1); Course securityCourse = outputRepo.getCourses().get(2); // JUnit assertions } 我们首先创建一个CourseRepo实例，然后将其编组为 XML 文档，最后解组该文档以重新创建原始对象。让我们验证重新创建的对象是否符合我们的预期： assertEquals(\u0026#34;Welcome to Beldung!\u0026#34;, outputRepo.getGreeting()); assertEquals(\u0026#34;REST with Spring\u0026#34;, restCourse.getName()); assertEquals(new Date(1234567890000L), restCourse.getEnrolmentDate()); assertNull(restCourse.getInstructor()); assertEquals(\u0026#34;Learn Spring Security\u0026#34;, securityCourse.getName()); assertEquals(new Date(1456789000000L), securityCourse.getEnrolmentDate()); assertNull(securityCourse.getInstructor()); 很明显，除了讲师属性之外，所有其他属性的值都已恢复，包括值类型为Date的**enrolmentDate属性。这正是我们所期望的，因为我们已指示 Aegis在编组Course对象时忽略讲师属性。 5.5. 输出 XML 文档 为了使 Aegis 映射文件的效果更加明确，我们在下面展示了没有自定义的 XML 文档： \u0026lt;ns1:codingman xmlns:ns1=\u0026#34;http://aegis.cxf.codingman.com\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;ns1:CourseRepo\u0026#34;\u0026gt; \u0026lt;ns1:courses\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;1\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2009-02-14T06:31:30+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;1\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:instructor\u0026gt;Eugen\u0026lt;/ns1:instructor\u0026gt; \u0026lt;ns1:name\u0026gt;REST with Spring\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;2\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2016-03-01T06:36:40+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;2\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:instructor\u0026gt;Eugen\u0026lt;/ns1:instructor\u0026gt; \u0026lt;ns1:name\u0026gt;Learn Spring Security\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;/ns1:courses\u0026gt; \u0026lt;ns1:greeting\u0026gt;Welcome to Beldung!\u0026lt;/ns1:greeting\u0026gt; \u0026lt;/ns1:codingman\u0026gt; 将此与 Aegis 自定义映射运行时的情况进行比较： \u0026lt;ns1:codingman xmlns:ns1=\u0026#34;http://aegis.cxf.codingman.com\u0026#34; xmlns:ns=\u0026#34;http://courserepo.codingman.com\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;ns:Codingman\u0026#34; greeting=\u0026#34;Welcome to Beldung!\u0026#34;\u0026gt; \u0026lt;ns:courses\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;1\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2009-02-14T06:31:30+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;1\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:name\u0026gt;REST with Spring\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;ns2:entry xmlns:ns2=\u0026#34;urn:org.apache.cxf.aegis.types\u0026#34;\u0026gt; \u0026lt;ns2:key\u0026gt;2\u0026lt;/ns2:key\u0026gt; \u0026lt;ns2:value xsi:type=\u0026#34;ns1:Course\u0026#34;\u0026gt; \u0026lt;ns1:enrolmentDate\u0026gt;2016-03-01T06:36:40+07:00 \u0026lt;/ns1:enrolmentDate\u0026gt; \u0026lt;ns1:id\u0026gt;2\u0026lt;/ns1:id\u0026gt; \u0026lt;ns1:name\u0026gt;Learn Spring Security\u0026lt;/ns1:name\u0026gt; \u0026lt;/ns2:value\u0026gt; \u0026lt;/ns2:entry\u0026gt; \u0026lt;/ns:courses\u0026gt; \u0026lt;/ns1:codingman\u0026gt; 运行本节中定义的测试后，您可以在项目主目录中的codingman.xml中找到这个 XML 结构。 您会看到CourseRepo对象对应的 XML 元素的type属性和命名空间会根据我们在CourseRepo.aegis.xml文件中设置的内容发生变化。greeting属性也转化为一个属性，Course对象的instructor属性如预期般消失了。 值得注意的是，默认情况下，Aegis 将基本 Java 类型转换为最匹配的模式类型，例如从Date对象转换为xsd:dateTime 元素，如本教程所示。但是，我们可以通过在相应的映射文件中设置配置来更改该特定绑定。 如果您想了解更多信息，请导航至Aegis 主页。 \u0026quot; ","permalink":"http://itcodingman.github.io/aegis_data_binding_in_apache_cxf/","tags":["Apache CXF"],"title":"Apache CXF Aegis 数据绑定简介"},{"categories":["Java"],"contents":" 概述   启动服务通常很容易。但是，有时我们需要制定一个优雅地关闭一个的计划。 在本教程中，我们将了解 JVM 应用程序可以终止的不同方式。然后，我们将使用 Java API 来管理 JVM 关闭挂钩。请 参阅本文以了解有关在 Java 应用程序中关闭 JVM 的更多信息。 2.JVM关闭 JVM 可以通过两种不同的方式关闭：  受控过程 突然的方式  在以下任一情况下，受控进程会关闭 JVM：  最后一个非守护线程终止。例如，当主线程退出时，JVM 开始其关闭进程 从操作系统发送中断信号。例如，通过按 Ctrl + C 或注销操作系统 从 Java 代码调用 System.exit()  虽然我们都在努力实现优雅的关闭，但有时 JVM 可能会以突然和意外的方式关闭。JVM 在以下情况下突然关闭：  从操作系统发送终止信号。例如，通过发出 kill -9 \u0026lt;jvm_pid\u0026gt; 从 Java 代码调用 Runtime.getRuntime().halt() 主机操作系统意外死机，例如电源故障或操作系统崩溃  关闭挂钩   JVM 允许注册函数在其完成关闭之前运行。这些功能通常是释放资源或其他类似内务任务的好地方。在 JVM 术语中，这些函数称为 s shutdown hooks。 关闭挂钩基本上是已初始化但未启动的线程。当 JVM 开始其关闭过程时，它将以未指定的顺序启动所有已注册的钩子。运行所有挂钩后，JVM 将停止。 3.1。添加挂钩 为了添加关闭钩子，我们可以使用 *Runtime.getRuntime().addShutdownHook()*方法： Thread printingHook = new Thread(() -\u0026gt; System.out.println(\u0026#34;In the middle of a shutdown\u0026#34;)); Runtime.getRuntime().addShutdownHook(printingHook); 在这里，我们只是在 JVM 自行关闭之前将一些内容打印到标准输出。如果我们像下面这样关闭 JVM： \u0026gt; System.exit(129); In the middle of a shutdown 然后我们将看到钩子实际上将消息打印到标准输出。 JVM 负责启动钩子线程。因此，如果给定的钩子已经启动，Java 将抛出异常： Thread longRunningHook = new Thread(() -\u0026gt; { try { Thread.sleep(300); } catch (InterruptedException ignored) {} }); longRunningHook.start(); assertThatThrownBy(() -\u0026gt; Runtime.getRuntime().addShutdownHook(longRunningHook)) .isInstanceOf(IllegalArgumentException.class) .hasMessage(\u0026#34;Hook already running\u0026#34;); 显然，我们也不能多次注册一个钩子： Thread unfortunateHook = new Thread(() -\u0026gt; {}); Runtime.getRuntime().addShutdownHook(unfortunateHook); assertThatThrownBy(() -\u0026gt; Runtime.getRuntime().addShutdownHook(unfortunateHook)) .isInstanceOf(IllegalArgumentException.class) .hasMessage(\u0026#34;Hook previously registered\u0026#34;); 3.2. 拆除挂钩 Java 提供了一个双重 删除方法来在注册后删除特定的关闭挂钩： Thread willNotRun = new Thread(() -\u0026gt; System.out.println(\u0026#34;Won\u0026#39;t run!\u0026#34;)); Runtime.getRuntime().addShutdownHook(willNotRun); assertThat(Runtime.getRuntime().removeShutdownHook(willNotRun)).isTrue(); 当成功删除关闭挂钩时，removeShutdownHook()方法返回 true 。 3.3. 注意事项 **JVM 仅在正常终止的情况下运行关闭挂钩。**因此，当外力突然杀死 JVM 进程时，JVM 将没有机会执行关闭挂钩。此外，从 Java 代码中停止 JVM 也会产生相同的效果： Thread haltedHook = new Thread(() -\u0026gt; System.out.println(\u0026#34;Halted abruptly\u0026#34;)); Runtime.getRuntime().addShutdownHook(haltedHook); Runtime.getRuntime().halt(129); halt方法强制终止当前运行的 JVM 。因此，注册的关闭钩子将没有机会执行。 \u0026quot; ","permalink":"http://itcodingman.github.io/adding_shutdown_hooks_for_jvm_applications/","tags":["JVM"],"title":"为 JVM 应用程序添加关闭挂钩"},{"categories":["Spring Security"],"contents":"1. 概述 Activiti 是一个开源 BPM（业务流程管理）系统。有关介绍，请查看我们的 Java Activiti 指南。 Activiti 和 Spring 框架都提供了自己的身份管理。但是，在集成了这两个项目的应用程序中，我们可能希望将两者组合成一个用户管理流程。 在下文中，我们将探索实现这一目标的两种可能性：一种是通过为 Spring Security 提供 Activiti 支持的用户服务，另一种是通过将 Spring Security 用户源插入到 Activiti 身份管理中。 2. Maven依赖 要在 Spring Boot 项目中设置 Activiti，请查看我们之前的文章。除了*activiti-spring-boot-starter-basic，*我们还需要activiti-spring-boot-starter-security依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.activiti\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activiti-spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. 使用 Activiti 进行身份管理 对于这个场景，Activiti 启动器提供了一个 Spring Boot 自动配置类，它使用HTTP 基本身份验证保护所有 REST 端点。 自动配置还创建了IdentityServiceUserDetailsService类的UserDetailsService bean。 该类实现了 Spring 接口UserDetailsService并覆盖了*loadUserByUsername()*方法。此方法检索具有给定id的 Activiti User对象，并使用它来创建 Spring UserDetails对象。 此外，Activiti Group对象对应于一个 Spring 用户角色。 这意味着当我们登录 Spring Security 应用程序时，我们将使用 Activiti 凭据。 3.1 设置 Activiti 用户 首先，让我们使用IdentityService在主*@SpringBootApplication类中定义的InitializingBean*中创建一个用户： @Bean InitializingBean usersAndGroupsInitializer(IdentityService identityService) { return new InitializingBean() { public void afterPropertiesSet() throws Exception { User user = identityService.newUser(\u0026#34;activiti_user\u0026#34;); user.setPassword(\u0026#34;pass\u0026#34;); identityService.saveUser(user); Group group = identityService.newGroup(\u0026#34;user\u0026#34;); group.setName(\u0026#34;ROLE_USER\u0026#34;); group.setType(\u0026#34;USER\u0026#34;); identityService.saveGroup(group); identityService.createMembership(user.getId(), group.getId()); } }; } 您会注意到，由于 Spring Security 将使用它，因此Group对象名称必须采用“ROLE_X”形式。 3.2. Spring 安全配置 如果我们想使用不同的安全配置而不是 HTTP Basic 身份验证，首先我们必须排除自动配置： @SpringBootApplication( exclude = org.activiti.spring.boot.SecurityAutoConfiguration.class) public class ActivitiSpringSecurityApplication { // ... } 然后，我们可以提供我们自己的 Spring Security 配置类，它使用*IdentityServiceUserDetailsService 从 Activiti 数据源中检索用户： @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private IdentityService identityService; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService()); } @Bean public UserDetailsService userDetailsService() { return new IdentityServiceUserDetailsService( this.identityService); } // spring security configuration } 4. 使用 Spring Security 进行身份管理 如果我们已经使用 Spring Security 设置了用户管理，并且我们想将 Activiti 添加到我们的应用程序中，那么我们需要自定义 Activiti 的身份管理。 为此，我们必须扩展两个主要类：UserEntityManagerImpl和GroupEntityManagerImpl，它们处理用户和组。 让我们更详细地看一下其中的每一个。 **4.1 扩展UserEntityManagerImpl ** 让我们创建自己的类来扩展UserEntityManagerImpl类： public class SpringSecurityUserManager extends UserEntityManagerImpl { private JdbcUserDetailsManager userManager; public SpringSecurityUserManager( ProcessEngineConfigurationImpl processEngineConfiguration, UserDataManager userDataManager, JdbcUserDetailsManager userManager) { super(processEngineConfiguration, userDataManager); this.userManager = userManager; } // ... } 此类需要上述形式的构造函数，以及 Spring Security 用户管理器。在我们的例子中，我们使用了数据库支持的UserDetailsManager。 我们要覆盖的主要方法是那些处理用户检索的方法：findById()、 findUserByQueryCriteria()和findGroupsByUser()。 findById()方法使用JdbcUserDetailsManager查找UserDetails对象并将其转换为User对象： @Override public UserEntity findById(String userId) { UserDetails userDetails = userManager.loadUserByUsername(userId); if (userDetails != null) { UserEntityImpl user = new UserEntityImpl(); user.setId(userId); return user; } return null; } 接下来，findGroupsByUser()方法查找用户的所有 Spring Security 权限并返回Group对象列表： public List\u0026lt;Group\u0026gt; findGroupsByUser(String userId) { UserDetails userDetails = userManager.loadUserByUsername(userId); if (userDetails != null) { return userDetails.getAuthorities().stream() .map(a -\u0026gt; { Group g = new GroupEntityImpl(); g.setId(a.getAuthority()); return g; }) .collect(Collectors.toList()); } return null; } findUserByQueryCriteria()方法基于具有多个属性的UserQueryImpl对象，我们将从中提取组 id 和用户 id，因为它们在 Spring Security 中具有对应关系： @Override public List\u0026lt;User\u0026gt; findUserByQueryCriteria( UserQueryImpl query, Page page) { // ... } 此方法遵循与上述类似的原则，通过从UserDetails对象创建User对象。 同样，我们有*findUserCountByQueryCriteria()*方法： public long findUserCountByQueryCriteria( UserQueryImpl query) { return findUserByQueryCriteria(query, null).size(); } *checkPassword()*方法应该总是返回 true，因为密码验证不是由 Activiti 完成的： @Override public Boolean checkPassword(String userId, String password) { return true; } 对于其他方法，例如那些处理更新用户的方法，我们只会抛出一个异常，因为这是由 Spring Security 处理的： public User createNewUser(String userId) { throw new UnsupportedOperationException(\u0026#34;This operation is not supported!\u0026#34;); } 4.2. 扩展GroupEntityManagerImpl SpringSecurityGroupManager类似于用户管理器类，除了它处理用户组的事实： public class SpringSecurityGroupManager extends GroupEntityManagerImpl { private JdbcUserDetailsManager userManager; public SpringSecurityGroupManager(ProcessEngineConfigurationImpl processEngineConfiguration, GroupDataManager groupDataManager) { super(processEngineConfiguration, groupDataManager); } // ... } 这里*要覆盖的主要方法是*findGroupsByUser()方法： @Override public List\u0026lt;Group\u0026gt; findGroupsByUser(String userId) { UserDetails userDetails = userManager.loadUserByUsername(userId); if (userDetails != null) { return userDetails.getAuthorities().stream() .map(a -\u0026gt; { Group g = new GroupEntityImpl(); g.setId(a.getAuthority()); return g; }) .collect(Collectors.toList()); } return null; } 该方法检索 Spring Security 用户的权限并将其转换为Group对象列表。 基于此，我们还可以重写*findGroupByQueryCriteria()和findGroupByQueryCriteriaCount()*方法： @Override public List\u0026lt;Group\u0026gt; findGroupByQueryCriteria(GroupQueryImpl query, Page page) { if (query.getUserId() != null) { return findGroupsByUser(query.getUserId()); } return null; } @Override public long findGroupCountByQueryCriteria(GroupQueryImpl query) { return findGroupByQueryCriteria(query, null).size(); } 可以覆盖更新组的其他方法以引发异常： public Group createNewGroup(String groupId) { throw new UnsupportedOperationException(\u0026#34;This operation is not supported!\u0026#34;); } 4.3. 流程引擎配置 在定义了两个身份管理器类之后，我们需要将它们连接到配置中。 spring 启动器为我们自动配置SpringProcessEngineConfiguration。要修改它，我们可以使用InitializingBean： @Autowired private SpringProcessEngineConfiguration processEngineConfiguration; @Autowired private JdbcUserDetailsManager userManager; @Bean InitializingBean processEngineInitializer() { return new InitializingBean() { public void afterPropertiesSet() throws Exception { processEngineConfiguration.setUserEntityManager( new SpringSecurityUserManager(processEngineConfiguration, new MybatisUserDataManager(processEngineConfiguration), userManager)); processEngineConfiguration.setGroupEntityManager( new SpringSecurityGroupManager(processEngineConfiguration, new MybatisGroupDataManager(processEngineConfiguration))); } }; } 在这里，现有的processEngineConfiguration被修改为使用我们的自定义身份管理器。 如果我们想在Activiti中设置当前用户，可以使用方法： identityService.setAuthenticatedUserId(userId); 请记住，这会设置一个ThreadLocal属性，因此每个线程的值都不同。 \u0026quot; ","permalink":"http://itcodingman.github.io/activiti_spring_security/","tags":["Activiti"],"title":"带有 Spring Security 的 Activiti"},{"categories":["Java","Programming"],"contents":"1. 概述 在我们之前的Activiti with Java介绍文章中，我们看到了ProcessEngine的重要性，并通过框架提供的默认静态 API 创建了一个。 除了默认设置之外，还有其他创建ProcessEngine的方法——我们将在这里探讨。 2. 获取ProcessEngine实例 有两种获取ProcessEngine实例的方法：  使用ProcessEngines类 以编程方式，通过ProcessEngineConfiguration  让我们仔细看看这两种方法的示例。 3. 使用ProcessEngines类获取ProcessEngine 通常，ProcessEngine是使用名为activiti.cfg.xml的 XML 文件配置的，默认创建过程也将使用该文件。 这是此配置的外观的快速示例： \u0026lt;beans xmlns=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;processEngineConfiguration\u0026#34; class= \u0026#34;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34; vasentence you have mentioned and also changed thelue=\u0026#34;jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcDriver\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcUsername\u0026#34; value=\u0026#34;root\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcPassword\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseSchemaUpdate\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 注意这里是如何配置引擎的持久性方面的。 现在，我们可以获得ProcessEngine： ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); **4. 使用ProcessEngineConfiguration获取ProcessEngine ** 超越获取引擎的默认路径——有两种创建ProcessEngineConfiguration的方法：  使用 XML 配置 使用 Java 配置  让我们从 XML 配置开始。 如第 2.1 节所述。– 我们可以以编程方式定义ProcessEngineConfiguration ，并使用该实例构建ProcessEngine ： @Test public void givenXMLConfig_whenCreateDefaultConfiguration_thenGotProcessEngine() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createProcessEngineConfigurationFromResourceDefault(); ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;root\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } createProcessEngineConfigurationFromResourceDefault()方法也会查找activiti.cfg.xml文件，现在我们只需要调用buildProcessEngine() API。 在这种情况下，它查找的默认 bean 名称是processEngineConfiguration。如果我们想更改配置文件名或 bean 名称，我们可以使用其他可用的方法来创建ProcessEngineConfiguration。 让我们看几个例子。 首先，我们将更改配置文件名并要求 API 使用我们的自定义文件： @Test public void givenDifferentNameXMLConfig_whenGetProcessEngineConfig_thenGotResult() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createProcessEngineConfigurationFromResource( \u0026#34;my.activiti.cfg.xml\u0026#34;); ProcessEngine processEngine = processEngineConfiguration .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;codingman\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 现在，让我们也更改 bean 名称： @Test public void givenDifferentBeanNameInXMLConfig_whenGetProcessEngineConfig_thenGotResult() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createProcessEngineConfigurationFromResource( \u0026#34;my.activiti.cfg.xml\u0026#34;, \u0026#34;myProcessEngineConfiguration\u0026#34;); ProcessEngine processEngine = processEngineConfiguration .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;codingman\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 当然，既然配置需要不同的名称，我们需要更改文件名（和 bean 名称）以匹配 - 在运行测试之前。 创建引擎的其他可用选项是createProcessEngineConfigurationFromInputStream(InputStream inputStream)、 createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName)。 如果我们不想使用 XML 配置，我们也可以仅使用 Java 配置进行设置。 我们将使用四个不同的类；每一个都代表不同的环境：  org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration – ProcessEngine以独立的方式使用，由数据库支持 *org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration –*默认情况下，使用 H2 内存数据库。数据库在引擎启动和关闭时创建和删除——因此，这种配置风格可用于测试 *org.activiti.spring.SpringProcessEngineConfiguration –*在 Spring 环境中使用 *org.activiti.engine.impl.cfg.JtaProcessEngineConfiguration –*引擎以独立模式运行，带有 JTA 事务  让我们看几个例子。 这是一个用于创建独立流程引擎配置的 JUnit 测试： @Test public void givenNoXMLConfig_whenCreateProcessEngineConfig_thenCreated() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createStandaloneProcessEngineConfiguration(); ProcessEngine processEngine = processEngineConfiguration .setDatabaseSchemaUpdate(ProcessEngineConfiguration .DB_SCHEMA_UPDATE_TRUE) .setJdbcUrl(\u0026#34;jdbc:h2:mem:my-own-db;DB_CLOSE_DELAY=1000\u0026#34;) .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;sa\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 同样，我们将编写一个 JUnit 测试用例，用于使用内存数据库创建独立流程引擎配置： @Test public void givenNoXMLConfig_whenCreateInMemProcessEngineConfig_thenCreated() { ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration .createStandaloneInMemProcessEngineConfiguration(); ProcessEngine processEngine = processEngineConfiguration .buildProcessEngine(); assertNotNull(processEngine); assertEquals(\u0026#34;sa\u0026#34;, processEngine.getProcessEngineConfiguration() .getJdbcUsername()); } 5. 数据库设置 默认情况下，Activiti API 将使用 H2 内存数据库，数据库名称为“activiti”，用户名为“sa”。 如果我们需要使用任何其他数据库，我们必须明确设置——使用两个主要属性。 databaseType – 有效值为h2、mysql、oracle、postgres、mssql、db2。这也可以从数据库配置中找出，但如果自动检测失败，这将很有用。 *databaseSchemaUpdate –*此属性允许我们定义引擎启动或关闭时数据库发生的情况。它可以有以下三个值：  false（默认）– 此选项根据库验证数据库模式的版本。如果它们不匹配，引擎将抛出异常 true – 构建流程引擎配置时，将对数据库执行检查。数据库将相应地创建/更新 create-drop “ - ” - 这将在创建流程引擎时创建数据库模式，并在流程引擎关闭时将其删除。  我们可以将 DB 配置定义为 JDBC 属性： \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34; value=\u0026#34;jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcDriver\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcUsername\u0026#34; value=\u0026#34;sa\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jdbcPassword\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseType\u0026#34; value=\u0026#34;mysql\u0026#34; /\u0026gt; 或者，如果我们使用DataSource： \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.apache.commons.dbcp.BasicDataSource\u0026#34; \u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;com.mysql.jdbc.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/activiti\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;activiti\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;activiti\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;defaultAutoCommit\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseType\u0026#34; value=\u0026#34;mysql\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/activiti_process_engine/","tags":["Activiti"],"title":"Activiti 中的 ProcessEngine 配置"},{"categories":["Java","Programming"],"contents":"1. 概述 在我们之前的文章（基于Java和Spring 的 Activiti API）中，我们看到了如何以编程方式管理进程。如果我们想设置一个演示，连同 Activiti 的 UI，我们有两个 web 应用程序可以让我们在几分钟内完成。 ** activiti-app提供了一个用户界面，用户可以通过它执行任何身份管理和任务管理相关的操作**，创建用户和组。 类似地，** activiti-rest是一个 webapp，它提供 REST API 用于对进程、任务、进程**等执行任何操作。 在本文中，我们将研究如何使用这些 web 应用程序，以及它们提供的功能。 2. 下载 我们可以从Activiti 网站本身下载两个 webapp 的战争文件。 对于 v6.0.0，我们只需下载activiti-6.0.0.zip并解压，war文件可以在activiti-6.0.0/wars目录中找到。 3. 激活 Kickstart 应用程序 我们需要一个有效的Java 运行时和一个Apache Tomcat安装来部署应用程序。任何 Web 容器都可以工作，但 Activiti 主要在 Tomcat 上进行测试。 现在，我们只需要在 Tomcat 上部署war并使用http://localhost:8080/activiti-app访问它。 主页应如下所示： Activiti 3.1 数据库 默认情况下，它使用 H2 内存数据库。如果我们想更改数据库配置，我们可以查看代码并修改activiti-app.properties文件。 完成此操作后，我们需要重新生成 war 文件，这可以通过运行start.sh脚本来完成。这将构建activiti-app以及所需的依赖项。 3.2. 启动应用程序 当我们单击 Kickstart 应用程序时，我们会获得使用流程的选项。我们可以创建/导入进程并从这里运行它们。 让我们创建一个小进程，它有一个User Task，它接收来自用户的消息。进入 Kickstart 应用程序后，要创建流程，请选择流程选项卡，然后单击创建流程： 应用活动创建新模型 流程编辑器将打开，我们可以在其中拖放开始事件、各种类型的任务和结束事件的各种符号来定义流程。 当我们将User Task添加到我们的流程中时，我们需要将其分配给某人。我们可以通过单击此任务选项中的分配并选择受让人来完成。 为简单起见，让我们将任务分配给流程发起者： activiti 应用分配任务 我们还希望此User Task从用户那里获得输入消息。为此，我们需要将带有单个文本字段的表单与此任务相关联。 选择User Task并选择Referenced Form。目前，没有与任务关联的表单，因此单击New Form，并添加所需的详细信息： 活动创建表格 在此之后，它将带我们到表单部分，我们可以在表单中拖放我们想要的各种字段，并为它们设置标签： 活动创建表格 2 请注意，我们勾选了必填项，这意味着如果不输入消息，**用户任务将无法完成。 完成后，我们将保存它并转到“应用程序”选项卡。为了能够运行我们创建的流程，我们需要创建一个 Process App。 在 Process App 中，我们可以添加一个或多个Process Definitions。完成此操作后，我们需要发布此应用程序，以便其他用户可以使用流程： 活动应用发布应用 3.3. 任务应用 在任务应用程序中，有两个选项卡：任务——用于当前运行的任务，进程——用于当前运行的进程。 单击“进程”选项卡中的“启动进程”后，我们将获得可以运行的可用进程列表。从这个列表中，我们将选择我们的进程并单击开始按钮： activiti 应用启动过程 我们的流程只包含一个任务，它是一个用户任务。因此，该进程正在等待用户完成此任务。当我们点击进程正在等待的任务时，我们可以看到我们创建的表单： activiti 给用户输入 如果我们点击Show Diagram，它不仅会显示流程图，还会突出显示已完成的任务和待处理的任务。在我们的例子中，用户任务仍处于未决状态，突出显示： activiti 应用流程图 要完成这个任务，我们可以点击完成按钮n。如前所述，我们需要输入消息，因为我们保持它是强制性的。因此，输入消息后，我们就可以完成任务了。 3.4. 身份管理应用 除了管理流程外，我们还有一个身份管理应用程序，它允许我们添加用户和组。我们还可以为用户定义角色。 4. REST活动 Activiti 为 Activiti Engine 提供了一个 REST API，可以通过将activiti-rest.war文件部署到像 Apache Tomcat 这样的 servlet 容器来安装它。 默认情况下，Activiti Engine 将连接到内存中的 H2 数据库。就像我们在activiti-app中看到的那样，在这里我们可以更改WEB-INF/classes文件夹中db.properties文件中的数据库设置并重新创建 war 文件。 随着应用程序启动并运行，我们可以将这个基本 URL 用于所有请求： http://localhost:8080/activiti-rest/service/ 默认情况下，所有 REST 资源都需要一个有效的 Activiti 用户进行身份验证。每个 REST 调用都应使用基本 HTTP 访问身份验证。 4.1 创建和运行进程 要创建流程，首先，我们需要流程的 BPMN 文件。我们可以创建文件，如我们之前基于Activiti with Java的文章中所述，也可以从 Kickstart App 的 Process 部分下载。 我们需要发出一个 POST 请求以及contentType: multipart/form-data，我们将在其中为我们的新流程上传 BPMN 文件： POST repository/deployments 当我们通过为我们创建的流程传递 BPMN 文件来进行此调用时，它将给出以下输出： { \u0026#34;id\u0026#34;: \u0026#34;40\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;user_msg.bpmn20.xml\u0026#34;, \u0026#34;deploymentTime\u0026#34;: \u0026#34;2017-10-04T17:28:07.963+05:30\u0026#34;, \u0026#34;category\u0026#34;: null, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/repository/deployments/40\u0026#34;, \u0026#34;tenantId\u0026#34;: \u0026#34;\u0026#34; } 现在，如果我们获得所有流程定义，我们可以看到我们列出的流程定义： GET repository/process-definitions 接下来，我们可以使用我们在 BPMN 文件中提到的processKey运行此流程： POST /runtime/process-instances 使用此请求正文： { \u0026#34;processDefinitionKey\u0026#34;:\u0026#34;user_msg\u0026#34; } 响应将是： { \u0026#34;id\u0026#34;: \u0026#34;44\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/runtime/process-instances/44\u0026#34;, \u0026#34;businessKey\u0026#34;: null, \u0026#34;suspended\u0026#34;: false, \u0026#34;ended\u0026#34;: false, \u0026#34;processDefinitionId\u0026#34;: \u0026#34;user_msg:1:43\u0026#34;, \u0026#34;processDefinitionUrl\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/repository/process-definitions/user_msg:1:43\u0026#34;, \u0026#34;processDefinitionKey\u0026#34;: \u0026#34;user_msg\u0026#34;, //other details... } 我们可以使用上一个响应返回的流程实例的id来查看我们正在运行的流程的图表： GET runtime/process-instances/44/diagram 如前所述，该过程正在等待用户任务完成，因此在图中突出显示： 活动休息图 4.2. 完成任务 现在让我们看看我们的待处理任务： GET runtime/tasks 响应将包含待处理任务的列表。目前，只有一项任务——我们的用户任务： { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;49\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8080/activiti-rest/service/runtime/tasks/49\u0026#34;, \u0026#34;owner\u0026#34;: null, \u0026#34;assignee\u0026#34;: \u0026#34;$INITIATOR\u0026#34;, \u0026#34;delegationState\u0026#34;: null, \u0026#34;name\u0026#34;: \u0026#34;User Input Message\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;User Task to take user input\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2017-10-04T17:33:07.205+05:30\u0026#34;, \u0026#34;dueDate\u0026#34;: null, // other details... } } 最后，让我们使用任务id 49完成这个任务： POST runtime/tasks/49 这是一个 POST 请求，我们需要发送指示我们想要对任务执行什么操作的*操作字段。*我们可以“解决”、“完成”或“删除”一项任务。此外，我们可以传递任务所需的变量数组来完成。 在我们的例子中，我们必须传递一个字段“消息”，它是用户消息文本字段。所以我们的请求正文是： { \u0026#34;action\u0026#34;: \u0026#34;complete\u0026#34;, \u0026#34;variables\u0026#34;: [{ \u0026#34;name\u0026#34;: \u0026#34;message\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;This is a User Input Message\u0026#34; }] } \u0026quot; ","permalink":"http://itcodingman.github.io/activiti_kickstart_and_rest_apps/","tags":["Activiti"],"title":"Activiti Kickstart App 和 Activiti Rest Webapp"},{"categories":["Java","REST"],"contents":"1. 概述 在本文中，我们将说明Activeweb——来自 JavaLite 的全栈 Web 框架——提供开发动态 Web 应用程序或 REST-ful Web 服务所需的一切。 2. 基本概念与原则 Activeweb 利用“约定优于配置”——这意味着它是可配置的，但具有合理的默认值并且不需要额外的配置。我们只需要遵循一些预定义的约定，例如以某种预定义的格式命名类、方法和字段。 它还通过重新编译并将源重新加载到正在运行的容器（默认为 Jetty）中来简化开发。 对于依赖管理，它使用 Google Guice 作为 DI 框架；要了解有关 Guice 的更多信息，请在此处查看我们的指南。 Maven 设置   首先，让我们先添加必要的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activeweb\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.15\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最新版本可以在这里找到。 此外，为了测试应用程序，我们需要activeweb-testing依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activeweb-testing\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.15\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 在这里查看最新版本。 4. 应用结构 正如我们所讨论的，应用程序结构需要遵循一定的约定；这是典型的 MVC 应用程序的样子： 我们可以看到，controllers、service、config、models应该位于app包中各自的子包中。 视图应位于WEB-INF/views目录中，每个视图都有基于控制器名称的自己的子目录。例如app.controllers.ArticleController应该有一个*article/*子目录，其中包含该控制器的所有视图文件。 部署描述符或web.xml通常应包含*和相应的。由于框架是一个 servlet 过滤器，所以有一个过滤器配置，而不是*配置： ... \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;dispatcher\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.javalite.activeweb.RequestDispatcher\u0026lt;/filter-class\u0026gt; ... \u0026lt;/filter\u0026gt; ... 我们还需要一个*root_controller来定义应用程序的默认控制器——类似于home*控制器： ... \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;root_controller\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;home\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; ... 5. 控制器 控制器是 ActiveWeb 应用程序的主要组件；并且，如前所述，所有控制器都应位于app.controllers包内： public class ArticleController extends AppController { // ... } 请注意，控制器正在扩展org.javalite.activeweb.AppController。 5.1 控制器 URL 映射 控制器会根据约定自动映射到 URL。例如，ArticleController将被映射到： http://host:port/contextroot/article 现在，这会将它们映射到控制器中的默认操作。动作只不过是控制器内部的方法。将默认方法命名为index()： public class ArticleController extends AppController { // ...  public void index() { render(\u0026#34;articles\u0026#34;); } // ... } 对于其他方法或操作，请将方法名称附加到 URL： public class ArticleController extends AppController { // ...  public void search() { render(\u0026#34;search\u0026#34;); } } 网址： http://host:port/contextroot/article/search 我们甚至可以有基于 HTTP 方法的控制器动作。只需使用*@POST、@PUT、@DELETE、@GET、@HEAD 中的任何一个来注释该方法。*如果我们不注释一个动作，它默认被认为是一个 GET。 5.2. 控制器 URL 解析 该框架使用控制器名称和子包名称来生成控制器 URL。例如app.controllers.ArticleController.java的 URL： http://host:port/contextroot/article 如果控制器位于子包中，则 URL 简单地变为： http://host:port/contextroot/codingman/article 对于包含多个单词的控制器名称（例如app.controllers.PublishedArticleController.java），URL 将使用下划线分隔： http://host:port/contextroot/published_article 5.3. 检索请求参数 在控制器内部，我们可以使用AppController 类的*param()或params()*方法访问请求参数。第一个方法接受一个字符串参数——要检索的参数的名称： public void search() { String keyword = param(\u0026#34;key\u0026#34;); view(\u0026#34;search\u0026#34;,articleService.search(keyword)); } 如果需要，我们可以使用后者来获取所有参数： public void search() { Map\u0026lt;String, String[]\u0026gt; criterion = params(); // ... } 6. 意见 在 ActiveWeb 术语中，视图通常称为模板。这主要是因为它使用 Apache FreeMarker模板引擎而不是 JSP。您可以在我们的指南中阅读有关 FreeMarker的更多信息，请点击此处。 将模板放在WEB-INF/views目录中。每个控制器都应该有一个按其名称命名的子目录，其中包含它所需的所有模板。 6.1 控制器视图映射 当一个控制器被点击时，默认的动作index()被执行并且框架将选择WEB-INF/views/article/ index.ftl模板作为该控制器的视图目录。同样，对于任何其他操作，将根据操作名称选择视图。 这并不总是我们想要的。有时我们可能希望根据内部业务逻辑返回一些视图。在这种情况下，我们可以使用父类org.javalite.activeweb.AppController类的*render()*方法来控制进程： public void index() { render(\u0026#34;articles\u0026#34;); } 请注意，自定义视图的位置也应该在该控制器的同一视图目录中。如果不是这种情况，则在模板名称前面加上模板所在的目录名称，并将其传递给*render()*方法： render(\u0026#34;/common/error\u0026#34;); 6.3. 数据视图 为了向视图发送数据，org.javalite.activeweb.AppController提供了*view()*方法： view(\u0026#34;articles\u0026#34;, articleService.getArticles()); 这需要两个参数。首先，用于访问模板中对象的对象名称，其次是包含数据的对象。 我们还可以使用*assign()*方法将数据传递给视图。*view() 和assign()*方法之间绝对没有区别——我们可以选择其中任何一种： assign(\u0026#34;article\u0026#34;, articleService.search(keyword)); 让我们映射模板中的数据： \u0026lt;@content for=\u0026#34;title\u0026#34;\u0026gt;Articles\u0026lt;/@content\u0026gt; ... \u0026lt;#list articles as article\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;${article.title}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${article.author}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${article.words}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${article.date}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/#list\u0026gt; \u0026lt;/table\u0026gt; 7. 管理依赖 为了管理对象和实例，ActiveWeb 使用 Google Guice 作为依赖管理框架。 假设我们的应用程序中需要一个服务类；这会将业务逻辑与控制器分开。 我们先创建一个服务接口： public interface ArticleService { List\u0026lt;Article\u0026gt; getArticles(); Article search(String keyword); } 和实施： public class ArticleServiceImpl implements ArticleService { public List\u0026lt;Article\u0026gt; getArticles() { return fetchArticles(); } public Article search(String keyword) { Article ar = new Article(); ar.set(\u0026#34;title\u0026#34;, \u0026#34;Article with \u0026#34;+keyword); ar.set(\u0026#34;author\u0026#34;, \u0026#34;codingman\u0026#34;); ar.set(\u0026#34;words\u0026#34;, \u0026#34;1250\u0026#34;); ar.setDate(\u0026#34;date\u0026#34;, Instant.now()); return ar; } } 现在，让我们将此服务绑定为 Guice 模块： public class ArticleServiceModule extends AbstractModule { @Override protected void configure() { bind(ArticleService.class).to(ArticleServiceImpl.class) .asEagerSingleton(); } } 最后，在应用程序上下文中注册它并根据需要将其注入控制器： public class AppBootstrap extends Bootstrap { public void init(AppContext context) { } public Injector getInjector() { return Guice.createInjector(new ArticleServiceModule()); } } 请注意，此配置类名称必须是AppBootstrap，并且它应该位于app.config包中。 最后，这是我们将其注入控制器的方法： @Inject private ArticleService articleService; 8. 测试 ActiveWeb 应用程序的单元测试是使用 JavaLite 的JSpec库编写的。 我们将使用 JSpec 中的org.javalite.activeweb.ControllerSpec类来测试我们的控制器，我们将按照类似的约定命名测试类： public class ArticleControllerSpec extends ControllerSpec { // ... } 请注意，该名称类似于它正在测试的控制器，末尾带有“Spec”。 这是测试用例： @Test public void whenReturnedArticlesThenCorrect() { request().get(\u0026#34;index\u0026#34;); a(responseContent()) .shouldContain(\u0026#34;\u0026lt;td\u0026gt;Introduction to Mule\u0026lt;/td\u0026gt;\u0026#34;); } 请注意，*request()方法模拟了对控制器的调用，而相应的 HTTP 方法get()*将操作名称作为参数。 我们还可以使用*params()*方法将参数传递给控制器： @Test public void givenKeywordWhenFoundArticleThenCorrect() { request().param(\u0026#34;key\u0026#34;, \u0026#34;Java\u0026#34;).get(\u0026#34;search\u0026#34;); a(responseContent()) .shouldContain(\u0026#34;\u0026lt;td\u0026gt;Article with Java\u0026lt;/td\u0026gt;\u0026#34;); } 要传递多个参数，我们也可以使用这个流畅的 API 链接方法。 部署应用程序   可以将应用程序部署在任何 servlet 容器中，例如 Tomcat、WildFly 或 Jetty。当然，部署和测试最简单的方法是使用 Maven Jetty 插件： ... \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetty-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.4.8.v20171121\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;reload\u0026gt;manual\u0026lt;/reload\u0026gt; \u0026lt;scanIntervalSeconds\u0026gt;10000\u0026lt;/scanIntervalSeconds\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; ... 最新版本的插件在这里。 现在，终于 - 我们可以启动它了： mvn jetty:run \u0026quot; ","permalink":"http://itcodingman.github.io/activeweb/","tags":[],"title":"ActiveWeb 简介"},{"categories":["Persistence"],"contents":" 简介   ActiveJDBC 是一个轻量级的 ORM，它遵循ActiveRecord的核心思想，它是 Ruby on Rails 的主要 ORM。 它侧重于**通过删除典型持久性管理器的额外层来简化与数据库的交互，**并侧重于 SQL 的使用，而不是创建新的查询语言。 此外，它通过DBSpec类为数据库交互提供了自己的编写单元测试的方式。 让我们看看这个库与其他流行的 Java ORM 有何不同以及如何使用它。 ActiveJDBC 与其他 ORM   与大多数其他 Java ORM 相比，ActiveJDBC 有明显的不同。它从数据库中推断出 DB 模式参数，从而无需将实体映射到基础表。 没有会话，没有持久性管理器，不需要学习新的查询语言，没有 getter/setter。库本身在大小和依赖数量方面很轻。 该实现鼓励使用在执行测试后由框架清理的测试数据库，从而降低维护测试数据库的成本。 但是，每当我们创建或更新模型时，都需要一些额外的检测步骤。我们将在接下来的部分讨论这个问题。 设计原则    从数据库推断元数据 基于约定的配置 没有会话，没有“附加，重新附加” 轻量级模型，简单 POJO 无代理 避免Anemic域模型 不需要 DAO 和 DTO  设置java包   使用 MySQL 数据库的典型 Maven 设置包括： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activejdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.34\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在 Maven 中央存储库中找到最新版本的activejdbc和mysql 连接器工件。 Instrumentation是简化的代价，在处理 ActiveJDBC 项目时需要。 有一个仪器插件需要在项目中配置： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.javalite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activejdbc-instrumentation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.13\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;process-classes\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;instrument\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 最新的activejdbc-instrumentation插件也可以在 Maven Central 中找到。 现在，我们可以通过执行以下两个命令之一来处理检测： mvn process-classes mvn activejdbc-instrumentation:instrument 使用 ActiveJDBC   5.1 模型 我们可以只用一行代码创建一个简单的模型——它涉及扩展Model类。 该库使用反射来实现名词的复数和单数形式的转换。这可以使用*@Table*注释覆盖。 让我们看看一个简单的模型是什么样子的： import org.javalite.activejdbc.Model; public class Employee extends Model {} 5.2 连接到数据库 提供了两个类——Base和DB——来连接数据库。 连接数据库的最简单方法是： Base.open(\u0026#34;com.mysql.jdbc.Driver\u0026#34;, \u0026#34;jdbc:mysql://host/organization\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;xxxxx\u0026#34;); 当模型在运行时，它们利用在当前线程中找到的连接。在任何 DB 操作之前，此连接由Base或DB类放在本地线程上。 上述方法允许使用更简洁的 API，无需像其他 Java ORM 中那样使用 DB Session 或 Persistence 管理器。 让我们看看如何使用DB类连接到数据库： new DB(\u0026#34;default\u0026#34;).open( \u0026#34;com.mysql.jdbc.Driver\u0026#34;, \u0026#34;jdbc:mysql://localhost/dbname\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;XXXXXX\u0026#34;); 如果我们看看Base和DB用于连接数据库的不同之处，它有助于我们得出结论，如果在单个数据库上操作应该使用Base ，而DB应该与多个数据库一起使用。 5.3. 插入记录 向数据库中添加记录非常简单。如前所述，不需要 setter 和 getter： Employee e = new Employee(); e.set(\u0026#34;first_name\u0026#34;, \u0026#34;Hugo\u0026#34;); e.set(\u0026#34;last_name\u0026#34;, \u0026#34;Choi\u0026#34;); e.saveIt(); 或者，我们可以通过这种方式添加相同的记录： Employee employee = new Employee(\u0026#34;Hugo\u0026#34;,\u0026#34;Choi\u0026#34;); employee.saveIt(); 甚至，流利地： new Employee() .set(\u0026#34;first_name\u0026#34;, \u0026#34;Hugo\u0026#34;, \u0026#34;last_name\u0026#34;, \u0026#34;Choi\u0026#34;) .saveIt(); 5.4. 更新记录 下面的代码片段显示了如何更新记录： Employee employee = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); employee .set(\u0026#34;last_name\u0026#34;,\u0026#34;Choi\u0026#34;) .saveIt(); 5.5. 删除记录 Employee e = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); e.delete(); 如果需要删除所有记录： Employee.deleteAll(); 如果我们想从级联到子表的主表中删除一条记录，请使用deleteCascade： Employee employee = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;,\u0026#34;Hugo\u0026#34;); employee.deleteCascade(); 5.6. 获取记录 让我们从数据库中获取一条记录： Employee e = Employee.findFirst(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); 如果我们想获取多条记录，我们可以使用where方法： List\u0026lt;Employee\u0026gt; employees = Employee.where(\u0026#34;first_name = ?\u0026#34;, \u0026#34;Hugo\u0026#34;); 6.交易支持 在 Java ORM 中，存在显式连接或管理器对象（JPA 中的 EntityManager、Hibernate 中的 SessionManager 等）。ActiveJDBC 中没有这样的东西。 调用*Base.open()打开一个连接，将其附加到当前线程，因此所有模型的所有后续方法都重用此连接。调用Base.close()*关闭连接并将其从当前线程中删除。 为了管理事务，有几个方便的调用： 开始交易： Base.openTransaction(); 提交事务： Base.commitTransaction(); 回滚事务： Base.rollbackTransaction(); 支持的数据库   最新版本支持 SQLServer、MySQL、Oracle、PostgreSQL、H2、SQLite3、DB2 等数据库。 \u0026quot; ","permalink":"http://itcodingman.github.io/active_jdbc/","tags":[],"title":"ActiveJDBC 简介"},{"categories":["Java"],"contents":"1. 概述 术语套接字编程是指编写跨多台计算机执行的程序，其中设备都使用网络相互连接。 我们可以使用两种通信协议进行套接字编程：用户数据报协议（UDP）和传输控制协议（TCP）。 两者的主要区别在于 UDP 是无连接的，这意味着客户端和服务器之间没有会话，而 TCP 是面向连接的，这意味着必须首先在客户端和服务器之间建立独占连接才能进行通信. 本教程介绍TCP/IP网络上的套接字编程，并演示如何用 Java 编写客户端/服务器应用程序。UDP 不是主流协议，因此可能不会经常遇到。 2. 项目设置 Java 提供了一组类和接口来处理客户端和服务器之间的低级通信细节。 这些大部分都包含在java.net包中，因此我们需要进行以下导入： import java.net.*; 我们还需要java.io包，它为我们提供了在通信时写入和读取的输入和输出流： import java.io.*; 为简单起见，我们将在同一台计算机上运行我们的客户端和服务器程序。如果我们要在不同的联网计算机上执行它们，唯一会改变的是 IP 地址。在这种情况下，我们将在127.0.0.1上使用localhost。 3. 简单例子 让我们用涉及客户端和服务器的最基本示例来动手。这将是一个双向通信应用程序，客户端向服务器打招呼，服务器响应。 我们将使用以下代码在名为GreetServer.java的类中创建服务器应用程序。 我们将包括main方法和全局变量，以提醒我们如何在本文中运行所有服务器。对于本文中的其余示例，我们将省略这种重复代码： public class GreetServer { private ServerSocket serverSocket; private Socket clientSocket; private PrintWriter out; private BufferedReader in; public void start(int port) { serverSocket = new ServerSocket(port); clientSocket = serverSocket.accept(); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); String greeting = in.readLine(); if (\u0026#34;hello server\u0026#34;.equals(greeting)) { out.println(\u0026#34;hello client\u0026#34;); } else { out.println(\u0026#34;unrecognised greeting\u0026#34;); } } public void stop() { in.close(); out.close(); clientSocket.close(); serverSocket.close(); } public static void main(String[] args) { GreetServer server=new GreetServer(); server.start(6666); } } 我们还将使用以下代码创建一个名为GreetClient.java的客户端： public class GreetClient { private Socket clientSocket; private PrintWriter out; private BufferedReader in; public void startConnection(String ip, int port) { clientSocket = new Socket(ip, port); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); } public String sendMessage(String msg) { out.println(msg); String resp = in.readLine(); return resp; } public void stopConnection() { in.close(); out.close(); clientSocket.close(); } } **现在让我们启动服务器。**在我们的 IDE 中，我们只需将其作为 Java 应用程序运行即可。 然后我们将使用单元测试向服务器发送问候语，确认服务器发送问候语作为响应： @Test public void givenGreetingClient_whenServerRespondsWhenStarted_thenCorrect() { GreetClient client = new GreetClient(); client.startConnection(\u0026#34;127.0.0.1\u0026#34;, 6666); String response = client.sendMessage(\u0026#34;hello server\u0026#34;); assertEquals(\u0026#34;hello client\u0026#34;, response); } 这个例子让我们对本文后面的内容有所了解。因此，我们可能还没有完全理解这里发生了什么。 在接下来的部分中，我们将使用这个简单的示例来剖析套接字通信，并深入研究更复杂的示例。 4. 套接字如何工作 我们将使用上面的示例来逐步介绍本节的不同部分。 根据定义，套接字是网络上不同计算机上运行的两个程序之间双向通信链路的一个端点。套接字绑定到端口号，以便传输层可以识别数据要发送到的应用程序。 4.1 服务器 通常，服务器在网络上的特定计算机上运行，并且有一个绑定到特定端口号的套接字。在我们的例子中，我们将使用与客户端相同的计算机，并在端口6666上启动服务器： ServerSocket serverSocket = new ServerSocket(6666); 服务器只是等待，侦听套接字以供客户端发出连接请求。这发生在下一步中： Socket clientSocket = serverSocket.accept(); 当服务器代码遇到accept方法时，它会阻塞，直到客户端向它发出连接请求。 如果一切顺利，服务器接受连接。接受后，服务器会获得一个新的套接字clientSocket，绑定到相同的本地端口6666，并将其远程端点设置为客户端的地址和端口。 此时，新的Socket对象将服务器与客户端直接连接。然后，我们可以访问输出和输入流，分别向客户端写入和接收消息： PrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); BufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); 现在，服务器能够与客户端无休止地交换消息，直到套接字与其流一起关闭。 但是，在我们的示例中，服务器只能在关闭连接之前发送问候响应。这意味着如果我们再次运行测试，服务器将拒绝连接。 为了保持通信的连续性，我们必须在while循环内从输入流中读取数据，并且仅在客户端发送终止请求时退出。我们将在下一节中看到这一点。 对于每个新客户端，服务器都需要一个由接受调用返回的新套接字。我们使用serverSocket继续监听连接请求，同时倾向于连接客户端的需求。在我们的第一个示例中，我们还没有允许这样做。 4.2 客户端 客户端必须知道服务器正在运行的机器的主机名或 IP，以及服务器正在侦听的端口号。 为了发出连接请求，客户端尝试在服务器的机器和端口上与服务器会合： Socket clientSocket = new Socket(\u0026#34;127.0.0.1\u0026#34;, 6666); 客户端还需要向服务器标识自己，因此它绑定到系统分配的本地端口号，它将在此连接期间使用。我们自己不处理这个。 上面的构造函数只在服务器接受连接时创建一个新的套接字；否则，我们会得到一个连接被拒绝的异常。创建成功后，我们就可以从中获取输入输出流，与服务器进行通信： PrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); BufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); 客户端的输入流连接到服务器的输出流，就像服务器的输入流连接到客户端的输出流一样。 5. 持续沟通 我们当前的服务器阻塞，直到客户端连接到它，然后再次阻塞以收听来自客户端的消息。在单个消息之后，它会关闭连接，因为我们还没有处理连续性。 因此，它仅对 ping 请求有用。但是想象一下我们想要实现一个聊天服务器；肯定需要服务器和客户端之间的持续来回通信。 我们必须创建一个 while 循环来持续观察服务器的输入流以获取传入消息。 因此，让我们创建一个名为EchoServer.java 的新服务器，其唯一目的是回显从客户端接收到的任何消息： public class EchoServer { public void start(int port) { serverSocket = new ServerSocket(port); clientSocket = serverSocket.accept(); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); String inputLine; while ((inputLine = in.readLine()) != null) { if (\u0026#34;.\u0026#34;.equals(inputLine)) { out.println(\u0026#34;good bye\u0026#34;); break; } out.println(inputLine); } } 请注意，我们添加了一个终止条件，当我们收到一个句点字符时，while 循环退出。 我们将使用 main 方法启动EchoServer，就像我们对GreetServer所做的那样。这一次，我们在另一个端口上启动它，例如*4444，*以避免混淆。 EchoClient类似于GreetClient ，因此我们可以复制代码。为了清楚起见，我们将它们分开。 在一个不同的测试类中，我们将创建一个测试来显示多个对EchoServer的请求将在服务器关闭套接字的情况下得到处理。只要我们从同一个客户端发送请求，情况就是如此。 与多个客户打交道是另一种情况，我们将在下一节中看到。 现在让我们创建一个设置方法来启动与服务器的连接： @Before public void setup() { client = new EchoClient(); client.startConnection(\u0026#34;127.0.0.1\u0026#34;, 4444); } 我们还将创建一个tearDown方法来释放我们所有的资源。这是我们使用网络资源的每种情况的最佳实践： @After public void tearDown() { client.stopConnection(); } 然后我们将使用一些请求来测试我们的 echo 服务器： @Test public void givenClient_whenServerEchosMessage_thenCorrect() { String resp1 = client.sendMessage(\u0026#34;hello\u0026#34;); String resp2 = client.sendMessage(\u0026#34;world\u0026#34;); String resp3 = client.sendMessage(\u0026#34;!\u0026#34;); String resp4 = client.sendMessage(\u0026#34;.\u0026#34;); assertEquals(\u0026#34;hello\u0026#34;, resp1); assertEquals(\u0026#34;world\u0026#34;, resp2); assertEquals(\u0026#34;!\u0026#34;, resp3); assertEquals(\u0026#34;good bye\u0026#34;, resp4); } 这是对初始示例的改进，在初始示例中，我们只在服务器关闭我们的连接之前通信一次。现在我们发送一个终止信号来告诉服务器我们什么时候完成了会话。 6. 多客户端服务器 尽管前面的示例比第一个示例有所改进，但它仍然不是一个很好的解决方案。服务器必须能够同时为许多客户端和许多请求提供服务。 处理多个客户端是我们将在本节中介绍的内容。 我们将在这里看到的另一个特性是，同一个客户端可以断开连接并再次重新连接，而不会出现连接被拒绝异常或服务器上的连接重置。我们以前无法做到这一点。 这意味着我们的服务器将在来自多个客户端的多个请求中更加健壮和有弹性。 为此，我们将为每个新客户端创建一个新套接字，并为该客户端在不同线程上的请求提供服务。同时服务的客户端数量将等于运行的线程数。 主线程在侦听新连接时将运行一个 while 循环。 现在让我们看看它的实际效果。我们将创建另一个名为EchoMultiServer.java的服务器。在其中，我们将创建一个处理程序线程类来管理每个客户端在其套接字上的通信： public class EchoMultiServer { private ServerSocket serverSocket; public void start(int port) { serverSocket = new ServerSocket(port); while (true) new EchoClientHandler(serverSocket.accept()).start(); } public void stop() { serverSocket.close(); } private static class EchoClientHandler extends Thread { private Socket clientSocket; private PrintWriter out; private BufferedReader in; public EchoClientHandler(Socket socket) { this.clientSocket = socket; } public void run() { out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader( new InputStreamReader(clientSocket.getInputStream())); String inputLine; while ((inputLine = in.readLine()) != null) { if (\u0026#34;.\u0026#34;.equals(inputLine)) { out.println(\u0026#34;bye\u0026#34;); break; } out.println(inputLine); } in.close(); out.close(); clientSocket.close(); } } 请注意，我们现在在while循环中调用了accept 。每次执行while循环时，它都会阻塞accept调用，直到有新的客户端连接。然后为该客户端创建处理程序线程EchoClientHandler。 线程内部发生的事情与EchoServer相同，我们只处理一个客户端。EchoMultiServer将此工作委托给EchoClientHandler，以便它可以在while循环中继续侦听更多客户端。 我们仍将使用EchoClient来测试服务器。这一次，我们将创建多个客户端，每个客户端从服务器发送和接收多条消息。 让我们使用端口5555上的 main 方法启动我们的服务器。 为清楚起见，我们仍将测试放在一个新套件中： @Test public void givenClient1_whenServerResponds_thenCorrect() { EchoClient client1 = new EchoClient(); client1.startConnection(\u0026#34;127.0.0.1\u0026#34;, 5555); String msg1 = client1.sendMessage(\u0026#34;hello\u0026#34;); String msg2 = client1.sendMessage(\u0026#34;world\u0026#34;); String terminate = client1.sendMessage(\u0026#34;.\u0026#34;); assertEquals(msg1, \u0026#34;hello\u0026#34;); assertEquals(msg2, \u0026#34;world\u0026#34;); assertEquals(terminate, \u0026#34;bye\u0026#34;); } @Test public void givenClient2_whenServerResponds_thenCorrect() { EchoClient client2 = new EchoClient(); client2.startConnection(\u0026#34;127.0.0.1\u0026#34;, 5555); String msg1 = client2.sendMessage(\u0026#34;hello\u0026#34;); String msg2 = client2.sendMessage(\u0026#34;world\u0026#34;); String terminate = client2.sendMessage(\u0026#34;.\u0026#34;); assertEquals(msg1, \u0026#34;hello\u0026#34;); assertEquals(msg2, \u0026#34;world\u0026#34;); assertEquals(terminate, \u0026#34;bye\u0026#34;); } 我们可以根据需要创建尽可能多的这些测试用例，每个都生成一个新客户端，服务器将为它们提供服务。 \u0026quot; ","permalink":"http://itcodingman.github.io/a_guide_to_java_sockets/","tags":["Java IO"],"title":"Java 套接字指南"},{"categories":["Java"],"contents":" 概述   在本教程中，我们将了解 Java 枚举是什么，它们解决了哪些问题，以及如何在实践中使用它们的一些设计模式。 **Java 5 首次引入了enum关键字。**它表示一种特殊类型的类，它总是扩展java.lang.Enum类。有关使用的官方文档，我们可以前往文档。 以这种方式定义的常量使代码更具可读性，允许编译时检查，预先记录接受值的列表，并避免由于传入无效值而导致的意外行为。 这是一个定义披萨订单状态的快速简单的枚举示例；订单状态可以是ORDERED、READY或DELIVERED： public enum PizzaStatus { ORDERED, READY, DELIVERED; } 此外，枚举带有许多有用的方法，如果我们使用传统的公共静态最终常量，我们将需要编写这些方法。 2. 自定义枚举方法 现在我们对枚举是什么以及如何使用它们有了基本的了解，我们将通过在枚举上定义一些额外的 API 方法，将前面的示例提升到一个新的水平： public class Pizza { private PizzaStatus status; public enum PizzaStatus { ORDERED, READY, DELIVERED; } public boolean isDeliverable() { if (getStatus() == PizzaStatus.READY) { return true; } return false; } // Methods that set and get the status variable. } 3. 使用“==”运算符比较枚举类型 由于枚举类型确保 JVM 中仅存在一个常量实例，因此我们可以安全地使用“==”运算符来比较两个变量，就像我们在上面的示例中所做的那样。此外，“==”运算符提供编译时和运行时安全性。 首先，我们将在以下代码段中查看**运行时安全性，其中我们将使用“==”运算符来比较状态。**任何一个值都可以为 空，我们不会得到 NullPointerException。相反，如果我们使用 equals 方法，我们会得到一个NullPointerException： if(testPz.getStatus().equals(Pizza.PizzaStatus.DELIVERED)); if(testPz.getStatus() == Pizza.PizzaStatus.DELIVERED); 至于编译时安全性，让我们看一个示例，我们将通过使用equals方法进行比较来确定不同类型的枚举是否相等。这是因为 enum 和getStatus方法的值恰好是相同的；但是，从逻辑上讲，比较应该是错误的。我们通过使用“==”运算符来避免这个问题。 编译器会将比较标记为不兼容错误： if(testPz.getStatus().equals(TestColor.GREEN)); if(testPz.getStatus() == TestColor.GREEN); 4. 在 Switch 语句中使用枚举类型 我们也可以在switch语句中使用枚举类型： public int getDeliveryTimeInDays() { switch (status) { case ORDERED: return 5; case READY: return 2; case DELIVERED: return 0; } return 0; } 5. 枚举中的字段、方法和构造函数 我们可以在枚举类型中定义构造函数、方法和字段，这使得它们非常强大。 接下来，让我们通过实现从披萨订单的一个阶段到另一个阶段的转换来扩展上面的示例。我们将看到如何摆脱之前使用的if和switch语句： public class Pizza { private PizzaStatus status; public enum PizzaStatus { ORDERED (5){ @Override public boolean isOrdered() { return true; } }, READY (2){ @Override public boolean isReady() { return true; } }, DELIVERED (0){ @Override public boolean isDelivered() { return true; } }; private int timeToDelivery; public boolean isOrdered() {return false;} public boolean isReady() {return false;} public boolean isDelivered(){return false;} public int getTimeToDelivery() { return timeToDelivery; } PizzaStatus (int timeToDelivery) { this.timeToDelivery = timeToDelivery; } } public boolean isDeliverable() { return this.status.isReady(); } public void printTimeToDeliver() { System.out.println(\u0026#34;Time to delivery is \u0026#34; + this.getStatus().getTimeToDelivery()); } // Methods that set and get the status variable. } 下面的测试片段演示了它是如何工作的： @Test public void givenPizaOrder_whenReady_thenDeliverable() { Pizza testPz = new Pizza(); testPz.setStatus(Pizza.PizzaStatus.READY); assertTrue(testPz.isDeliverable()); } EnumSet和EnumMap   6.1 EnumSet EnumSet是一个专门的Set实现，旨在与Enum类型一起使用。 与HashSet相比，由于使用了内部位向量表示，它是一组特定枚举常量的非常有效和紧凑的表示。它还为传统的基于int的“位标志”提供了一种类型安全的替代方案，使我们能够编写更易读和更易于维护的简洁代码。 EnumSet是一个抽象类，它有两个实现，RegularEnumSet和JumboEnumSet，其中一个是根据实例化时枚举中常量的数量来选择的。 因此，在大多数情况下（如子集、添加、删除和批量操作，如containsAll和removeAll），只要我们想使用枚举常量集合，最好使用这个集合，如果我们使用*Enum.values()*只想遍历所有可能的常量。 在下面的代码片段中，我们可以看到如何使用EnumSet创建常量子集： public class Pizza { private static EnumSet\u0026lt;PizzaStatus\u0026gt; undeliveredPizzaStatuses = EnumSet.of(PizzaStatus.ORDERED, PizzaStatus.READY); private PizzaStatus status; public enum PizzaStatus { ... } public boolean isDeliverable() { return this.status.isReady(); } public void printTimeToDeliver() { System.out.println(\u0026#34;Time to delivery is \u0026#34; + this.getStatus().getTimeToDelivery() + \u0026#34; days\u0026#34;); } public static List\u0026lt;Pizza\u0026gt; getAllUndeliveredPizzas(List\u0026lt;Pizza\u0026gt; input) { return input.stream().filter( (s) -\u0026gt; undeliveredPizzaStatuses.contains(s.getStatus())) .collect(Collectors.toList()); } public void deliver() { if (isDeliverable()) { PizzaDeliverySystemConfiguration.getInstance().getDeliveryStrategy() .deliver(this); this.setStatus(PizzaStatus.DELIVERED); } } // Methods that set and get the status variable. } 执行以下测试演示了Set接口的EnumSet实现的强大功能： @Test public void givenPizaOrders_whenRetrievingUnDeliveredPzs_thenCorrectlyRetrieved() { List\u0026lt;Pizza\u0026gt; pzList = new ArrayList\u0026lt;\u0026gt;(); Pizza pz1 = new Pizza(); pz1.setStatus(Pizza.PizzaStatus.DELIVERED); Pizza pz2 = new Pizza(); pz2.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz3 = new Pizza(); pz3.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz4 = new Pizza(); pz4.setStatus(Pizza.PizzaStatus.READY); pzList.add(pz1); pzList.add(pz2); pzList.add(pz3); pzList.add(pz4); List\u0026lt;Pizza\u0026gt; undeliveredPzs = Pizza.getAllUndeliveredPizzas(pzList); assertTrue(undeliveredPzs.size() == 3); } 6.2. EnumMap EnumMap是一种专门的Map实现，旨在与枚举常量一起用作键。与其对应的HashMap 相比，它是一种高效且紧凑的实现，内部表示为数组： EnumMap\u0026lt;Pizza.PizzaStatus, Pizza\u0026gt; map; 让我们看一个如何在实践中使用它的示例： public static EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; groupPizzaByStatus(List\u0026lt;Pizza\u0026gt; pizzaList) { EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; pzByStatus = new EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt;(PizzaStatus.class); for (Pizza pz : pizzaList) { PizzaStatus status = pz.getStatus(); if (pzByStatus.containsKey(status)) { pzByStatus.get(status).add(pz); } else { List\u0026lt;Pizza\u0026gt; newPzList = new ArrayList\u0026lt;Pizza\u0026gt;(); newPzList.add(pz); pzByStatus.put(status, newPzList); } } return pzByStatus; } 执行以下测试演示了Map接口的EnumMap实现的强大功能： @Test public void givenPizaOrders_whenGroupByStatusCalled_thenCorrectlyGrouped() { List\u0026lt;Pizza\u0026gt; pzList = new ArrayList\u0026lt;\u0026gt;(); Pizza pz1 = new Pizza(); pz1.setStatus(Pizza.PizzaStatus.DELIVERED); Pizza pz2 = new Pizza(); pz2.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz3 = new Pizza(); pz3.setStatus(Pizza.PizzaStatus.ORDERED); Pizza pz4 = new Pizza(); pz4.setStatus(Pizza.PizzaStatus.READY); pzList.add(pz1); pzList.add(pz2); pzList.add(pz3); pzList.add(pz4); EnumMap\u0026lt;Pizza.PizzaStatus,List\u0026lt;Pizza\u0026gt;\u0026gt; map = Pizza.groupPizzaByStatus(pzList); assertTrue(map.get(Pizza.PizzaStatus.DELIVERED).size() == 1); assertTrue(map.get(Pizza.PizzaStatus.ORDERED).size() == 2); assertTrue(map.get(Pizza.PizzaStatus.READY).size() == 1); } 使用枚举实现设计模式   7.1 单例模式 通常，使用单例模式实现一个类是非常重要的。枚举提供了一种实现单例的快速简便的方法。 此外，由于 enum 类在底层实现了Serializable接口，因此该类被 JVM 保证为单例。这与传统实现不同，在传统实现中，我们必须确保在反序列化期间不会创建新实例。 在下面的代码片段中，我们看到了如何实现单例模式： public enum PizzaDeliverySystemConfiguration { INSTANCE; PizzaDeliverySystemConfiguration() { // Initialization configuration which involves  // overriding defaults like delivery strategy  } private PizzaDeliveryStrategy deliveryStrategy = PizzaDeliveryStrategy.NORMAL; public static PizzaDeliverySystemConfiguration getInstance() { return INSTANCE; } public PizzaDeliveryStrategy getDeliveryStrategy() { return deliveryStrategy; } } 7.2 策略模式 传统上，策略模式是通过具有由不同类实现的接口来编写的。 添加新策略意味着添加新的实现类。使用枚举，我们可以用更少的努力来实现这一点，并且添加一个新的实现意味着简单地定义另一个具有一些实现的实例。 下面的代码片段展示了如何实现策略模式： public enum PizzaDeliveryStrategy { EXPRESS { @Override public void deliver(Pizza pz) { System.out.println(\u0026#34;Pizza will be delivered in express mode\u0026#34;); } }, NORMAL { @Override public void deliver(Pizza pz) { System.out.println(\u0026#34;Pizza will be delivered in normal mode\u0026#34;); } }; public abstract void deliver(Pizza pz); } 然后我们在Pizza类中添加以下方法： public void deliver() { if (isDeliverable()) { PizzaDeliverySystemConfiguration.getInstance().getDeliveryStrategy() .deliver(this); this.setStatus(PizzaStatus.DELIVERED); } } @Test public void givenPizaOrder_whenDelivered_thenPizzaGetsDeliveredAndStatusChanges() { Pizza pz = new Pizza(); pz.setStatus(Pizza.PizzaStatus.READY); pz.deliver(); assertTrue(pz.getStatus() == Pizza.PizzaStatus.DELIVERED); } Java 8 和枚举   我们可以在 Java 8 中重写Pizza类，看看getAllUndeliveredPizzas()和groupPizzaByStatus()方法如何通过使用 lambda 和Stream API 变得如此简洁： public static List\u0026lt;Pizza\u0026gt; getAllUndeliveredPizzas(List\u0026lt;Pizza\u0026gt; input) { return input.stream().filter( (s) -\u0026gt; !deliveredPizzaStatuses.contains(s.getStatus())) .collect(Collectors.toList()); } public static EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; groupPizzaByStatus(List\u0026lt;Pizza\u0026gt; pzList) { EnumMap\u0026lt;PizzaStatus, List\u0026lt;Pizza\u0026gt;\u0026gt; map = pzList.stream().collect( Collectors.groupingBy(Pizza::getStatus, () -\u0026gt; new EnumMap\u0026lt;\u0026gt;(PizzaStatus.class), Collectors.toList())); return map; } Enum 的 JSON 表示   使用 Jackson 库，可以将枚举类型的 JSON 表示为 POJO。在下面的代码片段中，我们将看到如何使用 Jackson 注释： @JsonFormat(shape = JsonFormat.Shape.OBJECT) public enum PizzaStatus { ORDERED (5){ @Override public boolean isOrdered() { return true; } }, READY (2){ @Override public boolean isReady() { return true; } }, DELIVERED (0){ @Override public boolean isDelivered() { return true; } }; private int timeToDelivery; public boolean isOrdered() {return false;} public boolean isReady() {return false;} public boolean isDelivered(){return false;} @JsonProperty(\u0026#34;timeToDelivery\u0026#34;) public int getTimeToDelivery() { return timeToDelivery; } private PizzaStatus (int timeToDelivery) { this.timeToDelivery = timeToDelivery; } } 我们可以使用Pizza和PizzaStatus如下： Pizza pz = new Pizza(); pz.setStatus(Pizza.PizzaStatus.READY); System.out.println(Pizza.getJsonString(pz)); 这将生成Pizza状态的以下 JSON 表示： { \u0026#34;status\u0026#34; : { \u0026#34;timeToDelivery\u0026#34; : 2, \u0026#34;ready\u0026#34; : true, \u0026#34;ordered\u0026#34; : false, \u0026#34;delivered\u0026#34; : false }, \u0026#34;deliverable\u0026#34; : true } 有关枚举类型的 JSON 序列化/反序列化（包括自定义）的更多信息，我们可以参考Jackson – Serialize Enums as JSON Objects。 \u0026quot; ","permalink":"http://itcodingman.github.io/a_guide_to_java_enums/","tags":["Core Java"],"title":"Java 枚举指南"},{"categories":["Algorithms","Java"],"contents":"1. 简介 **最近，我们研究了解决游戏 2048 的算法。**我们从理论的角度讨论了这个问题，而不是背后的任何真实代码。 **在这里，我们将用 Java 编写一个实现。**这将扮演人类和计算机玩家的角色，展示如何玩出更优化的游戏。 2. 初始设置 我们需要的第一件事是一个设置，我们可以在其中玩游戏并查看进展情况。 这将为我们提供玩游戏所需的所有构造，并完全实现计算机播放器——无论如何它只会放置随机图块。这为我们提供了实现“人类”玩家玩游戏的空间。 2.1 游戏板 首先，我们需要一个游戏板。这是一个可以放置数字单元格。 为了让一些事情更容易处理，让我们从一个简单的单元格位置表示开始。这实际上只是一对坐标的包装： public class Cell { private final int x; private final int y; // constructor, getters, and toString } 我们现在可以编写一个类来表示网格本身。这会将值存储在一个简单的二维数组中，但允许我们通过上面的Cell类访问它们： public class Board { private final int[][] board; private final int score; public Board(int size) { this.board = new int[size][]; this.score = 0; for (int x = 0; x \u0026lt; size; ++x) { this.board[x] = new int[size]; for (int y = 0; y \u0026lt; size; ++y) { board[x][y] = 0; } } } public int getSize() { return board.length; } public int getScore() { return score; } public int getCell(Cell cell) { return board[cell.getX()][cell.getY()]; } public boolean isEmpty(Cell cell) { return getCell(cell) == 0; } public List\u0026lt;Cell\u0026gt; emptyCells() { List\u0026lt;Cell\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (int x = 0; x \u0026lt; board.length; ++x) { for (int y = 0; y \u0026lt; board[x].length; ++y) { Cell cell = new Cell(x, y); if (isEmpty(cell)) { result.add(cell); } } } return result; } } **这是一个代表棋盘的不可变类，让我们查询它以找出当前状态。**它还跟踪当前的分数，我们稍后会谈到。 2.2 电脑选手和放置图块 现在我们有了一个游戏板，我们希望能够玩它。我们想要的第一件事是电脑选手，因为这是一个纯粹的随机选手，以后会完全按照需要。 电脑玩家只不过是在一个单元格中放置了一个棋子，所以我们需要一些方法来在我们的棋盘上实现这一点。我们希望保持它是不可变的，因此放置一个图块将在新状态下生成一个全新的棋盘。 首先，我们需要一个构造函数来获取实际的棋盘状态，而不是我们之前构造一个空白棋盘的构造函数： private Board(int[][] board, int score) { this.score = score; this.board = new int[board.length][]; for (int x = 0; x \u0026lt; board.length; ++x) { this.board[x] = Arrays.copyOf(board[x], board[x].length); } } 这是私有的，因此它只能被同一类中的其他方法使用。这有助于我们封装游戏板。 **接下来，我们将添加一个放置图块的方法。**这将返回一个与当前板相同的全新板，只是它在给定单元格中具有给定编号： public Board placeTile(Cell cell, int number) { if (!isEmpty(cell)) { throw new IllegalArgumentException(\u0026#34;That cell is not empty\u0026#34;); } Board result = new Board(this.board, this.score); result.board[cell.getX()][cell.getY()] = number; return result; } 最后，**我们将编写一个代表计算机选手的新类。**这将有一个方法可以获取当前板并返回新板： public class Computer { private final SecureRandom rng = new SecureRandom(); public Board makeMove(Board input) { List\u0026lt;Cell\u0026gt; emptyCells = input.emptyCells(); double numberToPlace = rng.nextDouble(); int indexToPlace = rng.nextInt(emptyCells.size()); Cell cellToPlace = emptyCells.get(indexToPlace); return input.placeTile(cellToPlace, numberToPlace \u0026gt;= 0.9 ? 4 : 2); } } **这会从板上获取每个空单元格的列表，随机选择一个，然后将一个数字放入其中。**我们将随机决定在 10% 的情况下将“4”放入单元格，在其他 90% 的情况下放入“2”。 2.2 一个“人类”玩家和移动图块 接下来我们需要的是一个“人类”玩家。**这不是最终目标，而是一个纯粹随机的玩家，每次移动时都会选择一个随机方向来移动图块。**然后，这将成为我们可以建立最佳玩家的地方。 首先，我们需要定义可以进行的可能移动的枚举： public enum Move { UP, DOWN, LEFT, RIGHT } **接下来，我们需要增加Board类以支持通过在这些方向之一上移动图块来进行移动。**为了降低这里的复杂性，我们想要旋转棋盘，这样我们总是在同一个方向移动瓷砖。 这意味着我们需要一种转置和反转板的方法： private static int[][] transpose(int[][] input) { int[][] result = new int[input.length][]; for (int x = 0; x \u0026lt; input.length; ++x) { result[x] = new int[input[0].length]; for (int y = 0; y \u0026lt; input[0].length; ++y) { result[x][y] = input[y][x]; } } return result; } private static int[][] reverse(int[][] input) { int[][] result = new int[input.length][]; for (int x = 0; x \u0026lt; input.length; ++x) { result[x] = new int[input[0].length]; for (int y = 0; y \u0026lt; input[0].length; ++y) { result[x][y] = input[x][input.length - y - 1]; } } return result; } 转置板将交换所有行和列，使得顶部边缘变为左侧边缘。反转板只是镜像它，使左边缘变成右边缘。 接下来，我们向Board添加一个方法，以在给定方向上移动，并以新的状态返回一个新的Board。 我们首先制作Board状态的副本，然后我们可以使用它： public Board move(Move move) { int newScore = 0; // Clone the board  int[][] tiles = new int[this.board.length][]; for (int x = 0; x \u0026lt; this.board.length; ++x) { tiles[x] = Arrays.copyOf(this.board[x], this.board[x].length); } 接下来，我们操纵我们的副本，以便我们总是向上移动瓷砖： if (move == Move.LEFT || move == Move.RIGHT) { tiles = transpose(tiles); } if (move == Move.DOWN || move == Move.RIGHT) { tiles = reverse(tiles); } 我们还需要另一组图块——这次是我们将构建最终结果的图块——以及一个用于跟踪此次移动获得的新分数的跟踪器： int[][] result = new int[tiles.length][]; int newScore = 0; 现在我们已经准备好开始移动图块了，并且我们已经操纵了一些东西，以便我们始终朝着同一个方向工作，我们可以开始了。 **我们可以独立于其他列移动每一列。**我们只需要遍历列并重复，从构建我们正在移动的图块的另一个副本开始。 这次我们将它们构建到LinkedList中，因为我们希望能够轻松地从中弹出值。我们也只添加具有数字的实际图块并跳过空图块。 这实现了我们的平移，但还没有实现图块的合并： for (int x = 0; x \u0026lt; tiles.length; ++x) { LinkedList\u0026lt;Integer\u0026gt; thisRow = new LinkedList\u0026lt;\u0026gt;(); for (int y = 0; y \u0026lt; tiles[0].length; ++y) { if (tiles[x][y] \u0026gt; 0) { thisRow.add(tiles[x][y]); } } 接下来，我们需要合并图块。我们需要与上述分开执行此操作；否则，我们可能会多次合并同一个图块。 这是通过从上面构建另一个图块的LinkedList来实现的，但这次我们合并： LinkedList\u0026lt;Integer\u0026gt; newRow = new LinkedList\u0026lt;\u0026gt;(); while (thisRow.size() \u0026gt;= 2) { int first = thisRow.pop(); int second = thisRow.peek(); if (second == first) { int newNumber = first * 2; newRow.add(newNumber); newScore += newNumber; thisRow.pop(); } else { newRow.add(first); } } newRow.addAll(thisRow); 在这里，我们还计算了这一举动的新分数。这是由于合并而创建的图块的总和。 我们现在可以将其构建到结果数组中。一旦我们用完列表中的图块，其余部分将填充值“0”以表示它们是空白的： result[x] = new int[tiles[0].length]; for (int y = 0; y \u0026lt; tiles[0].length; ++y) { if (newRow.isEmpty()) { result[x][y] = 0; } else { result[x][y] = newRow.pop(); } } } 一旦我们完成了图块的移动，我们需要再次将它们操作回正确的旋转。这与我们之前所做的完全相反： if (move == Move.DOWN || move == Move.RIGHT) { result = reverse(result); } if (move == Move.LEFT || move == Move.RIGHT) { result = transpose(result); } 最后，我们可以用这组新的图块和新计算的分数构建并返回一个新的棋盘： return new Board(result, this.score + newScore); } **我们现在可以编写随机的“人类”玩家。**这只不过是生成一个随机移动并调用上述方法来移动： public class Human { private SecureRandom rng = new SecureRandom(); public Board makeMove(Board input) { Move move = Move.values()[rng.nextInt(4)]; return input.move(move); } } 2.3. 玩游戏 **我们有足够的组件来玩这个游戏，虽然不是很成功。**但是，很快我们将改进Human类的游戏方式，这将使我们能够轻松地看到差异。 首先，我们需要一种打印游戏板的方法。 对于这个例子，我们只是要打印到控制台，所以System.out.print已经足够好了。对于一个真正的游戏，我们想要做更好的图形： private static void printBoard(Board board) { StringBuilder topLines = new StringBuilder(); StringBuilder midLines = new StringBuilder(); for (int x = 0; x \u0026lt; board.getSize(); ++x) { topLines.append(\u0026#34;+--------\u0026#34;); midLines.append(\u0026#34;| \u0026#34;); } topLines.append(\u0026#34;+\u0026#34;); midLines.append(\u0026#34;|\u0026#34;); for (int y = 0; y \u0026lt; board.getSize(); ++y) { System.out.println(topLines); System.out.println(midLines); for (int x = 0; x \u0026lt; board.getSize(); ++x) { Cell cell = new Cell(x, y); System.out.print(\u0026#34;|\u0026#34;); if (board.isEmpty(cell)) { System.out.print(\u0026#34; \u0026#34;); } else { StringBuilder output = new StringBuilder(Integer.toString(board.getCell(cell))); while (output.length() \u0026lt; 8) { output.append(\u0026#34; \u0026#34;); if (output.length() \u0026lt; 8) { output.insert(0, \u0026#34; \u0026#34;); } } System.out.print(output); } } System.out.println(\u0026#34;|\u0026#34;); System.out.println(midLines); } System.out.println(topLines); System.out.println(\u0026#34;Score: \u0026#34; + board.getScore()); } 我们差不多准备好了。我们只需要进行设置。 这意味着创建棋盘、两名玩家，并让计算机进行两个初始动作——即在棋盘上放置两个随机数： Board board = new Board(4); Computer computer = new Computer(); Human human = new Human(); for (int i = 0; i \u0026lt; 2; ++i) { board = computer.makeMove(board); } 现在我们有了实际的游戏循环。这将是人类和计算机玩家轮流进行的重复，只有在没有空单元格时才停止： printBoard(board); do { System.out.println(\u0026#34;Human move\u0026#34;); System.out.println(\u0026#34;==========\u0026#34;); board = human.makeMove(board); printBoard(board); System.out.println(\u0026#34;Computer move\u0026#34;); System.out.println(\u0026#34;=============\u0026#34;); board = computer.makeMove(board); printBoard(board); } while (!board.emptyCells().isEmpty()); System.out.println(\u0026#34;Final Score: \u0026#34; + board.getScore()); 此时，如果我们要运行该程序，我们会看到正在玩 2048 的随机游戏。 3. 实现 2048 玩家 一旦我们有了玩游戏的基础，我们就可以开始实现“人类”玩家并玩更好的游戏，而不仅仅是选择随机方向。 3.1 模拟动作 我们在这里实现的算法是基于Expectimax算法的。因此，算法的核心是模拟每一个可能的动作，为每一个动作分配一个分数，然后选择一个做得最好的动作。 我们将大量使用Java 8 Streams来帮助构建此代码，原因我们稍后会看到。 我们将从在Human类中*重写 makeMove()*方法开始： public Board makeMove(Board input) { return Arrays.stream(Move.values()) .map(input::move) .max(Comparator.comparingInt(board -\u0026gt; generateScore(board, 0))) .orElse(input); } 对于我们可以移动的每一个可能的方向，我们生成新的棋盘，然后开始评分算法——通过这个棋盘，深度为 0。然后我们选择得分最高的棋步。 然后，我们的*generateScore()*方法模拟每一个可能的计算机移动——也就是说，将“2”或“4”放入每个空单元格——然后看看接下来会发生什么： private int generateScore(Board board, int depth) { if (depth \u0026gt;= 3) { return calculateFinalScore(board); } return board.emptyCells().stream() .flatMap(cell -\u0026gt; Stream.of(new Pair\u0026lt;\u0026gt;(cell, 2), new Pair\u0026lt;\u0026gt;(cell, 4))) .mapToInt(move -\u0026gt; { Board newBoard = board.placeTile(move.getFirst(), move.getSecond()); int boardScore = calculateScore(newBoard, depth + 1); return (int) (boardScore * (move.getSecond() == 2 ? 0.9 : 0.1)); }) .sum(); } 如果我们达到了我们的深度限制，那么我们将立即停下来计算这个板有多好的最终分数；否则，我们继续我们的模拟。 然后，我们的*calculateScore()*方法是我们模拟的延续，运行等式的人类移动方面。 *这与上面的makeMove()*方法非常相似，但我们返回的是正在进行的分数而不是实际的棋盘： private int calculateScore(Board board, int depth) { return Arrays.stream(Move.values()) .map(board::move) .mapToInt(newBoard -\u0026gt; generateScore(newBoard, depth)) .max() .orElse(0); } 3.2 计分决赛板 我们现在处于可以模拟人类和计算机玩家来回移动的情况，当我们模拟足够多时停止。我们需要能够为每个模拟分支中的最终板生成一个分数，以便我们可以看到哪个分支是我们想要追求的分支。 我们的评分是多个因素的组合，我们将把每个因素应用到板上的每一行和每一列。这些都加在一起，然后返回总数。 因此，我们需要生成要评分的行和列列表： List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; rowsToScore = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; board.getSize(); ++i) { List\u0026lt;Integer\u0026gt; row = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; col = new ArrayList\u0026lt;\u0026gt;(); for (int j = 0; j \u0026lt; board.getSize(); ++j) { row.add(board.getCell(new Cell(i, j))); col.add(board.getCell(new Cell(j, i))); } rowsToScore.add(row); rowsToScore.add(col); } 然后我们取出我们建立的列表，对每个列表进行评分，然后将分数相加。这是我们即将填写的占位符： return rowsToScore.stream() .mapToInt(row -\u0026gt; { int score = 0; return score; }) .sum(); 最后，我们实际上需要生成我们的分数。这进入了上面的 lambda，并且是几个不同的因素都有助于：  每行的固定分数 行中每个数字的总和 行中可能的每个合并 行中的每个空单元格 行的单调性。这表示该行按数字升序排列的数量。  在计算分数之前，我们需要构建一些额外的数据。 首先，我们想要一个删除了空白单元格的数字列表： List\u0026lt;Integer\u0026gt; preMerged = row.stream() .filter(value -\u0026gt; value != 0) .collect(Collectors.toList()); 然后我们可以从这个新列表中进行一些计数，给出具有相同数字的相邻单元格的数量，数字严格递增，数字严格递减： int numMerges = 0; int monotonicityLeft = 0; int monotonicityRight = 0; for (int i = 0; i \u0026lt; preMerged.size() - 1; ++i) { Integer first = preMerged.get(i); Integer second = preMerged.get(i + 1); if (first.equals(second)) { ++numMerges; } else if (first \u0026gt; second) { monotonicityLeft += first - second; } else { monotonicityRight += second - first; } } 现在我们可以计算这一行的分数： int score = 1000; score += 250 * row.stream().filter(value -\u0026gt; value == 0).count(); score += 750 * numMerges; score -= 10 * row.stream().mapToInt(value -\u0026gt; value).sum(); score -= 50 * Math.min(monotonicityLeft, monotonicityRight); return score; 这里选择的数字是比较随意的。不同的数字将对游戏的表现产生影响，在我们的游戏方式中优先考虑不同的因素。 4. 算法改进 **到目前为止，我们所拥有的东西是有效的，我们可以看到它玩得很好，但是速度很慢。**每个人的移动大约需要 1 分钟。我们可以做得比这更好。 4.1 并行处理 **我们可以做的显而易见的事情是并行工作。**这是使用 Java Streams 的巨大好处——我们可以通过向每个流添加单个语句来并行工作。 仅此更改就可以将我们的每次移动时间缩短到 20 秒左右。 4.2 修剪不可游戏的分支 **接下来我们可以做的就是修剪掉所有无法游戏的分支。**也就是说，任何时候人类移动都会导致棋盘不变。几乎可以肯定，这些分支会导致更糟糕的结果——它们有效地让计算机自由移动——但它们花费了我们处理它们的时间。 为此，我们需要在Board上实现一个 equals 方法，以便我们可以比较它们： @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } Board board1 = (Board) o; return Arrays.deepEquals(board, board1.board); } 然后，我们可以向我们的流管道添加一些过滤器，以停止处理任何未更改的内容。 return Arrays.stream(Move.values()) .parallel() .map(board::move) .filter(moved -\u0026gt; !moved.equals(board)) ........ 这对游戏的早期部分影响很小——当填充的单元格很少时，可以修剪的动作也很少。然而，后来，这开始产生更大的影响，将移动时间减少到只有几秒钟。 \u0026quot; ","permalink":"http://itcodingman.github.io/2048_java_solver/","tags":[],"title":"用 Java 解决 2048 游戏"},{"categories":["Processes"],"contents":" 概述   在使用 Linux 命令行界面时，通常会将程序的输出重定向为另一个程序的输入。 在本教程中，我们将研究在 Linux 中使用管道和命名管道。 什么是管道？   管道是基于 Unix 的系统中的一种重要机制，它允许我们将数据从一个进程传递到另一个进程，而无需在磁盘上存储任何内容。 在 Linux 中，我们有两种类型的管道：管道（也称为匿名或未命名管道）和 FIFO（也称为命名管道）。 管道   管道通过将命令串在一起使用，由管道字符分隔，\u0026rsquo; | \u0026lsquo;。这通常被称为管道，每个 shell 都定义了它的行为。 shell 在后台运行的单独进程中执行每个命令，从最左边的命令开始。 然后，左侧命令的标准输出连接到右侧命令的标准输入。这提供了流的单向性。 这种机制一直持续到管道中的所有进程都完成为止。 像 Bash 和 Zsh 这样的 shell 使用标记“ |\u0026amp; ”来指代管道，将左侧命令的标准输出和标准错误与右侧命令的标准输入连接起来。 假设我们想使用netstat命令查看使用 localhost 正在运行的进程并使用grep实用程序进行过滤： $ netstat -tlpn | grep 127.0.0.1 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN - 在这个示例输出中，我们在netstat中看到了脚本的 stdout 和 stderr，而不管过滤器如何。 现在，让我们将 stderr 合并到 stdout 并将其传递给grep的标准输入： $ netstat -tlpn |\u0026amp; grep 127.0.0.1 tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN - 我们已经将警告信息隐藏起来了。 3.1。Bash 中的管道 Bash 有一个名为PIPESTATUS的变量，其中包含最近执行的管道中进程的退出状态列表： $ exit 1 | exit 2 | exit 3 | exit 4 | exit 5 $ echo ${PIPESTATUS[@]} 1 2 3 4 5 整个管道执行的返回状态将取决于pipefail变量的状态。 如果设置了此变量，则管道的返回状态将是最右边的非零状态命令的退出状态，或者如果所有命令成功退出，则将为零： $ set -o pipefail $ exit 1 | exit 2 | exit 3| exit 4 | exit 0 $ echo $? 4 禁用 pipefail选项后，管道的返回状态将是最后一个命令的退出状态： $ set +o pipefail $ exit 1 | exit 2 | exit 3| exit 4 | exit 0 $ echo $? 0 Bash 也有lastpipe选项，它指示 shell 在当前环境的前台执行最后一个命令。 3.2. Zsh 中的管道 Zsh 对管道的控制与 Bash 类似，但有一些区别。例如，Zsh 有 pipestatus命令，它类似于 Bash 中的 PIPESTATUS 变量。 此外，Zsh 在单独的进程中执行每个管道中的命令，除了最后一个命令，它在当前 shell 环境中执行。 命名管道   FIFO，也称为命名管道，是一种类似于管道但在文件系统上具有名称的特殊文件。多个进程可以像任何普通文件一样访问这个特殊文件进行读写。 因此，该名称仅作为需要在文件系统中使用名称的进程的参考点。 FIFO 具有与任何其他文件相同的特性。例如，它具有所有权、权限和元数据。 FIFO 的另一个重要特性是它提供双向通信。 在 Linux 中，我们可以使用命令mknod（使用字母“p”表示 FIFO 类型）和mkfifo创建一个 FIFO ： $ mkfifo pipe1 $ mknod pipe2 p $ ls -l prw-r--r-- 1 cuau cuau 0 Oct 7 21:17 pipe1 prw-r--r-- 1 cuau cuau 0 Oct 7 21:17 pipe2 在这里，我们可以看到我们的 FIFO 的文件类型用字母“p”表示。 这种机制允许我们使用我们的 shell 创建更复杂的应用程序。 命名管道和匿名管道可以一起使用。让我们创建一个结合 FIFO 和管道的反向 shell。 我们将使用nc实用程序创建一个客户端/服务器应用程序，其中“服务器”端将提供其 shell，“客户端”端将能够访问它。 首先，让我们安装netcat-openbsd包。我们可以使用以下命令将它安装在任何 Ubuntu/Debian 系统上： $ sudo apt install netcat-openbsd 接下来，让我们创建一个名为fifo_reverse的 FIFO，输入mkfifo fifo_reverse。 然后，让我们使用两个不同的用户登录，每个用户都充当“客户端”（比如“user1”）和“服务器”（比如“user2”）。让我们在 user2 shell 上运行这个管道： user2_prompt$ bash -i \u0026lt; fifo_reverse |\u0026amp; nc -l 127.0.0.1 1234 \u0026gt; fifo_reverse 在这个单行程序中，shell 读取我们的 FIFO 的内容并将其传递给交互式 Bash shell。 接下来，交互式 shell 的 stdout 和 stderr 都将传递给nc命令，该命令将在地址 127.0.0.1 的端口 1234 上进行侦听。 最后，当“客户端”成功建立连接时，nc会将接收到的内容写入我们的 FIFO，交互式 shell 将能够执行接收到的内容。 现在，使用 user1 shell，让我们输入： user1_prompt$ nc 127.0.0.1 1234 user2_prompt$ 我们已经获得了 user2 提示，但使用了结合匿名和命名管道的 user1 shell。 临时命名管道   一些 shell 具有称为进程替换的功能，它将命令列表的输入或输出连接到 FIFO。然后这些命令将使用此 FIFO 的名称。 这种机制在 Bash 和 Zsh 中的表示法是*\u0026lt;(command list)将列表的结果传递给实际命令的标准输入，或\u0026gt;(command list)*将实际命令的标准输出传递给标准输入的名单。 让我们使用我们所看到的将多个命令的输出传递给wc命令： $ wc -l \\  \u0026lt;(find / -mindepth 1 -maxdepth 1 -type d) \\  \u0026lt;(find /opt -mindepth 1 -maxdepth 1 -type d) 20 /proc/self/fd/11 2 /proc/self/fd/12 22 total 在此示例输出中，我们使用 find命令获取*/和/opt*目录中的目录数。 何时使用命名管道或匿名管道？   使用匿名管道而不是命名管道取决于我们正在寻找的特性。其中一些可以是持久性、双向通信、具有文件名、创建过滤器和限制访问权限等。 例如，如果我们想多次过滤命令的输出，使用匿名管道似乎是最合适的选择。我们还要记住，当我们使用匿名管道时，我们使用的 shell 将发挥核心作用。 另一方面，如果我们需要一个文件名并且我们不想将数据存储在磁盘上，我们正在寻找的是一个 FIFO。如果我们只需要一个名称作为参考，其内容直接来自另一个进程。 另外，让我们考虑一下，虽然匿名管道可能看起来像管道类型的管道，但 FIFO 可以创建更复杂的图表。 \u0026quot; ","permalink":"http://itcodingman.github.io/anonymous_named_pipes/","tags":["netstat"],"title":"Linux 中的匿名和命名管道"},{"categories":["Administration"],"contents":"1. 概述 在本文中，我们将介绍 Linux 系统的环境变量，以及如果我们要创建新的或修改现有的，我们需要了解哪些规则。本文将重点介绍环境变量的语法。 2.环境变量 要开始我们的讨论，最好先看一下 Linux 系统上的环境变量。为此，我们可以键入printenv命令来查看它们： $ printenv SHELL=/bin/bash SESSION_MANAGER=local/username-VirtualBox:@/tmp/.ICE-unix/1644,unix/username-VirtualBox:/tmp/.ICE-unix/1644 QT_ACCESSIBILITY=1 COLORTERM=truecolor ... PATH=/home/username/anaconda3/bin:/home/username/anaconda3/condabin:/home/username/.local/bin:... GDMSESSION=ubuntu DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus _=/usr/bin/printenv 上面的输出显示了我们当前机器登录会话的环境变量列表。**在这里，我们可以很容易地找到NAME=VALUE的模式。**因此，我们需要注意不要在命名环境变量时使用等号（ “ = ” ）字符。 3. 环境变量定义 从 IEEE 和 The Open Group 发布的 The Open Group Base Specifications （AKA POSIX 法规）第 8 章文档中，我们可以找到环境变量构成的一般定义。除了使用等号（“ = ”）字符外，还有一些关于可用字符的一般规定。 3.1 使用便携式字符 为了确保我们的程序适用于所有机器，我们需要使用Open Group Base Specifications 第 6 章中定义的Portable Character Set中的字符 （NUL除外）。这些字符由POSIX.1-2017定义，并且在已正确安装的 Linux 系统中始终可用。 只允许使用此字符集中的大写字母、小写字母和下划线。 3.2. 注意案例 系统环境变量由大写字母、数字和下划线（“ _ ”）组成。然而我们仍然可以用小写字母定义环境变量。此外，字母表壳代表不同的含义，因此我们不想将表壳折叠在一起。 按照惯例，小写字母仅供应用程序使用。 3.3. 不要以数字开头 **某些应用程序无法处理以数字开头的环境变量。**如果我们以这种方式定义这些变量，可能会出现意外的行为。 POSIX 文档和我们都不建议在任何地方创建以此类数字开头的环境变量。 3.4. 变量名冲突 下表显示了我们需要避免冲突的变量，其中大部分是系统定义的，并且有一些特殊用途。 关键字表在这里：            ARFLAGS IFS MAILPATH PS1   CC LANG MAILRC PS2   CDPATH LC_ALL MAKEFLAGS PS3   CFLAGS LC_COLLATE MAKESHELL PS4   CHARSET LC_CTYPE MANPATH PWD   COLUMNS LC_MESSAGES MBOX RANDOM   DATEMSK LC_MONETARY MORE SECONDS   DEAD LC_NUMERIC MSGVERB SHELL   \u0026gt;EDITOR LC_TIME NLSPATH TERM   ENV LDFLAGS NPROC TERMCAP   EXINIT LEX OLDPWD TERMINFO   FC LFLAGS OPTARG TMPDIR   FCEDIT LINENO OPTERR TZ   FFLAGS LINES OPTIND USER   GET LISTER PAGER VISUAL   GFLAGS LOGNAME PATH YACC   HISTFILE LPDEST PPID YFLAGS   HISTORY MAIL PRINTER    HISTSIZE MAILCHECK PROCLANG    HOME MAILER PROJECTDIR     系统非常频繁地调用这些变量。因此，与它们发生冲突可能会导致严重错误。 \u0026quot; ","permalink":"http://itcodingman.github.io/allowed_characters_variable_names/","tags":["printenv"],"title":"Linux 环境变量名称中允许的字符"},{"categories":["Administration"],"contents":" 概述   在本文中，我们将讨论如何在 Linux 上查找所有串行设备而无需打开它们。这将显示系统拥有的设备，这在诊断或设置新设备时很有用。 问题陈述   */dev/*目录包含任何给定系统的每个设备的文件。对于串行设备，我们将仅限于那些同时支持波特率和 RTS/CTS 流控制的设备，它代表 RS-232 电信标准下的 Request-to-Send/Clear-to-Send。 我们不想打开设备，因为这可能需要一段时间并可能返回错误。尝试打开设备时，会执行连接尝试。当系统的驱动程序想要连接设备时，通过蓝牙提供的串行设备会发生这种行为的一个示例。 解决方案   通过查看不同的文件并使用多种工具，我们将介绍上述问题的四种解决方案。 3.1 */sys/class/*目录 */sys/class/目录下的文件系统提供有关连接到系统的设备的信息。在其中，*目录/sys/class/tty显示了串行设备、虚拟终端和伪终端，**具有特定串行设备组的子目录。 例如，让我们获取串行 USB 设备： $ ls /sys/class/tty/ttyUSB* /sys/class/tty/ttyUSB0 /sys/class/tty/ttyUSB1 如果我们访问其中一台设备的目录之一，我们会看到不同的文件： $ ls /sys/class/tty/ttyUSB0/ dev device power subsystem uevent **声明我们正在处理串行设备（而不是终端）的文件是device/driver **。因此，我们只能检查那些具有这些目录树的设备： $ ls /sys/class/tty/*/device/driver /sys/class/tty/ttyS0/device/driver /sys/class/tty/ttyS1/device/driver /sys/class/tty/ttyUSB0/device/driver /sys/class/tty/ttyUSB1/device/driver 一种幼稚且错误的方法是仅遍历*/dev/ttyS* 目录，因为我们也可以通过其他接口访问串行设备。使用 USB 到 RS-232 适配器，串行设备位于/dev/ttyUSB* *下，如示例中所示。类似地，其他命名空间可能包含其他串行设备。 3.2. dmesg工具 使用**dmesg工具，我们可以在屏幕上显示内核日志，其中存储了连接到系统的设备的驱动程序产生的所有信息**。我们必须从dmesg（我们感兴趣的串行设备）中搜索整个消息缓冲区： $ dmesg | grep tty 我们可能需要以超级用户权限执行前面的命令。 3.3. HAL 软件 硬件抽象层 ( HAL ) 是一种已被*udev*弃用的工具。但是，该工具仍然可以在 2008 年之前的较旧 Linux 版本上找到，这些版本也是最常见的具有旧串行接口标准的版本。 我们可以从所有可用的端口中获取那些能够进行串行传输的端口： $ hal-find-by-capability --capability serial 这将返回唯一设备标识符的列表。我们可以将 UDI值插入： $ hal-get-property --udi UDI --key serial.device 如果我们想探索所有串行设备，我们可以将这两个命令与一个for循环结合起来： $ for device in $(hal-find-by-capability --capability serial) ; do hal-get-property --udi \u0026#34;${device}\u0026#34; --key serial.device done 3.4. */dev/serial/*目录 如果我们处理较新的 Linux 内核，HAL 工具将不再可用。但是，我们可以利用udev（只要我们安装了早于 2.5. 的版本）。 *在/dev/serial/*目录中，有一个所有可用串行端口的列表。*它们是指向适当的/dev/*文件的符号链接。我们找到两组串口： $ ls /dev/serial/ by-id/ by-path/ 这两组是指同一个串口，但根据端口的不同信息进行组织。让我们看看每个人的样子： $ ls -l /dev/serial/by-id/ total 0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 tty-WM_Gmbh._Serial_Controller-port0 -\u0026gt; ../../ttyS0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 tty-WM_Gmbh._Serial_Controller-port1 -\u0026gt; ../../ttyS1 lrwxrwxrwx 1 root root 13 2015-07-20 04:03 usb-PTechnology_Inc._USB-Serial_Controller-if00-port0 -\u0026gt; ../../ttyUSB0 lrwxrwxrwx 1 root root 13 2015-07-20 04:04 usb-PTechnology_Inc._USB-Serial_Controller-if00-port1 -\u0026gt; ../../ttyUSB1 对于路径组，我们有： $ ls -l /dev/serial/by-path/ total 0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 pci-0000:00:0a.0-tty-1:1:1.0-port0 -\u0026gt; ../../ttyS0 lrwxrwxrwx 1 root root 13 2010-02-10 09:03 pci-0000:00:0a.0-tty-1:1:1.0-port1 -\u0026gt; ../../ttyS1 lrwxrwxrwx 1 root root 13 2015-07-20 04:03pci-0000:00:0b.0-usb-0:3:1.0-port0-\u0026gt; ../../ttyUSB0 lrwxrwxrwx 1 root root 13 2015-07-20 04:04 pci-0000:00:0b.0-usb-0:3:1.1-port1 -\u0026gt; ../../ttyUSB1 当系统中没有串行端口时，文件系统中不存在/dev/serial/目录。 \u0026quot; ","permalink":"http://itcodingman.github.io/all_serial_devices/","tags":[],"title":"无需打开即可在 Linux 上查找所有串行设备"},{"categories":["Scripting"],"contents":" 概述   Shell 程序通常实现命令别名功能，即当命令的别名存在时，Shell 替换命令的第一个单词。当命令冗长或频繁使用时，这可以方便地节省一些键盘敲击。 当别名共享相同名称时，别名可能会隐藏现有命令。在这种情况下，我们需要依靠变通方法来消除命令的歧义。 在本教程中，我们将快速介绍使用别名的一些非常基本的用法，然后我们将研究几种不同的方法来运行被别名遮蔽的命令。 别名   2.1 命令别名 **最常见的别名形式是命令别名，它是命令中第一个单词的文本替换。**让我们创建一些虚拟目录和文件并隐藏ls命令： $ { mkdir -p a b c; touch e f g; } $ alias ls=\u0026#39;echo foobar\u0026#39; $ ls # foobar 我们可以使用一个简单的别名命令列出 shell 会话中的别名： $ alias # alias ls=\u0026#39;echo foobar\u0026#39; 2.2. 全局别名 在 zsh shell 中，我们还可以使用另一种形式的别名，称为全局别名，以替换输入中任何位置的文本： $ alias -g t=\u0026#39;foobar\u0026#39; $ echo t # foobar 避免别名替换   有时我们希望 shell 在解释命令时忽略别名。我们可以使用几种不同的方法来解决阻碍别名的问题。 接下来，让我们看看如何使用这些不同的技术来解决我们在前面部分中配置的ls别名。 3.1 删除别名 **一个简单的unalias ls将从我们的 shell 会话中删除ls别名，**我们将能够调用先前隐藏的命令： $ unalias ls $ ls # a b c e f g 虽然是一种简单的解决方法，但这种方法的缺点是我们将丢失 shell 会话中的别名。 3.2. 报价 **另一种技术是通过“引用”命令从命令中删除特殊含义。**只要字符串中的任何字符被引用，命令就会被视为引用。让我们看看引用命令的三种不同方式。 首先，我们可以使用转义字符（\\）来保留命令的字面意思： $ \\ls # a b c e f g 另一种选择是使用单引号 ('...') 来引用命令： $ \u0026#39;ls\u0026#39; # a b c e f g 我们可以使用双引号（”...”）来引用命令： $ \u0026#34;ls\u0026#34; # a b c e f g 引用是一个较少讨论的 shell 概念，有几点需要指出。我们应该知道，没有必要引用整个命令，以便 shell 将命令视为已引用。以下引用变体同样“引用” ls命令： $ l\\s # a b c e f g $ l\u0026#39;s\u0026#39; # a b c e f g $ l\u0026#34;s\u0026#34; # a b c e f g 我们还应该注意不要将别名与 shell 函数混淆，因为 shell 函数是常规命令，因此引用它们不会有任何效果： $ function foobar () { echo helloworld; } $ foo\\bar # helloworld 3.3. command（内置） 自命名的内置command可用于将命令的解释范围缩小到仅在***$PATH*****或 shell 内置目录中找到的可执行文件。**让我们看看如何使用命令忽略ls别名： $ command ls # a b c e f g 3.4. 绝对路径 当别名隐藏可执行文件时，一个简单的解决方案是简单地将可执行文件的完整路径名指定为 command。我们可以使用一些工具在$PATH目录中找到可执行文件： 我们可以使用which在我们的*$PATH中搜索与提供的文件名匹配的可执行文件。如果找不到可执行文件，那么它将*以退出代码 1 终止。让我们看看实际情况： $ which ls # /usr/bin/ls $ which foobar $ echo $? # 1 我们还可以使用type内置命令来了解 shell 如何解释命令： $ type -a ls # ls is aliased to `ls --color=auto\u0026#39; # ls is /usr/bin/ls # ls is /bin/ls \u0026quot; ","permalink":"http://itcodingman.github.io/alias_run_shadowed_command/","tags":["alias"],"title":"运行受别名影响的命令"},{"categories":["File Permissions","Files","Security"],"contents":" 概述   在 Linux 中，我们知道文件可以具有读、写和执行(rwx)权限标志。 除了这些标准权限外，还有三个特殊权限可用。 在本教程中，让我们看一下特殊类型的权限，并学习如何使用 Linux 命令设置和删除这些标志。 setuid   **通常，当一个进程在类 Unix 操作系统中启动时，它会以启动它的用户的有效用户 ID 和组 ID 以及相应的权限运行。**但是，如果我们对可执行文件设置特殊权限，则可以更改此行为。 setuid表示“设置用户 ID”。如果我们在一个可执行文件上设置setuid位，该文件总是以文件所有者的权限运行，无论是谁启动它。 setuid位仅在设置在可执行文件上时才有意义。如果我们在非可执行文件或目录上设置setuid位，则没有实际意义。 passwd命令是一个带有这个特殊位集的示例： $ ls -l /bin/passwd -rwsr-xr-x 1 root root 63624 Dec 15 21:06 /bin/passwd 我们注意到所有者的执行权限是小写的“s”而不是通常的“x”。这个“s”表示文件设置了setuid位。passwd命令将始终以 root权限运行，无论是谁启动它，因为文件的所有者是root。 我们可以使用chmod命令来设置文件的 setuid位： chmod u+s FILE 只有文件的所有者或root用户才能设置setuid位。 让我们看一个在文件上设置setuid位的示例： $ ls -l file -rwxr-xr-x 1 kent kent 0 Feb 2 12:22 file $ chmod u+s file $ ls -l file -rwsr-xr-x 1 kent kent 0 Feb 2 12:22 file 或者，我们也可以通过在模式前面加上“4”来使用八进制表示法设置setuid位： $ chmod 4755 file -rwsr-xr-x 1 kent kent 0 Feb 2 12:22 file 要删除setuid位，我们将我们传递给 chmod 命令： $ chmod u-s file $ ls -l file -rwxr-xr-x 1 kent kent 0 Feb 2 12:22 file setgid位   3.1 文件上的setgid位 setgid是“set group id”的缩写。如果我们在可执行文件上设置setgid位，那么无论谁启动该文件，它都会以所属组的权限运行。 定位**命令是设置了setgid位的文件示例： $ ls -l /usr/bin/locate -rwxr-sr-x 1 root locate 43048 Nov 13 18:09 /usr/bin/locate 与 setuid位类似，我们注意到ls*输出中有一个小写的“s” ，除了它在组部分而不是所有者部分中。 我们可以通过将g+s传递给chmod命令来设置文件的setgid位： $ ls -l file2 -rwxr-xr-x 1 kent kent 0 Feb 2 22:35 file2 $ chmod g+s file2 $ ls -l file2 -rwxr-sr-x 1 kent kent 0 Feb 2 22:35 file2 或者，我们可以通过在模式前面加上“2”来使用八进制表示法设置setgid位： chmod 2755 file2 如果我们想删除文件上的setgid位，我们将 gs传递给 chmod命令： $ chmod g-s file2 $ ls -l file2 -rwxr-xr-x 1 kent kent 0 Feb 2 22:35 file2 3.2. 目录上的setgid位 **如果我们在一个目录上设置setgid位，则该目录中所有新创建的文件和子目录都将继承该目录的组。**但是，现有文件和目录不会应用组更改。 让我们看一个例子来阐明这种行为。 首先，我们准备一个包含两个文件的parent目录： $ ls -ld parent drwxrwxrwx 2 root kent 4096 Feb 3 00:33 parent/ $ ls -l parent total 2 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest1 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest2 parent 由用户root和组kent拥有。它包含两个文件，组来宾拥有这两个文件。 接下来，让我们 使用chmod在parent上设置setgid位： root# chmod g+s parent root# ls -ld parent drwxrwsrwx 2 root kent 4096 Feb 3 00:33 parent/ 现在，我们将使用root在parent目录下创建一个新文件和一个子目录： root# touch parent/new_file_by_root root# mkdir parent/new_dir_by_root 然后，我们将检查parent下所有文件和子目录的组所有者： root# ls -l parent total 4 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest1 -rwxr-xr-x 1 guest guest 0 Feb 3 00:30 existing_grp_guest2 drwxr-sr-x 2 root kent 4096 Feb 3 00:54 new_dir_by_root/ -rw-r--r-- 1 root kent 0 Feb 3 00:54 new_file_by_root 在上面的输出中，我们看到在parent上设置setuid位后，两个现有文件没有改变。 但是，新创建的文件和子目录由kent而不是 root拥有，即使是root创建了它们。这是因为parent设置了setgid位，并且它下新创建的文件和目录继承了parent的组。 sticky位   4.1 sticky位 粘性位是保护目录中的文件。如果我们在一个目录上设置sticky位，那么这个目录下的文件只能通过以下方式之一删除：  文件的所有者 目录的所有者 根用户  换言之，此特殊权限可防止用户在公共目录中删除其他用户的文件。 /tmp目录是一个典型的真实世界sticky位示例： $ ls -ld /tmp drwxrwxrwt 24 root root 980 Feb 3 21:41 /tmp/ 由于“其他”权限部分中的“w”，我们知道任何用户都可以创建和删除*/tmp*目录下的任何文件。 但是如果我们仔细阅读上面的ls输出，我们会发现“other”部分中的执行权限位是小写的“t”，而不是通常的“x”。 这个小写字母*“t”表示 /tmp目录设置了粘性位。使用粘性位，任何用户仍然可以在/tmp* 下创建文件。但是，用户只能删除自己拥有的文件。 4.2. 目录上的sticky bit 要在目录上设置sticky bit，我们仍然可以使用 带有模式*+t的chmod*命令： chmod +t DIRECTORY 或者，我们也可以在目录模式前加上“1”来设置sticky bit： chmod 1777 DIRECTORY 我们还可以使用-t**从目录中删除sticky bit： chmod -t DIRECTORY 和往常一样，让我们看一个例子来了解sticky bit如何保护目录下的文件以及如何设置和删除目录上的sticky bit。 让我们从准备一个名为public的公共目录开始，并允许所有用户写入它： $ ls -ld public drwxrwxrwx 2 root root 40 Feb 3 22:22 public/ 接下来，我们将在不同用户的public下创建一些文件： $ ls -l -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file1_by_guest -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file2_by_guest -rw-r--r-- 1 kent kent 0 Feb 3 22:28 file_by_kent 到目前为止，我们还没有在任何地方设置sticky bit。让我们看看用户kent是否可以删除guest拥有的文件： kent$ rm file1_by_guest rm: remove write-protected regular empty file \u0026#39;file1_by_guest\u0026#39;? y kent$ ls -l -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file2_by_guest -rw-r--r-- 1 kent kent 0 Feb 3 22:28 file_by_kent 因此，没有sticky bit，我们可以删除其他用户拥有的文件。 现在，让我们设置sticky bit，看看是否有任何变化： root# chmod +t public root# ls -ld public drwxrwxrwt 2 root root 80 Feb 3 22:33 public/ root# su kent kent$ rm file2_by_guest rm: remove write-protected regular empty file \u0026#39;file2_by_guest\u0026#39;? y rm: cannot remove \u0026#39;file2_by_guest\u0026#39;: Operation not permitted kent$ ls -l -rw-r--r-- 1 guest guest 0 Feb 3 22:28 file2_by_guest -rw-r--r-- 1 kent kent 0 Feb 3 22:28 file_by_kent 设置sticky bit后*，* public下的文件 只能被文件所有者删除。 安全   setuid位在各种应用程序中可能非常方便。但是，当我们设置这些特殊权限时，我们必须谨慎，因为它会产生安全问题。 例如，典型用户可以通过执行将UID设置 为root的程序来获得超级用户权限。 5.1 权限提升 **我们监控系统是否有任何可疑的setuid位使用以获得超级用户权限是一个很好的做法。**我们可以使用find命令找到所有由root拥有并带有setuid位的文件： root# find / -user root -perm -4000 -exec ls -ldb {} \\; ... -rwsr-xr-x 1 root root 30744 Dec 12 22:11 /usr/lib/virtualbox/VBoxNetAdpCtl -rwsr-xr-x 1 root root 161720 Dec 12 22:11 /usr/lib/virtualbox/VBoxNetDHCP -rwsr-xr-x 1 root root 71728 Dec 15 21:06 /usr/bin/chage -rwsr-xr-x 1 root root 145176 Jan 1 13:17 /usr/bin/sudo -rwsr-sr-x 1 root root 38664 Nov 13 18:49 /usr/bin/unix_chkpwd -rwsr-xr-x 1 root root 12360 Dec 15 2013 /usr/bin/sflock ... 5.2. setuid和解释的可执行文件 解释的可执行文件通常是一个可执行文件，它通过shebang声明解释器。例如，以“ #!/bin/bash ”开头的 Bash 文件或以“ #!/usr/bin/env python ”开头的可执行 Python 源文件。 出于安全原因， Linux 忽略所有解释的可执行文件上的 setuid位。如果我们希望我们的 shell 脚本拥有setuid权限，我们可以使用sudo命令获得脚本文件所有者的权限。 \u0026quot; ","permalink":"http://itcodingman.github.io/advanced_file_permissions/","tags":["chmod"],"title":"Linux 中的高级文件权限"},{"categories":["File Editing","Files"],"contents":" 概述   我们有时需要快速更改文件，最好是从命令行本身。在文件的每一行末尾添加一个字符串就是这样一种更改。 在本教程中，我们将研究使用sed、awk、echo和perl 执行此操作的多种方法。 问题陈述   在本文中，我们将使用以下名为test.txt的示例文件： $ cat test.txt Python Java JavaScript PHP 我们将看到如何添加字符串“是一种很棒的编程语言”。使用不同的方法到我们的test.txt文件中每一行的末尾。 3.使用sed sed（流编辑器）是 Linux 中一个强大的内置实用程序。我们可以使用它来执行文件的查找和替换、搜索、插入和删除等功能。 我们可以使用sed来编辑文件，甚至无需打开它们，这使得它可以轻松快捷地执行不同的文件功能。 让我们在测试文件上运行sed命令： $ sed -i s/$/ is a great programming language./ test.txt Python is a great programming language. Java is a great programming language. JavaScript is a great programming language. PHP is a great programming language. 让我们分解此命令以了解更多信息：  -i：指示sed就地编辑文件 s : 用于替换 / : 用于基于正则表达式的替换 $ : 匹配行尾的正则表达式 ” is a great\u0026hellip;”：表示我们要添加的字符串  但是我们的结果只打印在标准输出上。要保存更改，我们需要修改我们的命令： $ sed -i s/$/ is a great programming language./ test.txt \u0026gt; test_sed.txt 这会将我们的更改保存到test_sed.txt文件中。 4.使用awk awk是包含在 Unix 和大多数 Unix 变体中的脚本语言。它的开发者名字是 Aho、Weinberger 和 Kernighan 的缩写，他们于 1977 年建造了它。 awk使我们能够以语句的形式编写小程序，这些语句定义要在文件的每一行中搜索的文本模式，并在找到匹配项后执行操作。 让我们输入以下命令来添加我们的字符串： $ awk \u0026#39;{print $0, \u0026#34; is a great programming language.\u0026#34;}\u0026#39; test.txt Python is a great programming language. Java is a great programming language. JavaScript is a great programming language. PHP is a great programming language. 让我们理解命令：  print：用于从输入文件中输出选定的数据。 $0：用于匹配整行的正则表达式。 ” is a great\u0026hellip;”：表示我们要在每行末尾添加的字符串。  此命令将结果输出到标准输出 (STDOUT)。 让我们修改它以将我们的更改保存到另一个文件： $ awk \u0026#39;{print $0, \u0026#34; is a great programming language.\u0026#34;}\u0026#39; test.txt \u0026gt; test_awk.txt 5.使用回声 众所周知，*echo*命令将文本写入标准输出（STDOUT）。 虽然echo命令的行为因 shell 而略有不同，但我们将在此处介绍 bash 内置版本。 让我们结合*cat命令并运行echo：* $ cat test.txt | while read line; do echo ${line}$\u0026#34; is a great programming language.\u0026#34;; done Python is a great programming language. Java is a great programming language. JavaScript is a great programming language. PHP is a great programming language. 和以前一样，让我们分解一下：  cat：我们首先使用cat来读取我们的文件。 | pipe：我们用它来将cat与一个附加命令结合起来。 while\u0026hellip;do：我们使用 while 循环遍历文件中的每一行。 done：一旦完成，我们就使用它来终止我们的函数。  但是，我们的结果只打印到标准输出 (STDOUT)，以保存我们的更改。 让我们将更改保存到一个名为test_echo.txt的新文件中： $ cat test.txt | while read line; do echo ${line}$\u0026#34; is a great programming language.\u0026#34; \u0026gt;\u0026gt; test_echo.txt; done 6.使用perl perl (Practical Extraction and Report Language)是一种**最初为扫描任意文本文件、从中提取信息并根据输入数据生成报告而优化的语言。**它结合了sed、awk和sh的一些特性，使我们能够更轻松、更熟悉地快速解决常见问题。 让我们运行perl命令： $ perl -pi -e \u0026#39;s/$/\\ is a great programming language./\u0026#39; test.txt 让我们仔细看看以了解更多信息：  *-pi：*我们使用这个标签来打印和保存我们的更改。 -e：我们使用这个标签，以便我们可以从终端执行perl代码，而不是创建一个文件。 s/$/：代表一个正则表达式，它以我们文件中每一行的结尾为目标。  上面的命令没有显示标准输出的结果。但是，我们可以对输入文件本身使用cat命令来查看更改。由于perl直接对输入文件进行更改，因此我们不需要创建新文件。 \u0026quot; ","permalink":"http://itcodingman.github.io/add_string_line_end/","tags":["awk","echo","file","perl","sed"],"title":"如何在 Linux 中的文件中的每一行之后添加一个字符串"},{"categories":["Scripting"],"contents":" 概述   我们可以想象需要在变量中插入换行符的情况。例如，对于任何需要文本格式的任务，生成要运行的命令列表。 出于这个原因，在本教程中，我们将举例说明如何在 bash 中将换行符插入到变量中。 2.显示已经格式化的文本 首先，我们想简要介绍一下用换行符显示文本的可能性。 假设我们有带有换行符的文本。鉴于让我们尝试使用*echo*： $ text=\u0026#34;first \\nsecond \\nthird\u0026#34; $ echo $text first \\nsecond \\nthird 正如我们所见，\\ n序列未被识别为新行。 2.1 echo -e命令 为了能够识别特殊字符序列，例如换行符*\\n*，我们可以使用带有特殊选项*-e的echo*： $ text=\u0026#34;first \\nsecond \\nthird\u0026#34; $ echo -e $text first second third 这一次我们已经实现了我们想要的，并且单词换行了。 2.2. printf命令 使用printf我们可以完成与使用echo -e相同的结果： $ text=\u0026#34;first \\nsecond \\nthird\u0026#34; $ printf %b $text first second third 2.3. 带有换行符的文本 让我们考虑一下当我们有一个带有换行符的文本时的情况： $ text=\u0026#34;first second third\u0026#34; $ echo \u0026#34;$text\u0026#34; first second third 正如我们所看到的，当我们处理包含插入换行符的文本时，我们也可以根据需要显示文本。但是，让我们注意我们必须用括号包裹变量，否则它不会显示带有新行的文本。 2.4. 外壳参数扩展 此外，我们可以通过参数扩展来操作文本。 为此，我们需要在所有出现的*\\n之前添加**$*运算符： $ text=\u0026#34;first \u0026#34;$\u0026#39;\\n\u0026#39;\u0026#34;second \u0026#34;$\u0026#39;\\n\u0026#39;\u0026#34;third\u0026#34; $ echo \u0026#34;$text\u0026#34; first second third 3.自动在文本中添加换行符 在上一节中，我们展示了如何显示和格式化文本以打印新行。但是，在实际示例中，具有预处理文本并根据指定规则添加换行符的能力可能非常有用。因此，我们准备了一些如何在文本中设置新行的示例。 3.1 顺序添加换行符 假设我们想在文本中插入换行符而不是空格，我们之前用作示例。因此，我们可以例如遍历每个世界并插入我们在上一节中已经知道的特殊序列字符之一： $ text=\u0026#34;first second third\u0026#34; $ for word in $text $ do $ p+=\u0026#34;$word\u0026#34;$\u0026#39;\\n\u0026#39; $ done $ echo \u0026#34;$p\u0026#34; first second third 正如我们所见，它很好用！ 3.2. 添加换行符而不是所选字符 但是如果我们想添加一个换行符而不是“;”呢？或除空格以外的任何其他字符？出于这个原因，我们必须稍微修改一下我们之前的脚本： $ text=\u0026#34;first ; second ; third\u0026#34; $ IFS=\u0026#34;;\u0026#34; $ for word in $text; do \u0026gt; p+=\u0026#34;$word\u0026#34;$\u0026#39;\\n\u0026#39; \u0026gt; done $ echo \u0026#34;$p\u0026#34; first second third 完美的！所以现在我们知道如何在变量中存储换行符，也知道如何操作任何文本或命令序列来在我们想要的任何地方插入换行符。 3.3. 使用*tr*命令 我们可以使用更方便的东西，而不是遍历文本中的所有单词。因此，对于我们的目的而言， *tr*将是一个完美的选择： $ text=\u0026#34;first second third\u0026#34; $ echo $text | tr \u0026#34; \u0026#34; \u0026#34;\\n\u0026#34; first second third 结果与我们使用循环时的结果相同，但这次我们将所有内容放在一行中。 将文件中的文本分配给变量   现在假设我们想使用存储在文件中的文本。出于这个原因，使用先前提供的命令没有任何障碍。但是，在处理文件中的文本时，我们首先想到的是sed命令。 4.1 使用sed命令 当然，结合echo的sed命令也可以用于我们使用分配给变量的文本的示例。但是为了使其优雅而不需要编写多于一行的代码，我们使用sed准备了示例： $ cat text.txt one two three four five six $ text=$(sed \u0026#39;s/ /\\n/g\u0026#39; text.txt) $ echo $text one two three four five six 很棒，只需要一行代码，我们就可以从文件中读取文本，插入换行符而不是空格（当然我们可以将任何字符交换到换行符），并将其分配给一个变量。 4.2. awk命令 我们认为拥有更多选择总是更好。考虑到这一点，我们想再举一个在变量中插入换行符的例子： $ cat text.txt one two three four five six $ text=$(awk \u0026#39;{gsub(/ /,\u0026#34;\\n\u0026#34;)}1\u0026#39; text.txt) $ echo $text one two three four five six 它的工作与sed几乎相同，但awk有很多附加功能，这可能对我们非常有用。 \u0026quot; ","permalink":"http://itcodingman.github.io/add_newline_variable_bash/","tags":["awk","printf","sed","tr"],"title":"在 Bash 的变量中插入换行符"},{"categories":["Scripting"],"contents":" 概述   在本教程中，我们将学习如何在 Bash shell 中将一列数字相加。我们将仔细研究一些可用于此目的的 Bash 实用程序。我们还将对所提供解决方案的性能进行基准测试。 设置   首先，让我们设置我们将在大部分教程中使用的输入文件： $ for i in `seq 1000000`; do echo $(($RANDOM%100)); done \u0026gt;numbers.csv 在这里，我们正在生成一个文件numbers.csv，其中包含 1-100 范围内的一百万个随机数。我们使用seq命令运行一个for循环，使用RANDOM内置变量生成 1,000,000 个数字。 在接下来的部分中，我们还将查看使用time命令提供的解决方案的本地速度，以了解每个命令的执行方式。 3.使用awk工具 让我们从*awk*命令开始计算列中数字的总和： $ awk \u0026#39;{Total=Total+$1} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; numbers.csv Total is: 49471228 现在，让我们看看使用time命令的执行时间： $ time awk \u0026#39;{Total=Total+$1} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; numbers.csv Total is: 49471228 real 0m0.228s user 0m0.141s sys 0m0.047s 它非常快！我们可以在 0.228 秒内计算出一百万个数字的总和。事实上，awk是 Bash 中用于文件处理的最强大的工具之一。 3.1 当文件包含多列时 到目前为止，我们知道一种使用awk将列中的数字相加的方法。让我们看看我们在一个文件中有多个列并且我们只对计算特定列的总和感兴趣的情况： $ cat prices.csv Books,40 Bag,70 Dress,80 Box,10 此处，文件prices.csv包含两列。现在，让我们计算第二列中元素的总和： $ awk -F \u0026#34;,\u0026#34; \u0026#39;{Total=Total+$2} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; prices.csv Total is: 200 3.2. 当文件包含标题行时 有时，文本或 CSV 文件也包含标题行。该标题行通常包含列名，以提高可读性。让我们修改我们的prices.csv并添加一个标题行： $ cat prices.csv Item,Value Books,40 Bag,70 Dress,80 Box,10 当文件包含标题行时，我们希望在文本处理发生之前消除此标题行。有几种方法可以实现这一点。在这种情况下，我们将使用awk工具来忽略标题行。所以，让我们继续修改我们的命令来计算列总和： $ awk -F \u0026#34;,\u0026#34; \u0026#39;NR!=1{Total=Total+$2} END{print \u0026#34;Total is: \u0026#34; Total}\u0026#39; prices.csv Total is: 200 在接下来的部分中，我们将检查一些其他方法来将列中的数字相加，并评估awk解决方案相对于这些方法的执行情况。 使用 Bash 循环进行迭代   awk是一个很棒的工具，但是，我们也可以使用循环来遍历列值。 4.1 使用expr命令 让我们运行一个实验并检查expr 命令在for循环中计算总和的有效性： $ time (sum=0;for number in `cat numbers.csv`; do sum=`expr $sum + $number`; done; echo \u0026#34;Total is: $sum\u0026#34;) Total is: 49471228 real 212m48.418s user 7m19.375s sys 145m48.203s **处理速度非常慢。使用expr命令，添加一百万个数字需要 3.5 多个小时。**值得注意的是，expr实用程序是 Bash 早期的遗留物，我们应该只在我们的脚本需要与遗留（POSIX 之前）实现互操作的情况下使用它。 4.2. 使用算术展开 由于使用expr命令没有多大帮助，让我们尝试另一种使用算术扩展的方法： $ time (sum=0;for number in `cat numbers.csv`; do sum=$((sum+number)); done; echo \u0026#34;Total is: $sum\u0026#34;) Total is: 49471228 real 0m1.961s user 0m1.813s sys 0m0.125s 在这里，我们使用算术展开式计算总和，形式为$((..))。与expr命令相反，使用算术扩展，我们能够在两秒内添加一百万个数字。**算术扩展允许我们执行简单的整数算术。但是，它不适用于浮点数。因此，对于浮点运算，我们必须使用bc命令。我们将在下一节检查bc命令的实现。 使用bc命令添加值   bc命令对单行表达式执行计算。因此，我们需要将这些数字组合成一行，并由加法运算符分隔。然后我们将表达式传递给bc以计算总数。让我们来看看实现这一点的几种方法。 5.1 使用paste命令 首先，**让我们看一下将数据集的前 10 个数字排列在一行中的paste**命令，它们之间使用加号 (+) 运算符： $ cat numbers.csv| head -10 | paste -sd+ - 2+44+6+15+23+0+15+88+82+1 选项*-s*确保 paste 将所有数字连接在一行中。我们还指定了 d+ 选项以在加入条目时添加“+”字符作为分隔符。 有了这个，我们准备将这个序列作为标准输入提供给bc命令： $ time echo \u0026#34;Total is: $(cat numbers.csv | paste -sd+ - | bc)\u0026#34; Total is: 49471228 real 0m0.244s user 0m0.203s sys 0m0.063s 值得注意的是，性能优于我们使用 Bash 循环观察到的性能（约 2 秒）。此外，它接近但无法击败awk命令的性能（0.228 秒）。 5.2. 使用tr命令 与粘贴命令类似，让我们再次使用tr命令生成一个序列： $ cat numbers.csv | head -10 |tr \u0026#34;\\n\u0026#34; \u0026#34;+\u0026#34; 2+44+6+15+23+0+15+88+82+1+ 在这里，我们将每个换行符*(\u0026rsquo;\\n\u0026rsquo;)转换为加号(\u0026rsquo;+\u0026rsquo;)字符。但是，请注意序列末尾的额外“+” 。作为一种解决方法，我们可以在最后添加一个额外的零来解决这个问题，然后再将它传递给bc*命令： $ cat numbers.csv | head -10 |tr \u0026#34;\\n\u0026#34; \u0026#34;+\u0026#34; ; echo \u0026#34;0\u0026#34; 2+44+6+15+23+0+15+88+82+1+0 现在，让我们将输出重定向到bc命令： $ time ((cat numbers.csv | tr \u0026#34;\\n\u0026#34; \u0026#34;+\u0026#34; ; echo \u0026#34;0\u0026#34;) | bc) 49471228 real 0m0.217s user 0m0.203s sys 0m0.031s tr和bc命令的组合执行速度比awk解决方案快。** 5.3. 使用sed命令 最后，我们将使用sed命令生成序列： $ cat numbers.csv | head -10 | sed -z \u0026#39;s#\\n#+#g\u0026#39; 2+44+6+15+23+0+15+88+82+1+ 同样，我们使用sed命令的搜索和替换选项将换行符*(\u0026rsquo;\\n\u0026rsquo;)替换为加号(\u0026rsquo;+\u0026rsquo;)*字符。此外，我们在末尾打印零来处理额外的加号运算符，类似于上一节： $ time ((cat numbers.csv | sed -z \u0026#39;s#\\n#+#g\u0026#39; ; echo \u0026#34;0\u0026#34;) | bc) 49471228 real 0m0.343s user 0m0.281s sys 0m0.109s 在这里，使用*-z选项会更改sed命令的换行符的含义。它将不再将\\n视为行尾，而是将空字符解释为行尾。实际上，我们可以用加号(\u0026rsquo;+\u0026rsquo;)字符替换换行符(\u0026rsquo;\\n\u0026rsquo;)*。 请注意，与tr和paste选项相比，用sed替换字符很慢。 在我们结束之前，我们应该知道，对于包含单个数字列的文件，非*awk替代方案可能运行得更快。*但是在许多现实世界的场景中，文件将包含多个列，并且在实际计算发生之前要去除一些附加信息（有点类似于我们在第 3.1 节中的讨论）。 在这种情况下，awk应该是首选工具，因为非awk替代方案的所有速度优势将被在计算其元素之和之前预处理文件以提取单个列所花费的时间所消耗。 \u0026quot; ","permalink":"http://itcodingman.github.io/add_column_of_numbers/","tags":["awk","expr","paste","sed","tr"],"title":"如何在 Bash 中添加一列数字"},{"categories":["Files"],"contents":" 简介   在本教程中，我们将了解如何使用两种常见的 Linux 文件系统工具获取给定文件的绝对目录。 2.先决条件 不幸的是，目前没有一个命令可以获取文件的绝对目录。相反，我们必须将操作分成两部分，使用一个命令的输出作为另一个命令的输入。 2.1 readlink 要获取文件的完整路径，我们使用readlink命令。readlink打印符号链接的绝对路径，但作为副作用，它还打印相对路径的绝对路径。 例如，假设我们有以下目录结构： / └── home/ └── example/ ├── foo/ | └── file.txt └── link -\u0026gt; foo/ 我们使用*-f标志来规范化相对路径或符号链接的路径。因此，如果我们将目录更改为/home/example/*，我们可以执行以下任何命令： readlink -f foo/file.txt readlink -f link/file.txt readlink -f ./foo/file.txt readlink -f ../example/foo/file.txt 这些命令将输出： /home/example/foo/file.txt 对于第一个命令，readlink将*foo/的相对路径解析为/home/example/foo/*的绝对路径。 在第二种情况下，readlink将*link/*的符号链接解析为相同的绝对路径。 对于最后两个命令，readlink将相对路径规范化并解析为与前面示例相同的绝对路径。 请注意，-f标志要求除了提供的路径中的最后一个组件（在我们的例子中为file.txt）之外的所有组件都必须存在。如果路径不存在，则不返回任何输出。例如，执行readlink -f bar/file.txt将不会产生任何输出，因为bar/目录不存在。相反，执行readlink -f foo/other.txt将返回*/home/example/foo/other.txt*，因为除了最终组件之外的所有组件都存在。 相反，如果我们不关心提供的路径中是否存在任何组件，我们可以使用*-m标志。同样，如果我们希望提供的路径中的所有组件都存在，我们可以使用-e标志。* 2.2 dirname 第二个先决条件是dirname命令，它打印包含提供的路径的目录。 如果我们提供一个目录，dirname会输出包含该目录的路径。例如，我们可以执行： dirname /home/example/foo/ 这将产生： /home/example 请注意，dirname会打印绝对目录，因为我们提供了绝对路径。如果我们将目录更改为*/home/并执行dirname example/foo/，dirname将输出example*。通常，如果提供了相对路径，则dirname将输出一个相对目录，如果提供了绝对路径，则dirname将输出一个绝对目录。 提供文件时，dirname输出包含该文件的路径。例如，我们可以执行： dirname foo/file.txt 这将产生： foo 3.文件的绝对目录 要获取文件的绝对目录，我们结合使用readlink和dirname命令。我们可以通过以下两种方式之一来做到这一点。 3.1 xargs 首先，我们可以使用xargs命令，它将输入转换为所提供命令的参数。通过将readlink的输出传送到xargs并将命令dirname作为参数提供给xargs，我们可以获得这个所需的绝对目录： readlink -f foo/file.txt | xargs dirname 这导致： /home/example/foo 3.2 命令替换 类似地，我们可以使用命令替换- $(command) - 在子 shell 中执行命令，并且该命令的输出替换它的调用。因此，我们可以执行以下操作： dirname $(readlink -f foo/file.txt) 此命令导致： /home/example/foo 等效地，我们也可以执行以下命令，并且输出将保持不变： dirname `readlink -f foo/file.txt` 请注意，命令替换适用于 bash，但不一定适用于其他 shell。 \u0026quot; ","permalink":"http://itcodingman.github.io/absolute_directory_of_file/","tags":["dirname","readlink"],"title":"在 Linux 中获取文件的绝对目录"},{"categories":["Processes","Scripting"],"contents":" 概述   使用Bash 脚本，我们拥有了一个强大的工具。Bash 脚本是连续运行多个命令的好方法。在编写脚本的时候，我们要提醒自己，如果一个命令失败了，后面的所有命令仍然会执行。在本文中，我们将学习如何通过添加一些保护措施来防止这种情况。本文示例中使用的命令已经在 Bash 中进行了测试。它们也应该在其他 POSIX 兼容的 shell 中工作。 2.问题 首先，让我们看一下 bash 脚本在默认情况下是如何处理错误的。假设我们有一个简单的脚本hello.sh打印单词 \u0026lsquo;hello\u0026rsquo; 和 \u0026lsquo;world\u0026rsquo;： #!/bin/bash echo hello echo world 运行它会给出预期的结果： $ ./hello.sh hello world 现在让我们添加一个保证失败的语句： #!/bin/bash echo hello cat non-existing-file echo world 执行时，此脚本将打印错误。然而，执行并没有停止，\u0026lsquo;world\u0026rsquo; 仍然被打印出来： $ ./hello.sh hello cat: non-existing-file: No such file or directory world 此外，我们的脚本的退出代码为零，表明一切正常： $ echo $? 0 3.第一个错误退出 假设我们想让我们的脚本在发生第一个错误时以非零退出代码终止。因此，我们必须在脚本开头使用set更改 shell 的默认行为： #!/bin/bash set -e echo hello cat non-existing-file echo world 在第一行使用 set -e，我们告诉 Bash 在第一个错误时停止执行： $ ./hello.sh hello cat: non-existing-file: No such file or directory 此外，返回的退出代码等于失败命令的退出代码： $ echo $? 1 使用pipefail   不幸的是，此解决方案不适用于包含管道语句的脚本。例如，让我们将前两个命令连接在一起，从失败的命令开始： #!/bin/bash set -e cat non-existing-file | echo hello echo world 尽管我们使用 了set -e，但输出是： $ ./hello.sh hello cat: non-existing-file: No such file or directory world 为了处理这种情况，让我们在第一行的set 命令中添加*-o pipefail* 作为附加选项 ： #!/bin/bash set -eo pipefail cat non-existing-file | echo hello echo world 因此我们告诉 Bash，当管道中发生错误时，它应该停止并返回最右边失败的命令的退出代码： $ ./hello.sh hello cat: non-existing-file: No such file or directory 这会产生与我们之前看到的相同的非零退出代码： $ echo $? 1 \u0026quot; ","permalink":"http://itcodingman.github.io/aborting_shell_script/","tags":[],"title":"如果任何命令失败则中止 Shell 脚本"},{"categories":["Administration","Installation"],"contents":" 概述   想象一个程序员想要设计和编写三个不同的程序。他认为这三个程序共享几个可以被程序重用的通用功能。为了让他的生活更轻松，他需要将这些功能收集到一个名为library的实体中。 通常，库是为其他程序员或程序重用而编写的数据和函数的集合。在 Linux 上，存档库以.a扩展名结尾，共享对象库以.so 扩展名**结尾。 在本文中，我们将了解程序如何在 Linux 下运行以及归档和共享对象库的用途。除此之外，我们还将看到一些关于如何为程序构建库的示例。我们将使用GNU C 编译器 和GNU ar实用程序。 2.Linux下程序如何运行 大多数 Linux 用户可能都遇到过*/lib和/usr/lib*目录。这些是我们存储 安装在我们的 Linux 机器上**的程序使用的所有常用功能的目录。**作为约定，库名称以“lib”开头，扩展名决定了库的类型：  .a — 代表“存档” .so — 代表“共享对象”  一个程序可能依赖于多个共享对象。因此，手动安装共享对象可能很麻烦。为了解决这个问题，我们需要一个包管理器——一个在安装实际程序之前计算和确定依赖关系的工具。 当我们运行程序时，它会在*/usr/lib* 和*/share*目录中查找所需的依赖项。但是，如果缺少所需的依赖项，程序将无法启动。 3.程序库 程序库由执行常见任务所需的相关数据和子程序组成。例如，多个程序可能需要使用复数来计算结果。提供此功能的库的一个很好的例子是GNU C 库，它在链接阶段由gcc编译器链接到我们的程序中。 3.1 静态库 传统的静态库是一种在编译时与程序链接的库。因此，库的目标代码包含在可执行程序的目标代码中。最终，如果我们有多个程序链接到一个静态库，那么每个生成的程序二进制文件都将包含引用库的目标代码。因此，这将导致更大的可执行文件。 静态库通常以*.a扩展名结尾——例如glibc.a*。 3.2 共享库 为了解决较大的可执行二进制文件的问题，程序员改用共享库。共享库也称为动态库。这些共享库在运行时由操作系统上可用的动态链接器链接。 共享库通常以*.so扩展名结尾——例如libboost.5.6.so*。与静态库不同，引用共享库的程序不会在其生成的可执行文件中包含共享库对象代码。因此，我们得到更小的可执行文件。 同样，当我们有多个程序引用同一个共享库时，该库将有一个可供程序同时重用的单一副本。这是由操作系统安全管理的，它是现代计算的基础。我们看一下*/usr/lib/xorg*目录： $ ls -halF /usr/bin/xorg -rwxr-xr-x 1 root root 95K Apr 13 20:12 libexa.so* -rwxr-xr-x 1 root root 23K Apr 13 20:12 libfbdevhw.so* -rwxr-xr-x 1 root root 111K Apr 13 20:12 libfb.so* -rwxr-xr-x 1 root root 213K Apr 13 20:12 libglamoregl.so* -rwxr-xr-x 1 root root 143K Apr 13 20:12 libint10.so* -rwxr-xr-x 1 root root 15K Apr 13 20:12 libshadowfb.so* -rwxr-xr-x 1 root root 39K Apr 13 20:12 libshadow.so* 正如我们所见，Xorg依赖于列出的共享库。反过来，这些库也可以被dwm等其他程序使用。 构建*.a*或静态库   为了使这个说明起作用，我们需要gcc来编译我们的源代码。假设我们有一堆C编程源文件——我们需要将源文件编译成目标代码。我们可以通过发出带有*-Wall选项的gcc*命令来实现： $ gcc -Wall -c *.c 我们需要确保我们位于源目录的根目录。-Wall选项告诉编译器打印它遇到的所有警告。*.c参数中的星号告诉编译器编译所有**.c源文件。发出上述命令后，编译器会将*.c文件编译为相应的目标文件。因此，我们获得了 构建库所需的所有必需的*.o*文件。 接下来，我们将使用GNU Binutils中包含的ar实用程序从目标代码创建一个库文件： $ ar -cvq libfile.a *.o -c选项抑制错误， -v 选项用于详细输出， -q选项用于快速将指定文件附加到存档。如果存档不存在，则会创建一个新存档。当ar命令执行成功时，我们应该得到一个静态库文件libfile.a。让我们看看libfile.a文件中包含的内容： $ ar -t libfile.a 这将列出归档到libfile.a中的所有目标文件。稍后，当我们想在我们的程序中包含该库时，我们可以简单地在编译命令中引用该库： $ gcc -o MyProgram *.o -L path/to/libdir -lfile.a -L选项用于指定库目录。 注意命令中的库文件名。我们 用*-l替换了lib*前缀。MyProgram可执行文件将包含 libfile.a库的目标代码。 构建*.so*或共享库   使用gcc可以轻松构建共享库。和之前一样，我们首先需要将源文件编译成对应的目标文件： $ gcc -Wall -c *.c 编译代码后，我们需要将目标代码文件提供给我们的下一个命令以创建共享库： $ gcc -shared -o libfile.so *.o -shared选项向编译器指定我们正在构建一个共享库。 成功编译后，我们将构建一个共享库，我们可以将其安装在我们的系统上，以便所有程序在运行时都可以使用它。 \u0026quot; ","permalink":"http://itcodingman.github.io/a_so_extension_files/","tags":["gcc"],"title":"什么是 .a 和 .so 文件？"},{"categories":["Spring MVC"],"contents":"1. 概述 本教程将讨论配置 Spring Transactions 的正确方法、如何使用*@Transactional*注解以及常见的陷阱。 有关核心持久性配置的更深入讨论，请查看Spring with JPA 教程。 基本上，有两种不同的方式来配置事务、注解和AOP，每一种方式都有自己的优势。我们将在这里讨论更常见的注释配置。 2. 配置事务 Spring 3.1 引入了**@EnableTransactionManagement注解**，我们可以在*@Configuration*类中使用它来启用事务支持： @Configuration @EnableTransactionManagement public class PersistenceJPAConfig{ @Bean public LocalContainerEntityManagerFactoryBean entityManagerFactoryBean(){ //...  } @Bean public PlatformTransactionManager transactionManager(){ JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory( entityManagerFactoryBean().getObject() ); return transactionManager; } } 但是，如果我们使用的是 Spring Boot 项目并且类路径上有 spring-data-* 或 spring-tx 依赖项，则默认情况下将启用事务管理。 3. 使用 XML 配置事务 对于 3.1 之前的版本，或者如果 Java 不是一个选项，这里是使用注释驱动和命名空间支持的 XML 配置： \u0026lt;bean id=\u0026#34;txManager\u0026#34; class=\u0026#34;org.springframework.orm.jpa.JpaTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;entityManagerFactory\u0026#34; ref=\u0026#34;myEmf\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;tx:annotation-driven transaction-manager=\u0026#34;txManager\u0026#34; /\u0026gt; 4. @Transactional注解 配置事务后，我们现在可以在类或方法级别使用*@Transactional注解 bean：* @Service @Transactional public class FooService { //... } 注解还支持进一步的配置：  交易的传播类型 事务的隔离级别 事务包装的操作的超时 一个readOnly 标志——提示持久性提供者事务应该是只读的 事务的回滚规则  请注意，默认情况下，回滚仅发生在运行时，未经检查的异常。检查的异常不会触发事务的回滚。当然，我们可以使用rollbackFor和noRollbackFor注释参数来配置这种行为。 5. 潜在的陷阱 5.1 交易和代理 在高层次上， Spring 为所有使用**@Transactional**注释的类创建代理，无论是在类上还是在任何方法上。代理允许框架在运行方法之前和之后注入事务逻辑，主要用于启动和提交事务。 需要记住的重要一点是，如果事务 bean 正在实现一个接口，那么默认情况下代理将是一个 Java 动态代理。这意味着只有通过代理传入的外部方法调用才会被拦截。**任何自调用都不会启动任何事务，*即使该方法具有@Transactional*注释。 使用代理的另一个注意事项是**只有公共方法才应该使用@Transactional 进行注释。**任何其他可见性的方法将简单地忽略注释，因为它们没有被代理。 5.2 更改隔离级别 courseDao.createWithRuntimeException(course); 我们还可以更改事务隔离级别： @Transactional(isolation = Isolation.SERIALIZABLE) 请注意，这实际上已在 Spring 4.1中引入；如果我们在 Spring 4.1之前运行上面的示例，它将导致：  org.springframework.transaction.InvalidIsolationLevelException：标准 JPA 不支持自定义隔离级别 -为您的 JPA 实现使用特殊的JpaDialect  5.3 只读事务 readOnly标志通常会产生混淆，尤其是在使用 JPA 时。来自 Javadoc：  这只是作为实际事务子系统的提示；它不一定会导致写访问尝试失败。无法解释只读提示的事务管理器在请求只读事务时不会抛出异常。  事实是，当设置了readOnly标志时，我们不能确定不会发生插入或更新。此行为取决于驱动，而 JPA 与驱动无关。 了解readOnly标志仅在事务内部相关也很重要。如果操作发生在事务上下文之外，则简单地忽略该标志。一个简单的示例将调用一个带有以下注释的方法： @Transactional( propagation = Propagation.SUPPORTS,readOnly = true ) 在非事务性上下文中，不会创建事务并且readOnly标志将被忽略。 5.4 事务记录 了解事务相关问题的一个有用方法是微调事务包中的日志记录。Spring中的相关包是“ org.springframework.transaction”，需要配置一个TRACE的日志级别。 5.5 事务回滚 @Transactional注解是指定方法上事务的语义的元数据。我们有两种回滚事务的方法：声明式和编程式。 在声明式方法中，我们使用 @Transactional对方法进行注解。@Transactional注解使用属性rollbackFor或rollbackForClassName来回滚事务，并使用属性noRollbackFor或noRollbackForClassName来避免对列出的异常进行回滚。 声明式方法中的默认回滚行为将在运行时异常时回滚。 让我们看一个使用声明性方法回滚事务以处理运行时异常或错误的简单示例： @Transactional public void createCourseDeclarativeWithRuntimeException(Course course) { courseDao.create(course); throw new DataIntegrityViolationException(\u0026#34;Throwing exception for demoing Rollback!!!\u0026#34;); } 接下来，我们将使用声明性方法为列出的检查异常回滚事务。我们示例中的回滚是在SQLException上： @Transactional(rollbackFor = { SQLException.class }) public void createCourseDeclarativeWithCheckedException(Course course) throws SQLException { courseDao.create(course); throw new SQLException(\u0026#34;Throwing exception for demoing rollback\u0026#34;); } 让我们看一下在声明性方法中对属性noRollbackFor的简单使用，以防止所列异常的事务回滚： @Transactional(noRollbackFor = { SQLException.class }) public void createCourseDeclarativeWithNoRollBack(Course course) throws SQLException { courseDao.create(course); throw new SQLException(\u0026#34;Throwing exception for demoing rollback\u0026#34;); } 在编程方法中，我们使用TransactionAspectSupport回滚事务： public void createCourseDefaultRatingProgramatic(Course course) { try { courseDao.create(course); } catch (Exception e) { TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); } } 声明性回滚策略应该优于程序化回滚策略。 \u0026quot; ","permalink":"http://itcodingman.github.io/transaction_configuration_with_jpa_and_spring/","tags":["Spring MVC Basics","Thymeleaf"],"title":"Spring 和 JPA 的事务配置"},{"categories":["Spring Data"],"contents":"1. 概述 Thymeleaf是一个 Java 模板引擎，用于处理和创建 HTML、XML、JavaScript、CSS 和文本。 在本教程中，我们将讨论如何在 Spring MVC 应用程序的视图层中使用 Thymeleaf以及一些基本用例。 该库具有极强的可扩展性，其自然的模板功能确保我们可以在没有后端的情况下制作模板原型。与其他流行的模板引擎（例如 JSP）相比，这使得开发速度非常快。 2. 将 Thymeleaf 与 Spring 集成 首先，让我们看看与 Spring 集成所需的配置。集成需要thymeleaf -spring库。 我们将以下依赖项添加到我们的 Maven POM 文件中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.11.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf-spring5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.11.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，对于 Spring 4 项目，我们必须使用thymeleaf-spring4库而不是thymeleaf-spring5。 SpringTemplateEngine类执行所有配置步骤。 我们可以在 Java 配置文件中将这个类配置为 bean： @Bean @Description(\u0026#34;Thymeleaf Template Resolver\u0026#34;) public ServletContextTemplateResolver templateResolver() { ServletContextTemplateResolver templateResolver = new ServletContextTemplateResolver(); templateResolver.setPrefix(\u0026#34;/WEB-INF/views/\u0026#34;); templateResolver.setSuffix(\u0026#34;.html\u0026#34;); templateResolver.setTemplateMode(\u0026#34;HTML5\u0026#34;); return templateResolver; } @Bean @Description(\u0026#34;Thymeleaf Template Engine\u0026#34;) public SpringTemplateEngine templateEngine() { SpringTemplateEngine templateEngine = new SpringTemplateEngine(); templateEngine.setTemplateResolver(templateResolver()); templateEngine.setTemplateEngineMessageSource(messageSource()); return templateEngine; } templateResolver bean 属性prefix和suffix分别指示webapp目录中视图页面的位置及其文件扩展名。 Spring MVC 中的ViewResolver接口将控制器返回的视图名称映射到实际的视图对象。ThymeleafViewResolver实现ViewResolver接口，它用于确定要呈现哪些 Thymeleaf 视图，给定视图名称。 集成的最后一步是将ThymeleafViewResolver添加为 bean： @Bean @Description(\u0026#34;Thymeleaf View Resolver\u0026#34;) public ThymeleafViewResolver viewResolver() { ThymeleafViewResolver viewResolver = new ThymeleafViewResolver(); viewResolver.setTemplateEngine(templateEngine()); viewResolver.setOrder(1); return viewResolver; } 3. Spring Boot 中的 Thymeleaf Spring Boot通过添加spring-boot-starter-thymeleaf依赖项为Thymeleaf提供自动配置： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 无需显式配置。默认情况下，HTML 文件应放置在resources/templates 位置。 4. 显示来自消息源（属性文件）的值 我们可以使用th:text=\u0026quot;#{key}\u0026quot; 标签属性来显示属性文件中的值。 为此，我们需要将属性文件配置为messageSource bean： @Bean @Description(\u0026#34;Spring Message Resolver\u0026#34;) public ResourceBundleMessageSource messageSource() { ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); messageSource.setBasename(\u0026#34;messages\u0026#34;); return messageSource; } 这是 Thymeleaf HTML 代码，用于显示与键welcome.message关联的值： \u0026lt;span th:text=\u0026#34;#{welcome.message}\u0026#34; /\u0026gt; 5. 显示模型属性 5.1 简单属性 我们可以使用th:text=\u0026quot;${attributename}\u0026quot; 标签属性来显示模型属性的值。 让我们在控制器类中添加一个名为serverTime的模型属性： model.addAttribute(\u0026#34;serverTime\u0026#34;, dateFormat.format(new Date())); 这是显示serverTime属性值的 HTML 代码： Current time is \u0026lt;span th:text=\u0026#34;${serverTime}\u0026#34; /\u0026gt; 5.2 集合属性 如果模型属性是对象的集合，我们可以使用th:each 标签属性对其进行迭代。 让我们定义一个包含两个字段id 和name的Student*模型类： public class Student implements Serializable { private Integer id; private String name; // standard getters and setters } 现在我们将在控制器类中添加一个学生列表作为模型属性： List\u0026lt;Student\u0026gt; students = new ArrayList\u0026lt;Student\u0026gt;(); // logic to build student data model.addAttribute(\u0026#34;students\u0026#34;, students); 最后，我们可以使用 Thymeleaf 模板代码遍历学生列表并显示所有字段值： \u0026lt;tbody\u0026gt; \u0026lt;tr th:each=\u0026#34;student: ${students}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${student.id}\u0026#34; /\u0026gt; \u0026lt;td th:text=\u0026#34;${student.name}\u0026#34; /\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; 6. 条件语句 6.1 if和unless 如果满足条件，我们使用th:if=\u0026quot;${condition}\u0026quot; 属性来显示视图的一部分。如果条件不满足，我们使用th:unless=\u0026quot;${condition}\u0026quot; 属性来显示视图的一部分。 让我们在Student模型中添加一个gender字段： public class Student implements Serializable { private Integer id; private String name; private Character gender; // standard getters and setters } 假设该字段有两个可能的值（M 或 F）来指示学生的性别。 如果我们希望显示单词“Male”或“Female”而不是单个字符，我们可以使用以下 Thymeleaf 代码： \u0026lt;td\u0026gt; \u0026lt;span th:if=\u0026#34;${student.gender} == \u0026#39;M\u0026#39;\u0026#34; th:text=\u0026#34;Male\u0026#34; /\u0026gt; \u0026lt;span th:unless=\u0026#34;${student.gender} == \u0026#39;M\u0026#39;\u0026#34; th:text=\u0026#34;Female\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; 6.2 switch和case 我们使用th:switch和th:case 属性来使用 switch 语句结构有条件地显示内容。 让我们使用th:switch和th:case 属性重写前面的代码： \u0026lt;td th:switch=\u0026#34;${student.gender}\u0026#34;\u0026gt; \u0026lt;span th:case=\u0026#34;\u0026#39;M\u0026#39;\u0026#34; th:text=\u0026#34;Male\u0026#34; /\u0026gt; \u0026lt;span th:case=\u0026#34;\u0026#39;F\u0026#39;\u0026#34; th:text=\u0026#34;Female\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; 7. 处理用户输入 我们可以使用th:action=\u0026quot;@{url}\u0026quot; 和 th:object=\u0026quot;${object}\u0026quot; 属性来处理表单输入。我们使用th:action 提供表单操作 URL，使用th:object 指定提交的表单数据将绑定到的对象。 使用th:field=\u0026quot;*{name}\u0026quot; 属性映射各个字段，其中name是对象的匹配属性。 对于Student类，我们可以创建一个输入表单： \u0026lt;form action=\u0026#34;#\u0026#34; th:action=\u0026#34;@{/saveStudent}\u0026#34; th:object=\u0026#34;${student}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;table border=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;label th:text=\u0026#34;#{msg.id}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;number\u0026#34; th:field=\u0026#34;*{id}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;label th:text=\u0026#34;#{msg.name}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; th:field=\u0026#34;*{name}\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; 在上面的代码中，/saveStudent是表单操作 URL，student是保存提交的表单数据的对象。 StudentController类处理表单提交： @Controller public class StudentController { @RequestMapping(value = \u0026#34;/saveStudent\u0026#34;, method = RequestMethod.POST) public String saveStudent(@ModelAttribute Student student, BindingResult errors, Model model) { // logic to process input data  } } @RequestMapping注解将控制器方法映射到表单中提供的 URL。带注释的方法saveStudent()对提交的表单执行所需的处理。最后，@ModelAttribute注释将表单字段绑定到学生对象。 8. 显示验证错误 我们可以使用*#fields.hasErrors()函数来检查一个字段是否有任何验证错误。我们使用#fields.errors()*函数来显示特定字段的错误。字段名称是这两个函数的输入参数。 让我们看一下用于迭代并显示表单中每个字段的错误的 HTML 代码： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;id\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;name\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 上述函数不接受字段名称，而是接受通配符*或常量all来表示所有字段。我们使用th:each 属性来迭代每个字段可能存在的多个错误。 这是之前使用通配符*重写的 HTML 代码： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;*\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 在这里我们使用常量all： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;all\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 同样，我们可以使用全局常量在 Spring 中显示全局错误。 这是显示全局错误的 HTML 代码： \u0026lt;ul\u0026gt; \u0026lt;li th:each=\u0026#34;err : ${#fields.errors(\u0026#39;global\u0026#39;)}\u0026#34; th:text=\u0026#34;${err}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 此外，我们可以使用th:errors属性来显示错误消息。 之前在表单中显示错误的代码可以使用th:errors属性重写： \u0026lt;ul\u0026gt; \u0026lt;li th:errors=\u0026#34;*{id}\u0026#34; /\u0026gt; \u0026lt;li th:errors=\u0026#34;*{name}\u0026#34; /\u0026gt; \u0026lt;/ul\u0026gt; 9. 使用转换 我们使用双括号语法*{{}}来格式化数据以供显示。这利用了为上下文文件的conversionService* bean 中的该类型字段配置的格式化程序。 让我们看看如何格式化Student类中的 name 字段： \u0026lt;tr th:each=\u0026#34;student: ${students}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${{student.name}}\u0026#34; /\u0026gt; \u0026lt;/tr\u0026gt; 上面的代码使用NameFormatter类，通过覆盖*WebMvcConfigurer接口的**addFormatters()*方法进行配置。 为此，我们的*@Configuration类覆盖了WebMvcConfigurerAdapter*类： @Configuration public class WebMVCConfig extends WebMvcConfigurerAdapter { // ...  @Override @Description(\u0026#34;Custom Conversion Service\u0026#34;) public void addFormatters(FormatterRegistry registry) { registry.addFormatter(new NameFormatter()); } } NameFormatter类实现了 Spring Formatter接口。 我们还可以使用*#conversions实用程序来转换对象以进行显示。实用程序函数的语法是#conversions.convert(Object, Class)，其中Object被转换为Class*类型。 以下是如何在删除小数部分的情况下显示学生对象百分比字段： \u0026lt;tr th:each=\u0026#34;student: ${students}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${#conversions.convert(student.percentage, \u0026#39;Integer\u0026#39;)}\u0026#34; /\u0026gt; \u0026lt;/tr\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/thymeleaf_in_spring_mvc/","tags":["JPA"],"title":"在 Spring 中使用 Thymeleaf"},{"categories":["Spring Persistence"],"contents":"1. 概述 本教程将重点**介绍将 Spring Data JPA 引入 Spring 项目，**并全面配置持久层。有关使用基于 Java 的配置和项目的基本 Maven pom 设置 Spring 上下文的分步介绍，请参阅本文。 2. Spring Data Generated DAO – 不再有 DAO 实现 正如我们在之前的文章中所讨论的，DAO 层通常由许多可以而且应该被简化的样板代码组成。这种简化的优点有很多：减少了我们需要定义和维护的工件数量、数据访问模式的一致性以及配置的一致性。 Spring Data 将这种简化更进一步，使得完全删除 DAO 实现成为可能。DAO 的接口现在是我们需要明确定义的唯一工件。 为了开始利用 JPA 的 Spring Data 编程模型，DAO 接口需要扩展 JPA 特定的Repository接口JpaRepository。这将使 Spring Data 能够找到这个接口并自动为其创建一个实现。 通过扩展接口，我们获得了标准 DAO 中可用的标准数据访问最相关的 CRUD 方法。 3. 自定义访问方法和查询 如前所述，通过实现Repository接口之一，DAO 将已经定义和实现了一些基本的 CRUD 方法（和查询）。 为了定义更具体的访问方法，Spring JPA 支持很多选项：  只需在接口中定义一个新方法 使用*@Query*注释提供实际的JPQL 查询 在 Spring Data 中使用更高级的Specification 和 Querydsl 支持 通过 JPA 命名查询定义自定义查询  第三个选项Specifications and Querydsl support 与 JPA Criteria 类似，但使用了更灵活方便的 API。这使得整个操作更具可读性和可重用性。当处理大量固定查询时，此 API 的优势将变得更加明显，因为我们可以通过较少数量的可重用块更简洁地表达这些。 最后一个选项的缺点是它要么涉及 XML，要么给域类增加了查询负担。 3.1 自动自定义查询 当 Spring Data 创建一个新的Repository实现时，它会分析接口定义的所有方法，并尝试从方法名称自动生成查询。虽然这有一些限制，但它是一种非常强大且优雅的方式，可以轻松定义新的自定义访问方法。 让我们看一个例子。如果实体有一个名称字段（以及 Java Bean 标准的getName和setName方法），**我们将在 DAO 接口中定义findByName方法。**这将自动生成正确的查询： public interface IFooDAO extends JpaRepository\u0026lt;Foo, Long\u0026gt; { Foo findByName(String name); } 这是一个比较简单的例子。查询创建机制支持更大的关键字集。 如果解析器无法将属性与域对象字段匹配，我们将看到以下异常： java.lang.IllegalArgumentException: No property nam found for type class com.baeldung.spring.data.persistence.model.Foo 3.2 手动自定义查询 现在让我们看一下我们将通过*@Query*注释定义的自定义查询： @Query(\u0026#34;SELECT f FROM Foo f WHERE LOWER(f.name) = LOWER(:name)\u0026#34;) Foo retrieveByName(@Param(\u0026#34;name\u0026#34;) String name); 要对查询的创建进行更细粒度的控制，例如使用命名参数或修改现有查询，参考是一个很好的起点。 4. 交易配置 Spring 管理的 DAO 的实际实现确实是隐藏的，因为我们不直接使用它。但是，它是一个足够简单的实现，即SimpleJpaRepository，它使用 annotations 定义事务语义。 更明确地说，这在类级别使用只读*@Transactional*注释，然后为非只读方法覆盖该注释。其余的事务语义是默认的，但是这些可以很容易地被每个方法手动覆盖。 4.1 异常翻译 现在的问题变成了：由于 Spring Data JPA 不依赖于旧的 ORM 模板（JpaTemplate、HibernateTemplate），并且自 Spring 5 以来它们已被删除，我们是否仍将 JPA 异常转换为 Spring 的DataAccessException层次结构？ 答案是，当然，我们是。通过在 DAO 上使用@Repository仍然可以启用异常翻译。此注解使 Spring bean 后处理器能够通知所有*@Repository* bean 以及在容器中找到的所有PersistenceExceptionTranslator实例，并像以前一样提供异常翻译。 让我们通过集成测试来验证异常翻译： @Test(expected = DataIntegrityViolationException.class) public void givenFooHasNoName_whenInvalidEntityIsCreated_thenDataException() { service.create(new Foo()); } 请记住，**异常翻译是通过代理完成的。**为了让 Spring 能够围绕 DAO 类创建代理，这些代理不能被声明为final。 5. Spring Data JPA 存储库配置 要激活 Spring JPA 存储库支持，我们可以使用*@EnableJpaRepositories*注释并指定包含 DAO 接口的包： @EnableJpaRepositories(basePackages = \u0026#34;com.codingman.spring.data.persistence.repository\u0026#34;) public class PersistenceConfig { ... } 我们可以对 XML 配置做同样的事情： \u0026lt;jpa:repositories base-package=\u0026#34;com.codingman.spring.data.persistence.repository\u0026#34; /\u0026gt; 6. Java 或 XML 配置 我们已经在之前的文章中详细讨论了如何在 Spring 中配置 JPA 。Spring Data 还利用了 Spring 对 JPA @PersistenceContext注释的支持。它使用它将EntityManager连接到负责创建实际 DAO 实现JpaRepositoryFactoryBean的 Spring 工厂 bean 。 除了已经讨论过的配置，如果我们使用 XML，我们还需要包含 Spring Data XML 配置： @Configuration @EnableTransactionManagement @ImportResource(\u0026#34;classpath*:*springDataConfig.xml\u0026#34;) public class PersistenceJPAConfig { ... } 7. Maven依赖 除了 JPA 的 Maven 配置之外，就像在之前的文章中一样，我们将添加spring -data-jpa依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 8. 使用 Spring Boot 我们还可以使用Spring Boot Starter Data JPA依赖项，它会自动为我们配置DataSource。 我们需要确保我们要使用的数据库存在于类路径中。在我们的示例中，我们添加了 H2 内存数据库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.200\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 结果，只需执行这些依赖项，我们的应用程序就可以启动并运行，我们可以将其用于其他数据库操作。 标准 Spring 应用程序的显式配置现在包含在 Spring Boot 自动配置中。 当然，我们可以通过添加我们自定义的显式配置来修改自动配置。 Spring Boot 提供了一种使用application.properties文件中的属性的简单方法。让我们看一个更改连接 URL 和凭据的示例： spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1 spring.datasource.username=sa spring.datasource.password=sa 9. Spring Data JPA 的有用工具 所有主要的 Java IDE 都支持 Spring Data JPA。让我们看看 Eclipse 和 IntelliJ IDEA 有哪些有用的工具。 **如果你使用 Eclipse 作为你的 IDE，你可以安装Dali Java Persistence Tools插件。**这提供了 JPA 实体的 ER 图、用于初始化模式的 DDL 生成以及基本的逆向工程功能。此外，您还可以使用 Eclipse Spring Tool Suite (STS)。它将有助于验证 Spring Data JPA 存储库中的查询方法名称。 如果您使用 IntelliJ IDEA，有两个选项。 IntelliJ IDEA Ultimate 支持 ER 图、用于测试 JPQL 语句的 JPA 控制台和有价值的检查。但是，这些功能在 Community Edition 中不可用。 **为了提高 IntelliJ 的生产力，您可以安装JPA Buddy插件，**它提供了许多功能，包括生成 JPA 实体、Spring Data JPA 存储库、DTO、初始化 DDL 脚本、Flyway 版本化迁移、Liquibase 更改日志等。此外，JPA Buddy 提供逆向工程的高级工具。 最后，JPA Buddy 插件适用于社区版和终极版。 \u0026quot; ","permalink":"http://itcodingman.github.io/the_persistence_layer_with_spring_data_jpa/","tags":["JPA"],"title":"Spring Data JPA 简介"},{"categories":["Spring"],"contents":"1. 概述 本教程展示了如何使用 Hibernate 作为持久性提供者来使用JPA 设置 Spring 。 有关使用基于 Java 的配置和项目的基本 Maven pom 设置 Spring 上下文的分步介绍，请参阅本文。 我们将从在 Spring Boot 项目中设置 JPA 开始。然后，如果我们有一个标准的 Spring 项目，我们将研究我们需要的完整配置。 2. Spring Boot 中的 JPA Spring Boot 项目旨在使创建 Spring 应用程序更快、更容易。这是通过对各种 Spring 功能使用启动器和自动配置来完成的，其中包括 JPA。 2.1 Maven 依赖项 要在 Spring Boot 应用程序中启用 JPA，我们需要*[spring-boot-starter](https://search.maven.org/classic/#search|ga|1|a%3A\u0026quot;spring-boot-starter\u0026quot; AND g%3A\u0026quot;org.springframework.boot\u0026quot;)和spring-boot-starter-data-jpa*依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-boot-starter包含 Spring JPA的必要自动配置。此外，spring-boot-starter-jpa项目引用了所有必要的依赖项，例如hibernate-core。 2.2 配置 Spring Boot 将Hibernate配置为默认的 JPA 提供程序，因此不再需要定义entityManagerFactory bean，除非我们想要自定义它。 **Spring Boot 还可以根据我们使用的数据库自动配置dataSource bean。**对于H2、HSQLDB 和Apache Derby类型的内存数据库，如果类路径上存在相应的数据库依赖项，则 Boot 会自动配置DataSource 。 例如，如果我们想在 Spring Boot JPA 应用程序中使用内存中的H2数据库，我们只需要在pom.xml文件中添加[h2](https://search.maven.org/classic/#search|ga|1|a%3A\u0026quot;h2\u0026quot; AND g%3A\u0026quot;com.h2database\u0026quot;)依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.200\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这样，我们不需要定义dataSource bean，但如果我们想自定义它，我们可以。 如果我们想将 JPA 与MySQL数据库一起使用，我们需要mysql-connector-java依赖项。我们还需要定义DataSource配置。 我们可以在*@Configuration*类中或使用标准 Spring Boot 属性来执行此操作。 Java 配置看起来与标准 Spring 项目中的配置相同： @Bean public DataSource dataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); dataSource.setUsername(\u0026#34;user\u0026#34;); dataSource.setPassword(\u0026#34;pass\u0026#34;); dataSource.setUrl( \u0026#34;jdbc:mysql://localhost:3306/myDb?createDatabaseIfNotExist=true\u0026#34;); return dataSource; } 要使用属性文件配置数据源，我们必须设置以spring.datasource为前缀的属性： spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.username=user spring.datasource.password=pass spring.datasource.url= jdbc:mysql://localhost:3306/myDb?createDatabaseIfNotExist=true Spring Boot 会根据这些属性自动配置一个数据源。 同样在 Spring Boot 1 中，默认连接池为Tomcat，但在 Spring Boot 2 中已更改为HikariCP。 正如我们所见，如果我们使用 Spring Boot，基本的 JPA 配置相当简单。 但是，**如果我们有一个标准的 Spring 项目，我们需要更明确的配置，使用 Java 或 XML。**这就是我们将在接下来的部分中关注的内容。 3. 非引导项目中使用 Java 的 JPA Spring 配置 要在 Spring 项目中使用 JPA，我们需要设置EntityManager。 这是配置的主要部分，我们可以通过 Spring 工厂 bean 来完成。这可以是更简单的LocalEntityManagerFactoryBean或更灵活的LocalContainerEntityManagerFactoryBean。 让我们看看如何使用后一个选项： @Configuration @EnableTransactionManagement public class PersistenceJPAConfig{ @Bean public LocalContainerEntityManagerFactoryBean entityManagerFactory() { LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(dataSource()); em.setPackagesToScan(new String[] { \u0026#34;com.baeldung.persistence.model\u0026#34; }); JpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); em.setJpaVendorAdapter(vendorAdapter); em.setJpaProperties(additionalProperties()); return em; } // ...  } 我们还需要显式定义我们上面使用的*DataSource* bean ： @Bean public DataSource dataSource(){ DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:mysql://localhost:3306/spring_jpa\u0026#34;); dataSource.setUsername( \u0026#34;tutorialuser\u0026#34; ); dataSource.setPassword( \u0026#34;tutorialmy5ql\u0026#34; ); return dataSource; } 配置的最后一部分是附加的 Hibernate 属性以及TransactionManager和exceptionTranslation bean： @Bean public PlatformTransactionManager transactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory(entityManagerFactory().getObject()); return transactionManager; } @Bean public PersistenceExceptionTranslationPostProcessor exceptionTranslation(){ return new PersistenceExceptionTranslationPostProcessor(); } Properties additionalProperties() { Properties properties = new Properties(); properties.setProperty(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;, \u0026#34;create-drop\u0026#34;); properties.setProperty(\u0026#34;hibernate.dialect\u0026#34;, \u0026#34;org.hibernate.dialect.MySQL5Dialect\u0026#34;); return properties; } 4. JPA Spring 配置 XML 接下来，让我们看一下使用 XML 的相同 Spring 配置： \u0026lt;bean id=\u0026#34;myEmf\u0026#34; class=\u0026#34;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;com.codingman.persistence.model\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jpaVendorAdapter\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter\u0026#34; /\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;jpaProperties\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.hbm2ddl.auto\u0026#34;\u0026gt;create-drop\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.dialect\u0026#34;\u0026gt;org.hibernate.dialect.MySQL5Dialect\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/spring_jpa\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;tutorialuser\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;tutorialmy5ql\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.orm.jpa.JpaTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;entityManagerFactory\u0026#34; ref=\u0026#34;myEmf\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;tx:annotation-driven /\u0026gt; \u0026lt;bean id=\u0026#34;persistenceExceptionTranslationPostProcessor\u0026#34; class= \u0026#34;org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\u0026#34; /\u0026gt; XML 和新的基于 Java 的配置之间存在相对较小的差异。也就是说，在 XML 中，对另一个 bean 的引用可以指向该 bean 或该 bean 的 bean 工厂。 但在 Java 中，由于类型不同，编译器不允许这样做，因此首先从其 bean 工厂中检索EntityManagerFactory ，然后将其传递给事务管理器： transactionManager.setEntityManagerFactory(entityManagerFactory().getObject()); 5. 完全无 XML 通常，JPA 通过META-INF/persistence.xml文件定义一个持久化单元。从 Spring 3.1 开始，persistence.xml不再需要。LocalContainerEntityManagerFactoryBean现在支持packagesToScan属性，其中可以指定要扫描*@Entity*类的包。 该文件是我们需要删除的最后一段 XML。我们现在可以在没有 XML 的情况下完全设置 JPA。 我们通常会在persistence.xml文件中指定 JPA 属性。 或者，我们可以将属性直接添加到实体管理器工厂 bean： factoryBean.setJpaProperties(this.additionalProperties()); 附带说明一下，如果 Hibernate 是持久性提供程序，那么这也是指定 Hibernate 特定属性的方法。 6. Maven 配置 除了 Spring Core 和持久性依赖项（在Spring with Maven 教程中有详细介绍）之外，我们还需要在项目中定义 JPA 和 Hibernate 以及 MySQL 连接器： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.17.Final\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.19\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，此处包含 MySQL 依赖项作为示例。我们需要一个驱动程序来配置数据源，但是任何支持 Hibernate 的数据库都可以。 \u0026quot; ","permalink":"http://itcodingman.github.io/the_persistence_layer_with_spring_and_jpa/","tags":["Spring Core Basics","Spring DI"],"title":"使用 Spring 的 JPA 指南"},{"categories":["Maven","Spring"],"contents":"1. 简介 在这个基础教程中，我们将学习如何使用 Spring Framework 进行简单的基于 XML 的 bean 配置。 2. 概述 让我们首先在pom.xml中添加 Spring 的库依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在[此处](https://search.maven.org/classic/#search|ga|1|g%3A\u0026quot;org.springframework\u0026quot; AND a%3A\u0026quot;spring-context\u0026quot;)找到最新版本的 Spring 依赖项。 3. 依赖注入——概述 依赖注入是一种技术，其中对象的依赖关系由外部容器提供。 假设我们有一个依赖于实际处理业务逻辑的服务的应用程序类： public class IndexApp { private IService service; // standard constructors/getters/setters } 现在假设IService是一个接口： public interface IService { public String serve(); } 这个接口可以有多种实现。 让我们快速看一下一种可能的实现： public class IndexService implements IService { @Override public String serve() { return \u0026#34;Hello World\u0026#34;; } } 在这里，IndexApp是一个高级组件，它依赖于名为IService的低级组件。 从本质上讲，我们将IndexApp与IService的特定实现分离，该实现可能会因各种因素而异。 4. 依赖注入——在行动 让我们看看如何注入依赖项。 4.1 使用属性 让我们看看如何使用基于 XML 的配置将依赖项连接在一起： \u0026lt;bean id=\u0026#34;indexService\u0026#34; class=\u0026#34;com.codingman.di.IndexService\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34; \u0026gt; \u0026lt;property name=\u0026#34;service\u0026#34; ref=\u0026#34;indexService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 可以看出，我们正在创建一个IndexService实例并为其分配一个id。默认情况下，bean是单例的。此外，我们正在创建一个IndexApp实例。 在这个 bean 中，我们使用 setter 方法注入另一个bean。 4.2 使用构造函数 我们可以使用构造函数注入依赖项，而不是通过 setter 方法注入 bean： \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34;\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;indexService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 4.3 使用静态工厂 我们还可以注入工厂返回的 bean。让我们创建一个简单的工厂，它根据提供的数字返回IService的实例： public class StaticServiceFactory { public static IService getNumber(int number) { // ...  } } 现在让我们看看如何使用上面的实现通过基于 XML 的配置将 bean 注入IndexApp ： \u0026lt;bean id=\u0026#34;messageService\u0026#34; class=\u0026#34;com.codingman.di.StaticServiceFactory\u0026#34; factory-method=\u0026#34;getService\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;service\u0026#34; ref=\u0026#34;messageService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 在上面的示例中，我们使用工厂方法调用静态**getService方法来创建一个 id为messageService的 bean ，我们将其注入IndexApp。 4.4 使用工厂方法 让我们考虑一个实例工厂，它根据提供的数字返回一个*IService实例。*这一次，方法不是静态的： public class InstanceServiceFactory { public IService getNumber(int number) { // ...  } } 现在让我们看看如何使用上述实现通过 XML 配置将 bean 注入IndexApp ： \u0026lt;bean id=\u0026#34;indexServiceFactory\u0026#34; class=\u0026#34;com.codingman.di.InstanceServiceFactory\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;messageService\u0026#34; class=\u0026#34;com.codingman.di.InstanceServiceFactory\u0026#34; factory-method=\u0026#34;getService\u0026#34; factory-bean=\u0026#34;indexServiceFactory\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;indexApp\u0026#34; class=\u0026#34;com.codingman.di.IndexApp\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;service\u0026#34; ref=\u0026#34;messageService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 在上面的示例中，我们使用工厂方法在InstanceServiceFactory 实例上调用getService方法，以创建一个 id 为messageService的 bean ，我们将其注入IndexApp。 5. 测试 这就是我们可以访问配置的 bean 的方式： @Test public void whenGetBeans_returnsBean() { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;...\u0026#34;); IndexApp indexApp = applicationContext.getBean(\u0026#34;indexApp\u0026#34;, IndexApp.class); assertNotNull(indexApp); } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_xml_injection/","tags":[],"title":"Spring 中基于 XML 的注入"},{"categories":["Spring"],"contents":"1. 概述 本教程说明了如何通过 Maven 设置Spring 依赖项。最新的 Spring 版本可以在 Maven Central上找到。 2. Maven 的基本 Spring 依赖 Spring 被设计成高度模块化的——使用 Spring 的一部分不应该也不需要另一部分。例如，基本的 Spring Context 可以没有 Persistence 或 MVC Spring 库。 让我们从一个基本的Maven 设置开始，它只使用spring-context依赖： \u0026lt;properties\u0026gt; \u0026lt;org.springframework.version\u0026gt;5.2.8.RELEASE\u0026lt;/org.springframework.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 这个依赖**——spring-context——定义了实际的 Spring Injection Container，并且有少量的依赖：spring-core、spring-expression、spring-aop和spring-beans。这些通过支持一些核心 Spring 技术**来增强容器：核心 Spring 实用程序、Spring 表达式语言(SpEL)、面向方面的编程支持和JavaBeans 机制。 请注意，我们在运行时范围内定义依赖项——这将确保在任何 Spring 特定 API 上都没有编译时依赖项。对于更高级的用例，可能会从一些选定的 Spring 依赖项中删除运行时范围，但对于更简单的项目，无需针对 Spring 进行编译以充分利用框架。 另请注意，JDK 8 是 Spring 5.2 所需的最低 Java 版本。它还支持 JDK 11 作为当前的 LTS 分支和 JDK 13 作为最新的 OpenJDK 版本。 3. Maven 的 Spring 持久性 现在让我们看看持久性 Spring 依赖项——主要是spring-orm： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-orm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这附带了 Hibernate 和 JPA 支持——例如HibernateTemplate和JpaTemplate——以及一些额外的与持久性相关的依赖项：spring-jdbc和spring-tx。 JDBC 数据访问库定义了Spring JDBC 支持以及JdbcTemplate，而spring-tx代表了极其灵活的事务管理抽象。 4. 使用 Maven 的 Spring MVC 要使用 Spring Web 和 Servlet 支持，除了上面的核心依赖项之外，还需要在pom中包含两个依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-web依赖项包含用于 Servlet 和 Portlet 环境的常见 Web 特定实用程序，而spring -webmvc启用了对 Servlet 环境的 MVC 支持。 由于spring-webmvc具有spring-web作为依赖项，因此在使用spring-webmvc时不需要显式定义spring-web。 从 Spring 5.0 开始，对于响应式堆栈 Web 框架的支持，我们可以添加Spring WebFlux的依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webflux\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${org.springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5. Maven 的 Spring 安全性 安全性 Maven 依赖项在Spring Security with Maven文章中进行了深入讨论。 6. 使用 Maven 进行Spring测试 Spring Test Framework 可以通过以下依赖项包含在项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 使用 Spring 5，我们也可以执行并发测试执行。 7. 使用里程碑 Spring 的发布版本托管在 Maven Central 上。但是，如果项目需要使用里程碑版本，则需要在 pom 中添加自定义 Spring 存储库： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.springframework.maven.milestone\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Framework Maven Milestone Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/milestone/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 一旦定义了这个存储库，项目就可以定义依赖项，例如： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0-M1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 8. 使用快照 与里程碑类似，快照托管在自定义存储库中： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.springframework.maven.snapshot\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Framework Maven Snapshot Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/snapshot/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 在 pom.xml 中启用 SNAPSHOT 存储库后，可以引用以下依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.3.BUILD-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 以及对于 5.x： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/spring_with_maven/","tags":["Spring Core Basics"],"title":"Spring 和 Maven"},{"categories":["Spring"],"contents":"1. 概述 在本文中，我们将介绍Spring作为最流行的 Java 框架之一的主要价值主张。 更重要的是，我们将尝试了解 Spring 成为我们选择框架的原因。Spring 及其组成部分的详细信息已在我们之前的教程中广泛介绍。因此，我们将跳过介绍性的“如何”部分，而主要关注“为什么”。 2. 为什么使用任何框架？ 在我们开始特别讨论 Spring 之前，让我们首先了解为什么我们首先需要使用任何框架。 像 Java 这样的通用编程语言能够支持各种各样的应用程序。更不用说 Java 每天都在积极地工作和改进。 此外，在这方面有无数的开源和专有库支持 Java。 那么我们到底为什么需要一个框架呢？老实说，使用框架来完成任务并不是绝对必要的。但是，出于以下几个原因，通常建议使用其中一种：  帮助我们专注于核心任务而不是与其相关的样板 以设计模式的形式汇集多年的智慧 帮助我们遵守行业和监管标准 降低应用程序的总拥有成本  我们只是在这里触及了表面，我们必须说这些好处是难以忽视的。但这不可能都是积极的，所以有什么问题：  迫使我们以特定的方式编写应用程序 绑定到特定版本的语言和库 增加应用程序的资源占用  坦率地说，软件开发中没有灵丹妙药，框架当然也不例外。因此，应该从上下文中驱动选择哪个框架或不选择哪个框架。 希望在本文结束时，我们能够更好地做出关于 Java 中的 Spring 的决定。 3. Spring生态系统简介 在我们开始对 Spring Framework 进行定性评估之前，让我们仔细看看 Spring 生态系统是什么样的。 **Spring 出现在 2003 年的某个地方，**当时 Java 企业版正在快速发展，开发企业应用程序令人兴奋但仍然乏味！ Spring 最初是作为Java 的控制反转 (IoC) 容器。我们仍然主要将 Spring 与它联系起来，事实上，它构成了框架的核心以及在它之上开发的其他项目。 3.1 Spring框架 Spring 框架分为模块，这使得在任何应用程序中都可以很容易地挑选和选择部分：  核心：提供核心功能，如 DI（依赖注入）、国际化、验证和 AOP（面向方面的编程） 数据访问：支持通过 JTA（Java Transaction API）、JPA（Java Persistence API）和 JDBC（Java 数据库连接）进行数据访问 Web：同时支持 Servlet API ( Spring MVC ) 和最近的 Reactive API ( Spring WebFlux )，另外还支持 WebSockets、STOMP 和 WebClient 集成：支持通过 JMS（Java 消息服务）、JMX（Java 管理扩展）和 RMI（远程方法调用）集成到 Enterprise Java 测试：通过模拟对象、测试装置、上下文管理和缓存对单元和集成测试提供广泛支持  3.2 Spring项目 但是，让 Spring 更有价值的是一个强大的生态系统，多年来围绕它发展并继续积极发展。这些都是在 Spring 框架之上开发的Spring 项目。 虽然 Spring 项目的列表很长，而且还在不断变化，但有几个值得一提：  Boot：为我们提供了一套高度自以为是但可扩展的模板，几乎可以在短时间内创建各种基于 Spring 的项目。它使得使用嵌入式 Tomcat 或类似容器创建独立的 Spring 应用程序变得非常容易。 云：提供支持以轻松开发一些常见的分布式系统模式，如服务发现、断路器和 API 网关。它可以帮助我们减少在本地、远程甚至托管平台上部署此类样板模式的工作量。 安全性：提供强大的机制，以高度可定制的方式为基于 Spring 的项目开发身份验证和授权。通过最少的声明性支持，我们可以防止会话固定、点击劫持和跨站点请求伪造等常见攻击。 移动：提供检测设备并相应地调整应用程序行为的功能。此外，支持设备感知视图管理以获得最佳用户体验、站点偏好管理和站点切换器。 Batch：提供轻量级框架，用于为数据归档等企业系统开发批处理应用程序。对调度、重新启动、跳过、收集指标和日志记录具有直观的支持。此外，支持通过优化和分区扩展大容量作业。  不用说，这是对 Spring 所提供的内容的相当抽象的介绍。但它为我们提供了足够的关于 Spring 的组织和广度的基础来进一步讨论。 4. Spring 示例 习惯上添加一个 hello-world 程序来了解任何新技术。 让我们看看Spring 如何让编写一个不仅仅是 hello-world 的程序变得轻而易举。我们将创建一个应用程序，它将 CRUD 操作公开为 REST API，用于由内存数据库支持的域实体（如 Employee）。更重要的是，我们将使用基本身份验证保护我们的突变端点。最后，没有好的、旧的单元测试，任何应用程序都不可能真正完整。 4.1 项目设置 我们将使用Spring Initializr设置我们的 Spring Boot 项目，这是一个方便的在线工具，可以使用正确的依赖项引导项目。我们将添加 Web、JPA、H2 和 Security 作为项目依赖项，以正确设置 Maven 配置。 有关引导的更多详细信息，请参阅我们之前的一篇文章。 4.2 领域模型和持久性 要做的事情很少，我们已经准备好定义我们的领域模型和持久性。 让我们首先将Employee定义为一个简单的 JPA 实体： @Entity public class Employee { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; @NotNull private String firstName; @NotNull private String lastName; // Standard constructor, getters and setters } 请注意我们在实体定义中包含的自动生成的 ID。 现在我们必须为我们的实体定义一个 JPA 存储库。这是 Spring 让它变得非常简单的地方： public interface EmployeeRepository extends CrudRepository\u0026lt;Employee, Long\u0026gt; { List\u0026lt;Employee\u0026gt; findAll(); } 我们所要做的就是定义一个这样的接口，Spring JPA 将为我们提供一个包含默认和自定义操作的实现。相当整洁！在我们的其他文章中查找有关使用 Spring Data JPA的更多详细信息。 4.3 控制器 现在我们必须定义一个 Web 控制器来路由和处理我们的传入请求： @RestController public class EmployeeController { @Autowired private EmployeeRepository repository; @GetMapping(\u0026#34;/employees\u0026#34;) public List\u0026lt;Employee\u0026gt; getEmployees() { return repository.findAll(); } // Other CRUD endpoints handlers } 实际上，我们所要做的就是注释类并定义路由元信息以及每个处理程序方法。 我们之前的文章详细介绍了使用Spring REST 控制器。 4.4 安全 所以我们现在已经定义了一切，但是如何保护诸如创建或删除员工之类的操作呢？我们不希望未经身份验证的访问这些端点！ Spring Security 在这方面确实大放异彩： @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/employees\u0026#34;, \u0026#34;/employees/**\u0026#34;) .permitAll() .anyRequest() .authenticated() .and() .httpBasic(); } // other necessary beans and definitions } 这里有更多细节需要注意理解，但最重要的一点是我们只允许不受限制的 GET 操作的声明方式。 4.5 测试 现在我们已经完成了所有工作，但是等等，我们如何测试呢？ 让我们看看 Spring 是否可以轻松地为 REST 控制器编写单元测试： @RunWith(SpringRunner.class) @SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT) @AutoConfigureMockMvc public class EmployeeControllerTests { @Autowired private MockMvc mvc; @Test @WithMockUser() public void givenNoEmployee_whenCreateEmployee_thenEmployeeCreated() throws Exception { mvc.perform(post(\u0026#34;/employees\u0026#34;).content( new ObjectMapper().writeValueAsString(new Employee(\u0026#34;First\u0026#34;, \u0026#34;Last\u0026#34;)) .with(csrf())) .contentType(MediaType.APPLICATION_JSON) .accept(MediaType.APPLICATION_JSON)) .andExpect(MockMvcResultMatchers.status() .isCreated()) .andExpect(jsonPath(\u0026#34;$.firstName\u0026#34;, is(\u0026#34;First\u0026#34;))) .andExpect(jsonPath(\u0026#34;$.lastName\u0026#34;, is(\u0026#34;Last\u0026#34;))); } // other tests as necessary } 正如我们所见，Spring 为我们提供了编写简单单元和集成测试所需的基础设施，否则这些测试依赖于 Spring 上下文进行初始化和配置。 4.6 运行应用程序 最后，我们如何运行这个应用程序？这是 Spring Boot 的另一个有趣的方面。尽管我们可以将其打包为常规应用程序并传统上部署在 Servlet 容器上。 但是这哪有什么好玩的！Spring Boot 带有一个嵌入式 Tomcat 服务器： @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 这是一个作为引导程序的一部分预先创建的类，具有使用嵌入式服务器启动此应用程序的所有必要细节。 此外，这是高度可定制的。 5. Spring 的替代品 虽然选择使用框架相对容易，但在框架之间进行选择通常会因我们的选择而令人生畏。但为此，我们必须至少对 Spring 必须提供的功能有哪些替代方案有一个粗略的了解。 正如我们之前所讨论的，Spring 框架及其项目为企业开发人员提供了广泛的选择。如果我们对当代 Java 框架进行快速评估，它们甚至还没有接近 Spring 为我们提供的生态系统。 但是，对于特定领域，它们确实形成了一个令人信服的论据来选择替代方案：  Guice：为 Java 应用程序提供强大的 IoC 容器 Play：非常适合作为具有响应式支持的 Web 框架 Hibernate : 已建立的支持 JPA 的数据访问框架  除了这些之外，还有一些最近添加的内容提供了比特定域更广泛的支持，但仍然没有涵盖 Spring 必须提供的所有内容：  Micronaut：针对云原生微服务量身定制的基于 JVM 的框架 Quarkus：一个新时代的 Java 堆栈，承诺提供更快的启动时间和更小的占用空间  显然，完全迭代列表既没有必要也不可行，但我们确实在这里得到了大致的想法。 6. 那么，为什么选择Spring？ 最后，我们已经构建了所有必需的上下文来解决我们的中心问题，为什么是 Spring？我们了解框架可以帮助我们开发复杂的企业应用程序的方式。 此外，我们确实了解针对特定问题的选择，例如 Web、数据访问、框架集成，尤其是 Java。 现在，春天在所有这些中闪耀在哪里？让我们探索一下。 6.1 可用性 任何框架流行的关键方面之一是开发人员使用它的难易程度。Spring 通过多个配置选项和 Convention over Configuration 使开发人员能够非常轻松地开始并准确地配置他们需要的东西。 像Spring Boot 这样的项目使得引导一个复杂的 Spring 项目几乎是微不足道的。更不用说，它有优秀的文档和教程来帮助任何人上手。 6.2 模块化 Spring 受欢迎的另一个关键方面是其高度模块化的特性。我们可以选择使用整个 Spring 框架或仅使用必要的模块。此外，我们可以根据需要选择包含一个或多个 Spring 项目。 更重要的是，我们还可以选择使用其他框架，如 Hibernate 或 Struts！ 6.3 一致性 尽管 Spring不支持所有 Jakarta EE 规范，但它支持其所有技术，并且经常在必要时改进对标准规范的支持。例如，Spring 支持基于 JPA 的存储库，因此可以轻松切换提供程序。 此外，Spring 支持Spring Web Reactive 下的Reactive Stream和Spring HATEOAS 下的 HATEOAS 等行业规范。 6.4 可测试性 采用任何框架很大程度上还取决于测试构建在它之上的应用程序的难易程度。Spring 的核心是倡导并支持测试驱动开发(TDD)。 Spring 应用程序主要由 POJO 组成，这自然使单元测试相对简单得多。但是，Spring 确实为 MVC 等单元测试变得复杂的场景提供了 Mock Objects。 6.5 成熟 Spring 在创新、采用和标准化方面有着悠久的历史。多年来，它已经足够成熟，成为大型企业应用程序开发中面临的最常见问题的默认解决方案。 更令人兴奋的是它的开发和维护有多积极。每天都在开发对新语言功能和企业集成解决方案的支持。 6.6 社区支持 最后但同样重要的是，任何框架甚至库都通过创新在行业中生存下来，没有比社区更好的创新场所了。Spring 是由 Pivotal Software 领导的开源项目，并得到了一个由组织和个人开发人员组成的大型联盟的支持。 这意味着它仍然是上下文相关的，而且往往是未来主义的，这一点从它旗下的项目数量就可以看出。 7. 不使用 Spring 的原因 有各种各样的应用程序可以从不同级别的 Spring 使用中受益，并且随着 Spring 的增长而变化。 但是，我们必须了解 Spring 与任何其他框架一样有助于管理应用程序开发的复杂性。它可以帮助我们避免常见的陷阱，并随着时间的推移保持应用程序的可维护性。 这是以额外的资源占用和学习曲线为代价的，尽管这可能很小。如果真的有一个足够简单且不会变得复杂的应用程序，那么完全不使用任何框架可能会受益更多！ \u0026quot; ","permalink":"http://itcodingman.github.io/spring_why_to_choose/","tags":["Spring Core Basics"],"title":"为什么选择 Spring 作为您的 Java 框架？"},{"categories":["Spring"],"contents":"1. 概述 Spring 的*@Value*注解提供了一种将属性值注入组件的便捷方式。为可能不存在属性的情况提供合理的默认值也非常有用。 这就是我们将在本教程中关注的内容——如何为*@Value* Spring 注解指定默认值。 有关*@Value*的更详细的快速指南，请参阅此处的文章。 2. 字符串默认值 让我们看一下为String属性设置默认值的基本语法： @Value(\u0026#34;${some.key:my default value}\u0026#34;) private String stringWithDefaultValue; 如果some.key无法解析，stringWithDefaultValue**将设置为我的 default value 的默认值。 同样，我们可以设置一个长度为零的字符串作为默认值： @Value(\u0026#34;${some.key:})\u0026#34; private String stringWithBlankDefaultValue; 3. 基本类型 要为boolean和int等基本类型设置默认值，我们使用文字值： @Value(\u0026#34;${some.key:true}\u0026#34;) private boolean booleanWithDefaultValue; @Value(\u0026#34;${some.key:42}\u0026#34;) private int intWithDefaultValue; 如果我们愿意，我们可以通过将类型更改为Boolean和Integer来使用原始包装器。 4. 数组 我们还可以将逗号分隔的值列表注入数组： @Value(\u0026#34;${some.key:one,two,three}\u0026#34;) private String[] stringArrayWithDefaults; @Value(\u0026#34;${some.key:1,2,3}\u0026#34;) private int[] intArrayWithDefaults; 在上面的第一个示例中，值one、two 和three作为默认值注入到stringArrayWithDefaults中。 在第二个示例中，值1、2 和3作为默认值注入到intArrayWithDefaults中。 5. 使用 SpEL 我们还可以使用 Spring 表达式语言 (SpEL) 来指定表达式和默认值。 在下面的示例中，我们希望将 some.system.key设置为系统属性，如果未设置，我们希望使用我的默认系统属性值 作为默认值： @Value(\u0026#34;#{systemProperties[\u0026#39;some.key\u0026#39;] ?: \u0026#39;my default system property value\u0026#39;}\u0026#34;) private String spelWithDefaultValue; \u0026quot; ","permalink":"http://itcodingman.github.io/spring_value_defaults/","tags":["Spring Annotations","Spring Core Basics"],"title":"使用带有默认值的 Spring @Value"},{"categories":["Maven","Spring Security"],"contents":"1.概述 在这个快速教程中，我们将看一下*@Value* 注释。 此注解可用于将值注入 Spring 管理的 bean 中的字段，并且可以在字段或构造函数/方法参数级别应用。 2. 设置应用程序 为了描述这个注解的不同用途，我们需要配置一个简单的 Spring 应用程序配置类。 自然，我们需要一个属性文件来定义我们想要使用*@Value*注释注入的值。因此，我们首先需要在我们的配置类中定义一个@PropertySource——使用属性文件名。 让我们定义属性文件： value.from.file=Value got from the file priority=high listOfValues=A,B,C 3. 使用示例 作为一个基本且几乎无用的示例，我们只能将注释中的“字符串值”注入字段： @Value(\u0026#34;string value\u0026#34;) private String stringValue; 使用*@PropertySource注释允许我们使用带有@Value*注释的属性文件中的值。 在以下示例中，我们从 分配给该字段的文件中获取 Value： @Value(\u0026#34;${value.from.file}\u0026#34;) private String valueFromFile; 我们还可以使用相同的语法从系统属性中设置值。 假设我们已经定义了一个名为systemValue的系统属性： @Value(\u0026#34;${systemValue}\u0026#34;) private String systemValue; 可以为可能未定义的属性提供默认值。在这里， 将注入一些默认值： @Value(\u0026#34;${unknown.param:some default}\u0026#34;) private String someDefault; 如果相同的属性被定义为系统属性并在属性文件中，则系统属性将被应用。 假设我们将属性优先级定义为系统属性，其值为System 属性，并在属性文件中定义为其他内容。该值将是系统属性： @Value(\u0026#34;${priority}\u0026#34;) private String prioritySystemProperty; 有时，我们需要注入一堆值。将它们定义为属性文件中单个属性的逗号分隔值或系统属性并注入数组会很方便。 在第一节中，我们在属性文件的listOfValues中定义了逗号分隔的值，因此数组值将是*[“A”, “B”, “C”]：* @Value(\u0026#34;${listOfValues}\u0026#34;) private String[] valuesArray; 4. SpEL 的高级示例 我们还可以使用 SpEL 表达式来获取值。 如果我们有一个名为priority的系统属性，那么它的值将应用于该字段： @Value(\u0026#34;#{systemProperties[\u0026#39;priority\u0026#39;]}\u0026#34;) private String spelValue; 如果我们没有定义系统属性，那么将分配空值。 为了防止这种情况，我们可以在 SpEL 表达式中提供一个默认值。如果未定义系统属性，我们将获得该字段的一些默认值： @Value(\u0026#34;#{systemProperties[\u0026#39;unknown\u0026#39;] ?: \u0026#39;some default\u0026#39;}\u0026#34;) private String spelSomeDefault; 此外，我们可以使用来自其他 bean 的字段值。假设我们有一个名为someBean的 bean ，其字段someValue等于10。然后，10将分配给该字段： @Value(\u0026#34;#{someBean.someValue}\u0026#34;) private Integer someBeanValue; 我们可以操作属性来获取值列表，这里是字符串值 A、B 和 C 的列表： @Value(\u0026#34;#{\u0026#39;${listOfValues}\u0026#39;.split(\u0026#39;,\u0026#39;)}\u0026#34;) private List\u0026lt;String\u0026gt; valuesList; 5. 将*@Value与Map*一起使用 我们还可以使用*@Value注解来注入Map*属性。 首先，我们需要在属性文件的*{key: \u0026lsquo;value\u0026rsquo; }*表单中定义属性： valuesMap={key1: \u0026#39;1\u0026#39;, key2: \u0026#39;2\u0026#39;, key3: \u0026#39;3\u0026#39;} 请注意，Map中的值必须用单引号引起来。 现在我们可以将属性文件中的这个值作为Map注入： @Value(\u0026#34;#{${valuesMap}}\u0026#34;) private Map\u0026lt;String, Integer\u0026gt; valuesMap; 如果我们需要在Map中获取特定键的值，我们所要做的就是在表达式中添加键的名称： @Value(\u0026#34;#{${valuesMap}.key1}\u0026#34;) private Integer valuesMapKey1; 如果我们不确定Map是否包含某个键，我们应该选择一个更安全的表达式，它不会抛出异常，而是在找不到键时将值设置为null ： @Value(\u0026#34;#{${valuesMap}[\u0026#39;unknownKey\u0026#39;]}\u0026#34;) private Integer unknownMapKey; 我们还可以为可能不存在的属性或键设置默认值： @Value(\u0026#34;#{${unknownMap : {key1: \u0026#39;1\u0026#39;, key2: \u0026#39;2\u0026#39;}}}\u0026#34;) private Map\u0026lt;String, Integer\u0026gt; unknownMap; @Value(\u0026#34;#{${valuesMap}[\u0026#39;unknownKey\u0026#39;] ?: 5}\u0026#34;) private Integer unknownMapKeyWithDefaultValue; 映射条目也可以在注入之前进行过滤。 假设我们只需要获取值大于 1 的条目： @Value(\u0026#34;#{${valuesMap}.?[value\u0026gt;\u0026#39;1\u0026#39;]}\u0026#34;) private Map\u0026lt;String, Integer\u0026gt; valuesMapFiltered; 我们还可以使用*@Value*注解注入所有当前系统属性： @Value(\u0026#34;#{systemProperties}\u0026#34;) private Map\u0026lt;String, String\u0026gt; systemPropertiesMap; 6. 将*@Value*与构造函数注入一起使用 当我们使用*@Value*注解时，我们并不局限于字段注入。我们也可以将它与构造函数注入一起使用。 让我们在实践中看看： @Component @PropertySource(\u0026#34;classpath:values.properties\u0026#34;) public class PriorityProvider { private String priority; @Autowired public PriorityProvider(@Value(\u0026#34;${priority:normal}\u0026#34;) String priority) { this.priority = priority; } // standard getter } 在上面的示例中，我们将优先级直接注入到PriorityProvider的构造函数中。 请注意，我们还提供默认值以防找不到该属性。 7. 使用*@Value*和 Setter 注入 类似于构造函数注入，我们也可以使用@Value*和setter注入。* 让我们来看看： @Component @PropertySource(\u0026#34;classpath:values.properties\u0026#34;) public class CollectionProvider { private List\u0026lt;String\u0026gt; values = new ArrayList\u0026lt;\u0026gt;(); @Autowired public void setValues(@Value(\u0026#34;#{\u0026#39;${listOfValues}\u0026#39;.split(\u0026#39;,\u0026#39;)}\u0026#34;) List\u0026lt;String\u0026gt; values) { this.values.addAll(values); } // standard getter } 我们使用 SpEL 表达式将值列表注入到setValues方法中。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_value_annotation/","tags":["Spring Security Basics"],"title":"Spring @Value 快速指南"},{"categories":["Spring MVC"],"contents":"1. 概述 在本文中，我们将解释如何**使用 Maven 设置 Spring Security，**并介绍使用 Spring Security 依赖项的特定用例。您可以在 Maven Central 上找到最新的 Spring Security 版本。 这是上一篇 Spring with Maven 文章的后续，因此对于非安全 Spring 依赖项，这是开始的地方。 2. 使用 Maven 的 Spring Security 2.1 Spring Security核心 核心 Spring Security 支持 - spring-security-core - 包含身份验证和访问控制功能。所有使用 Spring Security 的项目都必须包含此依赖项。 此外，spring-security-core支持独立（非 Web）应用程序、方法级安全性和 JDBC： \u0026lt;properties\u0026gt; \u0026lt;spring-security.version\u0026gt;5.3.4.RELEASE\u0026lt;/spring-security.version\u0026gt; \u0026lt;spring.version\u0026gt;5.2.8.RELEASE\u0026lt;/spring.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-security.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 请注意，Spring 和 Spring Security 的发布计划不同，因此版本号之间并不总是 1:1 匹配。 如果您使用的是旧版本的 Spring – 同样重要的是要了解一个事实，即**Spring Security 4.1.x 不依赖于 Spring 4.1.x 版本！**例如，当Spring Security 4.1.0发布时，Spring 核心框架已经是 4.2.x，因此包含该版本作为其编译依赖项。计划是在未来的版本中更紧密地调整这些依赖关系——有关更多详细信息，请参阅此 JIRA——但就目前而言，这具有实际意义，我们将在接下来研究。 2.2 Spring Security 要为 Spring Security 添加Web 支持，我们需要spring-security-web依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-security.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这包含过滤器和相关的 Web 安全基础设施，可在 Servlet 环境中启用 URL 访问控制。 2.3 Spring Security 和旧的 Spring Core 依赖问题 这种新的依赖关系也表现出Maven 依赖关系图的问题。如上所述，Spring Security jars 不依赖于最新的 Spring core jars（而是依赖于之前的版本）。这可能会导致这些较旧的依赖项出现在类路径之上，而不是较新的 5.x Spring 工件。 要理解为什么会发生这种情况，我们需要看看Maven 如何解决冲突。在版本冲突的情况下，Maven 将选择最接近树根的 jar。例如，spring-core由spring-orm（5.0.0 .RELEASE版本）和spring-security-core（5.0.2.RELEASE版本）定义。所以在这两种情况下，spring-jdbc都定义在我们项目的根 pom 的深度为 1 处。因此，在我们自己的 pom.xml 中定义spring-orm和spring-security-core的顺序实际上很重要。第一个将优先，所以我们最终可能会在类路径中使用任一版本。 为了解决这个问题，我们必须在我们自己的 pom 中显式定义一些 Spring 依赖，而不是依赖隐式的 Maven 依赖解析机制。这样做会将特定依赖项置于我们的 pom 深度 0（因为它在 pom 本身中定义），因此它将优先。以下所有内容都属于同一类别，并且都需要直接明确定义，或者对于多模块项目，在父项的dependencyManagement元素中进行明确定义： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-beans\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-tx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-expression\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.4 spring-security-config和其他 要使用丰富的 Spring Security XML 命名空间和注释，我们需要spring-security-config依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-security.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最后，LDAP、ACL、CAS、OAuth 和 OpenID 支持在 Spring Security 中都有自己的依赖项：spring-security-ldap、spring-security-acl、spring-security-cas、spring-security-oauth和spring-security-openid。 3. 使用 Spring Boot 使用 Spring Boot 时，spring-boot-starter-security启动器将自动包含所有依赖项，例如spring-security-core、spring-security-web和spring-security-config等： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 由于 Spring Boot 将自动为我们管理所有依赖项，这也将摆脱前面提到的 Spring 安全性和旧的核心依赖项问题。 4. 使用快照和里程碑 Spring Security里程碑和快照在 Spring 提供的自定义 Maven 存储库中可用。有关如何配置这些的更多详细信息，请参阅如何使用快照和里程碑。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_security_with_maven/","tags":["Spring MVC Basics"],"title":"使用 Maven 的 Spring 安全性"},{"categories":["Spring MVC"],"contents":"1. 简介 在这个快速教程中，我们简要概述了 Spring @RequestBody和*@ResponseBody*注释。 2. @RequestBody 简单地说，@RequestBody注释将HttpRequest主体映射到传输或域对象，从而将入站HttpRequest主体自动反序列化到 Java 对象上。 首先，我们来看一个 Spring 控制器方法： @PostMapping(\u0026#34;/request\u0026#34;) public ResponseEntity postController( @RequestBody LoginForm loginForm) { exampleService.fakeAuthenticate(loginForm); return ResponseEntity.ok(HttpStatus.OK); } 假设指定了适当的类型，Spring 会自动将 JSON 反序列化为 Java 类型。 默认情况下，我们使用@RequestBody*注解注解的类型必须对应于从我们的客户端控制器发送的 JSON：* public class LoginForm { private String username; private String password; // ... } 在这里，我们用来表示HttpRequest主体的对象映射到我们的LoginForm对象。 让我们使用 CURL 进行测试： curl -i \\ -H \u0026#34;Accept: application/json\u0026#34; \\ -H \u0026#34;Content-Type:application/json\u0026#34; \\ -X POST --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;ann\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;}\u0026#39; \u0026#34;https://localhost:8080/.../request\u0026#34; 这就是使用*@RequestBody*注解的 Spring REST API 和 Angular 客户端所需要的全部内容。 3. @ResponseBody @ResponseBody注解告诉控制器返回的对象自动序列化为 JSON 并传回HttpResponse对象。 假设我们有一个自定义的Response对象： public class ResponseTransfer { private String text; // standard getters/setters } 接下来，可以实现关联的控制器： @Controller @RequestMapping(\u0026#34;/post\u0026#34;) public class ExamplePostController { @Autowired ExampleService exampleService; @PostMapping(\u0026#34;/response\u0026#34;) @ResponseBody public ResponseTransfer postResponseController( @RequestBody LoginForm loginForm) { return new ResponseTransfer(\u0026#34;Thanks For Posting!!!\u0026#34;); } } 在我们浏览器的开发者控制台中或者使用 Postman 之类的工具，我们可以看到如下响应： {\u0026#34;text\u0026#34;:\u0026#34;Thanks For Posting!!!\u0026#34;} *请记住，我们不需要使用 @ResponseBody 注解来注解@RestController-*注解的控制器，**因为 Spring 默认会这样做。 3.1 设置内容类型 当我们使用*@ResponseBody*注解时，我们仍然能够显式地设置我们的方法返回的内容类型。 为此，我们可以使用@RequestMapping的produces属性。**请注意，@PostMapping、@GetMapping等注释定义了该参数的别名。 现在让我们添加一个发送 JSON 响应的新端点： @PostMapping(value = \u0026#34;/content\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) @ResponseBody public ResponseTransfer postResponseJsonContent( @RequestBody LoginForm loginForm) { return new ResponseTransfer(\u0026#34;JSON Content!\u0026#34;); } 在示例中，我们使用了MediaType.APPLICATION_JSON_VALUE常量。或者，我们可以直接使用application/json。 接下来，让我们实现一个新方法，映射到相同的*/content*路径，但返回 XML 内容： @PostMapping(value = \u0026#34;/content\u0026#34;, produces = MediaType.APPLICATION_XML_VALUE) @ResponseBody public ResponseTransfer postResponseXmlContent( @RequestBody LoginForm loginForm) { return new ResponseTransfer(\u0026#34;XML Content!\u0026#34;); } 现在，根据请求标头中发送的Accept参数的值，我们将得到不同的响应。 让我们看看它的实际效果： curl -i \\  -H \u0026#34;Accept: application/json\u0026#34; \\  -H \u0026#34;Content-Type:application/json\u0026#34; \\  -X POST --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;ann\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;}\u0026#39; \u0026#34;https://localhost:8080/.../content\u0026#34; CURL 命令返回 JSON 响应： HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 20 Feb 2020 19:43:06 GMT {\u0026#34;text\u0026#34;:\u0026#34;JSON Content!\u0026#34;} 现在，让我们更改Accept参数： curl -i \\ -H \u0026#34;Accept: application/xml\u0026#34; \\ -H \u0026#34;Content-Type:application/json\u0026#34; \\ -X POST --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;ann\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;}\u0026#39; \u0026#34;https://localhost:8080/.../content\u0026#34; 正如预期的那样，这次我们得到了一个 XML 内容： HTTP/1.1 200 Content-Type: application/xml Transfer-Encoding: chunked Date: Thu, 20 Feb 2020 19:43:19 GMT \u0026lt;ResponseTransfer\u0026gt;\u0026lt;text\u0026gt;XML Content!\u0026lt;/text\u0026gt;\u0026lt;/ResponseTransfer\u0026gt; \u0026quot; ","permalink":"http://itcodingman.github.io/spring_request_response_body/","tags":["Spring Annotations","Spring Core Basics","Spring MVC Basics"],"title":"Spring 的 @RequestBody 和 @ResponseBody 注解"},{"categories":["Spring"],"contents":"1. 概述 在这个快速教程中，我们将探索 Spring 的*@RequestParam*注解及其属性。 简单来说，我们可以使用@RequestParam*从请求中提取查询参数、表单参数，甚至是文件。* 2. 一个简单的映射 假设我们有一个端点*/api/foos*接受一个名为 id的查询参数： @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam String id) { return \u0026#34;ID: \u0026#34; + id; } 在此示例中，我们使用*@RequestParam来提取id*查询参数。 一个简单的 GET 请求会调用getFoos： http://localhost:8080/spring-mvc-basics/api/foos?id=abc ---- ID: abc 接下来，让我们看一下注解的属性：name、 value、required和defaultValue。 3. 指定请求参数名称 在前面的例子中，变量名和参数名都是一样的。 **不过，有时我们希望这些有所不同。**或者，如果我们不使用 Spring Boot，我们可能需要进行特殊的编译时配置，否则参数名称实际上不会出现在字节码中。 幸运的是，我们可以使用name属性配置*@RequestParam*名称： @PostMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String addFoo(@RequestParam(name = \u0026#34;id\u0026#34;) String fooId, @RequestParam String name) { return \u0026#34;ID: \u0026#34; + fooId + \u0026#34; Name: \u0026#34; + name; } 我们也可以使用 @RequestParam(value = \u0026ldquo;id\u0026rdquo;)或只是@RequestParam(\u0026ldquo;id\u0026rdquo;)。 4. 可选请求参数 默认情况下需要使用*@RequestParam*注释的方法参数 。 这意味着如果请求中不存在参数，我们将收到错误： GET /api/foos HTTP/1.1 ----- 400 Bad Request Required String parameter \u0026#39;id\u0026#39; is not present 不过，我们可以使用required 属性将@RequestParam*配置为可选的：* @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam(required = false) String id) { return \u0026#34;ID: \u0026#34; + id; } 在这种情况下，两者： http://localhost:8080/spring-mvc-basics/api/foos?id=abc ---- ID: abc 和 http://localhost:8080/spring-mvc-basics/api/foos ---- ID: null 将正确调用该方法。 未指定参数时，方法参数绑定为null。 4.1 使用 Java 8 Optional 或者，我们可以将参数包装在 *Optional*中： @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam Optional\u0026lt;String\u0026gt; id){ return \u0026#34;ID: \u0026#34; + id.orElseGet(() -\u0026gt; \u0026#34;not provided\u0026#34;); } 在这种情况下，我们不需要指定required属性。 如果未提供请求参数，将使用默认值： http://localhost:8080/spring-mvc-basics/api/foos ---- ID: not provided 5. 请求参数的默认值 我们还可以 使用defaultValue属性为*@RequestParam设置默认值：* @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam(defaultValue = \u0026#34;test\u0026#34;) String id) { return \u0026#34;ID: \u0026#34; + id; } 这就像required=false， 因为用户不再需要提供参数： http://localhost:8080/spring-mvc-basics/api/foos ---- ID: test 虽然，我们仍然可以提供它： http://localhost:8080/spring-mvc-basics/api/foos?id=abc ---- ID: abc 请注意，当我们设置 defaultValue 属性时， required确实设置为false。 6. 映射所有参数 我们也可以有多个参数，而无需定义它们的名称或数量，只需使用Map： @PostMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String updateFoos(@RequestParam Map\u0026lt;String,String\u0026gt; allParams) { return \u0026#34;Parameters are \u0026#34; + allParams.entrySet(); } 然后将反映发送的任何参数： curl -X POST -F \u0026#39;name=abc\u0026#39; -F \u0026#39;id=123\u0026#39; http://localhost:8080/spring-mvc-basics/api/foos ----- Parameters are {[name=abc], [id=123]} 7. 映射多值参数 单个*@RequestParam*可以有多个值： @GetMapping(\u0026#34;/api/foos\u0026#34;) @ResponseBody public String getFoos(@RequestParam List\u0026lt;String\u0026gt; id) { return \u0026#34;IDs are \u0026#34; + id; } Spring MVC 将映射一个逗号分隔的 id 参数： http://localhost:8080/spring-mvc-basics/api/foos?id=1,2,3 ---- IDs are [1,2,3] 或单独的id参数列表： http://localhost:8080/spring-mvc-basics/api/foos?id=1\u0026amp;id=2 ---- IDs are [1,2] \u0026quot; ","permalink":"http://itcodingman.github.io/spring_request_param/","tags":["Spring Annotations","Spring Core Basics"],"title":"Spring @RequestParam 注解"},{"categories":["REST","Spring MVC"],"contents":"1. 概述 在本教程中，我们将关注Spring MVC 中的主要注解之一：@RequestMapping。 简单来说，注解就是用来将 web 请求映射到 Spring Controller 方法上的。 2. @RequestMapping基础 让我们从一个简单的示例开始：使用一些基本标准将 HTTP 请求映射到方法。 2.1 @RequestMapping — 按路径 @RequestMapping(value = \u0026#34;/ex/foos\u0026#34;, method = RequestMethod.GET) @ResponseBody public String getFoosBySimplePath() { return \u0026#34;Get some Foos\u0026#34;; } 要使用简单的curl命令测试此映射，请运行： curl -i http://localhost:8080/spring-rest/ex/foos 2.2. @RequestMapping — HTTP 方法 HTTP方法参数**没有默认值。**因此，如果我们不指定值，它将映射到任何 HTTP 请求。 这是一个简单的示例，与上一个类似，但这次映射到 HTTP POST 请求： @RequestMapping(value = \u0026#34;/ex/foos\u0026#34;, method = POST) @ResponseBody public String postFoos() { return \u0026#34;Post some Foos\u0026#34;; } 通过curl命令测试 POST： curl -i -X POST http://localhost:8080/spring-rest/ex/foos 3. RequestMapping和 HTTP 标头 3.1 @RequestMapping带有headers属性 通过为请求指定标头，可以进一步缩小映射范围： @RequestMapping(value = \u0026#34;/ex/foos\u0026#34;, headers = \u0026#34;key=val\u0026#34;, method = GET) @ResponseBody public String getFoosWithHeader() { return \u0026#34;Get some Foos with Header\u0026#34;; } 为了测试操作，我们将使用curl标头支持： curl -i -H \u0026#34;key:val\u0026#34; http://localhost:8080/spring-rest/ex/foos 甚至通过*@RequestMapping的headers*属性设置多个标头： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, headers = { \u0026#34;key1=val1\u0026#34;, \u0026#34;key2=val2\u0026#34; }, method = GET) @ResponseBody public String getFoosWithHeaders() { return \u0026#34;Get some Foos with Header\u0026#34;; } 我们可以使用以下命令进行测试： curl -i -H \u0026#34;key1:val1\u0026#34; -H \u0026#34;key2:val2\u0026#34; http://localhost:8080/spring-rest/ex/foos 请注意，对于curl语法，冒号分隔标头键和标头值，与 HTTP 规范中相同，而在 Spring 中，使用等号。 3.2 @RequestMapping消费和生产 由控制器方法生成的映射媒体类型值得特别注意。 我们可以通过上面介绍的*@RequestMapping* headers属性根据其Accept标头映射请求： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, method = GET, headers = \u0026#34;Accept=application/json\u0026#34;) @ResponseBody public String getFoosAsJsonFromBrowser() { return \u0026#34;Get some Foos with Header Old\u0026#34;; } 这种定义Accept标头的方式的匹配是灵活的——它使用 contains 而不是 equals，所以像下面这样的请求仍然可以正确映射： curl -H \u0026#34;Accept:application/json,text/html\u0026#34; http://localhost:8080/spring-rest/ex/foos 从 Spring 3.1 开始，@RequestMapping注解现在具有生产和消费属性，专门用于此目的： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, method = RequestMethod.GET, produces = \u0026#34;application/json\u0026#34; ) @ResponseBody public String getFoosAsJsonFromREST() { return \u0026#34;Get some Foos with Header New\u0026#34;; } 此外，从 Spring 3.1 开始，带有headers属性的旧映射类型将自动转换为新的生产机制，因此结果将是相同的。 这是通过curl以相同的方式使用的： curl -H \u0026#34;Accept:application/json\u0026#34; http://localhost:8080/spring-rest/ex/foos 此外，produces 还支持多个值： @RequestMapping( value = \u0026#34;/ex/foos\u0026#34;, method = GET, produces = { \u0026#34;application/json\u0026#34;, \u0026#34;application/xml\u0026#34; } ) 请记住，这些（指定Accept标头的新旧方法）基本上是相同的映射，因此 Spring 不允许它们一起使用。 激活这两种方法将导致： Caused by: java.lang.IllegalStateException: Ambiguous mapping found. Cannot map \u0026#39;fooController\u0026#39; bean method java.lang.String org.baeldung.spring.web.controller .FooController.getFoosAsJsonFromREST() to { [/ex/foos], methods=[GET],params=[],headers=[], consumes=[],produces=[application/json],custom=[] }: There is already \u0026#39;fooController\u0026#39; bean method java.lang.String org.baeldung.spring.web.controller .FooController.getFoosAsJsonFromBrowser() mapped. 关于新生产和消费机制的最后一点说明，其行为与大多数其他注释不同：在类型级别指定时，方法级别注释不会补充而是覆盖类型级别信息。 当然，如果您想深入了解如何使用 Spring 构建 REST API，请查看新的 REST with Spring 课程。 ** 4. 带路径变量的 RequestMapping** 映射 URI 的一部分可以通过*@PathVariable*注释绑定到变量。 4.1 单个@PathVariable 带有单个路径变量的简单示例： @RequestMapping(value = \u0026#34;/ex/foos/{id}\u0026#34;, method = GET) @ResponseBody public String getFoosBySimplePathWithPathVariable( @PathVariable(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Get a specific Foo with id=\u0026#34; + id; } 这可以用curl测试： curl http://localhost:8080/spring-rest/ex/foos/1 如果方法参数的名称与路径变量的名称完全匹配，则可以使用不带值的@PathVariable来简化： @RequestMapping(value = \u0026#34;/ex/foos/{id}\u0026#34;, method = GET) @ResponseBody public String getFoosBySimplePathWithPathVariable( @PathVariable String id) { return \u0026#34;Get a specific Foo with id=\u0026#34; + id; } 请注意，@PathVariable受益于自动类型转换，因此我们也可以将id声明为： @PathVariable long id 4.2 多个@PathVariable 更复杂的 URI 可能需要将 URI 的多个部分映射到多个值： @RequestMapping(value = \u0026#34;/ex/foos/{fooid}/bar/{barid}\u0026#34;, method = GET) @ResponseBody public String getFoosBySimplePathWithPathVariables (@PathVariable long fooid, @PathVariable long barid) { return \u0026#34;Get a specific Bar with id=\u0026#34; + barid + \u0026#34; from a Foo with id=\u0026#34; + fooid; } 这很容易用curl以相同的方式进行测试： curl http://localhost:8080/spring-rest/ex/foos/1/bar/2 4.3 @PathVariable与正则表达式 映射*@PathVariable*时也可以使用正则表达式。 例如，我们将映射限制为只接受id的数值： @RequestMapping(value = \u0026#34;/ex/bars/{numericId:[\\\\d]+}\u0026#34;, method = GET) @ResponseBody public String getBarsBySimplePathWithPathVariable( @PathVariable long numericId) { return \u0026#34;Get a specific Bar with id=\u0026#34; + numericId; } 这意味着以下 URI 将匹配： http://localhost:8080/spring-rest/ex/bars/1 但这不会： http://localhost:8080/spring-rest/ex/bars/abc 5. 请求参数的RequestMapping @RequestMapping 允许使用@RequestParam注释轻松映射 URL 参数。 我们现在将请求映射到 URI： http://localhost:8080/spring-rest/ex/bars?id=100 @RequestMapping(value = \u0026#34;/ex/bars\u0026#34;, method = GET) @ResponseBody public String getBarBySimplePathWithRequestParam( @RequestParam(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Get a specific Bar with id=\u0026#34; + id; } 然后，我们使用控制器方法签名中的*@RequestParam(\u0026ldquo;id\u0026rdquo;)注释来提取id*参数的值。 要发送带有id参数的请求，我们将使用curl中的参数支持： curl -i -d id=100 http://localhost:8080/spring-rest/ex/bars 在这个例子中，参数是直接绑定的，没有先声明。 对于更高级的场景，@RequestMapping可以选择将参数定义为缩小请求映射的另一种方式： @RequestMapping(value = \u0026#34;/ex/bars\u0026#34;, params = \u0026#34;id\u0026#34;, method = GET) @ResponseBody public String getBarBySimplePathWithExplicitRequestParam( @RequestParam(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Get a specific Bar with id=\u0026#34; + id; } 允许更灵活的映射。可以设置多个参数值，而不是必须使用所有参数值： @RequestMapping( value = \u0026#34;/ex/bars\u0026#34;, params = { \u0026#34;id\u0026#34;, \u0026#34;second\u0026#34; }, method = GET) @ResponseBody public String getBarBySimplePathWithExplicitRequestParams( @RequestParam(\u0026#34;id\u0026#34;) long id) { return \u0026#34;Narrow Get a specific Bar with id=\u0026#34; + id; } 当然，还有对 URI 的请求，例如： http://localhost:8080/spring-rest/ex/bars?id=100\u0026amp;second=something 将始终映射到最佳匹配——这是更窄的匹配，它定义了id和第二个参数。 6. RequestMapping角落案例 6.1 @RequestMapping — 映射到同一个控制器方法的多个路径 尽管单个*@RequestMapping*路径值通常用于单个控制器方法（只是一种好的做法，而不是硬性规定），但在某些情况下可能需要将多个请求映射到同一个方法。 在这种情况下，@RequestMapping的value属性确实接受多个映射，而不仅仅是一个： @RequestMapping( value = { \u0026#34;/ex/advanced/bars\u0026#34;, \u0026#34;/ex/advanced/foos\u0026#34; }, method = GET) @ResponseBody public String getFoosOrBarsByPath() { return \u0026#34;Advanced - Get some Foos or Bars\u0026#34;; } 现在这两个curl命令都应该使用相同的方法： curl -i http://localhost:8080/spring-rest/ex/advanced/foos curl -i http://localhost:8080/spring-rest/ex/advanced/bars 6.2 @RequestMapping — 对同一个控制器方法的多个 HTTP 请求方法 使用不同 HTTP 动词的多个请求可以映射到同一个控制器方法： @RequestMapping( value = \u0026#34;/ex/foos/multiple\u0026#34;, method = { RequestMethod.PUT, RequestMethod.POST } ) @ResponseBody public String putAndPostFoos() { return \u0026#34;Advanced - PUT and POST within single method\u0026#34;; } 使用curl，这两个现在都将使用相同的方法： curl -i -X POST http://localhost:8080/spring-rest/ex/foos/multiple curl -i -X PUT http://localhost:8080/spring-rest/ex/foos/multiple 6.3 @RequestMapping — 所有请求的后备 要使用特定 HTTP 方法为所有请求实现简单的回退，例如，对于 GET： @RequestMapping(value = \u0026#34;*\u0026#34;, method = RequestMethod.GET) @ResponseBody public String getFallback() { return \u0026#34;Fallback for GET Requests\u0026#34;; } 甚至对于所有请求： @RequestMapping( value = \u0026#34;*\u0026#34;, method = { RequestMethod.GET, RequestMethod.POST ... }) @ResponseBody public String allFallback() { return \u0026#34;Fallback for All Requests\u0026#34;; } 6.4 模棱两可的映射错误 当 Spring 评估两个或多个请求映射对于不同的控制器方法相同时，会发生不明确的映射错误。当请求映射具有相同的 HTTP 方法、URL、参数、标头和媒体类型时，它是相同的。 例如，这是一个模棱两可的映射： @GetMapping(value = \u0026#34;foos/duplicate\u0026#34; ) public String duplicate() { return \u0026#34;Duplicate\u0026#34;; } @GetMapping(value = \u0026#34;foos/duplicate\u0026#34; ) public String duplicateEx() { return \u0026#34;Duplicate\u0026#34;; } 抛出的异常通常确实包含以下错误消息： Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map \u0026#39;fooMappingExamplesController\u0026#39; method public java.lang.String com.codingman.web.controller.FooMappingExamplesController.duplicateEx() to {[/ex/foos/duplicate],methods=[GET]}: There is already \u0026#39;fooMappingExamplesController\u0026#39; bean method public java.lang.String com.codingman.web.controller.FooMappingExamplesController.duplicate() mapped. 仔细阅读错误消息会发现 Spring 无法映射方法 *com.codingman.web.controller.FooMappingExamplesController.duplicateEx()，*因为它与已映射的 com.codingman.web.controller的映射存在冲突.FooMappingExamplesController.duplicate()。 下面的代码片段不会导致不明确的映射错误，因为两种方法都返回不同的内容类型： @GetMapping(value = \u0026#34;foos/duplicate\u0026#34;, produces = MediaType.APPLICATION_XML_VALUE) public String duplicateXml() { return \u0026#34;\u0026lt;message\u0026gt;Duplicate\u0026lt;/message\u0026gt;\u0026#34;; } @GetMapping(value = \u0026#34;foos/duplicate\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) public String duplicateJson() { return \u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Duplicate\\\u0026#34;}\u0026#34;; } 这种区分允许我们的控制器根据请求中提供的Accepts标头返回正确的数据表示 。 解决此问题的另一种方法是更新分配给所涉及的两种方法中的任何一种的 URL。 7. 新的请求映射快捷方式 Spring Framework 4.3 引入了一些新的HTTP 映射注解，全部基于*@RequestMapping*：  @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping  这些新的注释可以提高可读性并减少代码的冗长。 让我们通过创建一个支持 CRUD 操作的 RESTful API 来看看这些新注释的实际应用： @GetMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; getBazz(@PathVariable String id){ return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(id, \u0026#34;Bazz\u0026#34;+id), HttpStatus.OK); } @PostMapping public ResponseEntity\u0026lt;?\u0026gt; newBazz(@RequestParam(\u0026#34;name\u0026#34;) String name){ return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(\u0026#34;5\u0026#34;, name), HttpStatus.OK); } @PutMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; updateBazz( @PathVariable String id, @RequestParam(\u0026#34;name\u0026#34;) String name) { return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(id, name), HttpStatus.OK); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; deleteBazz(@PathVariable String id){ return new ResponseEntity\u0026lt;\u0026gt;(new Bazz(id), HttpStatus.OK); } 可以在这里找到对这些的深入了解。 8. Spring 配置 考虑到我们的FooController定义在以下包中，Spring MVC 配置非常简单： package com.codingman.controller; @Controller public class FooController { ... } 我们只需要一个*@Configuration*类来启用完整的 MVC 支持并为控制器配置类路径扫描： @Configuration @EnableWebMvc @ComponentScan({ \u0026#34;com.codingman.controller\u0026#34; }) public class MvcConfig { // } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_requestmapping/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring请求映射"},{"categories":["Spring"],"contents":"1.概述 在本教程中，我们将探讨**@Qualifier注解**可以帮助我们解决哪些问题，以及如何使用它。 2. Autowire 需要消歧义 @Autowired注解是一种在 Spring 中显式注入依赖项的好方法。尽管它很有用，但在某些用例中，仅此注解不足以让 Spring 了解要注入哪个 bean。 默认情况下，Spring 按类型解析自动装配的条目。 如果容器中有多个相同类型的 bean 可用，框架将抛出 NoUniqueBeanDefinitionException，表明有多个 bean 可用于自动装配。 让我们想象这样一种情况，其中 Spring 存在两个可能的候选对象，以便在给定实例中作为 bean 协作者注入： @Component(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter implements Formatter { public String format() { return \u0026#34;foo\u0026#34;; } } @Component(\u0026#34;barFormatter\u0026#34;) public class BarFormatter implements Formatter { public String format() { return \u0026#34;bar\u0026#34;; } } @Component public class FooService { @Autowired private Formatter formatter; } 如果我们尝试将FooService加载到我们的上下文中，Spring 框架将抛出* NoUniqueBeanDefinitionException*。这是因为Spring 不知道要注入哪个 bean。为了避免这个问题，有几种解决方案；@Qualifier注释就是其中之一。 3. @Qualifier注解 通过使用*@Qualifier*注解，我们可以消除需要注入哪个 bean 的问题。 让我们重新回顾之前的示例，看看我们如何通过包含*@Qualifier*注释来指示我们要使用哪个 bean 来解决问题： public class FooService { @Autowired @Qualifier(\u0026#34;fooFormatter\u0026#34;) private Formatter formatter; } 通过包含*@Qualifier注解，以及我们要使用的具体实现的名称，在这个例子中Foo*，我们可以避免当 Spring 找到多个相同类型的 bean 时产生歧义。 我们需要考虑到要使用的限定符名称是*@Component*注解中声明的名称。 请注意，我们也可以在Formatter实现类上使用*@Qualifier注释，而不是在它们的@Component*注释中指定名称，以获得相同的效果： @Component @Qualifier(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter implements Formatter { //... } @Component @Qualifier(\u0026#34;barFormatter\u0026#34;) public class BarFormatter implements Formatter { //... } 4. @Qualifier与*@Primary* 还有另一个名为@Primary的注解 ，当依赖注入存在歧义时，我们可以使用它来决定注入哪个 bean。 **当存在多个相同类型的 bean 时，*此注释定义了一个首选项。除非另有说明，否则将使用与@Primary*注释关联的 bean 。 让我们看一个例子： @Configuration public class Config { @Bean public Employee johnEmployee() { return new Employee(\u0026#34;Ann\u0026#34;); } @Bean @Primary public Employee tonyEmployee() { return new Employee(\u0026#34;Bob\u0026#34;); } } 在此示例中，两种方法都返回相同的Employee类型。Spring 将注入的 bean 是方法tonyEmployee返回的 bean 。这是因为它包含*@Primary*注释。当我们要指定默认注入某种类型的 bean时，此注解很有用。 如果我们在某个注入点需要另一个 bean，我们需要特别指出它。我们可以通过*@Qualifier注解做到这一点。例如，我们可以通过使用@Qualifier注释来指定我们想要使用johnEmployee*方法返回的 bean。 值得注意的是，*如果@Qualifier和@Primary注释都存在，那么@Qualifier注释将具有优先权。**基本上，@Primary定义了一个默认值，而@Qualifier*非常具体。 让我们看一下使用*@Primary*注解的另一种方式，这次使用初始示例： @Component @Primary public class FooFormatter implements Formatter { //... } @Component public class BarFormatter implements Formatter { //... } **在这种情况下，@Primary注释被放置在实现类之一中，**并将消除场景的歧义。 5. @Qualifier与按名称自动装配 自动装配时在多个 bean 之间做出决定的另一种方法是使用要注入的字段的名称。这是默认设置，以防 Spring 没有其他提示。让我们看一些基于我们最初示例的代码： public class FooService { @Autowired private Formatter fooFormatter; } 在这种情况下，Spring 将确定要注入的 bean 是FooFormatter的，因为字段名称与我们在*@Component*注释中为该 bean使用的值匹配。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_qualifier_annotation/","tags":["Spring Core Basics"],"title":"Spring @Qualifier 注解"},{"categories":["Spring MVC"],"contents":"1. 概述 在本教程中，我们将重点介绍 Spring 中的 Profiles。 配置文件是框架的核心特性——允许我们将 bean 映射到不同的配置文件——例如dev、test和prod。 然后，我们可以在不同的环境中激活不同的配置文件以仅引导我们需要的 bean。 2. 在 Bean 上使用@Profile 让我们从简单的开始，看看我们如何让一个 bean 属于一个特定的配置文件。我们使用@Profile*注释——我们将 bean 映射到那个特定的配置文件*；注释仅采用一个（或多个）配置文件的名称。 考虑一个基本场景：我们有一个 bean，它应该只在开发期间处于活动状态，而不是在生产中部署。 我们使用开发配置文件注释该 bean ，它只会在开发期间出现在容器中。在生产中，开发人员根本不会处于活动状态： @Component @Profile(\u0026#34;dev\u0026#34;) public class DevDatasourceConfig 作为一个快速的旁注，配置文件名称也可以使用 NOT 运算符作为前缀，例如*!dev*，以将它们从配置文件中排除。 在示例中，仅当dev 配置文件未激活时才会激活组件： @Component @Profile(\u0026#34;!dev\u0026#34;) public class DevDatasourceConfig 3. 在 XML 中声明配置文件 配置文件也可以在 XML 中配置。\u0026lt; beans\u0026gt;标签有一个profile属性，它采用逗号分隔的适用配置文件的值： \u0026lt;beans profile=\u0026#34;dev\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;devDatasourceConfig\u0026#34; class=\u0026#34;org.codingman.profiles.DevDatasourceConfig\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 4.设置配置文件 下一步是激活和设置配置文件，以便在容器中注册相应的 bean。 这可以通过多种方式完成，我们将在以下部分中进行探讨。 4.1 通过WebApplicationInitializer接口以编程方式 在 Web 应用程序中，WebApplicationInitializer可用于以编程方式配置ServletContext。 它也是以编程方式设置我们的活动配置文件的非常方便的位置： @Configuration public class MyWebApplicationInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletContext) throws ServletException { servletContext.setInitParameter( \u0026#34;spring.profiles.active\u0026#34;, \u0026#34;dev\u0026#34;); } } 4.2 通过ConfigurableEnvironment以编程方式 我们还可以直接在环境中设置配置文件： @Autowired private ConfigurableEnvironment env; ... env.setActiveProfiles(\u0026#34;someProfile\u0026#34;); 4.3 web.xml中的上下文参数 同样，我们可以使用上下文参数在 Web 应用程序的web.xml文件中定义活动配置文件： \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/app-config.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;spring.profiles.active\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;dev\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; 4.4 JVM 系统参数 配置文件名称也可以通过 JVM 系统参数传入。这些配置文件将在应用程序启动期间激活： -Dspring.profiles.active=dev 4.5 环境变量 在 Unix 环境中，配置文件也可以通过环境变量激活： export spring_profiles_active=dev 4.6 Maven 简介 Spring 配置文件也可以通过 Maven 配置文件激活，通过指定spring.profiles.active 配置属性。 在每个 Maven 配置文件中，我们可以设置一个spring.profiles.active属性： \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;dev\u0026lt;/id\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;spring.profiles.active\u0026gt;dev\u0026lt;/spring.profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;prod\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;spring.profiles.active\u0026gt;prod\u0026lt;/spring.profiles.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; 它的值将用于替换 application.properties 中的@spring.profiles.active@ 占位符：** spring.profiles.active=@spring.profiles.active@ 现在我们需要在pom.xml中启用资源过滤： \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; ... \u0026lt;/build\u0026gt; 并附加一个*-P*参数来切换将应用哪个 Maven 配置文件： mvn clean package -Pprod 此命令将为prod配置文件打包应用程序。它还 在此应用程序运行时应用spring.profiles.active 值prod 。 4.7. 测试中的@ActiveProfile 测试可以很容易地使用*@ActiveProfile*注释指定哪些配置文件处于活动状态以启用特定配置文件： @ActiveProfiles(\u0026#34;dev\u0026#34;) 到目前为止，我们已经研究了多种激活配置文件的方法。现在让我们看看哪个优先级高于另一个，如果我们使用多个优先级会发生什么，从最高到最低优先级：  web.xml中的上下文参数 WebApplicationInitializer JVM 系统参数 环境变量 Maven 简介  5. 默认配置文件 任何未指定配置文件的 bean 都属于默认 配置文件。 Spring 还提供了一种在没有其他配置文件处于活动状态时设置默认配置文件的方法——通过使用spring.profiles.default 属性。 6. 获取活跃的Profile Spring 的活动配置文件驱动*@Profile*注释的行为以启用/禁用 bean。但是，我们也可能希望以编程方式访问活动配置文件列表。 我们有两种方法可以做到这一点，使用Environment或spring.active.profile。 6.1 使用Environment 我们可以通过注入Environment对象来访问活动配置文件： public class ProfileManager { @Autowired private Environment environment; public void getActiveProfiles() { for (String profileName : environment.getActiveProfiles()) { System.out.println(\u0026#34;Currently active profile - \u0026#34; + profileName); } } } 6.2 使用spring.active.profile 或者，我们可以通过注入属性 spring.profiles.active来访问配置文件： @Value(\u0026#34;${spring.profiles.active}\u0026#34;) private String activeProfile; 在这里，我们的activeProfile 变量**将包含当前活动的配置文件的名称，**如果有多个，它将包含用逗号分隔的名称。 但是，我们应该**考虑如果根本没有活动配置文件会发生什么。**使用我们上面的代码，缺少活动配置文件会阻止创建应用程序上下文。由于缺少用于注入变量的占位符，这将导致IllegalArgumentException 。 为了避免这种情况，我们可以定义一个默认值： @Value(\u0026#34;${spring.profiles.active:}\u0026#34;) private String activeProfile; 现在，如果没有激活的配置文件，我们的activeProfile将只包含一个空字符串。 如果我们想像前面的例子一样访问它们的列表，我们可以通过拆分activeProfile变量来实现： public class ProfileManager { @Value(\u0026#34;${spring.profiles.active:}\u0026#34;) private String activeProfiles; public String getActiveProfiles() { for (String profileName : activeProfiles.split(\u0026#34;,\u0026#34;)) { System.out.println(\u0026#34;Currently active profile - \u0026#34; + profileName); } } } 7. 示例：使用配置文件分离数据源配置 既然基础知识已经结束，让我们看一个真实的例子。 考虑一个场景，我们必须为开发和生产环境维护数据源配置。 让我们创建一个需要由两个数据源实现实现的通用接口DatasourceConfig ： public interface DatasourceConfig { public void setup(); } 下面是开发环境的配置： @Component @Profile(\u0026#34;dev\u0026#34;) public class DevDatasourceConfig implements DatasourceConfig { @Override public void setup() { System.out.println(\u0026#34;Setting up datasource for DEV environment. \u0026#34;); } } 以及生产环境的配置： @Component @Profile(\u0026#34;production\u0026#34;) public class ProductionDatasourceConfig implements DatasourceConfig { @Override public void setup() { System.out.println(\u0026#34;Setting up datasource for PRODUCTION environment. \u0026#34;); } } 现在让我们创建一个测试并注入我们的 DatasourceConfig 接口；根据活动配置文件，Spring 将注入DevDatasourceConfig或ProductionDatasourceConfig bean： public class SpringProfilesWithMavenPropertiesIntegrationTest { @Autowired DatasourceConfig datasourceConfig; public void setupDatasource() { datasourceConfig.setup(); } } 当dev 配置文件处于活动状态时，Spring 注入DevDatasourceConfig对象，然后调用*setup()*方法时，输出如下： Setting up datasource for DEV environment. 8. Spring Boot 中的配置文件 Spring Boot 支持到目前为止列出的所有配置文件配置，并具有一些附加功能。 8.1 激活或设置配置文件 第 4 节中介绍的初始化参数spring.profiles.active也可以设置为 Spring Boot 中的属性，以定义当前活动的配置文件。这是 Spring Boot 将自动获取的标准属性： spring.profiles.active=dev 但是，从 Spring Boot 2.4 开始，此属性不能与spring.config.activate.on-profile结合使用，因为这可能会引发ConfigDataException （ 即InvalidConfigDataPropertyException或InactiveConfigDataAccessException ）。 要以编程方式设置配置文件，我们还可以使用SpringApplication类： SpringApplication.setAdditionalProfiles(\u0026#34;dev\u0026#34;); 要在 Spring Boot 中使用 Maven 设置配置文件，我们可以 在pom.xm l中**的 spring-boot-maven-plugin下指定配置文件名称： \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt;dev\u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; ... \u0026lt;/plugins\u0026gt; 并执行 Spring Boot 特定的 Maven 目标： mvn spring-boot:run 8.2 配置文件特定的属性文件 但是，Spring Boot 带来的最重要的配置文件相关功能是**配置文件特定的属性文件。**这些必须以application-{profile}.properties格式命名。 Spring Boot 将自动为所有配置文件加载application.properties文件中的属性，并且仅为指定配置文件加载特定于配置文件的*.properties文件中的属性。* 例如，我们可以使用名为application-dev.properties和application-production.properties的两个文件为dev和production配置文件配置不同的数据源： 在application-production.properties文件中，我们可以设置一个MySql数据源： spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/db spring.datasource.username=root spring.datasource.password=root 然后我们可以在application-dev.properties文件中为dev配置文件配置相同的属性，以使用内存H2数据库： spring.datasource.driver-class-name=org.h2.Driver spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1 spring.datasource.username=sa spring.datasource.password=sa 这样，我们就可以轻松地为不同的环境提供不同的配置。 在 Spring Boot 2.4 之前，可以从特定于配置文件的文档中激活配置文件。但情况已不再如此；对于更高版本， 在这些情况下，框架将再次抛出InvalidConfigDataPropertyException或 InactiveConfigDataAccessException 。 8.3 多文档文件 为了进一步简化为不同环境定义属性，我们甚至可以将所有属性合并到同一个文件中，并使用分隔符来指示配置文件。 从 2.4 版本开始，除了之前支持的YAML之外，Spring Boot 还扩展了对属性文件的多文档文件的支持。所以现在，我们可以在同一个application.properties中指定dev和production属性： my.prop=used-always-in-all-profiles #--- spring.config.activate.on-profile=dev spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/db spring.datasource.username=root spring.datasource.password=root #--- spring.config.activate.on-profile=production spring.datasource.driver-class-name=org.h2.Driver spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1 spring.datasource.username=sa spring.datasource.password=sa 此文件由 Spring Boot 按从上到下的顺序读取。也就是说，如果某个属性，比如my.prop，在上述示例的末尾再次出现，则将考虑最后的值。 8.4 配置文件组 Boot 2.4 中添加的另一个功能是配置文件组。顾名思义，它允许我们将相似的配置文件组合在一起。 让我们考虑一个用例，其中我们有多个用于生产环境的配置文件。比如说，一个用于数据库的proddb和一个用于生产环境中调度程序的prodquartz 。* 要通过我们的application.properties文件一次性启用这些配置文件，我们可以指定： spring.profiles.group.production=proddb,prodquartz 因此，激活production配置文件也将激活proddb和prodquartz。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_profiles/","tags":["Spring MVC Basics"],"title":"Spring 中的 Profiles"},{"categories":["Spring MVC"],"contents":"1. 概述 所有 MVC 框架都提供了一种处理视图的方法。 Spring 通过视图解析器做到这一点，这使您能够在浏览器中呈现模型，而无需将实现绑定到特定的视图技术。 ViewResolver将视图名称映射到实际视图。 Spring 框架附带了很多视图解析器，例如InternalResourceViewResolver、BeanNameViewResolver和其他一些。 这是一个简单的教程，展示了如何设置最常见的视图解析器以及如何在同一配置中使用多个ViewResolver。 2. Spring Web 配置 让我们从 web 配置开始；我们将使用*@EnableWebMvc*、@Configuration和*@ComponentScan*对其进行注释： @EnableWebMvc @Configuration @ComponentScan(\u0026#34;com.codingman.web\u0026#34;) public class WebConfig implements WebMvcConfigurer { // All web configuration will go here } 在这里，我们将在配置中设置我们的视图解析器。 3. 添加一个InternalResourceViewResolver 这个ViewResolver允许我们为视图名称设置前缀或后缀等属性，以生成最终的视图页面 URL： @Bean public ViewResolver internalResourceViewResolver() { InternalResourceViewResolver bean = new InternalResourceViewResolver(); bean.setViewClass(JstlView.class); bean.setPrefix(\u0026#34;/WEB-INF/view/\u0026#34;); bean.setSuffix(\u0026#34;.jsp\u0026#34;); return bean; } 为了示例的 简单性，我们不需要控制器来处理请求。 我们只需要一个简单的jsp页面，放在配置中定义的*/WEB-INF/view*文件夹中： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is the body of the sample view\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 4. 添加一个BeanNameViewResolver 这是 ViewResovler 的实现，它将视图名称解释为当前应用程序上下文中的 bean 名称。每个此类View都可以定义为 XML 或 Java 配置中的 bean。 首先，我们将BeanNameViewResolver添加到之前的配置中： @Bean public BeanNameViewResolver beanNameViewResolver(){ return new BeanNameViewResolver(); } 一旦定义了 ViewResolver，我们需要定义View类型的 beans，以便DispatcherServlet可以执行它来呈现视图： @Bean public View sample() { return new JstlView(\u0026#34;/WEB-INF/view/sample.jsp\u0026#34;); } 这是控制器类中相应的处理程序方法： @GetMapping(\u0026#34;/sample\u0026#34;) public String showForm() { return \u0026#34;sample\u0026#34;; } 从控制器方法中，视图名称作为“ *sample”*返回，这意味着来自此处理程序方法的视图解析为带有/WEB-INF/view/sample.jspURL 的 JstlView 类。 5. 链接ViewResolver并定义订单优先级 Spring MVC 还支持多个视图解析器。 这允许您在某些情况下覆盖特定视图。我们可以通过在配置中添加多个解析器来简单地链接视图解析器。 完成后，我们需要为这些解析器定义一个顺序。order属性用于定义链中调用的顺序。order 属性（最大订单号）越高，视图解析器在链中的位置就越晚。 要定义顺序，我们可以将以下代码行添加到我们的视图解析器的配置中： bean.setOrder(0); 请注意顺序优先级，因为InternalResourceViewResolver应该具有更高的顺序 - 因为它旨在表示非常明确的映射。如果其他解析器具有更高的顺序，则可能永远不会调用InternalResourceViewResolver 。 6. 使用 Spring Boot 使用 Spring Boot 时，WebMvcAutoConfiguration 会在我们的应用程序上下文中自动配置InternalResourceViewResolver 和BeanNameViewResolver bean 。 此外，为模板引擎添加相应的启动器会消除我们必须执行的大部分手动配置。 例如，通过将spring-boot-starter-thymeleaf依赖添加到我们的 pom.xml 中，Thymeleaf 被启用，并且不需要额外的配置： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot-starter-thymeleaf.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 此启动器依赖项在我们的应用程序上下文中使用名称thymeleafViewResolver配置ThymeleafViewResolver* bean。我们可以通过提供一个同名的 bean 来覆盖自动配置的 ThymeleafViewResolver。 Thymeleaf 视图解析器通过用前缀和后缀包围视图名称来工作。prefix 和 suffix 的默认值分别是 \u0026lsquo;classpath:/templates/\u0026rsquo; 和 \u0026lsquo;.html\u0026rsquo;。 spring.thymeleaf.prefixSpring Boot 还提供了一个选项来分别通过设置和spring.thymeleaf.suffix属性来改变前缀和后缀的默认值。 同样，我们有groovy-templates、freemarker和mustache模板引擎的启动器依赖项，我们可以使用它们来使用 Spring Boot 自动配置相应的视图解析器。 DispatcherServlet使用它在应用程序上下文中找到的所有视图解析器，并尝试每一个，直到得到结果，因此如果我们计划添加自己的视图解析器，这些视图解析器的顺序变得非常重要。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_view_resolver_tutorial/","tags":["Spring MVC Basics"],"title":"Spring MVC 中的 ViewResolver 指南"},{"categories":["Spring MVC"],"contents":"1. 概述 这是一个简单的Spring MVC 教程，展示了如何使用基于 Java 的配置以及 XML 配置来设置 Spring MVC 项目。 Spring MVC 项目的 Maven 依赖项在Spring MVC 依赖项文章中有详细描述。 2. 什么是Spring MVC？ 顾名思义，**它是 Spring 框架的一个模块，处理 Model-View-Controller 或 MVC 模式。**它结合了 MVC 模式的所有优点和 Spring 的便利性。 Spring使用其DispatcherServlet以前端控制器模式实现 MVC 。 简而言之，DispatcherServlet充当主控制器，将请求路由到其预期目的地。模型只不过是我们应用程序的数据，视图由各种模板引擎中的任何一个表示。 稍后我们将在示例中查看 JSP。 3. Spring MVC 使用 Java 配置 要通过 Java 配置类启用 Spring MVC 支持，我们只需添加*@EnableWebMvc*注解： @EnableWebMvc @Configuration public class WebConfig { /// ... } 这将为 MVC 项目设置我们所需的基本支持，例如注册控制器和映射、类型转换器、验证支持、消息转换器和异常处理。 如果我们想自定义这个配置，我们需要实现WebMvcConfigurer接口： @EnableWebMvc @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(\u0026#34;/\u0026#34;).setViewName(\u0026#34;index\u0026#34;); } @Bean public ViewResolver viewResolver() { InternalResourceViewResolver bean = new InternalResourceViewResolver(); bean.setViewClass(JstlView.class); bean.setPrefix(\u0026#34;/WEB-INF/view/\u0026#34;); bean.setSuffix(\u0026#34;.jsp\u0026#34;); return bean; } } 在这个例子中，我们注册了一个ViewResolver bean，它将从*/WEB-INF/view目录返回.jsp*视图。 这里非常重要的是，我们可以注册视图控制器， 使用ViewControllerRegistry在 URL 和视图名称之间创建直接映射。这样，两者之间就不需要任何控制器了。 如果我们还想定义和扫描控制器类，我们可以在包含控制器的包中添加*@ComponentScan注释：* @EnableWebMvc @Configuration @ComponentScan(basePackages = { \u0026#34;com.baeldung.web.controller\u0026#34; }) public class WebConfig implements WebMvcConfigurer { // ... } 要引导加载此配置的应用程序，我们还需要一个初始化程序类： public class MainWebAppInitializer implements WebApplicationInitializer { @Override public void onStartup(final ServletContext sc) throws ServletException { AnnotationConfigWebApplicationContext root = new AnnotationConfigWebApplicationContext(); root.scan(\u0026#34;com.codingman\u0026#34;); sc.addListener(new ContextLoaderListener(root)); ServletRegistration.Dynamic appServlet = sc.addServlet(\u0026#34;mvc\u0026#34;, new DispatcherServlet(new GenericWebApplicationContext())); appServlet.setLoadOnStartup(1); appServlet.addMapping(\u0026#34;/\u0026#34;); } } 请注意，对于 Spring 5 之前的版本，我们必须使用WebMvcConfigurerAdapter类而不是接口。 4. Spring MVC 使用 XML 配置 除了上面的 Java 配置，我们还可以使用纯 XML 配置： \u0026lt;context:component-scan base-package=\u0026#34;com.codingman.web.controller\u0026#34; /\u0026gt; \u0026lt;mvc:annotation-driven /\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/view/\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.jsp\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name=\u0026#34;index\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 如果我们想使用纯 XML 配置，我们还需要添加一个web.xml文件来引导应用程序。有关此方法的更多详细信息，请查看我们之前的文章。 5. 控制器和视图 让我们看一个基本控制器的示例： @Controller public class SampleController { @GetMapping(\u0026#34;/sample\u0026#34;) public String showForm() { return \u0026#34;sample\u0026#34;; } } 而对应的JSP资源就是sample.jsp文件： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is the body of the sample view\u0026lt;/h1\u0026gt;\t\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 基于 JSP 的视图文件位于项目的 / WEB-INF文件夹下，因此它们只能由 Spring 基础架构访问，而不能通过直接 URL 访问。 6. 带引导的 Spring MVC Spring Boot 是对 Spring 平台的一个补充，它使得上手和创建独立的生产级应用程序变得非常容易。Boot并不是为了取代 Spring，而是为了让使用它变得更快、更容易。 6.1 Spring Boot 启动器 新框架提供了方便的启动依赖项，这些依赖项描述符可以为特定功能引入所有必要的技术。 它们的优点是我们不再需要为每个依赖项指定一个版本，而是允许启动器为我们管理依赖项。 最快的入门方法是添加spring-boot-starter-parentpom.xml： \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 这将负责依赖管理。 6.2 Spring Boot 入口点 使用Spring Boot构建的每个应用程序只需要定义主入口点。 这通常是一个带有main方法的 Java 类，用*@SpringBootApplication*注解： @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 此注解添加了以下其他注解：  @Configuration将类标记为 bean 定义的来源。 @EnableAutoConfiguration告诉框架根据类路径上的依赖项自动添加 bean。 @ComponentScan扫描与Application类或以下相同包中的其他配置和 bean 。  使用 Spring Boot，我们可以使用 Thymeleaf 或 JSP 设置前端，而无需使用第 3 节中定义的 ViewResolver。通过向我们的 pom.xml 添加spring-boot-starter-thymeleaf依赖项，Thymeleaf 被启用，并且不需要额外的配置。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_tutorial/","tags":["Spring MVC Basics"],"title":"Spring MVC 教程"},{"categories":["Spring MVC"],"contents":"1. 概述 在本文中，我们将了解Spring MVC 提供的核心org.springframework.ui.Model、org.springframework.ui.ModelMap和org.springframework.web.servlet.ModelAndView的使用。 2. Maven依赖 让我们从pom.xml文件中的spring-context依赖项开始： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 spring-context 依赖项。 对于ModelAndView，需要spring-web依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 spring-web 依赖项。 而且，如果我们使用 Thymeleaf 作为我们的视图，我们应该将此依赖项添加到 pom.xml： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf-spring5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.11.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在[这里](https://search.maven.org/search?q=a:thymeleaf-spring5 AND g:org.thymeleaf)找到最新版本的 Thymeleaf 依赖项。 3. Model 让我们从这里最基本的概念开始——Model。 简单地说，Model可以提供用于渲染视图的属性。 要为视图提供可用数据，我们只需将此数据添加到其Model对象中。此外，具有属性的地图可以与Model实例合并： @GetMapping(\u0026#34;/showViewPage\u0026#34;) public String passParametersWithModel(Model model) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;spring\u0026#34;, \u0026#34;mvc\u0026#34;); model.addAttribute(\u0026#34;message\u0026#34;, \u0026#34;Baeldung\u0026#34;); model.mergeAttributes(map); return \u0026#34;viewPage\u0026#34;; } 4. ModelMap 就像上面的Model接口一样，ModelMap也用于传递值来渲染视图。 ModelMap的优势在于它使我们能够传递值的集合并将这些值视为在Map中： @GetMapping(\u0026#34;/printViewPage\u0026#34;) public String passParametersWithModelMap(ModelMap map) { map.addAttribute(\u0026#34;welcomeMessage\u0026#34;, \u0026#34;welcome\u0026#34;); map.addAttribute(\u0026#34;message\u0026#34;, \u0026#34;Baeldung\u0026#34;); return \u0026#34;viewPage\u0026#34;; } 5. ModelAndView 将值传递给视图的最终接口是ModelAndView。 这个接口允许我们一次返回传递 Spring MVC 所需的所有信息： @GetMapping(\u0026#34;/goToViewPage\u0026#34;) public ModelAndView passParametersWithModelAndView() { ModelAndView modelAndView = new ModelAndView(\u0026#34;viewPage\u0026#34;); modelAndView.addObject(\u0026#34;message\u0026#34;, \u0026#34;Baeldung\u0026#34;); return modelAndView; } 6. View 我们放置在这些模型中的所有数据都被一个视图使用——通常是一个模板化的视图来呈现网页。 如果我们有一个 Thymeleaf 模板文件，我们的控制器方法将其作为他们的视图。可以从 thymeleaf HTML 代码中访问通过模型传递的参数： \u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div th:text=\u0026#34;${message}\u0026#34;\u0026gt;Web Application. \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 此处传递的参数通过语法*${message}*使用，称为占位符。Thymeleaf 模板引擎将用通过模型传递的同名属性的实际值替换此占位符。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_model_model_map_model_view/","tags":["Spring MVC Basics"],"title":"Spring MVC 中的 Model、ModelMap 和 ModelAndView"},{"categories":["Spring MVC"],"contents":"1. 概述 在本文中，我们将讨论 Spring 表单和与控制器的数据绑定。此外，我们将看看Spring MVC中的主要注释之一，即*@ModelAttribute*。 当然，Spring MVC 是一个复杂的主题，您需要了解很多东西才能充分发挥它的潜力，所以一定要在这里更深入地研究这个框架。 2. 模型 首先——让我们定义一个简单的实体，我们将显示并绑定到表单： public class Employee { private String name; private long id; private String contactNumber; // standard getters and setters } 这将是我们的表单支持对象。 3. View 接下来——让我们定义实际的表单，当然还有包含它的 HTML 文件。我们将使用一个创建/注册新员工的页面： \u0026lt;%@ taglib prefix=\u0026#34;form\u0026#34; uri=\u0026#34;http://www.springframework.org/tags/form\u0026#34;%\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Welcome, Enter The Employee Details\u0026lt;/h3\u0026gt; \u0026lt;form:form method=\u0026#34;POST\u0026#34; action=\u0026#34;/spring-mvc-xml/addEmployee\u0026#34; modelAttribute=\u0026#34;employee\u0026#34;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:label path=\u0026#34;name\u0026#34;\u0026gt;Name\u0026lt;/form:label\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:input path=\u0026#34;name\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:label path=\u0026#34;id\u0026#34;\u0026gt;Id\u0026lt;/form:label\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:input path=\u0026#34;id\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:label path=\u0026#34;contactNumber\u0026#34;\u0026gt; Contact Number\u0026lt;/form:label\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;form:input path=\u0026#34;contactNumber\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form:form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 首先——请注意，我们在 JSP 页面中包含了一个标签库——form标签库——以帮助定义我们的表单。 Next – *form:form*标签在这里扮演着重要的角色；它与常规的 HTLM 标记非常相似，但modelAttribute属性是指定支持此表单的模型对象名称的键： \u0026lt;form:form method=\u0026#34;POST\u0026#34; action=\u0026#34;/SpringMVCFormExample/addEmployee\u0026#34; modelAttribute=\u0026#34;employee\u0026#34;\u0026gt; 这将对应于稍后在控制器中的*@ModelAttribute* 。 接下来 – 每个输入字段都使用 Spring Form taglib 中的另一个有用标签 – form: prefix。这些字段中的每一个都指定了一个路径属性——这必须对应于模型属性的 getter/setter（在本例中为 Employee 类）。加载页面时，输入字段由 Spring 填充，它调用绑定到输入字段的每个字段的 getter。提交表单时，会调用 setter 将表单的值保存到对象中。 最后——当表单提交时，控制器中的 POST 处理程序被调用，表单自动绑定到我们传入的员工参数。 4. Controller 现在，让我们看看将处理后端的Controller： @Controller public class EmployeeController { @RequestMapping(value = \u0026#34;/employee\u0026#34;, method = RequestMethod.GET) public ModelAndView showForm() { return new ModelAndView(\u0026#34;employeeHome\u0026#34;, \u0026#34;employee\u0026#34;, new Employee()); } @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit(@Valid @ModelAttribute(\u0026#34;employee\u0026#34;)Employee employee, BindingResult result, ModelMap model) { if (result.hasErrors()) { return \u0026#34;error\u0026#34;; } model.addAttribute(\u0026#34;name\u0026#34;, employee.getName()); model.addAttribute(\u0026#34;contactNumber\u0026#34;, employee.getContactNumber()); model.addAttribute(\u0026#34;id\u0026#34;, employee.getId()); return \u0026#34;employeeView\u0026#34;; } } 控制器定义了两个简单的操作——GET 用于在表单中显示数据，POST 用于创建操作，通过表单的提交。 还要注意，如果没有将名为“employee”的对象添加到模型中，当我们尝试访问 JSP 时，Spring 会报错，因为 JSP 将被设置为将表单绑定到“employee”模型属性： java.lang.IllegalStateException: Neither BindingResult nor plain target object for bean name \u0026#39;employee\u0026#39; available as request attribute at o.s.w.s.s.BindStatus.\u0026lt;init\u0026gt;(BindStatus.java:141) 要访问我们的表单支持对象，我们需要通过*@ModelAttribute*注释注入它。 方法参数上的一个\u0026lt;em\u0026gt;@ModelAttribute \u0026lt;/em\u0026gt;表示将从模型中检索该参数。如果模型中不存在，则参数将首先实例化，然后添加到模型中。 5. 处理绑定错误 默认情况下，Spring MVC 在请求绑定过程中发生错误时会抛出异常。这通常不是我们想要的，相反，我们应该将这些错误呈现给用户。我们将通过向控制器方法添加一个作为参数来使用BindingResult ： public String submit( @Valid @ModelAttribute(\u0026#34;employee\u0026#34;) Employee employee, BindingResult result, ModelMap model) BindingResult参数需要放置在我们的表单支持对象之后——这是方法参数的顺序很重要的罕见情况之一。否则，我们将遇到以下异常： java.lang.IllegalStateException: Errors/BindingResult argument declared without preceding model attribute. Check your handler method signature! 现在——不再抛出异常；相反，错误将在传递给submit方法的BindingResult上注册。此时，我们可以通过多种方式处理这些错误——例如，可以取消操作： @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit(@Valid @ModelAttribute(\u0026#34;employee\u0026#34;)Employee employee, BindingResult result, ModelMap model) { if (result.hasErrors()) { return \u0026#34;error\u0026#34;; } //Do Something  return \u0026#34;employeeView\u0026#34;; } 请注意，如果结果包含错误，我们如何将另一个视图返回给用户，以便正确显示这些错误。让我们看一下那个视图*——error.jsp*： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Please enter the correct details\u0026lt;/h3\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026#34;employee\u0026#34;\u0026gt;Retry\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 6. 显示员工 最后，除了创建一个新员工之外，我们还可以简单地显示一个——这是它的快速查看代码： \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;Submitted Employee Information\u0026lt;/h2\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Name :\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${name}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;ID :\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${id}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Contact Number :\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${contactNumber}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; JSP 页面只是使用 EL 表达式来显示模型中 Employee 对象的属性值。 7. 测试应用程序 可以部署简单的应用程序（例如在 Tomcat 服务器中）并在本地访问： http://localhost:8080/spring-mvc-xml/employee 这是包含主表单的视图——在提交操作之前： Spring MVC 表单示例——提交 提交后显示数据： Spring MVC 表单示例 – 查看 就是这样——一个使用 Spring MVC 的简单表单的工作示例，带有验证。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_form_tutorial/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring MVC 中的表单入门"},{"categories":["Spring MVC"],"contents":"1. 概述 在本教程中，我们将探索org.springframework.web.bind.annotation包中的 Spring Web 注释。 2. @RequestMapping 简单地说，@RequestMapping 标记了*@Controller*类内部的请求处理方法；可以使用以下方式进行配置：  路径或其别名、名称和*值：*方法映射到哪个 URL *方法：*兼容的 HTTP 方法 *params：*根据 HTTP 参数的存在、不存在或值过滤请求 *标头：*根据 HTTP 标头的存在、不存在或值过滤请求 *消费：*该方法可以在 HTTP 请求正文中消费哪些媒体类型 *产生：*该方法可以在 HTTP 响应正文中产生哪些媒体类型  这是一个简单的示例： @Controller class VehicleController { @RequestMapping(value = \u0026#34;/vehicles/home\u0026#34;, method = RequestMethod.GET) String home() { return \u0026#34;home\u0026#34;; } } 如果我们在类级别应用此注解，我们可以为@Controller类中的所有处理程序方法提供默认设置。唯一的例外是Spring不会用方法级别设置覆盖但附加两个路径部分的 URL。 例如，下面的配置和上面的效果是一样的： @Controller @RequestMapping(value = \u0026#34;/vehicles\u0026#34;, method = RequestMethod.GET) class VehicleController { @RequestMapping(\u0026#34;/home\u0026#34;) String home() { return \u0026#34;home\u0026#34;; } } 此外，@GetMapping、@PostMapping、@PutMapping、 @DeleteMapping和*@PatchMapping是@RequestMapping*的不同变体， HTTP 方法已分别设置为 GET、POST、PUT、DELETE 和 PATCH。 这些从 Spring 4.3 版本开始可用。 3. @RequestBody 让我们继续看@RequestBody——它将HTTP 请求的主体映射到一个对象： @PostMapping(\u0026#34;/save\u0026#34;) void saveVehicle(@RequestBody Vehicle vehicle) { // ... } 反序列化是自动的，取决于请求的内容类型。 4. @PathVariable 接下来，让我们谈谈*@PathVariable*。 此注释指示方法参数绑定到 URI 模板变量。我们可以使用*@RequestMapping注释指定 URI 模板，并使用@PathVariable*将方法参数绑定到模板部分之一。 我们可以使用名称或其别名、Value参数来实现这一点： @RequestMapping(\u0026#34;/{id}\u0026#34;) Vehicle getVehicle(@PathVariable(\u0026#34;id\u0026#34;) long id) { // ... } 如果模板中部分的名称与方法参数的名称匹配，我们不必在注解中指定： @RequestMapping(\u0026#34;/{id}\u0026#34;) Vehicle getVehicle(@PathVariable long id) { // ... } 此外，我们可以通过将required的参数设置为false来将路径变量标记为可选： @RequestMapping(\u0026#34;/{id}\u0026#34;) Vehicle getVehicle(@PathVariable(required = false) long id) { // ... } 5. @RequestParam 我们使用*@RequestParam*来访问 HTTP 请求参数： @RequestMapping Vehicle getVehicleByParam(@RequestParam(\u0026#34;id\u0026#34;) long id) { // ... } 它具有与*@PathVariable*注释相同的配置选项。 除了这些设置之外，当 Spring 在请求中发现没有值或空值时，我们可以使用*@RequestParam指定注入值。为此，我们必须设置defaultValue*参数。 提供默认值隐式地将required设置为false： @RequestMapping(\u0026#34;/buy\u0026#34;) Car buyCar(@RequestParam(defaultValue = \u0026#34;5\u0026#34;) int seatCount) { // ... } 除了参数，我们还可以访问其他 HTTP 请求部分：cookies 和 headers。我们可以分别使用注解*@CookieValue和@RequestHeader*来访问它们。 我们可以像@RequestParam一样配置它们。 6. 响应处理注解 在接下来的部分中，我们将看到在 Spring MVC 中操作 HTTP 响应的最常见的注解。 6.1 @ResponseBody 如果我们使用@ResponseBody标记请求处理程序方法，Spring 将方法的结果视为响应本身： @ResponseBody @RequestMapping(\u0026#34;/hello\u0026#34;) String hello() { return \u0026#34;Hello World!\u0026#34;; } 如果我们用这个注解来注解一个*@Controller*类，所有的请求处理方法都会使用它。 6.2 @ExceptionHandler 有了这个注解，我们可以声明一个自定义的错误处理方法。当请求处理程序方法抛出任何指定的异常时，Spring 调用此方法。 捕获的异常可以作为参数传递给方法： @ExceptionHandler(IllegalArgumentException.class) void onIllegalArgumentException(IllegalArgumentException exception) { // ... } 6.3 @ResponseStatus 如果我们使用此注释注释请求处理程序方法，我们可以指定**响应的所需 HTTP 状态。**我们可以使用code参数或它的别名value参数来声明状态代码。 此外，我们可以使用reason参数提供原因。 我们也可以将它与*@ExceptionHandler*一起使用： @ExceptionHandler(IllegalArgumentException.class) @ResponseStatus(HttpStatus.BAD_REQUEST) void onIllegalArgumentException(IllegalArgumentException exception) { // ... } 有关 HTTP 响应状态的更多信息，请访问本文。 7. 其他网页注解 一些注释不直接管理 HTTP 请求或响应。在接下来的部分中，我们将介绍最常见的部分。 7.1 @Controller 我们可以使用@Controller定义一个 Spring MVC 控制器。有关更多信息，请访问我们关于 Spring Bean Annotations 的文章。 7.2. @RestController @RestController结合了*@Controller和@ResponseBody*。 因此，以下声明是等价的： @Controller @ResponseBody class VehicleRestController { // ... } @RestController class VehicleRestController { // ... } 7.3 @ModelAttribute 使用这个注解，我们可以通过提供模型键来访问已经存在于MVC @Controller模型中的元素： @PostMapping(\u0026#34;/assemble\u0026#34;) void assembleVehicle(@ModelAttribute(\u0026#34;vehicle\u0026#34;) Vehicle vehicleInModel) { // ... } 与*@PathVariable和@RequestParam*一样，如果参数具有相同的名称，我们不必指定模型键： @PostMapping(\u0026#34;/assemble\u0026#34;) void assembleVehicle(@ModelAttribute Vehicle vehicle) { // ... } 此外，@ModelAttribute还有一个用途：如果我们用它来注解一个方法，Spring 会自动将该方法的返回值添加到模型中： @ModelAttribute(\u0026#34;vehicle\u0026#34;) Vehicle getVehicle() { // ... } 和以前一样，我们不必指定模型键，Spring 默认使用方法的名称： @ModelAttribute Vehicle vehicle() { // ... } 在 Spring 调用请求处理程序方法之前，它会调用类中所有*@ModelAttribute*注释的方法。 有关*@ModelAttribute*的更多信息，请参阅本文。 7.4 @CrossOrigin @CrossOrigin 为带注释的请求处理程序方法启用跨域通信： @CrossOrigin @RequestMapping(\u0026#34;/hello\u0026#34;) String hello() { return \u0026#34;Hello World!\u0026#34;; } 如果我们用它标记一个类，它适用于其中的所有请求处理程序方法。 我们可以使用此注释的参数微调 CORS 行为。 有关更多详细信息，请访问本文。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_annotations/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring Web 注释"},{"categories":["Maven","Spring"],"contents":"1. 概述 最重要的Spring MVC注释之一是@ModelAttribute注释。 @ModelAttribute是一个注解，它将方法参数或方法返回值绑定到命名模型属性，然后将其公开给 Web 视图。 在本教程中，我们将通过一个通用概念（公司员工提交的表单）来演示此注释的可用性和功能。 2. 深入了解@ModelAttribute 正如介绍性段落所揭示的，我们可以将*@ModelAttribute*用作方法参数或在方法级别使用。 2.1 在方法级别 当我们在方法级别使用注解时，它表明方法的目的是添加一个或多个模型属性。此类方法支持与@RequestMapping方法相同的参数类型，但它们不能直接映射到请求。 让我们看一个简单的例子来了解它是如何工作的： @ModelAttribute public void addAttributes(Model model) { model.addAttribute(\u0026#34;msg\u0026#34;, \u0026#34;Welcome to the Netherlands!\u0026#34;); } 在上面的例子中，我们看到了一个方法，它为控制器类中定义的所有Model添加了一个名为msg的属性。 当然，我们将在本文后面看到这一点。 一般来说，Spring MVC 在调用任何请求处理程序方法之前总是会先调用该方法。基本上，**@ModelAttribute方法在调用带有@RequestMapping注释的控制器方法之前被调用。**这是因为必须在控制器方法内部开始任何处理之前创建模型对象。 将相应的类注释为@ControllerAdvice也很重要。因此，我们可以在Model中添加将被标识为全局的值。这实际上意味着对于每个请求，响应中的每个方法都存在一个默认值。 2.2 作为方法论据 当我们使用注解作为方法参数时，它表示从模型中检索参数。当注释不存在时，它应该首先被实例化，然后添加到模型中。一旦出现在模型中，参数字段应该从具有匹配名称的所有请求参数中填充。 在以下代码片段中，我们将使用提交到addEmployee端点的表单中的数据填充员工模型属性。Spring MVC 在调用提交方法之前在后台执行此操作： @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit(@ModelAttribute(\u0026#34;employee\u0026#34;) Employee employee) { // Code that uses the employee object  return \u0026#34;employeeView\u0026#34;; } 在本文后面，我们将看到一个完整的示例，说明如何使用Employee对象来填充employeeView模板。 它将表单数据与 bean 绑定。使用@RequestMapping注释的控制器可以具有使用*@ModelAttribute*注释的自定义类参数。 在 Spring MVC 中，我们将其称为数据绑定，这是一种通用机制，可以让我们不必单独解析每个表单字段。 3. 表格示例 在本节中，我们将查看概述部分中概述的示例，这是一个非常基本的表单，提示用户（特别是公司员工）输入一些个人信息（特别是name和ID）。*在提交完成并且没有任何错误之后，用户希望看到之前提交的数据显示在另一个屏幕上。 3.1 View 让我们首先创建一个带有 id 和 name 字段的简单表单： \u0026lt;form:form method=\u0026#34;POST\u0026#34; action=\u0026#34;/spring-mvc-basics/addEmployee\u0026#34; modelAttribute=\u0026#34;employee\u0026#34;\u0026gt; \u0026lt;form:label path=\u0026#34;name\u0026#34;\u0026gt;Name\u0026lt;/form:label\u0026gt; \u0026lt;form:input path=\u0026#34;name\u0026#34; /\u0026gt; \u0026lt;form:label path=\u0026#34;id\u0026#34;\u0026gt;Id\u0026lt;/form:label\u0026gt; \u0026lt;form:input path=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34; /\u0026gt; \u0026lt;/form:form\u0026gt; 3.2 控制器 这是控制器类，我们将在其中实现上述视图的逻辑： @Controller @ControllerAdvice public class EmployeeController { private Map\u0026lt;Long, Employee\u0026gt; employeeMap = new HashMap\u0026lt;\u0026gt;(); @RequestMapping(value = \u0026#34;/addEmployee\u0026#34;, method = RequestMethod.POST) public String submit( @ModelAttribute(\u0026#34;employee\u0026#34;) Employee employee, BindingResult result, ModelMap model) { if (result.hasErrors()) { return \u0026#34;error\u0026#34;; } model.addAttribute(\u0026#34;name\u0026#34;, employee.getName()); model.addAttribute(\u0026#34;id\u0026#34;, employee.getId()); employeeMap.put(employee.getId(), employee); return \u0026#34;employeeView\u0026#34;; } @ModelAttribute public void addAttributes(Model model) { model.addAttribute(\u0026#34;msg\u0026#34;, \u0026#34;Welcome to the Netherlands!\u0026#34;); } } 在submit()方法中，我们有一个绑定到View的Employee对象。我们可以像这样简单地将表单字段映射到对象模型。在该方法中，我们从表单中获取值并将它们设置为ModelMap。 最后，我们返回employeeView，这意味着我们将各自的 JSP 文件称为View代表。 此外，还有一个addAttributes()方法。其目的是在模型中添加将被全局识别的值。也就是说，对每个控制器方法的每个请求都将返回一个默认值作为响应。我们还必须将特定类注释为*@ControllerAdvice。* 3.3 模型 如前所述，模型对象非常简单，包含“前端”属性所需的所有内容。现在让我们看一个例子： @XmlRootElement public class Employee { private long id; private String name; public Employee(long id, String name) { this.id = id; this.name = name; } // standard getters and setters removed } 3.4 ControllerAdvice @ControllerAdvice协助控制器，特别是适用于所有*@RequestMapping方法的@ModelAttribute方法。当然，我们的addAttributes()方法将是第一个运行的，在其余的@RequestMapping*方法之前。 记住这一点，在submit()和addAttributes()都运行之后，我们可以在从Controller类返回的View中引用它们，方法是在美元化的花括号中提及它们的给定名称，例如*${name}*。 3.5 结果视图 现在让我们打印我们从表单中收到的内容： \u0026lt;h3\u0026gt;${msg}\u0026lt;/h3\u0026gt; Name : ${name} ID : ${id} \u0026quot; ","permalink":"http://itcodingman.github.io/spring_mvc_and_the_modelattribute_annotation/","tags":[],"title":"Spring MVC 和 @ModelAttribute 注解"},{"categories":["Spring Persistence"],"contents":"1. 概述 本文将展示在项目中使用 Spring 工件时要使用的 Maven 存储库 - 请参阅Spring wiki上存储库的完整列表。以前的 SpringSource 工件管理基础设施是maven.springframework.org - 现在已被弃用，取而代之的是更强大的repo.spring.io。 2. Maven 发布 所有 GA/Release 工件都发布到 Maven Central，因此如果只需要发布，则无需在pom中添加任何新的 repo 。但是，如果由于某种原因 Central 不可用，也有一个可用于 Spring 版本的自定义、可浏览的 Maven 存储库： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.spring.release\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring GA Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/release\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; Spring 工件版本控制规则在项目 wiki 上进行了说明。 里程碑和快照不会直接发布到 Maven Central，因此它们有自己特定的存储库。 3. Maven 里程碑和候选版本 对于里程碑和 RC，需要将以下 repo 添加到pom中： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.spring.milestone\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Milestone Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/milestone\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 已经定义了一个这个存储库，项目可以开始使用 Spring里程碑依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.0.RC3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. Maven 快照 与里程碑类似，Spring 快照托管在自定义存储库中： \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;repository.spring.snapshot\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Snapshot Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repo.spring.io/snapshot\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 在 pom 中启用存储库后，项目可以开始使用 Spring 快照： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.5.BUILD-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 乃至： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.0.BUILD-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 现在还可以浏览快照存储库。 5. Spring OSGI 的 Maven 存储库 OSGI 兼容的 Spring 工件在 SpringSource Enterprise Bundle Repository中维护- 简而言之，EBR。这些存储库包含整个 Spring Framework 的有效 OSGI 包和库，以及这些库的完整依赖项集。对于捆绑： \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.bundles.release\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - SpringSource Bundle Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/bundles/release\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.bundles.external\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - External Bundle Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/bundles/external\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; 对于 OSGI 兼容库： \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.libraries.release\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - SpringSource Library Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/libraries/release\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;com.springsource.repository.libraries.external\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;SpringSource Enterprise Bundle Repository - External Library Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.springsource.com/maven/libraries/external\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; 注意：SpringSource EBR 现在是只读的，不再发布 Spring Framework 3.2.x 版本。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_maven_repository/","tags":["JDBC","SQL"],"title":"Spring Maven 存储库"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将介绍 Spring JDBC 模块的实际用例。 Spring JDBC 中的所有类都分为四个独立的包：  core — JDBC 的核心功能。该包下的一些重要类包括JdbcTemplate、 SimpleJdbcInsert、 SimpleJdbcCall和NamedParameterJdbcTemplate。 datasource — 用于访问数据源的实用程序类。它还具有用于在 Jakarta EE 容器之外测试 JDBC 代码的各种数据源实现。 object — 以面向对象的方式访问数据库。它允许运行查询并将结果作为业务对象返回。它还映射业务对象的列和属性之间的查询结果。 support — 支持核心和对象包下的类，例如，提供SQLException转换功能  2. 配置 让我们从数据源的一些简单配置开始。 我们将使用 MySQL 数据库： @Configuration @ComponentScan(\u0026#34;com.codingman.jdbc\u0026#34;) public class SpringJdbcConfig { @Bean public DataSource mysqlDataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:mysql://localhost:3306/springjdbc\u0026#34;); dataSource.setUsername(\u0026#34;user\u0026#34;); dataSource.setPassword(\u0026#34;password\u0026#34;); return dataSource; } } 或者，我们也可以充分利用嵌入式数据库进行开发或测试。 这是一个创建 H2 嵌入式数据库实例并使用简单 SQL 脚本预填充它的快速配置： @Bean public DataSource dataSource() { return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.H2) .addScript(\u0026#34;classpath:jdbc/schema.sql\u0026#34;) .addScript(\u0026#34;classpath:jdbc/test-data.sql\u0026#34;).build(); } 最后，同样可以使用 XML 配置数据源来完成： \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.apache.commons.dbcp.BasicDataSource\u0026#34; destroy-method=\u0026#34;close\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;com.mysql.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/springjdbc\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;user\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;password\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 3. JdbcTemplate和运行查询 3.1 基本查询 JDBC 模板是主要的 API，我们将通过它访问我们感兴趣的大部分功能：  创建和关闭连接 运行语句和存储过程调用 遍历ResultSet并返回结果  首先，我们从一个简单的例子开始，看看JdbcTemplate能做什么： int result = jdbcTemplate.queryForObject( \u0026#34;SELECT COUNT(*) FROM EMPLOYEE\u0026#34;, Integer.class); 这是一个简单的插入： public int addEmplyee(int id) { return jdbcTemplate.update( \u0026#34;INSERT INTO EMPLOYEE VALUES (?, ?, ?, ?)\u0026#34;, id, \u0026#34;Ann\u0026#34;, \u0026#34;Green\u0026#34;, \u0026#34;USA\u0026#34;); } *注意使用?*提供参数的标准语法 特点。 接下来，让我们看一下这种语法的替代方法。 3.2 带有命名参数的查询 为了获得对命名参数的支持，我们将使用框架提供的另一个 JDBC 模板 — NamedParameterJdbcTemplate。 此外，它包装了JbdcTemplate并使用 ? 提供了传统语法的替代方案。指定参数。 在幕后，它将命名参数替换为 JDBC ? 占位符并委托给包装的JDCTemplate以运行查询： SqlParameterSource namedParameters = new MapSqlParameterSource().addValue(\u0026#34;id\u0026#34;, 1); return namedParameterJdbcTemplate.queryForObject( \u0026#34;SELECT FIRST_NAME FROM EMPLOYEE WHERE ID = :id\u0026#34;, namedParameters, String.class); 请注意我们如何使用MapSqlParameterSource为命名参数提供值。 让我们看看使用 bean 的属性来确定命名参数： Employee employee = new Employee(); employee.setFirstName(\u0026#34;James\u0026#34;); String SELECT_BY_ID = \u0026#34;SELECT COUNT(*) FROM EMPLOYEE WHERE FIRST_NAME = :firstName\u0026#34;; SqlParameterSource namedParameters = new BeanPropertySqlParameterSource(employee); return namedParameterJdbcTemplate.queryForObject( SELECT_BY_ID, namedParameters, Integer.class); 请注意我们现在如何使用BeanPropertySqlParameterSource实现，而不是像以前那样手动指定命名参数。 3.3 将查询结果映射到 Java 对象 另一个非常有用的特性是能够通过实现RowMapper接口将查询结果映射到 Java 对象。 例如，对于查询返回的每一行，Spring 使用行映射器来填充 java bean： public class EmployeeRowMapper implements RowMapper\u0026lt;Employee\u0026gt; { @Override public Employee mapRow(ResultSet rs, int rowNum) throws SQLException { Employee employee = new Employee(); employee.setId(rs.getInt(\u0026#34;ID\u0026#34;)); employee.setFirstName(rs.getString(\u0026#34;FIRST_NAME\u0026#34;)); employee.setLastName(rs.getString(\u0026#34;LAST_NAME\u0026#34;)); employee.setAddress(rs.getString(\u0026#34;ADDRESS\u0026#34;)); return employee; } } 随后，我们现在可以将行映射器传递给查询 API 并获得完全填充的 Java 对象： String query = \u0026#34;SELECT * FROM EMPLOYEE WHERE ID = ?\u0026#34;; Employee employee = jdbcTemplate.queryForObject( query, new Object[] { id }, new EmployeeRowMapper()); 4. 异常翻译 Spring 自带开箱即用的数据异常层次结构——以DataAccessException作为根异常——并将所有底层原始异常转换为它。 因此，我们通过不处理低级持久性异常来保持理智。我们还受益于 Spring 将低级异常包装在DataAccessException或其子类之一中。 这也使异常处理机制独立于我们正在使用的底层数据库。 除了默认的SQLErrorCodeSQLExceptionTranslator之外，我们还可以提供自己的SQLExceptionTranslator实现。 下面是一个自定义实现的快速示例——在存在重复键违规时自定义错误消息，这在使用 H2 时会导致错误代码 23505 ： public class CustomSQLErrorCodeTranslator extends SQLErrorCodeSQLExceptionTranslator { @Override protected DataAccessException customTranslate(String task, String sql, SQLException sqlException) { if (sqlException.getErrorCode() == 23505) { return new DuplicateKeyException( \u0026#34;Custom Exception translator - Integrity constraint violation.\u0026#34;, sqlException); } return null; } } 要使用这个自定义异常转换器，我们需要通过调用setExceptionTranslator()方法将其传递给JdbcTemplate ： CustomSQLErrorCodeTranslator customSQLErrorCodeTranslator = new CustomSQLErrorCodeTranslator(); jdbcTemplate.setExceptionTranslator(customSQLErrorCodeTranslator); 5. 使用 SimpleJdbc 类的 JDBC 操作 SimpleJdbc类提供了一种简单的方法来配置和运行 SQL 语句。这些类使用数据库元数据来构建基本查询。因此，SimpleJdbcInsert和SimpleJdbcCall类提供了一种更简单的方法来运行插入和存储过程调用。 5.1 SimpleJdbcInsert 让我们看一下以最少的配置运行简单的插入语句。 INSERT 语句是根据SimpleJdbcInsert的配置生成的。我们只需要提供表名、列名和值。 首先，让我们创建一个 SimpleJdbcInsert： SimpleJdbcInsert simpleJdbcInsert = new SimpleJdbcInsert(dataSource).withTableName(\u0026#34;EMPLOYEE\u0026#34;); 接下来，让我们提供列名称和值，然后运行操作： public int addEmplyee(Employee emp) { Map\u0026lt;String, Object\u0026gt; parameters = new HashMap\u0026lt;String, Object\u0026gt;(); parameters.put(\u0026#34;ID\u0026#34;, emp.getId()); parameters.put(\u0026#34;FIRST_NAME\u0026#34;, emp.getFirstName()); parameters.put(\u0026#34;LAST_NAME\u0026#34;, emp.getLastName()); parameters.put(\u0026#34;ADDRESS\u0026#34;, emp.getAddress()); return simpleJdbcInsert.execute(parameters); } 此外，我们可以使用executeAndReturnKey() API 来允许数据库生成主键。我们还需要配置实际的自动生成列： SimpleJdbcInsert simpleJdbcInsert = new SimpleJdbcInsert(dataSource) .withTableName(\u0026#34;EMPLOYEE\u0026#34;) .usingGeneratedKeyColumns(\u0026#34;ID\u0026#34;); Number id = simpleJdbcInsert.executeAndReturnKey(parameters); System.out.println(\u0026#34;Generated id - \u0026#34; + id.longValue()); 最后，我们还可以使用BeanPropertySqlParameterSource和MapSqlParameterSource传入这些数据。 5.2 使用SimpleJdbcCall 的存储过程 让我们也看看正在运行的存储过程。 我们将使用SimpleJdbcCall抽象： SimpleJdbcCall simpleJdbcCall = new SimpleJdbcCall(dataSource) .withProcedureName(\u0026#34;READ_EMPLOYEE\u0026#34;); public Employee getEmployeeUsingSimpleJdbcCall(int id) { SqlParameterSource in = new MapSqlParameterSource().addValue(\u0026#34;in_id\u0026#34;, id); Map\u0026lt;String, Object\u0026gt; out = simpleJdbcCall.execute(in); Employee emp = new Employee(); emp.setFirstName((String) out.get(\u0026#34;FIRST_NAME\u0026#34;)); emp.setLastName((String) out.get(\u0026#34;LAST_NAME\u0026#34;)); return emp; } 6. 批量操作 另一个简单的用例是将多个操作批处理在一起。 6.1 使用JdbcTemplate 的基本批处理操作 使用JdbcTemplate，可以通过batchUpdate() API运行批处理操作。 这里有趣的部分是简洁但非常有用的BatchPreparedStatementSetter实现： public int[] batchUpdateUsingJdbcTemplate(List\u0026lt;Employee\u0026gt; employees) { return jdbcTemplate.batchUpdate(\u0026#34;INSERT INTO EMPLOYEE VALUES (?, ?, ?, ?)\u0026#34;, new BatchPreparedStatementSetter() { @Override public void setValues(PreparedStatement ps, int i) throws SQLException { ps.setInt(1, employees.get(i).getId()); ps.setString(2, employees.get(i).getFirstName()); ps.setString(3, employees.get(i).getLastName()); ps.setString(4, employees.get(i).getAddress(); } @Override public int getBatchSize() { return 50; } }); } 6.2 使用NamedParameterJdbcTemplate 进行批量操作 我们还可以选择使用NamedParameterJdbcTemplate – batchUpdate() API 进行批处理操作。 此 API 比上一个 API 更简单。因此，不需要实现任何额外的接口来设置参数，因为它有一个内部准备好的语句设置器来设置参数值。 相反，参数值可以作为SqlParameterSource数组传递给*batchUpdate()*方法。 SqlParameterSource[] batch = SqlParameterSourceUtils.createBatch(employees.toArray()); int[] updateCounts = namedParameterJdbcTemplate.batchUpdate( \u0026#34;INSERT INTO EMPLOYEE VALUES (:id, :firstName, :lastName, :address)\u0026#34;, batch); return updateCounts; 7. Spring JDBC 与 Spring Boot Spring Boot 提供了一个启动器spring-boot-starter-jdbc用于将 JDBC 与关系数据库一起使用。 与每个 Spring Boot 启动器一样，这个启动器可以帮助我们快速启动和运行我们的应用程序。 7.1 Maven 依赖 我们需要 spring-boot-starter-jdbc依赖项作为主要依赖项。我们还需要我们将使用的数据库的依赖项。在我们的例子中，这是MySQL： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 7.2 配置 Spring Boot 会自动为我们配置数据源。我们只需要在properties文件中提供属性： spring.datasource.url=jdbc:mysql://localhost:3306/springjdbc spring.datasource.username=user spring.datasource.password=password 就是这样。只需执行这些配置，我们的应用程序就可以启动并运行。我们现在可以将它用于其他数据库操作。 我们在上一节中看到的标准 Spring 应用程序的显式配置现在包含在 Spring Boot 自动配置中。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_jdbc_jdbctemplate/","tags":["Spring Core Basics","Spring DI"],"title":"Spring JDBC"},{"categories":["Spring Data"],"contents":"1. 简介 在本教程中，我们将介绍*BeanFactory.getBean()*方法的不同变体。 简单地说，正如该方法的名称所暗示的，它负责从 Spring 容器中检索一个 bean 实例。 2. Spring Beans 设置 首先，让我们定义一些用于测试的 Spring bean。我们可以通过多种方式为 Spring 容器提供 bean 定义，但在我们的示例中，我们将使用基于注解的 Java 配置： @Configuration class AnnotationConfig { @Bean(name = {\u0026#34;tiger\u0026#34;, \u0026#34;kitty\u0026#34;}) @Scope(value = \u0026#34;prototype\u0026#34;) Tiger getTiger(String name) { return new Tiger(name); } @Bean(name = \u0026#34;lion\u0026#34;) Lion getLion() { return new Lion(\u0026#34;demo lion name\u0026#34;); } interface Animal {} } 我们已经创建了两个 bean。Lion具有默认的单例范围。Tiger被明确设置为原型范围。此外，请注意，我们为每个 bean 定义了名称，我们将在进一步的请求中使用这些名称。 3. getBean() API BeanFactory提供了五种不同的*getBean()*方法签名，我们将在下面的小节中进行研究。 3.1 按名称检索 Bean 让我们看看如何使用名称检索Lion bean 实例： Object lion = context.getBean(\u0026#34;lion\u0026#34;); assertEquals(Lion.class, lion.getClass()); 在这个变体中，我们提供了一个名称，作为回报，如果具有给定名称的 bean 存在于应用程序上下文中，我们将获得一个*Object 类的实例。*否则，如果 bean 查找失败，此实现和所有其他实现都会抛出NoSuchBeanDefinitionException 。 主要缺点是在检索 bean 后，我们必须将其转换为所需的类型。如果返回的 bean 的类型与我们预期的不同，这可能会产生另一个异常。 假设我们尝试使用名称lion来获得Tiger。 当我们将结果转换为Tiger时，它会抛出ClassCastException： assertThrows(ClassCastException.class, () -\u0026gt; { Tiger tiger = (Tiger) context.getBean(\u0026#34;lion\u0026#34;); }); 3.2 按名称和类型检索 Bean 在这里，我们需要指定请求的 bean 的名称和类型： Lion lion = context.getBean(\u0026#34;lion\u0026#34;, Lion.class); 与前一种方法相比，这种方法更安全，因为我们可以立即获得有关类型不匹配的信息： assertThrows(BeanNotOfRequiredTypeException.class, () -\u0026gt; context.getBean(\u0026#34;lion\u0026#34;, Tiger.class)); } 3.3. 按类型检索 Bean 使用*getBean()*的第三个变体， 只指定 bean 类型就足够了： Lion lion = context.getBean(Lion.class); 在这种情况下，我们需要特别注意潜在的模棱两可的结果： assertThrows(NoUniqueBeanDefinitionException.class, () -\u0026gt; context.getBean(Animal.class)); } 在上面的示例中，由于Lion和Tiger都实现了Animal接口，因此仅指定类型不足以明确确定结果。因此，我们得到一个NoUniqueBeanDefinitionException。 3.4 使用构造函数参数按名称检索 Bean 除了bean名称，我们还可以传递构造函数参数： Tiger tiger = (Tiger) context.getBean(\u0026#34;tiger\u0026#34;, \u0026#34;Siberian\u0026#34;); 这个方法有点不同，因为它只适用于具有原型作用域的 bean。 在单例的情况下，我们将得到一个*BeanDefinitionStoreException。* 因为原型 bean 每次从应用程序容器请求时都会返回一个新创建的实例，所以我们可以在调用 getBean()时即时提供构造函数参数： Tiger tiger = (Tiger) context.getBean(\u0026#34;tiger\u0026#34;, \u0026#34;aaa\u0026#34;); Tiger secondTiger = (Tiger) context.getBean(\u0026#34;tiger\u0026#34;, \u0026#34;bbb\u0026#34;); assertEquals(\u0026#34;aaa\u0026#34;, tiger.getName()); assertEquals(\u0026#34;bbb\u0026#34;, secondTiger.getName()); 正如我们所见，根据我们在请求 bean 时指定的第二个参数，每个Tiger都会获得不同的名称。 3.5 使用构造函数参数按类型检索 Bean 这个方法类似于最后一个，但我们需要传递类型而不是名称作为第一个参数： Tiger tiger = context.getBean(Tiger.class, \u0026#34;ccc\u0026#34;); assertEquals(\u0026#34;ccc\u0026#34;, tiger.getName()); 与使用构造函数参数按名称检索 bean 类似，此方法仅适用于具有原型作用域的 bean。 4. 使用注意事项 尽管在BeanFactory接口中定义，getBean()方法最常通过ApplicationContext 访问。通常，*我们不想在程序中直接使用*getBean()方法。 bean 应该由容器管理。如果我们想使用其中之一，我们应该依赖依赖注入而不是直接调用ApplicationContext.getBean()。这样，我们就可以避免将应用程序逻辑与框架相关的细节混在一起。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_getbean/","tags":["JPA"],"title":"了解 Spring 中的 getBean()"},{"categories":["NoSQL","Spring Data"],"contents":"1. 概述 在本教程中，我们将为具有多个数据库的 Spring Data JPA 系统实现一个简单的 Spring 配置。 2. 实体 首先，让我们创建两个简单的实体，每个实体都存在于一个单独的数据库中。 这是第一个用户 实体： package com.codingman.multipledb.model.user; @Entity @Table(schema = \u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue(strategy = GenerationType.AUTO) private int id; private String name; @Column(unique = true, nullable = false) private String email; private int age; } 这是第二个实体Product： package com.codingman.multipledb.model.product; @Entity @Table(schema = \u0026#34;products\u0026#34;) public class Product { @Id private int id; private String name; private double price; } 我们可以看到这**两个实体也被放置在独立的包中。**当我们进入配置时，这将很重要。 3. JPA 存储库 接下来，让我们看一下我们的两个 JPA 存储库UserRepository： package com.codingman.multipledb.dao.user; public interface UserRepository extends JpaRepository\u0026lt;User, Integer\u0026gt; { } 和ProductRepository： package com.codingman.multipledb.dao.product; public interface ProductRepository extends JpaRepository\u0026lt;Product, Integer\u0026gt; { } 再次注意我们如何在不同的包中创建这两个存储库。 4. 用Java配置JPA 现在我们将了解实际的 Spring 配置。我们将首先设置两个配置类——一个用于User，另一个用于Product。 在每个配置类中，我们需要为User定义以下接口：  数据源 实体管理器工厂（用户实体管理器） 事务管理器（用户事务管理器）  让我们从查看用户配置开始： @Configuration @PropertySource({ \u0026#34;classpath:persistence-multiple-db.properties\u0026#34; }) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.user\u0026#34;, entityManagerFactoryRef = \u0026#34;userEntityManager\u0026#34;, transactionManagerRef = \u0026#34;userTransactionManager\u0026#34; ) public class PersistenceUserConfiguration { @Autowired private Environment env; @Bean @Primary public LocalContainerEntityManagerFactoryBean userEntityManager() { LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(userDataSource()); em.setPackagesToScan( new String[] { \u0026#34;com.codingman.multipledb.model.user\u0026#34; }); HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); em.setJpaVendorAdapter(vendorAdapter); HashMap\u0026lt;String, Object\u0026gt; properties = new HashMap\u0026lt;\u0026gt;(); properties.put(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;, env.getProperty(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;)); properties.put(\u0026#34;hibernate.dialect\u0026#34;, env.getProperty(\u0026#34;hibernate.dialect\u0026#34;)); em.setJpaPropertyMap(properties); return em; } @Primary @Bean public DataSource userDataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName( env.getProperty(\u0026#34;jdbc.driverClassName\u0026#34;)); dataSource.setUrl(env.getProperty(\u0026#34;user.jdbc.url\u0026#34;)); dataSource.setUsername(env.getProperty(\u0026#34;jdbc.user\u0026#34;)); dataSource.setPassword(env.getProperty(\u0026#34;jdbc.pass\u0026#34;)); return dataSource; } @Primary @Bean public PlatformTransactionManager userTransactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory( userEntityManager().getObject()); return transactionManager; } } 请注意我们如何通过使用 @Primary 注释 bean 定义来使用userTransactionManager作为我们的Primary *TransactionManager*。每当我们要隐式或显式地注入事务管理器而不指定哪个名称时，这都会很有帮助。 接下来，让我们讨论PersistenceProductConfiguration，我们在其中定义了类似的 bean： @Configuration @PropertySource({ \u0026#34;classpath:persistence-multiple-db.properties\u0026#34; }) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.product\u0026#34;, entityManagerFactoryRef = \u0026#34;productEntityManager\u0026#34;, transactionManagerRef = \u0026#34;productTransactionManager\u0026#34; ) public class PersistenceProductConfiguration { @Autowired private Environment env; @Bean public LocalContainerEntityManagerFactoryBean productEntityManager() { LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(productDataSource()); em.setPackagesToScan( new String[] { \u0026#34;com.codingman.multipledb.model.product\u0026#34; }); HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); em.setJpaVendorAdapter(vendorAdapter); HashMap\u0026lt;String, Object\u0026gt; properties = new HashMap\u0026lt;\u0026gt;(); properties.put(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;, env.getProperty(\u0026#34;hibernate.hbm2ddl.auto\u0026#34;)); properties.put(\u0026#34;hibernate.dialect\u0026#34;, env.getProperty(\u0026#34;hibernate.dialect\u0026#34;)); em.setJpaPropertyMap(properties); return em; } @Bean public DataSource productDataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName( env.getProperty(\u0026#34;jdbc.driverClassName\u0026#34;)); dataSource.setUrl(env.getProperty(\u0026#34;product.jdbc.url\u0026#34;)); dataSource.setUsername(env.getProperty(\u0026#34;jdbc.user\u0026#34;)); dataSource.setPassword(env.getProperty(\u0026#34;jdbc.pass\u0026#34;)); return dataSource; } @Bean public PlatformTransactionManager productTransactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory( productEntityManager().getObject()); return transactionManager; } } 5. 简单测试 最后，让我们测试一下我们的配置。 为此，我们将创建每个实体的实例并确保它已创建： @RunWith(SpringRunner.class) @SpringBootTest @EnableTransactionManagement public class JpaMultipleDBIntegrationTest { @Autowired private UserRepository userRepository; @Autowired private ProductRepository productRepository; @Test @Transactional(\u0026#34;userTransactionManager\u0026#34;) public void whenCreatingUser_thenCreated() { User user = new User(); user.setName(\u0026#34;Ann\u0026#34;); user.setEmail(\u0026#34;Ann@163.com\u0026#34;); user.setAge(205); user = userRepository.save(user); assertNotNull(userRepository.findOne(user.getId())); } @Test @Transactional(\u0026#34;userTransactionManager\u0026#34;) public void whenCreatingUsersWithSameEmail_thenRollback() { User user1 = new User(); user1.setName(\u0026#34;Ann\u0026#34;); user1.setEmail(\u0026#34;Ann@163.com\u0026#34;); user1.setAge(25); user1 = userRepository.save(user1); assertNotNull(userRepository.findOne(user1.getId())); User user2 = new User(); user2.setName(\u0026#34;Bob\u0026#34;); user2.setEmail(\u0026#34;Ann@163.com\u0026#34;); user2.setAge(28); try { user2 = userRepository.save(user2); } catch (DataIntegrityViolationException e) { } assertNull(userRepository.findOne(user2.getId())); } @Test @Transactional(\u0026#34;productTransactionManager\u0026#34;) public void whenCreatingProduct_thenCreated() { Product product = new Product(); product.setName(\u0026#34;Book\u0026#34;); product.setId(2); product.setPrice(20); product = productRepository.save(product); assertNotNull(productRepository.findOne(product.getId())); } } 6. Spring Boot 中的多个数据库 Spring Boot 可以简化上面的配置。 默认情况下，Spring Boot 将使用前缀为spring.datasource.的配置属性实例化其默认DataSource： spring.datasource.jdbcUrl = [url] spring.datasource.username = [username] spring.datasource.password = [password] 我们现在想继续使用相同的方式来配置第二个DataSource，但使用不同的属性命名空间： spring.second-datasource.jdbcUrl = [url] spring.second-datasource.username = [username] spring.second-datasource.password = [password] 因为我们希望 Spring Boot 自动配置能够获取这些不同的属性（并实例化两个不同的DataSources），所以我们将定义两个类似于前面部分的配置类： @Configuration @PropertySource({\u0026#34;classpath:persistence-multiple-db-boot.properties\u0026#34;}) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.user\u0026#34;, entityManagerFactoryRef = \u0026#34;userEntityManager\u0026#34;, transactionManagerRef = \u0026#34;userTransactionManager\u0026#34;) public class PersistenceUserAutoConfiguration { @Primary @Bean @ConfigurationProperties(prefix=\u0026#34;spring.datasource\u0026#34;) public DataSource userDataSource() { return DataSourceBuilder.create().build(); } // userEntityManager bean  // userTransactionManager bean } @Configuration @PropertySource({\u0026#34;classpath:persistence-multiple-db-boot.properties\u0026#34;}) @EnableJpaRepositories( basePackages = \u0026#34;com.codingman.multipledb.dao.product\u0026#34;, entityManagerFactoryRef = \u0026#34;productEntityManager\u0026#34;, transactionManagerRef = \u0026#34;productTransactionManager\u0026#34;) public class PersistenceProductAutoConfiguration { @Bean @ConfigurationProperties(prefix=\u0026#34;spring.second-datasource\u0026#34;) public DataSource productDataSource() { return DataSourceBuilder.create().build(); } // productEntityManager bean  // productTransactionManager bean } 现在我们已经根据 Boot 自动配置约定在persistence-multiple-db-boot.properties中定义了数据源属性。 有趣的部分是使用@ConfigurationProperties注释数据源 bean 创建方法。我们只需要指定相应的配置前缀。在这个方法中，我们使用了一个DataSourceBuilder，Spring Boot 会自动处理剩下的事情。 但是如何将配置的属性注入到DataSource配置中呢？ 在DataSourceBuilder上调用*build()方法时，它会调用其私有的bind()*方法： public T build() { Class\u0026lt;? extends DataSource\u0026gt; type = getType(); DataSource result = BeanUtils.instantiateClass(type); maybeGetDriverClassName(); bind(result); return (T) result; } 这个私有方法执行了很多自动配置魔法，将解析的配置绑定到实际的DataSource实例： private void bind(DataSource result) { ConfigurationPropertySource source = new MapConfigurationPropertySource(this.properties); ConfigurationPropertyNameAliases aliases = new ConfigurationPropertyNameAliases(); aliases.addAliases(\u0026#34;url\u0026#34;, \u0026#34;jdbc-url\u0026#34;); aliases.addAliases(\u0026#34;username\u0026#34;, \u0026#34;user\u0026#34;); Binder binder = new Binder(source.withAliases(aliases)); binder.bind(ConfigurationPropertyName.EMPTY, Bindable.ofInstance(result)); } 尽管我们自己不必接触任何这些代码，但了解 Spring Boot 自动配置背后发生的事情仍然很有用。 除此之外，事务管理器和实体管理器 bean 配置与标准 Spring 应用程序相同。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_data_jpa_multiple_databases/","tags":["Cassandra"],"title":"Spring JPA – 多个数据库"},{"categories":["Spring Persistence"],"contents":"1. 概述 本文是使用 Spring Data 使用 Cassandra 的实用介绍。 我们将从基础开始，通过配置和编码，最终构建一个完整的 Spring Data Cassandra 模块。 2. Maven依赖 让我们首先使用 Maven在pom.xml中定义依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.datastax.cassandra\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-driver-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.9\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3. Cassandra的配置 我们将在整个过程中使用 Java 配置风格来配置 Cassandra 集成。 3.1 主要配置（Spring） 我们将为此使用 Java 配置风格。让我们从主要的配置类开始——当然是通过类级别的*@Configuration*注解驱动的： @Configuration public class CassandraConfig extends AbstractCassandraConfiguration { @Override protected String getKeyspaceName() { return \u0026#34;testKeySpace\u0026#34;; } @Bean public CassandraClusterFactoryBean cluster() { CassandraClusterFactoryBean cluster = new CassandraClusterFactoryBean(); cluster.setContactPoints(\u0026#34;127.0.0.1\u0026#34;); cluster.setPort(9142); return cluster; } @Bean public CassandraMappingContext cassandraMapping() throws ClassNotFoundException { return new BasicCassandraMappingContext(); } } 注意带有默认实现的新 bean - *BasicCassandraMappingContext 。*这是在它们的对象和它们的持久格式之间映射持久实体所必需的。 并且由于默认实现足够强大，我们可以直接使用它。 3.2 主要配置（Spring Boot） 让我们通过application.properties进行 Cassandra 配置： spring.data.cassandra.keyspace-name=testKeySpace spring.data.cassandra.port=9142 spring.data.cassandra.contact-points=127.0.0.1 我们完成了！这就是我们在使用 Spring Boot 时所需要的。 3.3 Cassandra 连接属性 我们必须配置三个强制设置来设置 Cassandra 客户端的连接。 我们必须设置 Cassandra 服务器作为联系点运行的主机名*。端口*只是服务器中请求的侦听端口。KeyspaceName是定义节点上数据复制的命名空间，它基于 Cassandra 相关概念。 4. CassandraRepository 我们将使用CassandraRepository作为数据访问层。这遵循 Spring Data repository 抽象，该抽象专注于抽象出跨不同持久性机制实现数据访问层所需的代码。 4.1 创建CassandraRepository 让我们创建要在配置中使用的CassandraRepository： @Repository public interface BookRepository extends CassandraRepository\u0026lt;Book\u0026gt; { // } 4.2 CassandraRepository的配置 现在，我们可以扩展第 3.1 节中的配置，在 CassandraConfig 中添加*@EnableCassandraRepositories*类级别注释来标记我们在第 4.1 节中创建的 Cassandra Repository： @Configuration @EnableCassandraRepositories( basePackages = \u0026#34;com.codingman.spring.data.cassandra.repository\u0026#34;) public class CassandraConfig extends AbstractCassandraConfiguration { // } 5. 实体 让我们快速看一下实体——我们将要使用的模型类。该类被注释并定义了嵌入模式下元数据 Cassandra 数据表创建的附加参数。 使用*@Table*注解，bean 直接映射到 Cassandra 数据表。此外，每个属性都被定义为一种主键或简单列： @Table public class Book { @PrimaryKeyColumn( name = \u0026#34;isbn\u0026#34;, ordinal = 2, type = PrimaryKeyType.CLUSTERED, ordering = Ordering.DESCENDING) private UUID id; @PrimaryKeyColumn( name = \u0026#34;title\u0026#34;, ordinal = 0, type = PrimaryKeyType.PARTITIONED) private String title; @PrimaryKeyColumn( name = \u0026#34;publisher\u0026#34;, ordinal = 1, type = PrimaryKeyType.PARTITIONED) private String publisher; @Column private Set\u0026lt;String\u0026gt; tags = new HashSet\u0026lt;\u0026gt;(); // standard getters and setters } 6. 使用嵌入式服务器进行测试 6.1 Maven 依赖项 如果要在嵌入式模式下运行 Cassandra（无需手动安装单独的 Cassandra 服务器），则需要将cassandra-unit相关依赖项添加到pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.cassandraunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-unit-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.9.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.cassandraunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-unit\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.cassandraunit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cassandra-unit-shaded\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.9.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hectorclient\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hector-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0-0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以使用嵌入式 Cassandra 服务器来测试此应用程序。主要优点是您不想显式安装 Cassandra。 这个嵌入式服务器也与 Spring JUnit 测试兼容。在这里，我们可以使用*@RunWith注解与嵌入式服务器一起设置SpringJUnit4ClassRunner 。*因此，无需运行外部 Cassandra 服务即可实现完整的测试套件。 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = CassandraConfig.class) public class BookRepositoryIntegrationTest { // } 6.2 启动和停止服务器 如果您正在运行外部 Cassandra 服务器，则可以忽略此部分。 我们必须为整个测试套件启动一次服务器，因此服务器启动方法用*@BeforeClass*注释标记： @BeforeClass public static void startCassandraEmbedded() { EmbeddedCassandraServerHelper.startEmbeddedCassandra(); Cluster cluster = Cluster.builder() .addContactPoints(\u0026#34;127.0.0.1\u0026#34;).withPort(9142).build(); Session session = cluster.connect(); } 接下来，我们必须确保在测试套件执行完成后服务器停止： @AfterClass public static void stopCassandraEmbedded() { EmbeddedCassandraServerHelper.cleanEmbeddedCassandra(); } 6.3 清洁数据表 最好在每次测试执行之前删除并创建数据表，以避免由于早期测试执行中的操纵数据而导致意外结果。 现在我们可以在服务器启动时创建数据表： @Before public void createTable() { adminTemplate.createTable( true, CqlIdentifier.cqlId(DATA_TABLE_NAME), Book.class, new HashMap\u0026lt;String, Object\u0026gt;()); } 并在每个测试用例执行后丢弃： @After public void dropTable() { adminTemplate.dropTable(CqlIdentifier.cqlId(DATA_TABLE_NAME)); } 7. 使用CassandraRepository 进行数据访问 我们可以直接使用上面创建的BookRepository来持久化、操作和获取 Cassandra 数据库中的数据。 7.1 保存一本新书 我们可以将一本新书保存到我们的书店： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); 然后我们可以检查数据库中插入的书的可用性： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;); assertEquals(javaBook.getId(), books.iterator().next().getId()); 7.2 更新现有书籍 Lat 从插入一本新书开始： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); 让我们按标题获取这本书： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;); 那我们改一下书名： javaBook.setTitle(\u0026#34;Demo Book 2\u0026#34;); bookRepository.save(ImmutableSet.of(javaBook)); 最后让我们检查一下数据库中的标题是否更新： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 2\u0026#34;, \u0026#34;ABC Company\u0026#34;); assertEquals( javaBook.getTitle(), updateBooks.iterator().next().getTitle()); 7.3 删除现有书籍 插入一本新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); 然后删除新输入的书： bookRepository.delete(javaBook); 现在我们可以检查删除： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findByTitleAndPublisher( \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;); assertNotEquals(javaBook.getId(), books.iterator().next().getId()); 这将导致从代码中抛出 NoSuchElementException 以确保该书已被删除。 7.4 查找所有书籍 先插入一本新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 1\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); Book dPatternBook = new Book( UUIDs.timeBased(), \u0026#34;Demo Book 2\u0026#34;,\u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); bookRepository.save(ImmutableSet.of(javaBook)); bookRepository.save(ImmutableSet.of(dPatternBook)); 查找所有书籍： Iterable\u0026lt;Book\u0026gt; books = bookRepository.findAll(); 然后我们可以检查数据库中可用书籍的数量： int bookCount = 0; for (Book book : books) bookCount++; assertEquals(bookCount, 2); \u0026quot; ","permalink":"http://itcodingman.github.io/spring_data_cassandra_tutorial/","tags":["JPA"],"title":"Spring Data Cassandra简介"},{"categories":["NoSQL","Spring Data"],"contents":"1. 概述 这是 Spring Data Cassandra 文章系列的第二篇。在本文中，我们将主要关注数据访问层中的CassandraTemplate和 CQL 查询。您可以在该系列的第一篇文章中阅读有关 Spring Data Cassandra 的更多信息。 Cassandra Query Language (CQL) 是 Cassandra 数据库的查询语言，CqlTemplate是 Spring Data Cassandra 中的低级数据访问模板——它方便地公开与数据操作相关的操作以执行 CQL 语句。 CassandraTemplate构建在低级CqlTemplate 之上，并提供了一种简单的方法来查询域对象并将对象映射到 Cassandra 中的持久数据结构。 让我们从配置开始，然后深入研究使用这两个模板的示例。 2. CassandraTemplate配置 CassandraTemplate在 Spring 上下文中可用，因为我们的主要 Cassandra Spring 配置正在扩展 AbstractCassandraConfiguration： @Configuration @EnableCassandraRepositories(basePackages = \u0026#34;com.codingman.spring.data.cassandra.repository\u0026#34;) public class CassandraConfig extends AbstractCassandraConfiguration { ... } 然后我们可以在模板中进行简单的连接——或者通过它的确切类型，CassandraTemplate，或者作为更通用的接口CassandraOperations： @Autowired private CassandraOperations cassandraTemplate; 3. 使用CassandraTemplate进行数据访问 让我们使用上面在数据访问层模块中定义的CassandraTemplate来处理数据持久化。 3.1 保存一本新书 我们可以将一本新书保存到我们的书店： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); 然后我们可以检查数据库中插入的书的可用性： Select select = QueryBuilder.select().from(\u0026#34;book\u0026#34;) .where(QueryBuilder.eq(\u0026#34;title\u0026#34;, \u0026#34;Spring Demo Book\u0026#34;)) .and(QueryBuilder.eq(\u0026#34;publisher\u0026#34;, \u0026#34;ABC Company\u0026#34;)); Book retrievedBook = cassandraTemplate.selectOne(select, Book.class); 我们在这里使用Select QueryBuilder，映射到 cassandraTemplate 中的selectOne ( )。我们将在 CQL 查询部分更深入地讨论QueryBuilder。 3.2 保存多本书 我们可以使用列表一次将多本书保存到我们的书店： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); Book dPatternBook = new Book( UUIDs.timeBased(), \u0026#34;Java Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); List\u0026lt;Book\u0026gt; bookList = new ArrayList\u0026lt;Book\u0026gt;(); bookList.add(javaBook); bookList.add(dPatternBook); cassandraTemplate.insert(bookList); 3.3 更新现有书籍 Lat 从插入一本新书开始： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); 我们来取书： Select select = QueryBuilder.select().from(\u0026#34;book\u0026#34;); Book retrievedBook = cassandraTemplate.selectOne(select, Book.class); 然后让我们为检索到的书添加一些额外的标签： retrievedBook.setTags(ImmutableSet.of(\u0026#34;Java\u0026#34;, \u0026#34;Programming\u0026#34;)); cassandraTemplate.update(retrievedBook); 3.4 删除插入的书 让我们插入一本新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); 然后删除这本书： cassandraTemplate.delete(javaBook); 3.5 删除所有书籍 现在让我们插入一些新书： Book javaBook = new Book( UUIDs.timeBased(), \u0026#34;Spring Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); Book dPatternBook = new Book( UUIDs.timeBased(), \u0026#34;Java Demo Book\u0026#34;, \u0026#34;ABC Company\u0026#34;, ImmutableSet.of(\u0026#34;Computer\u0026#34;, \u0026#34;Software\u0026#34;)); cassandraTemplate.insert(javaBook); cassandraTemplate.insert(dPatternBook); 然后删除所有书籍： cassandraTemplate.deleteAll(Book.class); 4. 使用 CQL 查询的数据访问 始终可以使用 CQL 查询在数据访问层中进行数据操作。CQL 查询处理由CqlTemplate类执行，允许我们根据需要执行自定义查询。 但是，由于CassandraTemplate类是CqlTemplate的扩展，我们可以直接使用它来执行这些查询。 让我们看看我们可以使用 CQL 查询来操作数据的不同方法。 4.1。使用QueryBuilder QueryBuilder可用于为数据库中的数据操作构建查询。几乎所有标准操作都可以使用开箱即用的构建块构建： Insert insertQueryBuider = QueryBuilder.insertInto(\u0026#34;book\u0026#34;) .value(\u0026#34;isbn\u0026#34;, UUIDs.timeBased()) .value(\u0026#34;title\u0026#34;, \u0026#34;Spring Demo Book\u0026#34;) .value(\u0026#34;publisher\u0026#34;, \u0026#34;ABC Company\u0026#34;) .value(\u0026#34;tags\u0026#34;, ImmutableSet.of(\u0026#34;Software\u0026#34;)); cassandraTemplate.execute(insertQueryBuider); 如果您仔细查看代码片段，您可能会注意到使用了execute()方法而不是相关的操作类型（插入、删除等）。这是因为查询的类型是由QueryBuilder 的输出定义的。 4.2 使用PreparedStatements 尽管PreparedStatements可用于任何情况，但通常建议将此机制用于多个插入以进行高速摄取。 PreparedStatement只准备一次，有助于确保高性能： UUID uuid = UUIDs.timeBased(); String insertPreparedCql = \u0026#34;insert into book (isbn, title, publisher, tags) values (?, ?, ?, ?)\u0026#34;; List\u0026lt;Object\u0026gt; singleBookArgsList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;List\u0026lt;?\u0026gt;\u0026gt; bookList = new ArrayList\u0026lt;\u0026gt;(); singleBookArgsList.add(uuid); singleBookArgsList.add(\u0026#34;Spring Demo Book\u0026#34;); singleBookArgsList.add(\u0026#34;ABC Company\u0026#34;); singleBookArgsList.add(ImmutableSet.of(\u0026#34;Software\u0026#34;)); bookList.add(singleBookArgsList); cassandraTemplate.ingest(insertPreparedCql, bookList); 4.3 使用 CQL 语句 我们可以直接使用CQL语句查询数据，如下： UUID uuid = UUIDs.timeBased(); String insertCql = \u0026#34;insert into book (isbn, title, publisher, tags) values (\u0026#34; + uuid + \u0026#34;, \u0026#39;Spring Demo Book\u0026#39;, \u0026#39;ABC Company\u0026#39;, {\u0026#39;Software\u0026#39;})\u0026#34;; cassandraTemplate.execute(insertCql); \u0026quot; ","permalink":"http://itcodingman.github.io/spring_data_cassandratemplate_cqltemplate/","tags":["Cassandra"],"title":"使用 Spring Data 中的 CassandraTemplate"},{"categories":["Spring"],"contents":"1. 概述 本文将展示如何使用 Spring 和 JPA 实现 DAO。有关核心 JPA 配置，请参阅有关 JPA with Spring 的文章。 2. 不再有 Spring 模板 从 Spring 3.1 开始，已弃用JpaTemplate和相应的JpaDaoSupport 以支持使用本机 Java Persistence API。 此外，这两个类仅与 JPA 1 相关（来自JpaTemplate javadoc）：  请注意，此类没有升级到 JPA 2.0，也永远不会升级。  因此，现在最好的做法是直接使用 Java Persistence API而不是JpaTemplate。 2.1 没有模板的异常翻译 JpaTemplate的职责之一是异常转换——将低级异常转换为更高级别的通用 Spring 异常。 如果没有模板，异常翻译仍然可以为所有使用 @Repository 注释的 DAO启用并完全正常运行。Spring 使用 bean 后处理器实现这一点，该后处理器将使用容器中找到的所有PersistenceExceptionTranslator通知所有**@Repository bean 。 同样重要的是要注意异常转换机制使用代理——为了让 Spring 能够围绕 DAO 类创建代理，这些代理不能被声明为final。 3. DAO 首先，我们将为所有 DAO 实现基础层——一个使用泛型并设计为可扩展的抽象类： public abstract class AbstractJpaDAO\u0026lt;T extends Serializable\u0026gt; { private Class\u0026lt;T\u0026gt; clazz; @PersistenceContext EntityManager entityManager; public final void setClazz(Class\u0026lt;T\u0026gt; clazzToSet){ this.clazz = clazzToSet; } public T findOne( long id ){ return entityManager.find(clazz, id); } public List\u0026lt;T\u0026gt; findAll(){ return entityManager.createQuery(\u0026#34;from \u0026#34; + clazz.getName()) .getResultList(); } public void create(T entity){ entityManager.persist(entity); } public T update(T entity){ return entityManager.merge(entity); } public void delete(T entity){ entityManager.remove(entity); } public void deleteById(long entityId){ T entity = findOne(entityId); delete(entity); } } 这里主要有趣的方面是EntityManager的注入方式——使用标准的*@PersistenceContext注释。在后台，这是由PersistenceAnnotationBeanPostProcessor*处理的——它处理注释，从包含中检索 JPA 实体管理器并注入它。 持久化后处理器要么通过在配置中定义显式创建，要么通过在命名空间配置中定义context:annotation-config或context:component-scan自动创建。 另外，请注意实体Class在构造函数中传递以用于通用操作： @Repository public class FooDAO extends AbstractJPADAO\u0026lt; Foo \u0026gt; implements IFooDAO{ public FooDAO(){ setClazz(Foo.class ); } } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_dao_jpa/","tags":["Spring Annotations","Spring Core Basics","Spring DI"],"title":"JPA 和 Spring 的 DAO"},{"categories":["REST","Spring MVC"],"contents":"1. 概述 我们可以使用org.springframework.beans.factory.annotation 和 org.springframework.context.annotation包中的注释来利用 Spring DI 引擎的功能。 我们经常将这些称为“Spring 核心注释”，我们将在本教程中回顾它们。 2. DI 相关注解 2.1 @Autowired 我们可以使用*@Autowired*来标记 Spring 将要解析和注入的依赖项。我们可以将此注解与构造函数、setter 或字段注入一起使用。 构造函数注入： class Car { Engine engine; @Autowired Car(Engine engine) { this.engine = engine; } } setter注入： class Car { Engine engine; @Autowired void setEngine(Engine engine) { this.engine = engine; } } 现场注入： class Car { @Autowired Engine engine; } @Autowired有一个名为required的boolean参数，默认值为true。当找不到合适的 bean 进行连接时，它会调整 Spring 的行为。当true时，抛出异常，否则，什么都没有连接。 请注意，如果我们使用构造函数注入，则所有构造函数参数都是必需的。 从 4.3 版开始，除非我们声明至少两个构造函数，否则我们不需要显式使用*@Autowired注释构造函数。* 有关更多详细信息，请访问我们关于@Autowired和构造函数注入的文章。 2.2 @Bean @Bean标记了一个实例化 Spring bean 的工厂方法： @Bean Engine engine() { return new Engine(); } 当需要返回类型的新实例时，Spring 会调用这些方法。 生成的 bean 与工厂方法具有相同的名称。如果我们想以不同的方式命名它，我们可以使用这个注解的name或value参数（参数value是参数name的别名）： @Bean(\u0026#34;engine\u0026#34;) Engine getEngine() { return new Engine(); } 请注意，所有使用*@Bean注释的方法都必须在@Configuration*类中。 2.3 @Qualifier 我们使用*@Qualifier和@Autowired*来提供我们想要在模棱两可的情况下使用的bean id 或bean 名称。 例如，以下两个 bean 实现了相同的接口： class Bike implements Vehicle {} class Car implements Vehicle {} 如果 Spring 需要注入一个Vehicle bean，它最终会得到多个匹配的定义。在这种情况下，我们可以使用@Qualifier注释显式地提供 bean 的名称。 使用构造函数注入： @Autowired Biker(@Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle) { this.vehicle = vehicle; } 使用 setter 注入： @Autowired void setVehicle(@Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle) { this.vehicle = vehicle; } 或者： @Autowired @Qualifier(\u0026#34;bike\u0026#34;) void setVehicle(Vehicle vehicle) { this.vehicle = vehicle; } 使用字段注入： @Autowired @Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle; 更详细的描述，请阅读这篇文章。 2.4 @Required @Required在 setter 方法上标记我们希望通过 XML 填充的依赖项： @Required void setColor(String color) { this.color = color; } \u0026lt;bean class=\u0026#34;com.codingman.annotations.Bike\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;color\u0026#34; value=\u0026#34;green\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 否则，将抛出BeanInitializationException 。 2.5 @Value 我们可以使用@Value将属性值注入到 bean 中。它与构造函数、设置器和字段注入兼容。 构造函数注入： Engine(@Value(\u0026#34;8\u0026#34;) int cylinderCount) { this.cylinderCount = cylinderCount; } setter注入： @Autowired void setCylinderCount(@Value(\u0026#34;8\u0026#34;) int cylinderCount) { this.cylinderCount = cylinderCount; } 或者： @Value(\u0026#34;8\u0026#34;) void setCylinderCount(int cylinderCount) { this.cylinderCount = cylinderCount; } 现场注入： @Value(\u0026#34;8\u0026#34;) int cylinderCount; 当然，注入静态值是没有用的。因此，我们可以在*@Value中使用占位符字符串来连接外部源中定义的**值，例如，在.properties或.yaml*文件中。 让我们假设以下*.properties*文件： engine.fuelType=petrol 我们可以使用以下内容注入engine.fuelType的值： @Value(\u0026#34;${engine.fuelType}\u0026#34;) String fuelType; 即使在 SpEL 中，我们也可以使用*@Value*。更多高级示例可以在我们关于*@Value*的文章中找到。 2.6 @DependsOn 我们可以使用这个注解让Spring在被注解的bean之前初始化其他bean。通常，这种行为是自动的，基于 bean 之间的显式依赖关系。 我们只有在依赖是隐式的时候才需要这个注解，例如 JDBC 驱动加载或者静态变量初始化。 我们可以在依赖类上使用*@DependsOn来指定依赖bean 的名称。注释的value*参数需要一个包含依赖 bean 名称的数组： @DependsOn(\u0026#34;engine\u0026#34;) class Car implements Vehicle {} 或者，如果我们使用*@Bean注解定义 bean，则工厂方法应该使用@DependsOn*进行注解： @Bean @DependsOn(\u0026#34;fuel\u0026#34;) Engine engine() { return new Engine(); } 2.7 @Lazy 当我们想要懒惰地初始化我们的bean时，我们使用@Lazy默认情况下，Spring 在应用程序上下文的启动/引导时急切地创建所有单例 bean。 但是，在某些情况下，我们需要在请求时创建 bean，而不是在应用程序启动时。 这个注解的行为会根据我们准确放置的位置而有所不同。我们可以装上：  一个*@Bean*注释的 bean 工厂方法，用于延迟方法调用（因此创建 bean） 一个*@Configuration类和所有包含的@Bean*方法都会受到影响 一个*@Component类，它不是一个@Configuration*类，这个bean 将被延迟初始化 @Autowired构造函数、设置器或字段，用于延迟加载依赖项本身（通过代理）  此注释有一个名为value的参数，默认值为true。覆盖默认行为很有用。 例如，当全局设置为惰性时，将 bean 标记为预加载，或者在标有*@Lazy的**@Configuration类中配置特定的@Bean*方法以预加载： @Configuration @Lazy class VehicleFactoryConfig { @Bean @Lazy(false) Engine engine() { return new Engine(); } } 如需进一步阅读，请访问本文。 2.8 @Lookup 使用*@Lookup*注释的方法告诉 Spring 在我们调用它时返回该方法的返回类型的实例。 有关注释的详细信息可以在本文中找到。 2.9 @Primary 有时我们需要定义多个相同类型的bean。在这些情况下，注入将不成功，因为 Spring 不知道我们需要哪个 bean。 我们已经看到了处理这种情况的一个选项：用*@Qualifier*标记所有连接点并指定所需bean 的名称。 然而，大多数时候我们需要一个特定的 bean 而很少需要其他的。我们可以使用*@Primary来简化这种情况：如果我们用@Primary*标记最常用的bean，它将在不合格的注入点上被选中： @Component @Primary class Car implements Vehicle {} @Component class Bike implements Vehicle {} @Component class Driver { @Autowired Vehicle vehicle; } @Component class Biker { @Autowired @Qualifier(\u0026#34;bike\u0026#34;) Vehicle vehicle; } 在前面的示例中，汽车是主要车辆。因此，在Driver类中，Spring 注入了一个Car bean。当然，在Biker bean 中，字段vehicle的值将是Bike对象，因为它是合格的。 2.10 @Scope 我们使用*@Scope来定义@Component类或@Bean定义的范围。它可以是单例、原型、请求、会话、globalSession*或一些自定义范围。 例如： @Component @Scope(\u0026#34;prototype\u0026#34;) class Engine {} 3. 上下文配置注解 我们可以使用本节中描述的注释来配置应用程序上下文。 3.1 @Profile 如果我们希望 Spring仅在特定配置文件处于活动状态时使用*@Component类或@Bean方法，我们可以用@Profile标记它。我们可以使用注解的value*参数配置配置文件的名称： @Component @Profile(\u0026#34;sportDay\u0026#34;) class Bike implements Vehicle {} 您可以在本文中阅读有关配置文件的更多信息。 3.2. @Import 我们可以使用特定的*@Configuration类而无需使用此注解**进行组件扫描。*我们可以为这些类提供@Import的value参数： @Import(VehiclePartSupplier.class) class VehicleFactoryConfig {} 3.3 @ImportResource 我们可以使用此注解**导入 XML 配置。**我们可以使用位置参数指定 XML 文件位置，或者使用它的别名，Value参数： @Configuration @ImportResource(\u0026#34;classpath:/annotations.xml\u0026#34;) class VehicleFactoryConfig {} 3.4 @PropertySource 使用此注解，我们可以为应用程序设置定义属性文件： @Configuration @PropertySource(\u0026#34;classpath:/annotations.properties\u0026#34;) class VehicleFactoryConfig {} @PropertySource利用 Java 8 重复注释功能，这意味着我们可以多次使用它标记一个类： @Configuration @PropertySource(\u0026#34;classpath:/annotations.properties\u0026#34;) @PropertySource(\u0026#34;classpath:/vehicle-factory.properties\u0026#34;) class VehicleFactoryConfig {} 3.5. @PropertySources 我们可以使用这个注解来指定多个*@PropertySource*配置： @Configuration @PropertySources({ @PropertySource(\u0026#34;classpath:/annotations.properties\u0026#34;), @PropertySource(\u0026#34;classpath:/vehicle-factory.properties\u0026#34;) }) class VehicleFactoryConfig {} 请注意，从 Java 8 开始，我们可以通过上述重复注释功能实现相同的功能。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_core_annotations/","tags":["Spring Annotations","Spring MVC Basics"],"title":"Spring 核心注解"},{"categories":["Spring"],"contents":"1. 概述 在这个简短的教程中，我们将讨论Spring MVC 中*@Controller和@RestController*注解之间的区别。 我们可以将第一个注解用于传统的 Spring 控制器，它已经成为框架的一部分很长时间了。 Spring 4.0 引入了*@RestController注解，以简化 RESTful Web 服务的创建。*这是一个方便的注解，结合了@Controller和*@ResponseBody* *，它消除了使用@ResponseBody*注解对控制器类的每个请求处理方法进行注解的需要。 2. Spring MVC @Controller 我们可以使用*@Controller*注解来注解经典控制器。这只是 @Component类的一个特化，它允许我们通过类路径扫描自动检测实现类。 我们通常将 @Controller与*@RequestMapping*注解结合使用，用于请求处理方法。 让我们看一个 Spring MVC 控制器的快速示例： @Controller @RequestMapping(\u0026#34;books\u0026#34;) public class SimpleBookController { @GetMapping(\u0026#34;/{id}\u0026#34;, produces = \u0026#34;application/json\u0026#34;) public @ResponseBody Book getBook(@PathVariable int id) { return findBookById(id); } private Book findBookById(int id) { // ...  } } 我们用@ResponseBody注释了请求处理方法。此注释支持将返回对象自动序列化到HttpResponse中。 3. Spring MVC @RestController @RestController是控制器的专用版本。它包括*@Controller和@ResponseBody*注释，因此简化了控制器的实现： @RestController @RequestMapping(\u0026#34;books-rest\u0026#34;) public class SimpleBookRestController { @GetMapping(\u0026#34;/{id}\u0026#34;, produces = \u0026#34;application/json\u0026#34;) public Book getBook(@PathVariable int id) { return findBookById(id); } private Book findBookById(int id) { // ...  } } 控制器使用@RestController注解进行注解；因此，不需要@ResponseBody。** 控制器类的每个请求处理方法都会自动将返回对象序列化为HttpResponse。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_controller_vs_restcontroller/","tags":["Spring Annotations","Spring Core Basics","Spring DI"],"title":"Spring @Controller 和 @RestController 注解"},{"categories":["Spring Boot"],"contents":"1. 简介 在本快速教程中，我们将了解Spring Framework 中*@Component*、@Repository和*@Service*注释之间的区别。 2. Spring注解 在大多数典型应用程序中，我们有不同的层，如数据访问、表示、服务、业务等。 此外，在每一层中，我们都有各种 bean。为了自动检测这些 bean，Spring 使用类路径扫描注解。 然后它在ApplicationContext中注册每个 bean 。 以下是其中一些注释的快速概述：  @Component是任何 Spring 管理的组件的通用构造型。 @Service在服务层注释类。 @Repository在持久层注释类，它将充当数据库存储库。  我们已经有一篇关于这些注释的扩展文章，所以我们将重点放在它们之间的区别上。 3. 有什么不同？ **这些刻板印象之间的主要区别在于它们用于不同的分类。**当我们注释一个类进行自动检测时，我们应该使用各自的原型。 现在让我们更详细地了解它们。 3.1 @Component 我们可以在整个应用程序中使用 @Component 将 bean 标记为 Spring 的托管组件。Spring 只会使用*@Component获取和注册bean，一般不会查找@Service* 和 @Repository。 它们在ApplicationContext中注册，因为它们使用*@Component*注释： @Component public @interface Service { } @Component public @interface Repository { } @Service 和 @Repository是*@Component*的特例。它们在技术上是相同的，但我们将它们用于不同的目的。 3.2 @Repository @Repository的工作是捕获特定于持久性的异常并将它们作为Spring的统一未检查异常之一重新抛出。 为此，Spring 提供了PersistenceExceptionTranslationPostProcessor，我们需要将其添加到我们的应用程序上下文中（如果我们使用 Spring Boot，则已经包括在内）： \u0026lt;bean class= \u0026#34;org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\u0026#34;/\u0026gt; 这个 bean 后处理器为任何使用 @Repository 注释的 bean 添加了一个顾问。 3.3 @Service 我们用@Service 标记bean 以表明它们持有业务逻辑。该注解除了用于服务层外，没有其他特殊用途。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_component_repository_service/","tags":[],"title":"Spring 中的 @Component 与 @Repository 和 @Service"},{"categories":["Spring"],"contents":"1. 概述 Spring Boot Web 应用程序默认包含一个预配置的嵌入式 Web 服务器。但是，在某些情况下，我们希望修改默认配置以满足自定义要求。 在本教程中，我们将了解如何在 Spring Boot 2.x 应用程序的application.properties文件中为请求标头设置和使用max-http-header-size属性。 2. Max-HTTP-Header-Size Spring Boot 支持Tomcat、Undertow和Jetty作为嵌入式服务器。通常，我们在 Spring Boot 应用程序中的application.properties文件或application.yaml文件中编写服务器配置。 大多数 Web 服务器都有自己的 HTTP 请求标头大小限制。HTTP 标头值受服务器实现的限制。在 Spring Boot 应用程序中，最大 HTTP 标头大小是使用server.max-http-header-size配置的。 Tomcat 和 Jetty 的实际默认值为 8kB，Undertow 的默认值为 1MB。 要修改最大 HTTP 标头大小，我们将属性添加到application.properties文件中： server.max-http-header-size=20000 对于application.yaml格式也是如此： server:max-http-header-size:20000从 Spring Boot 2.1 开始，我们现在将使用DataSize可解析值： server.max-http-header-size=10KB 3.请求头太大 假设在总 HTTP 标头大小大于max-http-header-size值的情况下发送请求。服务器以“400 Bad request”错误拒绝该请求。在下一个示例中，我们将在日志文件中看到此错误。 让我们创建一个控制器，它有一个名为 token 的标头属性： @RestController @RequestMapping(value = \u0026#34;/request-header-test\u0026#34;) public class MaxHttpHeaderSizeController { @GetMapping public boolean testMaxHTTPHeaderSize(@RequestHeader(value = \u0026#34;token\u0026#34;) String token) { return true; } } 接下来，让我们在application.properties文件中添加一些属性： ## Server connections configuration\rserver.tomcat.threads.max=200\rserver.connection-timeout=5s\rserver.max-http-header-size=8KB\rserver.tomcat.max-swallow-size=2MB\rserver.tomcat.max-http-post-size=2MB 当我们在令牌中传递一个大小大于 8kb的字符串值时，我们将得到 400 错误，如下所示： 在日志中，我们看到以下错误： 19:41:50.757 [http-nio-8080-exec-7] INFO o.a.coyote.http11.Http11Processor - Error parsing HTTP request header Note: further occurrences of HTTP request parsing errors will be logged at DEBUG level. java.lang.IllegalArgumentException: Request header is too large ... 4.解决方案 我们可以根据需要在application.properties文件中增加max-http-header-size属性的值。 在上面的程序中，我们可以将它的值从默认的 8kb 升级到 40KB，这样就可以解决问题了。 server.max-http-header-size=40KB 现在，服务器将处理请求并返回 200 响应，如下所示： 因此，每当标头大小超过服务器列出的默认值时，我们将看到服务器返回 400-Bad Request 并显示错误“请求标头太大”。如上例所示，我们必须覆盖应用程序配置文件中的max-http-header-size值以匹配请求标头长度。 通常，当使用的令牌由于加密而非常长时，请求标头可能会变得太大。\u0026quot; ","permalink":"http://itcodingman.github.io/spring_boot_max_http_header_size/","tags":["Spring Core Basics","Spring DI"],"title":"Spring Boot 2 中的 Max-HTTP-Header-Size"},{"categories":["Spring"],"contents":"1. 概述 在这个快速教程中，我们将了解 Spring 框架中不同类型的 bean 作用域。bean 的范围定义了该 bean 在我们使用它的上下文中的生命周期和可见性。最新版本的 Spring 框架定义了 6 种作用域：  单身人士 原型 要求 会议 应用 网络套接字  最后提到的四个范围，request、session、application和websocket，仅在 web 感知应用程序中可用。 2. 单例范围 当我们使用单例范围定义 bean 时，容器会创建该 bean 的单个实例；对该 bean 名称的所有请求都将返回相同的对象，该对象被缓存。对对象的任何修改都将反映在对 bean 的所有引用中。如果未指定其他范围，则此范围是默认值。 让我们创建一个Person实体来举例说明作用域的概念： public class Person { private String name; // standard constructor, getters and setters } 之后，我们使用*@Scope注释定义具有单例*范围的 bean： @Bean @Scope(\u0026#34;singleton\u0026#34;) public Person personSingleton() { return new Person(); } 我们还可以通过以下方式使用常量而不是String值： @Scope(value = ConfigurableBeanFactory.SCOPE_SINGLETON) 现在我们可以继续编写一个测试，表明引用同一个 bean 的两个对象将具有相同的值，即使它们中只有一个改变了它们的状态，因为它们都引用了同一个 bean 实例： private static final String NAME = \u0026#34;John Smith\u0026#34;; @Test public void givenSingletonScope_whenSetName_thenEqualNames() { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;scopes.xml\u0026#34;); Person personSingletonA = (Person) applicationContext.getBean(\u0026#34;personSingleton\u0026#34;); Person personSingletonB = (Person) applicationContext.getBean(\u0026#34;personSingleton\u0026#34;); personSingletonA.setName(NAME); Assert.assertEquals(NAME, personSingletonB.getName()); ((AbstractApplicationContext) applicationContext).close(); } 此示例中的scopes.xml文件应包含所用 bean 的 xml 定义： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;personSingleton\u0026#34; class=\u0026#34;com.codingman.scopes.Person\u0026#34; scope=\u0026#34;singleton\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 3.原型范围 每次从容器请求时，具有原型作用域的 bean都会返回不同的实例。它是通过将值prototype设置为 bean 定义中的*@Scope*注解来定义的： @Bean @Scope(\u0026#34;prototype\u0026#34;) public Person personPrototype() { return new Person(); } 我们也可以像在单例作用域中那样使用常量： @Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE) 我们现在将编写一个与之前类似的测试，显示两个对象在 原型 范围内请求相同的 bean 名称。它们将具有不同的状态，因为它们不再引用同一个 bean 实例： private static final String NAME = \u0026#34;John Smith\u0026#34;; private static final String NAME_OTHER = \u0026#34;Anna Jones\u0026#34;; @Test public void givenPrototypeScope_whenSetNames_thenDifferentNames() { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;scopes.xml\u0026#34;); Person personPrototypeA = (Person) applicationContext.getBean(\u0026#34;personPrototype\u0026#34;); Person personPrototypeB = (Person) applicationContext.getBean(\u0026#34;personPrototype\u0026#34;); personPrototypeA.setName(NAME); personPrototypeB.setName(NAME_OTHER); Assert.assertEquals(NAME, personPrototypeA.getName()); Assert.assertEquals(NAME_OTHER, personPrototypeB.getName()); ((AbstractApplicationContext) applicationContext).close(); } scopes.xml文件类似于上一节中介绍的文件，同时为具有原型作用域的 bean 添加xml定义： \u0026lt;bean id=\u0026#34;personPrototype\u0026#34; class=\u0026#34;com.codingman.scopes.Person\u0026#34; scope=\u0026#34;prototype\u0026#34;/\u0026gt; 4. Web 感知范围 如前所述，有四个附加范围仅在 Web 感知应用程序上下文中可用。我们在实践中较少使用这些。 请求范围为单个 HTTP 请求创建一个 bean 实例，而 s会话范围为一个 HTTP 会话创建一个 bean 实例。 应用程序范围为ServletContext的生命周期创建 bean 实例，而websocket范围为特定的WebSocket会话创建它。 让我们创建一个用于实例化 bean 的类： public class HelloMessageGenerator { private String message; // standard getter and setter } 4.1。请求范围 我们可以使用*@Scope注释定义具有请求*范围的 bean： @Bean @Scope(value = WebApplicationContext.SCOPE_REQUEST, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator requestScopedBean() { return new HelloMessageGenerator(); } proxyMode属性是必要的*，*因为在 Web 应用程序上下文的实例化时刻，没有活动请求。Spring 创建一个代理作为依赖注入，并在请求中需要它时实例化目标 bean。 我们还可以使用*@RequestScope*组合注释作为上述定义的快捷方式： @Bean @RequestScope public HelloMessageGenerator requestScopedBean() { return new HelloMessageGenerator(); } 接下来，我们可以定义一个控制器，该控制器具有对requestScopedBean的注入引用。我们需要访问同一个请求两次以测试 Web 特定范围。 如果我们在每次运行请求时都显示该消息，我们可以看到该值被重置为**null，即使它后来在方法中被更改。这是因为每个请求都返回了不同的 bean 实例。 @Controller public class ScopesController { @Resource(name = \u0026#34;requestScopedBean\u0026#34;) HelloMessageGenerator requestScopedBean; @RequestMapping(\u0026#34;/scopes/request\u0026#34;) public String getRequestScopeMessage(final Model model) { model.addAttribute(\u0026#34;previousMessage\u0026#34;, requestScopedBean.getMessage()); requestScopedBean.setMessage(\u0026#34;Good morning!\u0026#34;); model.addAttribute(\u0026#34;currentMessage\u0026#34;, requestScopedBean.getMessage()); return \u0026#34;scopesExample\u0026#34;; } } 4.2. 会话范围 我们可以用类似的方式定义具有会话范围的 bean： @Bean @Scope(value = WebApplicationContext.SCOPE_SESSION, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator sessionScopedBean() { return new HelloMessageGenerator(); } 还有一个专用的组合注释，我们可以使用它来简化 bean 定义： @Bean @SessionScope public HelloMessageGenerator sessionScopedBean() { return new HelloMessageGenerator(); } 接下来我们定义一个引用sessionScopedBean的控制器。同样，我们需要运行两个请求以显示消息字段的值对于会话是相同的。 在这种情况下，当第一次发出请求时，值消息为*空。*但是，一旦更改，该值将保留给后续请求，因为为整个会话返回相同的 bean 实例。 @Controller public class ScopesController { @Resource(name = \u0026#34;sessionScopedBean\u0026#34;) HelloMessageGenerator sessionScopedBean; @RequestMapping(\u0026#34;/scopes/session\u0026#34;) public String getSessionScopeMessage(final Model model) { model.addAttribute(\u0026#34;previousMessage\u0026#34;, sessionScopedBean.getMessage()); sessionScopedBean.setMessage(\u0026#34;Good afternoon!\u0026#34;); model.addAttribute(\u0026#34;currentMessage\u0026#34;, sessionScopedBean.getMessage()); return \u0026#34;scopesExample\u0026#34;; } } 4.3. 适用范围 应用程序范围为ServletContext的生命周期创建 bean 实例。 这类似于单例范围，但在 bean 的范围方面有一个非常重要的区别。 当 bean 是应用程序作用域时，bean 的同一个实例在同一个**ServletContext中运行的多个基于 servlet 的应用程序之间共享，而单例作用域 bean 的作用域仅限于单个应用程序上下文。 让我们创建具有应用程序范围的 bean ： @Bean @Scope( value = WebApplicationContext.SCOPE_APPLICATION, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator applicationScopedBean() { return new HelloMessageGenerator(); } 类似于请求和会话范围，我们可以使用更短的版本： @Bean @ApplicationScope public HelloMessageGenerator applicationScopedBean() { return new HelloMessageGenerator(); } 现在让我们创建一个引用这个 bean 的控制器： @Controller public class ScopesController { @Resource(name = \u0026#34;applicationScopedBean\u0026#34;) HelloMessageGenerator applicationScopedBean; @RequestMapping(\u0026#34;/scopes/application\u0026#34;) public String getApplicationScopeMessage(final Model model) { model.addAttribute(\u0026#34;previousMessage\u0026#34;, applicationScopedBean.getMessage()); applicationScopedBean.setMessage(\u0026#34;Good afternoon!\u0026#34;); model.addAttribute(\u0026#34;currentMessage\u0026#34;, applicationScopedBean.getMessage()); return \u0026#34;scopesExample\u0026#34;; } } 在这种情况下，一旦在applicationScopedBean中设置，值消息将保留给所有后续请求、会话，甚至对于将访问此 bean 的不同 servlet 应用程序，只要它在相同的ServletContext 中运行。 4.4. WebSocket 范围 最后，让我们使用websocket范围创建 bean ： @Bean @Scope(scopeName = \u0026#34;websocket\u0026#34;, proxyMode = ScopedProxyMode.TARGET_CLASS) public HelloMessageGenerator websocketScopedBean() { return new HelloMessageGenerator(); } 首次访问时，WebSocket范围的 bean 存储在WebSocket会话属性中。每当在整个WebSocket会话期间访问该 bean 时，都会返回该 bean 的相同实例。 我们也可以说它表现出单例行为，但仅限于WebSocket**会话。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_bean_scopes/","tags":["Spring Annotations","Spring Core Basics"],"title":"Spring Bean 范围快速指南"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将讨论用于定义不同类型bean的最常见的 Spring bean 注释。 有几种方法可以在 Spring 容器中配置 bean。首先，我们可以使用 XML 配置声明它们。我们还可以在配置类中使用*@Bean*注解来声明 bean。 最后，我们可以使用org.springframework.stereotype包中的注释之一标记该类，并将其余部分留给组件扫描。 2. 组件扫描 如果启用了组件扫描，Spring可以自动扫描包中的bean。 @ComponentScan配置要扫描哪些包以查找具有注释配置的类。我们可以使用basePackages或value参数之一直接指定基本包名称（value是basePackages的别名）： @Configuration @ComponentScan(basePackages = \u0026#34;com.codingman.annotations\u0026#34;) class VehicleFactoryConfig {} 此外，我们可以使用basePackageClasses参数指向基础包中的类： @Configuration @ComponentScan(basePackageClasses = VehicleFactoryConfig.class) class VehicleFactoryConfig {} 这两个参数都是数组，因此我们可以为每个参数提供多个包。 如果未指定参数，则扫描从存在*@ComponentScan*注释类的同一包中进行。 @ComponentScan利用了 Java 8 的重复注解特性，这意味着我们可以用它多次标记一个类： @Configuration @ComponentScan(basePackages = \u0026#34;com.codingman.annotations\u0026#34;) @ComponentScan(basePackageClasses = VehicleFactoryConfig.class) class VehicleFactoryConfig {} 或者，我们可以使用*@ComponentScans指定多个@ComponentScan*配置： @Configuration @ComponentScans({ @ComponentScan(basePackages = \u0026#34;com.codingman.annotations\u0026#34;), @ComponentScan(basePackageClasses = VehicleFactoryConfig.class) }) class VehicleFactoryConfig {} 使用XML 配置时，配置组件扫描同样简单： \u0026lt;context:component-scan base-package=\u0026#34;com.codingman\u0026#34; /\u0026gt; 3. @Component @Component是一个类级别的注解。在组件扫描期间，Spring Framework 会自动检测带有@Component的类： @Component class CarUtility { // ... } 默认情况下，此类的 bean 实例与具有小写首字母的类名称具有相同的名称。此外，我们可以使用此注解的可选value参数指定不同的名称。 由于*@Repository*、@Service、@Configuration和*@Controller都是@Component*的元注释，它们共享相同的 bean 命名行为。Spring 还会在组件扫描过程中自动拾取它们。 4. @Repository DAO 或 Repository 类通常代表应用程序中的数据库访问层，应使用*@Repository 进行注释：* @Repository class VehicleRepository { // ... } 使用此注释的一个优点是它启用了自动持久性异常转换。当使用持久性框架（例如 Hibernate）时，在带有*@Repository注释的类中抛出的本机异常将自动转换为 Spring 的DataAccessExeption*的子类。 要启用异常翻译，我们需要声明我们自己的PersistenceExceptionTranslationPostProcessor bean： @Bean public PersistenceExceptionTranslationPostProcessor exceptionTranslation() { return new PersistenceExceptionTranslationPostProcessor(); } 请注意，在大多数情况下，Spring 会自动执行上述步骤。 或者通过 XML 配置： \u0026lt;bean class= \u0026#34;org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\u0026#34;/\u0026gt; 5. @Service 应用程序的业务逻辑通常驻留在服务层中，因此我们将使用*@Service*来指示一个类属于该层： @Service public class VehicleService { // ... } 6. @Controller @Controller是一个类级别的注解，它告诉 Spring Framework 这个类作为Spring MVC 中的一个控制器： @Controller public class VehicleController { // ... } 7. @Configuration Configuration类包含使用*@Bean*注解的bean 定义方法： @Configuration class VehicleFactoryConfig { @Bean Engine engine() { return new Engine(); } } 8. 原型注解和AOP 当我们使用Spring原型注解时，很容易创建一个指向所有具有特定原型的类的切入点。 例如，假设我们想从 DAO 层测量方法的执行时间。我们将利用*@Repository*原型创建以下方面（使用AspectJ 注释）： @Aspect @Component public class PerformanceAspect { @Pointcut(\u0026#34;within(@org.springframework.stereotype.Repository *)\u0026#34;) public void repositoryClassMethods() {}; @Around(\u0026#34;repositoryClassMethods()\u0026#34;) public Object measureMethodExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable { long start = System.nanoTime(); Object returnValue = joinPoint.proceed(); long end = System.nanoTime(); String methodName = joinPoint.getSignature().getName(); System.out.println( \u0026#34;Execution of \u0026#34; + methodName + \u0026#34; took \u0026#34; + TimeUnit.NANOSECONDS.toMillis(end - start) + \u0026#34; ms\u0026#34;); return returnValue; } } 在此示例中，我们创建了一个切入点，该切入点匹配使用*@Repository注释的类中的所有方法。然后我们使用@Around*通知来定位那个切入点，并确定被拦截方法调用的执行时间。 此外，使用这种方法，我们可以将日志记录、性能管理、审计和其他行为添加到每个应用程序层。\u0026quot; ","permalink":"http://itcodingman.github.io/spring_bean_annotations/","tags":["Spring Core Basics"],"title":"Spring Bean 注解"},{"categories":["Spring"],"contents":"1. 概述 Bean 是 Spring Framework 的一个关键概念。因此，理解这个概念对于掌握框架并以有效的方式使用它至关重要。 不幸的是，**对于 Spring bean 究竟是什么这个简单问题，并没有明确的答案。**一些解释太低了以至于错过了大局，而另一些解释太模糊了。 本教程将尝试阐明该主题，从官方文档中的描述开始。 2. bean定义 这是Spring Framework 文档中 bean 的定义 ： 在 Spring 中，构成应用程序主干并由 Spring IoC 容器管理的对象称为 bean。bean 是由 Spring IoC 容器实例化、组装和管理的对象。 这个定义简洁明了，**但没有详细说明一个重要元素：Spring IoC 容器。**让我们仔细看看它是什么以及它带来的好处。 3. 控制反转 简单地说，控制反转(IoC) 是**一个对象定义其依赖关系而不创建它们的过程。**该对象将构建此类依赖项的工作委托给 IoC 容器。 在深入研究 IoC 之前，让我们先声明几个域类。 3.1 领域类 假设我们有一个类声明： public class Company { private Address address; public Company(Address address) { this.address = address; } // getter, setter and other properties } 这个类需要一个 Address类型的协作者： public class Address { private String street; private int number; public Address(String street, int number) { this.street = street; this.number = number; } // getters and setters } 3.2 传统方法 通常，我们使用类的构造函数创建对象： Address address = new Address(\u0026#34;High Street\u0026#34;, 1000); Company company = new Company(address); 这种方法没有任何问题，但是以更好的方式管理依赖关系不是很好吗？ 想象一个有几十个甚至几百个类的应用程序。有时我们希望在整个应用程序中共享一个类的单个实例，有时我们需要为每个用例提供一个单独的对象，等等。 管理如此多的对象简直就是一场噩梦。这就是控制反转来拯救的地方。 对象可以从 IoC 容器中检索其依赖项，而不是自己构建依赖项。我们需要做的就是为容器提供适当的配置元数据。 3.3 Bean配置 首先，让我们用*@Component注解来装饰Company类：* @Component public class Company { // this body is the same as before } 这是一个向 IoC 容器提供 bean 元数据的配置类： @Configuration @ComponentScan(basePackageClasses = Company.class) public class Config { @Bean public Address getAddress() { return new Address(\u0026#34;High Street\u0026#34;, 1000); } } 配置类产生一个 Address类型的 bean 。它还带有*@ComponentScan注释，它指示容器在包含Company*类的包中查找 bean。 当 Spring IoC 容器构造这些类型的对象时，所有对象都称为 Spring bean，因为它们由 IoC 容器管理。 3.4 IoC 由于我们在配置类中定义了 bean，我们需要AnnotationConfigApplicationContext类的实例来构建容器： ApplicationContext context = new AnnotationConfigApplicationContext(Config.class); 快速测试验证我们的 bean 的存在和属性值： Company company = context.getBean(\u0026#34;company\u0026#34;, Company.class); assertEquals(\u0026#34;High Street\u0026#34;, company.getAddress().getStreet()); assertEquals(1000, company.getAddress().getNumber()); 结果证明 IoC 容器已经正确地创建和初始化了 bean。 \u0026quot; ","permalink":"http://itcodingman.github.io/spring_bean/","tags":["Spring Core Basics","Spring DI"],"title":"什么是 Spring Bean"},{"categories":["Spring"],"contents":"1. 概述 从 Spring 2.5 开始，该框架引入了注解驱动的依赖注入。此功能的主要注释是*@Autowired* 。 它允许 Spring 解析协作 bean 并将其注入到我们的 bean 中。 在本教程中，我们将首先了解如何启用自动装配以及自动装配 bean 的 各种 方法。之后，我们将讨论使用**@Qualifier注解解决 bean 冲突**，以及潜在的异常情况。 2. 启用*@Autowired*注解 Spring 框架支持自动依赖注入。换句话说，通过在 Spring 配置文件中声明所有 bean 依赖项，Spring 容器可以自动装配协作 bean 之间的关系。这称为Spring bean 自动装配。 要在我们的应用程序中使用基于 Java 的配置，让我们启用注解驱动注入 来加载我们的 Spring 配置： @Configuration @ComponentScan(\u0026#34;com.codingman.autowire.sample\u0026#34;) public class AppConfig {} 或者，注解主要用于激活 Spring XML 文件中的依赖注入注解。 此外，Spring Boot 引入了@SpringBootApplication注解。此单个注释等效于使用*@Configuration*、@EnableAutoConfiguration和 @ComponentScan。 让我们在应用程序的主类中使用这个注解： @SpringBootApplication class VehicleFactoryApplication { public static void main(String[] args) { SpringApplication.run(VehicleFactoryApplication.class, args); } } 因此，当我们运行这个 Spring Boot 应用程序时，它会自动扫描当前包及其子包中的组件。因此它将在 Spring 的应用程序上下文中注册它们，并允许我们使用*@Autowired*注入 bean 。 3. 使用*@Autowired* 启用注解注入后，我们可以对属性、设置器和构造器使用自动装配。 3.1 @Autowired属性 让我们看看如何使用*@Autowired*注释属性。这消除了对 getter 和 setter 的需要。 首先，让我们定义一个fooFormatter bean： @Component(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter { public String format() { return \u0026#34;foo\u0026#34;; } } 然后，我们将在字段定义上使用*@Autowired将此 bean 注入FooService bean：* @Component public class FooService { @Autowired private FooFormatter fooFormatter; } 因此，Spring在创建FooService时会注入fooFormatter。 3.2. 设置器上的@Autowired 现在让我们尝试在 setter 方法上添加*@Autowired注解。* 在以下示例中，在创建FooService时使用FooFormatter的实例调用 setter 方法： public class FooService { private FooFormatter fooFormatter; @Autowired public void setFooFormatter(FooFormatter fooFormatter) { this.fooFormatter = fooFormatter; } } 3.3. @Autowired在构造函数上 最后，让我们在构造函数上使用*@Autowired*。 我们将看到Spring 将 FooFormatter 的实例作为FooService**构造函数的参数注入： public class FooService { private FooFormatter fooFormatter; @Autowired public FooService(FooFormatter fooFormatter) { this.fooFormatter = fooFormatter; } } 4. @Autowired和可选依赖 构建 bean 时，@Autowired依赖项应该可用。否则，如果 Spring 无法解析 bean 进行布线，它将抛出异常。 因此，它会阻止 Spring 容器成功启动，但以下形式除外： Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.autowire.sample.FooDAO] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} 为了解决这个问题，我们需要声明一个所需类型的 bean： public class FooService { @Autowired(required = false) private FooDAO dataAccessor; } 5. Autowire歧义 默认情况下，Spring 按类型解析*@Autowired*条目。如果容器中有多个相同类型的 bean 可用，框架将抛出一个致命异常。 为了解决这个冲突，我们需要明确地告诉 Spring 我们要注入哪个bean。 5.1 @Qualifier自动装配 例如，让我们看看如何使用@Qualifier注解来指示所需的 bean。 首先，我们将定义 2 个Formatter类型的 bean ： @Component(\u0026#34;fooFormatter\u0026#34;) public class FooFormatter implements Formatter { public String format() { return \u0026#34;foo\u0026#34;; } } @Component(\u0026#34;barFormatter\u0026#34;) public class BarFormatter implements Formatter { public String format() { return \u0026#34;bar\u0026#34;; } } 现在让我们尝试将Formatter bean 注入FooService类： public class FooService { @Autowired private Formatter formatter; } 在我们的示例中，有两个可用于 Spring 容器的Formatter的具体实现。因此， Spring 在构造FooService时会抛出NoUniqueBeanDefinitionException异常： Caused by: org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type [com.autowire.sample.Formatter] is defined: expected single matching bean but found 2: barFormatter,fooFormatter 我们可以通过使用@Qualifier注解缩小实现范围来避免这种情况： public class FooService { @Autowired @Qualifier(\u0026#34;fooFormatter\u0026#34;) private Formatter formatter; } 当有多个相同类型的 bean 时，最好使用@Qualifier来避免歧义。 请注意，@Qualifier 注释的值与我们的FooFormatter实现的*@Component*注释中声明的名称匹配。 5.2 通过自定义限定符自动装配 Spring 还允许我们创建自己的自定义@Qualifier注释。为此，我们应该提供带有定义的*@Qualifier*注释： @Qualifier @Target({ ElementType.FIELD, ElementType.METHOD, ElementType.TYPE, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) public @interface FormatterType { String value(); } 然后我们可以在各种实现中使用FormatterType 来指定自定义值： @FormatterType(\u0026#34;Foo\u0026#34;) @Component public class FooFormatter implements Formatter { public String format() { return \u0026#34;foo\u0026#34;; } } @FormatterType(\u0026#34;Bar\u0026#34;) @Component public class BarFormatter implements Formatter { public String format() { return \u0026#34;bar\u0026#34;; } } 最后，我们的自定义 Qualifier 注解已准备好用于自动装配： @Component public class FooService { @Autowired @FormatterType(\u0026#34;Foo\u0026#34;) private Formatter formatter; } @Target元注释中指定的值限制了应用限定符的位置，在我们的示例中是字段、方法、类型和参数。 5.3. 按名称自动装配 **Spring 使用 bean 的名称作为默认限定符值。**它将检查容器并查找具有确切名称的 bean 作为属性来自动装配它。 因此，在我们的示例中，Spring 将fooFormatter属性名称与FooFormatter实现相匹配。因此，它在构造FooService时注入了该特定实现： public class FooService { @Autowired private Formatter fooFormatter; } \u0026quot; ","permalink":"http://itcodingman.github.io/spring_autowired/","tags":["Spring DI","Spring Core Basics"],"title":"Spring @Autowired 指南"},{"categories":["Spring"],"contents":"1. 概述 在本 Spring Framework 教程中，我们将演示如何使用与依赖注入相关的注解，即*@Resource*、@Inject和*@Autowired*注解。这些注解为类提供了一种声明性的方式来解决依赖关系： @Autowired ArbitraryClass arbObject; 与直接实例化它们相反（命令式）： ArbitraryClass arbObject = new ArbitraryClass(); 三个注解中有两个属于 Java 扩展包：javax.annotation.Resource和javax.inject.Inject。@Autowired注解属于org.springframework.beans.factory.annotation包。 这些注解中的每一个都可以通过字段注入或 setter 注入来解决依赖关系。我们将使用一个简化但实用的示例来演示三个注释之间的区别，基于每个注释所采用的执行路径。 示例将重点介绍如何在集成测试期间使用三个注入注解。测试所需的依赖可以是任意文件或任意类。 2. @Resource注解 @Resource注释是JSR-250注释集合的一部分，并与 Jakarta EE 一起打包。此注解具有以下执行路径，按优先级列出：  按名称匹配 按类型匹配 按限定词匹配  这些执行路径适用于 setter 和 field 注入。 2.1 现场注入 我们可以通过使用@Resource注释来注释实例变量来通过字段注入来解决依赖关系。 2.1.1 按名称匹配 我们将使用以下集成测试来演示按名称匹配字段注入： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceNameType.class) public class FieldResourceInjectionIntegrationTest { @Resource(name=\u0026#34;namedFile\u0026#34;) private File defaultFile; @Test public void givenResourceAnnotation_WhenOnField_ThenDependencyValid(){ assertNotNull(defaultFile); assertEquals(\u0026#34;namedFile.txt\u0026#34;, defaultFile.getName()); } } 让我们看一下代码。在FieldResourceInjectionTest集成测试中，在第 7 行，我们通过将 bean 名称作为属性值传递给*@Resource*注释来按名称解析依赖项： @Resource(name=\u0026#34;namedFile\u0026#34;) private File defaultFile; 此配置将使用按名称匹配执行路径解析依赖关系。我们必须在ApplicationContextTestResourceNameType应用程序上下文中定义 bean namedFile 。 注意 bean id 和对应的引用属性值必须匹配： @Configuration public class ApplicationContextTestResourceNameType { @Bean(name=\u0026#34;namedFile\u0026#34;) public File namedFile() { File namedFile = new File(\u0026#34;namedFile.txt\u0026#34;); return namedFile; } } 如果我们未能在应用程序上下文中定义 bean，它将导致org.springframework.beans.factory.NoSuchBeanDefinitionException被抛出。我们可以通过更改ApplicationContextTestResourceNameType应用程序上下文中传递给**@Bean注解的属性值，或者更改FieldResourceInjectionTest集成测试中传递给*@Resource*注解的属性值来证明这一点。 2.1.2 按类型匹配 为了演示按类型匹配的执行路径，我们只删除FieldResourceInjectionTest集成测试第 7 行的属性值： @Resource private File defaultFile; 然后我们再次运行测试。 测试仍然会通过，因为如果*@Resource*注释没有接收到 bean 名称作为属性值，Spring 框架将继续进行下一级优先级，按类型匹配，以尝试解决依赖关系。 2.1.3 按限定词匹配 为了演示 match-by-qualifier 执行路径，将修改集成测试场景，以便在ApplicationContextTestResourceQualifier应用程序上下文中定义两个 bean： @Configuration public class ApplicationContextTestResourceQualifier { @Bean(name=\u0026#34;defaultFile\u0026#34;) public File defaultFile() { File defaultFile = new File(\u0026#34;defaultFile.txt\u0026#34;); return defaultFile; } @Bean(name=\u0026#34;namedFile\u0026#34;) public File namedFile() { File namedFile = new File(\u0026#34;namedFile.txt\u0026#34;); return namedFile; } } 我们将使用QualifierResourceInjectionTest集成测试来演示逐个匹配的依赖关系解析。在这种情况下，需要将特定的 bean 依赖注入到每个引用变量中： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceQualifier.class) public class QualifierResourceInjectionIntegrationTest { @Resource private File dependency1; @Resource private File dependency2; @Test public void givenResourceAnnotation_WhenField_ThenDependency1Valid(){ assertNotNull(dependency1); assertEquals(\u0026#34;defaultFile.txt\u0026#34;, dependency1.getName()); } @Test public void givenResourceQualifier_WhenField_ThenDependency2Valid(){ assertNotNull(dependency2); assertEquals(\u0026#34;namedFile.txt\u0026#34;, dependency2.getName()); } } 当我们运行集成测试时，会抛出org.springframework.beans.factory.NoUniqueBeanDefinitionException 。**这会发生，因为应用程序上下文将找到两个类型为File的 bean 定义，并且不知道哪个 bean 应该解决依赖关系。 要解决这个问题，我们需要参考QualifierResourceInjectionTest集成测试的第 7 行到第 10 行： @Resource private File dependency1; @Resource private File dependency2; 我们必须添加以下代码行： @Qualifier(\u0026#34;defaultFile\u0026#34;) @Qualifier(\u0026#34;namedFile\u0026#34;) 使代码块如下所示： @Resource @Qualifier(\u0026#34;defaultFile\u0026#34;) private File dependency1; @Resource @Qualifier(\u0026#34;namedFile\u0026#34;) private File dependency2; 当我们再次运行集成测试时，它应该会通过。我们的测试表明，即使我们在应用程序上下文中定义了多个 bean，我们也可以使用*@Qualifier*注释通过允许我们将特定的依赖项注入到一个类中来消除任何混淆。 2.2 Setter注入 在字段上注入依赖项时所采用的执行路径也适用于基于 setter 的注入。 2.2.1 按名称匹配 唯一的区别是MethodResourceInjectionTest集成测试有一个 setter 方法： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceNameType.class) public class MethodResourceInjectionIntegrationTest { private File defaultFile; @Resource(name=\u0026#34;namedFile\u0026#34;) protected void setDefaultFile(File defaultFile) { this.defaultFile = defaultFile; } @Test public void givenResourceAnnotation_WhenSetter_ThenDependencyValid(){ assertNotNull(defaultFile); assertEquals(\u0026#34;namedFile.txt\u0026#34;, defaultFile.getName()); } } 我们通过注解引用变量的相应 setter 方法，通过 setter 注入来解决依赖关系。然后我们将bean依赖的名称作为属性值传递给*@Resource*注解： private File defaultFile; @Resource(name=\u0026#34;namedFile\u0026#34;) protected void setDefaultFile(File defaultFile) { this.defaultFile = defaultFile; } 在本例中，我们将重用namedFile bean 依赖项。bean 名称和相应的属性值必须匹配。 当我们运行集成测试时，它将通过。 为了让我们验证按名称匹配执行路径是否解决了依赖关系，我们需要将传递给*@Resource注解的属性值更改为我们选择的值并再次运行测试。这一次，测试将失败并出现NoSuchBeanDefinitionException*。 2.2.2 按类型匹配 为了演示基于 setter、按类型匹配的执行，我们将使用MethodByTypeResourceTest集成测试： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceNameType.class) public class MethodByTypeResourceIntegrationTest { private File defaultFile; @Resource protected void setDefaultFile(File defaultFile) { this.defaultFile = defaultFile; } @Test public void givenResourceAnnotation_WhenSetter_ThenValidDependency(){ assertNotNull(defaultFile); assertEquals(\u0026#34;namedFile.txt\u0026#34;, defaultFile.getName()); } } 当我们运行这个测试时，它会通过。 为了让我们验证按类型匹配的执行路径是否解决了File依赖关系，我们需要将defaultFile变量的类类型更改为另一个类类型，如String。然后我们可以再次执行MethodByTypeResourceTest集成测试，这次会抛出NoSuchBeanDefinitionException 。 该异常验证是否确实使用了按类型匹配来解决文件依赖关系。NoSuchBeanDefinitionException确认引用变量名称不需要与 bean 名称匹配。相反，依赖解析取决于 bean 的类类型与引用变量的类类型匹配。 2.2.3 按限定词匹配 我们将使用MethodByQualifierResourceTest集成测试来演示 match-by-qualifier 执行路径： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestResourceQualifier.class) public class MethodByQualifierResourceIntegrationTest { private File arbDependency; private File anotherArbDependency; @Test public void givenResourceQualifier_WhenSetter_ThenValidDependencies(){ assertNotNull(arbDependency); assertEquals(\u0026#34;namedFile.txt\u0026#34;, arbDependency.getName()); assertNotNull(anotherArbDependency); assertEquals(\u0026#34;defaultFile.txt\u0026#34;, anotherArbDependency.getName()); } @Resource @Qualifier(\u0026#34;namedFile\u0026#34;) public void setArbDependency(File arbDependency) { this.arbDependency = arbDependency; } @Resource @Qualifier(\u0026#34;defaultFile\u0026#34;) public void setAnotherArbDependency(File anotherArbDependency) { this.anotherArbDependency = anotherArbDependency; } } 我们的测试表明，即使我们在应用程序上下文中定义了特定类型的多个 bean 实现，我们也可以使用*@Qualifier注释和@Resource*注释来解决依赖关系。 类似于基于字段的依赖注入，如果我们在一个应用上下文中定义多个bean，我们必须使用 @Qualifier 注解来指定使用哪个bean来解析依赖，否则会抛出NoUniqueBeanDefinitionException 。 3. @Inject注解 @Inject注解属于JSR-330注解集合。此注解具有以下执行路径，按优先级列出：  按类型匹配 按预选赛匹配 按名称匹配  这些执行路径适用于 setter 和 field 注入。为了让我们访问*@Inject注解，我们必须将javax.inject*库声明为 Gradle 或 Maven 依赖项。 对于 Gradle： testCompile group: \u0026#39;javax.inject\u0026#39;, name: \u0026#39;javax.inject\u0026#39;, version: \u0026#39;1\u0026#39; 对于 Maven： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.inject\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.inject\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.1 现场注入 3.1.1 按类型匹配 我们将修改集成测试示例以使用另一种类型的依赖项，即ArbitraryDependency类。ArbitraryDependency类依赖仅作为一个简单的依赖，并没有进一步的意义： @Component public class ArbitraryDependency { private final String label = \u0026#34;Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 这是有问题的FieldInjectTest集成测试： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestInjectType.class) public class FieldInjectIntegrationTest { @Inject private ArbitraryDependency fieldInjectDependency; @Test public void givenInjectAnnotation_WhenOnField_ThenValidDependency(){ assertNotNull(fieldInjectDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, fieldInjectDependency.toString()); } } 与*@Resource注解首先按名称解析依赖关系不同，@* Inject注解的默认行为是按类型解析依赖关系。 这意味着即使类引用变量名称与 bean 名称不同，依赖关系仍然会被解析，前提是 bean 是在应用程序上下文中定义的。请注意以下测试中引用变量名称的方式： @Inject private ArbitraryDependency fieldInjectDependency; 与应用程序上下文中配置的 bean 名称不同： @Bean public ArbitraryDependency injectDependency() { ArbitraryDependency injectDependency = new ArbitraryDependency(); return injectDependency; } 当我们执行测试时，我们能够解决依赖关系。 3.1.2 按限定词匹配 如果一个特定的类类型有多个实现，并且某个类需要一个特定的 bean，该怎么办？让我们修改集成测试示例，使其需要另一个依赖项。 在此示例中，我们将ArbitraryDependency类（在按类型匹配示例中使用）进行子类化，以创建AnotherArbitraryDependency类： public class AnotherArbitraryDependency extends ArbitraryDependency { private final String label = \u0026#34;Another Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 每个测试用例的目标是确保我们将每个依赖项正确地注入每个引用变量中： @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; 我们可以使用FieldQualifierInjectTest集成测试来演示限定符匹配： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestInjectQualifier.class) public class FieldQualifierInjectIntegrationTest { @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; @Test public void givenInjectQualifier_WhenOnField_ThenDefaultFileValid(){ assertNotNull(defaultDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, defaultDependency.toString()); } @Test public void givenInjectQualifier_WhenOnField_ThenNamedFileValid(){ assertNotNull(defaultDependency); assertEquals(\u0026#34;Another Arbitrary Dependency\u0026#34;, namedDependency.toString()); } } 如果我们在应用程序上下文中有多个特定类的实现，并且FieldQualifierInjectTest集成测试尝试以下面列出的方式注入依赖项，则会抛出NoUniqueBeanDefinitionException ： @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; 抛出这个异常是 Spring 框架指出某个类有多个实现的方式，它对使用哪一个感到困惑。为了阐明混淆，我们可以转到FieldQualifierInjectTest集成测试的第 7 行和第 10 行： @Inject private ArbitraryDependency defaultDependency; @Inject private ArbitraryDependency namedDependency; 我们可以将所需的 bean 名称传递给*@Qualifier注释，我们将其与@Inject*注释一起使用。这就是代码块现在的样子： @Inject @Qualifier(\u0026#34;defaultFile\u0026#34;) private ArbitraryDependency defaultDependency; @Inject @Qualifier(\u0026#34;namedFile\u0026#34;) private ArbitraryDependency namedDependency; @Qualifier注解在接收 bean 名称时要求严格匹配。我们必须确保将 bean 名称正确传递给Qualifier，否则将抛出*NoUniqueBeanDefinitionException 。*如果我们再次运行测试，它应该会通过。 3.1.3 按名称匹配 用于演示按名称匹配的FieldByNameInjectTest集成测试类似于按类型匹配执行路径。唯一的区别是现在我们需要一个特定的 bean，而不是一个特定的类型。在此示例中，我们再次对ArbitraryDependency类进行子类化以生成YetAnotherArbitraryDependency类： public class YetAnotherArbitraryDependency extends ArbitraryDependency { private final String label = \u0026#34;Yet Another Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 为了演示按名称匹配的执行路径，我们将使用以下集成测试： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestInjectName.class) public class FieldByNameInjectIntegrationTest { @Inject @Named(\u0026#34;yetAnotherFieldInjectDependency\u0026#34;) private ArbitraryDependency yetAnotherFieldInjectDependency; @Test public void givenInjectQualifier_WhenSetOnField_ThenDependencyValid(){ assertNotNull(yetAnotherFieldInjectDependency); assertEquals(\u0026#34;Yet Another Arbitrary Dependency\u0026#34;, yetAnotherFieldInjectDependency.toString()); } } 我们列出应用程序上下文： @Configuration public class ApplicationContextTestInjectName { @Bean public ArbitraryDependency yetAnotherFieldInjectDependency() { ArbitraryDependency yetAnotherFieldInjectDependency = new YetAnotherArbitraryDependency(); return yetAnotherFieldInjectDependency; } } 如果我们运行集成测试，它将通过。 为了验证我们是否通过按名称匹配执行路径注入了依赖项，我们需要将传入*@Named注释的值**yetAnotherFieldInjectDependency更改为我们选择的另一个名称。当我们再次运行测试时，会抛出NoSuchBeanDefinitionException 。* 3.2 Setter注入 @Inject注解的基于设置器的注入类似于用于基于*@Resource*设置器的注入的方法。我们不是注释引用变量，而是注释相应的 setter 方法。基于字段的依赖注入所遵循的执行路径也适用于基于 setter 的注入。 4. @Autowired注解 @Autowired注解的行为类似于*@Inject注解。唯一的区别是@Autowired*注解是 Spring 框架的一部分。此注解与@Inject注解具有相同的执行路径，按优先顺序列出：  按类型匹配 按限定词匹配 按名称匹配  这些执行路径适用于 setter 和 field 注入。 4.1 现场注入 4.1.1 按类型匹配 用于演示*@Autowired按类型匹配执行路径的集成测试示例将类似于用于演示@Inject按类型匹配执行路径的测试。我们使用以下FieldAutowiredTest集成测试来演示使用@Autowired*注释的按类型匹配： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestAutowiredType.class) public class FieldAutowiredIntegrationTest { @Autowired private ArbitraryDependency fieldDependency; @Test public void givenAutowired_WhenSetOnField_ThenDependencyResolved() { assertNotNull(fieldDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, fieldDependency.toString()); } } 我们列出了此集成测试的应用程序上下文： @Configuration public class ApplicationContextTestAutowiredType { @Bean public ArbitraryDependency autowiredFieldDependency() { ArbitraryDependency autowiredFieldDependency = new ArbitraryDependency(); return autowiredFieldDependency; } } 我们使用此集成测试来证明按类型匹配优先于其他执行路径。注意FieldAutowiredTest集成测试第 8 行的引用变量名称： @Autowired private ArbitraryDependency fieldDependency; 这与应用程序上下文中的 bean 名称不同： @Bean public ArbitraryDependency autowiredFieldDependency() { ArbitraryDependency autowiredFieldDependency = new ArbitraryDependency(); return autowiredFieldDependency; } 当我们运行测试时，它应该通过了。 为了确认依赖确实是使用 match-by-type 执行路径解决的，我们需要更改fieldDependency引用变量的类型并再次运行集成测试。这一次，FieldAutowiredTest集成测试将失败，并引发NoSuchBeanDefinitionException。这验证了我们使用了按类型匹配来解决依赖关系。 4.1.2 按限定词匹配 如果我们遇到在应用程序上下文中定义了多个 bean 实现的情况怎么办： @Configuration public class ApplicationContextTestAutowiredQualifier { @Bean public ArbitraryDependency autowiredFieldDependency() { ArbitraryDependency autowiredFieldDependency = new ArbitraryDependency(); return autowiredFieldDependency; } @Bean public ArbitraryDependency anotherAutowiredFieldDependency() { ArbitraryDependency anotherAutowiredFieldDependency = new AnotherArbitraryDependency(); return anotherAutowiredFieldDependency; } } 如果我们执行以下FieldQualifierAutowiredTest集成测试，将抛出NoUniqueBeanDefinitionException ： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestAutowiredQualifier.class) public class FieldQualifierAutowiredIntegrationTest { @Autowired private ArbitraryDependency fieldDependency1; @Autowired private ArbitraryDependency fieldDependency2; @Test public void givenAutowiredQualifier_WhenOnField_ThenDep1Valid(){ assertNotNull(fieldDependency1); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, fieldDependency1.toString()); } @Test public void givenAutowiredQualifier_WhenOnField_ThenDep2Valid(){ assertNotNull(fieldDependency2); assertEquals(\u0026#34;Another Arbitrary Dependency\u0026#34;, fieldDependency2.toString()); } } 异常是由于应用程序上下文中定义的两个 bean 引起的歧义。Spring 框架不知道哪个 bean 依赖项应该自动装配到哪个引用变量。我们可以通过在FieldQualifierAutowiredTest集成测试的第 7 行和第 10 行添加*@Qualifier*注释来解决此问题： @Autowired private FieldDependency fieldDependency1; @Autowired private FieldDependency fieldDependency2; 使代码块如下所示： @Autowired @Qualifier(\u0026#34;autowiredFieldDependency\u0026#34;) private FieldDependency fieldDependency1; @Autowired @Qualifier(\u0026#34;anotherAutowiredFieldDependency\u0026#34;) private FieldDependency fieldDependency2; 当我们再次运行测试时，它将通过。 4.1.3 按名称匹配 我们将使用相同的集成测试场景来演示使用@Autowired注释注入字段依赖项的按名称匹配执行路径。当按名称自动装配依赖项时，@ComponentScan注释必须与应用程序上下文ApplicationContextTestAutowiredName一起使用： @Configuration @ComponentScan(basePackages={\u0026#34;com.codingman.dependency\u0026#34;}) public class ApplicationContextTestAutowiredName { } 我们使用*@ComponentScan注解在包中搜索已使用@Component 注解进行注解的Java类*。例如，在应用程序上下文中，将扫描com.codingman.dependency包以查找已使用*@Component注释进行注释的类。在这种情况下，Spring 框架必须检测带有@Component注解的ArbitraryDependency*类： @Component(value=\u0026#34;autowiredFieldDependency\u0026#34;) public class ArbitraryDependency { private final String label = \u0026#34;Arbitrary Dependency\u0026#34;; public String toString() { return label; } } 传递到*@Component注释的属性值autowiredFieldDependency告诉 Spring 框架ArbitraryDependency类是一个名为autowiredFieldDependency的组件。为了让@Autowired注解通过名称解析依赖，组件名称必须与FieldAutowiredNameTest*集成测试中定义的字段名称相对应；请参考第8行： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( loader=AnnotationConfigContextLoader.class, classes=ApplicationContextTestAutowiredName.class) public class FieldAutowiredNameIntegrationTest { @Autowired private ArbitraryDependency autowiredFieldDependency; @Test public void givenAutowiredAnnotation_WhenOnField_ThenDepValid(){ assertNotNull(autowiredFieldDependency); assertEquals(\u0026#34;Arbitrary Dependency\u0026#34;, autowiredFieldDependency.toString()); } } 当我们运行FieldAutowiredNameTest集成测试时，它将通过。 但是我们怎么知道*@Autowired注解确实调用了按名称匹配的执行路径呢？我们可以将引用变量autowiredFieldDependency*的名称更改为我们选择的另一个名称，然后再次运行测试。 这一次，测试将失败并抛出NoUniqueBeanDefinitionException。类似的检查是将*@Component属性值autowiredFieldDependency更改为我们选择的另一个值并再次运行测试。NoUniqueBeanDefinitionException也会*被抛出。 这个异常证明如果我们使用不正确的 bean 名称，将找不到有效的 bean。这就是我们知道调用了按名称匹配执行路径的方式。 4.2. Setter注入 @Autowired注解的基于设置器的注入类似于为基于*@Resource*设置器的注入演示的方法。我们不是用@Inject注解来注解引用变量，而是注解对应的setter。基于字段的依赖注入所遵循的执行路径也适用于基于 setter 的注入。 5. 应用这些注释 这就提出了应该使用哪种注释以及在什么情况下使用的问题。这些问题的答案取决于相关应用程序面临的设计场景，以及开发人员希望如何利用基于每个注释的默认执行路径的多态性。 5.1 通过多态性在应用程序范围内使用单例 如果设计是这样的应用程序行为基于接口或抽象类的实现，并且这些行为在整个应用程序中使用，那么我们可以使用*@Inject或@Autowired*注解。 这种方法的好处是，当我们升级应用程序或应用补丁来修复错误时，可以将类换出，而对整体应用程序行为的负面影响最小。在这种情况下，主要的默认执行路径是按类型匹配。 5.2 通过多态进行细粒度的应用程序行为配置 如果设计使得应用程序具有复杂的行为，每个行为都基于不同的接口/抽象类，并且这些实现中的每一个的使用因应用程序而异，那么我们可以使用*@Resource*注解。在这种情况下，主要的默认执行路径是按名称匹配。 5.3 依赖注入应该由 Jakarta EE 平台单独处理 如果 Jakarta EE 平台而不是 Spring 注入所有依赖项的设计要求，那么选择是在*@Resource注释和@Inject*注释之间进行选择。我们应该根据需要哪个默认执行路径来缩小两个注释之间的最终决定。 5.4 依赖注入应该由 Spring 框架单独处理 如果要求所有依赖项都由 Spring 框架处理，则唯一的选择是*@Autowired*注释。 5.5 讨论总结 下表总结了我们的讨论。    场景 @Resource @Inject @Autowired     通过多态性在应用程序范围内使用单例 ✗ ✔ ✔   通过多态进行细粒度的应用程序行为配置 ✔ ✗ ✗   依赖注入由 Jakarta EE 平台单独处理 ✔ ✔ ✗   依赖注入由 Spring Framework 单独处理 ✗ ✗ ✔   \u0026quot;       ","permalink":"http://itcodingman.github.io/spring_annotations_resource_inject_autowire/","tags":["Spring DI","Spring Core Basics"],"title":"Spring 中的注解：@Autowired、@Resource 和 @Inject"},{"categories":["Spring Security"],"contents":"1、概述 在本教程中，我们将使用 OAuth2 保护 REST API，并从一个简单的 Angular 客户端使用它。 我们要构建的应用程序将包含三个独立的模块：  授权服务器 资源服务器 UI 授权码：使用授权码流程的前端应用程序  **我们将在 Spring Security 5 中使用 OAuth 堆栈。**如果您想使用 Spring Security OAuth legacy stack，请查看之前的这篇文章：Spring REST API + OAuth2 + Angular（使用 Spring Security OAuth Legacy Stack）。 2. OAuth2授权服务器（AS） 简单地说，授权服务器是一个发布授权令牌的应用程序。 以前，Spring Security OAuth 堆栈提供了将授权服务器设置为 Spring 应用程序的可能性。但该项目已被弃用，主要是因为 OAuth 是一个开放标准，拥有许多成熟的供应商，例如 Okta、Keycloak 和 ForgeRock，仅举几例。 其中，我们将使用Keycloak。它是由 Red Hat 管理的开源身份和访问管理服务器，由 JBoss 用 Java 开发。它不仅支持 OAuth2，还支持其他标准协议，例如 OpenID Connect 和 SAML。 对于本教程，我们将在 Spring Boot 应用程序中设置嵌入式 Keycloak 服务器。 3. 资源服务器（RS） 现在让我们讨论资源服务器；这本质上是 REST API，我们最终希望能够使用它。 3.1 Maven 配置 我们的资源服务器的 pom 与之前的授权服务器 pom 非常相似，没有 Keycloak 部分，并具有额外的spring-boot-starter-oauth2-resource-server依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-oauth2-resource-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 3.2 安全配置 由于我们使用的是 Spring Boot，因此我们可以使用 Boot 属性定义所需的最低配置。 我们将在application.yml文件中执行此操作： server: port: 8081 servlet: context-path: /resource-server spring: security: oauth2: resourceserver: jwt: issuer-uri: http://localhost:8083/auth/realms/codingman jwk-set-uri: http://localhost:8083/auth/realms/codingman/protocol/openid-connect/certs 在这里，我们指定我们将使用 JWT 令牌进行授权。 jwk *-set-uri*属性指向包含公钥的 URI，以便我们的资源服务器可以验证令牌的完整性。 issuer-uri属性表示验证令牌颁发者（即授权服务器）的附加安全措施。但是，添加此属性还要求授权服务器应该在我们启动资源服务器应用程序之前运行。 接下来，让我们为 API 设置安全配置以保护端点： @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors() .and() .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/user/info\u0026#34;, \u0026#34;/api/foos/**\u0026#34;) .hasAuthority(\u0026#34;SCOPE_read\u0026#34;) .antMatchers(HttpMethod.POST, \u0026#34;/api/foos\u0026#34;) .hasAuthority(\u0026#34;SCOPE_write\u0026#34;) .anyRequest() .authenticated() .and() .oauth2ResourceServer() .jwt(); } } 正如我们所见，对于我们的 GET 方法，我们只允许具有读取范围的请求。对于 POST 方法，请求者除了read之外还需要有写权限。但是，对于任何其他端点，该请求应该只通过任何用户进行身份验证。 此外，**oauth2ResourceServer *()***方法指定这是一个资源服务器，带有*jwt()*格式的令牌。 这里要注意的另一点是使用方法*cors()*来允许请求上的 Access-Control 标头。这一点尤其重要，因为我们正在处理一个 Angular 客户端，并且我们的请求将来自另一个源 URL。 3.4 模型和存储库 接下来，让我们为我们的模型Foo定义一个javax.persistence.Entity： @Entity public class Foo { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; // constructor, getters and setters } 然后我们需要一个Foo的存储库。我们将使用 Spring 的PagingAndSortingRepository： public interface IFooRepository extends PagingAndSortingRepository\u0026lt;Foo, Long\u0026gt; { } 3.4 服务与实施 之后，我们将为我们的 API 定义并实现一个简单的服务： public interface IFooService { Optional\u0026lt;Foo\u0026gt; findById(Long id); Foo save(Foo foo); Iterable\u0026lt;Foo\u0026gt; findAll(); } @Service public class FooServiceImpl implements IFooService { private IFooRepository fooRepository; public FooServiceImpl(IFooRepository fooRepository) { this.fooRepository = fooRepository; } @Override public Optional\u0026lt;Foo\u0026gt; findById(Long id) { return fooRepository.findById(id); } @Override public Foo save(Foo foo) { return fooRepository.save(foo); } @Override public Iterable\u0026lt;Foo\u0026gt; findAll() { return fooRepository.findAll(); } } 3.5 示例控制器 现在让我们实现一个简单的控制器，通过 DTO公开我们的Foo资源： @RestController @RequestMapping(value = \u0026#34;/api/foos\u0026#34;) public class FooController { private IFooService fooService; public FooController(IFooService fooService) { this.fooService = fooService; } @CrossOrigin(origins = \u0026#34;http://localhost:8089\u0026#34;) @GetMapping(value = \u0026#34;/{id}\u0026#34;) public FooDto findOne(@PathVariable Long id) { Foo entity = fooService.findById(id) .orElseThrow(() -\u0026gt; new ResponseStatusException(HttpStatus.NOT_FOUND)); return convertToDto(entity); } @GetMapping public Collection\u0026lt;FooDto\u0026gt; findAll() { Iterable\u0026lt;Foo\u0026gt; foos = this.fooService.findAll(); List\u0026lt;FooDto\u0026gt; fooDtos = new ArrayList\u0026lt;\u0026gt;(); foos.forEach(p -\u0026gt; fooDtos.add(convertToDto(p))); return fooDtos; } protected FooDto convertToDto(Foo entity) { FooDto dto = new FooDto(entity.getId(), entity.getName()); return dto; } } 注意上面@CrossOrigin的使用；这是控制器级别的配置，我们需要允许来自我们的 Angular 应用程序的 CORS 在指定的 URL 上运行。 这是我们的FooDto： public class FooDto { private long id; private String name; } 4. 前端——设置 现在，我们将研究一个简单的客户端 Angular 前端实现，它将访问我们的 REST API。 我们将首先使用Angular CLI来生成和管理我们的前端模块。 首先，我们安装node 和 npm，因为 Angular CLI 是一个 npm 工具。 然后我们需要使用frontend-maven-plugin来使用 Maven 构建我们的 Angular 项目： \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.github.eirslett\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;frontend-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;nodeVersion\u0026gt;v6.10.2\u0026lt;/nodeVersion\u0026gt; \u0026lt;npmVersion\u0026gt;3.10.10\u0026lt;/npmVersion\u0026gt; \u0026lt;workingDirectory\u0026gt;src/main/resources\u0026lt;/workingDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;install node and npm\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;install-node-and-npm\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;npm install\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;npm\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;npm run build\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;npm\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;arguments\u0026gt;run build\u0026lt;/arguments\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 最后，使用 Angular CLI 生成一个新模块： ng new oauthApp 在下一节中，我们将讨论 Angular 应用程序逻辑。 5. 使用 Angular 的授权代码流程 我们将在此处使用 OAuth2 授权代码流程。 我们的用例：客户端应用程序从授权服务器请求代码并显示登录页面。**一旦用户提供了他们的有效凭证并提交，授权服务器就会给我们代码。**然后前端客户端使用它来获取访问令牌。 5.1 HomeComponent 让我们从我们的主要组件HomeComponent开始，所有动作都从这里开始： @Component({ selector: \u0026#39;home-header\u0026#39;, providers: [AppService], template: `\u0026lt;div class=\u0026#34;container\u0026#34; \u0026gt; \u0026lt;button *ngIf=\u0026#34;!isLoggedIn\u0026#34; class=\u0026#34;btn btn-primary\u0026#34; (click)=\u0026#34;login()\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt; Login\u0026lt;/button\u0026gt; \u0026lt;div *ngIf=\u0026#34;isLoggedIn\u0026#34; class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;span\u0026gt;Welcome !!\u0026lt;/span\u0026gt; \u0026lt;a class=\u0026#34;btn btn-default pull-right\u0026#34;(click)=\u0026#34;logout()\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Logout\u0026lt;/a\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;foo-details\u0026gt;\u0026lt;/foo-details\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;` }) export class HomeComponent { public isLoggedIn = false; constructor(private _service: AppService) { } ngOnInit() { this.isLoggedIn = this._service.checkCredentials(); let i = window.location.href.indexOf(\u0026#39;code\u0026#39;); if(!this.isLoggedIn \u0026amp;\u0026amp; i != -1) { this._service.retrieveToken(window.location.href.substring(i + 5)); } } login() { window.location.href = \u0026#39;http://localhost:8083/auth/realms/codingman/protocol/openid-connect/auth? response_type=code\u0026amp;scope=openid%20write%20read\u0026amp;client_id=\u0026#39; + this._service.clientId + \u0026#39;\u0026amp;redirect_uri=\u0026#39;+ this._service.redirectUri; } logout() { this._service.logout(); } } 一开始，当用户没有登录时，只出现登录按钮。单击此按钮后，用户将导航到 AS 的授权 URL，他们在其中键入用户名和密码。成功登录后，用户将使用授权代码重定向回来，然后我们使用此代码检索访问令牌。 5.2 AppService 现在让我们看看*AppService——位于app.service.ts——*它包含服务器交互的逻辑：  retrieveToken()：使用授权码获取访问令牌 saveToken()：使用 ng2-cookies 库将我们的访问令牌保存在 cookie 中 getResource()：使用其 ID 从服务器获取 Foo 对象 checkCredentials() : 检查用户是否登录 logout()：删除访问令牌cookie并注销用户  export class Foo { constructor(public id: number, public name: string) { } } @Injectable() export class AppService { public clientId = \u0026#39;newClient\u0026#39;; public redirectUri = \u0026#39;http://localhost:8089/\u0026#39;; constructor(private _http: HttpClient) { } retrieveToken(code) { let params = new URLSearchParams(); params.append(\u0026#39;grant_type\u0026#39;,\u0026#39;authorization_code\u0026#39;); params.append(\u0026#39;client_id\u0026#39;, this.clientId); params.append(\u0026#39;client_secret\u0026#39;, \u0026#39;newClientSecret\u0026#39;); params.append(\u0026#39;redirect_uri\u0026#39;, this.redirectUri); params.append(\u0026#39;code\u0026#39;,code); let headers = new HttpHeaders({\u0026#39;Content-type\u0026#39;: \u0026#39;application/x-www-form-urlencoded; charset=utf-8\u0026#39;}); this._http.post(\u0026#39;http://localhost:8083/auth/realms/codingman/protocol/openid-connect/token\u0026#39;, params.toString(), { headers: headers }) .subscribe( data =\u0026gt; this.saveToken(data), err =\u0026gt; alert(\u0026#39;Invalid Credentials\u0026#39;)); } saveToken(token) { var expireDate = new Date().getTime() + (1000 * token.expires_in); Cookie.set(\u0026#34;access_token\u0026#34;, token.access_token, expireDate); console.log(\u0026#39;Obtained Access token\u0026#39;); window.location.href = \u0026#39;http://localhost:8089\u0026#39;; } getResource(resourceUrl) : Observable\u0026lt;any\u0026gt; { var headers = new HttpHeaders({ \u0026#39;Content-type\u0026#39;: \u0026#39;application/x-www-form-urlencoded; charset=utf-8\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;CD \u0026#39;+Cookie.get(\u0026#39;access_token\u0026#39;)}); return this._http.get(resourceUrl, { headers: headers }) .catch((error:any) =\u0026gt; Observable.throw(error.json().error || \u0026#39;Server error\u0026#39;)); } checkCredentials() { return Cookie.check(\u0026#39;access_token\u0026#39;); } logout() { Cookie.delete(\u0026#39;access_token\u0026#39;); window.location.reload(); } } 在retrieveToken方法中，我们使用我们的客户端凭据和基本身份验证将POST发送到*/openid-connect/token*端点以获取访问令牌。参数以 URL 编码格式发送。获得访问令牌后，我们将其存储在 cookie 中。 cookie 存储在这里尤为重要，因为我们仅将 cookie 用于存储目的，而不是直接驱动身份验证过程。这有助于防止跨站点请求伪造 (CSRF) 攻击和漏洞。 5.3. Foo 组件 最后，我们的FooComponent来显示我们的 Foo 详细信息： @Component({ selector: \u0026#39;foo-details\u0026#39;, providers: [AppService], template: `\u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;col-sm-12\u0026#34;\u0026gt;Foo Details\u0026lt;/h1\u0026gt; \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;col-sm-3\u0026#34;\u0026gt;ID\u0026lt;/label\u0026gt; \u0026lt;span\u0026gt;{{foo.id}}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;col-sm-3\u0026#34;\u0026gt;Name\u0026lt;/label\u0026gt; \u0026lt;span\u0026gt;{{foo.name}}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;btn btn-primary\u0026#34; (click)=\u0026#34;getFoo()\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt;New Foo\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;` }) export class FooComponent { public foo = new Foo(1,\u0026#39;sample foo\u0026#39;); private foosUrl = \u0026#39;http://localhost:8081/resource-server/api/foos/\u0026#39;; constructor(private _service:AppService) {} getFoo() { this._service.getResource(this.foosUrl+this.foo.id) .subscribe( data =\u0026gt; this.foo = data, error =\u0026gt; this.foo.name = \u0026#39;Error\u0026#39;); } } 5.4 AppComponent 我们简单的AppComponent作为根组件： @Component({ selector: \u0026#39;app-root\u0026#39;, template: `\u0026lt;nav class=\u0026#34;navbar navbar-default\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container-fluid\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;navbar-header\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;navbar-brand\u0026#34; href=\u0026#34;/\u0026#34;\u0026gt;Spring Security Oauth - Authorization Code\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;router-outlet\u0026gt;\u0026lt;/router-outlet\u0026gt;` }) export class AppComponent { } 还有我们包装所有组件、服务和路由的AppModule ： @NgModule({ declarations: [ AppComponent, HomeComponent, FooComponent ], imports: [ BrowserModule, HttpClientModule, RouterModule.forRoot([ { path: \u0026#39;\u0026#39;, component: HomeComponent, pathMatch: \u0026#39;full\u0026#39; }], {onSameUrlNavigation: \u0026#39;reload\u0026#39;}) ], providers: [], bootstrap: [AppComponent] }) export class AppModule { } 5.5 运行前端  要运行我们的任何前端模块，我们需要先构建应用程序：  mvn clean install 然后我们需要导航到我们的 Angular 应用目录：  cd src/main/resources 最后，我们将启动我们的应用程序：  npm start 服务器将默认在端口 4200 上启动；要更改任何模块的端口，请更改： \u0026#34;start\u0026#34;: \u0026#34;ng serve\u0026#34; 在*package.json 中；*例如，要使其在端口 8089 上运行，请添加： \u0026#34;start\u0026#34;: \u0026#34;ng serve --port 8089\u0026#34; \u0026quot; ","permalink":"http://itcodingman.github.io/securing_a_restful_web_service_with_spring_security/","tags":["OAuth New Stack"],"title":"Spring REST API + OAuth2 + Angular"},{"categories":["REST","Spring"],"contents":"1. 概述 本教程将重点介绍使用 Spring MVC 和 Spring Data 在 REST API 中实现分页。 2. 页面作为资源与页面作为表示 在 RESTful 架构的上下文中设计分页时的第一个问题是，是否将页面视为实际资源或只是资源的表示。 将页面本身视为资源会带来许多问题，例如不再能够在调用之间唯一标识资源。这一点，再加上在持久层中，页面不是一个适当的实体，而是一个在必要时构建的持有者，这使得选择变得简单；页面是表示的一部分。 REST 上下文中分页设计的下一个问题是在哪里包含分页信息：  在 URI 路径中：/foo/page/1 URI 查询：/foo?page=1  请记住，页面不是 Resource，因此无法在 URI 中对页面信息进行编码。 我们将使用标准方法通过在 URI 查询中编码分页信息来解决这个问题。 3. 控制器 现在进行实施用于分页的 Spring MVC 控制器很简单： @GetMapping(params = { \u0026#34;page\u0026#34;, \u0026#34;size\u0026#34; }) public List\u0026lt;Foo\u0026gt; findPaginated(@RequestParam(\u0026#34;page\u0026#34;) int page, @RequestParam(\u0026#34;size\u0026#34;) int size, UriComponentsBuilder uriBuilder, HttpServletResponse response) { Page\u0026lt;Foo\u0026gt; resultPage = service.findPaginated(page, size); if (page \u0026gt; resultPage.getTotalPages()) { throw new MyResourceNotFoundException(); } eventPublisher.publishEvent(new PaginatedResultsRetrievedEvent\u0026lt;Foo\u0026gt;( Foo.class, uriBuilder, response, page, resultPage.getTotalPages(), size)); return resultPage.getContent(); } 在此示例中，我们 通过@RequestParam在 Controller 方法中注入两个查询参数size和page。 或者，我们可以使用Pageable对象，它自动映射page、 size和sort参数。此外，PagingAndSortingRepository实体提供了开箱即用的方法，支持使用Pageable作为参数。 我们还注入了 Http Response 和UriComponentsBuilder来帮助实现可发现性，我们通过自定义事件将其解耦。如果这不是 API 的目标，我们可以简单地删除自定义事件。 最后，注意本文的重点只是REST和web层；要深入了解分页的数据访问部分，我们可以查看这篇关于使用 Spring Data 进行分页的文章。 4. REST 分页的可发现性 在分页范围内，满足REST 的 HATEOAS 约束意味着 API 的客户端能够根据导航中的当前页面发现下一页和上一页。为此，我们将使用Link HTTP 标头，以及“下一个”、 “上一个”、“第一个”和“最后一个”链接关系类型。 在 REST 中，可发现性是一个横切关注点，不仅适用于特定操作，还适用于操作类型。例如，每次创建资源时，客户端应该可以发现该资源的 URI。由于此要求与 ANY Resource 的创建相关，因此我们将单独处理它。 正如我们在上一篇文章中讨论的那样，我们将使用事件来解耦这些关注点，重点是 REST 服务的可发现性。在分页的情况下，事件PaginatedResultsRetrievedEvent在控制器层中触发。然后，我们将使用此事件的自定义侦听器实现可发现性。 简而言之，监听器将检查导航是否允许下一页、 上一页、 第一页 和 最后一页。如果是这样，它会将相关的 URI 作为“链接”HTTP Header 添加到响应中。 现在让我们一步一步来。从控制器传递的UriComponentsBuilder仅包含基本 URL（主机、端口和上下文路径）。因此，我们必须添加其余部分： void addLinkHeaderOnPagedResourceRetrieval( UriComponentsBuilder uriBuilder, HttpServletResponse response, Class clazz, int page, int totalPages, int size ){ String resourceName = clazz.getSimpleName().toString().toLowerCase(); uriBuilder.path( \u0026#34;/admin/\u0026#34; + resourceName ); // ...  } 接下来，我们将使用StringJoiner 连接每个链接。我们将使用uriBuilder来生成 URI。让我们看看我们如何处理到下一页的链接： StringJoiner linkHeader = new StringJoiner(\u0026#34;, \u0026#34;); if (hasNextPage(page, totalPages)){ String uriForNextPage = constructNextPageUri(uriBuilder, page, size); linkHeader.add(createLinkHeader(uriForNextPage, \u0026#34;next\u0026#34;)); } 我们看一下 constructNextPageUri方法的逻辑： String constructNextPageUri(UriComponentsBuilder uriBuilder, int page, int size) { return uriBuilder.replaceQueryParam(PAGE, page + 1) .replaceQueryParam(\u0026#34;size\u0026#34;, size) .build() .encode() .toUriString(); } 我们将对我们想要包含的其余 URI 进行类似的处理。 最后，我们将输出添加为响应标头： response.addHeader(\u0026#34;Link\u0026#34;, linkHeader.toString()); 请注意，为简洁起见，仅包含部分代码示例。 5. 分页 分页和可发现性的主要逻辑都包含在小型、集中的集成测试中。与上一篇文章一样，我们将使用 REST-assured 库来使用 REST 服务并验证结果。 这些是分页集成测试的一些示例： @Test public void whenResourcesAreRetrievedPaged_then200IsReceived(){ Response response = RestAssured.get(paths.getFooURL() + \u0026#34;?page=0\u0026amp;size=2\u0026#34;); assertThat(response.getStatusCode(), is(200)); } @Test public void whenPageOfResourcesAreRetrievedOutOfBounds_then404IsReceived(){ String url = getFooURL() + \u0026#34;?page=\u0026#34; + randomNumeric(5) + \u0026#34;\u0026amp;size=2\u0026#34;; Response response = RestAssured.get.get(url); assertThat(response.getStatusCode(), is(404)); } @Test public void givenResourcesExist_whenFirstPageIsRetrieved_thenPageContainsResources(){ createResource(); Response response = RestAssured.get(paths.getFooURL() + \u0026#34;?page=0\u0026amp;size=2\u0026#34;); assertFalse(response.body().as(List.class).isEmpty()); } 6. 分页可发现性 测试分页是否可以被客户发现是相对简单的，尽管有很多内容需要覆盖。 测试将关注当前页面在导航中的位置，以及应该从每个位置发现的不同 URI： @Test public void whenFirstPageOfResourcesAreRetrieved_thenSecondPageIsNext(){ Response response = RestAssured.get(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;); String uriToNextPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;next\u0026#34;); assertEquals(getFooURL()+\u0026#34;?page=1\u0026amp;size=2\u0026#34;, uriToNextPage); } @Test public void whenFirstPageOfResourcesAreRetrieved_thenNoPreviousPage(){ Response response = RestAssured.get(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;); String uriToPrevPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;prev\u0026#34;); assertNull(uriToPrevPage ); } @Test public void whenSecondPageOfResourcesAreRetrieved_thenFirstPageIsPrevious(){ Response response = RestAssured.get(getFooURL()+\u0026#34;?page=1\u0026amp;size=2\u0026#34;); String uriToPrevPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;prev\u0026#34;); assertEquals(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;, uriToPrevPage); } @Test public void whenLastPageOfResourcesIsRetrieved_thenNoNextPageIsDiscoverable(){ Response first = RestAssured.get(getFooURL()+\u0026#34;?page=0\u0026amp;size=2\u0026#34;); String uriToLastPage = extractURIByRel(first.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;last\u0026#34;); Response response = RestAssured.get(uriToLastPage); String uriToNextPage = extractURIByRel(response.getHeader(\u0026#34;Link\u0026#34;), \u0026#34;next\u0026#34;); assertNull(uriToNextPage); } 7. 获取所有资源 在分页和可发现性的同一主题上，必须做出选择，是允许客户端一次检索系统中的所有资源，还是客户端必须分页请求它们。 如果确定客户端无法通过单个请求检索所有资源，并且需要分页，那么有几个选项可用于响应以获取请求。一种选择是返回 404 ( Not Found ) 并使用Link标头使第一页可发现：  链接=http://localhost:8080/rest/api/admin/foo?page=0\u0026size=2; rel=”first”, http://localhost:8080/rest/api/admin/foo?page=103\u0026size=2; rel=“last”  另一种选择是将重定向 303 （请参阅其他）返回到第一页。更保守的方法是简单地为 GET 请求返回 405（不允许的方法）给客户端。 8. 带有Range HTTP 标头的 REST 分页 实现分页的一种相对不同的方式是使用HTTP Range标头、 Range、Content-Range、If-Range、Accept-Ranges和HTTP 状态代码、 206（部分内容）、413（请求实体太大）和416（请求的范围不可满足）。 这种方法的一种观点是，HTTP Range 扩展不用于分页，它们应该由服务器管理，而不是由应用程序管理。基于 HTTP Range 标头扩展实现分页在技术上是可行的，尽管不像本文中讨论的实现那样普遍。 9. Spring Data REST 分页 在 Spring Data 中，如果我们需要从完整的数据集中返回一些结果，我们可以使用任何Pageable存储库方法，因为它总是返回一个Page。将根据页码、页面大小和排序方向返回结果。 Spring Data REST自动识别page, size, sort等URL 参数。 要使用任何存储库的分页方法，我们需要扩展PagingAndSortingRepository： public interface SubjectRepository extends PagingAndSortingRepository\u0026lt;Subject, Long\u0026gt;{} 如果我们调用 http://localhost:8080/subjects， Spring 会自动通过 API添加page, size, sort参数建议： \u0026#34;_links\u0026#34; : { \u0026#34;self\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/subjects{?page,size,sort}\u0026#34;, \u0026#34;templated\u0026#34; : true } } 默认情况下，页面大小为 20，但我们可以通过调用类似http://localhost:8080/subjects?page=10 的方法来更改它。 如果我们想在我们自己的自定义存储库 API 中实现分页，我们需要传递一个额外的Pageable参数并确保 API 返回一个Page： @RestResource(path = \u0026#34;nameContains\u0026#34;) public Page\u0026lt;Subject\u0026gt; findByNameContaining(@Param(\u0026#34;name\u0026#34;) String name, Pageable p); 每当我们添加自定义 API 时，都会将/search端点添加到生成的链接中。因此，如果我们调用 http://localhost:8080/subjects/search，我们将看到一个支持分页的端点： \u0026#34;findByNameContaining\u0026#34; : { \u0026#34;href\u0026#34; : \u0026#34;http://localhost:8080/subjects/search/nameContains{?name,page,size,sort}\u0026#34;, \u0026#34;templated\u0026#34; : true } 所有实现 PagingAndSortingRepository的 API都会返回一个Page。如果我们需要从Page返回结果列表， Page的getContent() API提供了作为 Spring Data REST API 结果获取的记录列表。 10. 将List转换为Page 假设我们有一个Pageable对象作为输入，但是我们需要检索的信息包含在一个列表而不是PagingAndSortingRepository中。在这些情况下，我们可能需要将List转换为Page。 例如，假设我们有一个SOAP服务的结果列表： List\u0026lt;Foo\u0026gt; list = getListOfFooFromSoapService(); 我们需要访问发送给我们的Pageable对象指定的特定位置的列表。所以让我们定义开始索引： int start = (int) pageable.getOffset(); 和结束索引： int end = (int) ((start + pageable.getPageSize()) \u0026gt; fooList.size() ? fooList.size() : (start + pageable.getPageSize())); 有了这两个，我们可以创建一个Page来获取它们之间的元素列表： Page\u0026lt;Foo\u0026gt; page = new PageImpl\u0026lt;Foo\u0026gt;(fooList.subList(start, end), pageable, fooList.size()); 而已！我们现在可以将page作为有效结果返回。 请注意，如果我们还想支持排序，我们需要在子列表之前对列表进行排序。 \u0026quot; ","permalink":"http://itcodingman.github.io/rest_api_pagination_in_spring/","tags":["Pagination"],"title":"Spring中的REST分页"},{"categories":["Spring","Spring Boot"],"contents":"1. 概述 本教程将展示如何通过Java配置和*@PropertySource*在 Spring 中设置和使用属性。 我们还将看到属性在 Spring Boot 中是如何工作的。 2. 通过注解注册一个属性文件 Spring 3.1 还引入了新的*@PropertySource*注解作为向环境添加属性源的便捷机制。 我们可以将此注解与*@Configuration*注解结合使用： @Configuration @PropertySource(\u0026#34;classpath:foo.properties\u0026#34;) public class PropertiesWithJavaConfig { //... } 注册新属性文件的另一种非常有用的方法是使用占位符，它允许我们在运行时动态选择正确的文件： @PropertySource({ \u0026#34;classpath:persistence-${envTarget:mysql}.properties\u0026#34; }) ... 2.1。定义多个属性位置 根据Java 8 约定， @PropertySource注释是可重复的。因此，如果我们使用 Java 8 或更高版本，我们可以使用这个注解来定义多个属性位置： @PropertySource(\u0026#34;classpath:foo.properties\u0026#34;) @PropertySource(\u0026#34;classpath:bar.properties\u0026#34;) public class PropertiesWithJavaConfig { //... } 当然，*我们也可以使用@PropertySources注解，指定一个@PropertySource*数组。**这适用于任何受支持的 Java 版本，而不仅仅是 Java 8 或更高版本： @PropertySources({ @PropertySource(\u0026#34;classpath:foo.properties\u0026#34;), @PropertySource(\u0026#34;classpath:bar.properties\u0026#34;) }) public class PropertiesWithJavaConfig { //... } 在任何一种情况下，值得注意的是，如果发生属性名称冲突，最后读取的源优先。 3. 使用/注入属性 **使用@Value注释**注入属性很简单： @Value( \u0026#34;${jdbc.url}\u0026#34; ) private String jdbcUrl; 我们还可以为属性指定一个默认值： @Value( \u0026#34;${jdbc.url:aDefaultUrl}\u0026#34; ) private String jdbcUrl; Spring 3.1 中添加的新PropertySourcesPlaceholderConfigurer在 bean 定义属性值和*@Value*注释中解析 ${…} 占位符。 最后，我们可以使用Environment API 获取属性的值 ： @Autowired private Environment env; ... dataSource.setUrl(env.getProperty(\u0026#34;jdbc.url\u0026#34;)); 4. Spring Boot 的属性 在我们进入更高级的属性配置选项之前，让我们花一些时间来看看 Spring Boot 中的新属性支持。 一般来说，与标准 Spring 相比，这种新的支持涉及更少的配置，这当然是 Boot 的主要目标之一。 4.1 application.properties：默认属性文件 Boot 将其典型的约定优于配置方法应用于属性文件。这意味着我们可以简单地将application.properties文件放在我们的src/main/resources 目录中，它会被自动检测到。然后我们可以像往常一样从中注入任何加载的属性。 因此，通过使用此默认文件，我们不必显式注册PropertySource ，甚至不必提供属性文件的路径。 如果需要，我们还可以使用环境属性在运行时配置不同的文件： java -jar app.jar --spring.config.location=classpath:/another-location.properties 从Spring Boot 2.3开始，我们还可以为配置文件指定通配符位置。 例如，我们可以将 spring.config.location 属性设置为 config/*/： java -jar app.jar --spring.config.location=config/*/ 这样，Spring Boot 将在我们的 jar 文件之外查找与config/*/ 目录模式匹配的配置文件。当我们有多个配置属性来源时，这会派上用场。 从2.4.0版本开始，Spring Boot 支持使用多文档属性文件，类似于YAML的设计： baeldung.customProperty=defaultValue #--- baeldung.customProperty=overriddenValue 请注意，对于属性文件，三破折号表示法前面有一个注释字符 ( # )。 4.2. 环境特定的属性文件 如果我们需要针对不同的环境，Boot 中有一个内置机制。 我们可以简单的在src/main/resources目录下定义一个application-environment.properties文件，然后设置一个相同环境名的Spring profile。 例如，如果我们定义一个“暂存”环境，这意味着我们必须定义一个暂存配置文件，然后定义application-staging.properties。 此 env 文件将被加载，**并将优先于默认属性文件。**注意还是会加载默认文件，只是当发生属性冲突时，环境特定的属性文件优先。 4.3. 测试特定的属性文件 当我们的应用程序正在测试时，我们可能还需要使用不同的属性值。 Spring Boot 通过在测试运行期间查看我们的src/test/resources 目录来为我们处理这个问题。同样，默认属性仍然可以正常注入，但如果发生冲突，默认属性将被这些属性覆盖。 4.4. @TestPropertySource注解 如果我们需要对测试属性进行更精细的控制，那么我们可以使用*@TestPropertySource*注释。 这允许我们为特定的测试上下文设置测试属性，优先于默认属性源： @RunWith(SpringRunner.class) @TestPropertySource(\u0026#34;/foo.properties\u0026#34;) public class FilePropertyInjectionUnitTest { @Value(\u0026#34;${foo}\u0026#34;) private String foo; @Test public void whenFilePropertyProvided_thenProperlyInjected() { assertThat(foo).isEqualTo(\u0026#34;bar\u0026#34;); } } 如果我们不想使用文件，我们可以直接指定名称和值： @RunWith(SpringRunner.class) @TestPropertySource(properties = {\u0026#34;foo=bar\u0026#34;}) public class PropertyInjectionUnitTest { @Value(\u0026#34;${foo}\u0026#34;) private String foo; @Test public void whenPropertyProvided_thenProperlyInjected() { assertThat(foo).isEqualTo(\u0026#34;bar\u0026#34;); } } 我们也可以使用@SpringBootTest注解的properties参数来实现类似的效果： @RunWith(SpringRunner.class) @SpringBootTest( properties = {\u0026#34;foo=bar\u0026#34;}, classes = SpringBootPropertiesTestApplication.class) public class SpringBootPropertyInjectionIntegrationTest { @Value(\u0026#34;${foo}\u0026#34;) private String foo; @Test public void whenSpringBootPropertyProvided_thenProperlyInjected() { assertThat(foo).isEqualTo(\u0026#34;bar\u0026#34;); } } 4.5. 分层属性 如果我们有组合在一起的属性，我们可以使用*@ConfigurationProperties*注释，它将这些属性层次结构映射到 Java 对象图中。 让我们使用一些用于配置数据库连接的属性： database.url=jdbc:postgresql:/localhost:5432/instance database.username=foo database.password=bar 然后让我们使用注解将它们映射到数据库对象： @ConfigurationProperties(prefix = \u0026#34;database\u0026#34;) public class Database { String url; String username; String password; // standard getters and setters } Spring Boot 再次应用它的约定而不是配置方法，在属性名称及其对应字段之间自动映射。我们需要提供的只是属性前缀。 如果您想深入了解配置属性，请查看我们的深度文章。 4.6 替代方案：YAML 文件 Spring 还支持 YAML 文件。 所有相同的命名规则都适用于特定于测试的、特定于环境的和默认属性文件。唯一的区别是文件扩展名和对我们类路径上的SnakeYAML库的依赖。 YAML 特别适合分层属性存储；以下属性文件： database.url=jdbc:postgresql:/localhost:5432/instance database.username=foo database.password=bar secret: foo 与以下 YAML 文件同义： database: url: jdbc:postgresql:/localhost:5432/instance username: foo password: bar secret: foo 还值得一提的是 YAML 文件不支持*@PropertySource*注解，所以如果我们需要使用这个注解，它会限制我们使用属性文件。 另一个值得注意的点是，在 2.4.0 版本中，Spring Boot 改变了从多文档 YAML 文件加载属性的方式。以前，它们的添加顺序基于配置文件激活顺序。然而，在新版本中，框架遵循我们之前为*.properties*文件指出的相同排序规则；在文件中声明较低的属性将简单地覆盖那些较高的属性。 此外，在此版本中，无法再从特定于配置文件的文档中激活配置文件，从而使结果更加清晰和可预测。 4.7 导入其他配置文件 在 2.4.0 版本之前，Spring Boot 允许使用spring.config.location和 spring.config.additional-location 属性包含其他配置文件，但它们有一定的限制。例如，必须在启动应用程序之前定义它们（作为环境或系统属性，或使用命令行参数），因为它们在流程的早期使用。 在上述版本中，**我们可以使用application.properties或application.yml文件中的spring.config.import属性来轻松包含其他文件。**这个属性支持一些有趣的特性：  添加多个文件或目录 可以从类路径或外部目录加载文件 指示如果找不到文件或者它是否是可选文件，则启动过程是否应该失败 导入无扩展名文件  让我们看一个有效的例子： spring.config.import=classpath:additional-application.properties, classpath:additional-application[.yml], optional:file:./external.properties, classpath:additional-application-properties/ 注意：为了清楚起见，我们在这里使用换行符格式化了这个属性。 Spring 会将导入视为紧接在导入声明下方插入的新文档。 4.8 命令行参数的属性 除了使用文件，我们还可以直接在命令行中传递属性： java -jar app.jar --property=\u0026#34;value\u0026#34; 我们也可以通过系统属性来做到这一点，这些属性在*-jar*命令之前而不是之后提供： java -Dproperty.name=\u0026#34;value\u0026#34; -jar app.jar 4.9 来自环境变量的属性 Spring Boot 还将检测环境变量，将它们视为属性： export name=value java -jar app.jar 4.10 属性值的随机化 如果我们不想要确定性属性值，我们可以使用*RandomValuePropertySource* 来随机化属性值： random.number=${random.int} random.long=${random.long} random.uuid=${random.uuid} 4.11 其他类型的财产来源 Spring Boot 支持多种属性源，实现了经过深思熟虑的排序以允许明智的覆盖。值得参考官方文档，这超出了本文的范围。 5. 使用原始 Bean 进行配置 — PropertySourcesPlaceholderConfigurer 除了将属性获取到 Spring 中的便捷方法外，我们还可以手动定义和注册属性配置 bean。 使用PropertySourcesPlaceholderConfigurer可以让我们完全控制配置，但缺点是更冗长且大多数时候是不必要的。 让我们看看如何使用 Java 配置定义这个 bean： @Bean public static PropertySourcesPlaceholderConfigurer properties(){ PropertySourcesPlaceholderConfigurer pspc = new PropertySourcesPlaceholderConfigurer(); Resource[] resources = new ClassPathResource[ ] { new ClassPathResource( \u0026#34;foo.properties\u0026#34; ) }; pspc.setLocations( resources ); pspc.setIgnoreUnresolvablePlaceholders( true ); return pspc; } 6. 父子上下文中的属性 这个问题一次又一次地出现：当我们的Web 应用程序有父上下文和子上下文时会发生什么？父上下文可能有一些共同的核心功能和 bean，然后是一个（或多个）子上下文，可能包含特定于 servlet 的 bean。 在这种情况下，定义属性文件并将它们包含在这些上下文中的最佳方法是什么？以及如何最好地从 Spring 中检索这些属性？ 我们将给出一个简单的细分。 如果文件是在父上下文中定义的：   @Value在子上下文中工作：是   @Value在父上下文中工作：是   子上下文中的environment.getProperty：是   父上下文中的environment.getProperty：是   如果文件在子上下文中定义：   @Value在子上下文中工作：是   @Value在父上下文中工作：否   子上下文中的environment.getProperty：是   父上下文中的environment.getProperty：否 \u0026quot;   ","permalink":"http://itcodingman.github.io/properties_with_spring/","tags":["Spring Core Basics"],"title":"Spring 和 Spring Boot 的属性"},{"categories":["Spring"],"contents":"1. 配置必须是特定于环境的 配置必须是特定于环境的——这是不争的事实。如果不是这种情况，那么它就不是配置，我们只会在代码中硬编码值。 对于 Spring 应用程序，您可以使用多种解决方案——从简单的解决方案一直到超级灵活、高度复杂的替代方案。 一个更常见和直接的解决方案是灵活使用属性文件和Spring 提供的属性支持。 作为概念证明，出于本文的目的，我们将了解一种特定类型的属性——数据库配置。将一种类型的数据库配置用于生产，另一种用于测试，另一种用于开发环境是非常有意义的。 2.每个环境的.properties文件 让我们开始我们的概念证明——通过定义我们想要定位的环境：  开发 分期 生产  接下来 – 让我们创建 3 个属性文件 – 每个环境一个：  persistence-dev.properties persistence-staging.properties persistence-production.properties  在典型的 Maven 应用程序中，它们可以驻留在src/main/resources中，但是无论它们在哪里，它们都需要在部署应用程序时在类路径中可用。 将所有属性文件置于版本控制之下，使配置更加透明和可重复。这与将配置放在磁盘上的某个地方并简单地将 Spring 指向它们不同。 3. Spring 配置 在 Spring 中，我们将根据环境包含正确的文件： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\u0026#34;\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath*:*persistence-${envTarget}.properties\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 当然，Java 配置也可以做到这一点： @PropertySource({ \u0026#34;classpath:persistence-${envTarget:dev}.properties\u0026#34; }) 这种方法允许灵活地拥有多个*.properties*文件以用于特定的、集中的目的。例如——在我们的例子中，Spring持久性配置导入持久性属性——这非常有意义。安全配置将导入与安全相关的属性等。 4. 在每个环境中设置属性 最终的、可部署的war将包含所有属性文件——例如持久性，persistence-*.properties的三个文件。由于文件实际上命名不同，因此不必担心意外包含错误的文件。我们将设置envTarget变量，从而从多个现有文件中选择我们想要的实例。 envTarget变量可以在操作系统/环境中设置或作为 JVM 命令行的参数*：* -DenvTarget=dev 5. 测试和 Maven 对于需要启用持久性的集成测试——我们只需在 pom.xml 中设置envTarget属性： \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;systemPropertyVariables\u0026gt; \u0026lt;envTarget\u0026gt;h2_test\u0026lt;/envTarget\u0026gt; \u0026lt;/systemPropertyVariables\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 对应的persistence-h2_test.properties文件可以放在src/test/resources中，这样它就只会用于测试，而不是在运行时不必要地包含和部署在 war 中。 6. 更进一步 如果需要，有几种方法可以在此解决方案中增加额外的灵活性。 一种这样的方法是对属性文件的名称使用更复杂的编码，不仅指定要使用它们的环境，还指定更多信息（例如持久性提供程序）。例如，我们可能会使用以下类型的属性：persistence-h2.properties、persistence-mysql.properties ，或者更具体的：persistence-dev_h2.properties、persistence-staging_mysql.properties、persistence-production_amazonRDS.properties。 这种命名约定的优势——它只是一个约定，因为整体方法没有任何变化——只是透明。现在仅通过查看名称就可以更清楚地了解配置的作用：  persistence-dev_h2.properties：开发环境的持久性提供程序是一个轻量级的内存 H2 数据库 persistence-staging_mysql.properties：暂存环境的持久性提供程序是一个 MySQL 实例 persistence-production_amazon_rds.propertie：生产环境的持久性提供程序是 Amazon RDS \u0026quot;  ","permalink":"http://itcodingman.github.io/project_configuration_with_spring/","tags":["Spring Core Basics"],"title":"使用 Spring 进行项目配置"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将介绍 IoC（控制反转）和 DI（依赖注入）的概念，并了解它们在 Spring 框架中是如何实现的。 2. 什么是控制反转？ 控制反转是软件工程中的一项原则，它将对象或程序部分的控制转移到容器或框架中。我们最常在面向对象编程的上下文中使用它。 与我们的自定义代码调用库的传统编程相比，IoC 使框架能够控制程序的流程并调用我们的自定义代码。为了实现这一点，框架使用内置附加行为的抽象。如果我们想添加自己的行为，我们需要扩展框架的类或插入我们自己的类。 这种架构的优点是：  将任务的执行与其实现分离 更容易在不同的实现之间切换 程序的更大模块化 通过隔离组件或模拟其依赖关系并允许组件通过合约进行通信，从而更轻松地测试程序  我们可以通过各种机制来实现控制反转，例如：策略设计模式、服务定位器模式、工厂模式和依赖注入（DI）。 接下来我们将研究 DI。 3. 什么是依赖注入？ 依赖注入是我们可以用来实现 IoC 的一种模式，其中被反转的控制是设置对象的依赖关系。 将对象与其他对象连接起来，或将对象“注入”到其他对象中，是由汇编程序完成的，而不是由对象本身完成的。 以下是我们如何在传统编程中创建对象依赖项： public class Store { private Item item; public Store() { item = new ItemImpl1(); } } 在上面的示例中，我们需要在Store类本身中实例化Item接口的实现。 通过使用 DI，我们可以重写示例，而无需指定我们想要的Item的实现： public class Store { private Item item; public Store(Item item) { this.item = item; } } 在接下来的部分中，我们将了解如何通过元数据提供Item的实现。 IoC 和 DI 都是简单的概念，但它们对我们构建系统的方式有着深远的影响，因此它们非常值得充分理解。 4. Spring IoC 容器 IoC 容器是实现 IoC 的框架的共同特征。 在 Spring 框架中，接口 ApplicationContext代表 IoC 容器。Spring 容器负责实例化、配置和组装称为bean的对象，以及管理它们的生命周期。 Spring 框架提供了ApplicationContext接口的几种实现：ClassPathXmlApplicationContext和FileSystemXmlApplicationContext用于独立应用程序，WebApplicationContext用于 Web 应用程序。 为了组装 bean，容器使用配置元数据，它可以是 XML 配置或注解的形式。 这是手动实例化容器的一种方法： ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;applicationContext.xml\u0026#34;); 要在上面的示例中设置项目属性，我们可以使用元数据。然后容器将读取此元数据并在运行时使用它来组装 bean。 Spring 中的依赖注入可以通过构造函数、setter 或字段来完成。 5. 基于构造函数的依赖注入 在基于构造函数的依赖注入的情况下，容器将调用带有参数的构造函数，每个参数代表我们要设置的依赖项。 Spring 主要按类型解析每个参数，然后是属性名称，以及用于消歧的索引。让我们使用注解查看 bean 的配置及其依赖项： @Configuration public class AppConfig { @Bean public Item item1() { return new ItemImpl1(); } @Bean public Store store() { return new Store(item1()); } } @Configuration注解表明该类是 bean 定义的来源。我们还可以将它添加到多个配置类中。 我们在方法上使用*@Bean*注解来定义一个 bean。如果我们不指定自定义名称，那么 bean 名称将默认为方法名称。 对于具有默认单例范围的 bean，Spring 首先检查 bean 的缓存实例是否已经存在，如果不存在则只创建一个新实例。如果我们使用原型作用域，容器会为每个方法调用返回一个新的 bean 实例。 创建 bean 配置的另一种方法是通过 XML 配置： \u0026lt;bean id=\u0026#34;item1\u0026#34; class=\u0026#34;com.codingman.store.ItemImpl1\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34;\u0026gt; \u0026lt;constructor-arg type=\u0026#34;ItemImpl1\u0026#34; index=\u0026#34;0\u0026#34; name=\u0026#34;item\u0026#34; ref=\u0026#34;item1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 6. 基于 Setter 的依赖注入 对于基于 setter 的 DI，容器会在调用无参数构造函数或无参数静态工厂方法实例化 bean 后调用我们类的 setter 方法。让我们使用注解创建这个配置： @Bean public Store store() { Store store = new Store(); store.setItem(item1()); return store; } 我们还可以将 XML 用于相同的 bean 配置： \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;item\u0026#34; ref=\u0026#34;item1\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 我们可以为同一个 bean 组合基于构造函数和基于 setter 的注入类型。Spring 文档建议对强制依赖项使用基于构造函数的注入，对可选依赖项使用基于 setter 的注入。 7. 基于字段的依赖注入 对于基于字段的 DI，我们可以通过使用*@Autowired*注释标记依赖项来注入依赖项： public class Store { @Autowired private Item item; } 在构造Store对象时，如果没有构造函数或 setter 方法来注入Item bean，容器将使用反射将Item注入Store。 我们也可以使用XML 配置来实现这一点。 这种方法可能看起来更简单、更干净，但我们不建议使用它，因为它有一些缺点，例如：  该方法使用反射来注入依赖项，这比基于构造函数或基于 setter 的注入成本更高。 使用这种方法继续添加多个依赖项真的很容易。如果我们使用构造函数注入，具有多个参数会让我们认为该类做了不止一件事，这可能违反单一职责原则。  更多关于*@Autowired*注解的信息可以在Wiring In Spring文章中找到。 8. 自动装配依赖 Wiring允许 Spring 容器通过检查已定义的 bean 来自动解决协作 bean 之间的依赖关系。 使用 XML 配置自动装配 bean 有四种模式：  no：默认值——这意味着 bean 不使用自动装配，我们必须显式命名依赖项。 byName：自动装配是基于属性的名称完成的，因此 Spring 将查找与需要设置的属性名称相同的 bean。 byType：类似于byName自动装配，仅基于属性的类型。这意味着 Spring 将寻找具有相同类型属性的 bean 来设置。如果该类型的 bean 不止一个，框架会抛出异常。 constructor：自动装配是基于构造函数参数完成的，这意味着 Spring 将寻找与构造函数参数具有相同类型的 bean。  例如，让我们将上面定义的item1 bean 按类型自动装配到store bean 中： @Bean(autowire = Autowire.BY_TYPE) public class Store { private Item item; public setItem(Item item){ this.item = item; } } 我们还可以使用*@Autowired*注解注入 bean，以便按类型自动装配： public class Store { @Autowired private Item item; } 如果有多个相同类型的 bean，我们可以使用*@Qualifier*注解按名称引用一个 bean： public class Store { @Autowired @Qualifier(\u0026#34;item1\u0026#34;) private Item item; } 现在让我们通过 XML 配置按类型自动装配 bean： \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34; autowire=\u0026#34;byType\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; 接下来，让我们通过 XML将一个名为item的 bean 按名称注入到store bean 的**item属性中： \u0026lt;bean id=\u0026#34;item\u0026#34; class=\u0026#34;com.codingman.store.ItemImpl1\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;store\u0026#34; class=\u0026#34;com.codingman.store.Store\u0026#34; autowire=\u0026#34;byName\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; 我们还可以通过构造函数参数或设置器显式定义依赖项来覆盖自动装配。 9. 延迟初始化 Bean 默认情况下，容器在初始化期间创建和配置所有单例 bean。为了避免这种情况，我们可以在 bean 配置中使用值为true的延迟初始化属性： \u0026lt;bean id=\u0026#34;item1\u0026#34; class=\u0026#34;com.codingman.store.ItemImpl1\u0026#34; lazy-init=\u0026#34;true\u0026#34; /\u0026gt; 因此，item1 bean 只会在第一次被请求时被初始化，而不是在启动时被初始化。这样做的好处是更快的初始化时间，但代价是在请求 bean 之前我们不会发现任何配置错误，这可能是应用程序已经运行后的几个小时甚至几天。 \u0026quot; ","permalink":"http://itcodingman.github.io/inversion_control_and_dependency_injection_in_spring/","tags":["Spring Core Basics","Spring DI"],"title":"Spring 控制反转和依赖注入简介"},{"categories":["Spring"],"contents":"1. 概述 在本教程中，我们将看一个实用的、以代码为中心的 Spring Batch 介绍。Spring Batch 是一个处理框架，专为作业的稳健执行而设计。 它的当前版本 4.3 支持 Spring 5 和 Java 8。它还适应 JSR-352，这是用于批处理的新 Java 规范。 以下是该框架的一些有趣且实用的用例。 2. 工作流程基础 Spring Batch 遵循传统的批处理架构，其中作业存储库执行调度和与作业交互的工作。 一个作业可以有多个步骤。每个步骤通常遵循读取数据、处理数据和写入数据的顺序。 当然，这里的框架将为我们完成大部分繁重的工作——尤其是在处理作业的低级持久性工作时——使用sqlite作为作业存储库。 2.1 示例用例 我们将在这里处理的简单用例是将一些金融交易数据从 CSV 迁移到 XML。 输入文件的结构非常简单。 它包含每行的交易，由用户名、用户 ID、交易日期和金额组成： username, userid, transaction_date, transaction_amount ann, 1234, 31/10/2015, 10000 bob, 2134, 3/12/2015, 12321 robin, 3134, 2/02/2015, 23411 3. Maven POM 本项目需要的依赖有spring core、spring batch和sqlite jdbc connector： \u0026lt;!-- SQLite database driver --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sqlite-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-oxm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.batch\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-batch-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. Spring批处理配置 我们要做的第一件事是使用 XML 配置 Spring Batch： \u0026lt;!-- connect to SQLite database --\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;org.sqlite.JDBC\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:sqlite:xxx.db\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- create job-meta tables automatically --\u0026gt; \u0026lt;jdbc:initialize-database data-source=\u0026#34;dataSource\u0026#34;\u0026gt; \u0026lt;jdbc:script location=\u0026#34;org/springframework/batch/core/schema-drop-sqlite.sql\u0026#34; /\u0026gt; \u0026lt;jdbc:script location=\u0026#34;org/springframework/batch/core/schema-sqlite.sql\u0026#34; /\u0026gt; \u0026lt;/jdbc:initialize-database\u0026gt; \u0026lt;!-- stored job-meta in memory --\u0026gt; \u0026lt;!-- \u0026lt;bean id=\u0026#34;jobRepository\u0026#34; class=\u0026#34;org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; --\u0026gt; \u0026lt;!-- stored job-meta in database --\u0026gt; \u0026lt;bean id=\u0026#34;jobRepository\u0026#34; class=\u0026#34;org.springframework.batch.core.repository.support.JobRepositoryFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;databaseType\u0026#34; value=\u0026#34;sqlite\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class= \u0026#34;org.springframework.batch.support.transaction.ResourcelessTransactionManager\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;jobLauncher\u0026#34; class=\u0026#34;org.springframework.batch.core.launch.support.SimpleJobLauncher\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jobRepository\u0026#34; ref=\u0026#34;jobRepository\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 当然，也可以使用 Java 配置： @Configuration @EnableBatchProcessing public class SpringConfig { @Value(\u0026#34;org/springframework/batch/core/schema-drop-sqlite.sql\u0026#34;) private Resource dropReopsitoryTables; @Value(\u0026#34;org/springframework/batch/core/schema-sqlite.sql\u0026#34;) private Resource dataReopsitorySchema; @Bean public DataSource dataSource() { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(\u0026#34;org.sqlite.JDBC\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:sqlite:xxx.db\u0026#34;); return dataSource; } @Bean public DataSourceInitializer dataSourceInitializer(DataSource dataSource) throws MalformedURLException { ResourceDatabasePopulator databasePopulator = new ResourceDatabasePopulator(); databasePopulator.addScript(dropReopsitoryTables); databasePopulator.addScript(dataReopsitorySchema); databasePopulator.setIgnoreFailedDrops(true); DataSourceInitializer initializer = new DataSourceInitializer(); initializer.setDataSource(dataSource); initializer.setDatabasePopulator(databasePopulator); return initializer; } private JobRepository getJobRepository() throws Exception { JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean(); factory.setDataSource(dataSource()); factory.setTransactionManager(getTransactionManager()); factory.afterPropertiesSet(); return (JobRepository) factory.getObject(); } private PlatformTransactionManager getTransactionManager() { return new ResourcelessTransactionManager(); } public JobLauncher getJobLauncher() throws Exception { SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); jobLauncher.setJobRepository(getJobRepository()); jobLauncher.afterPropertiesSet(); return jobLauncher; } } 5. Spring Batch 作业配置 现在让我们为 CSV 到 XML 工作编写工作描述： \u0026lt;import resource=\u0026#34;spring.xml\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;record\u0026#34; class=\u0026#34;com.codingman.spring_batch_intro.model.Transaction\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;itemReader\u0026#34; class=\u0026#34;org.springframework.batch.item.file.FlatFileItemReader\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resource\u0026#34; value=\u0026#34;input/record.csv\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;lineMapper\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.batch.item.file.mapping.DefaultLineMapper\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;lineTokenizer\u0026#34;\u0026gt; \u0026lt;bean class= \u0026#34;org.springframework.batch.item.file.transform.DelimitedLineTokenizer\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;names\u0026#34; value=\u0026#34;username,userid,transactiondate,amount\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;fieldSetMapper\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;com.codingman.spring_batch_intro.service.RecordFieldSetMapper\u0026#34; /\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;itemProcessor\u0026#34; class=\u0026#34;com.codingman.service.CustomItemProcessor\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;itemWriter\u0026#34; class=\u0026#34;org.springframework.batch.item.xml.StaxEventItemWriter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resource\u0026#34; value=\u0026#34;file:xml/output.xml\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;marshaller\u0026#34; ref=\u0026#34;recordMarshaller\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;rootTagName\u0026#34; value=\u0026#34;transactionRecord\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;recordMarshaller\u0026#34; class=\u0026#34;org.springframework.oxm.jaxb.Jaxb2Marshaller\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;classesToBeBound\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;com.codingman.spring_batch_intro.model.Transaction\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;batch:job id=\u0026#34;firstBatchJob\u0026#34;\u0026gt; \u0026lt;batch:step id=\u0026#34;step1\u0026#34;\u0026gt; \u0026lt;batch:tasklet\u0026gt; \u0026lt;batch:chunk reader=\u0026#34;itemReader\u0026#34; writer=\u0026#34;itemWriter\u0026#34; processor=\u0026#34;itemProcessor\u0026#34; commit-interval=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;/batch:chunk\u0026gt; \u0026lt;/batch:tasklet\u0026gt; \u0026lt;/batch:step\u0026gt; \u0026lt;/batch:job\u0026gt; 这是类似的基于 Java 的作业配置： public class SpringBatchConfig { @Autowired private JobBuilderFactory jobs; @Autowired private StepBuilderFactory steps; @Value(\u0026#34;input/record.csv\u0026#34;) private Resource inputCsv; @Value(\u0026#34;file:xml/output.xml\u0026#34;) private Resource outputXml; @Bean public ItemReader\u0026lt;Transaction\u0026gt; itemReader() throws UnexpectedInputException, ParseException { FlatFileItemReader\u0026lt;Transaction\u0026gt; reader = new FlatFileItemReader\u0026lt;Transaction\u0026gt;(); DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); String[] tokens = { \u0026#34;username\u0026#34;, \u0026#34;userid\u0026#34;, \u0026#34;transactiondate\u0026#34;, \u0026#34;amount\u0026#34; }; tokenizer.setNames(tokens); reader.setResource(inputCsv); DefaultLineMapper\u0026lt;Transaction\u0026gt; lineMapper = new DefaultLineMapper\u0026lt;Transaction\u0026gt;(); lineMapper.setLineTokenizer(tokenizer); lineMapper.setFieldSetMapper(new RecordFieldSetMapper()); reader.setLineMapper(lineMapper); return reader; } @Bean public ItemProcessor\u0026lt;Transaction, Transaction\u0026gt; itemProcessor() { return new CustomItemProcessor(); } @Bean public ItemWriter\u0026lt;Transaction\u0026gt; itemWriter(Marshaller marshaller) throws MalformedURLException { StaxEventItemWriter\u0026lt;Transaction\u0026gt; itemWriter = new StaxEventItemWriter\u0026lt;Transaction\u0026gt;(); itemWriter.setMarshaller(marshaller); itemWriter.setRootTagName(\u0026#34;transactionRecord\u0026#34;); itemWriter.setResource(outputXml); return itemWriter; } @Bean public Marshaller marshaller() { Jaxb2Marshaller marshaller = new Jaxb2Marshaller(); marshaller.setClassesToBeBound(new Class[] { Transaction.class }); return marshaller; } @Bean protected Step step1(ItemReader\u0026lt;Transaction\u0026gt; reader, ItemProcessor\u0026lt;Transaction, Transaction\u0026gt; processor, ItemWriter\u0026lt;Transaction\u0026gt; writer) { return steps.get(\u0026#34;step1\u0026#34;).\u0026lt;Transaction, Transaction\u0026gt; chunk(10) .reader(reader).processor(processor).writer(writer).build(); } @Bean(name = \u0026#34;firstBatchJob\u0026#34;) public Job job(@Qualifier(\u0026#34;step1\u0026#34;) Step step1) { return jobs.get(\u0026#34;firstBatchJob\u0026#34;).start(step1).build(); } } 现在我们有了整个配置，让我们分解它并开始讨论它。 5.1 使用ItemReader读取数据并创建对象 首先，我们配置了cvsFileItemReader ，它将从record.csv中读取数据并将其转换为Transaction对象： @SuppressWarnings(\u0026#34;restriction\u0026#34;) @XmlRootElement(name = \u0026#34;transactionRecord\u0026#34;) public class Transaction { private String username; private int userId; private LocalDateTime transactionDate; private double amount; /* getters and setters for the attributes */ @Override public String toString() { return \u0026#34;Transaction [username=\u0026#34; + username + \u0026#34;, userId=\u0026#34; + userId + \u0026#34;, transactionDate=\u0026#34; + transactionDate + \u0026#34;, amount=\u0026#34; + amount + \u0026#34;]\u0026#34;; } } 为此，它使用自定义映射器： public class RecordFieldSetMapper implements FieldSetMapper\u0026lt;Transaction\u0026gt; { public Transaction mapFieldSet(FieldSet fieldSet) throws BindException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd\u0026#34;); Transaction transaction = new Transaction(); transaction.setUsername(fieldSet.readString(\u0026#34;username\u0026#34;)); transaction.setUserId(fieldSet.readInt(1)); transaction.setAmount(fieldSet.readDouble(3)); String dateString = fieldSet.readString(2); transaction.setTransactionDate(LocalDate.parse(dateString, formatter).atStartOfDay()); return transaction; } } 5.2 使用ItemProcessor处理数据 我们创建了自己的项目处理器CustomItemProcessor。这不会处理与事务对象相关的任何内容。 它所做的只是将来自 reader 的原始对象传递给 writer： public class CustomItemProcessor implements ItemProcessor\u0026lt;Transaction, Transaction\u0026gt; { public Transaction process(Transaction item) { return item; } } 5.3 使用ItemWriter将对象写入 FS 最后，我们将此事务存储到位于xml/output.xml的 XML 文件中： \u0026lt;bean id=\u0026#34;itemWriter\u0026#34; class=\u0026#34;org.springframework.batch.item.xml.StaxEventItemWriter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resource\u0026#34; value=\u0026#34;file:xml/output.xml\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;marshaller\u0026#34; ref=\u0026#34;recordMarshaller\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;rootTagName\u0026#34; value=\u0026#34;transactionRecord\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 5.4 配置批处理作业 因此，我们所要做的就是使用batch:job语法将这些点与作业连接起来。 注意提交间隔。这是在将批次提交给itemWriter之前要保存在内存中的事务数。 它将在内存中保存事务直到该点（或直到遇到输入数据的结尾）： \u0026lt;batch:job id=\u0026#34;firstBatchJob\u0026#34;\u0026gt; \u0026lt;batch:step id=\u0026#34;step1\u0026#34;\u0026gt; \u0026lt;batch:tasklet\u0026gt; \u0026lt;batch:chunk reader=\u0026#34;itemReader\u0026#34; writer=\u0026#34;itemWriter\u0026#34; processor=\u0026#34;itemProcessor\u0026#34; commit-interval=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;/batch:chunk\u0026gt; \u0026lt;/batch:tasklet\u0026gt; \u0026lt;/batch:step\u0026gt; \u0026lt;/batch:job\u0026gt; 5.5 运行批处理作业 现在让我们设置并运行所有内容： public class App { public static void main(String[] args) { // Spring Java config  AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.register(SpringConfig.class); context.register(SpringBatchConfig.class); context.refresh(); JobLauncher jobLauncher = (JobLauncher) context.getBean(\u0026#34;jobLauncher\u0026#34;); Job job = (Job) context.getBean(\u0026#34;firstBatchJob\u0026#34;); System.out.println(\u0026#34;Starting the batch job\u0026#34;); try { JobExecution execution = jobLauncher.run(job, new JobParameters()); System.out.println(\u0026#34;Job Status : \u0026#34; + execution.getStatus()); System.out.println(\u0026#34;Job completed\u0026#34;); } catch (Exception e) { e.printStackTrace(); System.out.println(\u0026#34;Job failed\u0026#34;); } } } \u0026quot; ","permalink":"http://itcodingman.github.io/introduction_to_spring_batch/","tags":["Spring Batch"],"title":"Spring Batch 简介"},{"categories":["Spring Persistence"],"contents":"1. 概述 在本文中，我们将讨论如何使用 Spring 引导 Hibernate 5，同时使用 Java 和 XML 配置。 文章 Spring Boot with Hibernate 描述了如何在 Spring Boot 中使用 Hibernate。 2. Spring集成 使用本机 Hibernate API引导SessionFactory有点复杂，需要我们编写好几行代码（请查看官方文档）。 幸运的是，Spring支持引导SessionFactory因此我们只需要几行 Java 代码或 XML 配置。 3. Maven依赖 让我们首先将必要的依赖项添加到我们的pom.xml中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.4.2.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-orm 模块提供了 Spring 与 Hibernate 的集成： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-orm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 为简单起见，我们将使用H2作为我们的数据库： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.197\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 最后，我们将使用Tomcat JDBC 连接池，它比Spring 提供的DriverManagerDataSource更适合生产目的： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tomcat\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tomcat-dbcp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 4. 配置 如前所述，Spring 支持我们引导 Hibernate SessionFactory。 我们所要做的就是定义一些 bean 以及一些参数。 使用 Spring，我们为这些配置提供了两种选择，一种基于 Java 的方式，一种基于 XML 的方式。 4.1 使用 Java 配置 对于将 Hibernate 5 与 Spring 一起使用，自Hibernate 4以来几乎没有变化：我们必须使用包org.springframework.orm.hibernate5中的LocalSessionFactoryBean而不是org.springframework.orm.hibernate4。 与之前的 Hibernate 4 一样，我们必须为LocalSessionFactoryBean、DataSource和PlatformTransactionManager定义 bean ，以及一些 Hibernate 特定的属性。 让我们创建HibernateConfig类来使用 Spring 配置 Hibernate 5： @Configuration @EnableTransactionManagement public class HibernateConf { @Bean public LocalSessionFactoryBean sessionFactory() { LocalSessionFactoryBean sessionFactory = new LocalSessionFactoryBean(); sessionFactory.setDataSource(dataSource()); sessionFactory.setPackagesToScan( {\u0026#34;com.codingman.demo.model\u0026#34; }); sessionFactory.setHibernateProperties(hibernateProperties()); return sessionFactory; } @Bean public DataSource dataSource() { BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\u0026#34;org.h2.Driver\u0026#34;); dataSource.setUrl(\u0026#34;jdbc:h2:mem:db;DB_CLOSE_DELAY=-1\u0026#34;); dataSource.setUsername(\u0026#34;sa\u0026#34;); dataSource.setPassword(\u0026#34;sa\u0026#34;); return dataSource; } @Bean public PlatformTransactionManager hibernateTransactionManager() { HibernateTransactionManager transactionManager = new HibernateTransactionManager(); transactionManager.setSessionFactory(sessionFactory().getObject()); return transactionManager; } private final Properties hibernateProperties() { Properties hibernateProperties = new Properties(); hibernateProperties.setProperty( \u0026#34;hibernate.hbm2ddl.auto\u0026#34;, \u0026#34;create-drop\u0026#34;); hibernateProperties.setProperty( \u0026#34;hibernate.dialect\u0026#34;, \u0026#34;org.hibernate.dialect.H2Dialect\u0026#34;); return hibernateProperties; } } 4.2 使用 XML 配置 作为次要选项，我们还可以使用基于 XML 的配置来配置 Hibernate 5： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;sessionFactory\u0026#34; class=\u0026#34;org.springframework.orm.hibernate5.LocalSessionFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;com.codingman.demo.model\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernateProperties\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.hbm2ddl.auto\u0026#34;\u0026gt; create-drop \u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.dialect\u0026#34;\u0026gt; org.hibernate.dialect.H2Dialect \u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.apache.tomcat.dbcp.dbcp2.BasicDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;org.h2.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:h2:mem:db;DB_CLOSE_DELAY=-1\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;sa\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;sa\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;txManager\u0026#34; class=\u0026#34;org.springframework.orm.hibernate5.HibernateTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;sessionFactory\u0026#34; ref=\u0026#34;sessionFactory\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 正如我们很容易看到的那样，我们定义的 bean 和参数与前面基于 Java 的配置完全相同。 要将 XML 引导到 Spring 上下文中，如果应用程序配置了 Java 配置，我们可以使用一个简单的 Java 配置文件： @Configuration @EnableTransactionManagement @ImportResource({\u0026#34;classpath:hibernate5Configuration.xml\u0026#34;}) public class HibernateXMLConf { // } 或者，如果整体配置是纯 XML，我们可以简单地将 XML 文件提供给 Spring 上下文。 5. 用法 至此，Hibernate 5 完全配置了 Spring，我们可以在需要时直接注入原始的 Hibernate SessionFactory ： public abstract class BarHibernateDAO { @Autowired private SessionFactory sessionFactory; // ... } 6. 支持的数据库 不幸的是，Hibernate 项目并没有完全提供支持数据库的官方列表。 话虽如此，很容易看出是否支持特定的数据库类型，我们可以查看支持的方言列表。 \u0026quot; ","permalink":"http://itcodingman.github.io/hibernate_5_spring/","tags":["Hibernate"],"title":"在 Spring 中使用 Hibernate 5"},{"categories":["REST","Spring"],"contents":"1. 概述 本教程将说明**如何使用 Spring 为 REST API 实现异常处理。**我们还将获得一些历史概览，并查看不同版本引入了哪些新选项。 *在 Spring 3.2 之前，在 Spring MVC 应用程序中处理异常的两种主要方法是HandlerExceptionResolver或@ExceptionHandler*注解。**两者都有一些明显的缺点。 从 3.2 开始，我们有了@ControllerAdvice*注解*来解决前两个解决方案的局限性，并在整个应用程序中促进统一的异常处理。 现在Spring 5 引入了ResponseStatusException 类——一种在我们的 REST API 中进行基本错误处理的快速方法。 所有这些都有一个共同点：它们很好地处理了**关注点的分离。**该应用程序可以正常抛出异常以指示某种失败，然后将单独处理。 最后，我们将看到 Spring Boot 带来了什么，以及我们如何配置它以满足我们的需求。 2. 方案一：Controller级@ExceptionHandler 第一个解决方案适用于*@Controller级别。我们将定义一个方法来处理异常并使用@ExceptionHandler* 对其进行注释： public class FooController{ //...  @ExceptionHandler({ CustomException1.class, CustomException2.class }) public void handleException() { //  } } 这种方法有一个主要缺点：**@ExceptionHandler注释方法仅对特定的 Controller 有效，**而不是对整个应用程序全局有效。当然，将它添加到每个控制器使其不太适合一般的异常处理机制。 我们可以通过让所有控制器扩展一个基本控制器类来解决这个限制。 然而，这种解决方案对于应用程序来说可能是个问题，无论出于何种原因，这是不可能的。例如，控制器可能已经从另一个基类扩展而来，该基类可能在另一个 jar 中或不可直接修改，或者它们本身可能不可直接修改。 接下来，我们将研究另一种解决异常处理问题的方法——一种全局的并且不包括对现有工件（例如控制器）的任何更改。 3. 解决方案2：HandlerExceptionResolver 第二种解决方案是定义一个HandlerExceptionResolver。这将解决应用程序抛出的任何异常。它还将允许我们在 REST API 中实现统一的异常处理机制。 在使用自定义解析器之前，让我们回顾一下现有的实现。 3.1 ExceptionHandlerExceptionResolver 这个解析器是在 Spring 3.1 中引入的，默认情况下在DispatcherServlet中启用。这实际上是前面介绍的*@ExceptionHandler*机制如何工作的核心组件。 3.2. DefaultHandlerExceptionResolver 这个解析器是在 Spring 3.0 中引入的，默认情况下它在DispatcherServlet中启用。 它用于解决相应的HTTP 状态代码的标准 Spring 异常，即客户端错误4xx和服务器错误5xx状态代码。这是它处理的 Spring 异常的完整列表以及它们如何映射到状态代码。 虽然它确实正确设置了响应的状态代码，但一个**限制是它没有为响应的正文设置任何内容。**对于 REST API——状态码实际上不足以呈现给客户端——响应也必须有一个主体，以允许应用程序提供有关失败的附加信息。 这可以通过ModelAndView配置视图分辨率和渲染错误内容来解决，但该解决方案显然不是最优的。这就是为什么 Spring 3.2 引入了一个更好的选项，我们将在后面的部分讨论。 3.3. ResponseStatusExceptionResolver 这个解析器也在 Spring 3.0 中引入，默认情况下在DispatcherServlet中启用。 它的主要职责是使用自定义异常上可用的*@ResponseStatus*注释并将这些异常映射到 HTTP 状态代码。 这样的自定义异常可能如下所示： @ResponseStatus(value = HttpStatus.NOT_FOUND) public class MyResourceNotFoundException extends RuntimeException { public MyResourceNotFoundException() { super(); } public MyResourceNotFoundException(String message, Throwable cause) { super(message, cause); } public MyResourceNotFoundException(String message) { super(message); } public MyResourceNotFoundException(Throwable cause) { super(cause); } } 与DefaultHandlerExceptionResolver相同，此解析器在处理响应主体的方式上受到限制——它确实将状态代码映射到响应上，但主体仍然为空。 3.4 自定义HandlerExceptionResolver DefaultHandlerExceptionResolver和ResponseStatusExceptionResolver的组合在为 Spring RESTful 服务提供良好的错误处理机制方面大有帮助。如前所述，缺点是无法控制响应的主体。 理想情况下，我们希望能够输出 JSON 或 XML，具体取决于客户端要求的格式（通过Accept标头）。 仅此一项就证明了创建一个新的自定义异常解析器是合理的： @Component public class RestResponseStatusExceptionResolver extends AbstractHandlerExceptionResolver { @Override protected ModelAndView doResolveException( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { try { if (ex instanceof IllegalArgumentException) { return handleIllegalArgument( (IllegalArgumentException) ex, response, handler); } ... } catch (Exception handlerException) { logger.warn(\u0026#34;Handling of [\u0026#34; + ex.getClass().getName() + \u0026#34;] resulted in Exception\u0026#34;, handlerException); } return null; } private ModelAndView handleIllegalArgument(IllegalArgumentException ex, HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_CONFLICT); String accept = request.getHeader(HttpHeaders.ACCEPT); ... return new ModelAndView(); } } 这里要注意的一个细节是我们可以访问请求本身，因此我们可以考虑客户端发送的Accept标头的值。 例如，如果客户端请求application/json，那么在出现错误情况的情况下，我们希望确保返回一个使用application/json编码的响应正文。 另一个重要的实现细节是我们返回一个 ModelAndView——这是响应的主体，它允许我们在上面设置任何必要的东西。 这种方法是一种一致且易于配置的机制，用于 Spring REST 服务的错误处理。 但是，它确实有局限性：它与低级HtttpServletResponse 交互并适合使用ModelAndView的旧 MVC 模型，因此仍有改进的空间。 4. 解决方案3：@ControllerAdvice Spring 3.2通过@ControllerAdvice注释支持全局@ExceptionHandler。 这启用了一种脱离旧 MVC 模型并利用ResponseEntity以及@ExceptionHandler的类型安全性和灵活性的机制： @ControllerAdvice public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler(value = { IllegalArgumentException.class, IllegalStateException.class }) protected ResponseEntity\u0026lt;Object\u0026gt; handleConflict( RuntimeException ex, WebRequest request) { String bodyOfResponse = \u0026#34;This should be application specific\u0026#34;; return handleExceptionInternal(ex, bodyOfResponse, new HttpHeaders(), HttpStatus.CONFLICT, request); } } @ControllerAdvice注解允许我们将之前的多个分散的@ExceptionHandler整合到一个单一的全局错误处理组件中。 实际的机制非常简单，但也非常灵活：  它使我们可以完全控制响应的主体以及状态代码。 它提供了多个异常到同一方法的映射，以便一起处理。 它充分利用了较新的 RESTful ResposeEntity响应。  这里要记住的一件事是将使用@ExceptionHandler声明的异常与用作方法参数的异常相匹配。 如果这些不匹配，编译器不会抱怨——没有理由应该抱怨——Spring 也不会抱怨。 但是，当在运行时实际抛出异常时，异常解析机制将失败，并显示： java.lang.IllegalStateException: No suitable resolver for argument [0] [type=...] HandlerMethod details: ... 5. 解决方案4：ResponseStatusException（Spring 5及以上） Spring 5 引入了ResponseStatusException类。 我们可以创建它的一个实例，提供一个HttpStatus以及一个可选的reason和cause： @GetMapping(value = \u0026#34;/{id}\u0026#34;) public Foo findById(@PathVariable(\u0026#34;id\u0026#34;) Long id, HttpServletResponse response) { try { Foo resourceById = RestPreconditions.checkFound(service.findOne(id)); eventPublisher.publishEvent(new SingleResourceRetrievedEvent(this, response)); return resourceById; } catch (MyResourceNotFoundException exc) { throw new ResponseStatusException( HttpStatus.NOT_FOUND, \u0026#34;Foo Not Found\u0026#34;, exc); } } 使用ResponseStatusException有什么好处？  非常适合原型设计：我们可以非常快速地实施基本解决方案。 一种类型，多种状态码：一种异常类型可能导致多种不同的响应。与@ExceptionHandler相比，这减少了紧密耦合。 我们不必创建尽可能多的自定义异常类。 我们可以更好地控制异常处理，因为可以通过编程方式创建异常。  那么权衡呢？  没有统一的异常处理方式：与提供全局方法的@ControllerAdvice相比，执行一些应用程序范围的约定更加困难。 代码复制：我们可能会发现自己在多个控制器中复制代码。  我们还应该注意到，可以在一个应用程序中组合不同的方法。 例如，我们可以 全局 实现@ControllerAdvice ，也可以在本地实现ResponseStatusException 。 但是，我们需要小心：如果可以以多种方式处理同一个异常，我们可能会注意到一些令人惊讶的行为。一种可能的约定是始终以一种方式处理一种特定类型的异常。 有关更多详细信息和更多示例，请参阅我们的ResponseStatusException教程。 6. 处理Spring Security中的访问被拒绝 当经过身份验证的用户尝试访问他没有足够权限访问的资源时，会发生访问被拒绝。 6.1 REST 和方法级安全性 最后，让我们看看如何处理由方法级安全注解（@PreAuthorize、@PostAuthorize和@Secure ）引发的 Access Denied 异常。 当然，我们也会使用前面讨论过的全局异常处理机制来处理AccessDeniedException： @ControllerAdvice public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler({ AccessDeniedException.class }) public ResponseEntity\u0026lt;Object\u0026gt; handleAccessDeniedException( Exception ex, WebRequest request) { return new ResponseEntity\u0026lt;Object\u0026gt;( \u0026#34;Access denied message here\u0026#34;, new HttpHeaders(), HttpStatus.FORBIDDEN); } ... } 7. Spring Boot 支持 Spring Boot 提供了一个 ErrorController实现以合理的方式处理错误。 简而言之，它为浏览器提供后备错误页面（又名 Whitelabel 错误页面），并为 RESTful、非 HTML 请求提供 JSON 响应： { \u0026#34;timestamp\u0026#34;: \u0026#34;2019-01-17T16:12:45.977+0000\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Error processing the request!\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/my-endpoint-with-exceptions\u0026#34; } 像往常一样，Spring Boot 允许使用属性配置这些功能：  server.error.whitelabel.enabled：可用于禁用 Whitelabel 错误页面并依赖 servlet 容器提供 HTML 错误消息 server.error.include-stacktrace：始终 具有值；在 HTML 和 JSON 默认响应中包含堆栈跟踪 server.error.include-message： 从 2.3 版本开始，Spring Boot 在响应中隐藏了message字段，以避免泄露敏感信息；我们可以使用这个属性和一个 always 值来启用它  除了这些属性之外，我们还可以为 /error 提供我们自己的视图解析器映射，覆盖 Whitelabel 页面。 我们还可以通过在上下文中包含一个ErrorAttributes bean 来自定义我们想要在响应中显示的属性 。我们可以扩展 Spring Boot 提供的 DefaultErrorAttributes类以使事情变得更简单： @Component public class MyCustomErrorAttributes extends DefaultErrorAttributes { @Override public Map\u0026lt;String, Object\u0026gt; getErrorAttributes( WebRequest webRequest, ErrorAttributeOptions options) { Map\u0026lt;String, Object\u0026gt; errorAttributes = super.getErrorAttributes(webRequest, options); errorAttributes.put(\u0026#34;locale\u0026#34;, webRequest.getLocale() .toString()); errorAttributes.remove(\u0026#34;error\u0026#34;); //...  return errorAttributes; } } 如果我们想进一步定义（或覆盖）应用程序将如何处理特定内容类型的错误，我们可以注册一个 ErrorController bean。 同样，我们可以利用 Spring Boot 提供的默认 BasicErrorController 来帮助我们。 例如，假设我们想要自定义我们的应用程序如何处理在 XML 端点中触发的错误。我们所要做的就是使用 @RequestMapping定义一个公共方法，并声明它产生application/xml媒体类型： @Component public class MyErrorController extends BasicErrorController { public MyErrorController( ErrorAttributes errorAttributes, ServerProperties serverProperties) { super(errorAttributes, serverProperties.getError()); } @RequestMapping(produces = MediaType.APPLICATION_XML_VALUE) public ResponseEntity\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; xmlError(HttpServletRequest request) { // ...  } } 注意：这里我们仍然依赖于server.error.我们可能已经在项目中定义的引导属性，这些属性绑定到ServerProperties bean。 \u0026quot; ","permalink":"http://itcodingman.github.io/exception_handling_for_rest_with_spring/","tags":[],"title":"使用 Spring REST 错误处理"},{"categories":["REST","Spring"],"contents":"1. 概述 在本教程中，我们将处理需要在 Spring 应用程序的内部实体和发布回客户端的外部**DTO （数据传输对象）之间发生的转换。** 2. 模型映射器 让我们首先介绍我们将用于执行此实体-DTO 转换的主库*ModelMapper*。 我们将在pom.xml中需要这个依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.modelmapper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;modelmapper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 要检查此库是否有更新版本，请转到此处。 然后我们将在 Spring 配置中定义ModelMapper bean： @Bean public ModelMapper modelMapper() { return new ModelMapper(); } 3. DTO 接下来我们介绍一下这个双面问题的DTO端，Post DTO： public class PostDto { private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm\u0026#34;); private Long id; private String title; private String url; private String date; private UserDto user; public Date getSubmissionDateConverted(String timezone) throws ParseException { dateFormat.setTimeZone(TimeZone.getTimeZone(timezone)); return dateFormat.parse(this.date); } public void setSubmissionDate(Date date, String timezone) { dateFormat.setTimeZone(TimeZone.getTimeZone(timezone)); this.date = dateFormat.format(date); } // standard getters and setters } 请注意，两个自定义日期相关方法处理客户端和服务器之间来回的日期转换：  getSubmissionDateConverted()方法将日期字符串转换为服务器时区中的日期，以在持久的Post实体中使用它 setSubmissionDate()方法是在当前用户时区将 DTO 的日期设置为Post的日期  4. 服务层 现在让我们看一下服务级别操作，它显然适用于实体（而不是 DTO）： public List\u0026lt;Post\u0026gt; getPostsList( int page, int size, String sortDir, String sort) { PageRequest pageReq = PageRequest.of(page, size, Sort.Direction.fromString(sortDir), sort); Page\u0026lt;Post\u0026gt; posts = postRepository .findByUser(userService.getCurrentUser(), pageReq); return posts.getContent(); } 接下来我们将看一下服务之上的层，即控制器层。这是实际发生转换的地方。 5. 控制器层 接下来让我们检查一个标准控制器实现，为Post资源公开简单的 REST API。 我们将在这里展示一些简单的 CRUD 操作：创建、更新、获取一个和获取所有。鉴于操作非常简单，我们对 Entity-DTO 转换方面特别感兴趣： @Controller class PostRestController { @Autowired private IPostService postService; @Autowired private IUserService userService; @Autowired private ModelMapper modelMapper; @GetMapping @ResponseBody public List\u0026lt;PostDto\u0026gt; getPosts(...) { //...  List\u0026lt;Post\u0026gt; posts = postService.getPostsList(page, size, sortDir, sort); return posts.stream() .map(this::convertToDto) .collect(Collectors.toList()); } @PostMapping @ResponseStatus(HttpStatus.CREATED) @ResponseBody public PostDto createPost(@RequestBody PostDto postDto) { Post post = convertToEntity(postDto); Post postCreated = postService.createPost(post)); return convertToDto(postCreated); } @GetMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseBody public PostDto getPost(@PathVariable(\u0026#34;id\u0026#34;) Long id) { return convertToDto(postService.getPostById(id)); } @PutMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseStatus(HttpStatus.OK) public void updatePost(@PathVariable(\u0026#34;id\u0026#34;) Long id, @RequestBody PostDto postDto) { if(!Objects.equals(id, postDto.getId())){ throw new IllegalArgumentException(\u0026#34;IDs don\u0026#39;t match\u0026#34;); } Post post = convertToEntity(postDto); postService.updatePost(post); } } 这是我们从Post实体到PostDto的转换： private PostDto convertToDto(Post post) { PostDto postDto = modelMapper.map(post, PostDto.class); postDto.setSubmissionDate(post.getSubmissionDate(), userService.getCurrentUser().getPreference().getTimezone()); return postDto; } 这是从 DTO 到实体的转换： private Post convertToEntity(PostDto postDto) throws ParseException { Post post = modelMapper.map(postDto, Post.class); post.setSubmissionDate(postDto.getSubmissionDateConverted( userService.getCurrentUser().getPreference().getTimezone())); if (postDto.getId() != null) { Post oldPost = postService.getPostById(postDto.getId()); post.setRedditID(oldPost.getRedditID()); post.setSent(oldPost.isSent()); } return post; } 如我们所见，在模型映射器的帮助下，**转换逻辑快速而简单。**我们正在使用映射器的地图API，并且无需编写任何转换逻辑即可转换数据。 6. 单元测试 最后，让我们做一个非常简单的测试，以确保实体和 DTO 之间的转换工作正常： public class PostDtoUnitTest { private ModelMapper modelMapper = new ModelMapper(); @Test public void whenConvertPostEntityToPostDto_thenCorrect() { Post post = new Post(); post.setId(1L); post.setTitle(randomAlphabetic(6)); post.setUrl(\u0026#34;www.test.com\u0026#34;); PostDto postDto = modelMapper.map(post, PostDto.class); assertEquals(post.getId(), postDto.getId()); assertEquals(post.getTitle(), postDto.getTitle()); assertEquals(post.getUrl(), postDto.getUrl()); } @Test public void whenConvertPostDtoToPostEntity_thenCorrect() { PostDto postDto = new PostDto(); postDto.setId(1L); postDto.setTitle(randomAlphabetic(6)); postDto.setUrl(\u0026#34;www.test.com\u0026#34;); Post post = modelMapper.map(postDto, Post.class); assertEquals(postDto.getId(), post.getId()); assertEquals(postDto.getTitle(), post.getTitle()); assertEquals(postDto.getUrl(), post.getUrl()); } } \u0026quot; ","permalink":"http://itcodingman.github.io/entity_to_and_from_dto_for_a_java_spring_application/","tags":["DTO"],"title":"Spring REST API中从实体到 DTO 转换"},{"categories":["Spring"],"contents":"1. 简介 可以说，现代软件设计最重要的开发原则之一是依赖注入 (DI)，它很自然地源于另一个至关重要的原则：模块化。 这个教程将探讨 Spring 中一种特定类型的 DI 技术，称为基于构造函数的依赖注入， 简单地说，意味着我们在实例化时将所需的组件传递给一个类。 首先，我们需要在pom.xml中导入spring-context依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.8.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后我们需要设置一个配置文件。根据偏好，该文件可以是 POJO 或 XML 文件。 2. 基于注解的配置 Java 配置文件看起来类似于带有一些附加注释的 Java 对象： @Configuration @ComponentScan(\u0026#34;com.codingman.demodi\u0026#34;) public class Config { @Bean public Engine engine() { return new Engine(\u0026#34;v8\u0026#34;, 5); } @Bean public Transmission transmission() { return new Transmission(\u0026#34;sliding\u0026#34;); } } 在这里，我们使用注解来通知 Spring 运行时这个类提供了 bean 定义（@Bean注解），并且包com.codingman.demodi需要执行上下文扫描以查找其他 bean。接下来，我们定义一个Car类： @Component public class Car { @Autowired public Car(Engine engine, Transmission transmission) { this.engine = engine; this.transmission = transmission; } } Spring在进行包扫描时会遇到我们的Car类，并会通过调用@Autowired带注释的构造函数来初始化它的实例。 通过调用Config类的@Bean注解方法，我们将获得Engine 和 Transmission的实例。最后，我们需要使用我们的 POJO 配置来引导ApplicationContext： ApplicationContext context = new AnnotationConfigApplicationContext(Config.class); Car car = context.getBean(Car.class); 3. 隐式构造函数注入 从 Spring 4.3 开始，具有单个构造函数的类可以省略@Autowired注释。这是一个很好的便利和样板删除。 最重要的是，同样从 4.3 开始，我们可以在@Configuration注释类中利用基于构造函数的注入。另外，如果这样的类只有一个构造函数，我们也可以省略@Autowired注解。 4. 基于 XML 的配置 使用基于构造函数的依赖注入配置 Spring 运行时的另一种方法是使用 XML 配置文件： \u0026lt;bean id=\u0026#34;toyota\u0026#34; class=\u0026#34;com.codingman.demodi.domain.Car\u0026#34;\u0026gt; \u0026lt;constructor-arg index=\u0026#34;0\u0026#34; ref=\u0026#34;engine\u0026#34;/\u0026gt; \u0026lt;constructor-arg index=\u0026#34;1\u0026#34; ref=\u0026#34;transmission\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;engine\u0026#34; class=\u0026#34;com.codingman.demodi.domain.Engine\u0026#34;\u0026gt; \u0026lt;constructor-arg index=\u0026#34;0\u0026#34; value=\u0026#34;v4\u0026#34;/\u0026gt; \u0026lt;constructor-arg index=\u0026#34;1\u0026#34; value=\u0026#34;2\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transmission\u0026#34; class=\u0026#34;com.codingman.demodi.domain.Transmission\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;sliding\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 请注意，constructor-arg可以接受文字值或对另一个 bean 的引用，并且可以提供可选的显式索引和类型。我们可以使用Type和index属性来解决歧义（例如，如果构造函数采用相同类型的多个参数）。  name属性也可以用于 xml 到 java 变量的匹配，但是你的代码必须在编译时使用调试标志。  在这种情况下，我们需要使用ClassPathXmlApplicationContext引导我们的 Spring 应用程序上下文： ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;codingman.xml\u0026#34;); Car car = context.getBean(Car.class); 5. 优点和缺点 与字段注入相比，构造函数注入有一些优点。 第一个好处是可测试性。假设我们要对一个使用字段注入的 Spring bean 进行单元测试： public class UserService { @Autowired private UserRepository userRepository; } 在UserService 实例的构建过程中，我们无法初始化userRepository 状态。实现这一点的唯一方法是通过完全打破封装的反射 API此外，与简单的构造函数调用相比，生成的代码将不太安全。 此外，使用字段注入，我们无法强制执行类级别的不变量，因此可能会在没有正确初始化userRepository的情况下拥有 UserService 实例。因此，我们可能会在这里和那里遇到随机 的NullPointerException 。此外，使用构造函数注入，更容易构建不可变组件。 此外，从 OOP 的角度来看，使用构造函数创建对象实例更为自然。 另一方面，构造函数注入的主要缺点是其冗长，尤其是当 bean 具有少量依赖项时。有时这可能是因祸得福，因为我们可能会更加努力地将依赖项的数量保持在最低限度。 \u0026quot; ","permalink":"http://itcodingman.github.io/constructor_injection_in_spring/","tags":["Spring Core Basics","Spring DI"],"title":"Spring 的构造函数依赖注入"},{"categories":["REST","Spring"],"contents":"1.概述 在本教程中，我们将学习如何**在 Spring 中设置 REST，**包括控制器和 HTTP 响应代码、有效负载编组的配置和内容协商。 2. 了解 Spring 中的 REST Spring 框架支持两种创建 RESTful 服务的方式：  将 MVC 与ModelAndView一起使用 使用 HTTP 消息转换器  ModelAndView方法更老，文档更好，但也更冗长且配置繁重。它试图将 REST 范式硬塞到旧模型中，这并非没有问题。Spring 团队明白这一点，并从 Spring 3.0 开始提供一流的 REST 支持。 **新方法基于*HttpMessageConverter* 和注解，更轻量级且易于实现。**配置是最少的，它为我们对 RESTful 服务的期望提供了合理的默认值。 3. Java 配置 @Configuration @EnableWebMvc public class WebConfig{ // } 新的*@EnableWebMvc*注解做了一些有用的事情；具体来说，在 REST 的情况下，它会检测到类路径中 Jackson 和 JAXB 2 的存在，并自动创建和注册默认的 JSON 和 XML 转换器。注解的功能等同于 XML 版本： \u0026lt;mvc:注解驱动 /\u0026gt; 这是一条捷径，尽管它在许多情况下可能很有用，但并不完美。当我们需要更复杂的配置时，可以去掉注解，直接扩展WebMvcConfigurationSupport。 3.1 使用 Spring Boot 如果我们使用*@SpringBootApplication注解，并且spring-webmvc* 库位于类路径上，那么 @EnableWebMvc注解会自动添加，并带有默认的 autoconfiguration。 我们仍然可以通过在@Configuration 注释类上实现WebMvcConfigurer 接口 来将 MVC 功能添加到此配置中 。我们还可以使用 WebMvcRegistrationsAdapter实例来提供我们自己的 RequestMappingHandlerMapping、RequestMappingHandlerAdapter或ExceptionHandlerExceptionResolver 实现。 最后，如果我们想放弃 Spring Boot 的 MVC 特性并声明自定义配置，我们可以使用*@EnableWebMvc*注解来实现。 4. 测试 Spring 上下文 从 Spring 3.1 开始，我们获得了对@Configuration类的一流测试支持： @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( classes = {WebConfig.class, PersistenceConfig.class}, loader = AnnotationConfigContextLoader.class) public class SpringContextIntegrationTest { @Test public void contextLoads(){ // When  } } 我们使用*@ContextConfiguration注解指定 Java 配置类。新的AnnotationConfigContextLoader从@Configuration*类加载 bean 定义。 请注意，WebConfig配置类未包含在测试中，因为它需要在未提供的 Servlet 上下文中运行。 4.1 使用 Spring Boot Spring Boot 提供了几个注解来以更直观的方式为我们的测试设置 Spring ApplicationContext 。 我们可以只加载应用程序配置的特定部分，也可以模拟整个上下文启动过程。 例如， 如果我们想在不启动服务器的情况下创建整个上下文，我们可以使用*@SpringBootTest注解。* 有了它，我们就可以添加*@AutoConfigureMockMvc* 来注入 MockMvc 实例并发送 HTTP 请求*：* @RunWith(SpringRunner.class) @SpringBootTest @AutoConfigureMockMvc public class FooControllerAppIntegrationTest { @Autowired private MockMvc mockMvc; @Test public void whenTestApp_thenEmptyResponse() throws Exception { this.mockMvc.perform(get(\u0026#34;/foos\u0026#34;) .andExpect(status().isOk()) .andExpect(...); } } 为了避免创建整个上下文并只测试我们的 MVC 控制器，我们可以使用 @WebMvcTest： @RunWith(SpringRunner.class) @WebMvcTest(FooController.class) public class FooControllerWebLayerIntegrationTest { @Autowired private MockMvc mockMvc; @MockBean private IFooService service; @Test() public void whenTestMvcController_thenRetrieveExpectedResult() throws Exception { // ...  this.mockMvc.perform(get(\u0026#34;/foos\u0026#34;) .andExpect(...); } } 我们可以在“Spring Boot 中的测试”文章中找到有关此主题的详细信息。 5. 控制器 **@RestController是 RESTful API 的整个 Web 层中的核心工件*。***就本文而言，控制器正在建模一个简单的 REST 资源Foo： @RestController @RequestMapping(\u0026#34;/foos\u0026#34;) class FooController { @Autowired private IFooService service; @GetMapping public List\u0026lt;Foo\u0026gt; findAll() { return service.findAll(); } @GetMapping(value = \u0026#34;/{id}\u0026#34;) public Foo findById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { return RestPreconditions.checkFound(service.findById(id)); } @PostMapping @ResponseStatus(HttpStatus.CREATED) public Long create(@RequestBody Foo resource) { Preconditions.checkNotNull(resource); return service.create(resource); } @PutMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseStatus(HttpStatus.OK) public void update(@PathVariable( \u0026#34;id\u0026#34; ) Long id, @RequestBody Foo resource) { Preconditions.checkNotNull(resource); RestPreconditions.checkNotNull(service.getById(resource.getId())); service.update(resource); } @DeleteMapping(value = \u0026#34;/{id}\u0026#34;) @ResponseStatus(HttpStatus.OK) public void delete(@PathVariable(\u0026#34;id\u0026#34;) Long id) { service.deleteById(id); } } 正如我们所见，我们使用了一个简单的 Guava 风格的RestPreconditions实用程序： public class RestPreconditions { public static \u0026lt;T\u0026gt; T checkFound(T resource) { if (resource == null) { throw new MyResourceNotFoundException(); } return resource; } } Controller 实现是非公开的，因为它不需要。 通常，控制器是依赖链中的最后一个。它从 Spring 前端控制器（DispatcherServlet）接收 HTTP 请求，并将它们简单地委托给服务层。如果没有必须通过直接引用注入或操作控制器的用例，那么我们可能不希望将其声明为公共的。 请求映射很简单。与任何控制器一样，映射的实际值以及 HTTP 方法决定了请求的目标方法。@RequestBody将方法的参数绑定到 HTTP 请求的主体，而*@ResponseBody对响应和返回类型执行相同的操作。* @RestController 是在我们的类中包含 @ResponseBody 和 @Controller注释的简写。 他们还确保使用正确的 HTTP 转换器对资源进行编组和解组。将进行内容协商以选择将使用哪一个活动转换器，主要基于Accept标头，尽管也可以使用其他 HTTP 标头来确定表示形式。 6. 映射 HTTP 响应代码 HTTP 响应的状态码是 REST 服务最重要的部分之一，主题很快就会变得非常复杂。正确处理这些可能是服务的成败。 6.1 未映射的请求 如果 Spring MVC 接收到一个没有映射的请求，它认为该请求不允许，并返回一个 405 METHOD NOT ALLOWED 返回给客户端。 在向客户端返回405以指定允许哪些操作时，包含Allow HTTP 标头也是一种很好的做法。这是 Spring MVC 的标准行为，不需要任何额外的配置。 6.2 有效的映射请求 对于任何具有映射的请求，Spring MVC 认为该请求有效并以 200 OK 响应，如果没有另外指定其他状态代码。 正因为如此，控制器为create、update和delete操作声明了不同的@ResponseStatus，但没有为get声明，它确实应该返回默认的 200 OK。 6.3 客户端错误 在客户端错误的情况下，自定义异常被定义并映射到适当的错误代码。 简单地从 web 层的任何层抛出这些异常将确保 Spring 在 HTTP 响应上映射相应的状态代码： @ResponseStatus(HttpStatus.BAD_REQUEST) public class BadRequestException extends RuntimeException { // } @ResponseStatus(HttpStatus.NOT_FOUND) public class ResourceNotFoundException extends RuntimeException { // } 这些异常是 REST API 的一部分，因此，我们应该只在与 REST 对应的适当层中使用它们；例如，如果存在 DAO/DAL 层，则不应直接使用异常。 另请注意，这些不是检查异常，而是符合 Spring 实践和习惯用法的运行时异常。 6.4 使用@ExceptionHandler 将自定义异常映射到特定状态代码的另一个选项是在控制器中使用*@ExceptionHandler*注释。这种方法的问题在于注释仅适用于定义它的控制器。这意味着我们需要在每个控制器中单独声明它们。 当然，在 Spring 和 Spring Boot 中处理错误的方法更多，提供了更大的灵活性。 7. 额外的 Maven 依赖 除了标准 Web 应用程序所需的spring-webmvc依赖项之外，我们还需要为 REST API 设置内容编组和解组： \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 我们将使用这些库将 REST 资源的表示形式转换为 JSON 或 XML。 7.1 使用 Spring Boot 如果我们想检索 JSON 格式的资源，Spring Boot 提供了对不同库的支持，即 Jackson、Gson 和 JSON-B。 我们可以通过简单地在类路径中包含任何映射库来执行自动配置。 通常，如果我们正在开发一个 Web 应用程序，我们只需添加spring-boot-starter-web依赖项并依赖它来将所有必要的工件包含到我们的项目中： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Spring Boot 默认使用 Jackson。 如果我们想以 XML 格式序列化我们的资源，我们必须将 Jackson XML 扩展 ( jackson-dataformat-xml ) 添加到我们的依赖项中，或者通过使用回退到 JAXB 实现（JDK 中默认提供） 我们资源上的*@XmlRootElement*注释。\u0026quot; ","permalink":"http://itcodingman.github.io/building_a_restful_web_service_with_spring_and_java_based_configuration/","tags":[],"title":"使用 Spring 和 Java Config 构建 REST API"},{"categories":["REST","Spring"],"contents":"1. 概述 本教程说明了如何使用 Spring 创建 Web 应用程序。 我们将研究用于构建应用程序的 Spring Boot 解决方案，并查看非 Spring Boot 方法。 我们将主要使用 Java 配置，但也会看看它们等效的 XML 配置。 2. 使用 Spring Boot 进行设置 2.1 Maven 依赖 首先，我们需要spring-boot-starter-web 依赖项： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 该启动器包括：  spring-web和 Spring Web 应用程序所需的spring-webmvc模块 一个 Tomcat 启动器，这样我们就可以直接运行我们的 Web 应用程序，而无需显式安装任何服务器  2.2. 创建一个 Spring Boot 应用程序 开始使用 Spring Boot 最直接的方法是创建一个主类并使用 @SpringBootApplication对其进行注释： @SpringBootApplication public class SpringBootRestApplication { public static void main(String[] args) { SpringApplication.run(SpringBootRestApplication.class, args); } } 此单个注解等效于使用@Configuration、@EnableAutoConfiguration和@ComponentScan。 默认情况下，它将扫描同一包或以下的所有组件。 接下来，对于 Spring beans 的基于 Java 的配置，我们需要创建一个配置类并使用@Configuration注解对其进行注解： @Configuration public class WebConfig { } 这个注解是基于 Java 的 Spring 配置使用的主要工件；它本身使用@Component进行元注释，这使得带注释的类成为标准 bean，因此也是组件扫描的候选对象。 @Configuration类的主要目的是作为 Spring IoC 容器的 bean 定义的来源。更详细的描述请参见官方文档。 让我们也看看使用核心spring-webmvc库的解决方案。 3. 使用 spring-webmvc 进行设置 3.1 Maven 依赖项 首先，我们需要spring-webmvc依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.2 基于 Java 的 Web 配置 接下来，我们将添加具有@Configuration注解的配置类： @Configuration @EnableWebMvc @ComponentScan(basePackages = \u0026#34;com.codingman.controller\u0026#34;) public class WebConfig { } 在这里，与 Spring Boot 解决方案不同，我们必须显式定义@EnableWebMvc以设置默认 Spring MVC 配置和@ComponentScan以指定要扫描组件的包。 @EnableWebMvc注解提供Spring Web MVC配置，例如设置调度程序 servlet、启用@Controller和@RequestMapping注解以及设置其他默认值。 @ComponentScan配置组件扫描指令，指定要扫描的包。 3.3 初始化器类 接下来，我们需要添加一个实现 WebApplicationInitializer接口的类： public class AppInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext container) throws ServletException { AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); ctx.scan(\u0026#34;com.codingman\u0026#34;); container.addListener(new ContextLoaderListener(ctx)); ServletRegistration.Dynamic dyn = container.addServlet(\u0026#34;mvc\u0026#34;, new DispatcherServlet(ctx)); dyn.setLoadOnStartup(1); dyn.addMapping(\u0026#34;/\u0026#34;); } } 在这里，我们使用 AnnotationConfigWebApplicationContext类创建一个 Spring 上下文，这意味着我们只使用基于注释的配置。然后，我们指定要扫描组件和配置类的包。 最后，我们定义了 Web 应用程序的入口点——DispatcherServlet。 此类可以完全替换Servlet 3.0版本的web.xml文件。 4. XML 配置 让我们快速看一下等效的 XML Web 配置： \u0026lt;context:component-scan base-package=\u0026#34;com.codingman.controller\u0026#34; /\u0026gt; \u0026lt;mvc:annotation-driven /\u0026gt; 我们可以用上面的WebConfig类替换这个 XML 文件。 要启动应用程序，我们可以使用加载 XML 配置或 web.xml 文件的 Initializer 类。有关这两种方法的更多详细信息，请查看之前的文章。 \u0026quot; ","permalink":"http://itcodingman.github.io/bootstraping_a_web_application_with_spring_and_java_based_configuration/","tags":["Spring 5"],"title":"使用 Spring 5 创建 Web 应用程序"},{"categories":["REST","Spring Security"],"contents":"1. 概述 本文讨论如何在REST API 的相同 URI 结构上设置基本身份验证和摘要式身份验证。在之前的文章中，我们讨论了另一种保护 REST 服务的方法——基于表单的身份验证，因此基本和摘要式身份验证是自然的选择，也是更 RESTful 的一种。 2. 基本认证的配置 基于表单的身份验证不适合 RESTful 服务的主要原因是 Spring Security 将使用 Sessions——这当然是服务器上的状态，因此REST 中的无状态约束实际上被忽略了。 我们将从设置基本身份验证开始——首先我们从主**安全元素中删除旧的自定义入口点和过滤器： \u0026lt;http create-session=\u0026#34;stateless\u0026#34;\u0026gt; \u0026lt;intercept-url pattern=\u0026#34;/api/admin/**\u0026#34; access=\u0026#34;ROLE_ADMIN\u0026#34; /\u0026gt; \u0026lt;http-basic /\u0026gt; \u0026lt;/http\u0026gt; 请注意如何使用单个配置行添加对基本身份验证的支持 -  - 它处理BasicAuthenticationFilter和BasicAuthenticationEntryPoint的创建和连接。 2.1 满足无状态约束——摆脱会话 RESTful 架构风格的主要限制之一是客户端-服务器通信是完全无状态的，正如原始论文所述：  5.1.3 无状态 我们接下来为客户端-服务器交互添加一个约束：通信本质上必须是无状态的，如第 3.4.3 节（图 5-3）中的客户端-无状态-服务器（CSS）样式，这样从客户端到的每个请求服务器必须包含理解请求所需的所有信息，并且不能利用服务器上存储的任何上下文。因此，会话状态完全保留在客户端上。  服务端Session的概念在 Spring Security 中是一个由来已久的概念，直到现在完全移除它一直很困难，尤其是在使用命名空间进行配置的情况下。 然而，Spring Security为命名空间配置增加了一个用于创建会话的新无状态选项，这有效地保证了 Spring 不会创建或使用任何会话。这个新选项的作用是完全从安全过滤器链中删除所有与会话相关的过滤器，确保为每个请求执行身份验证。 3. 摘要认证的配置 从前面的配置开始，设置摘要认证所需的过滤器和入口点将被定义为 bean。然后，摘要入口点将覆盖由在幕后创建的入口点。最后，自定义摘要过滤器将被引入安全过滤器链中，使用安全命名空间的after语义将其直接定位在基本身份验证过滤器之后。 \u0026lt;http create-session=\u0026#34;stateless\u0026#34; entry-point-ref=\u0026#34;demoEntryPoint\u0026#34;\u0026gt; \u0026lt;intercept-url pattern=\u0026#34;/api/admin/**\u0026#34; access=\u0026#34;ROLE_ADMIN\u0026#34; /\u0026gt; \u0026lt;http-basic /\u0026gt; \u0026lt;custom-filter ref=\u0026#34;demoFilter\u0026#34; after=\u0026#34;BASIC_AUTH_FILTER\u0026#34; /\u0026gt; \u0026lt;/http\u0026gt; \u0026lt;beans:bean id=\u0026#34;demoFilter\u0026#34; class= \u0026#34;org.springframework.security.web.authentication.www.DigestAuthenticationFilter\u0026#34;\u0026gt; \u0026lt;beans:property name=\u0026#34;userDetailsService\u0026#34; ref=\u0026#34;userService\u0026#34; /\u0026gt; \u0026lt;beans:property name=\u0026#34;authenticationEntryPoint\u0026#34; ref=\u0026#34;demoEntryPoint\u0026#34; /\u0026gt; \u0026lt;/beans:bean\u0026gt; \u0026lt;beans:bean id=\u0026#34;demoEntryPoint\u0026#34; class= \u0026#34;org.springframework.security.web.authentication.www.DigestAuthenticationEntryPoint\u0026#34;\u0026gt; \u0026lt;beans:property name=\u0026#34;realmName\u0026#34; value=\u0026#34;Demo Authentication\u0026#34;/\u0026gt; \u0026lt;beans:property name=\u0026#34;key\u0026#34; value=\u0026#34;acegi\u0026#34; /\u0026gt; \u0026lt;/beans:bean\u0026gt; \u0026lt;authentication-manager\u0026gt; \u0026lt;authentication-provider\u0026gt; \u0026lt;user-service id=\u0026#34;userService\u0026#34;\u0026gt; \u0026lt;user name=\u0026#34;admin\u0026#34; password=\u0026#34;123\u0026#34; authorities=\u0026#34;ROLE_ADMIN\u0026#34; /\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34; password=\u0026#34;456\u0026#34; authorities=\u0026#34;ROLE_USER\u0026#34; /\u0026gt; \u0026lt;/user-service\u0026gt; \u0026lt;/authentication-provider\u0026gt; \u0026lt;/authentication-manager\u0026gt; 不幸的是，安全命名空间中不支持自动配置摘要式身份验证，就像可以使用配置基本身份验证一样。因此，必须手动定义必要的 bean 并将其连接到安全配置中。 4. 在同一个Restful服务中同时支持两种认证协议 单独的 Basic 或 Digest 身份验证可以在 Spring Security 中轻松实现；它在相同的 URI 映射上为相同的 RESTful Web 服务支持它们，这为服务的配置和测试引入了新的复杂性。 4.1 匿名请求 使用安全链中的基本过滤器和摘要过滤器，Spring Security 处理匿名请求（不包含身份验证凭据的请求,授权HTTP标头）的方式是，两个身份验证过滤器将找不到凭据并继续执行过滤链。然后，查看请求是如何未经过身份验证的，会抛出AccessDeniedException并在ExceptionTranslationFilter中捕获，它会启动摘要入口点，提示客户端输入凭据。 基本过滤器和摘要过滤器的职责都非常狭窄——如果它们无法识别请求中身份验证凭据的类型，它们将继续执行安全过滤器链。正因为如此，Spring Security 可以灵活地配置为支持同一 URI 上的多个身份验证协议。 当请求包含正确的身份验证凭据（基本或摘要）时，将正确使用该协议。但是，对于匿名请求，客户端只会收到摘要式身份验证凭据的提示。这是因为摘要入口点被配置为 Spring Security 链的主要和单一入口点；因此可以将摘要身份验证视为默认设置。 4.2 带有身份验证凭据的请求 带有 Basic 身份验证凭据的请求将由Authorization标头标识，该标头以前缀Basic开头。处理此类请求时，凭据将在基本身份验证过滤器中解码，并且请求将被授权。同样，带有摘要身份验证凭据的请求将使用前缀摘要作为其授权标头。 5. 测试两种场景 在使用基本或摘要进行身份验证后，测试将通过创建新资源来使用 REST 服务： @Test public void givenAuthenticatedByBasicAuth_whenAResourceIsCreated_then201IsReceived(){ // Given  // When  Response response = given() .auth().preemptive().basic( ADMIN_USERNAME, ADMIN_PASSWORD ) .contentType( HttpConstants.MIME_JSON ).body( new Foo( randomAlphabetic( 8 ) ) ) .post( paths.getFooURL() ); // Then  assertThat( response.getStatusCode(), is( 201 ) ); } @Test public void givenAuthenticatedByDigestAuth_whenAResourceIsCreated_then201IsReceived(){ // Given  // When  Response response = given() .auth().digest( ADMIN_USERNAME, ADMIN_PASSWORD ) .contentType( HttpConstants.MIME_JSON ).body( new Foo( randomAlphabetic( 8 ) ) ) .post( paths.getFooURL() ); // Then  assertThat( response.getStatusCode(), is( 201 ) ); } 请注意，使用基本身份验证的测试会抢先将凭据添加到请求中，无论服务器是否已对身份验证提出质疑。这是为了确保服务器不需要向客户端质询凭据，因为如果需要，质询将针对 Digest 凭据，因为这是默认设置。 \u0026quot; ","permalink":"http://itcodingman.github.io/basic_and_digest_authentication_for_a_rest_api_with_spring_security/","tags":["Authentication"],"title":"使用 Spring Security 的 REST 服务的基本和摘要式身份验证"},{"categories":["Persistence","Spring"],"contents":"1. 概述 这是对 Grails 3 和 GORM 的快速介绍。 我们当然会使用 Groovy，并且——隐含地——该框架还使用 Hibernate 来实现 ORM，Spring 框架用于依赖注入，SiteMash 用于布局和主题等。 2.数据源配置 我们无需指定任何显式数据源配置即可开始——默认情况下，Grails 使用 HSQLDB 数据库作为开发和测试环境。 但是如果你想改变这些默认值，你可以在application.yml中定义你选择的数据源： environments: development: dataSource: driverClassName : \u0026#34;com.mysql.jdbc.Driver\u0026#34; url : \u0026#34;jdbc:mysql://localhost:8080/test\u0026#34; dialect : org.hibernate.dialect.MySQL5InnoDBDialect 同样，我们可以在这里创建多个环境。 3. 域 Grails 能够基于数据库配置中的dbCreate属性为我们的域类创建数据库结构。 让我们在这里定义这些域类之一： Class User { String userName String password String email String age static constraints = { userName blank: false, unique: true password size: 5..10, blank: false email email: true, blank: true } } 请注意我们如何在模型中指定我们的验证约束，这使事情变得干净整洁，并且没有注释。 当实体被持久化时，这些约束将由 Grails 自动检查，如果这些约束中的任何一个被破坏，框架将抛出适当的验证异常。 我们还可以在模型的映射属性中指定 GORM 映射： static mapping = { sort \u0026#34;userName\u0026#34; } 现在，如果我们调用User.list() - 我们将返回按userName排序的结果。 我们当然可以通过将排序传递给列表 API 来实现相同的结果： User.list(sort: \u0026#34;userName\u0026#34;) 4. CRUD 操作 当我们看 API 操作时，脚手架在开始时扮演着非常有趣的角色；它允许您为域类生成基本的 CRUD API，包括：  必要的视图 标准 CRUD 操作的控制器操作 两种类型：动态和静态  以下是动态脚手架的工作原理： class UserController { static scaffold = true } 只需编写这一行代码，框架就会在运行时生成 7 个方法：显示、编辑、删除、创建、保存和更新。这些将作为该特定域实体的 API 发布。 静态脚手架示例：  使用脚手架创建视图：“ grails generate-views User ” 使用脚手架创建控制器和视图：“ grails generate-controller User ” 要在单个命令中创建所有内容，请使用：“ grails generate-all User ”  这些命令将为该特定域对象自动生成必要的管道。 现在让我们快速了解如何使用这些操作——例如，对于我们的User域对象。 创建新的User记录： def user = new User(username: \u0026#34;test\u0026#34;, password: \u0026#34;test123\u0026#34;, email: \u0026#34;a@a.com\u0026#34;, age: 14) user.save() 要获取单个记录： def user = User.get(1) 此get API 将以可编辑模式检索域对象。对于只读模式，我们可以使用read API： def user = User.read(1) 要更新现有记录： def user = User.get(1) user.userName = \u0026#34;testUpdate\u0026#34; user.age = 20 user.save() 以及对现有记录的简单删除操作： def user = User.get(1) user.delete() 5. GORM 查询 5.1 find 让我们从find API 开始： def user = User.find(\u0026#34;from User as u where u.username = \u0026#39;test\u0026#39; \u0026#34;) 我们还可以使用不同的语法来传递参数： def user = User.find(\u0026#34;from User as u where u.username?\u0026#34;, [\u0026#39;test\u0026#39;]) 我们还可以使用命名参数： def user = User.find(\u0026#34;from User as u where u.username=?\u0026#34;, [username: \u0026#39;test\u0026#39;]) 5.2 findBy Grails 提供了一个动态查找工具，它使用域属性在运行时执行查询并返回第一个匹配记录： def user = User.findByUsername(\u0026#34;test\u0026#34;) user = User.findByUsernameAndAge(\u0026#34;test\u0026#34;, 20) user = User.findByUsernameLike(\u0026#34;tes\u0026#34;) user = User.findByUsernameAndAgeNotEquals(\u0026#34;test\u0026#34;, \u0026#34;100\u0026#34;) 你可以在这里找到更多的表达方式。 5.3 Criteria 我们还可以使用一些灵活的标准检索数据： def user = User.find { username == \u0026#34;test\u0026#34;} def user = User.createCriteria() def results = user.list { like (\u0026#34;userName\u0026#34;, \u0026#34;te%\u0026#34;) and { between(\u0026#34;age\u0026#34;, 10, 20) } order(\u0026#34;userName\u0026#34;, \u0026#34;desc\u0026#34;) } 这里有一个说明——当使用条件查询时，使用“{}”而不是“()”。 5.4 执行查询/更新 GORM 还支持 HQL 查询语法——用于读取操作： def user = User.executeQuery( \u0026#34;select u.userName from User u where u.userName = ?\u0026#34;, [\u0026#39;test\u0026#39;]) 以及写操作： def user = User.executeUpdate(\u0026#34;delete User u where u.username =?\u0026#34;, [\u0026#39;test\u0026#39;]) \u0026quot; ","permalink":"http://itcodingman.github.io/grails_gorm_tutorial/","tags":[],"title":"Grails 3 和 GORM 简介"},{"categories":null,"contents":"","permalink":"http://itcodingman.github.io/search/","tags":null,"title":"Search"}]